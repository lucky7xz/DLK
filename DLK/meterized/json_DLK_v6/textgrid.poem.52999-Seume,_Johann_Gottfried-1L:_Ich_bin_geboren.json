{"textgrid.poem.52999": {"metadata": {"author": {"name": "Seume, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich bin geboren ", "genre": "verse", "period": "N.A.", "pub_year": 1786, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich bin geboren ", "tokens": ["Ich", "bin", "ge\u00b7bo\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Laut meiner Mutter Sage,", "tokens": ["Laut", "mei\u00b7ner", "Mut\u00b7ter", "Sa\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "In einem Dorf unweit des Rheins,", "tokens": ["In", "ei\u00b7nem", "Dorf", "un\u00b7weit", "des", "Rheins", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Am Sanct Egidytage.", "tokens": ["Am", "Sanct", "E\u00b7gi\u00b7dy\u00b7ta\u00b7ge", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "VVFIN", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Man trug mich Wicht ins Gotteshaus,", "tokens": ["Man", "trug", "mich", "Wicht", "ins", "Got\u00b7tes\u00b7haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und tauft' und trieb den Teufel aus;", "tokens": ["Und", "tauft'", "und", "trieb", "den", "Teu\u00b7fel", "aus", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Doch hats nicht viel geholfen.", "tokens": ["Doch", "hats", "nicht", "viel", "ge\u00b7hol\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "So tief ich mich erinnern kann,", "tokens": ["So", "tief", "ich", "mich", "e\u00b7rin\u00b7nern", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "PRF", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Kappe kaum entwachsen;", "tokens": ["Der", "Kap\u00b7pe", "kaum", "ent\u00b7wach\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Fing ich mit Meister Backeln an", "tokens": ["Fing", "ich", "mit", "Meis\u00b7ter", "Ba\u00b7ckeln", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mich im Donat zu baxen,", "tokens": ["Mich", "im", "Do\u00b7nat", "zu", "ba\u00b7xen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und conjugierte, ach und weh,", "tokens": ["Und", "con\u00b7ju\u00b7gier\u00b7te", ",", "ach", "und", "weh", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "XY", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Rasch ", "tokens": ["Rasch"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Mit vielen Circumflexen.", "tokens": ["Mit", "vie\u00b7len", "Cir\u00b7cum\u00b7fle\u00b7xen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$."], "meter": "-+-+---", "measure": "unknown.measure.di"}}, "stanza.3": {"line.1": {"text": "Mein Vater, Pastor Loci, war", "tokens": ["Mein", "Va\u00b7ter", ",", "Pas\u00b7tor", "Lo\u00b7ci", ",", "war"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PPOSAT", "NN", "$,", "NN", "NE", "$,", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Mann trotz Martin Luthern;", "tokens": ["Ein", "Mann", "trotz", "Mar\u00b7tin", "Lu\u00b7thern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "NE", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Hielt auf die Lehre rein und klar,", "tokens": ["Hielt", "auf", "die", "Leh\u00b7re", "rein", "und", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und lehrte fest mit Huttern;", "tokens": ["Und", "lehr\u00b7te", "fest", "mit", "Hut\u00b7tern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und als ein echter Orthodox", "tokens": ["Und", "als", "ein", "ech\u00b7ter", "Or\u00b7tho\u00b7dox"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ergriff er den Beweis des Stocks,", "tokens": ["Er\u00b7griff", "er", "den", "Be\u00b7weis", "des", "Stocks", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wenn die Vernunft mich plagte.", "tokens": ["Wenn", "die", "Ver\u00b7nunft", "mich", "plag\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Er fluchte oft gar f\u00fcrchterlich", "tokens": ["Er", "fluch\u00b7te", "oft", "gar", "f\u00fcrch\u00b7ter\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den H\u00f6llenspinozisten,", "tokens": ["Den", "H\u00f6l\u00b7len\u00b7spi\u00b7no\u00b7zis\u00b7ten", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und lamentirte j\u00e4mmerlich", "tokens": ["Und", "la\u00b7men\u00b7tir\u00b7te", "j\u00e4m\u00b7mer\u00b7lich"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ob dem Verfall der Christen;", "tokens": ["Ob", "dem", "Ver\u00b7fall", "der", "Chris\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.5": {"text": "Daher er denn auch Jeremies", "tokens": ["Da\u00b7her", "er", "denn", "auch", "Je\u00b7re\u00b7mies"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "PPER", "ADV", "ADV", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mich erste Frucht der Lenden hie\u00df,", "tokens": ["Mich", "ers\u00b7te", "Frucht", "der", "Len\u00b7den", "hie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "In der Manier der Bibel.", "tokens": ["In", "der", "Ma\u00b7nier", "der", "Bi\u00b7bel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Mit einem Kober voll Latein", "tokens": ["Mit", "ei\u00b7nem", "Ko\u00b7ber", "voll", "La\u00b7tein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Schickt' er mich fort ins Weite,", "tokens": ["Schickt'", "er", "mich", "fort", "ins", "Wei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "PTKVZ", "APPRART", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Und band mir auf die Seele ein,", "tokens": ["Und", "band", "mir", "auf", "die", "See\u00b7le", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht la\u00df zu seyn im Streite.", "tokens": ["Nicht", "la\u00df", "zu", "seyn", "im", "Strei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "PTKZU", "VAINF", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "De\u00df war ich denn nicht wenig froh,", "tokens": ["De\u00df", "war", "ich", "denn", "nicht", "we\u00b7nig", "froh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und ging ", "tokens": ["Und", "ging"], "token_info": ["word", "word"], "pos": ["KON", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Mit Briefen auf die Schule.", "tokens": ["Mit", "Brie\u00b7fen", "auf", "die", "Schu\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "So ging es fort in Einem Flu\u00df,", "tokens": ["So", "ging", "es", "fort", "in", "Ei\u00b7nem", "Flu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als ob ein Waldstrom rauschte.", "tokens": ["Als", "ob", "ein", "Wald\u00b7strom", "rauschte", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Hier wurd' uns denn Virgilius", "tokens": ["Hier", "wurd'", "uns", "denn", "Vir\u00b7gi\u00b7lius"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "NE"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Gar flei\u00dfig eingetrichtert,", "tokens": ["Gar", "flei\u00b7\u00dfig", "ein\u00b7ge\u00b7trich\u00b7tert", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und auch wohl eins nach seinem Fu\u00df,", "tokens": ["Und", "auch", "wohl", "eins", "nach", "sei\u00b7nem", "Fu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "PIS", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gott sey bey uns, gedichtert;", "tokens": ["Gott", "sey", "bey", "uns", ",", "ge\u00b7dich\u00b7tert", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "PPER", "$,", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Doch war der Rector nicht dabey,", "tokens": ["Doch", "war", "der", "Rec\u00b7tor", "nicht", "da\u00b7bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "PTKNEG", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So las ich Naso's Liebeley", "tokens": ["So", "las", "ich", "Na\u00b7so's", "Lie\u00b7be\u00b7ley"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Statt der Metamorphosen.", "tokens": ["Statt", "der", "Me\u00b7ta\u00b7mor\u00b7pho\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.8": {"line.1": {"text": "Der Plato wurde ", "tokens": ["Der", "Pla\u00b7to", "wur\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["ART", "NE", "VAFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Mit Hebelkraft getrieben,", "tokens": ["Mit", "He\u00b7bel\u00b7kraft", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und m\u00e4chtig manchem Peter Blax", "tokens": ["Und", "m\u00e4ch\u00b7tig", "man\u00b7chem", "Pe\u00b7ter", "Blax"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "PIAT", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Knoten eingerieben.", "tokens": ["Mit", "Kno\u00b7ten", "ein\u00b7ge\u00b7rie\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Das war Rumoren sp\u00e4t und fr\u00fch;", "tokens": ["Das", "war", "Ru\u00b7mo\u00b7ren", "sp\u00e4t", "und", "fr\u00fch", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Noch f\u00fchl' ich in den Fingern die", "tokens": ["Noch", "f\u00fchl'", "ich", "in", "den", "Fin\u00b7gern", "die"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Aphthonianschen Chrien.", "tokens": ["Aph\u00b7tho\u00b7ni\u00b7an\u00b7schen", "Chri\u00b7en", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Auch gings von Kal bis Hithpael,", "tokens": ["Auch", "gings", "von", "Kal", "bis", "Hith\u00b7pael", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Erl\u00f6s' uns von dem \u00dcbel!", "tokens": ["Er\u00b7l\u00f6s'", "uns", "von", "dem", "\u00dc\u00b7bel", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als pre\u00dften wir des Lebens \u00d6hl", "tokens": ["Als", "pre\u00df\u00b7ten", "wir", "des", "Le\u00b7bens", "\u00d6hl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VVFIN", "PPER", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Wurzeln aus der Bibel;", "tokens": ["Von", "Wur\u00b7zeln", "aus", "der", "Bi\u00b7bel", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und \u00fcber dem Entwurzeln sah,", "tokens": ["Und", "\u00fc\u00b7ber", "dem", "Ent\u00b7wur\u00b7zeln", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vor lauter Weisheit, bald beynah", "tokens": ["Vor", "lau\u00b7ter", "Weis\u00b7heit", ",", "bald", "bey\u00b7nah"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mein Kopf ", "tokens": ["Mein", "Kopf"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "-+", "measure": "iambic.single"}}, "stanza.10": {"line.1": {"text": "Ich konnte mit der H\u00f6llenfahrt", "tokens": ["Ich", "konn\u00b7te", "mit", "der", "H\u00f6l\u00b7len\u00b7fahrt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mich nicht recht ba\u00df vertragen;", "tokens": ["Mich", "nicht", "recht", "ba\u00df", "ver\u00b7tra\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Auch fuhr mir manches in den Bart,", "tokens": ["Auch", "fuhr", "mir", "man\u00b7ches", "in", "den", "Bart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und klebte fest am Kragen:", "tokens": ["Und", "kleb\u00b7te", "fest", "am", "Kra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Darob gesegnete ich die", "tokens": ["Da\u00b7rob", "ge\u00b7se\u00b7gne\u00b7te", "ich", "die"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ART"], "meter": "-+--+-++", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Hochheilige Theologie", "tokens": ["Hoch\u00b7hei\u00b7li\u00b7ge", "Theo\u00b7lo\u00b7gie"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Und schlug mich zu den Layen.", "tokens": ["Und", "schlug", "mich", "zu", "den", "La\u00b7yen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.11": {"line.1": {"text": "Man wei\u00df, die Leute baxten sich", "tokens": ["Man", "wei\u00df", ",", "die", "Leu\u00b7te", "bax\u00b7ten", "sich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "ART", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Kadix bis zum Rheine", "tokens": ["Von", "Ka\u00b7dix", "bis", "zum", "Rhei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "APPR", "APPRART", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So eben damahls f\u00fcrchterlich,", "tokens": ["So", "e\u00b7ben", "da\u00b7mahls", "f\u00fcrch\u00b7ter\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als w\u00e4ren Menschen Steine.", "tokens": ["Als", "w\u00e4\u00b7ren", "Men\u00b7schen", "Stei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Mein Vater war im Kriegstumult,", "tokens": ["Mein", "Va\u00b7ter", "war", "im", "Kriegs\u00b7tu\u00b7mult", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vor Kummer und vor Ungeduld,", "tokens": ["Vor", "Kum\u00b7mer", "und", "vor", "Un\u00b7ge\u00b7duld", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Gott tr\u00f6st' ihn dort! gestorben.", "tokens": ["Gott", "tr\u00f6st'", "ihn", "dort", "!", "ge\u00b7stor\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "$.", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Nun sing mich Sanct Justinian", "tokens": ["Nun", "sing", "mich", "Sanct", "Jus\u00b7ti\u00b7ni\u00b7an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "NE"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Mit Kodex und Pandecten", "tokens": ["Mit", "Ko\u00b7dex", "und", "Pan\u00b7dec\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "--+-++-", "measure": "anapaest.init"}, "line.3": {"text": "Nicht minder stark zu hudeln an,", "tokens": ["Nicht", "min\u00b7der", "stark", "zu", "hu\u00b7deln", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "PTKZU", "VVINF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und alle Seiten heckten", "tokens": ["Und", "al\u00b7le", "Sei\u00b7ten", "heck\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Mir Zweifel \u00fcber Zweifel aus:", "tokens": ["Mir", "Zwei\u00b7fel", "\u00fc\u00b7ber", "Zwei\u00b7fel", "aus", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Drob ward mir oft das Hirn so kraus,", "tokens": ["Drob", "ward", "mir", "oft", "das", "Hirn", "so", "kraus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df ich sehr schwer ergrimmte.", "tokens": ["Da\u00df", "ich", "sehr", "schwer", "er\u00b7grimm\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Die Regel Detri hatte mich", "tokens": ["Die", "Re\u00b7gel", "De\u00b7tri", "hat\u00b7te", "mich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "VAFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gerechtigkeit gelehret,", "tokens": ["Ge\u00b7rech\u00b7tig\u00b7keit", "ge\u00b7leh\u00b7ret", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und \u00fcber\u00fcberall fand ich", "tokens": ["Und", "\u00fc\u00b7be\u00b7r\u00fc\u00b7be\u00b7rall", "fand", "ich"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Das Ding nun umgekehret.", "tokens": ["Das", "Ding", "nun", "um\u00b7ge\u00b7keh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Vorz\u00fcglich wars ", "tokens": ["Vor\u00b7z\u00fcg\u00b7lich", "wars"], "token_info": ["word", "word"], "pos": ["ADV", "VAFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "So mi\u00dfgestalt und witsch und dumm,", "tokens": ["So", "mi\u00df\u00b7ge\u00b7stalt", "und", "witsch", "und", "dumm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Als schrieben es die M\u00f6nche.", "tokens": ["Als", "schrie\u00b7ben", "es", "die", "M\u00f6n\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Ich hatte leider dann und wann", "tokens": ["Ich", "hat\u00b7te", "lei\u00b7der", "dann", "und", "wann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "KON", "PWAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein F\u00fcnkchen Licht bekommen,", "tokens": ["Ein", "F\u00fcnk\u00b7chen", "Licht", "be\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Weil heimlich mich ein Engelsmann", "tokens": ["Weil", "heim\u00b7lich", "mich", "ein", "En\u00b7gels\u00b7mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJD", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Scharf in die Cur genommen:", "tokens": ["Scharf", "in", "die", "Cur", "ge\u00b7nom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Da sah ich denn gar j\u00e4mmerlich,", "tokens": ["Da", "sah", "ich", "denn", "gar", "j\u00e4m\u00b7mer\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie Frau Justinianinn mich", "tokens": ["Wie", "Frau", "Jus\u00b7ti\u00b7ni\u00b7a\u00b7ninn", "mich"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "NN", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mit ihren Zofen foppte.", "tokens": ["Mit", "ih\u00b7ren", "Zo\u00b7fen", "fopp\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Zum Durchbruch kam nun die Vernunft;", "tokens": ["Zum", "Durch\u00b7bruch", "kam", "nun", "die", "Ver\u00b7nunft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich zog das Maul, ich Gimpel,", "tokens": ["Ich", "zog", "das", "Maul", ",", "ich", "Gim\u00b7pel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sprach Conterband vor jeder Zunft;", "tokens": ["Sprach", "Con\u00b7ter\u00b7band", "vor", "je\u00b7der", "Zunft", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da stank der Koth im Dimpel.", "tokens": ["Da", "stank", "der", "Koth", "im", "Dim\u00b7pel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Nun sa\u00df der Teufel in dem Nest;", "tokens": ["Nun", "sa\u00df", "der", "Teu\u00b7fel", "in", "dem", "Nest", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Schnell hie\u00df es laut: ", "tokens": ["Schnell", "hie\u00df", "es", "laut", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.16": {"line.1": {"text": "Drauf lief ich, wie ein Don Quischott,", "tokens": ["Drauf", "lief", "ich", ",", "wie", "ein", "Don", "Qui\u00b7schott", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hinab hinan die Erde,", "tokens": ["Hin\u00b7ab", "hi\u00b7nan", "die", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bald Kuhschritt und bald Hundetrott,", "tokens": ["Bald", "Kuh\u00b7schritt", "und", "bald", "Hun\u00b7de\u00b7trott", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf meines Schusters Pferde:", "tokens": ["Auf", "mei\u00b7nes", "Schus\u00b7ters", "Pfer\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und h\u00f6rt' im Trabe links und rechts", "tokens": ["Und", "h\u00f6rt'", "im", "Tra\u00b7be", "links", "und", "rechts"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ADV", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Des altbipedischen Geschlechts", "tokens": ["Des", "alt\u00b7bi\u00b7pe\u00b7di\u00b7schen", "Ge\u00b7schlechts"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Gar sch\u00f6ne Litaneyen.", "tokens": ["Gar", "sch\u00f6\u00b7ne", "Li\u00b7ta\u00b7ne\u00b7yen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.17": {"line.1": {"text": "Bald war ich Dorfschulmeisterlein,", "tokens": ["Bald", "war", "ich", "Dorf\u00b7schul\u00b7meis\u00b7ter\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bald Held f\u00fcr sieben Dreyer;", "tokens": ["Bald", "Held", "f\u00fcr", "sie\u00b7ben", "Drey\u00b7er", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "CARD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bald sang ich neue Melodeyn", "tokens": ["Bald", "sang", "ich", "neu\u00b7e", "Me\u00b7lo\u00b7deyn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu einer alten Leyer;", "tokens": ["Zu", "ei\u00b7ner", "al\u00b7ten", "Le\u00b7yer", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Bald blies ich Horen von dem Thurm,", "tokens": ["Bald", "blies", "ich", "Ho\u00b7ren", "von", "dem", "Thurm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bald war ich Bootsmann in dem Sturm,", "tokens": ["Bald", "war", "ich", "Boots\u00b7mann", "in", "dem", "Sturm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Bald Amsterdamer B\u00f6hnhas.", "tokens": ["Bald", "A\u00b7mster\u00b7da\u00b7mer", "B\u00f6hn\u00b7has", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NE", "NE", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.18": {"line.1": {"text": "Bald lief ich, und bald jagte man", "tokens": ["Bald", "lief", "ich", ",", "und", "bald", "jag\u00b7te", "man"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KON", "ADV", "VVFIN", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mich mit dem Interdicte;", "tokens": ["Mich", "mit", "dem", "In\u00b7ter\u00b7dic\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "$."], "meter": "++-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Weil ich mich fast in jeden Plan", "tokens": ["Weil", "ich", "mich", "fast", "in", "je\u00b7den", "Plan"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie Stock ins Auge schickte.", "tokens": ["Wie", "Stock", "ins", "Au\u00b7ge", "schick\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "So wurd' ich immer fort geknufft.", "tokens": ["So", "wurd'", "ich", "im\u00b7mer", "fort", "ge\u00b7knufft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gut ist er! sprach man; wenn der Schuft", "tokens": ["Gut", "ist", "er", "!", "sprach", "man", ";", "wenn", "der", "Schuft"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "$.", "VVFIN", "PIS", "$.", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Nur nicht so r\u00e4sonnirte.", "tokens": ["Nur", "nicht", "so", "r\u00e4\u00b7son\u00b7nir\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Vorz\u00fcglich sprach ich rund und keck", "tokens": ["Vor\u00b7z\u00fcg\u00b7lich", "sprach", "ich", "rund", "und", "keck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "KON", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Narren und mit Schurken;", "tokens": ["Mit", "Nar\u00b7ren", "und", "mit", "Schur\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Daf\u00fcr bekam ich M\u00e4usedr ...", "tokens": ["Da\u00b7f\u00fcr", "be\u00b7kam", "ich", "M\u00e4u\u00b7se\u00b7dr", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Statt Pfeffer in die Gurken.", "tokens": ["Statt", "Pfef\u00b7fer", "in", "die", "Gur\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ich sagte stets nur, Kahn sey Kahn,", "tokens": ["Ich", "sag\u00b7te", "stets", "nur", ",", "Kahn", "sey", "Kahn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$,", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und das fuhr manchem Dummrian,", "tokens": ["Und", "das", "fuhr", "man\u00b7chem", "Dumm\u00b7ri\u00b7an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PIAT", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Mit Ehren, in die Nase.", "tokens": ["Mit", "Eh\u00b7ren", ",", "in", "die", "Na\u00b7se", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "So lange mans mit F\u00e4usten greift,", "tokens": ["So", "lan\u00b7ge", "mans", "mit", "F\u00e4us\u00b7ten", "greift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gehts immer noch erklecklich;", "tokens": ["Gehts", "im\u00b7mer", "noch", "er\u00b7kleck\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch wenn man mit dem Kopfe l\u00e4uft,", "tokens": ["Doch", "wenn", "man", "mit", "dem", "Kop\u00b7fe", "l\u00e4uft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird euch der Lauf gar schrecklich.", "tokens": ["Wird", "euch", "der", "Lauf", "gar", "schreck\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Drum rath' ich, jeder brave Tropf", "tokens": ["Drum", "ra\u00b7th'", "ich", ",", "je\u00b7der", "bra\u00b7ve", "Tropf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "$,", "PIAT", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Soll, so viel m\u00f6glich, ohne Kopf", "tokens": ["Soll", ",", "so", "viel", "m\u00f6g\u00b7lich", ",", "oh\u00b7ne", "Kopf"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VMFIN", "$,", "ADV", "ADV", "ADJD", "$,", "KOUI", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Am F\u00e4dchen weiter schlendern.", "tokens": ["Am", "F\u00e4d\u00b7chen", "wei\u00b7ter", "schlen\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "So lang' ich mich mit Prinz Eugen", "tokens": ["So", "lang'", "ich", "mich", "mit", "Prinz", "Eu\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "PPER", "PRF", "APPR", "NN", "NE"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und Friedrich tummeln konnte,", "tokens": ["Und", "Fried\u00b7rich", "tum\u00b7meln", "konn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und n\u00e4rrisch mich gar wundersch\u00f6n", "tokens": ["Und", "n\u00e4r\u00b7risch", "mich", "gar", "wun\u00b7der\u00b7sch\u00f6n"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An ihren Lorbern sonnte;", "tokens": ["An", "ih\u00b7ren", "Lor\u00b7bern", "sonn\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "So lange gings wohl immer gut;", "tokens": ["So", "lan\u00b7ge", "gings", "wohl", "im\u00b7mer", "gut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch nach und nach gerinnt das Blut,", "tokens": ["Doch", "nach", "und", "nach", "ge\u00b7rinnt", "das", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "KON", "APPR", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und morsch wird jeder Knochen.", "tokens": ["Und", "morsch", "wird", "je\u00b7der", "Kno\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Man wird so sauber und so fein", "tokens": ["Man", "wird", "so", "sau\u00b7ber", "und", "so", "fein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ADV", "ADJD", "KON", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht durch die Welt getragen.", "tokens": ["Nicht", "durch", "die", "Welt", "ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hier wurd' ein Arm und dort ein Bein", "tokens": ["Hier", "wurd'", "ein", "Arm", "und", "dort", "ein", "Bein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "KON", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mir in der Schlacht zerschlagen:", "tokens": ["Mir", "in", "der", "Schlacht", "zer\u00b7schla\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und hats der Feldscher gleich geflickt,", "tokens": ["Und", "hats", "der", "Feld\u00b7scher", "gleich", "ge\u00b7flickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit jedem gro\u00dfen Horne dr\u00fcckt", "tokens": ["Mit", "je\u00b7dem", "gro\u00b7\u00dfen", "Hor\u00b7ne", "dr\u00fcckt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das Flickwerk mich verteufelt.", "tokens": ["Das", "Flick\u00b7werk", "mich", "ver\u00b7teu\u00b7felt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Die Hand wird schwach, der Fu\u00df wird Eis.", "tokens": ["Die", "Hand", "wird", "schwach", ",", "der", "Fu\u00df", "wird", "Eis", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Bart ist Schnee am Kropfe,", "tokens": ["Der", "Bart", "ist", "Schnee", "am", "Krop\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das Haar ist um den Schedel wei\u00df,", "tokens": ["Das", "Haar", "ist", "um", "den", "Sche\u00b7del", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Schnupfen haust im Kopfe,", "tokens": ["Der", "Schnup\u00b7fen", "haust", "im", "Kop\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sonst neckt' ich k\u00fchnlich manchen Duns;", "tokens": ["Sonst", "neckt'", "ich", "k\u00fchn\u00b7lich", "man\u00b7chen", "Duns", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nun sitz' ich hier, Gott sey bey uns,", "tokens": ["Nun", "sitz'", "ich", "hier", ",", "Gott", "sey", "bey", "uns", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "NN", "VAFIN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Als Z\u00f6llner und als S\u00fcnder.", "tokens": ["Als", "Z\u00f6ll\u00b7ner", "und", "als", "S\u00fcn\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "KOUS", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "H\u00e4tt' ich geglaubt und nie gedacht,", "tokens": ["H\u00e4tt'", "ich", "ge\u00b7glaubt", "und", "nie", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVPP", "KON", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "K\u00f6nnt' ich jetzt stattlich lungern,", "tokens": ["K\u00f6nnt'", "ich", "jetzt", "statt\u00b7lich", "lun\u00b7gern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So weit hat mich Vernunft gebracht!", "tokens": ["So", "weit", "hat", "mich", "Ver\u00b7nunft", "ge\u00b7bracht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "PPER", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit ihr kann man verhungern.", "tokens": ["Mit", "ihr", "kann", "man", "ver\u00b7hun\u00b7gern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VMFIN", "PIS", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Daf\u00fcr, da\u00df ich ihr Ritter war,", "tokens": ["Da\u00b7f\u00fcr", ",", "da\u00df", "ich", "ihr", "Rit\u00b7ter", "war", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mach' ich nun hier mit grauem Haar", "tokens": ["Mach'", "ich", "nun", "hier", "mit", "grau\u00b7em", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Den Anhang der Akzise.", "tokens": ["Den", "An\u00b7hang", "der", "Ak\u00b7zi\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Noch wirft sich mir der Magen um,", "tokens": ["Noch", "wirft", "sich", "mir", "der", "Ma\u00b7gen", "um", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn Paroxismen kommen,", "tokens": ["Wenn", "Pa\u00b7ro\u00b7xis\u00b7men", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als h\u00e4tt' ich ein Emeticum", "tokens": ["Als", "h\u00e4tt'", "ich", "ein", "E\u00b7me\u00b7ti\u00b7cum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nur eben eingenommen,", "tokens": ["Nur", "e\u00b7ben", "ein\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Du sollst nicht stehlen! t\u00f6nt es schwer", "tokens": ["Du", "sollst", "nicht", "steh\u00b7len", "!", "t\u00f6nt", "es", "schwer"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF", "$.", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und m\u00e4chtig hoch von oben her:", "tokens": ["Und", "m\u00e4ch\u00b7tig", "hoch", "von", "o\u00b7ben", "her", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJD", "APPR", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Denn uns allein geb\u00fchrt es!", "tokens": ["Denn", "uns", "al\u00b7lein", "ge\u00b7b\u00fchrt", "es", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "VVFIN", "PPER", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "So bin am Ende von dem Ritt,", "tokens": ["So", "bin", "am", "En\u00b7de", "von", "dem", "Ritt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPRART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kraft meiner Amtsbekleidung,", "tokens": ["Kraft", "mei\u00b7ner", "Amts\u00b7be\u00b7klei\u00b7dung", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Ich denn ein St\u00fcck Israelit", "tokens": ["Ich", "denn", "ein", "St\u00fcck", "Is\u00b7ra\u00b7e\u00b7lit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "ART", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Akzise hei\u00dft Beschneidung.", "tokens": ["Ak\u00b7zi\u00b7se", "hei\u00dft", "Be\u00b7schnei\u00b7dung", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Kanonisirt man hier sofort", "tokens": ["Ka\u00b7no\u00b7ni\u00b7sirt", "man", "hier", "so\u00b7fort"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PIS", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gleich den Erfinder, soll doch dort", "tokens": ["Gleich", "den", "Er\u00b7fin\u00b7der", ",", "soll", "doch", "dort"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "VMFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der Teufel ihn kasteyen.", "tokens": ["Der", "Teu\u00b7fel", "ihn", "kas\u00b7te\u00b7yen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.27": {"line.1": {"text": "Gott, straf mich nicht in deinem Grimm", "tokens": ["Gott", ",", "straf", "mich", "nicht", "in", "dei\u00b7nem", "Grimm"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "PPER", "PTKNEG", "APPR", "PPOSAT", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr S\u00fcnden, die ich thue;", "tokens": ["F\u00fcr", "S\u00fcn\u00b7den", ",", "die", "ich", "thue", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Magen ist ein Ungeth\u00fcm;", "tokens": ["Der", "Ma\u00b7gen", "ist", "ein", "Un\u00b7ge\u00b7th\u00fcm", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich brauche Rock und Schuhe.", "tokens": ["Ich", "brau\u00b7che", "Rock", "und", "Schu\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Es geht nach altem schlechten Fu\u00df;", "tokens": ["Es", "geht", "nach", "al\u00b7tem", "schlech\u00b7ten", "Fu\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ich s\u00fcndige nur, was ich mu\u00df,", "tokens": ["Ich", "s\u00fcn\u00b7di\u00b7ge", "nur", ",", "was", "ich", "mu\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und andern in die Seele.", "tokens": ["Und", "an\u00b7dern", "in", "die", "See\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Noch jetzo regt der Kitzel sich,", "tokens": ["Noch", "jet\u00b7zo", "regt", "der", "Kit\u00b7zel", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und selber mit der Brille", "tokens": ["Und", "sel\u00b7ber", "mit", "der", "Bril\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Auf meiner Pritsche halt' ich mich", "tokens": ["Auf", "mei\u00b7ner", "Prit\u00b7sche", "halt'", "ich", "mich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Noch nicht geh\u00f6rig stille.", "tokens": ["Noch", "nicht", "ge\u00b7h\u00f6\u00b7rig", "stil\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Noch g\u00e4hrt das alte Cerebrum,", "tokens": ["Noch", "g\u00e4hrt", "das", "al\u00b7te", "Ce\u00b7re\u00b7brum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und meines Herzens Gaudium", "tokens": ["Und", "mei\u00b7nes", "Her\u00b7zens", "Gau\u00b7di\u00b7um"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sind Meister Rabners B\u00fccher.", "tokens": ["Sind", "Meis\u00b7ter", "Rab\u00b7ners", "B\u00fc\u00b7cher", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "Doch werd' ich nach und nach mit kalt,", "tokens": ["Doch", "werd'", "ich", "nach", "und", "nach", "mit", "kalt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "APPR", "KON", "APPR", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und fertig abzutrollen,", "tokens": ["Und", "fer\u00b7tig", "ab\u00b7zu\u00b7trol\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und seh vermuthlich jenseit bald,", "tokens": ["Und", "seh", "ver\u00b7muth\u00b7lich", "jen\u00b7seit", "bald", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie dort die Dinge rollen.", "tokens": ["Wie", "dort", "die", "Din\u00b7ge", "rol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Herrscht aber dort, wie hier, die Noth,", "tokens": ["Herrscht", "a\u00b7ber", "dort", ",", "wie", "hier", ",", "die", "Noth", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "$,", "PWAV", "ADV", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So schie\u00df' ich mich im Himmel todt;", "tokens": ["So", "schie\u00df'", "ich", "mich", "im", "Him\u00b7mel", "todt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPRART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dann mag ein Schurke leben.", "tokens": ["Dann", "mag", "ein", "Schur\u00b7ke", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Ihr Kinder, nehmt f\u00fcr diese Welt", "tokens": ["Ihr", "Kin\u00b7der", ",", "nehmt", "f\u00fcr", "die\u00b7se", "Welt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An mir euch ein Exempel;", "tokens": ["An", "mir", "euch", "ein", "Ex\u00b7em\u00b7pel", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sonst werdet ihr wie ich geprellt.", "tokens": ["Sonst", "wer\u00b7det", "ihr", "wie", "ich", "ge\u00b7prellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PWAV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Glaubt fest an Schlag und Stempel,", "tokens": ["Glaubt", "fest", "an", "Schlag", "und", "Stem\u00b7pel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wenn ihr das Gl\u00fcck des Lebens liebt,", "tokens": ["Wenn", "ihr", "das", "Gl\u00fcck", "des", "Le\u00b7bens", "liebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auch wenns Ephraimiten gibt;", "tokens": ["Auch", "wenns", "Eph\u00b7rai\u00b7mi\u00b7ten", "gibt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und h\u00fcthet euch vor Denken.", "tokens": ["Und", "h\u00fct\u00b7het", "euch", "vor", "Den\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}