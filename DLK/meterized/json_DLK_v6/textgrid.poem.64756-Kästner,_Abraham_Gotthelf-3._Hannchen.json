{"textgrid.poem.64756": {"metadata": {"author": {"name": "K\u00e4stner, Abraham Gotthelf", "birth": "N.A.", "death": "N.A."}, "title": "3. Hannchen", "genre": "verse", "period": "N.A.", "pub_year": 1745, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ungez\u00e4hlter Namen Menge", "tokens": ["Un\u00b7ge\u00b7z\u00e4hl\u00b7ter", "Na\u00b7men", "Men\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schm\u00fcckt die feurigen Ges\u00e4nge,", "tokens": ["Schm\u00fcckt", "die", "feu\u00b7ri\u00b7gen", "Ge\u00b7s\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die der Dichter Z\u00e4rtlichkeit", "tokens": ["Die", "der", "Dich\u00b7ter", "Z\u00e4rt\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihrer Sch\u00f6nen Reizung weiht.", "tokens": ["Ih\u00b7rer", "Sch\u00f6\u00b7nen", "Rei\u00b7zung", "weiht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Der besingt die kluge ", "tokens": ["Der", "be\u00b7singt", "die", "klu\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Jener die geputzte ", "tokens": ["Je\u00b7ner", "die", "ge\u00b7putz\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ART", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und des Dritten treuer Sinn", "tokens": ["Und", "des", "Drit\u00b7ten", "treu\u00b7er", "Sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sehnt sich nach ", "tokens": ["Sehnt", "sich", "nach"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.3": {"line.1": {"text": "Sind der Ewigkeit gewi\u00df.", "tokens": ["Sind", "der", "E\u00b7wig\u00b7keit", "ge\u00b7wi\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Doch wer kann ein Ende finden,", "tokens": ["Doch", "wer", "kann", "ein", "En\u00b7de", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.2": {"text": "Wo der Dichter Sch\u00f6pfungskraft", "tokens": ["Wo", "der", "Dich\u00b7ter", "Sch\u00f6p\u00b7fungs\u00b7kraft"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Namen, wie die Sch\u00f6nen, schafft?", "tokens": ["Na\u00b7men", ",", "wie", "die", "Sch\u00f6\u00b7nen", ",", "schafft", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ART", "NN", "$,", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Unbem\u00fcht, sie durchzuz\u00e4hlen,", "tokens": ["Un\u00b7be\u00b7m\u00fcht", ",", "sie", "durch\u00b7zu\u00b7z\u00e4h\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Werd' ich einen Namen w\u00e4hlen,", "tokens": ["Werd'", "ich", "ei\u00b7nen", "Na\u00b7men", "w\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Den von Reiz und Sch\u00f6nheit voll", "tokens": ["Den", "von", "Reiz", "und", "Sch\u00f6n\u00b7heit", "voll"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "KON", "NN", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Stets mein Lied erheben soll.", "tokens": ["Stets", "mein", "Lied", "er\u00b7he\u00b7ben", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Was man liebenswerth erkennet,", "tokens": ["Was", "man", "lie\u00b7bens\u00b7werth", "er\u00b7ken\u00b7net", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nennt man, wenn man ", "tokens": ["Nennt", "man", ",", "wenn", "man"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PIS", "$,", "KOUS", "PIS"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Wie viel Sch\u00f6nes nennt der nicht,", "tokens": ["Wie", "viel", "Sch\u00f6\u00b7nes", "nennt", "der", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VVFIN", "ART", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Der nur ", "tokens": ["Der", "nur"], "token_info": ["word", "word"], "pos": ["ART", "ADV"], "meter": "-+", "measure": "iambic.single"}}, "stanza.7": {"line.1": {"text": "Seht, wenn sich die bunten Mengen", "tokens": ["Seht", ",", "wenn", "sich", "die", "bun\u00b7ten", "Men\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "PRF", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sonntags aus den Kirchen dr\u00e4ngen,", "tokens": ["Sonn\u00b7tags", "aus", "den", "Kir\u00b7chen", "dr\u00e4n\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gebt auf unsrer Fenster Pracht", "tokens": ["Gebt", "auf", "uns\u00b7rer", "Fens\u00b7ter", "Pracht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVPP", "APPR", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit erhabnen Blicken Acht:", "tokens": ["Mit", "er\u00b7hab\u00b7nen", "Bli\u00b7cken", "Acht", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "CARD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Tausend m\u00fc\u00dft ihr reizend finden,", "tokens": ["Tau\u00b7send", "m\u00fc\u00dft", "ihr", "rei\u00b7zend", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tausend m\u00fcssen euch entz\u00fcnden,", "tokens": ["Tau\u00b7send", "m\u00fcs\u00b7sen", "euch", "ent\u00b7z\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und der ", "tokens": ["Und", "der"], "token_info": ["word", "word"], "pos": ["KON", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Mehr, als Aller sonsten seyn.", "tokens": ["Mehr", ",", "als", "Al\u00b7ler", "sons\u00b7ten", "seyn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "KOUS", "NN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Unbem\u00fcht, sie durchzuz\u00e4hlen,", "tokens": ["Un\u00b7be\u00b7m\u00fcht", ",", "sie", "durch\u00b7zu\u00b7z\u00e4h\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Werd' ich nur ein ", "tokens": ["Werd'", "ich", "nur", "ein"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "ART"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Dessen Reiz, der mich vergn\u00fcgt,", "tokens": ["Des\u00b7sen", "Reiz", ",", "der", "mich", "ver\u00b7gn\u00fcgt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aller ", "tokens": ["Al\u00b7ler"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}}}}}