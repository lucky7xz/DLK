{"textgrid.poem.38985": {"metadata": {"author": {"name": "Tieck, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "1L: M\u00fcd' und matt steig' ich vom Wagen", "genre": "verse", "period": "N.A.", "pub_year": 1813, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "M\u00fcd' und matt steig' ich vom Wagen", "tokens": ["M\u00fcd'", "und", "matt", "steig'", "ich", "vom", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "KON", "ADJD", "VVFIN", "PPER", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und vom Schmerz ersch\u00f6pft,", "tokens": ["Und", "vom", "Schmerz", "er\u00b7sch\u00f6pft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Such' ich Labsal mir und Linderung.", "tokens": ["Such'", "ich", "Lab\u00b7sal", "mir", "und", "Lin\u00b7de\u00b7rung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "PPER", "KON", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Nach dem Kaffeehause wallend", "tokens": ["Nach", "dem", "Kaf\u00b7fee\u00b7hau\u00b7se", "wal\u00b7lend"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Freu' ich mich schon am Gefrornen,", "tokens": ["Freu'", "ich", "mich", "schon", "am", "Ge\u00b7fror\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "APPRART", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.6": {"text": "Schwelge schon in dem Gedanken,", "tokens": ["Schwel\u00b7ge", "schon", "in", "dem", "Ge\u00b7dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Besser bald und kr\u00e4ftiger zu seyn.", "tokens": ["Bes\u00b7ser", "bald", "und", "kr\u00e4f\u00b7ti\u00b7ger", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "KON", "ADJD", "PTKZU", "VAINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Da \u00f6ffnet sich die Th\u00fcre gegen\u00fcber,", "tokens": ["Da", "\u00f6ff\u00b7net", "sich", "die", "Th\u00fc\u00b7re", "ge\u00b7gen\u00b7\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Heraus tritt, auf einer Kr\u00fccke hinkend,", "tokens": ["He\u00b7raus", "tritt", ",", "auf", "ei\u00b7ner", "Kr\u00fc\u00b7cke", "hin\u00b7kend", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Bla\u00df und mager ein Leidensgeno\u00df.", "tokens": ["Bla\u00df", "und", "ma\u00b7ger", "ein", "Lei\u00b7dens\u00b7ge\u00b7no\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "ART", "NN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Links kommt, mit dem Stabe klapperd,", "tokens": ["Links", "kommt", ",", "mit", "dem", "Sta\u00b7be", "klap\u00b7perd", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Ein andrer \u00e4chzend und st\u00f6hnend herbei:", "tokens": ["Ein", "an\u00b7drer", "\u00e4ch\u00b7zend", "und", "st\u00f6h\u00b7nend", "her\u00b7bei", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Ein Diener schl\u00e4gt die Th\u00fcr dort auf,", "tokens": ["Ein", "Die\u00b7ner", "schl\u00e4gt", "die", "Th\u00fcr", "dort", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und auf zwei Kr\u00fccken schleppt sich noch einer her,", "tokens": ["Und", "auf", "zwei", "Kr\u00fc\u00b7cken", "schleppt", "sich", "noch", "ei\u00b7ner", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "CARD", "NN", "VVFIN", "PRF", "ADV", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Sieh, dort haspelt sich jener an den W\u00e4nden fort,", "tokens": ["Sieh", ",", "dort", "has\u00b7pelt", "sich", "je\u00b7ner", "an", "den", "W\u00e4n\u00b7den", "fort", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "VVFIN", "PRF", "PDAT", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein andrer wieder wird von tr\u00f6stenden Freunde gef\u00fchret,", "tokens": ["Ein", "an\u00b7drer", "wie\u00b7der", "wird", "von", "tr\u00f6s\u00b7ten\u00b7den", "Freun\u00b7de", "ge\u00b7f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "VAFIN", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Jenen schleppen zwei redselige Bedienten,", "tokens": ["Je\u00b7nen", "schlep\u00b7pen", "zwei", "red\u00b7se\u00b7li\u00b7ge", "Be\u00b7dien\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "CARD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.11": {"text": "Und drinn im langen k\u00fchlen Saale", "tokens": ["Und", "drinn", "im", "lan\u00b7gen", "k\u00fch\u00b7len", "Saa\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Sitzen schon drei Kranke in Armsesseln l\u00e4ngst.", "tokens": ["Sit\u00b7zen", "schon", "drei", "Kran\u00b7ke", "in", "Arm\u00b7ses\u00b7seln", "l\u00e4ngst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "CARD", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Und hin nach Italien komm' ich", "tokens": ["Und", "hin", "nach", "I\u00b7ta\u00b7li\u00b7en", "komm'", "ich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "NE", "VVFIN", "PPER"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Um zu genesen?", "tokens": ["Um", "zu", "ge\u00b7ne\u00b7sen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUI", "PTKZU", "VVINF", "$."], "meter": "+-+--", "measure": "unknown.measure.di"}}, "stanza.4": {"line.1": {"text": "An der Wand sind alle Masken", "tokens": ["An", "der", "Wand", "sind", "al\u00b7le", "Mas\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VAFIN", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Arlechin, Pierrot, Brighella und Pantalon", "tokens": ["Ar\u00b7le\u00b7chin", ",", "Pier\u00b7rot", ",", "Brig\u00b7hel\u00b7la", "und", "Pan\u00b7ta\u00b7lon"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "NN", "$,", "NE", "KON", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "In kr\u00e4ftigen Farben bunt gemahlt:", "tokens": ["In", "kr\u00e4f\u00b7ti\u00b7gen", "Far\u00b7ben", "bunt", "ge\u00b7mahlt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und nun sitzen wir all und bilden", "tokens": ["Und", "nun", "sit\u00b7zen", "wir", "all", "und", "bil\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PIAT", "KON", "VVINF"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Ein Concilium,", "tokens": ["Ein", "Con\u00b7ci\u00b7lium", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Und referiren,", "tokens": ["Und", "re\u00b7fe\u00b7ri\u00b7ren", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVINF", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Judiciren,", "tokens": ["Ju\u00b7di\u00b7ci\u00b7ren", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "Lementiren,", "tokens": ["Le\u00b7men\u00b7ti\u00b7ren", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.9": {"text": "Setzen den Casus der Krankheit,", "tokens": ["Set\u00b7zen", "den", "Ca\u00b7sus", "der", "Krank\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NE", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Die F\u00fclle der Leiden,", "tokens": ["Die", "F\u00fcl\u00b7le", "der", "Lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.11": {"text": "Das Mangelhafte der Constitution,", "tokens": ["Das", "Man\u00b7gel\u00b7haf\u00b7te", "der", "Con\u00b7sti\u00b7tu\u00b7ti\u00b7on", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Weislich und preislich lang auseinander:", "tokens": ["Weis\u00b7lich", "und", "preis\u00b7lich", "lang", "aus\u00b7ein\u00b7an\u00b7der", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "ADJD", "PTKVZ", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.13": {"text": "Rath wird gegeben,", "tokens": ["Rath", "wird", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "VVPP", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.14": {"text": "Mittel gepriesen,", "tokens": ["Mit\u00b7tel", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.15": {"text": "W\u00fcnsche gehegt,", "tokens": ["W\u00fcn\u00b7sche", "ge\u00b7hegt", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.16": {"text": "Auf Aerzte geschm\u00e4lt,", "tokens": ["Auf", "A\u00b7erz\u00b7te", "ge\u00b7schm\u00e4lt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.17": {"text": "Das Wetter getadelt.", "tokens": ["Das", "Wet\u00b7ter", "ge\u00b7ta\u00b7delt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.18": {"text": "Ja, und was nicht zu l\u00e4ugnen,", "tokens": ["Ja", ",", "und", "was", "nicht", "zu", "l\u00e4ug\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KON", "PWS", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.19": {"text": "Keine Th\u00fcre schlie\u00dft,", "tokens": ["Kei\u00b7ne", "Th\u00fc\u00b7re", "schlie\u00dft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.20": {"text": "Kein Fenster ist dicht,", "tokens": ["Kein", "Fens\u00b7ter", "ist", "dicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.21": {"text": "Zug allenthalben,", "tokens": ["Zug", "al\u00b7len\u00b7thal\u00b7ben", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "ADV", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.22": {"text": "Und die Di\u00e4t", "tokens": ["Und", "die", "Di\u00b7\u00e4t"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.23": {"text": "Auch nicht die beste.", "tokens": ["Auch", "nicht", "die", "bes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ART", "ADJA", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Doch nach langem, vielen Rathen,", "tokens": ["Doch", "nach", "lan\u00b7gem", ",", "vie\u00b7len", "Ra\u00b7then", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "$,", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nach dem Schelten, Klagen, Tr\u00f6sten,", "tokens": ["Nach", "dem", "Schel\u00b7ten", ",", "Kla\u00b7gen", ",", "Tr\u00f6s\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Geht ein jeder doch nach Hause", "tokens": ["Geht", "ein", "je\u00b7der", "doch", "nach", "Hau\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "PIS", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eben so, wie er gekommen", "tokens": ["E\u00b7ben", "so", ",", "wie", "er", "ge\u00b7kom\u00b7men"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "PWAV", "PPER", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und die alte gute Zeit,", "tokens": ["Und", "die", "al\u00b7te", "gu\u00b7te", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Die Geduld, die unerla\u00dflich,", "tokens": ["Die", "Ge\u00b7duld", ",", "die", "un\u00b7er\u00b7la\u00df\u00b7lich", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Gutes Wetter, und ein Zufall", "tokens": ["Gu\u00b7tes", "Wet\u00b7ter", ",", "und", "ein", "Zu\u00b7fall"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Mu\u00df wie immer, so auch hier", "tokens": ["Mu\u00df", "wie", "im\u00b7mer", ",", "so", "auch", "hier"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VMFIN", "KOKOM", "ADV", "$,", "ADV", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Wohl das Beste thun.", "tokens": ["Wohl", "das", "Bes\u00b7te", "thun", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVINF", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}}}}