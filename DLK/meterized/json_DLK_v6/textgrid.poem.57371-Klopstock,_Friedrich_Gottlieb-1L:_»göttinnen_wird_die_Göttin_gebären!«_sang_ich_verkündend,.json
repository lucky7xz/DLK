{"textgrid.poem.57371": {"metadata": {"author": {"name": "Klopstock, Friedrich Gottlieb", "birth": "N.A.", "death": "N.A."}, "title": "1L: \u00bbg\u00f6ttinnen wird die G\u00f6ttin geb\u00e4ren!\u00ab sang ich verk\u00fcndend,", "genre": "verse", "period": "N.A.", "pub_year": 1794, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbg\u00f6ttinnen wird die G\u00f6ttin geb\u00e4ren!\u00ab sang ich verk\u00fcndend,", "tokens": ["\u00bb", "g\u00f6t\u00b7tin\u00b7nen", "wird", "die", "G\u00f6t\u00b7tin", "ge\u00b7b\u00e4\u00b7ren", "!", "\u00ab", "sang", "ich", "ver\u00b7k\u00fcn\u00b7dend", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVINF", "VAFIN", "ART", "NN", "VVPP", "$.", "$(", "VVFIN", "PPER", "VVPP", "$,"], "meter": "+--+-+--+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Da sie noch verwandelt nicht war, die heilige Freyheit,", "tokens": ["Da", "sie", "noch", "ver\u00b7wan\u00b7delt", "nicht", "war", ",", "die", "hei\u00b7li\u00b7ge", "Frey\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "PTKNEG", "VAFIN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "--+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Noch Alekto nicht war! geworden zur Nacht der Tag nicht,", "tokens": ["Noch", "A\u00b7lek\u00b7to", "nicht", "war", "!", "ge\u00b7wor\u00b7den", "zur", "Nacht", "der", "Tag", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "PTKNEG", "VAFIN", "$.", "VAPP", "APPRART", "NN", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Noch die Welt zum Chaos nicht.", "tokens": ["Noch", "die", "Welt", "zum", "Chaos", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPRART", "NN", "PTKNEG", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Falsches hab' ich verk\u00fcndet. Die G\u00f6ttin hat nicht geboren;", "tokens": ["Fal\u00b7sches", "hab'", "ich", "ver\u00b7k\u00fcn\u00b7det", ".", "Die", "G\u00f6t\u00b7tin", "hat", "nicht", "ge\u00b7bo\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "VAFIN", "PPER", "VVFIN", "$.", "ART", "NN", "VAFIN", "PTKNEG", "VVPP", "$."], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Aber Alekto! \u00bbEya, Poleya schlaf, Eumenidchen,", "tokens": ["A\u00b7ber", "A\u00b7lek\u00b7to", "!", "\u00bb", "Ey\u00b7a", ",", "Po\u00b7ley\u00b7a", "schlaf", ",", "Eu\u00b7men\u00b7id\u00b7chen", ","], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "NE", "$.", "$(", "NE", "$,", "NE", "VVFIN", "$,", "NE", "$,"], "meter": "+-+--+--+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Schlaf, du kleine Meg\u00e4ra! (die Mutter sang's) Der Rhodan", "tokens": ["Schlaf", ",", "du", "klei\u00b7ne", "Me\u00b7g\u00e4\u00b7ra", "!", "(", "die", "Mut\u00b7ter", "sang's", ")", "Der", "Rho\u00b7dan"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "PPER", "ADJA", "NN", "$.", "$(", "ART", "NN", "NE", "$(", "ART", "NN"], "meter": "+-+--+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Schweig', Alektochen, dir im See.", "tokens": ["Schweig'", ",", "A\u00b7lek\u00b7to\u00b7chen", ",", "dir", "im", "See", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NE", "$,", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Tisiphonchen, beginn an dem L\u00e4cheln die Mutter zu kennen,", "tokens": ["Ti\u00b7si\u00b7phon\u00b7chen", ",", "be\u00b7ginn", "an", "dem", "L\u00e4\u00b7cheln", "die", "Mut\u00b7ter", "zu", "ken\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "APPR", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.2": {"text": "Am sardonischen! Aber o schrey dich nicht blau nach den Kugeln,", "tokens": ["Am", "sar\u00b7do\u00b7ni\u00b7schen", "!", "A\u00b7ber", "o", "schrey", "dich", "nicht", "blau", "nach", "den", "Ku\u00b7geln", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "VVINF", "$.", "KON", "FM", "FM", "PPER", "PTKNEG", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "S\u00fcsse Tochter; da sind sie, und marmorne nicht! da sind auch", "tokens": ["S\u00fcs\u00b7se", "Toch\u00b7ter", ";", "da", "sind", "sie", ",", "und", "mar\u00b7mor\u00b7ne", "nicht", "!", "da", "sind", "auch"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NN", "$.", "ADV", "VAFIN", "PPER", "$,", "KON", "VVFIN", "PTKNEG", "$.", "ADV", "VAFIN", "ADV"], "meter": "+-+--+--+--+--+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Z\u00fcndbare K\u00fcgelchen ohne Zahl!", "tokens": ["Z\u00fcnd\u00b7ba\u00b7re", "K\u00fc\u00b7gel\u00b7chen", "oh\u00b7ne", "Zahl", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.4": {"line.1": {"text": "Wie du so schnell das Spiel mit den Kugeln, und K\u00fcgelchen lernest,", "tokens": ["Wie", "du", "so", "schnell", "das", "Spiel", "mit", "den", "Ku\u00b7geln", ",", "und", "K\u00fc\u00b7gel\u00b7chen", "ler\u00b7nest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "ART", "NN", "APPR", "ART", "NN", "$,", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "N\u00e4chtliche, schwarzbehautete! Wie dir die Schlang' in dem Haarbusch,", "tokens": ["N\u00e4cht\u00b7li\u00b7che", ",", "schwarz\u00b7be\u00b7hau\u00b7te\u00b7te", "!", "Wie", "dir", "die", "Schlang'", "in", "dem", "Haar\u00b7busch", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$.", "PWAV", "PPER", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+--+-+--+--+--+-", "measure": "hexameter"}, "line.3": {"text": "Schreckenblickende, steiget, so bald in den Todesschlummer", "tokens": ["Schre\u00b7cken\u00b7bli\u00b7cken\u00b7de", ",", "stei\u00b7get", ",", "so", "bald", "in", "den", "To\u00b7des\u00b7schlum\u00b7mer"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "$,", "ADV", "ADV", "APPR", "ART", "NN"], "meter": "+-+--+--+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Eya, Poleya aus Eisen sing.", "tokens": ["Ey\u00b7a", ",", "Po\u00b7ley\u00b7a", "aus", "Ei\u00b7sen", "sing", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "M\u00fctter sind blind; ich bin's nicht. Du bist eine wahre Meg\u00e4ra!", "tokens": ["M\u00fct\u00b7ter", "sind", "blind", ";", "ich", "bin's", "nicht", ".", "Du", "bist", "ei\u00b7ne", "wah\u00b7re", "Me\u00b7g\u00e4\u00b7ra", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "$.", "PPER", "VAFIN", "PTKNEG", "$.", "PPER", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-+--+-", "measure": "iambic.septa.invert"}, "line.2": {"text": "Gleichest mir, wie dem andern ein Dracheney. An dem Rhein kam's", "tokens": ["Glei\u00b7chest", "mir", ",", "wie", "dem", "an\u00b7dern", "ein", "Dra\u00b7che\u00b7ney", ".", "An", "dem", "Rhein", "kam's"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "PWAV", "ART", "ADJA", "ART", "NN", "$.", "APPR", "ART", "NE", "NE"], "meter": "---+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Todt mir zur Welt; du lebest, lebst! und des Schwachen spott' ich,", "tokens": ["Todt", "mir", "zur", "Welt", ";", "du", "le\u00b7best", ",", "lebst", "!", "und", "des", "Schwa\u00b7chen", "spott'", "ich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPRART", "NN", "$.", "PPER", "VVFIN", "$,", "VVFIN", "$.", "KON", "ART", "NN", "VVFIN", "PPER", "$,"], "meter": "+--+-+-+--+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Der dich, G\u00f6ttergeburt, verkent.", "tokens": ["Der", "dich", ",", "G\u00f6t\u00b7ter\u00b7ge\u00b7burt", ",", "ver\u00b7kent", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "$,", "NE", "$,", "VVPP", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.6": {"line.1": {"text": "Tochter, dir wurde Geist; du verstehst die Mutter, sie warnt dich:", "tokens": ["Toch\u00b7ter", ",", "dir", "wur\u00b7de", "Geist", ";", "du", "ver\u00b7stehst", "die", "Mut\u00b7ter", ",", "sie", "warnt", "dich", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "NN", "$.", "PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "PPER", "$."], "meter": "+--+-+--+-+-+-+", "measure": "iambic.septa.invert"}, "line.2": {"text": "Lass dich niemals blenden den Wahn der westlichen Th\u00f6rin!", "tokens": ["Lass", "dich", "nie\u00b7mals", "blen\u00b7den", "den", "Wahn", "der", "west\u00b7li\u00b7chen", "Th\u00f6\u00b7rin", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Ungethanes Gesetz ist (w\u00e4hnet sie) leerer Schall, ist", "tokens": ["Un\u00b7ge\u00b7tha\u00b7nes", "Ge\u00b7setz", "ist", "(", "w\u00e4h\u00b7net", "sie", ")", "lee\u00b7rer", "Schall", ",", "ist"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADJA", "NN", "VAFIN", "$(", "VVFIN", "PPER", "$(", "ADJA", "NN", "$,", "VAFIN"], "meter": "+-+--+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Bild des K\u00fcnstlers, das eilet, bleibt.\u00ab", "tokens": ["Bild", "des", "K\u00fcnst\u00b7lers", ",", "das", "ei\u00b7let", ",", "bleibt", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["NN", "ART", "NN", "$,", "PDS", "VVFIN", "$,", "VVFIN", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}}}}