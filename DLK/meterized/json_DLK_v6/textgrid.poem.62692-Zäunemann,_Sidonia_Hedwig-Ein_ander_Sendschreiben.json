{"textgrid.poem.62692": {"metadata": {"author": {"name": "Z\u00e4unemann, Sidonia Hedwig", "birth": "N.A.", "death": "N.A."}, "title": "Ein ander Sendschreiben", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "So, so, ", "tokens": ["So", ",", "so", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADV", "$,", "ADV", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Durch deinen netten Kiel anjetzo anzuregen,", "tokens": ["Durch", "dei\u00b7nen", "net\u00b7ten", "Kiel", "an\u00b7je\u00b7tzo", "an\u00b7zu\u00b7re\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein Thema kan hiervon ein wahrer Zeuge seyn:", "tokens": ["Dein", "The\u00b7ma", "kan", "hier\u00b7von", "ein", "wah\u00b7rer", "Zeu\u00b7ge", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PAV", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Da\u00df eine sch\u00f6ne Mohrin einem sch\u00f6nen Europ\u00e4er besser gefalle, als eine sch\u00f6ne Europ\u00e4erin.", "tokens": ["Da\u00df", "ei\u00b7ne", "sch\u00f6\u00b7ne", "Moh\u00b7rin", "ei\u00b7nem", "sch\u00f6\u00b7nen", "Eu\u00b7ro\u00b7p\u00e4\u00b7er", "bes\u00b7ser", "ge\u00b7fal\u00b7le", ",", "als", "ei\u00b7ne", "sch\u00f6\u00b7ne", "Eu\u00b7ro\u00b7p\u00e4\u00b7e\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "ADJD", "VVFIN", "$,", "KOUS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-+-+--+--+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.3": {"line.1": {"text": "Wohlan so schreibe ich! Mir f\u00e4llt ein Liedgen ein.", "tokens": ["Wo\u00b7hlan", "so", "schrei\u00b7be", "ich", "!", "Mir", "f\u00e4llt", "ein", "Lied\u00b7gen", "ein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Verzeihe, da\u00df ich dich jetzt auf den Schauplatz f\u00fchre,", "tokens": ["Ver\u00b7zei\u00b7he", ",", "da\u00df", "ich", "dich", "jetzt", "auf", "den", "Schau\u00b7platz", "f\u00fch\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "PRF", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und deine Liebes-Glut, doch sonder Neid ber\u00fchre.", "tokens": ["Und", "dei\u00b7ne", "Lie\u00b7bes\u00b7Glut", ",", "doch", "son\u00b7der", "Neid", "be\u00b7r\u00fch\u00b7re", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wie? soll ein muntrer Musen-Sohn", "tokens": ["Wie", "?", "soll", "ein", "mun\u00b7trer", "Mu\u00b7sen\u00b7Sohn"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Trieb der Liebe nicht empfinden?", "tokens": ["Den", "Trieb", "der", "Lie\u00b7be", "nicht", "emp\u00b7fin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wie? soll der junge Coridon", "tokens": ["Wie", "?", "soll", "der", "jun\u00b7ge", "Co\u00b7ri\u00b7don"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich nicht zu ihren Dienst verbinden?", "tokens": ["Sich", "nicht", "zu", "ih\u00b7ren", "Dienst", "ver\u00b7bin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKNEG", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "O nein! ich widerstrebe nicht.", "tokens": ["O", "nein", "!", "ich", "wi\u00b7der\u00b7stre\u00b7be", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PTKANT", "$.", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es fordert die Natur und Pflicht,", "tokens": ["Es", "for\u00b7dert", "die", "Na\u00b7tur", "und", "Pflicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ich soll ihr treuer Diener heisen.", "tokens": ["Ich", "soll", "ihr", "treu\u00b7er", "Die\u00b7ner", "hei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sie reitzet mich und andre an,", "tokens": ["Sie", "reit\u00b7zet", "mich", "und", "and\u00b7re", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KON", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So will ich denn, so sehr ich kan,", "tokens": ["So", "will", "ich", "denn", ",", "so", "sehr", "ich", "kan", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "$,", "ADV", "ADV", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ihr dienen, und mich ihr nicht freventlich entreisen.", "tokens": ["Ihr", "die\u00b7nen", ",", "und", "mich", "ihr", "nicht", "fre\u00b7vent\u00b7lich", "en\u00b7trei\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$,", "KON", "PPER", "PPER", "PTKNEG", "ADJD", "VVPP", "$."], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Vor ihrem Altar f\u00e4llt der Held,", "tokens": ["Vor", "ih\u00b7rem", "Al\u00b7tar", "f\u00e4llt", "der", "Held", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der K\u00f6nig und der Riese nieder;", "tokens": ["Der", "K\u00f6\u00b7nig", "und", "der", "Rie\u00b7se", "nie\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Priester wird von ihr gef\u00e4llt;", "tokens": ["Der", "Pries\u00b7ter", "wird", "von", "ihr", "ge\u00b7f\u00e4llt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er bringt ihr seine Sieges-Lieder.", "tokens": ["Er", "bringt", "ihr", "sei\u00b7ne", "Sie\u00b7ges\u00b7Lie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der Philosoph ist nicht im Stand,", "tokens": ["Der", "Phi\u00b7lo\u00b7soph", "ist", "nicht", "im", "Stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sich ihrer starken Macht und Hand", "tokens": ["Sich", "ih\u00b7rer", "star\u00b7ken", "Macht", "und", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PRF", "PPOSAT", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Durch seinen Witz zu widersetzen.", "tokens": ["Durch", "sei\u00b7nen", "Witz", "zu", "wi\u00b7der\u00b7set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die Liebe siegt nach Wunsch und Lust,", "tokens": ["Die", "Lie\u00b7be", "siegt", "nach", "Wunsch", "und", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Sie wei\u00df so gar die h\u00e4rtste Brust", "tokens": ["Sie", "wei\u00df", "so", "gar", "die", "h\u00e4rts\u00b7te", "Brust"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Bevor man sichs versieht aufs sch\u00e4rfste zu verletzen.", "tokens": ["Be\u00b7vor", "man", "sichs", "ver\u00b7sieht", "aufs", "sch\u00e4rfs\u00b7te", "zu", "ver\u00b7let\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PIS", "VVFIN", "APPRART", "ADJA", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ich habe ihre Macht gesehn,", "tokens": ["Ich", "ha\u00b7be", "ih\u00b7re", "Macht", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie hat mich an ihr Joch gebunden.", "tokens": ["Sie", "hat", "mich", "an", "ihr", "Joch", "ge\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was ist dir Coridon geschehn?", "tokens": ["Was", "ist", "dir", "Co\u00b7ri\u00b7don", "ge\u00b7schehn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Liebe hat dich \u00fcberwunden.", "tokens": ["Die", "Lie\u00b7be", "hat", "dich", "\u00fc\u00b7berw\u00b7un\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die reitzende ", "tokens": ["Die", "reit\u00b7zen\u00b7de"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+--", "measure": "dactylic.init"}, "line.6": {"text": "Hat mir die Freyheit weggenommen.", "tokens": ["Hat", "mir", "die", "Frey\u00b7heit", "weg\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ich bin, welch angenehmer Schmerz!", "tokens": ["Ich", "bin", ",", "welch", "an\u00b7ge\u00b7neh\u00b7mer", "Schmerz", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PWAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Durch diese ", "tokens": ["Durch", "die\u00b7se"], "token_info": ["word", "word"], "pos": ["APPR", "PDAT"], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Kaum da ich sie gesehn, gegr\u00fc\u00dft, geh\u00f6rt, gekommen.", "tokens": ["Kaum", "da", "ich", "sie", "ge\u00b7sehn", ",", "ge\u00b7gr\u00fc\u00dft", ",", "ge\u00b7h\u00f6rt", ",", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "PPER", "VVPP", "$,", "VVPP", "$,", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Bewundert ja nicht meine Wahl", "tokens": ["Be\u00b7wun\u00b7dert", "ja", "nicht", "mei\u00b7ne", "Wahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PTKNEG", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Meint nicht, ich wolte euch zur Quaal", "tokens": ["Meint", "nicht", ",", "ich", "wol\u00b7te", "euch", "zur", "Qua\u00b7al"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "$,", "PPER", "VMFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nur ", "tokens": ["Nur"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Nein! denkt nicht so von Coridon.", "tokens": ["Nein", "!", "denkt", "nicht", "so", "von", "Co\u00b7ri\u00b7don", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "VVFIN", "PTKNEG", "ADV", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es hat ja seiner Fl\u00f6ten-Thon", "tokens": ["Es", "hat", "ja", "sei\u00b7ner", "Fl\u00f6\u00b7ten\u00b7Thon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Euch, euren Ruhm und Prei\u00df gegeben.", "tokens": ["Euch", ",", "eu\u00b7ren", "Ruhm", "und", "Prei\u00df", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Drum h\u00f6hnt die That nicht die ich thu:", "tokens": ["Drum", "h\u00f6hnt", "die", "That", "nicht", "die", "ich", "thu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "PTKNEG", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Verg\u00f6nnet mir, und la\u00dft mir zu,", "tokens": ["Ver\u00b7g\u00f6n\u00b7net", "mir", ",", "und", "la\u00dft", "mir", "zu", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KON", "VVIMP", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Da\u00df meine Seele darf in ", "tokens": ["Da\u00df", "mei\u00b7ne", "See\u00b7le", "darf", "in"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "VMFIN", "APPR"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Das, was man alle Tage sieht,", "tokens": ["Das", ",", "was", "man", "al\u00b7le", "Ta\u00b7ge", "sieht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PIS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Pflegt man so hoch nicht zu betrachten.", "tokens": ["Pflegt", "man", "so", "hoch", "nicht", "zu", "be\u00b7trach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "ADJD", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Blume, die gew\u00f6hnlich bl\u00fcht,", "tokens": ["Die", "Blu\u00b7me", ",", "die", "ge\u00b7w\u00f6hn\u00b7lich", "bl\u00fcht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sieht man nicht sonderlich zu achten.", "tokens": ["Sieht", "man", "nicht", "son\u00b7der\u00b7lich", "zu", "ach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PTKNEG", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Nur rare Sachen fremde Frucht", "tokens": ["Nur", "ra\u00b7re", "Sa\u00b7chen", "frem\u00b7de", "Frucht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und seltne Sch\u00f6nheit wird gesucht,", "tokens": ["Und", "selt\u00b7ne", "Sch\u00f6n\u00b7heit", "wird", "ge\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und kan die Augen nach sich ziehen.", "tokens": ["Und", "kan", "die", "Au\u00b7gen", "nach", "sich", "zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Man siehet ja die Aloe.", "tokens": ["Man", "sie\u00b7het", "ja", "die", "A\u00b7loe", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Viel lieber als der Liljen Schnee", "tokens": ["Viel", "lie\u00b7ber", "als", "der", "Lil\u00b7jen", "Schnee"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "KOKOM", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Weil jenes rares ist, in unsern G\u00e4rten bl\u00fchen.", "tokens": ["Weil", "je\u00b7nes", "ra\u00b7res", "ist", ",", "in", "un\u00b7sern", "G\u00e4r\u00b7ten", "bl\u00fc\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "ADJA", "VAFIN", "$,", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Ein angenehmer Sommer-Tag", "tokens": ["Ein", "an\u00b7ge\u00b7neh\u00b7mer", "Som\u00b7mer\u00b7Tag"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kan Aug und Geist in Freude setzen;", "tokens": ["Kan", "Aug", "und", "Geist", "in", "Freu\u00b7de", "set\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "KON", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch da\u00df ichs recht beschreiben mag;", "tokens": ["Doch", "da\u00df", "ichs", "recht", "be\u00b7schrei\u00b7ben", "mag", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So bringt die Nacht oft mehr erg\u00f6tzen.", "tokens": ["So", "bringt", "die", "Nacht", "oft", "mehr", "er\u00b7g\u00f6t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ein blauer Himmel, den die Pracht", "tokens": ["Ein", "blau\u00b7er", "Him\u00b7mel", ",", "den", "die", "Pracht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der g\u00fcldnen Lichter helle macht,", "tokens": ["Der", "g\u00fcld\u00b7nen", "Lich\u00b7ter", "hel\u00b7le", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die still und warme Luft darneben;", "tokens": ["Die", "still", "und", "war\u00b7me", "Luft", "dar\u00b7ne\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJA", "NN", "PAV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Der feurig, doch nicht heise Schein", "tokens": ["Der", "feu\u00b7rig", ",", "doch", "nicht", "hei\u00b7se", "Schein"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "$,", "ADV", "PTKNEG", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Des Mondes, kan uns so erfreun;", "tokens": ["Des", "Mon\u00b7des", ",", "kan", "uns", "so", "er\u00b7freun", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Da\u00df wir des Nachts mit Lust in gr\u00fcnen Schatten leben.", "tokens": ["Da\u00df", "wir", "des", "Nachts", "mit", "Lust", "in", "gr\u00fc\u00b7nen", "Schat\u00b7ten", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADV", "APPR", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Sucht ihr nun eine solche Nacht", "tokens": ["Sucht", "ihr", "nun", "ei\u00b7ne", "sol\u00b7che", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ART", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Tage \u00f6fters vorzuziehen:", "tokens": ["Dem", "Ta\u00b7ge", "\u00f6f\u00b7ters", "vor\u00b7zu\u00b7zie\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was Wunder, wenn ich mich mit Macht", "tokens": ["Was", "Wun\u00b7der", ",", "wenn", "ich", "mich", "mit", "Macht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "NN", "$,", "KOUS", "PPER", "PRF", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Will um ", "tokens": ["Will", "um"], "token_info": ["word", "word"], "pos": ["VMFIN", "APPR"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Gleich denen sch\u00f6nen N\u00e4chten f\u00fcr,", "tokens": ["Gleich", "de\u00b7nen", "sch\u00f6\u00b7nen", "N\u00e4ch\u00b7ten", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "ADJA", "NN", "APPR", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die reitzend sind, und doch nicht brennen.", "tokens": ["Die", "reit\u00b7zend", "sind", ",", "und", "doch", "nicht", "bren\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "$,", "KON", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Erwehlt ihr immerhin den Tag", "tokens": ["Er\u00b7wehlt", "ihr", "im\u00b7mer\u00b7hin", "den", "Tag"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der weisen sch\u00f6nen gleichen mag:", "tokens": ["Der", "wei\u00b7sen", "sch\u00f6\u00b7nen", "glei\u00b7chen", "mag", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Bey meiner ", "tokens": ["Bey", "mei\u00b7ner"], "token_info": ["word", "word"], "pos": ["APPR", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.11": {"line.1": {"text": "Ein buntes Tuch aus Africa,", "tokens": ["Ein", "bun\u00b7tes", "Tuch", "aus", "A\u00b7fri\u00b7ca", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00e4llt Deutschlands Sch\u00f6nen in die Augen.", "tokens": ["F\u00e4llt", "Deutschlands", "Sch\u00f6\u00b7nen", "in", "die", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ein Kunst\u00fcck aus Batavia,", "tokens": ["Ein", "Kun\u00b7st\u00fcck", "aus", "Ba\u00b7ta\u00b7via", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Soll mehr als unsre Arbeit taugen.", "tokens": ["Soll", "mehr", "als", "uns\u00b7re", "Ar\u00b7beit", "tau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "KOKOM", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die Thiere, so der Mittag giebt,", "tokens": ["Die", "Thie\u00b7re", ",", "so", "der", "Mit\u00b7tag", "giebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die sind bey uns weit mehr beliebt,", "tokens": ["Die", "sind", "bey", "uns", "weit", "mehr", "be\u00b7liebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PPER", "ADJD", "ADV", "ADJD", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Als die in unsern Gr\u00e4nzen leben.", "tokens": ["Als", "die", "in", "un\u00b7sern", "Gr\u00e4n\u00b7zen", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So ists mit den Gew\u00e4chsen auch,", "tokens": ["So", "ists", "mit", "den", "Ge\u00b7w\u00e4ch\u00b7sen", "auch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wir werden einen fremden Strauch", "tokens": ["Wir", "wer\u00b7den", "ei\u00b7nen", "frem\u00b7den", "Strauch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Den angenehmsten Blick aus unsern Augen geben.", "tokens": ["Den", "an\u00b7ge\u00b7nehms\u00b7ten", "Blick", "aus", "un\u00b7sern", "Au\u00b7gen", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Ein Manuscript aus Mohrenland", "tokens": ["Ein", "Ma\u00b7nus\u00b7cript", "aus", "Moh\u00b7ren\u00b7land"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weis man nicht hoch genug zu sch\u00e4tzen.", "tokens": ["Weis", "man", "nicht", "hoch", "ge\u00b7nug", "zu", "sch\u00e4t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PTKNEG", "ADJD", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Buch aus einer fremden Hand", "tokens": ["Ein", "Buch", "aus", "ei\u00b7ner", "frem\u00b7den", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kan unser Aug und Geist erg\u00f6tzen.", "tokens": ["Kan", "un\u00b7ser", "Aug", "und", "Geist", "er\u00b7g\u00f6t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da nun ein unbelebtes Blat,", "tokens": ["Da", "nun", "ein", "un\u00b7be\u00b7leb\u00b7tes", "Blat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So viele W\u00fcrkung bey sich hat;", "tokens": ["So", "vie\u00b7le", "W\u00fcr\u00b7kung", "bey", "sich", "hat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "APPR", "PRF", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So wird man mir es nicht verdenken:", "tokens": ["So", "wird", "man", "mir", "es", "nicht", "ver\u00b7den\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "PPER", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wenn ich mit aufgewecktem Muth,", "tokens": ["Wenn", "ich", "mit", "auf\u00b7ge\u00b7weck\u00b7tem", "Muth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und Geist und Sch\u00f6nheit hat, mein Herze will verschenken.", "tokens": ["Und", "Geist", "und", "Sch\u00f6n\u00b7heit", "hat", ",", "mein", "Her\u00b7ze", "will", "ver\u00b7schen\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VAFIN", "$,", "PPOSAT", "VVFIN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Europens Lippen, Zung und Mund,", "tokens": ["Eu\u00b7ro\u00b7pens", "Lip\u00b7pen", ",", "Zung", "und", "Mund", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Stehn nur nach fremdgewachsnen Speisen.", "tokens": ["Stehn", "nur", "nach", "fremd\u00b7ge\u00b7wachs\u00b7nen", "Spei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Sie wissen sie zu jeder Stund", "tokens": ["Sie", "wis\u00b7sen", "sie", "zu", "je\u00b7der", "Stund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht gnug zu r\u00fchmen und zu preisen.", "tokens": ["Nicht", "gnug", "zu", "r\u00fch\u00b7men", "und", "zu", "prei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "O was vor Schmuck und Sch\u00f6n und Pracht", "tokens": ["O", "was", "vor", "Schmuck", "und", "Sch\u00f6n", "und", "Pracht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "PWS", "APPR", "NN", "KON", "NE", "KON", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Hat Africa uns zugedacht!", "tokens": ["Hat", "A\u00b7fri\u00b7ca", "uns", "zu\u00b7ge\u00b7dacht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Es giebt den Jungfern Glanz und Schimmer.", "tokens": ["Es", "giebt", "den", "Jung\u00b7fern", "Glanz", "und", "Schim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Liebt ihr nun was aus Africa,", "tokens": ["Liebt", "ihr", "nun", "was", "aus", "A\u00b7fri\u00b7ca", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PRELS", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So lieb ich auch ", "tokens": ["So", "lieb", "ich", "auch"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "PPER", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Und sch\u00e4tze dieses Kind vors ", "tokens": ["Und", "sch\u00e4t\u00b7ze", "die\u00b7ses", "Kind", "vors"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PDAT", "NN", "APPRART"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Die Blonden Sch\u00f6nen, ists nicht wahr?", "tokens": ["Die", "Blon\u00b7den", "Sch\u00f6\u00b7nen", ",", "ists", "nicht", "wahr", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "VAFIN", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kan man an allen Orten sehen.", "tokens": ["Kan", "man", "an", "al\u00b7len", "Or\u00b7ten", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nur schwarze Sch\u00f6nen bleiben rar;", "tokens": ["Nur", "schwar\u00b7ze", "Sch\u00f6\u00b7nen", "blei\u00b7ben", "rar", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVINF", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die\u00df mu\u00df mir jeder zugestehen.", "tokens": ["Die\u00df", "mu\u00df", "mir", "je\u00b7der", "zu\u00b7ge\u00b7ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Weil grosser H\u00e4upter ihr Pallast", "tokens": ["Weil", "gros\u00b7ser", "H\u00e4up\u00b7ter", "ihr", "Pal\u00b7last"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nur solche Sch\u00f6nen in sich fa\u00dft;", "tokens": ["Nur", "sol\u00b7che", "Sch\u00f6\u00b7nen", "in", "sich", "fa\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Man sucht sie nicht an allen Enden.", "tokens": ["Man", "sucht", "sie", "nicht", "an", "al\u00b7len", "En\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PTKNEG", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Drum was ein K\u00f6nig kostbar sch\u00e4tzt,", "tokens": ["Drum", "was", "ein", "K\u00f6\u00b7nig", "kost\u00b7bar", "sch\u00e4tzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PWS", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Da\u00df ist, was meine Brust erg\u00f6tzt.", "tokens": ["Da\u00df", "ist", ",", "was", "mei\u00b7ne", "Brust", "er\u00b7g\u00f6tzt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Nur einem solchen Kind will ich mein Herz verpf\u00e4nden.", "tokens": ["Nur", "ei\u00b7nem", "sol\u00b7chen", "Kind", "will", "ich", "mein", "Herz", "ver\u00b7pf\u00e4n\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PIAT", "NN", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Ich bin in Lieben delicat,", "tokens": ["Ich", "bin", "in", "Lie\u00b7ben", "de\u00b7li\u00b7cat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und liebe nicht was jeder liebet.", "tokens": ["Und", "lie\u00b7be", "nicht", "was", "je\u00b7der", "lie\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PWS", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich folge meinem eignen Rath", "tokens": ["Ich", "fol\u00b7ge", "mei\u00b7nem", "eig\u00b7nen", "Rath"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Damit mich keine Reu betr\u00fcbet.", "tokens": ["Da\u00b7mit", "mich", "kei\u00b7ne", "Reu", "be\u00b7tr\u00fc\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was edel, rar und kostbar heist,", "tokens": ["Was", "e\u00b7del", ",", "rar", "und", "kost\u00b7bar", "heist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "$,", "ADJD", "KON", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das liebe ich mit Mund und Geist;", "tokens": ["Das", "lie\u00b7be", "ich", "mit", "Mund", "und", "Geist", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die\u00df ist der Abgott meiner Sinnen.", "tokens": ["Die\u00df", "ist", "der", "Ab\u00b7gott", "mei\u00b7ner", "Sin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Drum bleibe ich bey meiner Wahl,", "tokens": ["Drum", "blei\u00b7be", "ich", "bey", "mei\u00b7ner", "Wahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und sage ein vor allemahl:", "tokens": ["Und", "sa\u00b7ge", "ein", "vor", "al\u00b7le\u00b7mahl", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "APPR", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Nach schwarzen Kirschen steigt man hoch,", "tokens": ["Nach", "schwar\u00b7zen", "Kir\u00b7schen", "steigt", "man", "hoch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und suchet sie dem Baum zu rauben.", "tokens": ["Und", "su\u00b7chet", "sie", "dem", "Baum", "zu", "rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ja ich behaupte dieses noch,", "tokens": ["Ja", "ich", "be\u00b7haup\u00b7te", "die\u00b7ses", "noch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PPER", "VVFIN", "PDAT", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Man greift mit Lust nach schwarzen Tauben,", "tokens": ["Man", "greift", "mit", "Lust", "nach", "schwar\u00b7zen", "Tau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Giebt nicht die \u00e4chte schwarze Tracht", "tokens": ["Giebt", "nicht", "die", "\u00e4ch\u00b7te", "schwar\u00b7ze", "Tracht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den gr\u00f6sten Fest- und Ehren-Pracht?", "tokens": ["Den", "gr\u00f6s\u00b7ten", "Fest", "und", "Eh\u00b7ren\u00b7Pracht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "TRUNC", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Schm\u00fcckt solche nicht die Silber-Haare?", "tokens": ["Schm\u00fcckt", "sol\u00b7che", "nicht", "die", "Sil\u00b7ber\u00b7Haa\u00b7re", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was Wunder, wenn mir in der Welt,", "tokens": ["Was", "Wun\u00b7der", ",", "wenn", "mir", "in", "der", "Welt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$,", "KOUS", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und ich mich h\u00f6chst vergn\u00fcgt mit einer ", "tokens": ["Und", "ich", "mich", "h\u00f6chst", "ver\u00b7gn\u00fcgt", "mit", "ei\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "PRF", "ADV", "VVPP", "APPR", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Die sch\u00f6ne L\u00e4nge der Persen,", "tokens": ["Die", "sch\u00f6\u00b7ne", "L\u00e4n\u00b7ge", "der", "Per\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Gang, Stellung, Nettigkeit und Mienen,", "tokens": ["Gang", ",", "Stel\u00b7lung", ",", "Net\u00b7tig\u00b7keit", "und", "Mie\u00b7nen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Kan dem verliebten Coridon,", "tokens": ["Kan", "dem", "ver\u00b7lieb\u00b7ten", "Co\u00b7ri\u00b7don", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zur innersten Vergn\u00fcgung dienen.", "tokens": ["Zur", "in\u00b7ners\u00b7ten", "Ver\u00b7gn\u00fc\u00b7gung", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Das zierlich aufgerollte Haar,", "tokens": ["Das", "zier\u00b7lich", "auf\u00b7ge\u00b7roll\u00b7te", "Haar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das sch\u00f6ne blaue Augen-Paar,", "tokens": ["Das", "sch\u00f6\u00b7ne", "blau\u00b7e", "Au\u00b7gen\u00b7Paar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mu\u00df dem, der sie erblickt, gefallen,", "tokens": ["Mu\u00df", "dem", ",", "der", "sie", "er\u00b7blickt", ",", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "ART", "$,", "PRELS", "PPER", "VVPP", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was sag ich mehr? Ihr rother Mund", "tokens": ["Was", "sag", "ich", "mehr", "?", "Ihr", "ro\u00b7ther", "Mund"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$.", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und wei\u00dfer Zahn hat mich verwundt!", "tokens": ["Und", "wei\u00b7\u00dfer", "Zahn", "hat", "mich", "ver\u00b7wundt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Nur dieses holde Kind erwehl ich mir vor allen.", "tokens": ["Nur", "die\u00b7ses", "hol\u00b7de", "Kind", "er\u00b7wehl", "ich", "mir", "vor", "al\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "ADJA", "NN", "VVFIN", "PPER", "PRF", "APPR", "PIAT", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Vergieb mir meinen Spa\u00df, ", "tokens": ["Ver\u00b7gieb", "mir", "mei\u00b7nen", "Spa\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Und denke, es sey hier so b\u00f6se nicht gemeint.", "tokens": ["Und", "den\u00b7ke", ",", "es", "sey", "hier", "so", "b\u00f6\u00b7se", "nicht", "ge\u00b7meint", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPER", "VAFIN", "ADV", "ADV", "ADJD", "PTKNEG", "VVPP", "$."], "meter": "-+-++--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Mich solte zwar jetzt nichts zu einem Scherze bringen,", "tokens": ["Mich", "sol\u00b7te", "zwar", "jetzt", "nichts", "zu", "ei\u00b7nem", "Scher\u00b7ze", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "PIS", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich k\u00f6nte wohl mit Recht das Klage-Liedgen singen,", "tokens": ["Ich", "k\u00f6n\u00b7te", "wohl", "mit", "Recht", "das", "Kla\u00b7ge\u00b7Lied\u00b7gen", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das dorten Israel in Babel angestimmt,", "tokens": ["Das", "dor\u00b7ten", "Is\u00b7rael", "in", "Ba\u00b7bel", "an\u00b7ge\u00b7stimmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "NE", "APPR", "NE", "VVPP", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Und abgesungen hat. Allein kein Mensche nimmt", "tokens": ["Und", "ab\u00b7ge\u00b7sun\u00b7gen", "hat", ".", "Al\u00b7lein", "kein", "Men\u00b7sche", "nimmt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVPP", "VAFIN", "$.", "ADV", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Mir doch mein Leiden ab; So mu\u00df ich mich selbst fassen,", "tokens": ["Mir", "doch", "mein", "Lei\u00b7den", "ab", ";", "So", "mu\u00df", "ich", "mich", "selbst", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PPOSAT", "NN", "PTKVZ", "$.", "ADV", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und zu gewisser Zeit das Trauren fahren lassen.", "tokens": ["Und", "zu", "ge\u00b7wis\u00b7ser", "Zeit", "das", "Trau\u00b7ren", "fah\u00b7ren", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "ART", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Das hab ich jetzt gethan: drum schrieb ich dieses Lied.", "tokens": ["Das", "hab", "ich", "jetzt", "ge\u00b7than", ":", "drum", "schrieb", "ich", "die\u00b7ses", "Lied", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "VVPP", "$.", "PAV", "VVFIN", "PPER", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Damit dein Auge auch das Gegen-", "tokens": ["Da\u00b7mit", "dein", "Au\u00b7ge", "auch", "das", "Ge\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "PPOSAT", "NN", "ADV", "ART", "TRUNC"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "So lies, was jetzo folgt: und merke auf mein Schreiben.", "tokens": ["So", "lies", ",", "was", "jet\u00b7zo", "folgt", ":", "und", "mer\u00b7ke", "auf", "mein", "Schrei\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PRELS", "ADV", "VVFIN", "$.", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Die Antwort wirst du mir gewi\u00df nicht schuldig bleiben.", "tokens": ["Die", "Ant\u00b7wort", "wirst", "du", "mir", "ge\u00b7wi\u00df", "nicht", "schul\u00b7dig", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PPER", "ADV", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Fehler magst du mir anbey zu wissen thun.", "tokens": ["Die", "Feh\u00b7ler", "magst", "du", "mir", "an\u00b7bey", "zu", "wis\u00b7sen", "thun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "PPER", "ADV", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Jetzt schreibt der Kiel nichts mehr; er schlie\u00dft und siegelt nun.", "tokens": ["Jetzt", "schreibt", "der", "Kiel", "nichts", "mehr", ";", "er", "schlie\u00dft", "und", "sie\u00b7gelt", "nun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NE", "PIS", "ADV", "$.", "PPER", "VVFIN", "KON", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}