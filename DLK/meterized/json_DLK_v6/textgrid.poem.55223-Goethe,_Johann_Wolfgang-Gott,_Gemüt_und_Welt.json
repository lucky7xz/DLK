{"textgrid.poem.55223": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "Gott, Gem\u00fct und Welt", "genre": "verse", "period": "N.A.", "pub_year": 1813, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In wenig Stunden", "tokens": ["In", "we\u00b7nig", "Stun\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PIAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Hat Gott das Rechte gefunden.", "tokens": ["Hat", "Gott", "das", "Rech\u00b7te", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Wer Gott vertraut,", "tokens": ["Wer", "Gott", "ver\u00b7traut", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "NN", "ADJD", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Ist schon auferbaut.", "tokens": ["Ist", "schon", "au\u00b7fer\u00b7baut", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Sogar dies Wort hat nicht gelogen:", "tokens": ["So\u00b7gar", "dies", "Wort", "hat", "nicht", "ge\u00b7lo\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "NN", "VAFIN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wen Gott betriegt, der ist wohl betrogen.", "tokens": ["Wen", "Gott", "be\u00b7triegt", ",", "der", "ist", "wohl", "be\u00b7tro\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$,", "PRELS", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Das ", "tokens": ["Das"], "token_info": ["word"], "pos": ["PDS"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Es dient und hilft in allen N\u00f6ten;", "tokens": ["Es", "dient", "und", "hilft", "in", "al\u00b7len", "N\u00f6\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn einer auch ", "tokens": ["Wenn", "ei\u00b7ner", "auch"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PIS", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "In Gottes Namen, la\u00df ihn beten.", "tokens": ["In", "Got\u00b7tes", "Na\u00b7men", ",", "la\u00df", "ihn", "be\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$,", "VVIMP", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ich wandle auf weiter, bunter Flur,", "tokens": ["Ich", "wand\u00b7le", "auf", "wei\u00b7ter", ",", "bun\u00b7ter", "Flur", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "$,", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Urspr\u00fcnglicher Natur;", "tokens": ["Ur\u00b7spr\u00fcng\u00b7li\u00b7cher", "Na\u00b7tur", ";"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein holder Born, in welchem ich bade,", "tokens": ["Ein", "hol\u00b7der", "Born", ",", "in", "wel\u00b7chem", "ich", "ba\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ist \u00dcberlieferung, ist Gnade.", "tokens": ["Ist", "\u00dc\u00b7berl\u00b7ie\u00b7fe\u00b7rung", ",", "ist", "Gna\u00b7de", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Was w\u00e4r ein Gott, der nur von au\u00dfen stie\u00dfe,", "tokens": ["Was", "w\u00e4r", "ein", "Gott", ",", "der", "nur", "von", "au\u00b7\u00dfen", "stie\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "$,", "PRELS", "ADV", "APPR", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Im Kreis das All am Finger laufen lie\u00dfe!", "tokens": ["Im", "Kreis", "das", "All", "am", "Fin\u00b7ger", "lau\u00b7fen", "lie\u00b7\u00dfe", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "APPRART", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ihm ziemt's, die Welt im Innern zu bewegen,", "tokens": ["Ihm", "ziemt's", ",", "die", "Welt", "im", "In\u00b7nern", "zu", "be\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Natur in Sich, Sich in Natur zu hegen,", "tokens": ["Na\u00b7tur", "in", "Sich", ",", "Sich", "in", "Na\u00b7tur", "zu", "he\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PRF", "$,", "PRF", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "So da\u00df, was in Ihm lebt und webt und ist,", "tokens": ["So", "da\u00df", ",", "was", "in", "Ihm", "lebt", "und", "webt", "und", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "$,", "PRELS", "APPR", "PPER", "VVFIN", "KON", "VVFIN", "KON", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Nie Seine Kraft, nie Seinen Geist vermi\u00dft", "tokens": ["Nie", "Sei\u00b7ne", "Kraft", ",", "nie", "Sei\u00b7nen", "Geist", "ver\u00b7mi\u00dft"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "$,", "ADV", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Im Innern ist ein Universum auch;", "tokens": ["Im", "In\u00b7nern", "ist", "ein", "U\u00b7ni\u00b7ver\u00b7sum", "auch", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Daher der V\u00f6lker l\u00f6blicher Gebrauch,", "tokens": ["Da\u00b7her", "der", "V\u00f6l\u00b7ker", "l\u00f6b\u00b7li\u00b7cher", "Ge\u00b7brauch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df jeglicher das Beste, was er kennt,", "tokens": ["Da\u00df", "jeg\u00b7li\u00b7cher", "das", "Bes\u00b7te", ",", "was", "er", "kennt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ART", "NN", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Er Gott, ja seinen Gott benennt,", "tokens": ["Er", "Gott", ",", "ja", "sei\u00b7nen", "Gott", "be\u00b7nennt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihm Himmel und Erden \u00fcbergibt,", "tokens": ["Ihm", "Him\u00b7mel", "und", "Er\u00b7den", "\u00fc\u00b7berg\u00b7ibt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Ihn f\u00fcrchtet und wo m\u00f6glich liebt.", "tokens": ["Ihn", "f\u00fcrch\u00b7tet", "und", "wo", "m\u00f6g\u00b7lich", "liebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "PWAV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Wie? Wann? und Wo? \u2013 Die G\u00f6tter bleiben stumm!", "tokens": ["Wie", "?", "Wann", "?", "und", "Wo", "?", "\u2013", "Die", "G\u00f6t\u00b7ter", "blei\u00b7ben", "stumm", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "PWAV", "$.", "KON", "PWAV", "$.", "$(", "ART", "NN", "VVINF", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Du halte dich ans ", "tokens": ["Du", "hal\u00b7te", "dich", "ans"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPRART"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "Willst du ins Unendliche schreiten,", "tokens": ["Willst", "du", "ins", "Un\u00b7end\u00b7li\u00b7che", "schrei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Geh nur im Endlichen nach allen Seiten.", "tokens": ["Geh", "nur", "im", "End\u00b7li\u00b7chen", "nach", "al\u00b7len", "Sei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPRART", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Willst du dich am Ganzen erquicken,", "tokens": ["Willst", "du", "dich", "am", "Gan\u00b7zen", "er\u00b7qui\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "APPRART", "NN", "VVINF", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "So mu\u00dft du das Ganze im Kleinsten erblicken.", "tokens": ["So", "mu\u00dft", "du", "das", "Gan\u00b7ze", "im", "Kleins\u00b7ten", "er\u00b7bli\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}, "stanza.11": {"line.1": {"text": "Aus tiefem Gem\u00fct, aus der Mutter Scho\u00df", "tokens": ["Aus", "tie\u00b7fem", "Ge\u00b7m\u00fct", ",", "aus", "der", "Mut\u00b7ter", "Scho\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "ART", "NN", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Will manches dem Tage entgegen;", "tokens": ["Will", "man\u00b7ches", "dem", "Ta\u00b7ge", "ent\u00b7ge\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Doch soll das Kleine je werden gro\u00df,", "tokens": ["Doch", "soll", "das", "Klei\u00b7ne", "je", "wer\u00b7den", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "ADJA", "ADV", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "So mu\u00df es sich r\u00fchren und regen.", "tokens": ["So", "mu\u00df", "es", "sich", "r\u00fch\u00b7ren", "und", "re\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "VVINF", "KON", "ADJA", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.12": {"line.1": {"text": "Da, wo das Wasser sich entzweit", "tokens": ["Da", ",", "wo", "das", "Was\u00b7ser", "sich", "ent\u00b7zweit"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PWAV", "ART", "NN", "PRF", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wird zuerst Lebendigs befreit.", "tokens": ["Wird", "zu\u00b7erst", "Le\u00b7ben\u00b7digs", "be\u00b7freit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Und wird das Wasser sich entfalten,", "tokens": ["Und", "wird", "das", "Was\u00b7ser", "sich", "ent\u00b7fal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sogleich wird sich's lebendig gestalten;", "tokens": ["Sog\u00b7leich", "wird", "sich's", "le\u00b7ben\u00b7dig", "ge\u00b7stal\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADJD", "VVPP", "$."], "meter": "+-+-++--+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Da w\u00e4lzen sich Tiere, sie trocknen zum Flor,", "tokens": ["Da", "w\u00e4l\u00b7zen", "sich", "Tie\u00b7re", ",", "sie", "trock\u00b7nen", "zum", "Flor", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ADJA", "$,", "PPER", "ADJA", "APPRART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Und Pflanzengezweige, sie dringen hervor.", "tokens": ["Und", "Pflan\u00b7zen\u00b7ge\u00b7zwei\u00b7ge", ",", "sie", "drin\u00b7gen", "her\u00b7vor", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.14": {"line.1": {"text": "Durchsichtig erscheint die Luft so rein", "tokens": ["Durch\u00b7sich\u00b7tig", "er\u00b7scheint", "die", "Luft", "so", "rein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ART", "NN", "ADV", "ADJD"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und tr\u00e4gt im Busen Stahl und Stein.", "tokens": ["Und", "tr\u00e4gt", "im", "Bu\u00b7sen", "Stahl", "und", "Stein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Entz\u00fcndet werden sie sich begegnen;", "tokens": ["Ent\u00b7z\u00fcn\u00b7det", "wer\u00b7den", "sie", "sich", "be\u00b7geg\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da wird's Metall und Steine regnen.", "tokens": ["Da", "wird's", "Me\u00b7tall", "und", "Stei\u00b7ne", "reg\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Denn was das Feuer lebendig erfa\u00dft,", "tokens": ["Denn", "was", "das", "Feu\u00b7er", "le\u00b7ben\u00b7dig", "er\u00b7fa\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+---+", "measure": "zehnsilber"}, "line.2": {"text": "Bleibt nicht mehr Unform und Erdenlast.", "tokens": ["Bleibt", "nicht", "mehr", "Un\u00b7form", "und", "Er\u00b7den\u00b7last", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "PIAT", "NN", "KON", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Verfl\u00fcchtigt wird es und unsichtbar,", "tokens": ["Ver\u00b7fl\u00fcch\u00b7tigt", "wird", "es", "und", "un\u00b7sicht\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "KON", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Eilt hinauf, wo erst sein Anfang war.", "tokens": ["Eilt", "hin\u00b7auf", ",", "wo", "erst", "sein", "An\u00b7fang", "war", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "PWAV", "ADV", "PPOSAT", "NN", "VAFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.16": {"line.1": {"text": "Und so kommt wieder zur Erde herab,", "tokens": ["Und", "so", "kommt", "wie\u00b7der", "zur", "Er\u00b7de", "her\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ADV", "APPRART", "NN", "ADV", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dem die Erde den Ursprung gab.", "tokens": ["Dem", "die", "Er\u00b7de", "den", "Ur\u00b7sprung", "gab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Gleicherweise sind wir auch gez\u00fcchtigt,", "tokens": ["Glei\u00b7cher\u00b7wei\u00b7se", "sind", "wir", "auch", "ge\u00b7z\u00fcch\u00b7tigt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Einmal gefestet, einmal verfl\u00fcchtigt.", "tokens": ["Ein\u00b7mal", "ge\u00b7fes\u00b7tet", ",", "ein\u00b7mal", "ver\u00b7fl\u00fcch\u00b7tigt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$,", "ADV", "VVPP", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}}, "stanza.17": {"line.1": {"text": "Und wer durch alle die Elemente", "tokens": ["Und", "wer", "durch", "al\u00b7le", "die", "E\u00b7le\u00b7men\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "APPR", "PIS", "ART", "NN"], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Feuer, Luft, Wasser und Erde rennte,", "tokens": ["Feu\u00b7er", ",", "Luft", ",", "Was\u00b7ser", "und", "Er\u00b7de", "renn\u00b7te", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-++--+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Der wird zuletzt sich \u00fcberzeugen,", "tokens": ["Der", "wird", "zu\u00b7letzt", "sich", "\u00fc\u00b7berz\u00b7eu\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Er sei kein Wesen ihresgleichen.", "tokens": ["Er", "sei", "kein", "We\u00b7sen", "ih\u00b7res\u00b7glei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "\u00bbwas will die Nadel nach Norden gekehrt?\u00ab", "tokens": ["\u00bb", "was", "will", "die", "Na\u00b7del", "nach", "Nor\u00b7den", "ge\u00b7kehrt", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "VMFIN", "ART", "NN", "APPR", "NN", "VVPP", "$.", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sich selbst zu finden, es ist ihr verwehrt.", "tokens": ["Sich", "selbst", "zu", "fin\u00b7den", ",", "es", "ist", "ihr", "ver\u00b7wehrt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "PTKZU", "VVINF", "$,", "PPER", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.19": {"line.1": {"text": "Die endliche Ruhe wird nur versp\u00fcrt,", "tokens": ["Die", "end\u00b7li\u00b7che", "Ru\u00b7he", "wird", "nur", "ver\u00b7sp\u00fcrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Sobald der Pol den Pol ber\u00fchrt.", "tokens": ["So\u00b7bald", "der", "Pol", "den", "Pol", "be\u00b7r\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Drum danket Gott, ihr S\u00f6hne der Zeit,", "tokens": ["Drum", "dan\u00b7ket", "Gott", ",", "ihr", "S\u00f6h\u00b7ne", "der", "Zeit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NN", "$,", "PPOSAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Da\u00df er die Pole f\u00fcr ewig entzweit.", "tokens": ["Da\u00df", "er", "die", "Po\u00b7le", "f\u00fcr", "e\u00b7wig", "ent\u00b7zweit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "ADJD", "PTKVZ", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}, "stanza.21": {"line.1": {"text": "\u00bbmagnetes Geheimnis, erkl\u00e4re mir das!\u00ab", "tokens": ["\u00bb", "mag\u00b7ne\u00b7tes", "Ge\u00b7heim\u00b7nis", ",", "er\u00b7kl\u00e4\u00b7re", "mir", "das", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "VVFIN", "PPER", "PDS", "$.", "$("], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Kein gr\u00f6\u00dfer Geheimnis als Lieb und Ha\u00df.", "tokens": ["Kein", "gr\u00f6\u00b7\u00dfer", "Ge\u00b7heim\u00b7nis", "als", "Lieb", "und", "Ha\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "KOUS", "NN", "KON", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.22": {"line.1": {"text": "Wirst du deinesgleichen kennenlernen,", "tokens": ["Wirst", "du", "dei\u00b7nes\u00b7glei\u00b7chen", "ken\u00b7nen\u00b7ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "so wirst du dich gleich wieder entfernen.", "tokens": ["so", "wirst", "du", "dich", "gleich", "wie\u00b7der", "ent\u00b7fer\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.23": {"line.1": {"text": "\u00bbwarum tanzen B\u00fcbchen mit M\u00e4dchen so gern?\u00ab", "tokens": ["\u00bb", "wa\u00b7rum", "tan\u00b7zen", "B\u00fcb\u00b7chen", "mit", "M\u00e4d\u00b7chen", "so", "gern", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "VVFIN", "NN", "APPR", "NN", "ADV", "ADV", "$.", "$("], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Ungleich dem Gleichen bleibet nicht fern.", "tokens": ["Un\u00b7gleich", "dem", "Glei\u00b7chen", "blei\u00b7bet", "nicht", "fern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "VVFIN", "PTKNEG", "ADJD", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}}, "stanza.24": {"line.1": {"text": "Dagegen die Bauern in der Schenke", "tokens": ["Da\u00b7ge\u00b7gen", "die", "Bau\u00b7ern", "in", "der", "Schen\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Pr\u00fcgeln sich gleich mit den Beinen der B\u00e4nke.", "tokens": ["Pr\u00fc\u00b7geln", "sich", "gleich", "mit", "den", "Bei\u00b7nen", "der", "B\u00e4n\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ADV", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}}, "stanza.25": {"line.1": {"text": "Der Amtmann schnell das \u00dcbel stillt,", "tokens": ["Der", "Amt\u00b7mann", "schnell", "das", "\u00dc\u00b7bel", "stillt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weil er nicht f\u00fcr ihresgleichen gilt.", "tokens": ["Weil", "er", "nicht", "f\u00fcr", "ih\u00b7res\u00b7glei\u00b7chen", "gilt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "APPR", "PIS", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.26": {"line.1": {"text": "Soll dein Kompa\u00df dich richtig leiten,", "tokens": ["Soll", "dein", "Kom\u00b7pa\u00df", "dich", "rich\u00b7tig", "lei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00fcte dich vor Magnetstein', die dich begleiten.", "tokens": ["H\u00fc\u00b7te", "dich", "vor", "Ma\u00b7gnet\u00b7stein'", ",", "die", "dich", "be\u00b7glei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "APPR", "NN", "$,", "PRELS", "PRF", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.27": {"line.1": {"text": "Verdoppelte sich der Sterne Schein,", "tokens": ["Ver\u00b7dop\u00b7pel\u00b7te", "sich", "der", "Ster\u00b7ne", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das All wird ewig finster sein.", "tokens": ["Das", "All", "wird", "e\u00b7wig", "fins\u00b7ter", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "\u00bbund was sich zwischen beide stellt?\u00ab", "tokens": ["\u00bb", "und", "was", "sich", "zwi\u00b7schen", "bei\u00b7de", "stellt", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "PWS", "PRF", "APPR", "PIS", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Auge, so wie die K\u00f6rperwelt.", "tokens": ["Dein", "Au\u00b7ge", ",", "so", "wie", "die", "K\u00f6r\u00b7per\u00b7welt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "KOKOM", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.29": {"line.1": {"text": "An der Finsternis zusammengeschrunden,", "tokens": ["An", "der", "Fins\u00b7ter\u00b7nis", "zu\u00b7sam\u00b7men\u00b7ge\u00b7schrun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Wird dein Auge vom Licht entbunden.", "tokens": ["Wird", "dein", "Au\u00b7ge", "vom", "Licht", "ent\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}}, "stanza.30": {"line.1": {"text": "Schwarz und Wei\u00df, eine Totenschau,", "tokens": ["Schwarz", "und", "Wei\u00df", ",", "ei\u00b7ne", "To\u00b7ten\u00b7schau", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$,", "ART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Vermischt ein niedertr\u00e4chtig Grau.", "tokens": ["Ver\u00b7mischt", "ein", "nie\u00b7der\u00b7tr\u00e4ch\u00b7tig", "Grau", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Will Licht einem K\u00f6rper sich verm\u00e4hlen,", "tokens": ["Will", "Licht", "ei\u00b7nem", "K\u00f6r\u00b7per", "sich", "ver\u00b7m\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Es wird den ganz durchsicht'gen w\u00e4hlen.", "tokens": ["Es", "wird", "den", "ganz", "durch\u00b7sicht'\u00b7gen", "w\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Du aber halte dich mit Liebe", "tokens": ["Du", "a\u00b7ber", "hal\u00b7te", "dich", "mit", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "PRF", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "An das Durchscheinende, das Tr\u00fcbe.", "tokens": ["An", "das", "Durch\u00b7schei\u00b7nen\u00b7de", ",", "das", "Tr\u00fc\u00b7be", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.33": {"line.1": {"text": "Denn steht das Tr\u00fcbste vor der Sonne,", "tokens": ["Denn", "steht", "das", "Tr\u00fcbs\u00b7te", "vor", "der", "Son\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da siehst die herrlichste Purpurwonne.", "tokens": ["Da", "siehst", "die", "herr\u00b7lichs\u00b7te", "Pur\u00b7pur\u00b7won\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.34": {"line.1": {"text": "Und will das Licht sich dem Tr\u00fcbsten entwinden,", "tokens": ["Und", "will", "das", "Licht", "sich", "dem", "Tr\u00fcbs\u00b7ten", "ent\u00b7win\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "PRF", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "So wird es gl\u00fchend Rot entz\u00fcnden.", "tokens": ["So", "wird", "es", "gl\u00fc\u00b7hend", "Rot", "ent\u00b7z\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Und wie das Tr\u00fcbe verdunstet und weicht,", "tokens": ["Und", "wie", "das", "Tr\u00fc\u00b7be", "ver\u00b7duns\u00b7tet", "und", "weicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "VVPP", "KON", "VVFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das Rote zum hellsten Gelb erbleicht.", "tokens": ["Das", "Ro\u00b7te", "zum", "hells\u00b7ten", "Gelb", "er\u00b7bleicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.36": {"line.1": {"text": "Ist endlich der \u00c4ther rein und klar,", "tokens": ["Ist", "end\u00b7lich", "der", "\u00c4\u00b7ther", "rein", "und", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ist das Licht wei\u00df, wie es anfangs war.", "tokens": ["Ist", "das", "Licht", "wei\u00df", ",", "wie", "es", "an\u00b7fangs", "war", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVFIN", "$,", "PWAV", "PPER", "ADV", "VAFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.37": {"line.1": {"text": "Steht vor dem Finstern milchig Grau,", "tokens": ["Steht", "vor", "dem", "Fins\u00b7tern", "mil\u00b7chig", "Grau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Sonne bescheint's, da wird es Blau.", "tokens": ["Die", "Son\u00b7ne", "be\u00b7scheint's", ",", "da", "wird", "es", "Blau", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ADV", "VAFIN", "PPER", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.38": {"line.1": {"text": "Auf Bergen, in der reinsten H\u00f6he,", "tokens": ["Auf", "Ber\u00b7gen", ",", "in", "der", "reins\u00b7ten", "H\u00f6\u00b7he", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Tief R\u00f6tlichblau ist Himmelsn\u00e4he.", "tokens": ["Tief", "R\u00f6t\u00b7lich\u00b7blau", "ist", "Him\u00b7mels\u00b7n\u00e4\u00b7he", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Du staunest \u00fcber die K\u00f6nigspracht,", "tokens": ["Du", "stau\u00b7nest", "\u00fc\u00b7ber", "die", "K\u00f6\u00b7nig\u00b7spracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und gleich ist sammetschwarz die Nacht.", "tokens": ["Und", "gleich", "ist", "sam\u00b7met\u00b7schwarz", "die", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Und so bleibt auch, in ewigem Frieden,", "tokens": ["Und", "so", "bleibt", "auch", ",", "in", "e\u00b7wi\u00b7gem", "Frie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Die Finsternis vom Licht geschieden.", "tokens": ["Die", "Fins\u00b7ter\u00b7nis", "vom", "Licht", "ge\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Da\u00df sie miteinander streiten k\u00f6nnen,", "tokens": ["Da\u00df", "sie", "mi\u00b7tein\u00b7an\u00b7der", "strei\u00b7ten", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "VMINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Das ist eine bare Torheit zu nennen.", "tokens": ["Das", "ist", "ei\u00b7ne", "ba\u00b7re", "Tor\u00b7heit", "zu", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.42": {"line.1": {"text": "Sie streiten mit der K\u00f6rperwelt,", "tokens": ["Sie", "strei\u00b7ten", "mit", "der", "K\u00f6r\u00b7per\u00b7welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die sie ewig auseinander h\u00e4lt.", "tokens": ["Die", "sie", "e\u00b7wig", "aus\u00b7ein\u00b7an\u00b7der", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "PTKVZ", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}