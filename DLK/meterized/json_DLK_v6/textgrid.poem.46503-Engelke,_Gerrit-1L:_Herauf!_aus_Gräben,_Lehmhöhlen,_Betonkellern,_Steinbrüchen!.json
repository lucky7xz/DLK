{"textgrid.poem.46503": {"metadata": {"author": {"name": "Engelke, Gerrit", "birth": "N.A.", "death": "N.A."}, "title": "1L: Herauf! aus Gr\u00e4ben, Lehmh\u00f6hlen, Betonkellern, Steinbr\u00fcchen!", "genre": "verse", "period": "N.A.", "pub_year": 1918, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Herauf! aus Gr\u00e4ben, Lehmh\u00f6hlen, Betonkellern, Steinbr\u00fcchen!", "tokens": ["Her\u00b7auf", "!", "aus", "Gr\u00e4\u00b7ben", ",", "Lehm\u00b7h\u00f6h\u00b7len", ",", "Be\u00b7ton\u00b7kel\u00b7lern", ",", "Stein\u00b7br\u00fc\u00b7chen", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PTKVZ", "$.", "APPR", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+--+--+--++-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Heraus aus Schlamm und Glut, Kalkstaub und Aasger\u00fcchen!", "tokens": ["He\u00b7raus", "aus", "Schlamm", "und", "Glut", ",", "Kalk\u00b7staub", "und", "Aas\u00b7ge\u00b7r\u00fc\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Herbei! Kameraden! Denn von Front zu Front, von Feld zu Feld", "tokens": ["Her\u00b7bei", "!", "Ka\u00b7me\u00b7ra\u00b7den", "!", "Denn", "von", "Front", "zu", "Front", ",", "von", "Feld", "zu", "Feld"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKVZ", "$.", "NN", "$.", "KON", "APPR", "NE", "APPR", "NE", "$,", "APPR", "NN", "APPR", "NN"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Komme euch allen der neue Feiertag der Welt!", "tokens": ["Kom\u00b7me", "euch", "al\u00b7len", "der", "neu\u00b7e", "Fei\u00b7er\u00b7tag", "der", "Welt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.5": {"text": "Stahlhelme ab, M\u00fctzen, K\u00e4ppis! und fort die Gewehre!", "tokens": ["Stahl\u00b7hel\u00b7me", "ab", ",", "M\u00fct\u00b7zen", ",", "K\u00e4p\u00b7pis", "!", "und", "fort", "die", "Ge\u00b7weh\u00b7re", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "NN", "$,", "NE", "$.", "KON", "PTKVZ", "ART", "NN", "$."], "meter": "-+-++--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Genug der blutbadenden Feindschaft und Mordehre!", "tokens": ["Ge\u00b7nug", "der", "blut\u00b7ba\u00b7den\u00b7den", "Feind\u00b7schaft", "und", "Mor\u00b7deh\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Euch alle beschw\u00f6r' ich bei eurer Heimat Weilern und", "tokens": ["Euch", "al\u00b7le", "be\u00b7schw\u00f6r'", "ich", "bei", "eu\u00b7rer", "Hei\u00b7mat", "Wei\u00b7lern", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "PIS", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "NN", "KON"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.8": {"text": "St\u00e4dten,", "tokens": ["St\u00e4d\u00b7ten", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.9": {"text": "Den furchtbaren Samen des Hasses auszutreten, zu j\u00e4ten,", "tokens": ["Den", "furcht\u00b7ba\u00b7ren", "Sa\u00b7men", "des", "Has\u00b7ses", "aus\u00b7zu\u00b7tre\u00b7ten", ",", "zu", "j\u00e4\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-+-+--+-", "measure": "amphibrach.tri.plus"}, "line.10": {"text": "Beschw\u00f6re euch bei eurer Liebe zur Schwester, zur Mutter, zum Kind,", "tokens": ["Be\u00b7schw\u00f6\u00b7re", "euch", "bei", "eu\u00b7rer", "Lie\u00b7be", "zur", "Schwes\u00b7ter", ",", "zur", "Mut\u00b7ter", ",", "zum", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "APPRART", "NN", "$,", "APPRART", "NN", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+--+--+--+", "measure": "iambic.septa.relaxed"}, "line.11": {"text": "Die allein euer narbiges Herz noch zum Singen stimmt.", "tokens": ["Die", "al\u00b7lein", "eu\u00b7er", "nar\u00b7bi\u00b7ges", "Herz", "noch", "zum", "Sin\u00b7gen", "stimmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPOSAT", "ADJA", "NN", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Bei eurer Liebe zur Gattin \u2013 auch ich liebe ein Weib!", "tokens": ["Bei", "eu\u00b7rer", "Lie\u00b7be", "zur", "Gat\u00b7tin", "\u2013", "auch", "ich", "lie\u00b7be", "ein", "Weib", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "NN", "$(", "ADV", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Bei eurer Liebe zur Mutter \u2013 auch mich trug ein Mutterleib!", "tokens": ["Bei", "eu\u00b7rer", "Lie\u00b7be", "zur", "Mut\u00b7ter", "\u2013", "auch", "mich", "trug", "ein", "Mut\u00b7ter\u00b7leib", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "NN", "$(", "ADV", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+-+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.14": {"text": "Bei eurer Liebe zum Kinde \u2013 denn ich liebe die Kleinen!", "tokens": ["Bei", "eu\u00b7rer", "Lie\u00b7be", "zum", "Kin\u00b7de", "\u2013", "denn", "ich", "lie\u00b7be", "die", "Klei\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "NN", "$(", "KON", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Und die H\u00e4user sind voll von Fluchen, Beten, Weinen!", "tokens": ["Und", "die", "H\u00e4u\u00b7ser", "sind", "voll", "von", "Flu\u00b7chen", ",", "Be\u00b7ten", ",", "Wei\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJD", "APPR", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.2": {"line.1": {"text": "Lagst du bei Ypern, dem zertr\u00fcmmerten? Auch ich lag dort.", "tokens": ["Lagst", "du", "bei", "Y\u00b7pern", ",", "dem", "zer\u00b7tr\u00fcm\u00b7mer\u00b7ten", "?", "Auch", "ich", "lag", "dort", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "$,", "PRELS", "VVFIN", "$.", "ADV", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Bei Mihiel, dem verk\u00fcmmerten? Ich war an diesem Ort.", "tokens": ["Bei", "Mi\u00b7hiel", ",", "dem", "ver\u00b7k\u00fcm\u00b7mer\u00b7ten", "?", "Ich", "war", "an", "die\u00b7sem", "Ort", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "VVFIN", "$.", "PPER", "VAFIN", "APPR", "PDAT", "NN", "$."], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Dixmuide, dem umschwemmten? Ich lag vor deiner Stirn,", "tokens": ["Dix\u00b7mu\u00b7i\u00b7de", ",", "dem", "um\u00b7schwemm\u00b7ten", "?", "Ich", "lag", "vor", "dei\u00b7ner", "Stirn", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "VVFIN", "$.", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "In H\u00f6llenschluchten Verduns, wie du in Rauch und Klirrn,", "tokens": ["In", "H\u00f6l\u00b7len\u00b7schluch\u00b7ten", "Ver\u00b7duns", ",", "wie", "du", "in", "Rauch", "und", "Klirrn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$,", "PWAV", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Mit dir im Schnee vor D\u00fcnaburg, frierend, immer tr\u00fcber,", "tokens": ["Mit", "dir", "im", "Schnee", "vor", "D\u00fc\u00b7na\u00b7burg", ",", "frie\u00b7rend", ",", "im\u00b7mer", "tr\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPRART", "NN", "APPR", "NE", "$,", "VVPP", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "An der leichenfressenden Somme lag ich dir gegen\u00fcber.", "tokens": ["An", "der", "lei\u00b7chen\u00b7fres\u00b7sen\u00b7den", "Som\u00b7me", "lag", "ich", "dir", "ge\u00b7gen\u00b7\u00fc\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "+-+-+--+-+--+-+-", "measure": "trochaic.septa.relaxed"}, "line.7": {"text": "Ich lag dir gegen\u00fcber \u00fcberall, doch wu\u00dftest du es nicht!", "tokens": ["Ich", "lag", "dir", "ge\u00b7gen\u00b7\u00fc\u00b7ber", "\u00fc\u00b7be\u00b7rall", ",", "doch", "wu\u00df\u00b7test", "du", "es", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ADV", "$,", "ADV", "VVFIN", "PPER", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.8": {"text": "Feind an Feind, Mensch an Mensch und Leib an Leib, warm und dicht.", "tokens": ["Feind", "an", "Feind", ",", "Mensch", "an", "Mensch", "und", "Leib", "an", "Leib", ",", "warm", "und", "dicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "NN", "APPR", "NN", "KON", "NN", "APPR", "NN", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "+--+-+-+-+--+", "measure": "iambic.hexa.invert"}}, "stanza.3": {"line.1": {"text": "Ich war Soldat und Mann und Pflichterf\u00fcller, so wie du,", "tokens": ["Ich", "war", "Sol\u00b7dat", "und", "Mann", "und", "Pflich\u00b7ter\u00b7f\u00fcl\u00b7ler", ",", "so", "wie", "du", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "KON", "NN", "KON", "NN", "$,", "ADV", "KOKOM", "PPER", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "D\u00fcrstend, schlaflos, krank \u2013 auf Marsch und Posten immerzu.", "tokens": ["D\u00fcrs\u00b7tend", ",", "schlaf\u00b7los", ",", "krank", "\u2013", "auf", "Marsch", "und", "Pos\u00b7ten", "im\u00b7mer\u00b7zu", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADJD", "$,", "ADJD", "$(", "APPR", "NE", "KON", "NN", "ADV", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.3": {"text": "St\u00fcndlich vom Tode umst\u00fcrzt, umschrien, umdampft,", "tokens": ["St\u00fcnd\u00b7lich", "vom", "To\u00b7de", "um\u00b7st\u00fcrzt", ",", "um\u00b7schri\u00b7en", ",", "um\u00b7dampft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "VVFIN", "$,", "VVFIN", "$,", "VVPP", "$,"], "meter": "+--+--+-+--+", "measure": "dactylic.di.plus"}, "line.4": {"text": "St\u00fcndlich an Heimat, Geliebte, Geburtsstadt gekrampft", "tokens": ["St\u00fcnd\u00b7lich", "an", "Hei\u00b7mat", ",", "Ge\u00b7lieb\u00b7te", ",", "Ge\u00b7burts\u00b7stadt", "ge\u00b7krampft"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ADJD", "APPR", "NN", "$,", "NN", "$,", "NN", "VVPP"], "meter": "+--+--+--+--+", "measure": "dactylic.penta"}, "line.5": {"text": "Wie du und du und ihr alle. \u2013", "tokens": ["Wie", "du", "und", "du", "und", "ihr", "al\u00b7le", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PPER", "KON", "PPER", "KON", "PPER", "PIS", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Rei\u00df auf deinen Rock! Entbl\u00f6\u00dfe die W\u00f6lbung der Brust!", "tokens": ["Rei\u00df", "auf", "dei\u00b7nen", "Rock", "!", "Ent\u00b7bl\u00f6\u00b7\u00dfe", "die", "W\u00f6l\u00b7bung", "der", "Brust", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$.", "NN", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+--+--+", "measure": "trochaic.hexa.relaxed"}, "line.7": {"text": "Ich sehe den Streifschu\u00df von f\u00fcnfzehn, die schorfige Krust,", "tokens": ["Ich", "se\u00b7he", "den", "Streif\u00b7schu\u00df", "von", "f\u00fcnf\u00b7zehn", ",", "die", "schor\u00b7fi\u00b7ge", "Krust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "CARD", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+--+", "measure": "amphibrach.penta.plus"}, "line.8": {"text": "Und da an der Stirn vern\u00e4hten Schlitz vom Sturm bei Tah\u00fcre \u2013", "tokens": ["Und", "da", "an", "der", "Stirn", "ver\u00b7n\u00e4h\u00b7ten", "Schlitz", "vom", "Sturm", "bei", "Ta\u00b7h\u00fc\u00b7re", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "ADJA", "NN", "APPRART", "NN", "APPR", "NN", "$("], "meter": "--+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Doch da\u00df du nicht denkst, ich heuchle, vergelt' ich mit gleicher Geb\u00fchr:", "tokens": ["Doch", "da\u00df", "du", "nicht", "denkst", ",", "ich", "heuch\u00b7le", ",", "ver\u00b7gelt'", "ich", "mit", "glei\u00b7cher", "Ge\u00b7b\u00fchr", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PTKNEG", "VVFIN", "$,", "PPER", "ADV", "$,", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+--+--+--+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Ich \u00f6ffne mein Hemd: hier ist noch die vielfarbige Narbe am Arm!", "tokens": ["Ich", "\u00f6ff\u00b7ne", "mein", "Hemd", ":", "hier", "ist", "noch", "die", "viel\u00b7far\u00b7bi\u00b7ge", "Nar\u00b7be", "am", "Arm", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$.", "ADV", "VAFIN", "ADV", "ART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+--+-+---+--+--+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Der Brandstempel der Schlacht! von Sprung und Alarm,", "tokens": ["Der", "Brands\u00b7tem\u00b7pel", "der", "Schlacht", "!", "von", "Sprung", "und", "A\u00b7larm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$.", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Ein z\u00e4rtliches Andenken lang nach dem Kriege.", "tokens": ["Ein", "z\u00e4rt\u00b7li\u00b7ches", "An\u00b7den\u00b7ken", "lang", "nach", "dem", "Krie\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Wie sind wir doch stolz unsrer Wunden! Stolz du der deinigen,", "tokens": ["Wie", "sind", "wir", "doch", "stolz", "uns\u00b7rer", "Wun\u00b7den", "!", "Stolz", "du", "der", "dei\u00b7ni\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "ADJD", "PPOSAT", "NN", "$.", "NN", "PPER", "ART", "PPOSS", "$,"], "meter": "-+--+--+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.14": {"text": "Doch nicht stolzer als ich auch der meinigen.", "tokens": ["Doch", "nicht", "stol\u00b7zer", "als", "ich", "auch", "der", "mei\u00b7ni\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADJD", "KOKOM", "PPER", "ADV", "ART", "PPOSS", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.4": {"line.1": {"text": "Du gabst nicht besseres Blut, und nicht r\u00f6tere Kraft,", "tokens": ["Du", "gabst", "nicht", "bes\u00b7se\u00b7res", "Blut", ",", "und", "nicht", "r\u00f6\u00b7te\u00b7re", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADJA", "NN", "$,", "KON", "PTKNEG", "ADJA", "NN", "$,"], "meter": "-+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und der gleiche zerhackte Sand trank unsern Saft! \u2013", "tokens": ["Und", "der", "glei\u00b7che", "zer\u00b7hack\u00b7te", "Sand", "trank", "un\u00b7sern", "Saft", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "ADJA", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$.", "$("], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Zerschlug deinen Bruder der gr\u00e4\u00dfliche Krach der Granate?", "tokens": ["Zer\u00b7schlug", "dei\u00b7nen", "Bru\u00b7der", "der", "gr\u00e4\u00df\u00b7li\u00b7che", "Krach", "der", "Gra\u00b7na\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+--+--+--+--+-", "measure": "amphibrach.penta.plus"}, "line.4": {"text": "Fiel nicht dein Onkel, dein Vetter, dein Pate?", "tokens": ["Fiel", "nicht", "dein", "On\u00b7kel", ",", "dein", "Vet\u00b7ter", ",", "dein", "Pa\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Liegt nicht der b\u00e4rtige Vater verscharrt in der Kuhle?", "tokens": ["Liegt", "nicht", "der", "b\u00e4r\u00b7ti\u00b7ge", "Va\u00b7ter", "ver\u00b7scharrt", "in", "der", "Kuh\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Und dein Freund, dein lustiger Freund aus der Schule? \u2013", "tokens": ["Und", "dein", "Freund", ",", "dein", "lus\u00b7ti\u00b7ger", "Freund", "aus", "der", "Schu\u00b7le", "?", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "PPOSAT", "ADJA", "NN", "APPR", "ART", "NN", "$.", "$("], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Hermann und Fritz, meine Vettern, verstr\u00f6mten im Blute,", "tokens": ["Her\u00b7mann", "und", "Fritz", ",", "mei\u00b7ne", "Vet\u00b7tern", ",", "ver\u00b7str\u00f6m\u00b7ten", "im", "Blu\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$,", "PPOSAT", "NN", "$,", "VVFIN", "APPRART", "NN", "$,"], "meter": "+--+--+--+--+-", "measure": "dactylic.penta"}, "line.8": {"text": "Und der hilfreiche Freund, der J\u00fcngling, der blonde und gute.", "tokens": ["Und", "der", "hilf\u00b7rei\u00b7che", "Freund", ",", "der", "J\u00fcng\u00b7ling", ",", "der", "blon\u00b7de", "und", "gu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,", "ART", "NN", "$,", "ART", "ADJA", "KON", "ADJA", "$."], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Und zu Hause wartet sein Bett, und im \u00e4rmlichen Zimmer", "tokens": ["Und", "zu", "Hau\u00b7se", "war\u00b7tet", "sein", "Bett", ",", "und", "im", "\u00e4rm\u00b7li\u00b7chen", "Zim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "VVFIN", "PPOSAT", "NN", "$,", "KON", "APPRART", "ADJA", "NN"], "meter": "--+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Seit sechzehn, seit siebzehn die gramgraue Mutter noch immer.", "tokens": ["Seit", "sech\u00b7zehn", ",", "seit", "sieb\u00b7zehn", "die", "gram\u00b7grau\u00b7e", "Mut\u00b7ter", "noch", "im\u00b7mer", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "$,", "KOUS", "PPER", "ART", "ADJA", "NN", "ADV", "ADV", "$."], "meter": "--+-+---+-+-+-+", "measure": "anapaest.init"}, "line.11": {"text": "Wo ist uns sein Kreuz und sein Grab! \u2013", "tokens": ["Wo", "ist", "uns", "sein", "Kreuz", "und", "sein", "Grab", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$.", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.5": {"line.1": {"text": "Franzose du, von Brest, Bordeaux, Garonne,", "tokens": ["Fran\u00b7zo\u00b7se", "du", ",", "von", "Brest", ",", "Bor\u00b7dea\u00b7ux", ",", "Ga\u00b7ron\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "NE", "$,", "APPR", "NE", "$,", "NE", "$,", "NN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ukrainer du, Kosak vom Ural, Dnjestr und Don,", "tokens": ["Uk\u00b7rai\u00b7ner", "du", ",", "Ko\u00b7sak", "vom", "U\u00b7ral", ",", "Dn\u00b7jestr", "und", "Don", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "NN", "APPRART", "NN", "$,", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.3": {"text": "\u00d6sterreicher, Bulgare, Osmanen und Serben,", "tokens": ["\u00d6s\u00b7ter\u00b7rei\u00b7cher", ",", "Bul\u00b7ga\u00b7re", ",", "Os\u00b7ma\u00b7nen", "und", "Ser\u00b7ben", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NE", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-----+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Ihr alle im rasenden Strudel von Tat und von Sterben \u2013", "tokens": ["Ihr", "al\u00b7le", "im", "ra\u00b7sen\u00b7den", "Stru\u00b7del", "von", "Tat", "und", "von", "Ster\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "APPRART", "ADJA", "NN", "APPR", "NN", "KON", "APPR", "NN", "$("], "meter": "-+--+--+--+--+-", "measure": "amphibrach.penta.plus"}, "line.5": {"text": "Du Brite aus London, York, Manchester,", "tokens": ["Du", "Bri\u00b7te", "aus", "Lon\u00b7don", ",", "Y\u00b7ork", ",", "Man\u00b7ches\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "NN", "APPR", "NE", "$,", "NE", "$,", "NN", "$,"], "meter": "-+--+-+-+--", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Soldat, Kamerad, in Wahrheit Mitmensch und Bester \u2013", "tokens": ["Sol\u00b7dat", ",", "Ka\u00b7me\u00b7rad", ",", "in", "Wahr\u00b7heit", "Mit\u00b7mensch", "und", "Bes\u00b7ter", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "APPR", "NN", "NN", "KON", "NN", "$("], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Amerikaner, aus den volkreichen Staaten der Freiheit:", "tokens": ["A\u00b7me\u00b7ri\u00b7ka\u00b7ner", ",", "aus", "den", "vol\u00b7krei\u00b7chen", "Staa\u00b7ten", "der", "Frei\u00b7heit", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+--+-+-+--+--+-", "measure": "hexameter"}, "line.8": {"text": "Wirf ab: Sonderinteresse, Nationald\u00fcnkel und Zweiheit!", "tokens": ["Wirf", "ab", ":", "Son\u00b7de\u00b7rin\u00b7ter\u00b7es\u00b7se", ",", "Na\u00b7ti\u00b7o\u00b7nal\u00b7d\u00fcn\u00b7kel", "und", "Zwei\u00b7heit", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$.", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "--+-+-+-+-+-+--+-", "measure": "iambic.septa.relaxed"}, "line.9": {"text": "Warst du ein ehrlicher Feind, wirst du ein ehrlicher Freund.", "tokens": ["Warst", "du", "ein", "ehr\u00b7li\u00b7cher", "Feind", ",", "wirst", "du", "ein", "ehr\u00b7li\u00b7cher", "Freund", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJD", "NN", "$,", "VAFIN", "PPER", "ART", "ADJD", "NN", "$."], "meter": "+--+--+-+-+--+", "measure": "dactylic.di.plus"}, "line.10": {"text": "Hier meine Hand, da\u00df sich nun Hand in Hand zum Kreise binde", "tokens": ["Hier", "mei\u00b7ne", "Hand", ",", "da\u00df", "sich", "nun", "Hand", "in", "Hand", "zum", "Krei\u00b7se", "bin\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "$,", "KOUS", "PRF", "ADV", "NN", "APPR", "NN", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.11": {"text": "Und unser neuer Tag uns echt und menschlich finde.", "tokens": ["Und", "un\u00b7ser", "neu\u00b7er", "Tag", "uns", "echt", "und", "menschlich", "fin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "PPER", "ADJD", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "Die Welt ist f\u00fcr euch alle gro\u00df und sch\u00f6n und sch\u00f6n!", "tokens": ["Die", "Welt", "ist", "f\u00fcr", "euch", "al\u00b7le", "gro\u00df", "und", "sch\u00f6n", "und", "sch\u00f6n", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "PPER", "PIS", "ADJD", "KON", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Geht her! staunt auf! nach Schlacht und Blutgest\u00f6hn:", "tokens": ["Geht", "her", "!", "staunt", "auf", "!", "nach", "Schlacht", "und", "Blut\u00b7ge\u00b7st\u00f6hn", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$.", "VVFIN", "PTKVZ", "$.", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wie gr\u00fcne Meere frei in Horizonte fluten,", "tokens": ["Wie", "gr\u00fc\u00b7ne", "Mee\u00b7re", "frei", "in", "Ho\u00b7ri\u00b7zon\u00b7te", "flu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "ADJD", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie Morgen, Abende in reiner Klarheit gluten,", "tokens": ["Wie", "Mor\u00b7gen", ",", "A\u00b7ben\u00b7de", "in", "rei\u00b7ner", "Klar\u00b7heit", "glu\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.5": {"text": "Wie aus den T\u00e4lern sich Gebirge heben,", "tokens": ["Wie", "aus", "den", "T\u00e4\u00b7lern", "sich", "Ge\u00b7bir\u00b7ge", "he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "PRF", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wie Milliarden Wesen uns umbeben!", "tokens": ["Wie", "Mil\u00b7li\u00b7ar\u00b7den", "We\u00b7sen", "uns", "um\u00b7be\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "O, unser allerh\u00f6chstes Gl\u00fcck hei\u00dft: Leben! \u2013", "tokens": ["O", ",", "un\u00b7ser", "al\u00b7ler\u00b7h\u00f6chs\u00b7tes", "Gl\u00fcck", "hei\u00dft", ":", "Le\u00b7ben", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["NE", "$,", "PPOSAT", "ADJA", "NN", "VVFIN", "$.", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "O, da\u00df sich Bruder wirklich Bruder wieder nenne!", "tokens": ["O", ",", "da\u00df", "sich", "Bru\u00b7der", "wirk\u00b7lich", "Bru\u00b7der", "wie\u00b7der", "nen\u00b7ne", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUS", "PRF", "NN", "ADJD", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df Ost und West den gleichen Wert erkenne:", "tokens": ["Da\u00df", "Ost", "und", "West", "den", "glei\u00b7chen", "Wert", "er\u00b7ken\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df wieder Freude in die V\u00f6lker blitzt:", "tokens": ["Da\u00df", "wie\u00b7der", "Freu\u00b7de", "in", "die", "V\u00f6l\u00b7ker", "blitzt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und Mensch an Mensch zur G\u00fcte sich erhitzt!", "tokens": ["Und", "Mensch", "an", "Mensch", "zur", "G\u00fc\u00b7te", "sich", "er\u00b7hitzt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NN", "APPRART", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Von Front zu Front und Feld zu Feld,", "tokens": ["Von", "Front", "zu", "Front", "und", "Feld", "zu", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "NE", "KON", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "La\u00dft singen uns den Feiertag der neuen Welt!", "tokens": ["La\u00dft", "sin\u00b7gen", "uns", "den", "Fei\u00b7er\u00b7tag", "der", "neu\u00b7en", "Welt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "VVFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Aus aller Br\u00fcsten dr\u00f6hne eine Bebung:", "tokens": ["Aus", "al\u00b7ler", "Br\u00fcs\u00b7ten", "dr\u00f6h\u00b7ne", "ei\u00b7ne", "Be\u00b7bung", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Psalm des Friedens, der Vers\u00f6hnung, der Erhebung!", "tokens": ["Der", "Psalm", "des", "Frie\u00b7dens", ",", "der", "Ver\u00b7s\u00f6h\u00b7nung", ",", "der", "Er\u00b7he\u00b7bung", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und das meerrauschende, dampfende Lied,", "tokens": ["Und", "das", "meer\u00b7rau\u00b7schen\u00b7de", ",", "damp\u00b7fen\u00b7de", "Lied", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-++--+--+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Das hinrei\u00dfende, br\u00fcderumarmende,", "tokens": ["Das", "hin\u00b7rei\u00b7\u00dfen\u00b7de", ",", "br\u00fc\u00b7de\u00b7rum\u00b7ar\u00b7men\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "$,"], "meter": "--+--+--+--", "measure": "anapaest.tri.plus"}, "line.7": {"text": "Das wilde und heilig erbarmende", "tokens": ["Das", "wil\u00b7de", "und", "hei\u00b7lig", "er\u00b7bar\u00b7men\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "KON", "ADJD", "ADJA"], "meter": "-+--+--+--", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Der tausendfachen Liebe laut um alle Erden!", "tokens": ["Der", "tau\u00b7send\u00b7fa\u00b7chen", "Lie\u00b7be", "laut", "um", "al\u00b7le", "Er\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}