{"textgrid.poem.35440": {"metadata": {"author": {"name": "Conradi, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "Erdeinsamkeit", "genre": "verse", "period": "N.A.", "pub_year": 1876, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Oh, wir sind einsam \u2013", "tokens": ["Oh", ",", "wir", "sind", "ein\u00b7sam", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VAFIN", "ADJD", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Grenzenlos einsam!", "tokens": ["Gren\u00b7zen\u00b7los", "ein\u00b7sam", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "ADJD", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.2": {"line.1": {"text": "Br\u00fcder! Meine Br\u00fcder!", "tokens": ["Br\u00fc\u00b7der", "!", "Mei\u00b7ne", "Br\u00fc\u00b7der", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Habt ihr bedacht schon:", "tokens": ["Habt", "ihr", "be\u00b7dacht", "schon", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Wir rollen dahin", "tokens": ["Wir", "rol\u00b7len", "da\u00b7hin"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "PAV"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "In engen Bezirken,", "tokens": ["In", "en\u00b7gen", "Be\u00b7zir\u00b7ken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Und ob wir auch tasten \u2013", "tokens": ["Und", "ob", "wir", "auch", "tas\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVFIN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Mit pochendem Geistesfinger tasten", "tokens": ["Mit", "po\u00b7chen\u00b7dem", "Geis\u00b7tes\u00b7fin\u00b7ger", "tas\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "An die Pforten des Alls:", "tokens": ["An", "die", "Pfor\u00b7ten", "des", "Alls", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Unserer Weltennachbarn", "tokens": ["Un\u00b7se\u00b7rer", "Wel\u00b7ten\u00b7nach\u00b7barn"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.7": {"text": "Kein einziger sp\u00fcrt uns ...", "tokens": ["Kein", "ein\u00b7zi\u00b7ger", "sp\u00fcrt", "uns", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "VVFIN", "PPER", "$("], "meter": "--+-+-", "measure": "anapaest.init"}}, "stanza.4": {"line.1": {"text": "Sie kreisen und kreisen \u2013", "tokens": ["Sie", "krei\u00b7sen", "und", "krei\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVINF", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Und ob wir auch tr\u00e4umen,", "tokens": ["Und", "ob", "wir", "auch", "tr\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Da\u00df durch die Himmel", "tokens": ["Da\u00df", "durch", "die", "Him\u00b7mel"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Ein einiges Ahnen", "tokens": ["Ein", "ei\u00b7ni\u00b7ges", "Ah\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Gefl\u00fcgelt sich schwingt \u2013", "tokens": ["Ge\u00b7fl\u00fc\u00b7gelt", "sich", "schwingt", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "VVFIN", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Auf Strahlenbr\u00fccken", "tokens": ["Auf", "Strah\u00b7len\u00b7br\u00fc\u00b7cken"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Von Stern zu Stern", "tokens": ["Von", "Stern", "zu", "Stern"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Bewu\u00dftsein tr\u00e4gt", "tokens": ["Be\u00b7wu\u00df\u00b7tsein", "tr\u00e4gt"], "token_info": ["word", "word"], "pos": ["NN", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Und br\u00fcnstig wirbt,", "tokens": ["Und", "br\u00fcns\u00b7tig", "wirbt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Tiefen erw\u00fchlend,", "tokens": ["Tie\u00b7fen", "er\u00b7w\u00fch\u00b7lend", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.11": {"text": "Um der Botschaft Erh\u00f6rung:", "tokens": ["Um", "der", "Bot\u00b7schaft", "Er\u00b7h\u00f6\u00b7rung", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}}, "stanza.5": {"line.1": {"text": "Br\u00fcder! O meine Br\u00fcder!", "tokens": ["Br\u00fc\u00b7der", "!", "O", "mei\u00b7ne", "Br\u00fc\u00b7der", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NE", "PPOSAT", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Es ist nur ein Traum,", "tokens": ["Es", "ist", "nur", "ein", "Traum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Und keine der Leuchten,", "tokens": ["Und", "kei\u00b7ne", "der", "Leuch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Der Myriaden Leuchten,", "tokens": ["Der", "My\u00b7ria\u00b7den", "Leuch\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Die unser Auge gebiert,", "tokens": ["Die", "un\u00b7ser", "Au\u00b7ge", "ge\u00b7biert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Erh\u00f6rt unserer Tr\u00e4ume", "tokens": ["Er\u00b7h\u00f6rt", "un\u00b7se\u00b7rer", "Tr\u00e4u\u00b7me"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN"], "meter": "-+---+-", "measure": "dactylic.init"}, "line.7": {"text": "Rauschenden Fl\u00fcgelschlag ...", "tokens": ["Rau\u00b7schen\u00b7den", "Fl\u00fc\u00b7gel\u00b7schlag", "..."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.6": {"line.1": {"text": "Sie sind alle so blind ...", "tokens": ["Sie", "sind", "al\u00b7le", "so", "blind", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "ADV", "ADJD", "$("], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Sie sind alle so taub ...", "tokens": ["Sie", "sind", "al\u00b7le", "so", "taub", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "ADV", "ADJD", "$("], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und der sie bewegt,", "tokens": ["Und", "der", "sie", "be\u00b7wegt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPER", "VVFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Der urgeborene Geist,", "tokens": ["Der", "ur\u00b7ge\u00b7bo\u00b7re\u00b7ne", "Geist", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Gab ihnen das Leben, \u2013", "tokens": ["Gab", "ih\u00b7nen", "das", "Le\u00b7ben", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Doch Leben hei\u00dft Grenze ...", "tokens": ["Doch", "Le\u00b7ben", "hei\u00dft", "Gren\u00b7ze", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "NN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.7": {"line.1": {"text": "Aber der Tod ist der Meister,", "tokens": ["A\u00b7ber", "der", "Tod", "ist", "der", "Meis\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Der da s\u00e4et Staub und erntet Staub,", "tokens": ["Der", "da", "s\u00e4et", "Staub", "und", "ern\u00b7tet", "Staub", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "NN", "KON", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und \u00fcber uns alle,", "tokens": ["Und", "\u00fc\u00b7ber", "uns", "al\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "PIS", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Die menschengezeugt,", "tokens": ["Die", "men\u00b7schen\u00b7ge\u00b7zeugt", ","], "token_info": ["word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Hat sich der Zypresse Trauerlaub", "tokens": ["Hat", "sich", "der", "Zyp\u00b7res\u00b7se", "Trau\u00b7er\u00b7laub"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PRF", "ART", "NN", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Herabgebeugt! ...", "tokens": ["Her\u00b7ab\u00b7ge\u00b7beugt", "!", "..."], "token_info": ["word", "punct", "punct"], "pos": ["VVFIN", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Und wir trauern ...", "tokens": ["Und", "wir", "trau\u00b7ern", "..."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVINF", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Wir trauern.", "tokens": ["Wir", "trau\u00b7ern", "."], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Denn die Himmel sind leer,", "tokens": ["Denn", "die", "Him\u00b7mel", "sind", "leer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Ob sie auch leuchten ...", "tokens": ["Ob", "sie", "auch", "leuch\u00b7ten", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "Wir wollen uns lieben, meine Br\u00fcder,", "tokens": ["Wir", "wol\u00b7len", "uns", "lie\u00b7ben", ",", "mei\u00b7ne", "Br\u00fc\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "$,", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Denn wir sind einsam ...", "tokens": ["Denn", "wir", "sind", "ein\u00b7sam", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "$("], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "Wohl leuchten die Himmel,", "tokens": ["Wohl", "leuch\u00b7ten", "die", "Him\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Und ihr Leuchten ber\u00fcckt", "tokens": ["Und", "ihr", "Leuch\u00b7ten", "be\u00b7r\u00fcckt"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Uns die Seele so ganz.", "tokens": ["Uns", "die", "See\u00b7le", "so", "ganz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "ADV", "ADV", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.11": {"line.1": {"text": "Und sie heben hinaus uns", "tokens": ["Und", "sie", "he\u00b7ben", "hin\u00b7aus", "uns"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APZR", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ueber irdische Kleinheit,", "tokens": ["Ue\u00b7ber", "ir\u00b7di\u00b7sche", "Klein\u00b7heit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Den Engpa\u00df des Lebens ...", "tokens": ["Den", "Eng\u00b7pa\u00df", "des", "Le\u00b7bens", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.12": {"line.1": {"text": "Doch wir sind sterblich.", "tokens": ["Doch", "wir", "sind", "sterb\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Drum wollen wir heimkehren, meine Br\u00fcder,", "tokens": ["Drum", "wol\u00b7len", "wir", "heim\u00b7keh\u00b7ren", ",", "mei\u00b7ne", "Br\u00fc\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "VVINF", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und wollen uns lieben", "tokens": ["Und", "wol\u00b7len", "uns", "lie\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Mit gel\u00e4uterten Sinnen ...", "tokens": ["Mit", "ge\u00b7l\u00e4u\u00b7ter\u00b7ten", "Sin\u00b7nen", "..."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.13": {"line.1": {"text": "Denn wir sind einsam ...", "tokens": ["Denn", "wir", "sind", "ein\u00b7sam", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "$("], "meter": "-+-+-", "measure": "iambic.di"}}}}}