{"dta.poem.23456": {"metadata": {"author": {"name": "Hoffmann von Fallersleben, August Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Aus Ovids Metamorphosen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1841", "urn": "urn:nbn:de:kobv:b4-200905192634", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Es flickt ein Schneider ein Gewand", "tokens": ["Es", "flickt", "ein", "Schnei\u00b7der", "ein", "Ge\u00b7wand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NE", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr eine Majest\u00e4t,", "tokens": ["F\u00fcr", "ei\u00b7ne", "Ma\u00b7jes\u00b7t\u00e4t", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wie er's h\u00e4lt in seiner Hand", "tokens": ["Und", "wie", "er's", "h\u00e4lt", "in", "sei\u00b7ner", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PIS", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und in den Falten sp\u00e4ht:", "tokens": ["Und", "in", "den", "Fal\u00b7ten", "sp\u00e4ht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "O Wunder, Wunder! was schaut heraus?", "tokens": ["O", "Wun\u00b7der", ",", "Wun\u00b7der", "!", "was", "schaut", "he\u00b7raus", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "NN", "$.", "PWS", "VVFIN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Eine Laus, eine Laus, eine k\u00f6nigliche Laus.", "tokens": ["Ei\u00b7ne", "Laus", ",", "ei\u00b7ne", "Laus", ",", "ei\u00b7ne", "k\u00f6\u00b7nig\u00b7li\u00b7che", "Laus", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "+-+--+--+-+-+", "measure": "trochaic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "Der Schneider h\u00fcpft vor Freud' empor,", "tokens": ["Der", "Schnei\u00b7der", "h\u00fcpft", "vor", "Freud'", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sieht sie mit Wollust an,", "tokens": ["Sieht", "sie", "mit", "Wol\u00b7lust", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und holt sein Messer flugs hervor,", "tokens": ["Und", "holt", "sein", "Mes\u00b7ser", "flugs", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und ach! was macht er dann?", "tokens": ["Und", "ach", "!", "was", "macht", "er", "dann", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$.", "PWS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "O Wunder, Wunder! er spaltet sie,", "tokens": ["O", "Wun\u00b7der", ",", "Wun\u00b7der", "!", "er", "spal\u00b7tet", "sie", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "NN", "$.", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Spaltet sie, spaltet sie, dieses k\u00f6nigliche Vieh.", "tokens": ["Spal\u00b7tet", "sie", ",", "spal\u00b7tet", "sie", ",", "die\u00b7ses", "k\u00f6\u00b7nig\u00b7li\u00b7che", "Vieh", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VVFIN", "PPER", "$,", "PDAT", "ADJA", "NN", "$."], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}}, "stanza.3": {"line.1": {"text": "\u201edie eine H\u00e4lfte bleibet mir", "tokens": ["\u201e", "die", "ei\u00b7ne", "H\u00e4lf\u00b7te", "blei\u00b7bet", "mir"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "ART", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von dieser K\u00f6nigslaus,", "tokens": ["Von", "die\u00b7ser", "K\u00f6\u00b7nigs\u00b7laus", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es stecket soviel Blut in ihr,", "tokens": ["Es", "ste\u00b7cket", "so\u00b7viel", "Blut", "in", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein F\u00fcrst wohl wird noch draus.\u201c", "tokens": ["Ein", "F\u00fcrst", "wohl", "wird", "noch", "draus", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "ADV", "PAV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "O Wunder, Wunder! er speist sie geschwind,", "tokens": ["O", "Wun\u00b7der", ",", "Wun\u00b7der", "!", "er", "speist", "sie", "ge\u00b7schwind", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "NN", "$.", "PPER", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und er wird, und er wird, wird ein f\u00fcrnehm", "tokens": ["Und", "er", "wird", ",", "und", "er", "wird", ",", "wird", "ein", "f\u00fcr\u00b7nehm"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "$,", "KON", "PPER", "VAFIN", "$,", "VAFIN", "ART", "ADJD"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.7": {"text": "F\u00fcrstenkind.", "tokens": ["F\u00fcrs\u00b7ten\u00b7kind", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "Da fragen die Gesellen ihn:", "tokens": ["Da", "fra\u00b7gen", "die", "Ge\u00b7sel\u00b7len", "ihn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201ewas aber kriegen wir?\u201c", "tokens": ["\u201e", "was", "a\u00b7ber", "krie\u00b7gen", "wir", "?", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "ADV", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201edie andre H\u00e4lft' ist euch verliehn,", "tokens": ["\u201e", "die", "and\u00b7re", "H\u00e4lft'", "ist", "euch", "ver\u00b7liehn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das ist genug f\u00fcr vier.", "tokens": ["Das", "ist", "ge\u00b7nug", "f\u00fcr", "vier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "APPR", "CARD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "O Wunder, Wunder! aus der halben Laus", "tokens": ["O", "Wun\u00b7der", ",", "Wun\u00b7der", "!", "aus", "der", "hal\u00b7ben", "Laus"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "$,", "NN", "$.", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Kommen noch, kommen noch f\u00fcnfthalb Grafen wohl", "tokens": ["Kom\u00b7men", "noch", ",", "kom\u00b7men", "noch", "f\u00fcnf\u00b7thalb", "Gra\u00b7fen", "wohl"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "$,", "VVFIN", "ADV", "CARD", "NN", "ADV"], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.7": {"text": "heraus.\u201c", "tokens": ["he\u00b7raus", ".", "\u201c"], "token_info": ["word", "punct", "punct"], "pos": ["PTKVZ", "$.", "$("], "meter": "--", "measure": "unknown.measure.zero"}}, "stanza.5": {"line.1": {"text": "Der Lehrjung sah sich Alles an:", "tokens": ["Der", "Lehr\u00b7jung", "sah", "sich", "Al\u00b7les", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eherr Meister, sagt mir jetzt,", "tokens": ["\u201e", "herr", "Meis\u00b7ter", ",", "sagt", "mir", "jetzt", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Hier seh' ich kriegt ja jedermann,", "tokens": ["Hier", "seh'", "ich", "kriegt", "ja", "je\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "ADV", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was krieg ich denn zuletzt?\u201c", "tokens": ["Was", "krieg", "ich", "denn", "zu\u00b7letzt", "?", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ADV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "\u201eo lecke, lecke das Messer rein,", "tokens": ["\u201e", "o", "le\u00b7cke", ",", "le\u00b7cke", "das", "Mes\u00b7ser", "rein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "FM", "$,", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und du wirst, und du wirst 'n schlechter Edelmann", "tokens": ["Und", "du", "wirst", ",", "und", "du", "wirst", "'n", "schlech\u00b7ter", "E\u00b7del\u00b7mann"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "$,", "KON", "PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "noch sein!\u201c", "tokens": ["noch", "sein", "!", "\u201c"], "token_info": ["word", "word", "punct", "punct"], "pos": ["ADV", "VAINF", "$.", "$("], "meter": "-+", "measure": "iambic.single"}}}}}