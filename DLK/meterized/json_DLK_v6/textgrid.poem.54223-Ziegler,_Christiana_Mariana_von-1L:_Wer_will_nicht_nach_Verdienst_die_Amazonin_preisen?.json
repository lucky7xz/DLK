{"textgrid.poem.54223": {"metadata": {"author": {"name": "Ziegler, Christiana Mariana von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wer will nicht nach Verdienst die Amazonin preisen?", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wer will nicht nach Verdienst die Amazonin preisen?", "tokens": ["Wer", "will", "nicht", "nach", "Ver\u00b7dienst", "die", "A\u00b7ma\u00b7zo\u00b7nin", "prei\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PTKNEG", "APPR", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die noch die heutge Welt mu\u00df heldenm\u00fcthig heissen?", "tokens": ["Die", "noch", "die", "heut\u00b7ge", "Welt", "mu\u00df", "hel\u00b7den\u00b7m\u00fct\u00b7hig", "heis\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "In M\u00e4nner-Hertzen wohnt nicht Hertz und Muth allein,", "tokens": ["In", "M\u00e4n\u00b7ner\u00b7Hert\u00b7zen", "wohnt", "nicht", "Hertz", "und", "Muth", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PTKNEG", "NN", "KON", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das Frauenzimmer kan auch Heroinen seyn.", "tokens": ["Das", "Frau\u00b7en\u00b7zim\u00b7mer", "kan", "auch", "He\u00b7roi\u00b7nen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "NN", "VAINF", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Wie viele k\u00f6nnen uns davon ein Zeugni\u00df stellen,", "tokens": ["Wie", "vie\u00b7le", "k\u00f6n\u00b7nen", "uns", "da\u00b7von", "ein", "Zeug\u00b7ni\u00df", "stel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VMFIN", "PPER", "PAV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die mit behertzter Faust den Feind im Treffen f\u00e4llen.", "tokens": ["Die", "mit", "be\u00b7hertz\u00b7ter", "Faust", "den", "Feind", "im", "Tref\u00b7fen", "f\u00e4l\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was dort Semiramis, was Fulvia, gethan,", "tokens": ["Was", "dort", "Se\u00b7mi\u00b7ra\u00b7mis", ",", "was", "Ful\u00b7via", ",", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "ADV", "NE", "$,", "PRELS", "NE", "$,", "VVPP", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "Das h\u00f6rt man Wunders-voll und mit Erstaunen an.", "tokens": ["Das", "h\u00f6rt", "man", "Wun\u00b7der\u00b7svoll", "und", "mit", "Er\u00b7stau\u00b7nen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "NN", "KON", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ismenens Tapferkeit, Zenobiens Beginnen,", "tokens": ["Is\u00b7me\u00b7nens", "Tap\u00b7fer\u00b7keit", ",", "Ze\u00b7no\u00b7biens", "Be\u00b7gin\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "NE", "NN", "$,"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.10": {"text": "Besinget heute noch der Chor der Pierinnen,", "tokens": ["Be\u00b7sin\u00b7get", "heu\u00b7te", "noch", "der", "Chor", "der", "Pie\u00b7rin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Und wie L\u00e4dusia den blancken Degen f\u00fchrt,", "tokens": ["Und", "wie", "L\u00e4\u00b7du\u00b7sia", "den", "blan\u00b7cken", "De\u00b7gen", "f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NE", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "--+-+-+-+-+", "measure": "anapaest.init"}, "line.12": {"text": "Das hat schon mancher Kiel vor langer Zeit ber\u00fchrt.", "tokens": ["Das", "hat", "schon", "man\u00b7cher", "Kiel", "vor", "lan\u00b7ger", "Zeit", "be\u00b7r\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PIAT", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und mein! wer wolte di\u00df den Frauenvolck verwehren?", "tokens": ["Und", "mein", "!", "wer", "wol\u00b7te", "di\u00df", "den", "Frau\u00b7en\u00b7volck", "ver\u00b7weh\u00b7ren", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "$.", "PWS", "VMFIN", "PDS", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die Pallas, die zu uns nothwendig mu\u00df geh\u00f6ren,", "tokens": ["Die", "Pal\u00b7las", ",", "die", "zu", "uns", "noth\u00b7wen\u00b7dig", "mu\u00df", "ge\u00b7h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "PPER", "ADJD", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Dieweil sie weiblich ist, f\u00fchrt Lantze, Schild und Schwerd,", "tokens": ["Die\u00b7weil", "sie", "weib\u00b7lich", "ist", ",", "f\u00fchrt", "Lant\u00b7ze", ",", "Schild", "und", "Schwerd", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$,", "VVFIN", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Zum Zeichen, da\u00df sie di\u00df von andern auch begehrt.", "tokens": ["Zum", "Zei\u00b7chen", ",", "da\u00df", "sie", "di\u00df", "von", "an\u00b7dern", "auch", "be\u00b7gehrt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "KOUS", "PPER", "PDS", "APPR", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Bellona giebet durch ihr heldenm\u00fcthges Wesen,", "tokens": ["Bel\u00b7lo\u00b7na", "gie\u00b7bet", "durch", "ihr", "hel\u00b7den\u00b7m\u00fcth\u00b7ges", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Als Krieges-G\u00f6ttin, di\u00df ohnstreitig auch zu lesen,", "tokens": ["Als", "Krie\u00b7ge\u00b7sG\u00f6t\u00b7tin", ",", "di\u00df", "ohn\u00b7strei\u00b7tig", "auch", "zu", "le\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "PDS", "ADJD", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Lucina schenckt uns nicht das Licht der Welt allein", "tokens": ["Lu\u00b7ci\u00b7na", "schenckt", "uns", "nicht", "das", "Licht", "der", "Welt", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "ART", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Da\u00df wir der Liebe blo\u00df die Hertzen solten weyhn.", "tokens": ["Da\u00df", "wir", "der", "Lie\u00b7be", "blo\u00df", "die", "Hert\u00b7zen", "sol\u00b7ten", "weyhn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Die Damen so sich nur in Amors Waffen \u00fcben,", "tokens": ["Die", "Da\u00b7men", "so", "sich", "nur", "in", "A\u00b7mors", "Waf\u00b7fen", "\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PRF", "ADV", "APPR", "NE", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und s\u00fcssen Zeitvertreib statt edler Arbeit lieben,", "tokens": ["Und", "s\u00fcs\u00b7sen", "Zeit\u00b7ver\u00b7treib", "statt", "ed\u00b7ler", "Ar\u00b7beit", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Sind G\u00e4nse-Blumen gleich gemein und gantz veracht,", "tokens": ["Sind", "G\u00e4n\u00b7se\u00b7Blu\u00b7men", "gleich", "ge\u00b7mein", "und", "gantz", "ver\u00b7acht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "ADJD", "KON", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Da man hingegen die zu K\u00e4yser-Cronen macht.", "tokens": ["Da", "man", "hin\u00b7ge\u00b7gen", "die", "zu", "K\u00e4y\u00b7ser\u00b7Cro\u00b7nen", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ART", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Mars ist deswegen nicht ein Unhold zu benennen,", "tokens": ["Mars", "ist", "des\u00b7we\u00b7gen", "nicht", "ein", "Un\u00b7hold", "zu", "be\u00b7nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PAV", "PTKNEG", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Ob gleich sein Auge pflegt vor Wuth und Zorn zu brennen;", "tokens": ["Ob", "gleich", "sein", "Au\u00b7ge", "pflegt", "vor", "Wuth", "und", "Zorn", "zu", "bren\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "VVFIN", "APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Er kan deswegen doch, l\u00e4st ihm sein Handwerck ruhn,", "tokens": ["Er", "kan", "des\u00b7we\u00b7gen", "doch", ",", "l\u00e4st", "ihm", "sein", "Hand\u00b7werck", "ruhn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PAV", "ADV", "$,", "VVFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.28": {"text": "Mit Frauenzimmer sch\u00f6n und unvergleichlich thun,", "tokens": ["Mit", "Frau\u00b7en\u00b7zim\u00b7mer", "sch\u00f6n", "und", "un\u00b7ver\u00b7gleich\u00b7lich", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "KON", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "So bald er seinen Helm und K\u00fcra\u00df hingeschmissen,", "tokens": ["So", "bald", "er", "sei\u00b7nen", "Helm", "und", "K\u00fc\u00b7ra\u00df", "hin\u00b7ge\u00b7schmis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PPOSAT", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "So wei\u00df er in der That die Venus so zu k\u00fcssen,", "tokens": ["So", "wei\u00df", "er", "in", "der", "That", "die", "Ve\u00b7nus", "so", "zu", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Da\u00df mancher Spa\u00df-Galan, der doch die Kunst versteht,", "tokens": ["Da\u00df", "man\u00b7cher", "Spa\u00df\u00b7Ga\u00b7lan", ",", "der", "doch", "die", "Kunst", "ver\u00b7steht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Sich \u00fcberwunden sieht, von ihm besch\u00e4met geht.", "tokens": ["Sich", "\u00fc\u00b7berw\u00b7un\u00b7den", "sieht", ",", "von", "ihm", "be\u00b7sch\u00e4\u00b7met", "geht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVINF", "VVFIN", "$,", "APPR", "PPER", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}