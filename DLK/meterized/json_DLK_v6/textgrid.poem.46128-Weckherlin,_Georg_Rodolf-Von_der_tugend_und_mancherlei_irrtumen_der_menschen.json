{"textgrid.poem.46128": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Von der tugend und mancherlei irrtumen der menschen", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nein, es ist nicht der tugend schein,", "tokens": ["Nein", ",", "es", "ist", "nicht", "der", "tu\u00b7gend", "schein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "PTKNEG", "ART", "NN", "PTKVZ", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "so uns die wahre freud kan geben,", "tokens": ["so", "uns", "die", "wah\u00b7re", "freud", "kan", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "ADJA", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "sondern die tugend selbs allein", "tokens": ["son\u00b7dern", "die", "tu\u00b7gend", "selbs", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV", "ADV"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "kan uns gl\u00fcckselig machen leben;", "tokens": ["kan", "uns", "gl\u00fcck\u00b7se\u00b7lig", "ma\u00b7chen", "le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "VVINF", "VVINF", "$."], "meter": "+----+-+-", "measure": "dactylic.init"}, "line.5": {"text": "die tugend selbs hat das verm\u00f6gen", "tokens": ["die", "tu\u00b7gend", "selbs", "hat", "das", "ver\u00b7m\u00f6\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VAFIN", "PDS", "VVFIN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "m\u00fch und verdru\u00df von uns zu legen.", "tokens": ["m\u00fch", "und", "ver\u00b7dru\u00df", "von", "uns", "zu", "le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.2": {"line.1": {"text": "Die tugend macht den menschen reich,", "tokens": ["Die", "tu\u00b7gend", "macht", "den", "men\u00b7schen", "reich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "da\u00df ihn die armut nicht beschweret;", "tokens": ["da\u00df", "ihn", "die", "ar\u00b7mut", "nicht", "be\u00b7schwe\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "gl\u00fcck und ungl\u00fcck gilt ihm ganz gleich,", "tokens": ["gl\u00fcck", "und", "un\u00b7gl\u00fcck", "gilt", "ihm", "ganz", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VVFIN", "PPER", "ADV", "ADV", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "der hagel sein feld nicht entehret;", "tokens": ["der", "ha\u00b7gel", "sein", "feld", "nicht", "en\u00b7teh\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "got ihn mit solchem gut belohnet,", "tokens": ["got", "ihn", "mit", "sol\u00b7chem", "gut", "be\u00b7loh\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PIAT", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "das allzeit mit und in ihm wohnet.", "tokens": ["das", "all\u00b7zeit", "mit", "und", "in", "ihm", "woh\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "KON", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Die tugend gibt ruhm, adel, ehr,", "tokens": ["Die", "tu\u00b7gend", "gibt", "ruhm", ",", "a\u00b7del", ",", "ehr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "$,", "NE", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wer sie hat, der ist wolgeboren,", "tokens": ["wer", "sie", "hat", ",", "der", "ist", "wol\u00b7ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VAFIN", "$,", "PRELS", "VAFIN", "ADJD", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "ob er wol weder f\u00fcrst noch herr,", "tokens": ["ob", "er", "wol", "we\u00b7der", "f\u00fcrst", "noch", "herr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "KON", "ADV", "ADV", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "ist er doch von got auserkoren;", "tokens": ["ist", "er", "doch", "von", "got", "au\u00b7ser\u00b7ko\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "NE", "VVIZU", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "dan \u00fcber sein herz er regieret", "tokens": ["dan", "\u00fc\u00b7ber", "sein", "herz", "er", "re\u00b7gie\u00b7ret"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "PPER", "VVFIN"], "meter": "----+--+-", "measure": "iambic.di.relaxed"}, "line.6": {"text": "und \u00fcber die welt triumfieret.", "tokens": ["und", "\u00fc\u00b7ber", "die", "welt", "tri\u00b7um\u00b7fie\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.4": {"line.1": {"text": "Ob wol der natur freie hand", "tokens": ["Ob", "wol", "der", "na\u00b7tur", "frei\u00b7e", "hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "nicht seine glider wolgestaltet,", "tokens": ["nicht", "sei\u00b7ne", "gli\u00b7der", "wol\u00b7ge\u00b7stal\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPOSAT", "NN", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "wird der beharrliche wolstand", "tokens": ["wird", "der", "be\u00b7harr\u00b7li\u00b7che", "wol\u00b7stand"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "doch seiner seelen nicht veraltet:", "tokens": ["doch", "sei\u00b7ner", "see\u00b7len", "nicht", "ver\u00b7al\u00b7tet", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbsoll man nu wegen guter lehren", "tokens": ["\u00bb", "soll", "man", "nu", "we\u00b7gen", "gu\u00b7ter", "leh\u00b7ren"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VMFIN", "PIS", "ADV", "APPR", "ADJA", "VVINF"], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}, "line.6": {"text": "mehr das haupt oder den hut ehren?\u00ab", "tokens": ["mehr", "das", "haupt", "o\u00b7der", "den", "hut", "eh\u00b7ren", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ART", "NN", "KON", "ART", "NN", "VVINF", "$.", "$("], "meter": "+-+-+----", "measure": "unknown.measure.tri"}}, "stanza.5": {"line.1": {"text": "Die leibsgesundheit ist die gab,", "tokens": ["Die", "leibs\u00b7ge\u00b7sund\u00b7heit", "ist", "die", "gab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "damit uns die natur erlabet;", "tokens": ["da\u00b7mit", "uns", "die", "na\u00b7tur", "er\u00b7la\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "vil besser aber dessen hab,", "tokens": ["vil", "bes\u00b7ser", "a\u00b7ber", "des\u00b7sen", "hab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "PDS", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "der mit gesunder seel begabet,", "tokens": ["der", "mit", "ge\u00b7sun\u00b7der", "seel", "be\u00b7ga\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "seel, die kein zufall kan erschrecken,", "tokens": ["seel", ",", "die", "kein", "zu\u00b7fall", "kan", "er\u00b7schre\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PRELS", "PIAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "bekr\u00e4nken, schw\u00e4chen noch beflecken.", "tokens": ["be\u00b7kr\u00e4n\u00b7ken", ",", "schw\u00e4\u00b7chen", "noch", "be\u00b7fle\u00b7cken", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVINF", "$,", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Was hilft es, da\u00df in meinem hirn", "tokens": ["Was", "hilft", "es", ",", "da\u00df", "in", "mei\u00b7nem", "hirn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "$,", "KOUS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der Platon selbs und Zenon stecket?", "tokens": ["der", "Pla\u00b7ton", "selbs", "und", "Ze\u00b7non", "ste\u00b7cket", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "KON", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "da\u00df witzig scheinet meine stirn,", "tokens": ["da\u00df", "wit\u00b7zig", "schei\u00b7net", "mei\u00b7ne", "stirn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df mein mund stets von weisheit gecket?", "tokens": ["da\u00df", "mein", "mund", "stets", "von", "weis\u00b7heit", "ge\u00b7cket", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "wan in der einfalt reinen seelen", "tokens": ["wan", "in", "der", "ein\u00b7falt", "rei\u00b7nen", "see\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "die tugend sich pflegt zu verhehlen?", "tokens": ["die", "tu\u00b7gend", "sich", "pflegt", "zu", "ver\u00b7heh\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.7": {"line.1": {"text": "Was hilft es, da\u00df ich geb bericht", "tokens": ["Was", "hilft", "es", ",", "da\u00df", "ich", "geb", "be\u00b7richt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "von allem was jemal gewesen?", "tokens": ["von", "al\u00b7lem", "was", "je\u00b7mal", "ge\u00b7we\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "PWS", "ADV", "VAPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "da\u00df alle k\u00fcnstliche gedicht", "tokens": ["da\u00df", "al\u00b7le", "k\u00fcnst\u00b7li\u00b7che", "ge\u00b7dicht"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "der poeten ich wol gelesen:", "tokens": ["der", "po\u00b7e\u00b7ten", "ich", "wol", "ge\u00b7le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "ADV", "VVPP", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "wan sie durch ihr kunstreiches liegen,", "tokens": ["wan", "sie", "durch", "ihr", "kuns\u00b7trei\u00b7ches", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PPOSAT", "ADJA", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "mein zeit verk\u00fcrzend, mich betriegen?", "tokens": ["mein", "zeit", "ver\u00b7k\u00fcr\u00b7zend", ",", "mich", "be\u00b7trie\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$,", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Was hilft es, das gem\u00e4ld, gesang,", "tokens": ["Was", "hilft", "es", ",", "das", "ge\u00b7m\u00e4ld", ",", "ge\u00b7sang", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "PRELS", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "die zahl und ma\u00df wol zu verstehen,", "tokens": ["die", "zahl", "und", "ma\u00df", "wol", "zu", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "der sternen lauf, der welt fortgang", "tokens": ["der", "ster\u00b7nen", "lauf", ",", "der", "welt", "fort\u00b7gang"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und alle l\u00e4nder zu besehen:", "tokens": ["und", "al\u00b7le", "l\u00e4n\u00b7der", "zu", "be\u00b7se\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "wan in sich selbs mein herz, verblindet,", "tokens": ["wan", "in", "sich", "selbs", "mein", "herz", ",", "ver\u00b7blin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "APPR", "PRF", "ADV", "PPOSAT", "NN", "$,", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "kein zil, ma\u00df, zahl noch regul findet?", "tokens": ["kein", "zil", ",", "ma\u00df", ",", "zahl", "noch", "re\u00b7gul", "fin\u00b7det", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "NN", "$,", "ADV", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Was hilft es, andern rat, arznei,", "tokens": ["Was", "hilft", "es", ",", "an\u00b7dern", "rat", ",", "arz\u00b7nei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "PIS", "VVFIN", "$,", "ITJ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wolredenheit theur zu verkaufen,", "tokens": ["wol\u00b7re\u00b7den\u00b7heit", "theur", "zu", "ver\u00b7kau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "in fremde land um spezerei,", "tokens": ["in", "frem\u00b7de", "land", "um", "spe\u00b7ze\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "CARD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und mutig dem krieg zuzulaufen:", "tokens": ["und", "mu\u00b7tig", "dem", "krieg", "zu\u00b7zu\u00b7lau\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "VVIZU", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "wan zank und krankheit mich selbs plaget", "tokens": ["wan", "zank", "und", "krank\u00b7heit", "mich", "selbs", "pla\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "KON", "NN", "PPER", "ADV", "VVFIN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "und mir der tod allzeit nachjaget?", "tokens": ["und", "mir", "der", "tod", "all\u00b7zeit", "nach\u00b7ja\u00b7get", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Was hilft es mich, blind, taub und stum", "tokens": ["Was", "hilft", "es", "mich", ",", "blind", ",", "taub", "und", "stum"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "PRF", "$,", "ADJD", "$,", "ADJD", "KON", "XY"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "an gro\u00dfer herren h\u00f6f zu wohnen,", "tokens": ["an", "gro\u00b7\u00dfer", "her\u00b7ren", "h\u00f6f", "zu", "woh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und durch gesundheit und willkom", "tokens": ["und", "durch", "ge\u00b7sund\u00b7heit", "und", "will\u00b7kom"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "KON", "XY"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "des geists und leibs nicht zu verschonen,", "tokens": ["des", "geists", "und", "leibs", "nicht", "zu", "ver\u00b7scho\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "erlangend nichts mit m\u00fch und sorgen", "tokens": ["er\u00b7lan\u00b7gend", "nichts", "mit", "m\u00fch", "und", "sor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVPP", "PIS", "APPR", "ADJD", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "dan villeicht einen guten morgen?", "tokens": ["dan", "vil\u00b7leicht", "ei\u00b7nen", "gu\u00b7ten", "mor\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "ADV", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.11": {"line.1": {"text": "Ist es nicht fein, eh man guts thut", "tokens": ["Ist", "es", "nicht", "fein", ",", "eh", "man", "guts", "thut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADJD", "$,", "KOUS", "PIS", "NN", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "ohn bit und schmieren die leut hassen;", "tokens": ["ohn", "bit", "und", "schmie\u00b7ren", "die", "leut", "has\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "mit aufgenagelt krummem hut", "tokens": ["mit", "auf\u00b7ge\u00b7na\u00b7gelt", "krum\u00b7mem", "hut"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "sich breiter machen dan die gassen,", "tokens": ["sich", "brei\u00b7ter", "ma\u00b7chen", "dan", "die", "gas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVFIN", "ADV", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und auch mit sauren spotsaugbrauen", "tokens": ["und", "auch", "mit", "sau\u00b7ren", "spots\u00b7aug\u00b7brau\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "VVINF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "den, der vil be\u00dfer, schlim anschauen?", "tokens": ["den", ",", "der", "vil", "be\u00b7\u00dfer", ",", "schlim", "an\u00b7schau\u00b7en", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "ADV", "ADJD", "$,", "ADJD", "VVINF", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}}, "stanza.12": {"line.1": {"text": "Ist es nicht ein st\u00fcck der misgunst,", "tokens": ["Ist", "es", "nicht", "ein", "st\u00fcck", "der", "mis\u00b7gunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "da\u00df die, so sunst die k\u00fcnsten fliehen,", "tokens": ["da\u00df", "die", ",", "so", "sunst", "die", "k\u00fcns\u00b7ten", "flie\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$,", "ADV", "ADV", "ART", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "gestigen hoch durch des gelts kunst", "tokens": ["ges\u00b7ti\u00b7gen", "hoch", "durch", "des", "gelts", "kunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVPP", "ADJD", "APPR", "ART", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "die leiter stracks nach ihnen ziehen,", "tokens": ["die", "lei\u00b7ter", "stracks", "nach", "ih\u00b7nen", "zie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "damit die, deren werk bezeugen,", "tokens": ["da\u00b7mit", "die", ",", "de\u00b7ren", "werk", "be\u00b7zeu\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "$,", "PRELAT", "NN", "VVFIN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "da\u00df sie mehr wert, nicht hinachsteigen?", "tokens": ["da\u00df", "sie", "mehr", "wert", ",", "nicht", "hi\u00b7nach\u00b7stei\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "$,", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Ist es nicht artlich, andre leut", "tokens": ["Ist", "es", "nicht", "art\u00b7lich", ",", "and\u00b7re", "leut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADJD", "$,", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der seelen seligkeit berauben", "tokens": ["der", "see\u00b7len", "se\u00b7lig\u00b7keit", "be\u00b7rau\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und doch nicht wissen selbs den streit,", "tokens": ["und", "doch", "nicht", "wis\u00b7sen", "selbs", "den", "streit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "noch was, wie und warum zu glauben?", "tokens": ["noch", "was", ",", "wie", "und", "wa\u00b7rum", "zu", "glau\u00b7ben", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "$,", "PWAV", "KON", "PWAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "fein ist es, andre stets zu schm\u00e4hen", "tokens": ["fein", "ist", "es", ",", "and\u00b7re", "stets", "zu", "schm\u00e4\u00b7hen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "PIS", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und seine eigne fehl nicht sehen.", "tokens": ["und", "sei\u00b7ne", "eig\u00b7ne", "fehl", "nicht", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Es ist gar h\u00f6flich, seine sprach", "tokens": ["Es", "ist", "gar", "h\u00f6f\u00b7lich", ",", "sei\u00b7ne", "sprach"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "PPOSAT", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mit fremden worten zu parlieren", "tokens": ["mit", "frem\u00b7den", "wor\u00b7ten", "zu", "par\u00b7lie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und sie mit eines andern schmach,", "tokens": ["und", "sie", "mit", "ei\u00b7nes", "an\u00b7dern", "schmach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "mit fluchen, zotten, bossen zieren;", "tokens": ["mit", "flu\u00b7chen", ",", "zot\u00b7ten", ",", "bos\u00b7sen", "zie\u00b7ren", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "VVINF", "$,", "VVFIN", "$,", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "von spilen, schlemmen, stechen, schlagen,", "tokens": ["von", "spi\u00b7len", ",", "schlem\u00b7men", ",", "ste\u00b7chen", ",", "schla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "VVINF", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "von huren, hetzen, beizen sagen.", "tokens": ["von", "hu\u00b7ren", ",", "het\u00b7zen", ",", "bei\u00b7zen", "sa\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "VVINF", "$,", "VVFIN", "$,", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Wie lieb ist es, da\u00df arme leut", "tokens": ["Wie", "lieb", "ist", "es", ",", "da\u00df", "ar\u00b7me", "leut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "$,", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sich f\u00fcr dir neigen zu der erden?", "tokens": ["sich", "f\u00fcr", "dir", "nei\u00b7gen", "zu", "der", "er\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "wie gut ist es, in kurzer zeit", "tokens": ["wie", "gut", "ist", "es", ",", "in", "kur\u00b7zer", "zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "bei seinem dienst gar reich zu werden,", "tokens": ["bei", "sei\u00b7nem", "dienst", "gar", "reich", "zu", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADV", "ADV", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und doch noch dolle wort ausgie\u00dfen,", "tokens": ["und", "doch", "noch", "dol\u00b7le", "wort", "aus\u00b7gie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "wie man dabei mu\u00df vil einb\u00fc\u00dfen.", "tokens": ["wie", "man", "da\u00b7bei", "mu\u00df", "vil", "ein\u00b7b\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PAV", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Es ist fein, da\u00df ein fremdling sich", "tokens": ["Es", "ist", "fein", ",", "da\u00df", "ein", "fremd\u00b7ling", "sich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "KOUS", "ART", "VVFIN", "PRF"], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "kan in ein gutes haus einnisten,", "tokens": ["kan", "in", "ein", "gu\u00b7tes", "haus", "ein\u00b7nis\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und mit dem fuchsschwanz listiglich", "tokens": ["und", "mit", "dem", "fuchs\u00b7schwanz", "lis\u00b7tig\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ausbutzet fertiglich die kisten", "tokens": ["aus\u00b7but\u00b7zet", "fer\u00b7tig\u00b7lich", "die", "kis\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und dan, als ein subtiler sp\u00f6tter", "tokens": ["und", "dan", ",", "als", "ein", "sub\u00b7ti\u00b7ler", "sp\u00f6t\u00b7ter"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "die g\u00f6tter r\u00fchmet seine vetter.", "tokens": ["die", "g\u00f6t\u00b7ter", "r\u00fch\u00b7met", "sei\u00b7ne", "vet\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Es ist ein bo\u00df, ein reiches weib,", "tokens": ["Es", "ist", "ein", "bo\u00df", ",", "ein", "rei\u00b7ches", "weib", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "VVFIN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wie sie sunst sein mag, zu erdappen", "tokens": ["wie", "sie", "sunst", "sein", "mag", ",", "zu", "er\u00b7dap\u00b7pen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "VAINF", "VMFIN", "$,", "PTKZU", "VVINF"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "und sich bei ihr in stetem keib", "tokens": ["und", "sich", "bei", "ihr", "in", "ste\u00b7tem", "keib"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PRF", "APPR", "PPOSAT", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "bedecken mit der narrenkappen;", "tokens": ["be\u00b7de\u00b7cken", "mit", "der", "nar\u00b7ren\u00b7kap\u00b7pen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "wie auch ein jungfraubas zu freien,", "tokens": ["wie", "auch", "ein", "jung\u00b7frau\u00b7bas", "zu", "frei\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "ADJA", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "damit die herren g\u00fcnstig seien.", "tokens": ["da\u00b7mit", "die", "her\u00b7ren", "g\u00fcns\u00b7tig", "sei\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Es ist ein kunst, wan einer kan", "tokens": ["Es", "ist", "ein", "kunst", ",", "wan", "ei\u00b7ner", "kan"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PWAV", "PIS", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "vil guts zu nichts verdistillieren;", "tokens": ["vil", "guts", "zu", "nichts", "ver\u00b7dis\u00b7til\u00b7lie\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "es ist ein lob mit jederman", "tokens": ["es", "ist", "ein", "lob", "mit", "je\u00b7der\u00b7man"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "von jedem ding zu disputieren:", "tokens": ["von", "je\u00b7dem", "ding", "zu", "dis\u00b7pu\u00b7tie\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "in gutem gl\u00fcck sich zu erfreuen", "tokens": ["in", "gu\u00b7tem", "gl\u00fcck", "sich", "zu", "er\u00b7freu\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "PRF", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und weis zu sein sich selbs beschreien.", "tokens": ["und", "weis", "zu", "sein", "sich", "selbs", "be\u00b7schrei\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "PTKZU", "VAINF", "PRF", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Nein. Der bem\u00fchet sich umsunst,", "tokens": ["Nein", ".", "Der", "be\u00b7m\u00fc\u00b7het", "sich", "um\u00b7sunst", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "ART", "VVFIN", "PRF", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sein herz vern\u00fcget zu befinden", "tokens": ["sein", "herz", "ver\u00b7n\u00fc\u00b7get", "zu", "be\u00b7fin\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVPP", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "(er sei gleich wie er w\u00f6ll voll kunst)", "tokens": ["(", "er", "sei", "gleich", "wie", "er", "w\u00f6ll", "voll", "kunst", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "KOKOM", "PPER", "VMFIN", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "der sich selbs nicht kan \u00fcberwinden", "tokens": ["der", "sich", "selbs", "nicht", "kan", "\u00fc\u00b7berw\u00b7in\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "ADV", "PTKNEG", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und der sein freud und sein vern\u00fcgen", "tokens": ["und", "der", "sein", "freud", "und", "sein", "ver\u00b7n\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "PPOSAT", "NN", "KON", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "will au\u00dferhalb sich selbs erkriegen.", "tokens": ["will", "au\u00b7\u00dfer\u00b7halb", "sich", "selbs", "er\u00b7krie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Dan es ja nicht der tugend ", "tokens": ["Dan", "es", "ja", "nicht", "der", "tu\u00b7gend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "ADV", "PTKNEG", "ART", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "so uns die wahre freud kan geben,", "tokens": ["so", "uns", "die", "wah\u00b7re", "freud", "kan", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "ADJA", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "sondern die tugend selbs allein", "tokens": ["son\u00b7dern", "die", "tu\u00b7gend", "selbs", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV", "ADV"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "kan uns gl\u00fcckselig machen leben;", "tokens": ["kan", "uns", "gl\u00fcck\u00b7se\u00b7lig", "ma\u00b7chen", "le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "VVINF", "VVINF", "$."], "meter": "+----+-+-", "measure": "dactylic.init"}, "line.5": {"text": "sie selbs, die einig sich verbindet", "tokens": ["sie", "selbs", ",", "die", "ei\u00b7nig", "sich", "ver\u00b7bin\u00b7det"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "$,", "PRELS", "ADJD", "PRF", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "mit der gotsforcht, stets \u00fcberwindet.", "tokens": ["mit", "der", "gots\u00b7forcht", ",", "stets", "\u00fc\u00b7berw\u00b7in\u00b7det", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}