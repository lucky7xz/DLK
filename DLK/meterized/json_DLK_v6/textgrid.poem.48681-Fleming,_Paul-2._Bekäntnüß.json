{"textgrid.poem.48681": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "2. Bek\u00e4ntn\u00fc\u00df", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mehr b\u00f6se noch als b\u00f6s' hab' ich bisher gelebet,", "tokens": ["Mehr", "b\u00f6\u00b7se", "noch", "als", "b\u00f6s'", "hab'", "ich", "bis\u00b7her", "ge\u00b7le\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "ADV", "KOUS", "ADJD", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "bei kalter Gottesfurcht mich brennend angestellt,", "tokens": ["bei", "kal\u00b7ter", "Got\u00b7tes\u00b7furcht", "mich", "bren\u00b7nend", "an\u00b7ge\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "den Himmel oft get\u00e4uscht, mehr mein Freund und der Welt,", "tokens": ["den", "Him\u00b7mel", "oft", "ge\u00b7t\u00e4uscht", ",", "mehr", "mein", "Freund", "und", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "$,", "ADV", "PPOSAT", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "bin selten \u00fcber mich und Wolken an geschwebet;", "tokens": ["bin", "sel\u00b7ten", "\u00fc\u00b7ber", "mich", "und", "Wol\u00b7ken", "an", "ge\u00b7schwe\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "PPER", "KON", "NN", "APZR", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "der schn\u00f6den Eitelkeit der Erden angeklebet.", "tokens": ["der", "schn\u00f6\u00b7den", "Ei\u00b7tel\u00b7keit", "der", "Er\u00b7den", "an\u00b7ge\u00b7kle\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich habe das getan, das mir selbst nicht gef\u00e4llt,", "tokens": ["Ich", "ha\u00b7be", "das", "ge\u00b7tan", ",", "das", "mir", "selbst", "nicht", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDS", "VVPP", "$,", "PRELS", "PPER", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "ein Sch\u00fcldner alles des, das Mosis Rechnung h\u00e4lt,", "tokens": ["ein", "Sch\u00fcld\u00b7ner", "al\u00b7les", "des", ",", "das", "Mo\u00b7sis", "Rech\u00b7nung", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIS", "ART", "$,", "PRELS", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "der ich mit Eifer auch hab' ofte widerstrebet.", "tokens": ["der", "ich", "mit", "Ei\u00b7fer", "auch", "hab'", "of\u00b7te", "wi\u00b7der\u00b7stre\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "ADV", "VAFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ich mu\u00df, will ich schon nicht, bekennen wider mich.", "tokens": ["Ich", "mu\u00df", ",", "will", "ich", "schon", "nicht", ",", "be\u00b7ken\u00b7nen", "wi\u00b7der", "mich", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "VMFIN", "PPER", "ADV", "PTKNEG", "$,", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mein Urteil, meine Straf' und Todesart sprech' ich.", "tokens": ["Mein", "Ur\u00b7teil", ",", "mei\u00b7ne", "Straf'", "und", "To\u00b7des\u00b7art", "sprech'", "ich", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "KON", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich hab' es so und so und \u00e4rger noch getrieben.", "tokens": ["Ich", "hab'", "es", "so", "und", "so", "und", "\u00e4r\u00b7ger", "noch", "ge\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "KON", "ADV", "KON", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Und was erz\u00e4hl' ich viel die angez\u00e4hlte Zahl", "tokens": ["Und", "was", "er\u00b7z\u00e4hl'", "ich", "viel", "die", "an\u00b7ge\u00b7z\u00e4hl\u00b7te", "Zahl"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "von meinen Schulden her? Gott liest sie allzumal", "tokens": ["von", "mei\u00b7nen", "Schul\u00b7den", "her", "?", "Gott", "liest", "sie", "all\u00b7zu\u00b7mal"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$.", "NN", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "von meiner Stirnen ab, an der sie sind geschrieben.", "tokens": ["von", "mei\u00b7ner", "Stir\u00b7nen", "ab", ",", "an", "der", "sie", "sind", "ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$,", "APPR", "PRELS", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}