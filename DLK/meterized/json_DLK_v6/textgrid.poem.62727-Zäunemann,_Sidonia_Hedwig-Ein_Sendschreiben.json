{"textgrid.poem.62727": {"metadata": {"author": {"name": "Z\u00e4unemann, Sidonia Hedwig", "birth": "N.A.", "death": "N.A."}, "title": "Ein Sendschreiben", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "durch Sitten und Tugend,", "tokens": ["durch", "Sit\u00b7ten", "und", "Tu\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Schm\u00fcckt diese die muntre und adliche Jugend,", "tokens": ["Schm\u00fcckt", "die\u00b7se", "die", "mun\u00b7tre", "und", "ad\u00b7li\u00b7che", "Ju\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "ART", "ADJA", "KON", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Gleich wie du sie tr\u00e4gest, so saget man frey:", "tokens": ["Gleich", "wie", "du", "sie", "tr\u00e4\u00b7gest", ",", "so", "sa\u00b7get", "man", "frey", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PPER", "PPER", "VVFIN", "$,", "ADV", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Da\u00df dieser mit Wahrheit ein Edelmann sey.", "tokens": ["Da\u00df", "die\u00b7ser", "mit", "Wahr\u00b7heit", "ein", "E\u00b7del\u00b7mann", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "APPR", "NN", "ART", "NN", "VAFIN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.5": {"text": "Ich kenne dein Wesen, drum mu\u00df ich bekennen:", "tokens": ["Ich", "ken\u00b7ne", "dein", "We\u00b7sen", ",", "drum", "mu\u00df", "ich", "be\u00b7ken\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "PAV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Du seyst ein Warhafter von Adel zu nennen.", "tokens": ["Du", "seyst", "ein", "War\u00b7haf\u00b7ter", "von", "A\u00b7del", "zu", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+--+-+--", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Ich heuchle mit nicht, dir ist es bewust,", "tokens": ["Ich", "heuch\u00b7le", "mit", "nicht", ",", "dir", "ist", "es", "be\u00b7wust", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "PTKNEG", "$,", "PPER", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Ich liebe die Wahrheit mit innigster Lust.", "tokens": ["Ich", "lie\u00b7be", "die", "Wahr\u00b7heit", "mit", "in\u00b7nigs\u00b7ter", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Ich habe mit Freuden im Schreiben gelesen,", "tokens": ["Ich", "ha\u00b7be", "mit", "Freu\u00b7den", "im", "Schrei\u00b7ben", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Da\u00df viele gelehrte im Lehrsaal gewesen,", "tokens": ["Da\u00df", "vie\u00b7le", "ge\u00b7lehr\u00b7te", "im", "Lehr\u00b7saal", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ADJA", "APPRART", "NN", "VAPP", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Als du dich vor kurzen zum Redner gemacht,", "tokens": ["Als", "du", "dich", "vor", "kur\u00b7zen", "zum", "Red\u00b7ner", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ADJA", "APPRART", "NN", "VVPP", "$,"], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Und nunmehr die Rede zur Presse gebracht.", "tokens": ["Und", "nun\u00b7mehr", "die", "Re\u00b7de", "zur", "Pres\u00b7se", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.5": {"text": "Drum hoff ich mit n\u00e4chsten zu meinen Vergn\u00fcgen", "tokens": ["Drum", "hoff", "ich", "mit", "n\u00e4chs\u00b7ten", "zu", "mei\u00b7nen", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "ADJA", "APPR", "PPOSAT", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.6": {"text": "Das artige Werkgen verehret zu kriegen.", "tokens": ["Das", "ar\u00b7ti\u00b7ge", "Werk\u00b7gen", "ver\u00b7eh\u00b7ret", "zu", "krie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.7": {"text": "Doch mach es jetzt anders als letzlich geschehn,", "tokens": ["Doch", "mach", "es", "jetzt", "an\u00b7ders", "als", "letz\u00b7lich", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "KOKOM", "ADV", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.8": {"text": "Und la\u00df mich bey Anfang ein Reimigen sehn.", "tokens": ["Und", "la\u00df", "mich", "bey", "An\u00b7fang", "ein", "Rei\u00b7mi\u00b7gen", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "APPR", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.3": {"line.1": {"text": "Wie kommt es ", "tokens": ["Wie", "kommt", "es"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "VVFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Ob G\u00fcnther, dein Landsmann ein Grabmaal soll kriegen?", "tokens": ["Ob", "G\u00fcn\u00b7ther", ",", "dein", "Lands\u00b7mann", "ein", "Grab\u00b7maal", "soll", "krie\u00b7gen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "$,", "PPOSAT", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Wie treibst ", "tokens": ["Wie", "treibst"], "token_info": ["word", "word"], "pos": ["PWAV", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "Der Dichter verdiente ja billig die Ehr.", "tokens": ["Der", "Dich\u00b7ter", "ver\u00b7dien\u00b7te", "ja", "bil\u00b7lig", "die", "Ehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJD", "ART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.5": {"text": "W\u00e4r dieses geschehen, so h\u00e4tt ich gebethen,", "tokens": ["W\u00e4r", "die\u00b7ses", "ge\u00b7sche\u00b7hen", ",", "so", "h\u00e4tt", "ich", "ge\u00b7be\u00b7then", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "ADJA", "$,", "ADV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.6": {"text": "Du lie\u00dft mich stat deiner zur Rede auftreten,", "tokens": ["Du", "lie\u00dft", "mich", "stat", "dei\u00b7ner", "zur", "Re\u00b7de", "auf\u00b7tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "PPOSAT", "APPRART", "NN", "VVINF", "$,"], "meter": "-+--+--+-+--", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Vor schlesische Redner geziehmt es sich nicht,", "tokens": ["Vor", "schle\u00b7si\u00b7sche", "Red\u00b7ner", "ge\u00b7ziehmt", "es", "sich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "PPER", "PRF", "PTKNEG", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.8": {"text": "Da\u00df man sich selbst lobet, und von sich selbst spricht.", "tokens": ["Da\u00df", "man", "sich", "selbst", "lo\u00b7bet", ",", "und", "von", "sich", "selbst", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "ADV", "VVFIN", "$,", "KON", "APPR", "PRF", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.4": {"line.1": {"text": "Du hast auch nicht \u00fcbel in Wehlen getroffen", "tokens": ["Du", "hast", "auch", "nicht", "\u00fc\u00b7bel", "in", "Weh\u00b7len", "ge\u00b7trof\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "ADJD", "APPR", "NN", "VVPP"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Von diesen zwey Sch\u00f6nen ist vieles zu hoffen", "tokens": ["Von", "die\u00b7sen", "zwey", "Sch\u00f6\u00b7nen", "ist", "vie\u00b7les", "zu", "hof\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "CARD", "NN", "VAFIN", "PIS", "PTKZU", "VVINF"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Die erste ist warlich die sch\u00f6nste Person,", "tokens": ["Die", "ers\u00b7te", "ist", "war\u00b7lich", "die", "sch\u00f6ns\u00b7te", "Per\u00b7son", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Du liesest von dieser wohl schwerlich davon.", "tokens": ["Du", "lie\u00b7sest", "von", "die\u00b7ser", "wohl", "schwer\u00b7lich", "da\u00b7von", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "ADV", "ADJD", "PAV", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.5": {"text": "Ja, wenn du die Liebe des N\u00e4chsten bed\u00e4chtest,", "tokens": ["Ja", ",", "wenn", "du", "die", "Lie\u00b7be", "des", "N\u00e4chs\u00b7ten", "be\u00b7d\u00e4ch\u00b7test", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "PPER", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "----+--+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Ihr andre Begriffe und Lehren beybr\u00e4chtest,", "tokens": ["Ihr", "and\u00b7re", "Be\u00b7grif\u00b7fe", "und", "Leh\u00b7ren", "bey\u00b7br\u00e4ch\u00b7test", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.7": {"text": "So th\u00e4tst du was Gutes. Wers besser versteht,", "tokens": ["So", "th\u00e4tst", "du", "was", "Gu\u00b7tes", ".", "Wers", "bes\u00b7ser", "ver\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "$.", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Der Lehre ein M\u00e4dgen das irrend rum geht.", "tokens": ["Der", "Leh\u00b7re", "ein", "M\u00e4d\u00b7gen", "das", "ir\u00b7rend", "rum", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ART", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.9": {"text": "Die andre ist gleichfals nicht \u00fcbel gesinnet,", "tokens": ["Die", "and\u00b7re", "ist", "gleich\u00b7fals", "nicht", "\u00fc\u00b7bel", "ge\u00b7sin\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VAFIN", "ADV", "PTKNEG", "ADJD", "VVPP", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.10": {"text": "Dieweil ihr Verm\u00f6gen dadurch nicht zerinnet.", "tokens": ["Die\u00b7weil", "ihr", "Ver\u00b7m\u00f6\u00b7gen", "da\u00b7durch", "nicht", "ze\u00b7rin\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PAV", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.11": {"text": "Vier Groschen die Woche vor alles verzehrt.", "tokens": ["Vier", "Gro\u00b7schen", "die", "Wo\u00b7che", "vor", "al\u00b7les", "ver\u00b7zehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ART", "NN", "APPR", "PIS", "VVPP", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.12": {"text": "O gl\u00fccklicher Ehmann! dem diese beschert.", "tokens": ["O", "gl\u00fcck\u00b7li\u00b7cher", "Eh\u00b7mann", "!", "dem", "die\u00b7se", "be\u00b7schert", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$.", "ART", "PDS", "VVFIN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.13": {"text": "Bek\u00f6mst du dereinsten so eine wie jene,", "tokens": ["Be\u00b7k\u00f6mst", "du", "de\u00b7reins\u00b7ten", "so", "ei\u00b7ne", "wie", "je\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "PIS", "KOKOM", "PDS", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.14": {"text": "So darfst du nicht sorgen, es werde die Sch\u00f6ne", "tokens": ["So", "darfst", "du", "nicht", "sor\u00b7gen", ",", "es", "wer\u00b7de", "die", "Sch\u00f6\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,", "PPER", "VAFIN", "ART", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.15": {"text": "Dir schn\u00f6de begegnen, sie schmeichelt dich ehr,", "tokens": ["Dir", "schn\u00f6\u00b7de", "be\u00b7geg\u00b7nen", ",", "sie", "schmei\u00b7chelt", "dich", "ehr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVINF", "$,", "PPER", "VVFIN", "PPER", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.16": {"text": "Sie fraget dich freundlich und bittet dich sehr:", "tokens": ["Sie", "fra\u00b7get", "dich", "freund\u00b7lich", "und", "bit\u00b7tet", "dich", "sehr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "KON", "VVFIN", "PPER", "ADV", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.17": {"text": "Du solst ihr bald dieses, bald jenes berichten.", "tokens": ["Du", "solst", "ihr", "bald", "die\u00b7ses", ",", "bald", "je\u00b7nes", "be\u00b7rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PDAT", "$,", "ADV", "PDS", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.18": {"text": "Sie wird dir nichts l\u00e4ugnen noch etwas erdichten.", "tokens": ["Sie", "wird", "dir", "nichts", "l\u00e4ug\u00b7nen", "noch", "et\u00b7was", "er\u00b7dich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PIS", "VVFIN", "ADV", "PIS", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.19": {"text": "Sie bittet mit L\u00e4cheln: Schatz! f\u00fcr mir die Hand,", "tokens": ["Sie", "bit\u00b7tet", "mit", "L\u00e4\u00b7cheln", ":", "Schatz", "!", "f\u00fcr", "mir", "die", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$.", "NN", "$.", "APPR", "PPER", "ART", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Und mach mir, den Namen zu schreiben, bekant.", "tokens": ["Und", "mach", "mir", ",", "den", "Na\u00b7men", "zu", "schrei\u00b7ben", ",", "be\u00b7kant", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "ART", "NN", "PTKZU", "VVINF", "$,", "ADJD", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.21": {"text": "Wie? wird dich nicht dieses aufs h\u00f6chste erg\u00f6tzen!", "tokens": ["Wie", "?", "wird", "dich", "nicht", "die\u00b7ses", "aufs", "h\u00f6chs\u00b7te", "er\u00b7g\u00f6t\u00b7zen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VAFIN", "PPER", "PTKNEG", "PDAT", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.22": {"text": "Was wirst du wohl diesen Vergn\u00fcgen gleich sch\u00e4tzen!", "tokens": ["Was", "wirst", "du", "wohl", "die\u00b7sen", "Ver\u00b7gn\u00fc\u00b7gen", "gleich", "sch\u00e4t\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "PDAT", "NN", "ADV", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.23": {"text": "Erfreuet dich aber das gunstige Gl\u00fcck", "tokens": ["Er\u00b7freu\u00b7et", "dich", "a\u00b7ber", "das", "guns\u00b7ti\u00b7ge", "Gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.24": {"text": "Mit einer Gemahlin, die alle die St\u00fcck", "tokens": ["Mit", "ei\u00b7ner", "Ge\u00b7mah\u00b7lin", ",", "die", "al\u00b7le", "die", "St\u00fcck"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PIS", "ART", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.25": {"text": "Und Gaben und Tugend der letzteren tr\u00e4get;", "tokens": ["Und", "Ga\u00b7ben", "und", "Tu\u00b7gend", "der", "letz\u00b7te\u00b7ren", "tr\u00e4\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "ART", "ADJA", "VVFIN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.26": {"text": "So wirst du mit keiner Xantippe beleget.", "tokens": ["So", "wirst", "du", "mit", "kei\u00b7ner", "Xan\u00b7tip\u00b7pe", "be\u00b7le\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.27": {"text": "Sie \u00e4rgert sich niemahls, verstellt das Gesicht,", "tokens": ["Sie", "\u00e4r\u00b7gert", "sich", "nie\u00b7mahls", ",", "ver\u00b7stellt", "das", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.28": {"text": "Betr\u00fcbt sich sehr selten, erz\u00f6rnet sich nicht.", "tokens": ["Be\u00b7tr\u00fcbt", "sich", "sehr", "sel\u00b7ten", ",", "er\u00b7z\u00f6r\u00b7net", "sich", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "ADJD", "$,", "VVFIN", "PRF", "PTKNEG", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.29": {"text": "Ist munter und sparsam, und mehret die G\u00fcter.", "tokens": ["Ist", "mun\u00b7ter", "und", "spar\u00b7sam", ",", "und", "meh\u00b7ret", "die", "G\u00fc\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KON", "ADJD", "$,", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.30": {"text": "Du wehlst dir warhaftig sehr sch\u00f6ne Gem\u00fcther.", "tokens": ["Du", "wehlst", "dir", "war\u00b7haf\u00b7tig", "sehr", "sch\u00f6\u00b7ne", "Ge\u00b7m\u00fc\u00b7ther", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "ADV", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.31": {"text": "Vergieb mir mein Scherzen, verzeihe dem Kiel,", "tokens": ["Ver\u00b7gieb", "mir", "mein", "Scher\u00b7zen", ",", "ver\u00b7zei\u00b7he", "dem", "Kiel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN", "$,", "VVFIN", "ART", "NE", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.32": {"text": "Mein Schreiben ist jetzo ein lustiges Spiel.", "tokens": ["Mein", "Schrei\u00b7ben", "ist", "jet\u00b7zo", "ein", "lus\u00b7ti\u00b7ges", "Spiel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+--++-+--+", "measure": "iambic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Es ist nicht zu leugnen, man k\u00f6nte von diesen", "tokens": ["Es", "ist", "nicht", "zu", "leug\u00b7nen", ",", "man", "k\u00f6n\u00b7te", "von", "die\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$,", "PIS", "VMFIN", "APPR", "PDAT"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Ein Schauspiel erdenken und lustig beschliessen,", "tokens": ["Ein", "Schau\u00b7spiel", "er\u00b7den\u00b7ken", "und", "lus\u00b7tig", "be\u00b7schlies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "KON", "ADJD", "VVPP", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Es k\u00e4me viel artges zu Lachen mit f\u00fcr.", "tokens": ["Es", "k\u00e4\u00b7me", "viel", "art\u00b7ges", "zu", "La\u00b7chen", "mit", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "APPR", "NN", "APPR", "APPR", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Was lachen wir aber! was suchen denn wir", "tokens": ["Was", "la\u00b7chen", "wir", "a\u00b7ber", "!", "was", "su\u00b7chen", "denn", "wir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$.", "PWS", "VVFIN", "KON", "PPER"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "Ein Schauspiel von fremden und anderen Sachen", "tokens": ["Ein", "Schau\u00b7spiel", "von", "frem\u00b7den", "und", "an\u00b7de\u00b7ren", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADJA", "KON", "ADJA", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.6": {"text": "Die uns nicht betreffen, mit M\u00fche zu machen?", "tokens": ["Die", "uns", "nicht", "be\u00b7tref\u00b7fen", ",", "mit", "M\u00fc\u00b7he", "zu", "ma\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "VVINF", "$,", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Ich glaube jedwedens sein Leben und Lauf,", "tokens": ["Ich", "glau\u00b7be", "jed\u00b7we\u00b7dens", "sein", "Le\u00b7ben", "und", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.8": {"text": "F\u00fchrt selbsten ein Schauspiel gar oftermahls auf.", "tokens": ["F\u00fchrt", "selbs\u00b7ten", "ein", "Schau\u00b7spiel", "gar", "of\u00b7ter\u00b7mahls", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.9": {"text": "Freund! da\u00df dich die Grafen vor andern verehren,", "tokens": ["Freund", "!", "da\u00df", "dich", "die", "Gra\u00b7fen", "vor", "an\u00b7dern", "ver\u00b7eh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KOUS", "PPER", "ART", "NN", "APPR", "PIS", "VVFIN", "$,"], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.10": {"text": "Das wird dir dein Gl\u00fccke und Ehre vermehren,", "tokens": ["Das", "wird", "dir", "dein", "Gl\u00fc\u00b7cke", "und", "Eh\u00b7re", "ver\u00b7meh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "PPOSAT", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.11": {"text": "Vergn\u00fcg dich dar\u00fcber: die Lust ist verg\u00f6nnt.", "tokens": ["Ver\u00b7gn\u00fcg", "dich", "da\u00b7r\u00fc\u00b7ber", ":", "die", "Lust", "ist", "ver\u00b7g\u00f6nnt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "PAV", "$.", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.12": {"text": "Denn welcher die Grafen gesehen und kennt,", "tokens": ["Denn", "wel\u00b7cher", "die", "Gra\u00b7fen", "ge\u00b7se\u00b7hen", "und", "kennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELS", "ART", "NN", "VVPP", "KON", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.13": {"text": "Der mu\u00df es gestehen, Sie zieren die Erde", "tokens": ["Der", "mu\u00df", "es", "ge\u00b7ste\u00b7hen", ",", "Sie", "zie\u00b7ren", "die", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "PPER", "VVPP", "$,", "PPER", "VVFIN", "ART", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.14": {"text": "Durch Stand und durch Tugend, und jedermann werde", "tokens": ["Durch", "Stand", "und", "durch", "Tu\u00b7gend", ",", "und", "je\u00b7der\u00b7mann", "wer\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,", "KON", "PIS", "VAFIN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.15": {"text": "Zur Liebe und Ehrfurcht gereitzt und gef\u00fchrt.", "tokens": ["Zur", "Lie\u00b7be", "und", "Ehr\u00b7furcht", "ge\u00b7reitzt", "und", "ge\u00b7f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NN", "VVPP", "KON", "VVPP", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.16": {"text": "So bald er sie h\u00f6ret, erblicket und sp\u00fchrt.", "tokens": ["So", "bald", "er", "sie", "h\u00f6\u00b7ret", ",", "er\u00b7bli\u00b7cket", "und", "sp\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PPER", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.17": {"text": "Saline wird herrlich durch diese geschm\u00fccket.", "tokens": ["Sa\u00b7li\u00b7ne", "wird", "herr\u00b7lich", "durch", "die\u00b7se", "ge\u00b7schm\u00fc\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJD", "APPR", "PDAT", "VVPP", "$."], "meter": "+---+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.18": {"text": "Das Bildni\u00df der Weisheit ist in sie gedr\u00fccket.", "tokens": ["Das", "Bild\u00b7ni\u00df", "der", "Weis\u00b7heit", "ist", "in", "sie", "ge\u00b7dr\u00fc\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.19": {"text": "Sie kennen das Wahre und Falsche so gleich,", "tokens": ["Sie", "ken\u00b7nen", "das", "Wah\u00b7re", "und", "Fal\u00b7sche", "so", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "KON", "NN", "ADV", "ADV", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.20": {"text": "Sie lieben die Musen und mehren ihr Reich.", "tokens": ["Sie", "lie\u00b7ben", "die", "Mu\u00b7sen", "und", "meh\u00b7ren", "ihr", "Reich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.21": {"text": "Ich hab mich gewundert, da\u00df du und mein Vetter,", "tokens": ["Ich", "hab", "mich", "ge\u00b7wun\u00b7dert", ",", "da\u00df", "du", "und", "mein", "Vet\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "$,", "KOUS", "PPER", "KON", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.22": {"text": "In Feindschaft gerathen. O! was vor ein Wetter", "tokens": ["In", "Feind\u00b7schaft", "ge\u00b7ra\u00b7then", ".", "O", "!", "was", "vor", "ein", "Wet\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVPP", "$.", "NE", "$.", "PWS", "APPR", "ART", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Ist unter euch kommen? Ihr habt euch geliebt,", "tokens": ["Ist", "un\u00b7ter", "euch", "kom\u00b7men", "?", "Ihr", "habt", "euch", "ge\u00b7liebt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "VVINF", "$.", "PPER", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.24": {"text": "Nun aber ist pl\u00f6tzlich die Freundschaft zerstiebt.", "tokens": ["Nun", "a\u00b7ber", "ist", "pl\u00f6tz\u00b7lich", "die", "Freund\u00b7schaft", "zer\u00b7stiebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.25": {"text": "Wie \u00e4ndert sich alles. Wo sind wohl auf Erden", "tokens": ["Wie", "\u00e4n\u00b7dert", "sich", "al\u00b7les", ".", "Wo", "sind", "wohl", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PRF", "PIS", "$.", "PWAV", "VAFIN", "ADV", "APPR", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.26": {"text": "Best\u00e4ndige Freunde, getreue Gefehrden", "tokens": ["Be\u00b7st\u00e4n\u00b7di\u00b7ge", "Freun\u00b7de", ",", "ge\u00b7treu\u00b7e", "Ge\u00b7fehr\u00b7den"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.27": {"text": "Zu sehn und zu h\u00f6ren? wo findet man sie?", "tokens": ["Zu", "sehn", "und", "zu", "h\u00f6\u00b7ren", "?", "wo", "fin\u00b7det", "man", "sie", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$.", "PWAV", "VVFIN", "PIS", "PPER", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.28": {"text": "Wenn bl\u00fchet die Treue? ich glaube wohl nie!", "tokens": ["Wenn", "bl\u00fc\u00b7het", "die", "Treu\u00b7e", "?", "ich", "glau\u00b7be", "wohl", "nie", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "ART", "NN", "$.", "PPER", "VVFIN", "ADV", "ADV", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.29": {"text": "Vers\u00f6hnt euch doch wieder! ich hab in eilf Wochen,", "tokens": ["Ver\u00b7s\u00f6hnt", "euch", "doch", "wie\u00b7der", "!", "ich", "hab", "in", "eilf", "Wo\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "$.", "PPER", "VAFIN", "APPR", "CARD", "NN", "$,"], "meter": "-+--+-+++-+-", "measure": "iambic.hexa.relaxed"}, "line.30": {"text": "Nichts von ihm gelesen, ihr auch nicht gesprochen.", "tokens": ["Nichts", "von", "ihm", "ge\u00b7le\u00b7sen", ",", "ihr", "auch", "nicht", "ge\u00b7spro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "PPER", "VVPP", "$,", "PPER", "ADV", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.31": {"text": "Ich wundre mich ziehmlich, warum er so schweigt.", "tokens": ["Ich", "wund\u00b7re", "mich", "ziehm\u00b7lich", ",", "wa\u00b7rum", "er", "so", "schweigt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "$,", "PWAV", "PPER", "ADV", "VVFIN", "$."], "meter": "-+--+-++--+", "measure": "iambic.penta.relaxed"}, "line.32": {"text": "Es bleibet dir ferner mit Freundschafft geneigt.", "tokens": ["Es", "blei\u00b7bet", "dir", "fer\u00b7ner", "mit", "Freund\u00b7schafft", "ge\u00b7neigt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}}}}