{"textgrid.poem.48361": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Chevy-Chase", "genre": "verse", "period": "N.A.", "pub_year": 1848, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gott sch\u00fctz' den K\u00f6nig, unsren Herrn,", "tokens": ["Gott", "sch\u00fctz'", "den", "K\u00f6\u00b7nig", ",", "un\u00b7sren", "Herrn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und unser aller Leben;", "tokens": ["Und", "un\u00b7ser", "al\u00b7ler", "Le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Im Chevy-Walde hat sich einst", "tokens": ["Im", "Che\u00b7vy\u00b7Wal\u00b7de", "hat", "sich", "einst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VAFIN", "PRF", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wehvolle Jagd begeben.", "tokens": ["Weh\u00b7vol\u00b7le", "Jagd", "be\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.2": {"line.1": {"text": "Graf Percy von Northumberland,", "tokens": ["Graf", "Per\u00b7cy", "von", "Nor\u00b7thum\u00b7ber\u00b7land", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NE", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Vor Taue noch und Tage", "tokens": ["Vor", "Tau\u00b7e", "noch", "und", "Ta\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADV", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Zog aus er heut, mit Hund und Horn,", "tokens": ["Zog", "aus", "er", "heut", ",", "mit", "Hund", "und", "Horn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "ADV", "$,", "APPR", "NN", "KON", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df er den Hirsch erjage.", "tokens": ["Da\u00df", "er", "den", "Hirsch", "er\u00b7ja\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.3": {"line.1": {"text": "Er schwur es j\u00fcngst an heil'ger St\u00e4tt'", "tokens": ["Er", "schwur", "es", "j\u00fcngst", "an", "heil'\u00b7ger", "St\u00e4tt'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u2013 Sorglos um Groll und Knirschen \u2013,", "tokens": ["\u2013", "Sorg\u00b7los", "um", "Groll", "und", "Knir\u00b7schen", "\u2013", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NN", "APPR", "NN", "KON", "NN", "$(", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Er woll' drei Sommertage lang", "tokens": ["Er", "woll'", "drei", "Som\u00b7mer\u00b7ta\u00b7ge", "lang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "CARD", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf schott'schem Boden pirschen.", "tokens": ["Auf", "schott'\u00b7schem", "Bo\u00b7den", "pir\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Er woll', was lebt im Chevy-Forst,", "tokens": ["Er", "woll'", ",", "was", "lebt", "im", "Che\u00b7vy\u00b7Forst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "PWS", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Speer und Pfeil erlegen.", "tokens": ["Mit", "Speer", "und", "Pfeil", "er\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bblord Douglas sch\u00fctze, wenn er kann,", "tokens": ["\u00bb", "lord", "Doug\u00b7las", "sch\u00fct\u00b7ze", ",", "wenn", "er", "kann", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NE", "NE", "VVFIN", "$,", "KOUS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Hirsch in den Gehegen.\u00ab", "tokens": ["Den", "Hirsch", "in", "den", "Ge\u00b7he\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Lord Douglas, der in Schottland lag,", "tokens": ["Lord", "Doug\u00b7las", ",", "der", "in", "Schott\u00b7land", "lag", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "PRELS", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als er das Wort vernommen,", "tokens": ["Als", "er", "das", "Wort", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dem Percy-Grafen schwur er da", "tokens": ["Dem", "Per\u00b7cy\u00b7Gra\u00b7fen", "schwur", "er", "da"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein blutiges Willkommen;", "tokens": ["Ein", "blu\u00b7ti\u00b7ges", "Will\u00b7kom\u00b7men", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Mit f\u00fcnfzehnhundert Mannen,", "tokens": ["Mit", "f\u00fcnf\u00b7zehn\u00b7hun\u00b7dert", "Man\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wohlausgesucht und wohlerprobt,", "tokens": ["Wohl\u00b7aus\u00b7ge\u00b7sucht", "und", "woh\u00b7ler\u00b7probt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Bogen straff zu spannen.", "tokens": ["Den", "Bo\u00b7gen", "straff", "zu", "span\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Schon, von der Meute aufgeschreckt,", "tokens": ["Schon", ",", "von", "der", "Meu\u00b7te", "auf\u00b7ge\u00b7schreckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Flieht, was die Schlucht geborgen;", "tokens": ["Flieht", ",", "was", "die", "Schlucht", "ge\u00b7bor\u00b7gen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein Montag war's, noch halbe Nacht,", "tokens": ["Ein", "Mon\u00b7tag", "wa\u00b7r's", ",", "noch", "hal\u00b7be", "Nacht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "ADV", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Es graute just im Morgen.", "tokens": ["Es", "grau\u00b7te", "just", "im", "Mor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Und eh' der Mittag kam, da lag", "tokens": ["Und", "eh'", "der", "Mit\u00b7tag", "kam", ",", "da", "lag"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "VVFIN", "$,", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Haufweis das Wild erschlagen,", "tokens": ["Hauf\u00b7weis", "das", "Wild", "er\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch rastlos, nach getanem Schmaus,", "tokens": ["Doch", "rast\u00b7los", ",", "nach", "ge\u00b7ta\u00b7nem", "Schmaus", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Begann ein neues Jagen.", "tokens": ["Be\u00b7gann", "ein", "neu\u00b7es", "Ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Aufs neu durch Schlucht und Dickicht hin", "tokens": ["Aufs", "neu", "durch", "Schlucht", "und", "Di\u00b7ckicht", "hin"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJD", "APPR", "NN", "KON", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Stob Huf und Hund nach Beute,", "tokens": ["Stob", "Huf", "und", "Hund", "nach", "Beu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und neuer Angstschrei mischte sich", "tokens": ["Und", "neu\u00b7er", "Angst\u00b7schrei", "mischte", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dem Lustgeheul der Meute.", "tokens": ["Dem", "Lust\u00b7ge\u00b7heul", "der", "Meu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Graf Percy nun war satt des Spiels", "tokens": ["Graf", "Per\u00b7cy", "nun", "war", "satt", "des", "Spiels"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "ADV", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Hirschen und mit Hinden,", "tokens": ["Mit", "Hir\u00b7schen", "und", "mit", "Hin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Er sprach: \u00bbLord Douglas gab sein Wort,", "tokens": ["Er", "sprach", ":", "\u00bb", "Lord", "Doug\u00b7las", "gab", "sein", "Wort", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "NN", "NE", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hier soll' ich heut ihn finden.", "tokens": ["Hier", "soll'", "ich", "heut", "ihn", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Bei Gott, nicht l\u00e4nger harrt' ich sein,", "tokens": ["Bei", "Gott", ",", "nicht", "l\u00e4n\u00b7ger", "harrt'", "ich", "sein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PTKNEG", "ADJD", "VVFIN", "PPER", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "D\u00e4cht' ich, er k\u00f6nn' es brechen.\u00ab", "tokens": ["D\u00e4cht'", "ich", ",", "er", "k\u00f6nn'", "es", "bre\u00b7chen", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPER", "VMFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da t\u00e4t alsbald ein Ritter jung", "tokens": ["Da", "t\u00e4t", "als\u00b7bald", "ein", "Rit\u00b7ter", "jung"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Also zum Grafen sprechen:", "tokens": ["Al\u00b7so", "zum", "Gra\u00b7fen", "spre\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.12": {"line.1": {"text": "\u00bbschau, Herr, dort blitzt es durch den Wald,", "tokens": ["\u00bb", "schau", ",", "Herr", ",", "dort", "blitzt", "es", "durch", "den", "Wald", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "NN", "$,", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das ist er mit den Seinen,", "tokens": ["Das", "ist", "er", "mit", "den", "Sei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "APPR", "ART", "PPOSS", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Schau, wie im Mittagssonnengl\u00fchn", "tokens": ["Schau", ",", "wie", "im", "Mit\u00b7tags\u00b7son\u00b7nen\u00b7gl\u00fchn"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PWAV", "APPRART", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Die blanken Speere scheinen.", "tokens": ["Die", "blan\u00b7ken", "Spee\u00b7re", "schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Zweitausend sind's vom Lauf des Tweed,", "tokens": ["Zweit\u00b7au\u00b7send", "sin\u00b7d's", "vom", "Lauf", "des", "Tweed", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "APPRART", "NN", "ART", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Aus T\u00e4lern und aus Glennen,", "tokens": ["Aus", "T\u00e4\u00b7lern", "und", "aus", "Glen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und der vorauf ist Douglas selbst,", "tokens": ["Und", "der", "vor\u00b7auf", "ist", "Doug\u00b7las", "selbst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "VAFIN", "NE", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An Ro\u00df und Helm zu kennen.\u00ab", "tokens": ["An", "Ro\u00df", "und", "Helm", "zu", "ken\u00b7nen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "\u00bb ... Nun denn, wohlan!\u00ab rief Percy da,", "tokens": ["\u00bb", "...", "Nun", "denn", ",", "wo\u00b7hlan", "!", "\u00ab", "rief", "Per\u00b7cy", "da", ","], "token_info": ["punct", "punct", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "$(", "ADV", "ADV", "$,", "ADV", "$.", "$(", "VVFIN", "NE", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbdies Feld sei unsre Schranke,", "tokens": ["\u00bb", "dies", "Feld", "sei", "uns\u00b7re", "Schran\u00b7ke", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Noch schl\u00fcpfte keiner mir hindurch,", "tokens": ["Noch", "schl\u00fcpf\u00b7te", "kei\u00b7ner", "mir", "hin\u00b7durch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sei's Schotte oder Franke.", "tokens": ["Sei's", "Schot\u00b7te", "o\u00b7der", "Fran\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Nun lohnt es sich, zu jagen,", "tokens": ["Nun", "lohnt", "es", "sich", ",", "zu", "ja\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Es brennt mein Herz, Mann gegen Mann", "tokens": ["Es", "brennt", "mein", "Herz", ",", "Mann", "ge\u00b7gen", "Mann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "NN", "APPR", "NN"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Die Schlacht mit ihm zu schlagen.\u00ab", "tokens": ["Die", "Schlacht", "mit", "ihm", "zu", "schla\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Lord Douglas h\u00f6rt's und ruft ihm zu:", "tokens": ["Lord", "Doug\u00b7las", "h\u00f6rt's", "und", "ruft", "ihm", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "KON", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbda soll mich Gott verderben,", "tokens": ["\u00bb", "da", "soll", "mich", "Gott", "ver\u00b7der\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So wahr ein Lord ich bin wie du,", "tokens": ["So", "wahr", "ein", "Lord", "ich", "bin", "wie", "du", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "PPER", "VAFIN", "KOKOM", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du oder ich mu\u00df sterben.", "tokens": ["Du", "o\u00b7der", "ich", "mu\u00df", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Doch h\u00f6r' mich, Percy, Schande w\u00e4r's", "tokens": ["Doch", "h\u00f6r'", "mich", ",", "Per\u00b7cy", ",", "Schan\u00b7de", "w\u00e4r's"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$,", "NE", "$,", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Schimpf an unsrem Leben,", "tokens": ["Und", "Schimpf", "an", "uns\u00b7rem", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So vieler Mannen schuldlos Blut", "tokens": ["So", "vie\u00b7ler", "Man\u00b7nen", "schuld\u00b7los", "Blut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit in den Kauf zu geben.", "tokens": ["Mit", "in", "den", "Kauf", "zu", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Es sei all' unser Streit gelegt", "tokens": ["Es", "sei", "all'", "un\u00b7ser", "Streit", "ge\u00b7legt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIS", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In unsre beiden Speere ...\u00ab", "tokens": ["In", "uns\u00b7re", "bei\u00b7den", "Spee\u00b7re", "...", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "PIAT", "NN", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbverdammt sei der\u00ab, rief Percy da,", "tokens": ["\u00bb", "ver\u00b7dammt", "sei", "der", "\u00ab", ",", "rief", "Per\u00b7cy", "da", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVPP", "VAFIN", "ART", "$(", "$,", "VVFIN", "NE", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbder andren Sinnes w\u00e4re ...\u00ab", "tokens": ["\u00bb", "der", "an\u00b7dren", "Sin\u00b7nes", "w\u00e4\u00b7re", "...", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "VAFIN", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Da trat ein Rittersmann herf\u00fcr,", "tokens": ["Da", "trat", "ein", "Rit\u00b7ters\u00b7mann", "her\u00b7f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Withrington hie\u00df der Degen,", "tokens": ["Wit\u00b7hring\u00b7ton", "hie\u00df", "der", "De\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der sprach: \u00bbHier m\u00fc\u00dfig zuzuschaun,", "tokens": ["Der", "sprach", ":", "\u00bb", "Hier", "m\u00fc\u00b7\u00dfig", "zu\u00b7zu\u00b7schaun", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$.", "$(", "ADV", "ADJD", "VVIZU", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dran ist uns nicht gelegen.", "tokens": ["Dran", "ist", "uns", "nicht", "ge\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Wir wollen nicht, dieweil ihr k\u00e4mpft,", "tokens": ["Wir", "wol\u00b7len", "nicht", ",", "die\u00b7weil", "ihr", "k\u00e4mpft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hier Psalm und Lieder singen,", "tokens": ["Hier", "Psalm", "und", "Lie\u00b7der", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und unsrem K\u00f6nig Heinrich dann", "tokens": ["Und", "uns\u00b7rem", "K\u00f6\u00b7nig", "Hein\u00b7rich", "dann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "NE", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In London Botschaft bringen.", "tokens": ["In", "Lon\u00b7don", "Bot\u00b7schaft", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Wohl seid ihr Lords und edle Herrn,", "tokens": ["Wohl", "seid", "ihr", "Lords", "und", "ed\u00b7le", "Herrn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wir nur Knapp' und Ritter,", "tokens": ["Und", "wir", "nur", "Knapp'", "und", "Rit\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch d\u00e4cht' ich traun, auch unser Schwert", "tokens": ["Doch", "d\u00e4cht'", "ich", "traun", ",", "auch", "un\u00b7ser", "Schwert"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "VVINF", "$,", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Macht Wunden oder Splitter.\u00ab", "tokens": ["Macht", "Wun\u00b7den", "o\u00b7der", "Split\u00b7ter", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Da tat alsbald all' englisch Volk", "tokens": ["Da", "tat", "als\u00b7bald", "all'", "eng\u00b7lisch", "Volk"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Eschenbogen biegen,", "tokens": ["Den", "E\u00b7schen\u00b7bo\u00b7gen", "bie\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und achtzig Schotten sanken hin", "tokens": ["Und", "acht\u00b7zig", "Schot\u00b7ten", "san\u00b7ken", "hin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "CARD", "NN", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von ihrer Pfeile Fliegen.", "tokens": ["Von", "ih\u00b7rer", "Pfei\u00b7le", "Flie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Lord Douglas aber, unbewegt,", "tokens": ["Lord", "Doug\u00b7las", "a\u00b7ber", ",", "un\u00b7be\u00b7wegt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "NE", "ADV", "$,", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sitzt fest im Eisenb\u00fcgel", "tokens": ["Sitzt", "fest", "im", "Ei\u00b7sen\u00b7b\u00fc\u00b7gel"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und kehrt zu seinen Mannen jetzt", "tokens": ["Und", "kehrt", "zu", "sei\u00b7nen", "Man\u00b7nen", "jetzt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hoch auf des Waldes H\u00fcgel.", "tokens": ["Hoch", "auf", "des", "Wal\u00b7des", "H\u00fc\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Schon stehn sie da, nach Kriegesart", "tokens": ["Schon", "stehn", "sie", "da", ",", "nach", "Krie\u00b7ge\u00b7sart"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geteilt zu dreien Rotten,", "tokens": ["Ge\u00b7teilt", "zu", "drei\u00b7en", "Rot\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und nieder wie ein Hagel jetzt", "tokens": ["Und", "nie\u00b7der", "wie", "ein", "Ha\u00b7gel", "jetzt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKVZ", "KOKOM", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00e4hrt Douglas mit den Schotten.", "tokens": ["F\u00e4hrt", "Doug\u00b7las", "mit", "den", "Schot\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Das gab ein Stechen und ein Hau'n,", "tokens": ["Das", "gab", "ein", "Ste\u00b7chen", "und", "ein", "Hau'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Manch breite Wunde klaffte,", "tokens": ["Manch", "brei\u00b7te", "Wun\u00b7de", "klaff\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "L\u00e4ngst unser englisch Bogenvolk", "tokens": ["L\u00e4ngst", "un\u00b7ser", "eng\u00b7lisch", "Bo\u00b7gen\u00b7volk"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht mehr den Bogen straffte.", "tokens": ["Nicht", "mehr", "den", "Bo\u00b7gen", "straff\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "O Christ, es war f\u00fcr Herz und Sinn", "tokens": ["O", "Christ", ",", "es", "war", "f\u00fcr", "Herz", "und", "Sinn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "$,", "PPER", "VAFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Leid, nicht auszusagen,", "tokens": ["Ein", "Leid", ",", "nicht", "aus\u00b7zu\u00b7sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wie st\u00f6hnend da in Sand und Blut", "tokens": ["Wie", "st\u00f6h\u00b7nend", "da", "in", "Sand", "und", "Blut"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Menschenkn\u00e4ule lagen.", "tokens": ["Die", "Men\u00b7schen\u00b7kn\u00e4u\u00b7le", "la\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Und immer schwankte noch die Schlacht,", "tokens": ["Und", "im\u00b7mer", "schwank\u00b7te", "noch", "die", "Schlacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da endlich \u2013 mit Gestampfe \u2013", "tokens": ["Da", "end\u00b7lich", "\u2013", "mit", "Ge\u00b7stamp\u00b7fe", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "APPR", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ansprangen wie zwei L\u00f6wen jetzt", "tokens": ["An\u00b7spran\u00b7gen", "wie", "zwei", "L\u00f6\u00b7wen", "jetzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KOKOM", "CARD", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die F\u00fchrer selbst zum Kampfe.", "tokens": ["Die", "F\u00fch\u00b7rer", "selbst", "zum", "Kamp\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Sie k\u00e4mpften, bis vernehmbar fast", "tokens": ["Sie", "k\u00e4mpf\u00b7ten", ",", "bis", "ver\u00b7nehm\u00b7bar", "fast"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ADJD", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr Herz im Busen klopfte,", "tokens": ["Ihr", "Herz", "im", "Bu\u00b7sen", "klopf\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bis Blut und Schwei\u00df von Brust und Stirn", "tokens": ["Bis", "Blut", "und", "Schwei\u00df", "von", "Brust", "und", "Stirn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie Regen niedertropfte.", "tokens": ["Wie", "Re\u00b7gen", "nie\u00b7der\u00b7tropf\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "\u00bbergib dich, Percy!\u00ab Douglas rief's,", "tokens": ["\u00bb", "er\u00b7gib", "dich", ",", "Per\u00b7cy", "!", "\u00ab", "Doug\u00b7las", "rie\u00b7f's", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "$,", "NE", "$.", "$(", "NE", "NE", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "\u00bbganz Schottland soll dich preisen,", "tokens": ["\u00bb", "ganz", "Schott\u00b7land", "soll", "dich", "prei\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "NE", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und K\u00f6nig Jakob Ehr' und Gunst", "tokens": ["Und", "K\u00f6\u00b7nig", "Ja\u00b7kob", "Ehr'", "und", "Gunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "NE", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Am Throne dir erweisen.\u00ab", "tokens": ["Am", "Thro\u00b7ne", "dir", "er\u00b7wei\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Doch Percy stolz: \u00bbDa wollt' ich eh'", "tokens": ["Doch", "Per\u00b7cy", "stolz", ":", "\u00bb", "Da", "wollt'", "ich", "eh'"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["KON", "NE", "ADJD", "$.", "$(", "ADV", "VMFIN", "PPER", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie Kraut am Sumpf verrotten,", "tokens": ["Wie", "Kraut", "am", "Sumpf", "ver\u00b7rot\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mein Wort ist nein und dreimal nein", "tokens": ["Mein", "Wort", "ist", "nein", "und", "drei\u00b7mal", "nein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKANT", "KON", "ADV", "PTKANT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gen\u00fcber jedem Schotten.\u00ab", "tokens": ["Ge\u00b7n\u00fc\u00b7ber", "je\u00b7dem", "Schot\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADV", "PIAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "Da kam ein Pfeil aus unsern Reihn", "tokens": ["Da", "kam", "ein", "Pfeil", "aus", "un\u00b7sern", "Reihn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verr\u00e4trisch durch die L\u00fcfte", "tokens": ["Ver\u00b7r\u00e4t\u00b7risch", "durch", "die", "L\u00fcf\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und bohrte tief in Douglas' Herz", "tokens": ["Und", "bohr\u00b7te", "tief", "in", "Dou\u00b7glas'", "Herz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch Rippe sich und H\u00fcfte.", "tokens": ["Durch", "Rip\u00b7pe", "sich", "und", "H\u00fcf\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PRF", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "Er sank vom Ro\u00df, ein stiller Mann,", "tokens": ["Er", "sank", "vom", "Ro\u00df", ",", "ein", "stil\u00b7ler", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Graf Percy sah ihn enden", "tokens": ["Graf", "Per\u00b7cy", "sah", "ihn", "en\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "VVFIN", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und fa\u00dfte dann des Toten Hand", "tokens": ["Und", "fa\u00df\u00b7te", "dann", "des", "To\u00b7ten", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit seinen beiden H\u00e4nden.", "tokens": ["Mit", "sei\u00b7nen", "bei\u00b7den", "H\u00e4n\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.33": {"line.1": {"text": "\u00bbo Douglas\u00ab, rief er, \u00bbsolchen Siegs,", "tokens": ["\u00bb", "o", "Doug\u00b7las", "\u00ab", ",", "rief", "er", ",", "\u00bb", "sol\u00b7chen", "Siegs", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "FM", "FM", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des hat mein Herz nicht Labe,", "tokens": ["Des", "hat", "mein", "Herz", "nicht", "La\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "PTKNEG", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hin g\u00e4b' ich f\u00fcr dein Leben jetzt", "tokens": ["Hin", "g\u00e4b'", "ich", "f\u00fcr", "dein", "Le\u00b7ben", "jetzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mein Land und meine Habe.\u00ab", "tokens": ["Mein", "Land", "und", "mei\u00b7ne", "Ha\u00b7be", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.34": {"line.1": {"text": "Er sprach es kaum, da kam's wie Sturm", "tokens": ["Er", "sprach", "es", "kaum", ",", "da", "kam's", "wie", "Sturm"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PIS", "KOKOM", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch Freund und Feind gestoben,", "tokens": ["Durch", "Freund", "und", "Feind", "ge\u00b7sto\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Den Leib zum Sto\u00df weit vorgebeugt", "tokens": ["Den", "Leib", "zum", "Sto\u00df", "weit", "vor\u00b7ge\u00b7beugt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und hoch den Schild gehoben.", "tokens": ["Und", "hoch", "den", "Schild", "ge\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.35": {"line.1": {"text": "Wer ist's? Sir Ralph Montgommery.", "tokens": ["Wer", "ist's", "?", "Sir", "Ral\u00b7ph", "Mont\u00b7gom\u00b7me\u00b7ry", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$.", "NN", "NE", "NE", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er sah den Douglas sinken,", "tokens": ["Er", "sah", "den", "Doug\u00b7las", "sin\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nun soll auch Percys Helmbuschzier", "tokens": ["Nun", "soll", "auch", "Per\u00b7cys", "Helm\u00b7buschzier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADV", "NE", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nicht l\u00e4nger drohn und winken.", "tokens": ["Nicht", "l\u00e4n\u00b7ger", "drohn", "und", "win\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.36": {"line.1": {"text": "Und schleudernd jetzt den wucht'gen Schaft", "tokens": ["Und", "schleu\u00b7dernd", "jetzt", "den", "wucht'\u00b7gen", "Schaft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Hasses Kraft und Schnelle,", "tokens": ["Mit", "Has\u00b7ses", "Kraft", "und", "Schnel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Durchfuhr die Lanze Percys Leib", "tokens": ["Durch\u00b7fuhr", "die", "Lan\u00b7ze", "Per\u00b7cys", "Leib"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Um eine Weber-Elle.", "tokens": ["Um", "ei\u00b7ne", "We\u00b7ber\u00b7El\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.37": {"line.1": {"text": "Hin sank der ritterlichste Held", "tokens": ["Hin", "sank", "der", "rit\u00b7ter\u00b7lichs\u00b7te", "Held"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf hufgestampfte Tenne,", "tokens": ["Auf", "huf\u00b7ge\u00b7stampf\u00b7te", "Ten\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Schon aber griff ein Bogensch\u00fctz", "tokens": ["Schon", "a\u00b7ber", "griff", "ein", "Bo\u00b7gen\u00b7sch\u00fctz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nach K\u00f6cher und nach Senne.", "tokens": ["Nach", "K\u00f6\u00b7cher", "und", "nach", "Sen\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.38": {"line.1": {"text": "Er spannte straff des Bogens Seil,", "tokens": ["Er", "spann\u00b7te", "straff", "des", "Bo\u00b7gens", "Seil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So straff, wie nie er's spannte,", "tokens": ["So", "straff", ",", "wie", "nie", "er's", "spann\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PWAV", "ADV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und dr\u00fcckte seinen l\u00e4ngsten Pfeil", "tokens": ["Und", "dr\u00fcck\u00b7te", "sei\u00b7nen", "l\u00e4ngs\u00b7ten", "Pfeil"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Scharf an die Eschenkante.", "tokens": ["Scharf", "an", "die", "E\u00b7schen\u00b7kan\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.39": {"line.1": {"text": "Lang zielt' er so, da\u00df sichren Flugs", "tokens": ["Lang", "zielt'", "er", "so", ",", "da\u00df", "sich\u00b7ren", "Flugs"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "ADV", "$,", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Pfeil zum Herzen dringe,", "tokens": ["Der", "Pfeil", "zum", "Her\u00b7zen", "drin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und feucht vom Blut des Schotten jetzt", "tokens": ["Und", "feucht", "vom", "Blut", "des", "Schot\u00b7ten", "jetzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPRART", "NN", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bebt' in der Brust die Schwinge.", "tokens": ["Bebt'", "in", "der", "Brust", "die", "Schwin\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.40": {"line.1": {"text": "So fiel Sir Ralph Montgommery,", "tokens": ["So", "fiel", "Sir", "Ral\u00b7ph", "Mont\u00b7gom\u00b7me\u00b7ry", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "NE", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und mit ihm sind gefallen", "tokens": ["Und", "mit", "ihm", "sind", "ge\u00b7fal\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPER", "VAFIN", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Auf beiden Seiten m\u00e4nniglich", "tokens": ["Auf", "bei\u00b7den", "Sei\u00b7ten", "m\u00e4n\u00b7nig\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Ritter und Vasallen.", "tokens": ["Die", "Rit\u00b7ter", "und", "Va\u00b7sal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$."], "meter": "-+--+--", "measure": "iambic.di.relaxed"}}, "stanza.41": {"line.1": {"text": "Von zwanzighundert schott'schen Volks,", "tokens": ["Von", "zwan\u00b7zig\u00b7hun\u00b7dert", "schott'\u00b7schen", "Volks", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Schild und Speer genommen,", "tokens": ["Die", "Schild", "und", "Speer", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Kaum f\u00fcnfundf\u00fcnfzig, weh und wund,", "tokens": ["Kaum", "f\u00fcn\u00b7fund\u00b7f\u00fcnf\u00b7zig", ",", "weh", "und", "wund", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sind norderw\u00e4rts entkommen.", "tokens": ["Sind", "nor\u00b7der\u00b7w\u00e4rts", "ent\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.42": {"line.1": {"text": "Und unser Volk, nicht siegesfroh", "tokens": ["Und", "un\u00b7ser", "Volk", ",", "nicht", "sie\u00b7ges\u00b7froh"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "$,", "PTKNEG", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Trug es den Sieg von dannen,", "tokens": ["Trug", "es", "den", "Sieg", "von", "dan\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "ADV", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Nur dreiundf\u00fcnfzig kehrten heim", "tokens": ["Nur", "drei\u00b7und\u00b7f\u00fcnf\u00b7zig", "kehr\u00b7ten", "heim"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "CARD", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von f\u00fcnfzehnhundert Mannen.", "tokens": ["Von", "f\u00fcnf\u00b7zehn\u00b7hun\u00b7dert", "Man\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.43": {"line.1": {"text": "Die andern schliefen fest im Wald", "tokens": ["Die", "an\u00b7dern", "schlie\u00b7fen", "fest", "im", "Wald"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach hei\u00dfem Kampfgew\u00fchle,", "tokens": ["Nach", "hei\u00b7\u00dfem", "Kampf\u00b7ge\u00b7w\u00fch\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und Nachtwind nur und Mondenlicht", "tokens": ["Und", "Nacht\u00b7wind", "nur", "und", "Mon\u00b7den\u00b7licht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "ADV", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Glitt \u00fcber ihre Pf\u00fchle.", "tokens": ["Glitt", "\u00fc\u00b7ber", "ih\u00b7re", "Pf\u00fch\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.44": {"line.1": {"text": "Das war die Jagd im Chevy-Forst,", "tokens": ["Das", "war", "die", "Jagd", "im", "Che\u00b7vy\u00b7Forst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo Herr und Hirsch gefallen.", "tokens": ["Wo", "Herr", "und", "Hirsch", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Gott sch\u00fctz' den K\u00f6nig, unsren Herrn,", "tokens": ["Gott", "sch\u00fctz'", "den", "K\u00f6\u00b7nig", ",", "un\u00b7sren", "Herrn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sei uns gn\u00e4dig allen.", "tokens": ["Und", "sei", "uns", "gn\u00e4\u00b7dig", "al\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "PIAT", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}