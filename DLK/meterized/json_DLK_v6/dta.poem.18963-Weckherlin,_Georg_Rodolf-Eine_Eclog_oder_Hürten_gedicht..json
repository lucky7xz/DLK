{"dta.poem.18963": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Eine Eclog oder H\u00fcrten gedicht.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-200905198111", "language": ["de:0.99"], "booktitle": "Weckherlin, Georg Rodolf: Gaistliche und Weltliche Gedichte. Amsterdam, 1641."}, "poem": {"stanza.1": {"line.1": {"text": "Der Sch\u00e4fer Filodor hat schon durch seine tugent/", "tokens": ["Der", "Sch\u00e4\u00b7fer", "Fi\u00b7lo\u00b7dor", "hat", "schon", "durch", "sei\u00b7ne", "tu\u00b7gent", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NE", "VAFIN", "ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Durch seine lieb vnd trew/ die ehr vnd lehr der", "tokens": ["Durch", "sei\u00b7ne", "lieb", "vnd", "trew", "/", "die", "ehr", "vnd", "lehr", "der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJD", "KON", "ADJD", "$(", "ART", "NN", "KON", "NN", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "jugent/", "tokens": ["ju\u00b7gent", "/"], "token_info": ["word", "punct"], "pos": ["ADJD", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Der Lieblichkeit gestirn/ der holdseeligkeit blum/", "tokens": ["Der", "Lieb\u00b7lich\u00b7keit", "ge\u00b7stirn", "/", "der", "hold\u00b7see\u00b7lig\u00b7keit", "blum", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$(", "ART", "NN", "NE", "$("], "meter": "-+-+-+-++--+", "measure": "iambic.hexa.chol"}, "line.5": {"text": "Der Zucht vnd Keuschheit form/ vnd aller Sch\u00f6n-", "tokens": ["Der", "Zucht", "vnd", "Keuschheit", "form", "/", "vnd", "al\u00b7ler", "Sch\u00f6n"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN", "PTKVZ", "$(", "KON", "PIAT", "TRUNC"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "heit Ruhm/", "tokens": ["heit", "Ruhm", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "NN", "$("], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Der Insul Albion wohn vnd Cron so bew\u00f6get/", "tokens": ["Der", "In\u00b7sul", "Al\u00b7bi\u00b7on", "wohn", "vnd", "Cron", "so", "be\u00b7w\u00f6\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "KON", "NN", "ADV", "VVFIN", "$("], "meter": "---+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Da\u00df andre\u0304r Sch\u00e4fer dienst vnd lieb sie beygel\u00f6get:", "tokens": ["Da\u00df", "an\u00b7dr\u0113r", "Sch\u00e4\u00b7fer", "dienst", "vnd", "lieb", "sie", "bey\u00b7ge\u00b7l\u00f6\u00b7get", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NE", "ADV", "KON", "ADJD", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Vnd wie Er/ ", "tokens": ["Vnd", "wie", "Er", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "So sagte Sie nun jhm/ ", "tokens": ["So", "sag\u00b7te", "Sie", "nun", "jhm", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PPER", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Als Er mit Corydon/ den Cloris hielt gefangen", "tokens": ["Als", "Er", "mit", "Co\u00b7ry\u00b7don", "/", "den", "Clo\u00b7ris", "hielt", "ge\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NE", "$(", "ART", "NE", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "In jhrer haaren strick/ zu jhnen kam gegangen.", "tokens": ["In", "jhrer", "haa\u00b7ren", "strick", "/", "zu", "jh\u00b7nen", "kam", "ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$(", "APPR", "PPER", "VVFIN", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.13": {"text": "Daher/ als Myrta nu vnd Filodor mit lust", "tokens": ["Da\u00b7her", "/", "als", "Myr\u00b7ta", "nu", "vnd", "Fi\u00b7lo\u00b7dor", "mit", "lust"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "$(", "KOUS", "NN", "ADV", "KON", "NE", "APPR", "NN"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Empfunden gleiche hitz vnd lieb in jhrer brust/", "tokens": ["Emp\u00b7fun\u00b7den", "glei\u00b7che", "hitz", "vnd", "lieb", "in", "jhrer", "brust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "KON", "ADJD", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.15": {"text": "(wie Cloris anders thails wolt/ stoltz vnd hart/ eh", "tokens": ["(", "wie", "Clo\u00b7ris", "an\u00b7ders", "thails", "wolt", "/", "stoltz", "vnd", "hart", "/", "eh"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["$(", "KOKOM", "NE", "ADV", "ADV", "VMFIN", "$(", "ADJD", "KON", "ADJD", "$(", "KOUS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "sterben/", "tokens": ["ster\u00b7ben", "/"], "token_info": ["word", "punct"], "pos": ["VVINF", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.17": {"text": "Dan da\u00df Er Corydon solt jhre huld erwerben)", "tokens": ["Dan", "da\u00df", "Er", "Co\u00b7ry\u00b7don", "solt", "jhre", "huld", "er\u00b7wer\u00b7ben", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "NE", "VMFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "+--+-+--+-+-", "measure": "iambic.penta.invert"}, "line.18": {"text": "Sprach Myrta/ Filodor/ gantz glicklich ist dein", "tokens": ["Sprach", "Myr\u00b7ta", "/", "Fi\u00b7lo\u00b7dor", "/", "gantz", "glick\u00b7lich", "ist", "dein"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NE", "$(", "NE", "$(", "ADV", "ADJD", "VAFIN", "PPOSAT"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.19": {"text": "gang/", "tokens": ["gang", "/"], "token_info": ["word", "punct"], "pos": ["ADJD", "$("], "meter": "+", "measure": "single.up"}, "line.20": {"text": "Dieweil (wie Ich verhoff) du vns nu ein gesang", "tokens": ["Die\u00b7weil", "(", "wie", "Ich", "ver\u00b7hoff", ")", "du", "vns", "nu", "ein", "ge\u00b7sang"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "$(", "PWAV", "PPER", "VVFIN", "$(", "PPER", "PRF", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Mit Corydon/ der auch wol singen kan/ wilt lehren.", "tokens": ["Mit", "Co\u00b7ry\u00b7don", "/", "der", "auch", "wol", "sin\u00b7gen", "kan", "/", "wilt", "leh\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "$(", "ART", "ADV", "ADV", "VVINF", "VMFIN", "$(", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Er/ der nichts dan was Sie begehret/ kan begehren/", "tokens": ["Er", "/", "der", "nichts", "dan", "was", "Sie", "be\u00b7ge\u00b7hret", "/", "kan", "be\u00b7geh\u00b7ren", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$(", "ART", "PIS", "ADV", "PWS", "PPER", "VVFIN", "$(", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Beredet Corydon/ der von dem angesicht/", "tokens": ["Be\u00b7re\u00b7det", "Co\u00b7ry\u00b7don", "/", "der", "von", "dem", "an\u00b7ge\u00b7sicht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$(", "ART", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Darinnen seine sehl/ sich kan abwenden nicht/", "tokens": ["Da\u00b7rin\u00b7nen", "sei\u00b7ne", "sehl", "/", "sich", "kan", "ab\u00b7wen\u00b7den", "nicht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$(", "PRF", "VMFIN", "VVINF", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Sich zu den Nymfelein mit jhm al\u00dfbald zus\u00f6tzen/", "tokens": ["Sich", "zu", "den", "Nym\u00b7fel\u00b7ein", "mit", "jhm", "al\u00df\u00b7bald", "zu\u00b7s\u00f6t\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "APPR", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Vnd (wan es m\u00f6glich wer) Sie vnd sich zuerg\u00f6tzen.", "tokens": ["Vnd", "(", "wan", "es", "m\u00f6g\u00b7lich", "wer", ")", "Sie", "vnd", "sich", "zu\u00b7er\u00b7g\u00f6t\u00b7zen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "PWAV", "PPER", "ADJD", "PWS", "$(", "PPER", "KON", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Da al\u00dfdan Filodor au\u00df grosser lieb vnd fraid/", "tokens": ["Da", "al\u00df\u00b7dan", "Fi\u00b7lo\u00b7dor", "au\u00df", "gros\u00b7ser", "lieb", "vnd", "fraid", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NE", "APPR", "ADJA", "ADJD", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Da al\u00dfdan Corydon au\u00df grosser lieb vnd layd/", "tokens": ["Da", "al\u00df\u00b7dan", "Co\u00b7ry\u00b7don", "au\u00df", "gros\u00b7ser", "lieb", "vnd", "layd", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NE", "APPR", "ADJA", "ADJD", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Durch ein schier gleiches lied/ doch mit vngleichem", "tokens": ["Durch", "ein", "schier", "glei\u00b7ches", "lied", "/", "doch", "mit", "vn\u00b7glei\u00b7chem"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "$(", "ADV", "APPR", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "willen/", "tokens": ["wil\u00b7len", "/"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.31": {"text": "Fieng an auff dise wei\u00df der Myrt bit zu erfillen:", "tokens": ["Fi\u00b7eng", "an", "auff", "di\u00b7se", "wei\u00df", "der", "Myrt", "bit", "zu", "er\u00b7fil\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "APPR", "PDS", "VVFIN", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}}}}}