{"textgrid.poem.53230": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "Bey unverhofft- und h\u00f6chsterfrewlicher Ankunfft Sr. Churfl. Durchl. in Dero Hertzogthumb Preussen und Residentz K\u00f6nigsberg", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Hieher gehn nur unsre Schmertzen", "tokens": ["Hie\u00b7her", "gehn", "nur", "uns\u00b7re", "Schmert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wegen Dein, Du Helden Rhum,", "tokens": ["We\u00b7gen", "Dein", ",", "Du", "Hel\u00b7den", "Rhum", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "$,", "PPER", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Churf\u00fcrst, die\u00df dein Hertzogthum", "tokens": ["Chur\u00b7f\u00fcrst", ",", "die\u00df", "dein", "Hert\u00b7zog\u00b7thum"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "PDS", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lieget Gott zu tieff im Hertzen,", "tokens": ["Lie\u00b7get", "Gott", "zu", "tieff", "im", "Hert\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PTKA", "ADJD", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Als da\u00df Du, O Sonnen-Schein,", "tokens": ["Als", "da\u00df", "Du", ",", "O", "Son\u00b7nen\u00b7Schein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "$,", "NE", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "L\u00e4nger k\u00f6ntest von uns seyn.", "tokens": ["L\u00e4n\u00b7ger", "k\u00f6n\u00b7test", "von", "uns", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "APPR", "PPER", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Zwar was Du Dir vorgenommen", "tokens": ["Zwar", "was", "Du", "Dir", "vor\u00b7ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PWS", "PPER", "PPER", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mu\u00df durchau\u00df von statten gehn,", "tokens": ["Mu\u00df", "durch\u00b7au\u00df", "von", "stat\u00b7ten", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "ADJA", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn was mag Dir wiederstehn?", "tokens": ["Denn", "was", "mag", "Dir", "wie\u00b7ders\u00b7tehn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch da\u00df Du jetzt zu uns kommen,", "tokens": ["Doch", "da\u00df", "Du", "jetzt", "zu", "uns", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "G\u00f6nnest ", "tokens": ["G\u00f6n\u00b7nest"], "token_info": ["word"], "pos": ["NE"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Ist ohn Gottes Antrieb nicht.", "tokens": ["Ist", "ohn", "Got\u00b7tes", "An\u00b7trieb", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Unsre Noht, Du Himmels-Segen,", "tokens": ["Uns\u00b7re", "Noht", ",", "Du", "Him\u00b7mels\u00b7Se\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unser Angstgeschrey und Qual", "tokens": ["Un\u00b7ser", "Angst\u00b7ge\u00b7schrey", "und", "Qual"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist in gar zu grosser Zahl", "tokens": ["Ist", "in", "gar", "zu", "gros\u00b7ser", "Zahl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vor des H\u00f6chsten Thron gelegen,", "tokens": ["Vor", "des", "H\u00f6chs\u00b7ten", "Thron", "ge\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Bi\u00df Dich seyn verborgner Raht", "tokens": ["Bi\u00df", "Dich", "seyn", "ver\u00b7borg\u00b7ner", "Raht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Auff zu seyn gereitzet hat.", "tokens": ["Auff", "zu", "seyn", "ge\u00b7reit\u00b7zet", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PTKZU", "VAINF", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Nun, Du k\u00f6mpst, doch unempfangen,", "tokens": ["Nun", ",", "Du", "k\u00f6mpst", ",", "doch", "un\u00b7em\u00b7pfan\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "$,", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil das m\u00fcde ", "tokens": ["Weil", "das", "m\u00fc\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Rhut von seinem Tagewerck,", "tokens": ["Rhut", "von", "sei\u00b7nem", "Ta\u00b7ge\u00b7werck", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und schon Luna auff ist gangen,", "tokens": ["Und", "schon", "Lu\u00b7na", "auff", "ist", "gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "APPR", "VAFIN", "VVPP", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.5": {"text": "Die Dich von der Himmels-bahn", "tokens": ["Die", "Dich", "von", "der", "Him\u00b7mels\u00b7bahn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "ART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Sieht f\u00fcr ihren Bruder an.", "tokens": ["Sieht", "f\u00fcr", "ih\u00b7ren", "Bru\u00b7der", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Sie wil Dir sich heller zieren,", "tokens": ["Sie", "wil", "Dir", "sich", "hel\u00b7ler", "zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PRF", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Thut der Wolcken Zelt bey Seit,", "tokens": ["Thut", "der", "Wol\u00b7cken", "Zelt", "bey", "Seit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Giebt der Nacht ihr blawes Kleid,", "tokens": ["Giebt", "der", "Nacht", "ihr", "bla\u00b7wes", "Kleid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Heisst die Sternen T\u00e4ntze f\u00fchren,", "tokens": ["Heisst", "die", "Ster\u00b7nen", "T\u00e4nt\u00b7ze", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und des runden Himmels Dach", "tokens": ["Und", "des", "run\u00b7den", "Him\u00b7mels", "Dach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Klar seyn auff den Tag hernach.", "tokens": ["Klar", "seyn", "auff", "den", "Tag", "her\u00b7nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAINF", "APPR", "ART", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Al\u00df es auch darauff mu\u00df tagen,", "tokens": ["Al\u00df", "es", "auch", "dar\u00b7auff", "mu\u00df", "ta\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PAV", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bringt Aurora durch den Ost", "tokens": ["Bringt", "Au\u00b7ro\u00b7ra", "durch", "den", "Ost"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "NE", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Frost, den Stadt- und Felder-Trost,", "tokens": ["Frost", ",", "den", "Stadt", "und", "Fel\u00b7der\u00b7Trost", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "TRUNC", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und sch\u00f6n Wetter mit getragen,", "tokens": ["Und", "sch\u00f6n", "Wet\u00b7ter", "mit", "ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "NN", "APPR", "VVPP", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.5": {"text": "Und macht nochmals so bekant,", "tokens": ["Und", "macht", "noch\u00b7mals", "so", "be\u00b7kant", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Da\u00df Du seyst der Sternen Pfandt.", "tokens": ["Da\u00df", "Du", "seyst", "der", "Ster\u00b7nen", "Pfandt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Dieses thun die Himmels-Liechter.", "tokens": ["Die\u00b7ses", "thun", "die", "Him\u00b7mels\u00b7Liech\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sol nicht Hoff und B\u00fcrgerschafft", "tokens": ["Sol", "nicht", "Hoff", "und", "B\u00fcr\u00b7ger\u00b7schafft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PTKNEG", "VVFIN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Jetzt empfinden newe Krafft?", "tokens": ["Jetzt", "emp\u00b7fin\u00b7den", "ne\u00b7we", "Krafft", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sollen nicht vorau\u00df wir Tichter,", "tokens": ["Sol\u00b7len", "nicht", "vor\u00b7au\u00df", "wir", "Tich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "ADV", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und was lebet in gemein,", "tokens": ["Und", "was", "le\u00b7bet", "in", "ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "APPR", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Uber Dir erfrewet seyn?", "tokens": ["U\u00b7ber", "Dir", "er\u00b7fre\u00b7wet", "seyn", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Gut, da\u00df man im gantzen Lande", "tokens": ["Gut", ",", "da\u00df", "man", "im", "gant\u00b7zen", "Lan\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "KOUS", "PIS", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auff den Cantzeln Gott erhebt,", "tokens": ["Auff", "den", "Cant\u00b7zeln", "Gott", "er\u00b7hebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df Er Dich gesund, belebt,", "tokens": ["Da\u00df", "Er", "Dich", "ge\u00b7sund", ",", "be\u00b7lebt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "$,", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Frewdig und in guttem Stande,", "tokens": ["Frew\u00b7dig", "und", "in", "gut\u00b7tem", "Stan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Eh' ein Mensch noch wird gewar,", "tokens": ["Eh'", "ein", "Mensch", "noch", "wird", "ge\u00b7war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "VAFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Stellt vor unser Augen dar.", "tokens": ["Stellt", "vor", "un\u00b7ser", "Au\u00b7gen", "dar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Es vergr\u00f6ssert unsre Frewde,", "tokens": ["Es", "ver\u00b7gr\u00f6s\u00b7sert", "uns\u00b7re", "Frew\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was so unverhofft entsteht.", "tokens": ["Was", "so", "un\u00b7ver\u00b7hofft", "ent\u00b7steht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil man gantz bek\u00fcmmert geht,", "tokens": ["Weil", "man", "gantz", "be\u00b7k\u00fcm\u00b7mert", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist besorget und in Leide,", "tokens": ["Ist", "be\u00b7sor\u00b7get", "und", "in", "Lei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "KON", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Behtet f\u00fcr Dich spat und fr\u00fce,", "tokens": ["Beh\u00b7tet", "f\u00fcr", "Dich", "spat", "und", "fr\u00fce", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "VVFIN", "KON", "ADJA", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und Dich dort sch\u00e4tzt, bistu hie.", "tokens": ["Und", "Dich", "dort", "sch\u00e4tzt", ",", "bis\u00b7tu", "hie", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "VVFIN", "$,", "ADV", "ADV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Also wenn das Haff besieget", "tokens": ["Al\u00b7so", "wenn", "das", "Haff", "be\u00b7sie\u00b7get"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch den Sturm ein schwaches Boht,", "tokens": ["Durch", "den", "Sturm", "ein", "schwa\u00b7ches", "Boht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und man denn nach langer Noht", "tokens": ["Und", "man", "denn", "nach", "lan\u00b7ger", "Noht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Pl\u00f6tzlich sch\u00f6nes Wetter krieget,", "tokens": ["Pl\u00f6tz\u00b7lich", "sch\u00f6\u00b7nes", "Wet\u00b7ter", "krie\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Doppelt sich die Fr\u00f6licheit,", "tokens": ["Dop\u00b7pelt", "sich", "die", "Fr\u00f6\u00b7lic\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Die so unverhofft erfrewt.", "tokens": ["Die", "so", "un\u00b7ver\u00b7hofft", "er\u00b7frewt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Nichts ist newes bey den Leuten,", "tokens": ["Nichts", "ist", "ne\u00b7wes", "bey", "den", "Leu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADJA", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Herr, als Deine Gegenwart,", "tokens": ["Herr", ",", "als", "Dei\u00b7ne", "Ge\u00b7gen\u00b7wart", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Jederman ist wie bestarrt,", "tokens": ["Je\u00b7der\u00b7man", "ist", "wie", "be\u00b7starrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "KOKOM", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und lesst sich es kaum bedeuten,", "tokens": ["Und", "lesst", "sich", "es", "kaum", "be\u00b7deu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PPER", "ADV", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Wie Dein Auffbruch sey geschehn,", "tokens": ["Wie", "Dein", "Auff\u00b7bruch", "sey", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df sich Sein kein Mensch versehn.", "tokens": ["Da\u00df", "sich", "Sein", "kein", "Mensch", "ver\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PPOSAT", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "K\u00f6nte doch Dein Ohr nur dringen", "tokens": ["K\u00f6n\u00b7te", "doch", "Dein", "Ohr", "nur", "drin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "PPOSAT", "NN", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zu den Unterthanen hin,", "tokens": ["Zu", "den", "Un\u00b7ter\u00b7tha\u00b7nen", "hin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Jedes reitzet seinen Sinn", "tokens": ["Je\u00b7des", "reit\u00b7zet", "sei\u00b7nen", "Sinn"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dich zu sagen, dich zu singen,", "tokens": ["Dich", "zu", "sa\u00b7gen", ",", "dich", "zu", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Jedes suchet umb und an,", "tokens": ["Je\u00b7des", "su\u00b7chet", "umb", "und", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "KON", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ob es wo Dich sehen kan.", "tokens": ["Ob", "es", "wo", "Dich", "se\u00b7hen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PWAV", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Man vernimpt in diesen Tagen", "tokens": ["Man", "ver\u00b7nimpt", "in", "die\u00b7sen", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nichts durch jedes B\u00fcrger-Hau\u00df", "tokens": ["Nichts", "durch", "je\u00b7des", "B\u00fcr\u00b7ger\u00b7Hau\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "APPR", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Als: Wie sieht Er itzund au\u00df?", "tokens": ["Als", ":", "Wie", "sieht", "Er", "it\u00b7zund", "au\u00df", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$.", "PWAV", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Diesen die\u00df, den jenes fragen,", "tokens": ["Die\u00b7sen", "die\u00df", ",", "den", "je\u00b7nes", "fra\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDAT", "PDS", "$,", "PRELS", "PDS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Aller Sorge Trost und Rhue", "tokens": ["Al\u00b7ler", "Sor\u00b7ge", "Trost", "und", "Rhue"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "NN", "KON", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und Ergetzlicheit bist du.", "tokens": ["Und", "Er\u00b7getz\u00b7li\u00b7cheit", "bist", "du", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Welcher denn Bescheid kan geben,", "tokens": ["Wel\u00b7cher", "denn", "Be\u00b7scheid", "kan", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "KON", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der wei\u00df die Gestalt an Dir,", "tokens": ["Der", "wei\u00df", "die", "Ge\u00b7stalt", "an", "Dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "APPR", "PPER", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Huld, Verstand und alle Zier", "tokens": ["Huld", ",", "Ver\u00b7stand", "und", "al\u00b7le", "Zier"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "NN", "KON", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht nach Gn\u00fcge zu erheben,", "tokens": ["Nicht", "nach", "Gn\u00fc\u00b7ge", "zu", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da ist Frewde, Lieb und Prei\u00df,", "tokens": ["Da", "ist", "Frew\u00b7de", ",", "Lieb", "und", "Prei\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und was man zu dencken wei\u00df.", "tokens": ["Und", "was", "man", "zu", "den\u00b7cken", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Herr, vermehr in uns die Wonne,", "tokens": ["Herr", ",", "ver\u00b7mehr", "in", "uns", "die", "Won\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "APPR", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nicht entzeuch dem Volcke dich,", "tokens": ["Nicht", "ent\u00b7zeuch", "dem", "Vol\u00b7cke", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00df dich schawen \u00f6ffentlich,", "tokens": ["La\u00df", "dich", "scha\u00b7wen", "\u00f6f\u00b7fent\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVFIN", "ADJD", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Denn du bist des Landes Sonne.", "tokens": ["Denn", "du", "bist", "des", "Lan\u00b7des", "Son\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Weil man Gott nicht sehen kan,", "tokens": ["Weil", "man", "Gott", "nicht", "se\u00b7hen", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sieht man Dich, sein Bild, gern an.", "tokens": ["Sieht", "man", "Dich", ",", "sein", "Bild", ",", "gern", "an", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "$,", "PPOSAT", "NN", "$,", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Stell' ich mich auch bey den Hauffen,", "tokens": ["Stell'", "ich", "mich", "auch", "bey", "den", "Hauf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PRF", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mich, den sonst Geringsten hier,", "tokens": ["Mich", ",", "den", "sonst", "Ge\u00b7rings\u00b7ten", "hier", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "ADV", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ey ich wei\u00df, da\u00df keiner mir", "tokens": ["Ey", "ich", "wei\u00df", ",", "da\u00df", "kei\u00b7ner", "mir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "VVFIN", "$,", "KOUS", "PIS", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Diesen Vortrab ab soll lauffen,", "tokens": ["Die\u00b7sen", "Vor\u00b7trab", "ab", "soll", "lauf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "PTKVZ", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df durch Lieb und Andacht-Schein", "tokens": ["Da\u00df", "durch", "Lieb", "und", "An\u00b7dacht\u00b7Schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ich nicht hie solt' Erster seyn.", "tokens": ["Ich", "nicht", "hie", "solt'", "Ers\u00b7ter", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "PIAT", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Andre bringen andre Sachen,", "tokens": ["And\u00b7re", "brin\u00b7gen", "and\u00b7re", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVINF", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Warumb sie Dir hold sind, bey,", "tokens": ["Wa\u00b7rumb", "sie", "Dir", "hold", "sind", ",", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADJD", "VAFIN", "$,", "APPR", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Meine Schuldigkeit und Trew", "tokens": ["Mei\u00b7ne", "Schul\u00b7dig\u00b7keit", "und", "Trew"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wei\u00df vorau\u00df sich gro\u00df zu machen,", "tokens": ["Wei\u00df", "vor\u00b7au\u00df", "sich", "gro\u00df", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Weil Du mehr bey mir gethan,", "tokens": ["Weil", "Du", "mehr", "bey", "mir", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PPER", "VVPP", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.6": {"text": "Als sich ein Mensch r\u00fchmen kan.", "tokens": ["Als", "sich", "ein", "Mensch", "r\u00fch\u00b7men", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Preussen hat mich erst gebohren,", "tokens": ["Preus\u00b7sen", "hat", "mich", "erst", "ge\u00b7boh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dein Herr Vater nachmals hie", "tokens": ["Dein", "Herr", "Va\u00b7ter", "nach\u00b7mals", "hie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "NN", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "In der Edlen Poesie", "tokens": ["In", "der", "Ed\u00b7len", "Poe\u00b7sie"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Ihm zum Diener selbs erkohren,", "tokens": ["Ihm", "zum", "Die\u00b7ner", "selbs", "er\u00b7koh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df ich ferner Brodt und Rhue", "tokens": ["Da\u00df", "ich", "fer\u00b7ner", "Brodt", "und", "Rhue"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "NN", "KON", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Finde, schaffen Gott und Du.", "tokens": ["Fin\u00b7de", ",", "schaf\u00b7fen", "Gott", "und", "Du", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "NN", "KON", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Leute, welche mehr begehren,", "tokens": ["Leu\u00b7te", ",", "wel\u00b7che", "mehr", "be\u00b7geh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Als die\u00df kurtze Leben wil,", "tokens": ["Als", "die\u00df", "kurt\u00b7ze", "Le\u00b7ben", "wil", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ADJA", "NN", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "D\u00fcncket die\u00df vieleicht nicht viel,", "tokens": ["D\u00fcn\u00b7cket", "die\u00df", "vie\u00b7leicht", "nicht", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "ADV", "PTKNEG", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ich, dem gn\u00fcgt, sich ehrlich nehren,", "tokens": ["Ich", ",", "dem", "gn\u00fcgt", ",", "sich", "ehr\u00b7lich", "neh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "VVFIN", "$,", "PRF", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und dabey ein freyer Muth,", "tokens": ["Und", "da\u00b7bey", "ein", "frey\u00b7er", "Muth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "ART", "ADJA", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.6": {"text": "Halt' es f\u00fcr ein F\u00fcrsten-gut.", "tokens": ["Halt'", "es", "f\u00fcr", "ein", "F\u00fcrs\u00b7ten\u00b7gut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Dieses und viel andre Dinge,", "tokens": ["Die\u00b7ses", "und", "viel", "and\u00b7re", "Din\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "KON", "PIAT", "ADJA", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Da\u00df Du bist der Helden Liecht,", "tokens": ["Da\u00df", "Du", "bist", "der", "Hel\u00b7den", "Liecht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Deiner L\u00e4nder Zuversicht,", "tokens": ["Dei\u00b7ner", "L\u00e4n\u00b7der", "Zu\u00b7ver\u00b7sicht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Macht, da\u00df ich erfrewlich singe,", "tokens": ["Macht", ",", "da\u00df", "ich", "er\u00b7frew\u00b7lich", "sin\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und mir deiner Ankunfft Schein", "tokens": ["Und", "mir", "dei\u00b7ner", "An\u00b7kunfft", "Schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Lasse hoch und heilig seyn.", "tokens": ["Las\u00b7se", "hoch", "und", "hei\u00b7lig", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Herr, Du bist ein Trost der Zeiten,", "tokens": ["Herr", ",", "Du", "bist", "ein", "Trost", "der", "Zei\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsrer letzten Hoffnung Grund,", "tokens": ["Uns\u00b7rer", "letz\u00b7ten", "Hoff\u00b7nung", "Grund", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Du erh\u00e4ltst den Friedens-bund,", "tokens": ["Du", "er\u00b7h\u00e4ltst", "den", "Frie\u00b7dens\u00b7bund", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ausser Dir ist Angst und Streiten,", "tokens": ["Aus\u00b7ser", "Dir", "ist", "Angst", "und", "Strei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist Gefahr und h\u00f6chste Noht", "tokens": ["Ist", "Ge\u00b7fahr", "und", "h\u00f6chs\u00b7te", "Noht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "KON", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und ein tausentfacher Todt.", "tokens": ["Und", "ein", "tau\u00b7sent\u00b7fa\u00b7cher", "Todt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Nicht f\u00fcr deine Wolfahrt behten,", "tokens": ["Nicht", "f\u00fcr", "dei\u00b7ne", "Wol\u00b7fahrt", "beh\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist seyn aller Bo\u00dfheit Freund,", "tokens": ["Ist", "seyn", "al\u00b7ler", "Bo\u00df\u00b7heit", "Freund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "PIAT", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aller Rhue und Liebe Feind,", "tokens": ["Al\u00b7ler", "Rhue", "und", "Lie\u00b7be", "Feind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist die Tugend untertreten,", "tokens": ["Ist", "die", "Tu\u00b7gend", "un\u00b7ter\u00b7tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und an Barbarey und Wust", "tokens": ["Und", "an", "Bar\u00b7ba\u00b7rey", "und", "Wust"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "KON", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.6": {"text": "Haben seine beste Lust.", "tokens": ["Ha\u00b7ben", "sei\u00b7ne", "bes\u00b7te", "Lust", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Lieber hielt ich mich verlohren", "tokens": ["Lie\u00b7ber", "hielt", "ich", "mich", "ver\u00b7loh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Umb den schnellen Nilus-Flu\u00df,", "tokens": ["Umb", "den", "schnel\u00b7len", "Ni\u00b7lus\u00b7Flu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Oder umb den Caucasus,", "tokens": ["O\u00b7der", "umb", "den", "Cau\u00b7ca\u00b7sus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Oder lebte bey den Mohren,", "tokens": ["O\u00b7der", "leb\u00b7te", "bey", "den", "Moh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Als ohn deines Lebens Standt", "tokens": ["Als", "ohn", "dei\u00b7nes", "Le\u00b7bens", "Standt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Noch bewohnen Preussenlandt.", "tokens": ["Noch", "be\u00b7woh\u00b7nen", "Preus\u00b7sen\u00b7landt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Und die strenge Winter-Reyse", "tokens": ["Und", "die", "stren\u00b7ge", "Win\u00b7ter\u00b7Rey\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sol Dir drewen Noht und Zwangk?", "tokens": ["Sol", "Dir", "dre\u00b7wen", "Noht", "und", "Zwangk", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "CARD", "NN", "KON", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Und der starcken Weichsel Gangk", "tokens": ["Und", "der", "star\u00b7cken", "Weich\u00b7sel", "Gangk"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Sorglich seyn mit schwachem Eyse?", "tokens": ["Sorg\u00b7lich", "seyn", "mit", "schwa\u00b7chem", "Ey\u00b7se", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAINF", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nein, der Himmel h\u00e4lt Dir Schutz", "tokens": ["Nein", ",", "der", "Him\u00b7mel", "h\u00e4lt", "Dir", "Schutz"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ART", "NN", "VVFIN", "PPER", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wieder alles Wetters Trutz.", "tokens": ["Wie\u00b7der", "al\u00b7les", "Wet\u00b7ters", "Trutz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "La\u00df das \u00e4rgste Leid ergrimmen,", "tokens": ["La\u00df", "das", "\u00e4rgs\u00b7te", "Leid", "er\u00b7grim\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "La\u00df Neid, Unmuth, Zorn und Ha\u00df,", "tokens": ["La\u00df", "Neid", ",", "Un\u00b7muth", ",", "Zorn", "und", "Ha\u00df", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zeit und Noht ohn alle Ma\u00df", "tokens": ["Zeit", "und", "Noht", "ohn", "al\u00b7le", "Ma\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wieder dich zusammen stimmen,", "tokens": ["Wie\u00b7der", "dich", "zu\u00b7sam\u00b7men", "stim\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Das Gebeth der frommen Welt", "tokens": ["Das", "Ge\u00b7beth", "der", "from\u00b7men", "Welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist was Dich gefahrloh\u00df helt.", "tokens": ["Ist", "was", "Dich", "ge\u00b7fahr\u00b7loh\u00df", "helt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PWS", "PPER", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Nur eyl nicht so bald von hinnen,", "tokens": ["Nur", "eyl", "nicht", "so", "bald", "von", "hin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PTKNEG", "ADV", "ADV", "APPR", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Es erhole sich dein Sinn,", "tokens": ["Es", "er\u00b7ho\u00b7le", "sich", "dein", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df der Schweden K\u00f6niginn,", "tokens": ["Da\u00df", "der", "Schwe\u00b7den", "K\u00f6\u00b7ni\u00b7ginn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die Pfaltz- und Marg-Gr\u00e4ffinnen,", "tokens": ["Und", "die", "Pfaltz", "und", "Mar\u00b7gGr\u00e4f\u00b7fin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "TRUNC", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "S\u00e4mptlich, Chur F\u00fcrst, dein Gebl\u00fct,", "tokens": ["S\u00e4mpt\u00b7lich", ",", "Chur", "F\u00fcrst", ",", "dein", "Ge\u00b7bl\u00fct", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "NN", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "An Dir laben jhr Gem\u00fcht.", "tokens": ["An", "Dir", "la\u00b7ben", "jhr", "Ge\u00b7m\u00fcht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Nimm Dein F\u00fcrstliches Ergetzen", "tokens": ["Nimm", "Dein", "F\u00fcrst\u00b7li\u00b7ches", "Er\u00b7get\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "PPOSAT", "ADJA", "NN"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.2": {"text": "Auff der wilden B\u00e4hren-Jagt,", "tokens": ["Auff", "der", "wil\u00b7den", "B\u00e4h\u00b7ren\u00b7Jagt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Such die Sorg und was Dich plagt", "tokens": ["Such", "die", "Sorg", "und", "was", "Dich", "plagt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "ART", "NN", "KON", "PWS", "PPER", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Zu vertreiben durch das Hetzen,", "tokens": ["Zu", "ver\u00b7trei\u00b7ben", "durch", "das", "Het\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Schaw, Diana r\u00fcstet sich,", "tokens": ["Schaw", ",", "Di\u00b7a\u00b7na", "r\u00fcs\u00b7tet", "sich", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NE", "VVFIN", "PRF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und lockt in die W\u00e4lder Dich.", "tokens": ["Und", "lockt", "in", "die", "W\u00e4l\u00b7der", "Dich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PPER", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.28": {"line.1": {"text": "Ross' und Hunde wollen eilen,", "tokens": ["Ross'", "und", "Hun\u00b7de", "wol\u00b7len", "ei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VMFIN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Phoebus selbs, der J\u00e4ger F\u00fcrst,", "tokens": ["Phoe\u00b7bus", "selbs", ",", "der", "J\u00e4\u00b7ger", "F\u00fcrst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mercket, wenn Du auff seyn wirst,", "tokens": ["Mer\u00b7cket", ",", "wenn", "Du", "auff", "seyn", "wirst", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "APPR", "VAINF", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wartet mit Gescho\u00df und Pfeilen,", "tokens": ["War\u00b7tet", "mit", "Ge\u00b7scho\u00df", "und", "Pfei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wil Dich leiten \u00fcberall", "tokens": ["Wil", "Dich", "lei\u00b7ten", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "VVFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Durch Gep\u00fcsch, Gebirg und Thal.", "tokens": ["Durch", "Ge\u00b7p\u00fcsch", ",", "Ge\u00b7birg", "und", "Thal", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Wann die liebe Sonn' indessen", "tokens": ["Wann", "die", "lie\u00b7be", "Sonn'", "in\u00b7des\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich dem Norden n\u00e4her dringt,", "tokens": ["Sich", "dem", "Nor\u00b7den", "n\u00e4\u00b7her", "dringt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und das sch\u00f6ne Vorjahr bringt,", "tokens": ["Und", "das", "sch\u00f6\u00b7ne", "Vor\u00b7jahr", "bringt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df der K\u00e4lte wird vergessen,", "tokens": ["Da\u00df", "der", "K\u00e4l\u00b7te", "wird", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Haff und Pregel offen sind,", "tokens": ["Haff", "und", "Pre\u00b7gel", "of\u00b7fen", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und der Wald sein Haar gewinnt,", "tokens": ["Und", "der", "Wald", "sein", "Haar", "ge\u00b7winnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.30": {"line.1": {"text": "Wird sich auch Dein Gartt' erheben", "tokens": ["Wird", "sich", "auch", "Dein", "Gartt'", "er\u00b7he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PRF", "ADV", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit geferbter Blumen Zier", "tokens": ["Mit", "ge\u00b7ferb\u00b7ter", "Blu\u00b7men", "Zier"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mit Kr\u00e4utern da und hier,", "tokens": ["Und", "mit", "Kr\u00e4u\u00b7tern", "da", "und", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADV", "KON", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und dir schencken newes Leben.", "tokens": ["Und", "dir", "schen\u00b7cken", "ne\u00b7wes", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJA", "NN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.5": {"text": "Nimm, was dir der Himmel giebt,", "tokens": ["Nimm", ",", "was", "dir", "der", "Him\u00b7mel", "giebt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Zeitig gnug k\u00f6mpt was betr\u00fcbt.", "tokens": ["Zei\u00b7tig", "gnug", "k\u00f6mpt", "was", "be\u00b7tr\u00fcbt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "VVFIN", "PIS", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}