{"textgrid.poem.49689": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "R\u00fchmlicher Tod", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Kennt ihr alle die Geschichte", "tokens": ["Kennt", "ihr", "al\u00b7le", "die", "Ge\u00b7schich\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PIS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von Johannes Ilzebiel,", "tokens": ["Von", "Jo\u00b7han\u00b7nes", "Il\u00b7ze\u00b7biel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dessen Leben ward zunichte,", "tokens": ["Des\u00b7sen", "Le\u00b7ben", "ward", "zu\u00b7nich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als er im Duelle fiel?", "tokens": ["Als", "er", "im", "Du\u00b7el\u00b7le", "fiel", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Halle hie\u00df die Bildungsst\u00e4tte,", "tokens": ["Hal\u00b7le", "hie\u00df", "die", "Bil\u00b7dungs\u00b7st\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sein Beruf war Medizin,", "tokens": ["Sein", "Be\u00b7ruf", "war", "Me\u00b7di\u00b7zin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ohne da\u00df er jemals h\u00e4tte", "tokens": ["Oh\u00b7ne", "da\u00df", "er", "je\u00b7mals", "h\u00e4t\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "PPER", "ADV", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wirklich sich bem\u00fcht darin.", "tokens": ["Wirk\u00b7lich", "sich", "be\u00b7m\u00fcht", "da\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "VVFIN", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Seine Eltern waren Bauern", "tokens": ["Sei\u00b7ne", "El\u00b7tern", "wa\u00b7ren", "Bau\u00b7ern"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit Verm\u00f6gen \u2013 Gott sei Dank! \u2013,", "tokens": ["Mit", "Ver\u00b7m\u00f6\u00b7gen", "\u2013", "Gott", "sei", "Dank", "!", "\u2013", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "NN", "$(", "NN", "VAFIN", "NN", "$.", "$(", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Jeder mu\u00df sie heut bedauern,", "tokens": ["Je\u00b7der", "mu\u00df", "sie", "heut", "be\u00b7dau\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Weil der Sohn das Geld vertrank.", "tokens": ["Weil", "der", "Sohn", "das", "Geld", "ver\u00b7trank", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Als aus Kasten und aus Kisten", "tokens": ["Als", "aus", "Kas\u00b7ten", "und", "aus", "Kis\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NN", "KON", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nirgends mehr kein Kreuzer fiel,", "tokens": ["Nir\u00b7gends", "mehr", "kein", "Kreu\u00b7zer", "fiel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Fing die Not sich einzunisten", "tokens": ["Fing", "die", "Not", "sich", "ein\u00b7zu\u00b7nis\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "An bei Johann Ilzebiel.", "tokens": ["An", "bei", "Jo\u00b7hann", "Il\u00b7ze\u00b7biel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "NE", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Und es kam bei ihm zutage,", "tokens": ["Und", "es", "kam", "bei", "ihm", "zu\u00b7ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df er nicht die Arbeit kennt.", "tokens": ["Da\u00df", "er", "nicht", "die", "Ar\u00b7beit", "kennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieses stand auch au\u00dfer Frage,", "tokens": ["Die\u00b7ses", "stand", "auch", "au\u00b7\u00dfer", "Fra\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn er war ein Korpsstudent.", "tokens": ["Denn", "er", "war", "ein", "Korps\u00b7stu\u00b7dent", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Soll er selbst den Rest sich geben?", "tokens": ["Soll", "er", "selbst", "den", "Rest", "sich", "ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ART", "NN", "PRF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nein! Nur das Proletentum", "tokens": ["Nein", "!", "Nur", "das", "Pro\u00b7le\u00b7ten\u00b7tum"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$.", "ADV", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dr\u00fcckt sich schweigend aus dem Leben.", "tokens": ["Dr\u00fcckt", "sich", "schwei\u00b7gend", "aus", "dem", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Er begehrte andern Ruhm.", "tokens": ["Er", "be\u00b7gehr\u00b7te", "an\u00b7dern", "Ruhm", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Als zu sterben er entschlossen,", "tokens": ["Als", "zu", "ster\u00b7ben", "er", "ent\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKZU", "VVFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schlug er jeden auf das Ohr.", "tokens": ["Schlug", "er", "je\u00b7den", "auf", "das", "Ohr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zweie hat er selbst erschossen,", "tokens": ["Zwei\u00b7e", "hat", "er", "selbst", "er\u00b7schos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Erst der dritte kam zuvor.", "tokens": ["Erst", "der", "drit\u00b7te", "kam", "zu\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}