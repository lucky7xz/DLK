{"textgrid.poem.63656": {"metadata": {"author": {"name": "Heyse, Paul", "birth": "N.A.", "death": "N.A."}, "title": "Der verlorne Sohn", "genre": "verse", "period": "N.A.", "pub_year": 1872, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Schon elf \u2013 und er noch immer nicht zu Haus! \u2013", "tokens": ["Schon", "elf", "\u2013", "und", "er", "noch", "im\u00b7mer", "nicht", "zu", "Haus", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "CARD", "$(", "KON", "PPER", "ADV", "ADV", "PTKNEG", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u2013 Ei nun, gewi\u00df auf Liebesabenteuer,", "tokens": ["\u2013", "Ei", "nun", ",", "ge\u00b7wi\u00df", "auf", "Lie\u00b7be\u00b7sa\u00b7bent\u00b7eu\u00b7er", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NN", "ADV", "$,", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie er gewohnt ist, ging der Schlingel aus.", "tokens": ["Wie", "er", "ge\u00b7wohnt", "ist", ",", "ging", "der", "Schlin\u00b7gel", "aus", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVPP", "VAFIN", "$,", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Doch sorge nicht; sein jugendliches Feuer", "tokens": ["Doch", "sor\u00b7ge", "nicht", ";", "sein", "ju\u00b7gend\u00b7li\u00b7ches", "Feu\u00b7er"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "PTKNEG", "$.", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "H\u00e4lt ihn wohl warm, und daf\u00fcr will ich stehn,", "tokens": ["H\u00e4lt", "ihn", "wohl", "warm", ",", "und", "da\u00b7f\u00fcr", "will", "ich", "stehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "$,", "KON", "PAV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "All deiner \u00c4ngste lacht das Ungeheuer.", "tokens": ["All", "dei\u00b7ner", "\u00c4ngs\u00b7te", "lacht", "das", "Un\u00b7ge\u00b7heu\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Wir aber sollten endlich schlafen gehn. \u2013", "tokens": ["Wir", "a\u00b7ber", "soll\u00b7ten", "end\u00b7lich", "schla\u00b7fen", "gehn", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "ADV", "VMFIN", "ADV", "VVINF", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u2013 Wie? schlafen? Nein, kein Auge k\u00f6nnt' ich schlie\u00dfen,", "tokens": ["\u2013", "Wie", "?", "schla\u00b7fen", "?", "Nein", ",", "kein", "Au\u00b7ge", "k\u00f6nnt'", "ich", "schlie\u00b7\u00dfen", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "$.", "VVINF", "$.", "PTKANT", "$,", "PIAT", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Bevor ich sicher ihn zu Haus gesehn.", "tokens": ["Be\u00b7vor", "ich", "si\u00b7cher", "ihn", "zu", "Haus", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Doch da\u00df er mich so \u00e4ngstigt, soll er b\u00fc\u00dfen.", "tokens": ["Doch", "da\u00df", "er", "mich", "so", "\u00e4ngs\u00b7tigt", ",", "soll", "er", "b\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "ADV", "VVFIN", "$,", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Er treibt's zu toll! Dies Streunen auf den Gassen", "tokens": ["Er", "treibt's", "zu", "toll", "!", "Dies", "Streu\u00b7nen", "auf", "den", "Gas\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKA", "ADJD", "$.", "PDS", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wird er sich endlich abgew\u00f6hnen m\u00fcssen.", "tokens": ["Wird", "er", "sich", "end\u00b7lich", "ab\u00b7ge\u00b7w\u00f6h\u00b7nen", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ADV", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Nur \u2013 vor verschlo\u00dfnem Haus ihn stehn zu lassen", "tokens": ["Nur", "\u2013", "vor", "ver\u00b7schlo\u00df\u00b7nem", "Haus", "ihn", "stehn", "zu", "las\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$(", "APPR", "ADJA", "NN", "PPER", "VVINF", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "In eis'ger Nacht, w\u00e4r' allzu grausam, mehr", "tokens": ["In", "eis'\u00b7ger", "Nacht", ",", "w\u00e4r'", "all\u00b7zu", "grau\u00b7sam", ",", "mehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "VAFIN", "PTKA", "ADJD", "$,", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Als er verdient. Drum will ich auf ihn passen.", "tokens": ["Als", "er", "ver\u00b7dient", ".", "Drum", "will", "ich", "auf", "ihn", "pas\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "$.", "PAV", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Geh du zu Bett! \u2013", "tokens": ["Geh", "du", "zu", "Bett", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "PPER", "APPR", "NN", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "\u2013 Nun bei den G\u00f6ttern, wer", "tokens": ["\u2013", "Nun", "bei", "den", "G\u00f6t\u00b7tern", ",", "wer"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word"], "pos": ["$(", "ADV", "APPR", "ART", "NN", "$,", "PWS"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Verd\u00e4chte mir's, wenn ich, dein teurer Gatte,", "tokens": ["Ver\u00b7d\u00e4ch\u00b7te", "mir's", ",", "wenn", "ich", ",", "dein", "teu\u00b7rer", "Gat\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$,", "KOUS", "PPER", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Auf diesen Hausfreund eifers\u00fcchtig w\u00e4r'?", "tokens": ["Auf", "die\u00b7sen", "Haus\u00b7freund", "ei\u00b7fer\u00b7s\u00fcch\u00b7tig", "w\u00e4r'", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Auf meine Tugend zwar fiel nie ein Schatte,", "tokens": ["Auf", "mei\u00b7ne", "Tu\u00b7gend", "zwar", "fiel", "nie", "ein", "Schat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Drum bist du ruhig stets zu Bett gegangen,", "tokens": ["Drum", "bist", "du", "ru\u00b7hig", "stets", "zu", "Bett", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADJD", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Auch wenn ich nachts mich mal versp\u00e4tet hatte. \u2013", "tokens": ["Auch", "wenn", "ich", "nachts", "mich", "mal", "ver\u00b7sp\u00e4\u00b7tet", "hat\u00b7te", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "KOUS", "PPER", "APPR", "PPER", "ADV", "VVPP", "VAFIN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "\u2013 Ja, aber schlief ich dann? Horcht' ich mit Bangen", "tokens": ["\u2013", "Ja", ",", "a\u00b7ber", "schlief", "ich", "dann", "?", "Horcht'", "ich", "mit", "Ban\u00b7gen"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PTKANT", "$,", "ADV", "VVFIN", "PPER", "ADV", "$.", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nicht stets hinaus, unruhig und beklommen,", "tokens": ["Nicht", "stets", "hin\u00b7aus", ",", "un\u00b7ru\u00b7hig", "und", "be\u00b7klom\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PTKVZ", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Bis dann die wohlbekannten Schritte klangen?", "tokens": ["Bis", "dann", "die", "wohl\u00b7be\u00b7kann\u00b7ten", "Schrit\u00b7te", "klan\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Du hattst ja auch den Schl\u00fcssel mitgenommen,", "tokens": ["Du", "hattst", "ja", "auch", "den", "Schl\u00fcs\u00b7sel", "mit\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Indessen er \u2013 doch still! T\u00e4uscht mich mein Ohr?", "tokens": ["In\u00b7des\u00b7sen", "er", "\u2013", "doch", "still", "!", "T\u00e4uscht", "mich", "mein", "Ohr", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "ADV", "PTKVZ", "$.", "NN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u2013 Ich h\u00f6re nichts. \u2013 Doch, doch! Ich h\u00f6r' ihn kommen.", "tokens": ["\u2013", "Ich", "h\u00f6\u00b7re", "nichts", ".", "\u2013", "Doch", ",", "doch", "!", "Ich", "h\u00f6r'", "ihn", "kom\u00b7men", "."], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PIS", "$.", "$(", "KON", "$,", "ADV", "$.", "PPER", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Er r\u00fcttelt, h\u00f6rst du nicht? am Gartentor,", "tokens": ["Er", "r\u00fct\u00b7telt", ",", "h\u00f6rst", "du", "nicht", "?", "am", "Gar\u00b7ten\u00b7tor", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PPER", "PTKNEG", "$.", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und jetzt, o sieh, versucht er gar zu schellen", "tokens": ["Und", "jetzt", ",", "o", "sieh", ",", "ver\u00b7sucht", "er", "gar", "zu", "schel\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "FM", "FM", "$,", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und springt und reckt zur Klingel sich empor.", "tokens": ["Und", "springt", "und", "reckt", "zur", "Klin\u00b7gel", "sich", "em\u00b7por", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "ADJD", "APPRART", "NN", "PRF", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Sein schlecht Gewissen h\u00e4lt ihn ab zu bellen.", "tokens": ["Sein", "schlecht", "Ge\u00b7wis\u00b7sen", "h\u00e4lt", "ihn", "ab", "zu", "bel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "VVFIN", "PPER", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nein, armer S\u00fcnder, wer bereut, dem wird", "tokens": ["Nein", ",", "ar\u00b7mer", "S\u00fcn\u00b7der", ",", "wer", "be\u00b7reut", ",", "dem", "wird"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PTKANT", "$,", "ADJA", "NN", "$,", "PWS", "VVFIN", "$,", "PDS", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Gnade vor Recht zuteil. In solchen F\u00e4llen,", "tokens": ["Gna\u00b7de", "vor", "Recht", "zu\u00b7teil", ".", "In", "sol\u00b7chen", "F\u00e4l\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "PTKVZ", "$.", "APPR", "PIAT", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.12": {"line.1": {"text": "Wo unerfahrne Jugend sich verirrt,", "tokens": ["Wo", "un\u00b7er\u00b7fahr\u00b7ne", "Ju\u00b7gend", "sich", "ver\u00b7irrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mu\u00df man mit Liebe sie zu bessern streben.", "tokens": ["Mu\u00df", "man", "mit", "Lie\u00b7be", "sie", "zu", "bes\u00b7sern", "stre\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "APPR", "NN", "PPER", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ich lass' ihn ein. \u2013 \u2013 O sieh nur, wie verwirrt", "tokens": ["Ich", "lass'", "ihn", "ein", ".", "\u2013", "\u2013", "O", "sieh", "nur", ",", "wie", "ver\u00b7wirrt"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$.", "$(", "$(", "NE", "VVFIN", "ADV", "$,", "PWAV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Er n\u00e4herschleicht und meine Knie mit Beben", "tokens": ["Er", "n\u00e4\u00b7her\u00b7schleicht", "und", "mei\u00b7ne", "Knie", "mit", "Be\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "PPOSAT", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Umpfotet und reum\u00fctig mir am Rock", "tokens": ["Um\u00b7pfo\u00b7tet", "und", "reu\u00b7m\u00fc\u00b7tig", "mir", "am", "Rock"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVPP", "KON", "ADJD", "PPER", "APPRART", "NN"], "meter": "-+--++-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Emporstrebt. Nun, so mu\u00df ich wohl vergeben,", "tokens": ["Em\u00b7por\u00b7strebt", ".", "Nun", ",", "so", "mu\u00df", "ich", "wohl", "ver\u00b7ge\u00b7ben", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "ADV", "$,", "ADV", "VMFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Und hungrig wirst du auch sein, armer Flock!", "tokens": ["Und", "hung\u00b7rig", "wirst", "du", "auch", "sein", ",", "ar\u00b7mer", "Flock", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "ADV", "VAINF", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dein Futter steht noch da. \u2013 Was lachst du so?", "tokens": ["Dein", "Fut\u00b7ter", "steht", "noch", "da", ".", "\u2013", "Was", "lachst", "du", "so", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ADV", "$.", "$(", "PWS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nein, wenn ich ihn erz\u00f6ge mit dem Stock,", "tokens": ["Nein", ",", "wenn", "ich", "ihn", "er\u00b7z\u00f6\u00b7ge", "mit", "dem", "Stock", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "PPER", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Verh\u00e4rtet wurde sein Gem\u00fct und roh. \u2013", "tokens": ["Ver\u00b7h\u00e4r\u00b7tet", "wur\u00b7de", "sein", "Ge\u00b7m\u00fct", "und", "roh", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "VAFIN", "PPOSAT", "NN", "KON", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u2013 Gewi\u00df! Sei nur wie alle P\u00e4dagogen", "tokens": ["\u2013", "Ge\u00b7wi\u00df", "!", "Sei", "nur", "wie", "al\u00b7le", "P\u00e4d\u00b7a\u00b7go\u00b7gen"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PTKANT", "$.", "VAFIN", "ADV", "KOKOM", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Inkonsequent. Des aber bin ich froh,", "tokens": ["In\u00b7kon\u00b7se\u00b7quent", ".", "Des", "a\u00b7ber", "bin", "ich", "froh", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ART", "ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Da\u00df du die ", "tokens": ["Da\u00df", "du", "die"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "ART"], "meter": "+--", "measure": "dactylic.init"}}}}}