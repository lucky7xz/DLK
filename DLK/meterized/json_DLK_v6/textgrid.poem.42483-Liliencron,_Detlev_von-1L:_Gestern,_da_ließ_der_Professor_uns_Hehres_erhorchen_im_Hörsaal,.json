{"textgrid.poem.42483": {"metadata": {"author": {"name": "Liliencron, Detlev von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Gestern, da lie\u00df der Professor uns Hehres erhorchen im H\u00f6rsaal,", "genre": "verse", "period": "N.A.", "pub_year": 1876, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gestern, da lie\u00df der Professor uns Hehres erhorchen im H\u00f6rsaal,", "tokens": ["Ge\u00b7stern", ",", "da", "lie\u00df", "der", "Pro\u00b7fes\u00b7sor", "uns", "Heh\u00b7res", "er\u00b7hor\u00b7chen", "im", "H\u00f6r\u00b7saal", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "VVFIN", "ART", "NN", "PPER", "NE", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+--+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sprach von Platon, Homer, k\u00fcndet Apollos Verdienst.", "tokens": ["Sprach", "von", "Pla\u00b7ton", ",", "Ho\u00b7mer", ",", "k\u00fcn\u00b7det", "A\u00b7pol\u00b7los", "Ver\u00b7dienst", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$,", "NE", "$,", "VVFIN", "NE", "NN", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.3": {"text": "Und es troff ihm die Stirn von heiliger Weihe wie Angstschwei\u00df;", "tokens": ["Und", "es", "troff", "ihm", "die", "Stirn", "von", "hei\u00b7li\u00b7ger", "Wei\u00b7he", "wie", "A\u00b7ngstschwei\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ART", "NN", "APPR", "ADJA", "NN", "KOKOM", "NN", "$."], "meter": "--+--+-+--+-+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "\u00bbseht\u00ab, so rief er erhaben, \u00bbdie Griechen, die nenn ich ein Volk noch:", "tokens": ["\u00bb", "seht", "\u00ab", ",", "so", "rief", "er", "er\u00b7ha\u00b7ben", ",", "\u00bb", "die", "Grie\u00b7chen", ",", "die", "nenn", "ich", "ein", "Volk", "noch", ":"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$(", "$,", "ADV", "VVFIN", "PPER", "ADJD", "$,", "$(", "ART", "NN", "$,", "PRELS", "VVFIN", "PPER", "ART", "NN", "ADV", "$."], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.5": {"text": "Herrliche Strenge der Form, g\u00f6ttliches Nasenger\u00fcst.", "tokens": ["Herr\u00b7li\u00b7che", "Stren\u00b7ge", "der", "Form", ",", "g\u00f6tt\u00b7li\u00b7ches", "Na\u00b7sen\u00b7ge\u00b7r\u00fcst", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "$,", "ADJA", "NN", "$."], "meter": "+--+--++--+--+", "measure": "dactylic.di.plus"}, "line.6": {"text": "Nichts war ihnen bekannt von des Nordens barbarischer Roheit;", "tokens": ["Nichts", "war", "ih\u00b7nen", "be\u00b7kannt", "von", "des", "Nor\u00b7dens", "bar\u00b7ba\u00b7ri\u00b7scher", "Ro\u00b7heit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "ADJD", "APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+--+--+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.7": {"text": "Zeus regierte die Welt, flammte vom hohen Olymp.\u00ab", "tokens": ["Zeus", "re\u00b7gier\u00b7te", "die", "Welt", ",", "flamm\u00b7te", "vom", "ho\u00b7hen", "O\u00b7lymp", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$,", "VVFIN", "APPRART", "ADJA", "NN", "$.", "$("], "meter": "+-+--++--+--+", "measure": "trochaic.hexa.relaxed"}, "line.8": {"text": "Ach, mir dampfte das Hirn, ich befand mich im Brodem des W\u00fcstseins;", "tokens": ["Ach", ",", "mir", "dampf\u00b7te", "das", "Hirn", ",", "ich", "be\u00b7fand", "mich", "im", "Bro\u00b7dem", "des", "W\u00fcst\u00b7seins", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "PRF", "APPRART", "NN", "ART", "NN", "$."], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.9": {"text": "Drau\u00dfen der Sommer so klar, sa\u00dfen wir dumpfig im Pferch.", "tokens": ["Drau\u00b7\u00dfen", "der", "Som\u00b7mer", "so", "klar", ",", "sa\u00b7\u00dfen", "wir", "dump\u00b7fig", "im", "Pferch", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "ADJD", "$,", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$."], "meter": "+--+--+---+--+", "measure": "dactylic.tri.plus"}, "line.10": {"text": "Endlich ert\u00f6nte das Zeichen, wir st\u00fcrmten hinaus in die Freiheit;", "tokens": ["End\u00b7lich", "er\u00b7t\u00f6n\u00b7te", "das", "Zei\u00b7chen", ",", "wir", "st\u00fcrm\u00b7ten", "hin\u00b7aus", "in", "die", "Frei\u00b7heit", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.11": {"text": "Dick mit der Mappe beschwert, schleppt ich mein Wissen nach Haus.", "tokens": ["Dick", "mit", "der", "Map\u00b7pe", "be\u00b7schwert", ",", "schleppt", "ich", "mein", "Wis\u00b7sen", "nach", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VVPP", "$,", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "NN", "$."], "meter": "+--+--++--+--+", "measure": "dactylic.di.plus"}, "line.12": {"text": "Dort auf dem Tisch ein Zettel: \u00bbGewartet hab ich vergebens\u00ab", "tokens": ["Dort", "auf", "dem", "Tisch", "ein", "Zet\u00b7tel", ":", "\u00bb", "Ge\u00b7war\u00b7tet", "hab", "ich", "ver\u00b7ge\u00b7bens", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "NN", "$.", "$(", "VVPP", "VAFIN", "PPER", "ADV", "$("], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Sagte mir deutlich genug: Griechenland war nicht bei mir,", "tokens": ["Sag\u00b7te", "mir", "deut\u00b7lich", "ge\u00b7nug", ":", "Grie\u00b7chen\u00b7land", "war", "nicht", "bei", "mir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ADV", "$.", "NE", "VAFIN", "PTKNEG", "APPR", "PPER", "$,"], "meter": "+--+-+-+-+-+-+", "measure": "iambic.septa.invert"}, "line.14": {"text": "Aber Seffinka war da, mit dem h\u00f6chst unklassischen Nasloch \u2013", "tokens": ["A\u00b7ber", "Sef\u00b7fin\u00b7ka", "war", "da", ",", "mit", "dem", "h\u00f6chst", "un\u00b7klas\u00b7si\u00b7schen", "Nas\u00b7loch", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "ADV", "$,", "APPR", "ART", "ADV", "ADJA", "NN", "$("], "meter": "+--+-+-+-+-+-+-+", "measure": "iambic.octa.plus.invert"}, "line.15": {"text": "Und nun ist es zu sp\u00e4t; hol dich der Satanas, Zeus!", "tokens": ["Und", "nun", "ist", "es", "zu", "sp\u00e4t", ";", "hol", "dich", "der", "Sa\u00b7ta\u00b7nas", ",", "Zeus", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PTKA", "ADJD", "$.", "VVFIN", "PRF", "ART", "NN", "$,", "NE", "$."], "meter": "--+--++-+-+-+", "measure": "anapaest.di.plus"}}}}}