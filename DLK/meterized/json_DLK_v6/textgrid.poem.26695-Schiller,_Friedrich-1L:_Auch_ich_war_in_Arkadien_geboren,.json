{"textgrid.poem.26695": {"metadata": {"author": {"name": "Schiller, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Auch ich war in Arkadien geboren,", "genre": "verse", "period": "N.A.", "pub_year": 1782, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Auch ich war in Arkadien geboren,", "tokens": ["Auch", "ich", "war", "in", "Ar\u00b7ka\u00b7di\u00b7en", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "APPR", "NE", "VVPP", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Auch mir hat die Natur", "tokens": ["Auch", "mir", "hat", "die", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VAFIN", "ART", "NN"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "An meiner Wiege Freude zugeschworen,", "tokens": ["An", "mei\u00b7ner", "Wie\u00b7ge", "Freu\u00b7de", "zu\u00b7ge\u00b7schwo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Auch ich war in Arkadien geboren,", "tokens": ["Auch", "ich", "war", "in", "Ar\u00b7ka\u00b7di\u00b7en", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "APPR", "NE", "VVPP", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Doch Tr\u00e4nen gab der kurze Lenz mir nur.", "tokens": ["Doch", "Tr\u00e4\u00b7nen", "gab", "der", "kur\u00b7ze", "Lenz", "mir", "nur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ART", "ADJA", "NN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Des Lebens Mai bl\u00fcht einmal und nicht wieder,", "tokens": ["Des", "Le\u00b7bens", "Mai", "bl\u00fcht", "ein\u00b7mal", "und", "nicht", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "ADV", "KON", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mir hat er abgebl\u00fcht.", "tokens": ["Mir", "hat", "er", "ab\u00b7ge\u00b7bl\u00fcht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der stille Gott \u2013 o weinet, meine Br\u00fcder \u2013", "tokens": ["Der", "stil\u00b7le", "Gott", "\u2013", "o", "wei\u00b7net", ",", "mei\u00b7ne", "Br\u00fc\u00b7der", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "FM", "VVFIN", "$,", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der stille Gott taucht meine Fackel nieder,", "tokens": ["Der", "stil\u00b7le", "Gott", "taucht", "mei\u00b7ne", "Fa\u00b7ckel", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und die Erscheinung flieht.", "tokens": ["Und", "die", "Er\u00b7schei\u00b7nung", "flieht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Da steh ich schon auf deiner Schauerbr\u00fccke,", "tokens": ["Da", "steh", "ich", "schon", "auf", "dei\u00b7ner", "Schau\u00b7er\u00b7br\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ehrw\u00fcrdge Geistermutter \u2013 Ewigkeit.", "tokens": ["Ehr\u00b7w\u00fcrd\u00b7ge", "Geis\u00b7ter\u00b7mut\u00b7ter", "\u2013", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$(", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Empfange meinen Vollmachtbrief zum Gl\u00fccke,", "tokens": ["Emp\u00b7fan\u00b7ge", "mei\u00b7nen", "Voll\u00b7macht\u00b7brief", "zum", "Gl\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ich bring ihn unerbrochen dir zur\u00fccke,", "tokens": ["Ich", "bring", "ihn", "un\u00b7er\u00b7bro\u00b7chen", "dir", "zu\u00b7r\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJA", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Mein Lauf ist aus. Ich wei\u00df von keiner Seligkeit.", "tokens": ["Mein", "Lauf", "ist", "aus", ".", "Ich", "wei\u00df", "von", "kei\u00b7ner", "Se\u00b7lig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKVZ", "$.", "PPER", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Vor deinem Thron erheb ich meine Klage,", "tokens": ["Vor", "dei\u00b7nem", "Thron", "er\u00b7heb", "ich", "mei\u00b7ne", "Kla\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Verh\u00fcllte Richterin.", "tokens": ["Ver\u00b7h\u00fcll\u00b7te", "Rich\u00b7te\u00b7rin", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Auf jenem Stern ging eine frohe Sage,", "tokens": ["Auf", "je\u00b7nem", "Stern", "ging", "ei\u00b7ne", "fro\u00b7he", "Sa\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Du thronest hier mit des Gerichtes Waage", "tokens": ["Du", "thro\u00b7nest", "hier", "mit", "des", "Ge\u00b7rich\u00b7tes", "Waa\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Und nennest dich Vergelterin.", "tokens": ["Und", "nen\u00b7nest", "dich", "Ver\u00b7gel\u00b7te\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Hier \u2013 spricht man \u2013 warten Schrecken auf den B\u00f6sen,", "tokens": ["Hier", "\u2013", "spricht", "man", "\u2013", "war\u00b7ten", "Schre\u00b7cken", "auf", "den", "B\u00f6\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "VVFIN", "PIS", "$(", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und Freuden auf den Redlichen.", "tokens": ["Und", "Freu\u00b7den", "auf", "den", "Red\u00b7li\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des Herzens Kr\u00fcmmen werdest du entbl\u00f6\u00dfen,", "tokens": ["Des", "Her\u00b7zens", "Kr\u00fcm\u00b7men", "wer\u00b7dest", "du", "ent\u00b7bl\u00f6\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Vorsicht R\u00e4tsel werdest du mir l\u00f6sen", "tokens": ["Der", "Vor\u00b7sicht", "R\u00e4t\u00b7sel", "wer\u00b7dest", "du", "mir", "l\u00f6\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VAFIN", "PPER", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und Rechnung halten mit dem Leidenden.", "tokens": ["Und", "Rech\u00b7nung", "hal\u00b7ten", "mit", "dem", "Lei\u00b7den\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Hier \u00f6ffne sich die Heimat dem Verbannten,", "tokens": ["Hier", "\u00f6ff\u00b7ne", "sich", "die", "Hei\u00b7mat", "dem", "Ver\u00b7bann\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Hier endige des Dulders Dornenbahn.", "tokens": ["Hier", "en\u00b7di\u00b7ge", "des", "Dul\u00b7ders", "Dor\u00b7nen\u00b7bahn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein G\u00f6tterkind, das sie mir ", "tokens": ["Ein", "G\u00f6t\u00b7ter\u00b7kind", ",", "das", "sie", "mir"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PPER"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Die meisten flohen, wenige nur kannten,", "tokens": ["Die", "meis\u00b7ten", "flo\u00b7hen", ",", "we\u00b7ni\u00b7ge", "nur", "kann\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$,", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Hielt meines Lebens raschen Z\u00fcgel an.", "tokens": ["Hielt", "mei\u00b7nes", "Le\u00b7bens", "ra\u00b7schen", "Z\u00fc\u00b7gel", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "\u00bbich zahle dir in einem andern Leben,", "tokens": ["\u00bb", "ich", "zah\u00b7le", "dir", "in", "ei\u00b7nem", "an\u00b7dern", "Le\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gib deine Jugend mir!", "tokens": ["Gib", "dei\u00b7ne", "Ju\u00b7gend", "mir", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Nichts kann ich dir als diese Weisung geben.\u00ab", "tokens": ["Nichts", "kann", "ich", "dir", "als", "die\u00b7se", "Wei\u00b7sung", "ge\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "VMFIN", "PPER", "PPER", "KOUS", "PDAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ich nahm die Weisung auf das andre Leben,", "tokens": ["Ich", "nahm", "die", "Wei\u00b7sung", "auf", "das", "and\u00b7re", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und meiner Jugend Freuden gab ich ihr.", "tokens": ["Und", "mei\u00b7ner", "Ju\u00b7gend", "Freu\u00b7den", "gab", "ich", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "\u00bbgib mir das Weib, so teuer deinem Herzen,", "tokens": ["\u00bb", "gib", "mir", "das", "Weib", ",", "so", "teu\u00b7er", "dei\u00b7nem", "Her\u00b7zen", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "ART", "NN", "$,", "ADV", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gib deine Laura mir.", "tokens": ["Gib", "dei\u00b7ne", "Lau\u00b7ra", "mir", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Jenseits der Gr\u00e4ber wuchern deine Schmerzen.\u00ab \u2013", "tokens": ["Jen\u00b7seits", "der", "Gr\u00e4\u00b7ber", "wu\u00b7chern", "dei\u00b7ne", "Schmer\u00b7zen", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$.", "$(", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ich ri\u00df sie blutend aus dem wunden Herzen", "tokens": ["Ich", "ri\u00df", "sie", "blu\u00b7tend", "aus", "dem", "wun\u00b7den", "Her\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und weinte laut und gab sie ihr.", "tokens": ["Und", "wein\u00b7te", "laut", "und", "gab", "sie", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "KON", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "\u00bbdu siehst die Zeit nach jenen Ufern fliegen,", "tokens": ["\u00bb", "du", "siehst", "die", "Zeit", "nach", "je\u00b7nen", "U\u00b7fern", "flie\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "NN", "APPR", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die bl\u00fchende Natur", "tokens": ["Die", "bl\u00fc\u00b7hen\u00b7de", "Na\u00b7tur"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bleibt hinter ihr \u2013 ein welker Leichnam \u2013 liegen.", "tokens": ["Bleibt", "hin\u00b7ter", "ihr", "\u2013", "ein", "wel\u00b7ker", "Leich\u00b7nam", "\u2013", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "$(", "ART", "ADJA", "NN", "$(", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wenn Erd und Himmel tr\u00fcmmernd auseinanderfliegen,", "tokens": ["Wenn", "Erd", "und", "Him\u00b7mel", "tr\u00fcm\u00b7mernd", "aus\u00b7ein\u00b7an\u00b7der\u00b7flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Daran erkenne den erf\u00fcllten Schwur.\u00ab", "tokens": ["Da\u00b7ran", "er\u00b7ken\u00b7ne", "den", "er\u00b7f\u00fcll\u00b7ten", "Schwur", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VVFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "\u00bbdie Schuldverschreibung lautet an die Toten\u00ab,", "tokens": ["\u00bb", "die", "Schuld\u00b7ver\u00b7schrei\u00b7bung", "lau\u00b7tet", "an", "die", "To\u00b7ten", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$(", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Hohnl\u00e4chelte die Welt,", "tokens": ["Hohn\u00b7l\u00e4\u00b7chel\u00b7te", "die", "Welt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbdie L\u00fcgnerin, gedungen von Despoten,", "tokens": ["\u00bb", "die", "L\u00fcg\u00b7ne\u00b7rin", ",", "ge\u00b7dun\u00b7gen", "von", "Des\u00b7po\u00b7ten", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "VVPP", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Hat f\u00fcr die Wahrheit Schatten dir geboten,", "tokens": ["Hat", "f\u00fcr", "die", "Wahr\u00b7heit", "Schat\u00b7ten", "dir", "ge\u00b7bo\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Du bist nicht mehr, wenn dieser Schein verf\u00e4llt.\u00ab", "tokens": ["Du", "bist", "nicht", "mehr", ",", "wenn", "die\u00b7ser", "Schein", "ver\u00b7f\u00e4llt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "$,", "KOUS", "PDAT", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Frech witzelte das Schlangenheer der Sp\u00f6tter:", "tokens": ["Frech", "wit\u00b7zel\u00b7te", "das", "Schlan\u00b7gen\u00b7heer", "der", "Sp\u00f6t\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbvor einem Wahn, den nur Verj\u00e4hrung weiht,", "tokens": ["\u00bb", "vor", "ei\u00b7nem", "Wahn", ",", "den", "nur", "Ver\u00b7j\u00e4h\u00b7rung", "weiht", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "NN", "$,", "PRELS", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Erzitterst du? Was sollen deine G\u00f6tter,", "tokens": ["Er\u00b7zit\u00b7terst", "du", "?", "Was", "sol\u00b7len", "dei\u00b7ne", "G\u00f6t\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PWS", "VMFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Des kranken Weltplans schlau erdachte Retter,", "tokens": ["Des", "kran\u00b7ken", "Welt\u00b7plans", "schlau", "er\u00b7dach\u00b7te", "Ret\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die Menschenwitz des Menschen Notdurft leiht?", "tokens": ["Die", "Men\u00b7schen\u00b7witz", "des", "Men\u00b7schen", "Not\u00b7durft", "leiht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Ein Gaukelspiel, ohnm\u00e4chtigen Gew\u00fcrmen", "tokens": ["Ein", "Gau\u00b7kel\u00b7spiel", ",", "ohn\u00b7m\u00e4ch\u00b7ti\u00b7gen", "Ge\u00b7w\u00fcr\u00b7men"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Vom M\u00e4chtigen geg\u00f6nnt,", "tokens": ["Vom", "M\u00e4ch\u00b7ti\u00b7gen", "ge\u00b7g\u00f6nnt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Schreckfeuer, angesteckt auf hohen T\u00fcrmen,", "tokens": ["Schreck\u00b7feu\u00b7er", ",", "an\u00b7ge\u00b7steckt", "auf", "ho\u00b7hen", "T\u00fcr\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Phantasie des Tr\u00e4umers zu best\u00fcrmen,", "tokens": ["Die", "Phan\u00b7ta\u00b7sie", "des", "Tr\u00e4u\u00b7mers", "zu", "be\u00b7st\u00fcr\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wo des Gesetzes Fackel dunkel brennt.", "tokens": ["Wo", "des", "Ge\u00b7set\u00b7zes", "Fa\u00b7ckel", "dun\u00b7kel", "brennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Was hei\u00dft die Zukunft, die uns Gr\u00e4ber decken?", "tokens": ["Was", "hei\u00dft", "die", "Zu\u00b7kunft", ",", "die", "uns", "Gr\u00e4\u00b7ber", "de\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Ewigkeit, mit der du eitel prangst?", "tokens": ["Die", "E\u00b7wig\u00b7keit", ",", "mit", "der", "du", "ei\u00b7tel", "prangst", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "PRELS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ehrw\u00fcrdig nur, weil schlaue H\u00fcllen sie verstecken,", "tokens": ["Ehr\u00b7w\u00fcr\u00b7dig", "nur", ",", "weil", "schlau\u00b7e", "H\u00fcl\u00b7len", "sie", "ver\u00b7ste\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$,", "KOUS", "ADJA", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Riesenschatten unsrer eignen Schrecken", "tokens": ["Der", "Rie\u00b7sen\u00b7schat\u00b7ten", "uns\u00b7rer", "eig\u00b7nen", "Schre\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Im hohlen Spiegel der Gewissensangst;", "tokens": ["Im", "hoh\u00b7len", "Spie\u00b7gel", "der", "Ge\u00b7wis\u00b7sen\u00b7sangst", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Ein L\u00fcgenbild lebendiger Gestalten,", "tokens": ["Ein", "L\u00fc\u00b7gen\u00b7bild", "le\u00b7ben\u00b7di\u00b7ger", "Ge\u00b7stal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Mumie der Zeit,", "tokens": ["Die", "Mu\u00b7mie", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "--+-+", "measure": "anapaest.init"}, "line.3": {"text": "Vom Balsamgeist der Hoffnung in den kalten", "tokens": ["Vom", "Bal\u00b7sam\u00b7geist", "der", "Hoff\u00b7nung", "in", "den", "kal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Behausungen des Grabes hingehalten,", "tokens": ["Be\u00b7hau\u00b7sun\u00b7gen", "des", "Gra\u00b7bes", "hin\u00b7ge\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.5": {"text": "Das nennt dein Fieberwahn \u2013 Unsterblichkeit?", "tokens": ["Das", "nennt", "dein", "Fie\u00b7ber\u00b7wahn", "\u2013", "U\u00b7nsterb\u00b7lich\u00b7keit", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$(", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.15": {"line.1": {"text": "F\u00fcr Hoffnungen \u2013 Verwesung straft sie L\u00fcgen \u2013", "tokens": ["F\u00fcr", "Hoff\u00b7nun\u00b7gen", "\u2013", "Ver\u00b7we\u00b7sung", "straft", "sie", "L\u00fc\u00b7gen", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "NN", "VVFIN", "PPER", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gabst du ", "tokens": ["Gabst", "du"], "token_info": ["word", "word"], "pos": ["VVFIN", "PPER"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Sechstausend Jahre hat der Tod geschwiegen,", "tokens": ["Sech\u00b7stau\u00b7send", "Jah\u00b7re", "hat", "der", "Tod", "ge\u00b7schwie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Kam je ein Leichnam aus der Gruft gestiegen,", "tokens": ["Kam", "je", "ein", "Leich\u00b7nam", "aus", "der", "Gruft", "ge\u00b7stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Der Meldung tat von der Vergelterin?\u00ab \u2013", "tokens": ["Der", "Mel\u00b7dung", "tat", "von", "der", "Ver\u00b7gel\u00b7te\u00b7rin", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$.", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Ich sah die Zeit nach deinen Ufern fliegen,", "tokens": ["Ich", "sah", "die", "Zeit", "nach", "dei\u00b7nen", "U\u00b7fern", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die bl\u00fchende Natur", "tokens": ["Die", "bl\u00fc\u00b7hen\u00b7de", "Na\u00b7tur"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Blieb hinter ihr, ein welker Leichnam, liegen,", "tokens": ["Blieb", "hin\u00b7ter", "ihr", ",", "ein", "wel\u00b7ker", "Leich\u00b7nam", ",", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "APPR", "PPER", "$,", "ART", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Kein Toter kam aus seiner Gruft gestiegen,", "tokens": ["Kein", "To\u00b7ter", "kam", "aus", "sei\u00b7ner", "Gruft", "ge\u00b7stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und fest vertraut ich auf den G\u00f6tterschwur.", "tokens": ["Und", "fest", "ver\u00b7traut", "ich", "auf", "den", "G\u00f6t\u00b7ter\u00b7schwur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "All meine Freuden hab ich dir geschlachtet,", "tokens": ["All", "mei\u00b7ne", "Freu\u00b7den", "hab", "ich", "dir", "ge\u00b7schlach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "NN", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Jetzt werf ich mich vor deinen Richterthron.", "tokens": ["Jetzt", "werf", "ich", "mich", "vor", "dei\u00b7nen", "Rich\u00b7ter\u00b7thron", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Menge Spott hab ich beherzt verachtet,", "tokens": ["Der", "Men\u00b7ge", "Spott", "hab", "ich", "be\u00b7herzt", "ver\u00b7ach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nur ", "tokens": ["Nur"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Vergelterin, ich fodre meinen Lohn.", "tokens": ["Ver\u00b7gel\u00b7te\u00b7rin", ",", "ich", "fod\u00b7re", "mei\u00b7nen", "Lohn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "\u00bbmit gleicher Liebe lieb ich meine Kinder!\u00ab", "tokens": ["\u00bb", "mit", "glei\u00b7cher", "Lie\u00b7be", "lieb", "ich", "mei\u00b7ne", "Kin\u00b7der", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "ADJA", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Rief unsichtbar ein Genius.", "tokens": ["Rief", "un\u00b7sicht\u00b7bar", "ein", "Ge\u00b7nius", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbzwei Blumen\u00ab, rief er, \u00bb\u2013 h\u00f6rt es, Menschenkinder \u2013", "tokens": ["\u00bb", "zwei", "Blu\u00b7men", "\u00ab", ",", "rief", "er", ",", "\u00bb", "\u2013", "h\u00f6rt", "es", ",", "Men\u00b7schen\u00b7kin\u00b7der", "\u2013"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "CARD", "NN", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "$(", "VVFIN", "PPER", "$,", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zwei Blumen bl\u00fchen f\u00fcr den weisen Finder,", "tokens": ["Zwei", "Blu\u00b7men", "bl\u00fc\u00b7hen", "f\u00fcr", "den", "wei\u00b7sen", "Fin\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sie hei\u00dfen ", "tokens": ["Sie", "hei\u00b7\u00dfen"], "token_info": ["word", "word"], "pos": ["PPER", "VVINF"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.19": {"line.1": {"text": "Wer dieser Blumen ", "tokens": ["Wer", "die\u00b7ser", "Blu\u00b7men"], "token_info": ["word", "word", "word"], "pos": ["PWS", "PDAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Die andre Schwester nicht.", "tokens": ["Die", "and\u00b7re", "Schwes\u00b7ter", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Genie\u00dfe, wer nicht glauben kann. Die Lehre", "tokens": ["Ge\u00b7nie\u00b7\u00dfe", ",", "wer", "nicht", "glau\u00b7ben", "kann", ".", "Die", "Leh\u00b7re"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "PWS", "PTKNEG", "VVINF", "VMFIN", "$.", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ist ewig wie die Welt. Wer glauben kann, entbehre.", "tokens": ["Ist", "e\u00b7wig", "wie", "die", "Welt", ".", "Wer", "glau\u00b7ben", "kann", ",", "ent\u00b7beh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "ADJD", "KOKOM", "ART", "NN", "$.", "PWS", "VVINF", "VMFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Weltgeschichte ist das Weltgericht.", "tokens": ["Die", "Welt\u00b7ge\u00b7schich\u00b7te", "ist", "das", "Welt\u00b7ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Du hast ", "tokens": ["Du", "hast"], "token_info": ["word", "word"], "pos": ["PPER", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Dein ", "tokens": ["Dein"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Du konntest deine Weisen fragen,", "tokens": ["Du", "konn\u00b7test", "dei\u00b7ne", "Wei\u00b7sen", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Was man von der Minute ausgeschlagen,", "tokens": ["Was", "man", "von", "der", "Mi\u00b7nu\u00b7te", "aus\u00b7ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Gibt keine Ewigkeit zur\u00fcck.\u00ab", "tokens": ["Gibt", "kei\u00b7ne", "E\u00b7wig\u00b7keit", "zu\u00b7r\u00fcck", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PIAT", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}