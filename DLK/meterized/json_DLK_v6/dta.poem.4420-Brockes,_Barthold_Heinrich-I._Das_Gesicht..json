{"dta.poem.4420": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "I.  Das Gesicht.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1727", "urn": "urn:nbn:de:kobv:b4-200905198599", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Da\u00df GOtt dieses Rund der Erden,", "tokens": ["Da\u00df", "Gott", "die\u00b7ses", "Rund", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PDAT", "NN", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wie uns Schrift und Bibel lehr\u2019t,", "tokens": ["Wie", "uns", "Schrift", "und", "Bi\u00b7bel", "lehr't", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch ein W\u00f6rtchen lassen werden,", "tokens": ["Durch", "ein", "W\u00f6rt\u00b7chen", "las\u00b7sen", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist ja wol erstaunens-wehrt:", "tokens": ["Ist", "ja", "wol", "er\u00b7stau\u00b7nens\u00b7wehrt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Doch nicht minder ist zu preisen,", "tokens": ["Doch", "nicht", "min\u00b7der", "ist", "zu", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "VAFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df in zwey so kleinen Kreisen", "tokens": ["Da\u00df", "in", "zwey", "so", "klei\u00b7nen", "Krei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "CARD", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Alles, was der grosse heg\u2019t,", "tokens": ["Al\u00b7les", ",", "was", "der", "gros\u00b7se", "heg't", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "ART", "ADJA", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Sich in uns\u2019re Selen pr\u00e4g\u2019t.", "tokens": ["Sich", "in", "un\u00b7s'\u00b7re", "Se\u00b7len", "pr\u00e4g'", "t."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["PRF", "APPR", "PPOSAT", "NN", "XY", "XY"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.2": {"line.1": {"text": "Was der Erden Grenzen fassen,", "tokens": ["Was", "der", "Er\u00b7den", "Gren\u00b7zen", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mu\u00df sich durch besond\u2019re Kraft", "tokens": ["Mu\u00df", "sich", "durch", "be\u00b7son\u00b7d'\u00b7re", "Kraft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Von zwey P\u00fcnctchen fassen lassen;", "tokens": ["Von", "zwey", "P\u00fcnct\u00b7chen", "fas\u00b7sen", "las\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Deren selt\u2019ne Eigenschaft", "tokens": ["De\u00b7ren", "selt'\u00b7ne", "Ei\u00b7gen\u00b7schaft"], "token_info": ["word", "word", "word"], "pos": ["PDS", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Auch die allergr\u00f6sten Sachen", "tokens": ["Auch", "die", "al\u00b7ler\u00b7gr\u00f6s\u00b7ten", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dergestalt wei\u00df klein zu machen,", "tokens": ["Der\u00b7ge\u00b7stalt", "wei\u00df", "klein", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df, was nicht zu messen steh\u2019t,", "tokens": ["Da\u00df", ",", "was", "nicht", "zu", "mes\u00b7sen", "steh't", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PRELS", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Ins Gehirn durchs Auge geh\u2019t.", "tokens": ["Ins", "Ge\u00b7hirn", "durchs", "Au\u00b7ge", "geh'", "t."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["APPRART", "NN", "APPRART", "NN", "VVFIN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Aug\u2019, in deinen engen Schranken", "tokens": ["Aug'", ",", "in", "dei\u00b7nen", "en\u00b7gen", "Schran\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sieht man, was das Herze spricht.", "tokens": ["Sieht", "man", ",", "was", "das", "Her\u00b7ze", "spricht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "PWS", "PDS", "VVFIN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Rege Zunge der Gedanken,", "tokens": ["Re\u00b7ge", "Zun\u00b7ge", "der", "Ge\u00b7dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Witz des C\u00f6rpers, Selen-Licht,", "tokens": ["Witz", "des", "C\u00f6r\u00b7pers", ",", "Se\u00b7len\u00b7Licht", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Richter der Vollkommenheiten,", "tokens": ["Rich\u00b7ter", "der", "Voll\u00b7kom\u00b7men\u00b7hei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Spiegel aller Seltsamkeiten,", "tokens": ["Spie\u00b7gel", "al\u00b7ler", "Selt\u00b7sam\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Die der Erd-Kreis in sich h\u00e4lt,", "tokens": ["Die", "der", "Erd\u00b7Kreis", "in", "sich", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "APPR", "PRF", "VVFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.8": {"text": "F\u00fchrer der sonst blinden Welt!", "tokens": ["F\u00fch\u00b7rer", "der", "sonst", "blin\u00b7den", "Welt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "G\u00f6ttlichs Glied, kein Stral, kein Blitzen", "tokens": ["G\u00f6tt\u00b7lichs", "Glied", ",", "kein", "Stral", ",", "kein", "Blit\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NE", "NN", "$,", "PIAT", "NN", "$,", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Teil\u2019t die Luft so schnell, als du.", "tokens": ["Teil't", "die", "Luft", "so", "schnell", ",", "als", "du", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "ADJD", "$,", "KOUS", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Du bleib\u2019st, wo du sitzest, sitzen,", "tokens": ["Du", "bleib'st", ",", "wo", "du", "sit\u00b7zest", ",", "sit\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Flieg\u2019st und steh\u2019st in steter Ruh\u2019:", "tokens": ["Flieg'st", "und", "steh'st", "in", "ste\u00b7ter", "Ruh'", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Alle Bilder, die der Selen", "tokens": ["Al\u00b7le", "Bil\u00b7der", ",", "die", "der", "Se\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "NN", "$,", "PRELS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sich so wunderbar verm\u00e4len,", "tokens": ["Sich", "so", "wun\u00b7der\u00b7bar", "ver\u00b7m\u00e4\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Was Verstand und Weisheit wei\u00df,", "tokens": ["Was", "Ver\u00b7stand", "und", "Weis\u00b7heit", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Zeug\u2019t dein Stralen-schwang\u2019rer Kreis.", "tokens": ["Zeug't", "dein", "Stra\u00b7len\u00b7schwang'\u00b7rer", "Kreis", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Wer auf dieses Wunder achtet,", "tokens": ["Wer", "auf", "die\u00b7ses", "Wun\u00b7der", "ach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PDAT", "NN", "VVFIN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Wenn der Selen rege Kraft", "tokens": ["Wenn", "der", "Se\u00b7len", "re\u00b7ge", "Kraft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch das Aug\u2019 ein Aug betrachtet;", "tokens": ["Durch", "das", "Aug'", "ein", "Aug", "be\u00b7trach\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird fast aus sich selbst gerafft,", "tokens": ["Wird", "fast", "aus", "sich", "selbst", "ge\u00b7rafft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PRF", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Weil er mit Erstaunen siehet,", "tokens": ["Weil", "er", "mit", "Er\u00b7stau\u00b7nen", "sie\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie sich die Natur bem\u00fchet,", "tokens": ["Wie", "sich", "die", "Na\u00b7tur", "be\u00b7m\u00fc\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und so unsch\u00e4tzbaren Schatz", "tokens": ["Und", "so", "un\u00b7sch\u00e4tz\u00b7ba\u00b7ren", "Schatz"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Schliesst in solchen kleinen Platz.", "tokens": ["Schliesst", "in", "sol\u00b7chen", "klei\u00b7nen", "Platz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Jm Gehirn, der Nerven-Qvelle,", "tokens": ["Jm", "Ge\u00b7hirn", ",", "der", "Ner\u00b7ven\u00b7Q\u00b7vel\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wird der Mittel-Punct gezeugt,", "tokens": ["Wird", "der", "Mit\u00b7tel\u00b7Punct", "ge\u00b7zeugt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der sich von der Ursprungs-Stelle", "tokens": ["Der", "sich", "von", "der", "Ur\u00b7sprungs\u00b7Stel\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In zween zarte G\u00e4nge beugt,", "tokens": ["In", "zween", "zar\u00b7te", "G\u00e4n\u00b7ge", "beugt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Draus die aufmerksamen Augen", "tokens": ["Draus", "die", "auf\u00b7merk\u00b7sa\u00b7men", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die Bewegungs-Kr\u00e4fte saugen,", "tokens": ["Die", "Be\u00b7we\u00b7gungs\u00b7Kr\u00e4f\u00b7te", "sau\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df daher, wenn eins sich reg\u2019t,", "tokens": ["Da\u00df", "da\u00b7her", ",", "wenn", "eins", "sich", "reg't", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PAV", "$,", "KOUS", "PIS", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Auch das and\u2019re sich beweg\u2019t.", "tokens": ["Auch", "das", "an\u00b7d'\u00b7re", "sich", "be\u00b7weg'", "t."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["ADV", "ART", "PIS", "PRF", "VVFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Uns\u2019rer Augen w\u00e4ssricht Wesen", "tokens": ["Un\u00b7s'\u00b7rer", "Au\u00b7gen", "w\u00e4ss\u00b7richt", "We\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Samt der Haut ist ungef\u00e4rbt,", "tokens": ["Samt", "der", "Haut", "ist", "un\u00b7ge\u00b7f\u00e4rbt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Damit, was wir sehn und lesen,", "tokens": ["Da\u00b7mit", ",", "was", "wir", "sehn", "und", "le\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "PRELS", "PPER", "VVINF", "KON", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht ver\u00e4ndert, nicht verderbt", "tokens": ["Nicht", "ver\u00b7\u00e4n\u00b7dert", ",", "nicht", "ver\u00b7derbt"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PTKNEG", "VVPP", "$,", "PTKNEG", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Uns\u2019rer Sele scheinen m\u00f6gte;", "tokens": ["Un\u00b7s'\u00b7rer", "Se\u00b7le", "schei\u00b7nen", "m\u00f6g\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Sie also nur f\u00e4lschlich d\u00e4chte,", "tokens": ["Sie", "al\u00b7so", "nur", "f\u00e4lschlich", "d\u00e4ch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Wie, wenn wir durch Gl\u00e4ser sehn,", "tokens": ["Wie", ",", "wenn", "wir", "durch", "Gl\u00e4\u00b7ser", "sehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "KOUS", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Die gef\u00e4rb\u2019t, pfleg\u2019t zu geschehn.", "tokens": ["Die", "ge\u00b7f\u00e4r\u00b7b't", ",", "pfleg't", "zu", "ge\u00b7schehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "VVPP", "$,", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.8": {"line.1": {"text": "Hinter einem jeden Kreise", "tokens": ["Hin\u00b7ter", "ei\u00b7nem", "je\u00b7den", "Krei\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Find\u2019t sich eine schwarze Wand,", "tokens": ["Find't", "sich", "ei\u00b7ne", "schwar\u00b7ze", "Wand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "An der, auf besond\u2019re Weise,", "tokens": ["An", "der", ",", "auf", "be\u00b7son\u00b7d'\u00b7re", "Wei\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Da sie gleichsam ausgespann\u2019t,", "tokens": ["Da", "sie", "gleich\u00b7sam", "aus\u00b7ge\u00b7spann't", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Durch die w\u00e4ss\u2019richten Krystallen", "tokens": ["Durch", "die", "w\u00e4ss'\u00b7rich\u00b7ten", "Krys\u00b7tal\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.6": {"text": "Mancherley Gestalten fallen,", "tokens": ["Man\u00b7cher\u00b7ley", "Ge\u00b7stal\u00b7ten", "fal\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wann das Licht, so sie bestral\u2019t,", "tokens": ["Wann", "das", "Licht", ",", "so", "sie", "be\u00b7stral't", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "ADV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Tausend Bilder daran mal\u2019t.", "tokens": ["Tau\u00b7send", "Bil\u00b7der", "da\u00b7ran", "mal'", "t."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["CARD", "NN", "PAV", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Linsen gleich zu beyden Seiten,", "tokens": ["Lin\u00b7sen", "gleich", "zu", "bey\u00b7den", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zur Bef\u00f6rderung des Lichts,", "tokens": ["Zur", "Be\u00b7f\u00f6r\u00b7de\u00b7rung", "des", "Lichts", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wollt\u2019 es die Natur bereiten,", "tokens": ["Wollt'", "es", "die", "Na\u00b7tur", "be\u00b7rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df die Stralen des Gesicht\u2019s,", "tokens": ["Da\u00df", "die", "Stra\u00b7len", "des", "Ge\u00b7sicht's", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Die vom Gegenstand\u2019 erscheinen,", "tokens": ["Die", "vom", "Ge\u00b7gen\u00b7stand'", "er\u00b7schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sich in einen Punct vereinen,", "tokens": ["Sich", "in", "ei\u00b7nen", "Punct", "ver\u00b7ei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df durch doppeln Gegenschlag", "tokens": ["Da\u00df", "durch", "dop\u00b7peln", "Ge\u00b7gen\u00b7schlag"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Alles deutlich scheinen mag.", "tokens": ["Al\u00b7les", "deut\u00b7lich", "schei\u00b7nen", "mag."], "token_info": ["word", "word", "word", "abbreviation"], "pos": ["PIS", "ADJD", "VVFIN", "NE"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.10": {"line.1": {"text": "Beyde Tr\u00e4ubchen in den Augen", "tokens": ["Bey\u00b7de", "Tr\u00e4ub\u00b7chen", "in", "den", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Haben solche selt\u2019ne Kraft,", "tokens": ["Ha\u00b7ben", "sol\u00b7che", "selt'\u00b7ne", "Kraft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df sie sich zu \u00f6ffnen taugen,", "tokens": ["Da\u00df", "sie", "sich", "zu", "\u00f6ff\u00b7nen", "tau\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und, nach Muskeln Eigenschaft,", "tokens": ["Und", ",", "nach", "Mus\u00b7keln", "Ei\u00b7gen\u00b7schaft", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wiederum zusammen ziehen.", "tokens": ["Wie\u00b7de\u00b7rum", "zu\u00b7sam\u00b7men", "zie\u00b7hen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dieses, wenn sie sich bem\u00fchen,", "tokens": ["Die\u00b7ses", ",", "wenn", "sie", "sich", "be\u00b7m\u00fc\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "KOUS", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Starkem Lichte zu entgehn,", "tokens": ["Star\u00b7kem", "Lich\u00b7te", "zu", "ent\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Das, um in die Fern zu sehn.", "tokens": ["Das", ",", "um", "in", "die", "Fern", "zu", "sehn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "KOUI", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Alles dieses kann man weisen;", "tokens": ["Al\u00b7les", "die\u00b7ses", "kann", "man", "wei\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PDAT", "VMFIN", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aber, wie das Auge sieht,", "tokens": ["A\u00b7ber", ",", "wie", "das", "Au\u00b7ge", "sieht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ob das Sehn in seinen Kreisen,", "tokens": ["Ob", "das", "Sehn", "in", "sei\u00b7nen", "Krei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Oder ausserhalb, geschieht;", "tokens": ["O\u00b7der", "aus\u00b7ser\u00b7halb", ",", "ge\u00b7schieht", ";"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["KON", "ADJD", "$,", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Davon, wie von vielen Sachen,", "tokens": ["Da\u00b7von", ",", "wie", "von", "vie\u00b7len", "Sa\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "PWAV", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist kein fester Schlu\u00df zu machen.", "tokens": ["Ist", "kein", "fes\u00b7ter", "Schlu\u00df", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Vielen scheinets, wenn wir sehn,", "tokens": ["Vie\u00b7len", "schei\u00b7nets", ",", "wenn", "wir", "sehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "PPER", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "So, wie folget, zu geschehn:", "tokens": ["So", ",", "wie", "fol\u00b7get", ",", "zu", "ge\u00b7schehn", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "VVFIN", "$,", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Unser Auge treibt zusammen", "tokens": ["Un\u00b7ser", "Au\u00b7ge", "treibt", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKVZ"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alle Geister, die es braucht:", "tokens": ["Al\u00b7le", "Geis\u00b7ter", ",", "die", "es", "braucht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seine Stralen sind wie Flammen,", "tokens": ["Sei\u00b7ne", "Stra\u00b7len", "sind", "wie", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "KOKOM", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die der Geist stets von sich haucht,", "tokens": ["Die", "der", "Geist", "stets", "von", "sich", "haucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "APPR", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Die, in Form der Flammen-Seulen,", "tokens": ["Die", ",", "in", "Form", "der", "Flam\u00b7men\u00b7Seu\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "APPR", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Stetig aus den Augen eilen,", "tokens": ["Ste\u00b7tig", "aus", "den", "Au\u00b7gen", "ei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wodurch es uns ins Gem\u00fct", "tokens": ["Wo\u00b7durch", "es", "uns", "ins", "Ge\u00b7m\u00fct"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PRF", "APPRART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": "Allerley Gestalten zieht.", "tokens": ["Al\u00b7ler\u00b7ley", "Ge\u00b7stal\u00b7ten", "zieht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Hat man auf verborg\u2019ne Weise", "tokens": ["Hat", "man", "auf", "ver\u00b7bor\u00b7g'\u00b7ne", "Wei\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "APPR", "ADJA", "NN"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Dieses Feuer weggesandt,", "tokens": ["Die\u00b7ses", "Feu\u00b7er", "weg\u00b7ge\u00b7sandt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und es findet auf der Reise", "tokens": ["Und", "es", "fin\u00b7det", "auf", "der", "Rei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Einen dichten Gegenstand,", "tokens": ["Ei\u00b7nen", "dich\u00b7ten", "Ge\u00b7gen\u00b7stand", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wovon lichte Teilchen springen;", "tokens": ["Wo\u00b7von", "lich\u00b7te", "Teil\u00b7chen", "sprin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wird es diese r\u00fcckw\u00e4rts dringen,", "tokens": ["Wird", "es", "die\u00b7se", "r\u00fcck\u00b7w\u00e4rts", "drin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PDS", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und die prall\u2019n im Augenblick", "tokens": ["Und", "die", "prall'n", "im", "Au\u00b7gen\u00b7blick"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "APPRART", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.8": {"text": "Durch den Gegenstand zur\u00fcck.", "tokens": ["Durch", "den", "Ge\u00b7gen\u00b7stand", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Da sp\u00fcr\u2019t\u2019s durch besond\u2019re K\u00fcnste", "tokens": ["Da", "sp\u00fcr't's", "durch", "be\u00b7son\u00b7d'\u00b7re", "K\u00fcns\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Seines Gegenstandes Bild,", "tokens": ["Sei\u00b7nes", "Ge\u00b7gen\u00b7stan\u00b7des", "Bild", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Welches gleichsam als durch D\u00fcnste", "tokens": ["Wel\u00b7ches", "gleich\u00b7sam", "als", "durch", "D\u00fcns\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADJD", "KOKOM", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Stets aus allen C\u00f6rpern qvillt,", "tokens": ["Stets", "aus", "al\u00b7len", "C\u00f6r\u00b7pern", "qvillt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sich best\u00e4ndig draus erhebet,", "tokens": ["Sich", "be\u00b7st\u00e4n\u00b7dig", "draus", "er\u00b7he\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "PAV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und auf allen Fl\u00e4chen schwebet:", "tokens": ["Und", "auf", "al\u00b7len", "Fl\u00e4\u00b7chen", "schwe\u00b7bet", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da, spricht man, sieht das Gesicht,", "tokens": ["Da", ",", "spricht", "man", ",", "sieht", "das", "Ge\u00b7sicht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PIS", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": "Aber in dem Auge nicht.", "tokens": ["A\u00b7ber", "in", "dem", "Au\u00b7ge", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Ich hingegen k\u00f6nnte weisen,", "tokens": ["Ich", "hin\u00b7ge\u00b7gen", "k\u00f6nn\u00b7te", "wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wie das F\u00fclen, wenn ich seh\u2019,", "tokens": ["Wie", "das", "F\u00fc\u00b7len", ",", "wenn", "ich", "seh'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "In der Augen regen Kreisen", "tokens": ["In", "der", "Au\u00b7gen", "re\u00b7gen", "Krei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und beym Vorwurf nicht gescheh,", "tokens": ["Und", "beym", "Vor\u00b7wurf", "nicht", "ge\u00b7scheh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie die Bildung aller Dinge", "tokens": ["Wie", "die", "Bil\u00b7dung", "al\u00b7ler", "Din\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Durch das Licht ins Auge dringe,", "tokens": ["Durch", "das", "Licht", "ins", "Au\u00b7ge", "drin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Welches, wenn man es betracht\u2019t,", "tokens": ["Wel\u00b7ches", ",", "wenn", "man", "es", "be\u00b7tracht't", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Die\u00df Exempel glaublich macht:", "tokens": ["Die\u00df", "Ex\u00b7em\u00b7pel", "glaub\u00b7lich", "macht", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "ADJD", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "Alle C\u00f6rper auf der Erden,", "tokens": ["Al\u00b7le", "C\u00f6r\u00b7per", "auf", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die rund, glatt und dunkel seyn,", "tokens": ["Die", "rund", ",", "glatt", "und", "dun\u00b7kel", "seyn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$,", "ADJD", "KON", "ADJD", "VAINF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wenn sie recht betrachtet werden,", "tokens": ["Wenn", "sie", "recht", "be\u00b7trach\u00b7tet", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VVPP", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Haben einen kleinen Schein:", "tokens": ["Ha\u00b7ben", "ei\u00b7nen", "klei\u00b7nen", "Schein", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dieser f\u00e4nget wie ein Spiegel", "tokens": ["Die\u00b7ser", "f\u00e4n\u00b7get", "wie", "ein", "Spie\u00b7gel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "KOKOM", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "W\u00e4lder, Wolken, Thal und H\u00fcgel,", "tokens": ["W\u00e4l\u00b7der", ",", "Wol\u00b7ken", ",", "Thal", "und", "H\u00fc\u00b7gel", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "(wenn die Sonn\u2019 auf selbe stral\u2019t)", "tokens": ["(", "wenn", "die", "Sonn'", "auf", "sel\u00b7be", "stral't", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "ART", "NN", "APPR", "ADJA", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Als wenn sie darin gemal\u2019t.", "tokens": ["Als", "wenn", "sie", "da\u00b7rin", "ge\u00b7mal'", "t."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["KOUS", "KOUS", "PPER", "PAV", "XY", "XY"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.17": {"line.1": {"text": "Ja bey aufgekl\u00e4r\u2019tem Wetter", "tokens": ["Ja", "bey", "auf\u00b7ge\u00b7kl\u00e4r'\u00b7tem", "Wet\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKANT", "APPR", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Hab\u2019 ich einst von ungefehr,", "tokens": ["Hab'", "ich", "einst", "von", "un\u00b7ge\u00b7fehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "APPR", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie sich Felder, B\u00e4ume, Bl\u00e4tter", "tokens": ["Wie", "sich", "Fel\u00b7der", ",", "B\u00e4u\u00b7me", ",", "Bl\u00e4t\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PWAV", "PRF", "NN", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gar in einer Heidelbeer", "tokens": ["Gar", "in", "ei\u00b7ner", "Hei\u00b7del\u00b7beer"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Fast unsichtbar\u2019s Scheinchen dr\u00fcckten,", "tokens": ["Fast", "un\u00b7sicht\u00b7ba\u00b7r's", "Schein\u00b7chen", "dr\u00fcck\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Jhn mit Farb\u2019 und Zeichnung schm\u00fcckten,", "tokens": ["Jhn", "mit", "Fa\u00b7rb'", "und", "Zeich\u00b7nung", "schm\u00fcck\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "--++-+-+-", "measure": "anapaest.init"}, "line.7": {"text": "Unvergleichlich, rein und sch\u00f6n,", "tokens": ["Un\u00b7ver\u00b7gleich\u00b7lich", ",", "rein", "und", "sch\u00f6n", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Mit Erstaunen angesehn.", "tokens": ["Mit", "Er\u00b7stau\u00b7nen", "an\u00b7ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Wie nun solche Bilder fallen", "tokens": ["Wie", "nun", "sol\u00b7che", "Bil\u00b7der", "fal\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "PIAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf was dichtes; also f\u00e4llt", "tokens": ["Auf", "was", "dich\u00b7tes", ";", "al\u00b7so", "f\u00e4llt"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PRELS", "ADJA", "$.", "ADV", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "In die gl\u00e4nzenden Krystallen", "tokens": ["In", "die", "gl\u00e4n\u00b7zen\u00b7den", "Krys\u00b7tal\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Uns\u2019rer Augen, was die Welt", "tokens": ["Un\u00b7s'\u00b7rer", "Au\u00b7gen", ",", "was", "die", "Welt"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ART", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Durch die Sonne sichtbar heget;", "tokens": ["Durch", "die", "Son\u00b7ne", "sicht\u00b7bar", "he\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df sich\u2019s aber in uns pr\u00e4get,", "tokens": ["Da\u00df", "sich's", "a\u00b7ber", "in", "uns", "pr\u00e4\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Komm\u2019t, weils sich durchs Auge spielt,", "tokens": ["Kom\u00b7m't", ",", "weils", "sich", "durchs", "Au\u00b7ge", "spielt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PRF", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da der Sinn die Bilder f\u00fcl\u2019t.", "tokens": ["Da", "der", "Sinn", "die", "Bil\u00b7der", "f\u00fcl'", "t."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVFIN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Welches nun von beyden Teilen", "tokens": ["Wel\u00b7ches", "nun", "von", "bey\u00b7den", "Tei\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unrecht sey, und welches wahr,", "tokens": ["Un\u00b7recht", "sey", ",", "und", "wel\u00b7ches", "wahr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "KON", "PWS", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "(wenn wir uns nicht \u00fcbereilen)", "tokens": ["(", "wenn", "wir", "uns", "nicht", "\u00fc\u00b7be\u00b7rei\u00b7len", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PRF", "PTKNEG", "VVINF", "$("], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Ist nicht eben allzuklar.", "tokens": ["Ist", "nicht", "e\u00b7ben", "all\u00b7zu\u00b7klar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Gottes Wege sind verborgen;", "tokens": ["Got\u00b7tes", "We\u00b7ge", "sind", "ver\u00b7bor\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Darum will ich minder sorgen,", "tokens": ["Da\u00b7rum", "will", "ich", "min\u00b7der", "sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ADV", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wie die Wunder zu verstehn,", "tokens": ["Wie", "die", "Wun\u00b7der", "zu", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Als erfreut sie anzusehn.", "tokens": ["Als", "er\u00b7freut", "sie", "an\u00b7zu\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "VVIZU", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Mit wie vielerley Geweben,", "tokens": ["Mit", "wie", "vie\u00b7ler\u00b7ley", "Ge\u00b7we\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "KOKOM", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Adern, Nerven, Fleisch und Haut", "tokens": ["A\u00b7dern", ",", "Ner\u00b7ven", ",", "Fleisch", "und", "Haut"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist durchflochten und umgeben", "tokens": ["Ist", "durch\u00b7floch\u00b7ten", "und", "um\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "VVPP", "KON", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das, was man im Auge schaut!", "tokens": ["Das", ",", "was", "man", "im", "Au\u00b7ge", "schaut", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PIS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Grosse F\u00e4den, kleine K\u00f6rner,", "tokens": ["Gros\u00b7se", "F\u00e4\u00b7den", ",", "klei\u00b7ne", "K\u00f6r\u00b7ner", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Netze, Knoten, Trauben, H\u00f6rner,", "tokens": ["Net\u00b7ze", ",", "Kno\u00b7ten", ",", "Trau\u00b7ben", ",", "H\u00f6r\u00b7ner", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wasser, z\u00e4he Feuchtigkeit,", "tokens": ["Was\u00b7ser", ",", "z\u00e4\u00b7he", "Feuch\u00b7tig\u00b7keit", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "D\u00e4mmerung und Dunkelheit,", "tokens": ["D\u00e4m\u00b7me\u00b7rung", "und", "Dun\u00b7kel\u00b7heit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+---+-+", "measure": "dactylic.init"}}, "stanza.21": {"line.1": {"text": "Geister, Wasser, Blut-Gef\u00e4sse.", "tokens": ["Geis\u00b7ter", ",", "Was\u00b7ser", ",", "Blut\u00b7Ge\u00b7f\u00e4s\u00b7se", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nimmer, nimmer glaubte man,", "tokens": ["Nim\u00b7mer", ",", "nim\u00b7mer", "glaub\u00b7te", "man", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df so viel im Auge s\u00e4sse,", "tokens": ["Da\u00df", "so", "viel", "im", "Au\u00b7ge", "s\u00e4s\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als man kaum erzehlen kann.", "tokens": ["Als", "man", "kaum", "er\u00b7zeh\u00b7len", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "M\u00e4uslein, H\u00e4ute, Nerven, Dr\u00fcsen", "tokens": ["M\u00e4us\u00b7lein", ",", "H\u00e4u\u00b7te", ",", "Ner\u00b7ven", ",", "Dr\u00fc\u00b7sen"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Werden uns darin gewiesen.", "tokens": ["Wer\u00b7den", "uns", "da\u00b7rin", "ge\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PAV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Kurz: es wird des Sch\u00f6pfers Hand", "tokens": ["Kurz", ":", "es", "wird", "des", "Sch\u00f6p\u00b7fers", "Hand"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$.", "PPER", "VAFIN", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Wunderbar im Aug\u2019 erkannt.", "tokens": ["Wun\u00b7der\u00b7bar", "im", "Aug'", "er\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Doch das herrlichste von allen,", "tokens": ["Doch", "das", "herr\u00b7lichs\u00b7te", "von", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "APPR", "PIAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Das verwirr\u2019t Verstand und Witz,", "tokens": ["Das", "ver\u00b7wirr't", "Ver\u00b7stand", "und", "Witz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sind die stralenden Krystallen,", "tokens": ["Sind", "die", "stra\u00b7len\u00b7den", "Krys\u00b7tal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die des Lichtes Thron und Sitz.", "tokens": ["Die", "des", "Lich\u00b7tes", "Thron", "und", "Sitz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Helle Cirkel, kleine Sterne,", "tokens": ["Hel\u00b7le", "Cir\u00b7kel", ",", "klei\u00b7ne", "Ster\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die ihr so was nah als ferne", "tokens": ["Die", "ihr", "so", "was", "nah", "als", "fer\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADV", "PWS", "ADJD", "KOKOM", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Unterscheidet; euer Schein", "tokens": ["Un\u00b7ter\u00b7schei\u00b7det", ";", "eu\u00b7er", "Schein"], "token_info": ["word", "punct", "word", "word"], "pos": ["VVFIN", "$.", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Scheint was G\u00f6ttliches zu seyn!", "tokens": ["Scheint", "was", "G\u00f6tt\u00b7li\u00b7ches", "zu", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "NN", "PTKZU", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Ferner sind die edlen Glieder", "tokens": ["Fer\u00b7ner", "sind", "die", "ed\u00b7len", "Glie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit sechs Muskeln noch versehn;", "tokens": ["Mit", "sechs", "Mus\u00b7keln", "noch", "ver\u00b7sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da das Par der Augenlieder,", "tokens": ["Da", "das", "Par", "der", "Au\u00b7gen\u00b7lie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die bald auf-bald nieder gehn,", "tokens": ["Die", "bald", "auf\u00b7bald", "nie\u00b7der", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "PTKVZ", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Durch ihr nimmer m\u00fcdes regen,", "tokens": ["Durch", "ihr", "nim\u00b7mer", "m\u00fc\u00b7des", "re\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "ADJA", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und ihr ewiges Bewegen", "tokens": ["Und", "ihr", "e\u00b7wi\u00b7ges", "Be\u00b7we\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Macht, da\u00df K\u00e4lte, Staub und Wind", "tokens": ["Macht", ",", "da\u00df", "K\u00e4l\u00b7te", ",", "Staub", "und", "Wind"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Nie den Augen sch\u00e4dlich sind.", "tokens": ["Nie", "den", "Au\u00b7gen", "sch\u00e4d\u00b7lich", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Da\u00df kein Zufall es verletzen,", "tokens": ["Da\u00df", "kein", "Zu\u00b7fall", "es", "ver\u00b7let\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Keine Not ihm schaden mag;", "tokens": ["Kei\u00b7ne", "Not", "ihm", "scha\u00b7den", "mag", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat\u2019s der Sch\u00f6pfer wollen setzen", "tokens": ["Hat's", "der", "Sch\u00f6p\u00b7fer", "wol\u00b7len", "set\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unter ein gew\u00f6lbtes Dach:", "tokens": ["Un\u00b7ter", "ein", "ge\u00b7w\u00f6lb\u00b7tes", "Dach", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wo der Augenbraunen Bogen", "tokens": ["Wo", "der", "Au\u00b7gen\u00b7brau\u00b7nen", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sich zur Zierde vorgezogen,", "tokens": ["Sich", "zur", "Zier\u00b7de", "vor\u00b7ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "APPRART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Unter deren halbem Kreis\u2019", "tokens": ["Un\u00b7ter", "de\u00b7ren", "hal\u00b7bem", "Kreis'"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PRELAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Es von keinem Schaden wei\u00df.", "tokens": ["Es", "von", "kei\u00b7nem", "Scha\u00b7den", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Ja da\u00df uns das Licht nicht m\u00f6ge", "tokens": ["Ja", "da\u00df", "uns", "das", "Licht", "nicht", "m\u00f6\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "KOUS", "PPER", "ART", "NN", "PTKNEG", "VMFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hinderlich am Schlafe seyn,", "tokens": ["Hin\u00b7der\u00b7lich", "am", "Schla\u00b7fe", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sch\u00fctzet GOTT durch diese Wege", "tokens": ["Sch\u00fct\u00b7zet", "GoTT", "durch", "die\u00b7se", "We\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "NE", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unser Aug vor dessen Schein,", "tokens": ["Un\u00b7ser", "Aug", "vor", "des\u00b7sen", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PRELAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da vor des Gesicht\u2019s Krystallen", "tokens": ["Da", "vor", "des", "Ge\u00b7sicht's", "Krys\u00b7tal\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Sie recht wie ein Vorhang fallen,", "tokens": ["Sie", "recht", "wie", "ein", "Vor\u00b7hang", "fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "KOKOM", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Der sich fr\u00fch, damit man sieht,", "tokens": ["Der", "sich", "fr\u00fch", ",", "da\u00b7mit", "man", "sieht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADJD", "$,", "KOUS", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Wunderbar zusammen zieht.", "tokens": ["Wun\u00b7der\u00b7bar", "zu\u00b7sam\u00b7men", "zieht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Wer kann ohn\u2019 Erstaunen fassen,", "tokens": ["Wer", "kann", "ohn'", "Er\u00b7stau\u00b7nen", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "APPR", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wie die Augen-Lieder sich", "tokens": ["Wie", "die", "Au\u00b7gen\u00b7Lie\u00b7der", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "PRF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "So geschwind bewegen lassen!", "tokens": ["So", "ge\u00b7schwind", "be\u00b7we\u00b7gen", "las\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Seht doch, wie verwunderlich", "tokens": ["Seht", "doch", ",", "wie", "ver\u00b7wun\u00b7der\u00b7lich"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ADV", "$,", "PWAV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "GoTT den Augen einen Bogen", "tokens": ["GoTT", "den", "Au\u00b7gen", "ei\u00b7nen", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "In den Liedern vorgezogen,", "tokens": ["In", "den", "Lie\u00b7dern", "vor\u00b7ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Der so nett aufs Aug sich schickt,", "tokens": ["Der", "so", "nett", "aufs", "Aug", "sich", "schickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "APPRART", "NN", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Das er dr\u00fcckt, und doch nicht dr\u00fcckt.", "tokens": ["Das", "er", "dr\u00fcckt", ",", "und", "doch", "nicht", "dr\u00fcckt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "VVFIN", "$,", "KON", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "H\u00fcben sich die Augen-Lieder", "tokens": ["H\u00fc\u00b7ben", "sich", "die", "Au\u00b7gen\u00b7Lie\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PRF", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch die Muskeln selbst nicht auf,", "tokens": ["Durch", "die", "Mus\u00b7keln", "selbst", "nicht", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "PTKNEG", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sondern s\u00fcnken immer wieder,", "tokens": ["Son\u00b7dern", "s\u00fcn\u00b7ken", "im\u00b7mer", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "(ach man achte doch darauf!)", "tokens": ["(", "ach", "man", "ach\u00b7te", "doch", "da\u00b7rauf", "!", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "XY", "PIS", "VVFIN", "ADV", "PAV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie erb\u00e4rmlich w\u00fcrd\u2019 es lassen,", "tokens": ["Wie", "er\u00b7b\u00e4rm\u00b7lich", "w\u00fcrd'", "es", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn man sie mit H\u00e4nden fassen,", "tokens": ["Wenn", "man", "sie", "mit", "H\u00e4n\u00b7den", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und erst aufw\u00e4rts schieben m\u00fcst!", "tokens": ["Und", "erst", "auf\u00b7w\u00e4rts", "schie\u00b7ben", "m\u00fcst", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Merks, verstockter Atheist!", "tokens": ["Merks", ",", "ver\u00b7stock\u00b7ter", "A\u00b7theist", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.28": {"line.1": {"text": "Der du keine Gottheit gl\u00e4ubest,", "tokens": ["Der", "du", "kei\u00b7ne", "Got\u00b7theit", "gl\u00e4u\u00b7best", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und bisher verblendet bist,", "tokens": ["Und", "bis\u00b7her", "ver\u00b7blen\u00b7det", "bist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wo du hier im Jrrtum bleibest,", "tokens": ["Wo", "du", "hier", "im", "Jrr\u00b7tum", "blei\u00b7best", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die\u00df Wunder nicht ermist;", "tokens": ["Und", "die\u00df", "Wun\u00b7der", "nicht", "er\u00b7mist", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "NN", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "So willt du mit Flei\u00df nichts sehen.", "tokens": ["So", "willt", "du", "mit", "Flei\u00df", "nichts", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "NN", "PIS", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Kann die\u00df von sich selbst geschehen?", "tokens": ["Kann", "die\u00df", "von", "sich", "selbst", "ge\u00b7sche\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "APPR", "PRF", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Zieht sich selbst von ungefehr", "tokens": ["Zieht", "sich", "selbst", "von", "un\u00b7ge\u00b7fehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ADV", "APPR", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Wol ein Vorhang hin und her?", "tokens": ["Wol", "ein", "Vor\u00b7hang", "hin", "und", "her", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Da\u00df die Trockenheit nicht wehre", "tokens": ["Da\u00df", "die", "Tro\u00b7cken\u00b7heit", "nicht", "weh\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PTKNEG", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die Bewegung dem Gesicht\u2019,", "tokens": ["Die", "Be\u00b7we\u00b7gung", "dem", "Ge\u00b7sicht'", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist im Auge manche R\u00f6hre", "tokens": ["Ist", "im", "Au\u00b7ge", "man\u00b7che", "R\u00f6h\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPRART", "NN", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wunderbarlich zugericht\u2019t,", "tokens": ["Wun\u00b7der\u00b7bar\u00b7lich", "zu\u00b7ge\u00b7richt't", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Welche stetig Feuchtigkeiten", "tokens": ["Wel\u00b7che", "ste\u00b7tig", "Feuch\u00b7tig\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["PWS", "ADJD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Unterm Lied\u2019 aufs Auge leiten:", "tokens": ["Un\u00b7term", "Lied'", "aufs", "Au\u00b7ge", "lei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Daher, weil es glatt verbleibt,", "tokens": ["Da\u00b7her", ",", "weil", "es", "glatt", "ver\u00b7bleibt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "KOUS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Nicht versehrt wird, noch sich reibt.", "tokens": ["Nicht", "ver\u00b7sehrt", "wird", ",", "noch", "sich", "reibt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVPP", "VAFIN", "$,", "ADV", "PRF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Da\u00df hiern\u00e4chst durch stete G\u00fcsse", "tokens": ["Da\u00df", "hier\u00b7n\u00e4chst", "durch", "ste\u00b7te", "G\u00fcs\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unser Aug\u2019 ohn\u2019 Unterla\u00df", "tokens": ["Un\u00b7ser", "Aug'", "ohn'", "Un\u00b7ter\u00b7la\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht in Thr\u00e4nen stehen m\u00fcsse;", "tokens": ["Nicht", "in", "Thr\u00e4\u00b7nen", "ste\u00b7hen", "m\u00fcs\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird ein \u00fcberfl\u00fcssigs na\u00df,", "tokens": ["Wird", "ein", "\u00fc\u00b7berf\u00b7l\u00fcs\u00b7sigs", "na\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie man es ja stetig sp\u00fcret,", "tokens": ["Wie", "man", "es", "ja", "ste\u00b7tig", "sp\u00fc\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Durch die Nase weggef\u00fchret,", "tokens": ["Durch", "die", "Na\u00b7se", "weg\u00b7ge\u00b7f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Welches, da es so verseigt,", "tokens": ["Wel\u00b7ches", ",", "da", "es", "so", "ver\u00b7seigt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "KOUS", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Eine grosse Weisheit zeigt.", "tokens": ["Ei\u00b7ne", "gros\u00b7se", "Weis\u00b7heit", "zeigt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Da\u00df auch, jedes Ding zu sehen,", "tokens": ["Da\u00df", "auch", ",", "je\u00b7des", "Ding", "zu", "se\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$,", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Welches man zu sehn gedenkt,", "tokens": ["Wel\u00b7ches", "man", "zu", "sehn", "ge\u00b7denkt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Man den Kopf nicht d\u00fcrfe drehen;", "tokens": ["Man", "den", "Kopf", "nicht", "d\u00fcr\u00b7fe", "dre\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "NN", "PTKNEG", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird das Auge selbst gelenkt", "tokens": ["Wird", "das", "Au\u00b7ge", "selbst", "ge\u00b7lenkt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Auf so wunderbare Weise,", "tokens": ["Auf", "so", "wun\u00b7der\u00b7ba\u00b7re", "Wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Unter-aufw\u00e4rts, rings im Kreise,", "tokens": ["Un\u00b7ter\u00b7auf\u00b7w\u00e4rts", ",", "rings", "im", "Krei\u00b7se", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Rechts und Links durch Muskeln, die", "tokens": ["Rechts", "und", "Links", "durch", "Mus\u00b7keln", ",", "die"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "KON", "NE", "APPR", "NN", "$,", "PRELS"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Sich bewegen sonder M\u00fch.", "tokens": ["Sich", "be\u00b7we\u00b7gen", "son\u00b7der", "M\u00fch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "VVINF", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Schaut die Weisheit und das Lieben", "tokens": ["Schaut", "die", "Weis\u00b7heit", "und", "das", "Lie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "KON", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsers Sch\u00f6pfers, der dem Licht", "tokens": ["Un\u00b7sers", "Sch\u00f6p\u00b7fers", ",", "der", "dem", "Licht"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Solch Gesetze vorgeschrieben,", "tokens": ["Solch", "Ge\u00b7set\u00b7ze", "vor\u00b7ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df es sich im Wasser bricht,", "tokens": ["Da\u00df", "es", "sich", "im", "Was\u00b7ser", "bricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df die Stralen folglich taugen,", "tokens": ["Da\u00df", "die", "Stra\u00b7len", "folg\u00b7lich", "tau\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "In dem Wasser uns\u2019rer Augen", "tokens": ["In", "dem", "Was\u00b7ser", "un\u00b7s'\u00b7rer", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Sich zu brechen: Da die Spitz\u2019", "tokens": ["Sich", "zu", "bre\u00b7chen", ":", "Da", "die", "Spitz'"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PRF", "PTKZU", "VVINF", "$.", "KOUS", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Alles zu verkleinern n\u00fctz.", "tokens": ["Al\u00b7les", "zu", "ver\u00b7klei\u00b7nern", "n\u00fctz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "PTKZU", "VVINF", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Wie sich durch des Lichtes Stralen,", "tokens": ["Wie", "sich", "durch", "des", "Lich\u00b7tes", "Stra\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch ein Glas im dunkeln Ort\u2019", "tokens": ["Durch", "ein", "Glas", "im", "dun\u00b7keln", "Ort'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Alle Bilder deutlich malen;", "tokens": ["Al\u00b7le", "Bil\u00b7der", "deut\u00b7lich", "ma\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "So begreift man alsofort,", "tokens": ["So", "be\u00b7greift", "man", "al\u00b7so\u00b7fort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df, zu diesem Zweck alleine,", "tokens": ["Da\u00df", ",", "zu", "die\u00b7sem", "Zweck", "al\u00b7lei\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "APPR", "PDAT", "NN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Eine wunderbarlich kleine", "tokens": ["Ei\u00b7ne", "wun\u00b7der\u00b7bar\u00b7lich", "klei\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJD", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Zierlich-runde schwarze Wand", "tokens": ["Zier\u00b7lich\u00b7run\u00b7de", "schwar\u00b7ze", "Wand"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "In den Augen ausgespannt.", "tokens": ["In", "den", "Au\u00b7gen", "aus\u00b7ge\u00b7spannt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Drauf viel tausend Schildereyen", "tokens": ["Drauf", "viel", "tau\u00b7send", "Schil\u00b7de\u00b7re\u00b7yen"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "ADV", "CARD", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Schneller, als der schnell\u2019ste Blitz,", "tokens": ["Schnel\u00b7ler", ",", "als", "der", "schnell'\u00b7ste", "Blitz", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sich formiren, sich zerstreuen,", "tokens": ["Sich", "for\u00b7mi\u00b7ren", ",", "sich", "zer\u00b7streu\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "$,", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und sich in der Selen Sitz", "tokens": ["Und", "sich", "in", "der", "Se\u00b7len", "Sitz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PRF", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ehe noch, eh wirs gedenken,", "tokens": ["E\u00b7he", "noch", ",", "eh", "wirs", "ge\u00b7den\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "KOUS", "PIS", "VVINF", "$,"], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Durch das kleine Nervgen sen ken,", "tokens": ["Durch", "das", "klei\u00b7ne", "Nerv\u00b7gen", "sen", "ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da denn, was so lieblich scheint,", "tokens": ["Da", "denn", ",", "was", "so", "lieb\u00b7lich", "scheint", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PRELS", "ADV", "ADJD", "VVFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.8": {"text": "Mit der Sele sich vereint.", "tokens": ["Mit", "der", "Se\u00b7le", "sich", "ver\u00b7eint", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "Sollten alle diese Sachen", "tokens": ["Soll\u00b7ten", "al\u00b7le", "die\u00b7se", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PIS", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wol von ungefehr geschehn,", "tokens": ["Wol", "von", "un\u00b7ge\u00b7fehr", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Oder, um sie nachzumachen,", "tokens": ["O\u00b7der", ",", "um", "sie", "nach\u00b7zu\u00b7ma\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUI", "PPER", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sich wol K\u00fcnstler unterstehn,", "tokens": ["Sich", "wol", "K\u00fcnst\u00b7ler", "un\u00b7ter\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sie aus Fischen, Fleisch und Speise", "tokens": ["Sie", "aus", "Fi\u00b7schen", ",", "Fleisch", "und", "Spei\u00b7se"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Auf so wunderbare Weise", "tokens": ["Auf", "so", "wun\u00b7der\u00b7ba\u00b7re", "Wei\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Zu formiren? Sehet dann", "tokens": ["Zu", "for\u00b7mi\u00b7ren", "?", "Se\u00b7het", "dann"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PTKZU", "VVINF", "$.", "VVFIN", "ADV"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "GoTTES Werk in ihnen an?", "tokens": ["GoT\u00b7TES", "Werk", "in", "ih\u00b7nen", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "Da\u00df der Sinne Kraft nicht gr\u00f6sser,", "tokens": ["Da\u00df", "der", "Sin\u00b7ne", "Kraft", "nicht", "gr\u00f6s\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Stell\u2019t ein neues Wunder dar.", "tokens": ["Stell't", "ein", "neu\u00b7es", "Wun\u00b7der", "dar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "S\u00e4hen unser\u2019 Augen besser", "tokens": ["S\u00e4\u00b7hen", "un\u00b7ser'", "Au\u00b7gen", "bes\u00b7ser"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In der N\u00e4he scharf und klar,", "tokens": ["In", "der", "N\u00e4\u00b7he", "scharf", "und", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "KON", "ADJD", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.5": {"text": "Und als durch Vergr\u00f6ss\u2019rungs-Gl\u00e4ser", "tokens": ["Und", "als", "durch", "Ver\u00b7gr\u00f6ss'\u00b7rungs\u00b7Gl\u00e4\u00b7ser"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "KOUS", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Aller Dinge klein\u2019ste Z\u00e4ser;", "tokens": ["Al\u00b7ler", "Din\u00b7ge", "klein'\u00b7ste", "Z\u00e4\u00b7ser", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Uebers\u00e4h der Augen-Stral", "tokens": ["Ue\u00b7ber\u00b7s\u00e4h", "der", "Au\u00b7gen\u00b7S\u00b7tral"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Kaum ein Sand-Korn auf einmal.", "tokens": ["Kaum", "ein", "San\u00b7dKorn", "auf", "ein\u00b7mal", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "W\u00e4ren Gegenteils die Augen", "tokens": ["W\u00e4\u00b7ren", "Ge\u00b7gen\u00b7teils", "die", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie ein Fern-Glas zugericht\u2019t;", "tokens": ["Wie", "ein", "Fern\u00b7Glas", "zu\u00b7ge\u00b7richt't", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVPP", "$."], "meter": "+-++--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "W\u00fcrd\u2019 ich zwar zu sehen taugen", "tokens": ["W\u00fcrd'", "ich", "zwar", "zu", "se\u00b7hen", "tau\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "PTKZU", "VVINF", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Manch entfern\u2019tes Sternen-Licht:", "tokens": ["Manch", "ent\u00b7fern'\u00b7tes", "Ster\u00b7nen\u00b7Licht", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Aber Sachen in der N\u00e4he,", "tokens": ["A\u00b7ber", "Sa\u00b7chen", "in", "der", "N\u00e4\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die ich itzo deutlich sehe,", "tokens": ["Die", "ich", "it\u00b7zo", "deut\u00b7lich", "se\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "W\u00fcrden, auch beym Sonnen-Schein,", "tokens": ["W\u00fcr\u00b7den", ",", "auch", "beym", "Son\u00b7nen\u00b7Schein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Dunkel und unsichtbar seyn.", "tokens": ["Dun\u00b7kel", "und", "un\u00b7sicht\u00b7bar", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VAINF", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.38": {"line.1": {"text": "Welch Ergetzen, welche Freuden", "tokens": ["Welch", "Er\u00b7get\u00b7zen", ",", "wel\u00b7che", "Freu\u00b7den"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "$,", "PWAT", "NN"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.2": {"text": "Bringt uns Menschen das Gesicht,", "tokens": ["Bringt", "uns", "Men\u00b7schen", "das", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn man das, nach langem Scheiden,", "tokens": ["Wenn", "man", "das", ",", "nach", "lan\u00b7gem", "Schei\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PDS", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was man liebet, sieht und spricht!", "tokens": ["Was", "man", "lie\u00b7bet", ",", "sieht", "und", "spricht", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Denkt, wie das Gesicht uns n\u00fctzet,", "tokens": ["Denkt", ",", "wie", "das", "Ge\u00b7sicht", "uns", "n\u00fct\u00b7zet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn\u2019s uns f\u00fcr Gefahr besch\u00fctzet,", "tokens": ["Wenn's", "uns", "f\u00fcr", "Ge\u00b7fahr", "be\u00b7sch\u00fct\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Die durch Straucheln, Sto\u00df und Fall", "tokens": ["Die", "durch", "Strau\u00b7cheln", ",", "Sto\u00df", "und", "Fall"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Uns sonst drohet\u2019 \u00fcberall.", "tokens": ["Uns", "sonst", "dro\u00b7het'", "\u00fc\u00b7be\u00b7rall", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.39": {"line.1": {"text": "Wenn wir es genau betrachten,", "tokens": ["Wenn", "wir", "es", "ge\u00b7nau", "be\u00b7trach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ist die Kraft von diesem Sinn", "tokens": ["Ist", "die", "Kraft", "von", "die\u00b7sem", "Sinn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "APPR", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit dem h\u00f6chsten Recht zu achten,", "tokens": ["Mit", "dem", "h\u00f6chs\u00b7ten", "Recht", "zu", "ach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als der Sinne K\u00f6niginn,", "tokens": ["Als", "der", "Sin\u00b7ne", "K\u00f6\u00b7ni\u00b7ginn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da ja K\u00fcnst\u2019 und Wissenschaften", "tokens": ["Da", "ja", "K\u00fcnst'", "und", "Wis\u00b7sen\u00b7schaf\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "All\u2019 an unsern Augen haften:", "tokens": ["All'", "an", "un\u00b7sern", "Au\u00b7gen", "haf\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "K\u00fcnstlich, ja gelehrt, zu seyn,", "tokens": ["K\u00fcnst\u00b7lich", ",", "ja", "ge\u00b7lehrt", ",", "zu", "seyn", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADV", "VVPP", "$,", "PTKZU", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Wirkt fast das Gesicht allein.", "tokens": ["Wirkt", "fast", "das", "Ge\u00b7sicht", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Alles w\u00fcrd\u2019 uns Menschen felen,", "tokens": ["Al\u00b7les", "w\u00fcrd'", "uns", "Men\u00b7schen", "fe\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fel\u2019t\u2019 uns Menschen das Gesicht.", "tokens": ["Fel't'", "uns", "Men\u00b7schen", "das", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ja wenn wir von ihm erz\u00e4len,", "tokens": ["Ja", "wenn", "wir", "von", "ihm", "er\u00b7z\u00e4\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "KOUS", "PPER", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df es unsers Leibes Licht,", "tokens": ["Da\u00df", "es", "un\u00b7sers", "Lei\u00b7bes", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist es wahr: doch wird man\u2019s k\u00f6nnen", "tokens": ["Ist", "es", "wahr", ":", "doch", "wird", "man's", "k\u00f6n\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKVZ", "$.", "ADV", "VAFIN", "PIS", "VMFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Gar ein Licht der Sele nennen,", "tokens": ["Gar", "ein", "Licht", "der", "Se\u00b7le", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Weil es uns, wenn man studir\u2019t,", "tokens": ["Weil", "es", "uns", ",", "wenn", "man", "stu\u00b7dir't", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "$,", "KOUS", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Auf den Weg der Weisheit f\u00fchr\u2019t.", "tokens": ["Auf", "den", "Weg", "der", "Weis\u00b7heit", "f\u00fchr'", "t."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVFIN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.41": {"line.1": {"text": "Da\u00df wir ferner durch die Augen", "tokens": ["Da\u00df", "wir", "fer\u00b7ner", "durch", "die", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In des Himmels Abgrunds-Tal", "tokens": ["In", "des", "Him\u00b7mels", "Ab\u00b7grunds\u00b7Tal"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Deutlich zu erkennen taugen", "tokens": ["Deut\u00b7lich", "zu", "er\u00b7ken\u00b7nen", "tau\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "PTKZU", "VVINF", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sonnen, sonder Ma\u00df und Zal:", "tokens": ["Son\u00b7nen", ",", "son\u00b7der", "Ma\u00df", "und", "Zal", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df wir in dem Heer der Sternen", "tokens": ["Da\u00df", "wir", "in", "dem", "Heer", "der", "Ster\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Gottes Gr\u00f6sse kennen lernen,", "tokens": ["Got\u00b7tes", "Gr\u00f6s\u00b7se", "ken\u00b7nen", "ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Ist ein Wunder, welches man", "tokens": ["Ist", "ein", "Wun\u00b7der", ",", "wel\u00b7ches", "man"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "ART", "NN", "$,", "PRELS", "PIS"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Gott nicht g\u2019nug verdanken kann.", "tokens": ["Gott", "nicht", "g'\u00b7nug", "ver\u00b7dan\u00b7ken", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "K\u00f6nnten wir es dahin bringen,", "tokens": ["K\u00f6nn\u00b7ten", "wir", "es", "da\u00b7hin", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "PAV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df man (ach da\u00df es gescheh!)", "tokens": ["Da\u00df", "man", "(", "ach", "da\u00df", "es", "ge\u00b7scheh", "!", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "$(", "XY", "KOUS", "PPER", "ADJD", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "GoTT durchs Aug\u2019 in allen Dingen", "tokens": ["GoTT", "durchs", "Aug'", "in", "al\u00b7len", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "APPRART", "NN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jmmer gegenw\u00e4rtig seh!", "tokens": ["Jm\u00b7mer", "ge\u00b7gen\u00b7w\u00e4r\u00b7tig", "seh", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Gottes Weisheit, Lieb\u2019 und St\u00e4rke", "tokens": ["Got\u00b7tes", "Weis\u00b7heit", ",", "Lieb'", "und", "St\u00e4r\u00b7ke"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Zeiget sich durch aller Werke", "tokens": ["Zei\u00b7get", "sich", "durch", "al\u00b7ler", "Wer\u00b7ke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "K\u00fcnstlichen Zusammenhang,", "tokens": ["K\u00fcnst\u00b7li\u00b7chen", "Zu\u00b7sam\u00b7men\u00b7hang", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.8": {"text": "Lieblichen Zusammenklang.", "tokens": ["Lieb\u00b7li\u00b7chen", "Zu\u00b7sam\u00b7men\u00b7klang", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}}}}}