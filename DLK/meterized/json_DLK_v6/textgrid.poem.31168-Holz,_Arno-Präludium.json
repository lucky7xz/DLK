{"textgrid.poem.31168": {"metadata": {"author": {"name": "Holz, Arno", "birth": "N.A.", "death": "N.A."}, "title": "Pr\u00e4ludium", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dieses lachende Pr\u00e4ludium,", "tokens": ["Die\u00b7ses", "la\u00b7chen\u00b7de", "Pr\u00e4\u00b7lu\u00b7di\u00b7um", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Lachend sei es dedicirt", "tokens": ["La\u00b7chend", "sei", "es", "de\u00b7di\u00b7cirt"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "VVPP"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Euch, ihr wohlverbohrten Ritter", "tokens": ["Euch", ",", "ihr", "wohl\u00b7ver\u00b7bohr\u00b7ten", "Rit\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Vom romantisch blauen Strumpfband", "tokens": ["Vom", "ro\u00b7man\u00b7tisch", "blau\u00b7en", "Strumpf\u00b7band"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "ADJD", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und vom klassischen Kothurn.", "tokens": ["Und", "vom", "klas\u00b7si\u00b7schen", "Ko\u00b7thurn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Euch und allen andern windgen,", "tokens": ["Euch", "und", "al\u00b7len", "an\u00b7dern", "wind\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PIAT", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hyperschlauen Kritifatzkis,", "tokens": ["Hy\u00b7per\u00b7schlau\u00b7en", "Kri\u00b7ti\u00b7fatz\u00b7kis", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Die, zum Zeichen, dass sie's lasen,", "tokens": ["Die", ",", "zum", "Zei\u00b7chen", ",", "dass", "sie's", "la\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "APPRART", "NN", "$,", "KOUS", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In dies saubre Exemplar", "tokens": ["In", "dies", "saub\u00b7re", "Ex\u00b7emp\u00b7lar"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDS", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Eselsohren falzen werden.", "tokens": ["E\u00b7sel\u00b7soh\u00b7ren", "fal\u00b7zen", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVINF", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Bitte sich nicht zu geniren,", "tokens": ["Bit\u00b7te", "sich", "nicht", "zu", "ge\u00b7ni\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Dass ich dies mein kleines Epos", "tokens": ["Dass", "ich", "dies", "mein", "klei\u00b7nes", "E\u00b7pos"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PDS", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht gleich, zunft- und zopfgerecht,", "tokens": ["Nicht", "gleich", ",", "zunft", "und", "zopf\u00b7ge\u00b7recht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "$,", "TRUNC", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Philologisch pr\u00e4ludirte:", "tokens": ["Phi\u00b7lo\u00b7lo\u00b7gisch", "pr\u00e4\u00b7lu\u00b7dir\u00b7te", ":"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "\u00bbnenne mir den Mann, o Muse!\u00ab", "tokens": ["\u00bb", "nen\u00b7ne", "mir", "den", "Mann", ",", "o", "Mu\u00b7se", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PPER", "ART", "NN", "$,", "FM", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Armer klassischer College!", "tokens": ["Ar\u00b7mer", "klas\u00b7si\u00b7scher", "Col\u00b7le\u00b7ge", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.5": {"line.1": {"text": "Streu, wie unser Grossohm Hiob", "tokens": ["Streu", ",", "wie", "un\u00b7ser", "Gros\u00b7sohm", "Hiob"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PWAV", "PPOSAT", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Asche Dir auf deine Platte,", "tokens": ["A\u00b7sche", "Dir", "auf", "dei\u00b7ne", "Plat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn die Welt hat sich gedreht", "tokens": ["Denn", "die", "Welt", "hat", "sich", "ge\u00b7dreht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "PRF", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und mit Wolfgang Goethe starb", "tokens": ["Und", "mit", "Wolf\u00b7gang", "Goe\u00b7the", "starb"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NE", "NE", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "L\u00e4ngst der Letzte der Olympier.", "tokens": ["L\u00e4ngst", "der", "Letz\u00b7te", "der", "O\u00b7lym\u00b7pier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Andre Zeiten, andre Lieder,", "tokens": ["And\u00b7re", "Zei\u00b7ten", ",", "and\u00b7re", "Lie\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Andre Lieder, andre Menschen,", "tokens": ["And\u00b7re", "Lie\u00b7der", ",", "and\u00b7re", "Men\u00b7schen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und von Wien bis nach Paris", "tokens": ["Und", "von", "Wi\u00b7en", "bis", "nach", "Pa\u00b7ris"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NE", "ADV", "APPR", "NE"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "F\u00e4hrt man heutzutag per Blitzzug", "tokens": ["F\u00e4hrt", "man", "heut\u00b7zu\u00b7tag", "per", "Blitz\u00b7zug"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Noch nicht lumpge siebzehn Stunden.", "tokens": ["Noch", "nicht", "lump\u00b7ge", "sieb\u00b7zehn", "Stun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "VVFIN", "CARD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Zwar ein Dichter, der wie ich", "tokens": ["Zwar", "ein", "Dich\u00b7ter", ",", "der", "wie", "ich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "PRELS", "KOKOM", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Schon von jeher kein Talent,", "tokens": ["Schon", "von", "je\u00b7her", "kein", "Ta\u00b7lent", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADV", "PIAT", "NN", "$,"], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.3": {"text": "Und, getreu der goldnen Fahne,", "tokens": ["Und", ",", "ge\u00b7treu", "der", "gold\u00b7nen", "Fah\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADJD", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die mir roth zu H\u00e4upten flattert,", "tokens": ["Die", "mir", "roth", "zu", "H\u00e4up\u00b7ten", "flat\u00b7tert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Zukunftsroth und gleichheitspredgend,", "tokens": ["Zu\u00b7kunfts\u00b7roth", "und", "gleich\u00b7heits\u00b7pred\u00b7gend", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "Warn ich meine Concurrenten", "tokens": ["Warn", "ich", "mei\u00b7ne", "Con\u00b7cur\u00b7ren\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PPOSAT", "NN"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.7": {"text": "Vor der unsoliden Firma", "tokens": ["Vor", "der", "un\u00b7so\u00b7li\u00b7den", "Fir\u00b7ma"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "Der Homer und Compagnie.", "tokens": ["Der", "Ho\u00b7mer", "und", "Com\u00b7pag\u00b7nie", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "KON", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Ja, mein Herz, ich muss Dich seufzend,", "tokens": ["Ja", ",", "mein", "Herz", ",", "ich", "muss", "Dich", "seuf\u00b7zend", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPOSAT", "NN", "$,", "PPER", "VMFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Seufzend, wenn ich daran denke,", "tokens": ["Seuf\u00b7zend", ",", "wenn", "ich", "da\u00b7ran", "den\u00b7ke", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "PPER", "PAV", "VVFIN", "$,"], "meter": "+-++-+--", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Dass auch ich ein Versfaiseur nur,", "tokens": ["Dass", "auch", "ich", "ein", "Ver\u00b7sfai\u00b7seur", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Oeffentlich hier denunciren:", "tokens": ["Oef\u00b7fent\u00b7lich", "hier", "de\u00b7nun\u00b7ci\u00b7ren", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Dein Credit beginnt zu wanken,", "tokens": ["Dein", "Cre\u00b7dit", "be\u00b7ginnt", "zu", "wan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Deine Curse stehen schlecht,", "tokens": ["Dei\u00b7ne", "Cur\u00b7se", "ste\u00b7hen", "schlecht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und dein Renommee ward schartig", "tokens": ["Und", "dein", "Re\u00b7nom\u00b7mee", "ward", "schar\u00b7tig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie ein sch\u00e4biger Cylinder.", "tokens": ["Wie", "ein", "sch\u00e4\u00b7bi\u00b7ger", "Cy\u00b7lin\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Ach, es ist nur gar zu wahr,", "tokens": ["Ach", ",", "es", "ist", "nur", "gar", "zu", "wahr", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VAFIN", "ADV", "ADV", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dein ambrosisch gr\u00fcner Lorbeer", "tokens": ["Dein", "am\u00b7bro\u00b7sisch", "gr\u00fc\u00b7ner", "Lor\u00b7beer"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJD", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Fing mit Harold \u2013 Byron schon", "tokens": ["Fing", "mit", "Ha\u00b7rold", "\u2013", "By\u00b7ron", "schon"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "APPR", "NE", "$(", "NE", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ganz bedenklich an zu welken,", "tokens": ["Ganz", "be\u00b7denk\u00b7lich", "an", "zu", "wel\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und in meinen Augen bist Du", "tokens": ["Und", "in", "mei\u00b7nen", "Au\u00b7gen", "bist", "Du"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VAFIN", "PPER"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Nur ein ganz profaner Mensch", "tokens": ["Nur", "ein", "ganz", "pro\u00b7fa\u00b7ner", "Mensch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADV", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und als solcher wiederum", "tokens": ["Und", "als", "sol\u00b7cher", "wie\u00b7de\u00b7rum"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "KOUS", "PIS", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Nur der erste aller blinden", "tokens": ["Nur", "der", "ers\u00b7te", "al\u00b7ler", "blin\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "PIAT", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "B\u00e4nkels\u00e4nger Griechenlands.", "tokens": ["B\u00e4n\u00b7kel\u00b7s\u00e4n\u00b7ger", "Grie\u00b7chen\u00b7lands", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Ja, mein Hirn ist ein Rebell,", "tokens": ["Ja", ",", "mein", "Hirn", "ist", "ein", "Re\u00b7bell", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPOSAT", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und wie alle diese Leute,", "tokens": ["Und", "wie", "al\u00b7le", "die\u00b7se", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die auf Thron und Altar pfeifen,", "tokens": ["Die", "auf", "Thron", "und", "Al\u00b7tar", "pfei\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bl\u00e4ht es frech sich auf und pfeift auch", "tokens": ["Bl\u00e4ht", "es", "frech", "sich", "auf", "und", "pfeift", "auch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "PRF", "PTKVZ", "KON", "VVFIN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Auf das schulstaubtrockne Dogma", "tokens": ["Auf", "das", "schul\u00b7staub\u00b7trock\u00b7ne", "Dog\u00b7ma"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Klassischer Autorit\u00e4t", "tokens": ["Klas\u00b7si\u00b7scher", "Au\u00b7to\u00b7ri\u00b7t\u00e4t"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Immer noch durch unsre K\u00f6pfe", "tokens": ["Im\u00b7mer", "noch", "durch", "uns\u00b7re", "K\u00f6p\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Taumeln schwarz bechapeauclacquet", "tokens": ["Tau\u00b7meln", "schwarz", "be\u00b7ch\u00b7a\u00b7pea\u00b7u\u00b7clac\u00b7quet"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJD", "VVFIN"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Sich die G\u00f6tter des Olymp,", "tokens": ["Sich", "die", "G\u00f6t\u00b7ter", "des", "O\u00b7lymp", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und wenn Rothschild mein Cousin w\u00e4r,", "tokens": ["Und", "wenn", "Roth\u00b7schild", "mein", "Cou\u00b7sin", "w\u00e4r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NN", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Liessen heute noch die \u00bbTimes\u00ab", "tokens": ["Lies\u00b7sen", "heu\u00b7te", "noch", "die", "\u00bb", "Ti\u00b7mes", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ART", "$(", "NE", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Einen Aufruf los zur Gr\u00fcndung", "tokens": ["Ei\u00b7nen", "Auf\u00b7ruf", "los", "zur", "Gr\u00fcn\u00b7dung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Eines internationalen", "tokens": ["Ei\u00b7nes", "in\u00b7ter\u00b7na\u00b7ti\u00b7o\u00b7na\u00b7len"], "token_info": ["word", "word"], "pos": ["PIS", "VVINF"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Antimuseistenclubs.", "tokens": ["An\u00b7ti\u00b7mus\u00b7eis\u00b7ten\u00b7clubs", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.13": {"line.1": {"text": "H\u00e4tte ein gewisser Herwegh,", "tokens": ["H\u00e4t\u00b7te", "ein", "ge\u00b7wis\u00b7ser", "Her\u00b7wegh", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der ein grosser Demokrat", "tokens": ["Der", "ein", "gros\u00b7ser", "De\u00b7mo\u00b7krat"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ein gr\u00f6ssrer Dichter war,", "tokens": ["Und", "ein", "gr\u00f6ss\u00b7rer", "Dich\u00b7ter", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Ihn nicht meuchlings schon verausgabt,", "tokens": ["Ihn", "nicht", "meuch\u00b7lings", "schon", "ver\u00b7aus\u00b7gabt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Hier an dieser sch\u00f6nen Stelle", "tokens": ["Hier", "an", "die\u00b7ser", "sch\u00f6\u00b7nen", "Stel\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Br\u00e4ch ich aus in den Naturlaut:", "tokens": ["Br\u00e4ch", "ich", "aus", "in", "den", "Na\u00b7tur\u00b7laut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u00bbraum, ihr Herrn, dem Fl\u00fcgelschlag", "tokens": ["\u00bb", "raum", ",", "ihr", "Herrn", ",", "dem", "Fl\u00fc\u00b7gel\u00b7schlag"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "NN", "$,", "PPOSAT", "NN", "$,", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Einer freien Seele!\u00ab", "tokens": ["Ei\u00b7ner", "frei\u00b7en", "See\u00b7le", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.14": {"line.1": {"text": "Poesien f\u00fcr Penn\u00e4ler", "tokens": ["Poe\u00b7si\u00b7en", "f\u00fcr", "Pen\u00b7n\u00e4\u00b7ler"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPR", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Sind bereits genug gedrechselt;", "tokens": ["Sind", "be\u00b7reits", "ge\u00b7nug", "ge\u00b7drech\u00b7selt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Siehe hier das Gros der Werke", "tokens": ["Sie\u00b7he", "hier", "das", "Gros", "der", "Wer\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unsrer deutschen Dioskuren \u2013", "tokens": ["Uns\u00b7rer", "deut\u00b7schen", "Dios\u00b7ku\u00b7ren", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Nomina odiosa sunt!", "tokens": ["No\u00b7mi\u00b7na", "o\u00b7dio\u00b7sa", "sunt", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Aber vollends lasst mich schweigen", "tokens": ["A\u00b7ber", "vol\u00b7lends", "lasst", "mich", "schwei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von den l\u00e4cherlichen Gr\u00f6ssen", "tokens": ["Von", "den", "l\u00e4\u00b7cher\u00b7li\u00b7chen", "Gr\u00f6s\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihres l\u00e4cherlichen Nachtrabs!", "tokens": ["Ih\u00b7res", "l\u00e4\u00b7cher\u00b7li\u00b7chen", "Nach\u00b7trabs", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Graf von Platen war ihr Mogul,", "tokens": ["Graf", "von", "Pla\u00b7ten", "war", "ihr", "Mo\u00b7gul", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Und die griechische Schablone", "tokens": ["Und", "die", "grie\u00b7chi\u00b7sche", "Scha\u00b7blo\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "R\u00fcpelte jahrzehntelang", "tokens": ["R\u00fc\u00b7pel\u00b7te", "jahr\u00b7zehn\u00b7te\u00b7lang"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "Ihre l\u00e4ngstversteinten Formen", "tokens": ["Ih\u00b7re", "l\u00e4ngst\u00b7ver\u00b7stein\u00b7ten", "For\u00b7men"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ueber jeden deutschen Quark.", "tokens": ["Ue\u00b7ber", "je\u00b7den", "deut\u00b7schen", "Quark", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "O, ich hasse dies Gez\u00fccht", "tokens": ["O", ",", "ich", "has\u00b7se", "dies", "Ge\u00b7z\u00fccht"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PPER", "VVFIN", "PDS", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Phrasenschwammiger Banausen,", "tokens": ["Phra\u00b7sen\u00b7schwam\u00b7mi\u00b7ger", "Ba\u00b7nau\u00b7sen", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Das nach jedem Wort sich einen", "tokens": ["Das", "nach", "je\u00b7dem", "Wort", "sich", "ei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "APPR", "PIAT", "NN", "PRF", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Idealen Kloss ins Maul pfropft!", "tokens": ["I\u00b7dea\u00b7len", "Kloss", "ins", "Maul", "pfropft", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Aber ach, mein braves Deutschland", "tokens": ["A\u00b7ber", "ach", ",", "mein", "bra\u00b7ves", "Deutschland"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "XY", "$,", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "War ja leider das beliebte", "tokens": ["War", "ja", "lei\u00b7der", "das", "be\u00b7lieb\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eldorado der Philister", "tokens": ["El\u00b7do\u00b7ra\u00b7do", "der", "Phi\u00b7lis\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["NE", "ART", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Schon seit anno Tacitus!", "tokens": ["Schon", "seit", "an\u00b7no", "Ta\u00b7ci\u00b7tus", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "NE", "$."], "meter": "+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.19": {"line.1": {"text": "Seit der alte Herr von Hutten,", "tokens": ["Seit", "der", "al\u00b7te", "Herr", "von", "Hut\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von der Meute seiner braven", "tokens": ["Von", "der", "Meu\u00b7te", "sei\u00b7ner", "bra\u00b7ven"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zeitgen\u00f6ssischen Philister", "tokens": ["Zeit\u00b7ge\u00b7n\u00f6s\u00b7si\u00b7schen", "Phi\u00b7lis\u00b7ter"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie ein Hirsch ins Holz gehetzt,", "tokens": ["Wie", "ein", "Hirsch", "ins", "Holz", "ge\u00b7hetzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Auf der Ufenau verreckt ist,", "tokens": ["Auf", "der", "U\u00b7fe\u00b7nau", "ver\u00b7reckt", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hat nur ein Mensch hier in Deutschland", "tokens": ["Hat", "nur", "ein", "Mensch", "hier", "in", "Deutschland"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADV", "APPR", "NE"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Tabak, Bier und Kohl verdaut,", "tokens": ["Ta\u00b7bak", ",", "Bier", "und", "Kohl", "ver\u00b7daut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Der, bis in den Tod sich selbst treu,", "tokens": ["Der", ",", "bis", "in", "den", "Tod", "sich", "selbst", "treu", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "APPR", "ART", "NN", "PRF", "ADV", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.9": {"text": "Ein lebendiger Protest war", "tokens": ["Ein", "le\u00b7ben\u00b7di\u00b7ger", "Pro\u00b7test", "war"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.10": {"text": "Gegen jedes l\u00e4cherliche,", "tokens": ["Ge\u00b7gen", "je\u00b7des", "l\u00e4\u00b7cher\u00b7li\u00b7che", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Kn\u00f6cherne Schablonenthum.", "tokens": ["Kn\u00f6\u00b7cher\u00b7ne", "Scha\u00b7blo\u00b7nen\u00b7thum", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}}, "stanza.20": {"line.1": {"text": "Fern vom Rhein, wo er sein erstes", "tokens": ["Fern", "vom", "Rhein", ",", "wo", "er", "sein", "ers\u00b7tes"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "APPRART", "NE", "$,", "PWAV", "PPER", "PPOSAT", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kinderh\u00f6schenpaar zerrissen,", "tokens": ["Kin\u00b7der\u00b7h\u00f6\u00b7schen\u00b7paar", "zer\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Fern in Frankreich liegt sein Grab,", "tokens": ["Fern", "in", "Fran\u00b7kreich", "liegt", "sein", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und von Immergr\u00fcn umwoben", "tokens": ["Und", "von", "Im\u00b7mer\u00b7gr\u00fcn", "um\u00b7wo\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Schaut es hoch her vom Montmartre", "tokens": ["Schaut", "es", "hoch", "her", "vom", "Mont\u00b7mar\u00b7tre"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "ADV", "APPRART", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Auf die Weltstadt an der Seine.", "tokens": ["Auf", "die", "Welt\u00b7stadt", "an", "der", "Sei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NE", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "O, ich weiss, wie einst die Mitwelt", "tokens": ["O", ",", "ich", "weiss", ",", "wie", "einst", "die", "Mit\u00b7welt"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PPER", "VVFIN", "$,", "PWAV", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vipernz\u00fcngig ihn begeifert;", "tokens": ["Vi\u00b7pern\u00b7z\u00fcn\u00b7gig", "ihn", "be\u00b7gei\u00b7fert", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Kann doch selber heutzutag noch", "tokens": ["Kann", "doch", "sel\u00b7ber", "heut\u00b7zu\u00b7tag", "noch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ADV", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihm kein Dunkelmann vergessen,", "tokens": ["Ihm", "kein", "Dun\u00b7kel\u00b7mann", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dass sein rothes Dichterherz nicht", "tokens": ["Dass", "sein", "ro\u00b7thes", "Dich\u00b7ter\u00b7herz", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "PTKNEG"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Pauvre wie ein pauvres Talglicht,", "tokens": ["Pauv\u00b7re", "wie", "ein", "pauv\u00b7res", "Talg\u00b7licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Sondern gross und welterleuchtend,", "tokens": ["Son\u00b7dern", "gross", "und", "wel\u00b7ter\u00b7leuch\u00b7tend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "KON", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Golden wie die Sonne brannte.", "tokens": ["Gol\u00b7den", "wie", "die", "Son\u00b7ne", "brann\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Ach, die L\u00f6sung dieses R\u00e4thsels,", "tokens": ["Ach", ",", "die", "L\u00f6\u00b7sung", "die\u00b7ses", "R\u00e4th\u00b7sels", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ART", "NN", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Das durchaus kein Ph\u00e4nomen,", "tokens": ["Das", "durc\u00b7haus", "kein", "Ph\u00e4\u00b7no\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "L\u00e4sst sich leicht in Worte fassen:", "tokens": ["L\u00e4sst", "sich", "leicht", "in", "Wor\u00b7te", "fas\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADJD", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Heinrich Heine war kein Stockfisch,", "tokens": ["Hein\u00b7rich", "Hei\u00b7ne", "war", "kein", "Stock\u00b7fisch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Heinrich Heine war ein Mensch!", "tokens": ["Hein\u00b7rich", "Hei\u00b7ne", "war", "ein", "Mensch", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Schellenfroh aus seinen Nestern,", "tokens": ["Schel\u00b7len\u00b7froh", "aus", "sei\u00b7nen", "Nes\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Drin es lichtscheu sich verkrochen,", "tokens": ["Drin", "es", "licht\u00b7scheu", "sich", "ver\u00b7kro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADJD", "PRF", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schreckte er das nachtverliebte", "tokens": ["Schreck\u00b7te", "er", "das", "nacht\u00b7ver\u00b7lieb\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PDS", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Fledermausgez\u00fccht der Vorzeit,", "tokens": ["Fle\u00b7der\u00b7maus\u00b7ge\u00b7z\u00fccht", "der", "Vor\u00b7zeit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und sein blutender Messias", "tokens": ["Und", "sein", "blu\u00b7ten\u00b7der", "Mes\u00b7si\u00b7as"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "War das dreimal heilge Recht!", "tokens": ["War", "das", "drei\u00b7mal", "heil\u00b7ge", "Recht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Ja, Hosianna! rief er jubelnd,", "tokens": ["Ja", ",", "Ho\u00b7si\u00b7an\u00b7na", "!", "rief", "er", "ju\u00b7belnd", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NE", "$.", "VVFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Seine Hymnen pr\u00e4ludirten", "tokens": ["Sei\u00b7ne", "Hym\u00b7nen", "pr\u00e4\u00b7lu\u00b7dir\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Den Befreiungskrieg der Menschheit,", "tokens": ["Den", "Be\u00b7frei\u00b7ungs\u00b7krieg", "der", "Menschheit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und in seinem Herzen schliefen", "tokens": ["Und", "in", "sei\u00b7nem", "Her\u00b7zen", "schlie\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Schon des neuen Weltprogramms", "tokens": ["Schon", "des", "neu\u00b7en", "Welt\u00b7pro\u00b7gramms"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Goldne Zukunftsparagraphen.", "tokens": ["Gold\u00b7ne", "Zu\u00b7kunfts\u00b7pa\u00b7ra\u00b7gra\u00b7phen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.25": {"line.1": {"text": "Zwar sein armer K\u00f6rper war", "tokens": ["Zwar", "sein", "ar\u00b7mer", "K\u00f6r\u00b7per", "war"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Abgemergelt wie ein Schatten,", "tokens": ["Ab\u00b7ge\u00b7mer\u00b7gelt", "wie", "ein", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber seine goldne Seele", "tokens": ["A\u00b7ber", "sei\u00b7ne", "gold\u00b7ne", "See\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Strotzte nur so von Gesundheit.", "tokens": ["Strotz\u00b7te", "nur", "so", "von", "Ge\u00b7sund\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Fern im lachenden Paris,", "tokens": ["Fern", "im", "la\u00b7chen\u00b7den", "Pa\u00b7ris", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "ADJA", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Eingepfercht in ihre graue,", "tokens": ["Ein\u00b7ge\u00b7pfercht", "in", "ih\u00b7re", "grau\u00b7e", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Muffige Matratzengruft,", "tokens": ["Muf\u00b7fi\u00b7ge", "Ma\u00b7trat\u00b7zen\u00b7gruft", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Rang sie singend wie ein Schwan", "tokens": ["Rang", "sie", "sin\u00b7gend", "wie", "ein", "Schwan"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "KOKOM", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Jahrelang mit ihrem Tode,", "tokens": ["Jah\u00b7re\u00b7lang", "mit", "ih\u00b7rem", "To\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Denn die Weltlust war ihr Spielzeug", "tokens": ["Denn", "die", "Welt\u00b7lust", "war", "ihr", "Spiel\u00b7zeug"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und ihr Liebling war das Meer.", "tokens": ["Und", "ihr", "Lieb\u00b7ling", "war", "das", "Meer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Doch das Schwimmbassin des Nereus", "tokens": ["Doch", "das", "Schwimm\u00b7bas\u00b7sin", "des", "Ne\u00b7reus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "War von jeher schon ein \u00e4usserst", "tokens": ["War", "von", "je\u00b7her", "schon", "ein", "\u00e4us\u00b7serst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ADV", "ADV", "ART", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Komplizirter Mechanismus.", "tokens": ["Kom\u00b7pli\u00b7zir\u00b7ter", "Me\u00b7cha\u00b7nis\u00b7mus", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.28": {"line.1": {"text": "Neben Perlen z\u00fcchtet es", "tokens": ["Ne\u00b7ben", "Per\u00b7len", "z\u00fcch\u00b7tet", "es"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Auch noch ganz gemeine Schlangen.", "tokens": ["Auch", "noch", "ganz", "ge\u00b7mei\u00b7ne", "Schlan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "L\u00e4ngst versoffne Seemannsprime", "tokens": ["L\u00e4ngst", "ver\u00b7soff\u00b7ne", "See\u00b7mann\u00b7spri\u00b7me"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00e4lzt es gleichfalls tief im Bauch rum,", "tokens": ["W\u00e4lzt", "es", "gleich\u00b7falls", "tief", "im", "Bauch", "rum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "APPRART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die Traumwelt der Atlantis", "tokens": ["Und", "die", "Traum\u00b7welt", "der", "At\u00b7lan\u00b7tis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NE"], "meter": "--++-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Hart, bedeckt von Gold und Seetang,", "tokens": ["Hart", ",", "be\u00b7deckt", "von", "Gold", "und", "See\u00b7tang", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVPP", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ihrer k\u00fcnftgen Auferstehung.", "tokens": ["Ih\u00b7rer", "k\u00fcnft\u00b7gen", "Auf\u00b7er\u00b7ste\u00b7hung", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Um den Wendekreis des Krebses", "tokens": ["Um", "den", "Wen\u00b7de\u00b7kreis", "des", "Kreb\u00b7ses"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUI", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00e4lzt der Teifun vor sich her", "tokens": ["W\u00e4lzt", "der", "Tei\u00b7fun", "vor", "sich", "her"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "APPR", "PRF", "APZR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Chinas r\u00e4uberische Dschunken,", "tokens": ["Chi\u00b7nas", "r\u00e4u\u00b7be\u00b7ri\u00b7sche", "Dschun\u00b7ken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und am Strand von Norderney", "tokens": ["Und", "am", "Strand", "von", "Nor\u00b7der\u00b7ney"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Baden Deutschlands Aphroditen", "tokens": ["Ba\u00b7den", "Deutschlands", "A\u00b7phro\u00b7di\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["NN", "NE", "NE"], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.6": {"text": "Ihre semmelblonden Glieder.", "tokens": ["Ih\u00b7re", "sem\u00b7mel\u00b7blon\u00b7den", "Glie\u00b7der", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Ja, ein K\u00fcnstler ist der Weltgeist", "tokens": ["Ja", ",", "ein", "K\u00fcnst\u00b7ler", "ist", "der", "Welt\u00b7geist"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ART", "NN", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und das Meer sein Meisterwerk!", "tokens": ["Und", "das", "Meer", "sein", "Meis\u00b7ter\u00b7werk", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Silbergrau durch seine rothen,", "tokens": ["Sil\u00b7ber\u00b7grau", "durch", "sei\u00b7ne", "ro\u00b7then", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Brennenden Corallenw\u00e4lder", "tokens": ["Bren\u00b7nen\u00b7den", "Co\u00b7ral\u00b7len\u00b7w\u00e4l\u00b7der"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Tummelt sich der flinke St\u00f6r,", "tokens": ["Tum\u00b7melt", "sich", "der", "flin\u00b7ke", "St\u00f6r", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und versunkne St\u00e4dte l\u00e4uten", "tokens": ["Und", "ver\u00b7sunk\u00b7ne", "St\u00e4d\u00b7te", "l\u00e4u\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Oft aus seinen blauen Fluthen", "tokens": ["Oft", "aus", "sei\u00b7nen", "blau\u00b7en", "Flut\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ihre tr\u00e4umerischen Glocken", "tokens": ["Ih\u00b7re", "tr\u00e4u\u00b7me\u00b7ri\u00b7schen", "Glo\u00b7cken"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "M\u00e4rchenhaft ins Abendroth.", "tokens": ["M\u00e4r\u00b7chen\u00b7haft", "ins", "A\u00b7ben\u00b7droth", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Doch zur Zeit der Aequinoctien", "tokens": ["Doch", "zur", "Zeit", "der", "A\u00b7e\u00b7qui\u00b7noc\u00b7ti\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "ART", "NN"], "meter": "--+-+--+--", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wird es hungrig wie ein W\u00e4rwolf,", "tokens": ["Wird", "es", "hung\u00b7rig", "wie", "ein", "W\u00e4r\u00b7wolf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Und die jungen Fischerfrauen", "tokens": ["Und", "die", "jun\u00b7gen", "Fi\u00b7scher\u00b7frau\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schrein dann n\u00e4chtlich oft im Traum auf.", "tokens": ["Schrein", "dann", "n\u00e4cht\u00b7lich", "oft", "im", "Traum", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJD", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Mit dem Herzen eines Dichters,", "tokens": ["Mit", "dem", "Her\u00b7zen", "ei\u00b7nes", "Dich\u00b7ters", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der sein Lebtag nicht nur Thee soff,", "tokens": ["Der", "sein", "Leb\u00b7tag", "nicht", "nur", "Thee", "soff", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "PTKNEG", "ADV", "NN", "VVFIN", "$,"], "meter": "+-+--++-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Sondern manchmal auch frivol", "tokens": ["Son\u00b7dern", "manch\u00b7mal", "auch", "fri\u00b7vol"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Veritablen Rum hineingoss,", "tokens": ["Ve\u00b7ri\u00b7tab\u00b7len", "Rum", "hin\u00b7ein\u00b7goss", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist es \u00e4hnlich meist bestellt.", "tokens": ["Ist", "es", "\u00e4hn\u00b7lich", "meist", "be\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "Heine war ein solcher Dichter;", "tokens": ["Hei\u00b7ne", "war", "ein", "sol\u00b7cher", "Dich\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und wenn dann und wann sein Magen,", "tokens": ["Und", "wenn", "dann", "und", "wann", "sein", "Ma\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "KON", "PWAV", "PPOSAT", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Statt des oben schon erw\u00e4hnten", "tokens": ["Statt", "des", "o\u00b7ben", "schon", "er\u00b7w\u00e4hn\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ART", "ADV", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Obligaten \u00bbThees mit Rum\u00ab,", "tokens": ["Ob\u00b7li\u00b7ga\u00b7ten", "\u00bb", "Thees", "mit", "Rum", "\u00ab", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$(", "FM.la", "FM.la", "FM.la", "$(", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "\u00bbrum mit Thee\u00ab verconsumirte:", "tokens": ["\u00bb", "rum", "mit", "Thee", "\u00ab", "ver\u00b7con\u00b7su\u00b7mir\u00b7te", ":"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ADV", "APPR", "NN", "$(", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nun, wer will ihm das verdenken?", "tokens": ["Nun", ",", "wer", "will", "ihm", "das", "ver\u00b7den\u00b7ken", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VMFIN", "PPER", "PDS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "Spucken m\u00f6gen auf sein Grab", "tokens": ["Spu\u00b7cken", "m\u00f6\u00b7gen", "auf", "sein", "Grab"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dreimal alle alten Jungfern:", "tokens": ["Drei\u00b7mal", "al\u00b7le", "al\u00b7ten", "Jung\u00b7fern", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Heilig war ihm seine Liebe,", "tokens": ["Hei\u00b7lig", "war", "ihm", "sei\u00b7ne", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Heilig war ihm auch sein Hass!", "tokens": ["Hei\u00b7lig", "war", "ihm", "auch", "sein", "Hass", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "Sein Geschlecht war ein erlauchtes,", "tokens": ["Sein", "Ge\u00b7schlecht", "war", "ein", "er\u00b7lauch\u00b7tes", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die Bl\u00fcthen seines Stammbaums", "tokens": ["Und", "die", "Bl\u00fc\u00b7then", "sei\u00b7nes", "Stamm\u00b7baums"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sind die Sterne ihre V\u00f6lker.", "tokens": ["Sind", "die", "Ster\u00b7ne", "ih\u00b7re", "V\u00f6l\u00b7ker", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "Aristophanes, der Grieche,", "tokens": ["A\u00b7ris\u00b7to\u00b7pha\u00b7nes", ",", "der", "Grie\u00b7che", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "War sein vielgeliebter Ahnherr,", "tokens": ["War", "sein", "viel\u00b7ge\u00b7lieb\u00b7ter", "Ahn\u00b7herr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Miguel de Saavedra", "tokens": ["Mi\u00b7guel", "de", "Saa\u00b7ve\u00b7dra"], "token_info": ["word", "word", "word"], "pos": ["NE", "NE", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und der Doctor Rabelais", "tokens": ["Und", "der", "Doc\u00b7tor", "Ra\u00b7be\u00b7lais"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NE"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.5": {"text": "Waren gleichfalls seine Ahnen.", "tokens": ["Wa\u00b7ren", "gleich\u00b7falls", "sei\u00b7ne", "Ah\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.39": {"line.1": {"text": "Doch wozu, o Publikum,", "tokens": ["Doch", "wo\u00b7zu", ",", "o", "Pub\u00b7li\u00b7kum", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWAV", "$,", "FM", "FM", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Geb ich heut, wo Dahn und Ebers", "tokens": ["Geb", "ich", "heut", ",", "wo", "Dahn", "und", "E\u00b7bers"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$,", "PWAV", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Siegreich mit mir concurriren,", "tokens": ["Sieg\u00b7reich", "mit", "mir", "con\u00b7cur\u00b7ri\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dir ein Privatissimum", "tokens": ["Dir", "ein", "Pri\u00b7va\u00b7tis\u00b7si\u00b7mum"], "token_info": ["word", "word", "word"], "pos": ["PPER", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "In der Kunst der Langenweile?", "tokens": ["In", "der", "Kunst", "der", "Lan\u00b7gen\u00b7wei\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Ach, die Werke jener M\u00e4nner", "tokens": ["Ach", ",", "die", "Wer\u00b7ke", "je\u00b7ner", "M\u00e4n\u00b7ner"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "ART", "NN", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kennst Du kaum dem Namen nach,", "tokens": ["Kennst", "Du", "kaum", "dem", "Na\u00b7men", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn ein einzger Pattitriller", "tokens": ["Denn", "ein", "einz\u00b7ger", "Pat\u00b7tit\u00b7ril\u00b7ler"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Gilt Dir mehr als tausend Mozarts.", "tokens": ["Gilt", "Dir", "mehr", "als", "tau\u00b7send", "Mo\u00b7zarts", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "KOKOM", "CARD", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.41": {"line.1": {"text": "Strickstrumpffl\u00fcchtig rettete", "tokens": ["Strick\u00b7strumpf\u00b7fl\u00fcch\u00b7tig", "ret\u00b7te\u00b7te"], "token_info": ["word", "word"], "pos": ["ADJD", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Vor dem Schreckregime der Trikots", "tokens": ["Vor", "dem", "Schreck\u00b7re\u00b7gi\u00b7me", "der", "Tri\u00b7kots"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Die Vernunft aus dem Theater", "tokens": ["Die", "Ver\u00b7nunft", "aus", "dem", "The\u00b7a\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sich ins Land der Botokuden,", "tokens": ["Sich", "ins", "Land", "der", "Bo\u00b7to\u00b7ku\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPRART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn das neunzehnte Jahrhundert", "tokens": ["Denn", "das", "neun\u00b7zehn\u00b7te", "Jahr\u00b7hun\u00b7dert"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Applaudirt wie ein Cretin", "tokens": ["Ap\u00b7plau\u00b7dirt", "wie", "ein", "Cre\u00b7tin"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "KOKOM", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Nur Ballets und Operetten.", "tokens": ["Nur", "Bal\u00b7lets", "und", "O\u00b7per\u00b7et\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.42": {"line.1": {"text": "Wer wird heut auch, wo der Golddurst", "tokens": ["Wer", "wird", "heut", "auch", ",", "wo", "der", "Gold\u00b7durst"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VAFIN", "ADV", "ADV", "$,", "PWAV", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wie ein Moloch sich gerirt,", "tokens": ["Wie", "ein", "Mo\u00b7loch", "sich", "ge\u00b7rirt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PRF", "VVPP", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Hamlet oder Faust studiren?", "tokens": ["Ham\u00b7let", "o\u00b7der", "Faust", "stu\u00b7di\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.43": {"line.1": {"text": "Lieber schluckt man Casanovas", "tokens": ["Lie\u00b7ber", "schluckt", "man", "Ca\u00b7sa\u00b7no\u00b7vas"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PIS", "NE"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Elegante Sauerein!", "tokens": ["E\u00b7leg\u00b7an\u00b7te", "Sau\u00b7er\u00b7ein", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.44": {"line.1": {"text": "Ja, ein L\u00fcstling ist der Zeitgeist,", "tokens": ["Ja", ",", "ein", "L\u00fcst\u00b7ling", "ist", "der", "Zeit\u00b7geist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ein gealterter Rou\u00e9,", "tokens": ["Ein", "ge\u00b7al\u00b7ter\u00b7ter", "Rou\u00e9", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Und in jedem neuen Buch,", "tokens": ["Und", "in", "je\u00b7dem", "neu\u00b7en", "Buch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Das ihm eine Kernnatur", "tokens": ["Das", "ihm", "ei\u00b7ne", "Kern\u00b7na\u00b7tur"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPER", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Zornig lachend an den Kopf wirft,", "tokens": ["Zor\u00b7nig", "la\u00b7chend", "an", "den", "Kopf", "wirft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wittert er versteckte Zoten.", "tokens": ["Wit\u00b7tert", "er", "ver\u00b7steck\u00b7te", "Zo\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.45": {"line.1": {"text": "Seine alternde Maitresse,", "tokens": ["Sei\u00b7ne", "al\u00b7tern\u00b7de", "Mai\u00b7tres\u00b7se", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.2": {"text": "Die Geborene von Welt,", "tokens": ["Die", "Ge\u00b7bo\u00b7re\u00b7ne", "von", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,"], "meter": "--+---+", "measure": "anapaest.init"}, "line.3": {"text": "Thut es selbstverst\u00e4ndlich dito.", "tokens": ["Thut", "es", "selbst\u00b7ver\u00b7st\u00e4nd\u00b7lich", "di\u00b7to", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ADV", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.46": {"line.1": {"text": "Jeden kantigen Charakter,", "tokens": ["Je\u00b7den", "kan\u00b7ti\u00b7gen", "Cha\u00b7rak\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der es l\u00e4sterlich verschm\u00e4ht", "tokens": ["Der", "es", "l\u00e4s\u00b7ter\u00b7lich", "ver\u00b7schm\u00e4ht"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPER", "ADJD", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Honig ihr ums Maul zu schmieren,", "tokens": ["Ho\u00b7nig", "ihr", "ums", "Maul", "zu", "schmie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "W\u00fchlt sie skeptisch um und um,", "tokens": ["W\u00fchlt", "sie", "skep\u00b7tisch", "um", "und", "um", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie's mit einem St\u00fcckchen Erde", "tokens": ["Wie's", "mit", "ei\u00b7nem", "St\u00fcck\u00b7chen", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wohl nach W\u00fcrmern thut ein Maulwurf.", "tokens": ["Wohl", "nach", "W\u00fcr\u00b7mern", "thut", "ein", "Maul\u00b7wurf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.47": {"line.1": {"text": "Grosser Zeitgenosse Emile,", "tokens": ["Gros\u00b7ser", "Zeit\u00b7ge\u00b7nos\u00b7se", "E\u00b7mi\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NE", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Dich auch, Dich hat sie verl\u00e4stert,", "tokens": ["Dich", "auch", ",", "Dich", "hat", "sie", "ver\u00b7l\u00e4s\u00b7tert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "PPER", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und der Shakespeare des Romans", "tokens": ["Und", "der", "Sha\u00b7ke\u00b7spe\u00b7a\u00b7re", "des", "Ro\u00b7mans"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN"], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Ward zum Dichter der Kloake.", "tokens": ["Ward", "zum", "Dich\u00b7ter", "der", "Kloa\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "ART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.48": {"line.1": {"text": "Doch was thut's? Wenn auch die alten", "tokens": ["Doch", "was", "thut's", "?", "Wenn", "auch", "die", "al\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PWS", "VVFIN", "$.", "KOUS", "ADV", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weiber beiderlei Geschlechts", "tokens": ["Wei\u00b7ber", "bei\u00b7der\u00b7lei", "Ge\u00b7schlechts"], "token_info": ["word", "word", "word"], "pos": ["NN", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Pr\u00fcde sich vor Dir bekreuzgen,", "tokens": ["Pr\u00fc\u00b7de", "sich", "vor", "Dir", "be\u00b7kr\u00b7euz\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "APPR", "PPER", "VVINF", "$,"], "meter": "+---+--+-", "measure": "trochaic.tri.relaxed"}, "line.4": {"text": "Dein Genie reckt seine Glieder,", "tokens": ["Dein", "Ge\u00b7nie", "reckt", "sei\u00b7ne", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Seine giftgeschwollnen Stichler", "tokens": ["Sei\u00b7ne", "gift\u00b7ge\u00b7schwoll\u00b7nen", "Stich\u00b7ler"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Fallen von ihm wie die Fliegen", "tokens": ["Fal\u00b7len", "von", "ihm", "wie", "die", "Flie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PPER", "KOKOM", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und sein Haupt ragt in die Wolken!", "tokens": ["Und", "sein", "Haupt", "ragt", "in", "die", "Wol\u00b7ken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.49": {"line.1": {"text": "Zola, Jbsen, Leo Tolstoi,", "tokens": ["Zo\u00b7la", ",", "Jb\u00b7sen", ",", "Leo", "Tol\u00b7stoi", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NE", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Eine Welt liegt in den Worten,", "tokens": ["Ei\u00b7ne", "Welt", "liegt", "in", "den", "Wor\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eine, die noch nicht verfault,", "tokens": ["Ei\u00b7ne", ",", "die", "noch", "nicht", "ver\u00b7fault", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine, die noch kerngesund ist!", "tokens": ["Ei\u00b7ne", ",", "die", "noch", "kern\u00b7ge\u00b7sund", "ist", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "ADV", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.50": {"line.1": {"text": "Klammert euch, ihr lieben Leutchen,", "tokens": ["Klam\u00b7mert", "euch", ",", "ihr", "lie\u00b7ben", "Leut\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Klammert euch nur an die Sch\u00fcrze", "tokens": ["Klam\u00b7mert", "euch", "nur", "an", "die", "Sch\u00fcr\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Einer l\u00e4ngst verlotterten,", "tokens": ["Ei\u00b7ner", "l\u00e4ngst", "ver\u00b7lot\u00b7ter\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "ADV", "VVFIN", "$,"], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "Abgetakelten Aesthetik:", "tokens": ["Ab\u00b7ge\u00b7ta\u00b7kel\u00b7ten", "A\u00b7e\u00b7sthe\u00b7tik", ":"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+--+---", "measure": "trochaic.tri.relaxed"}, "line.5": {"text": "Unsre Welt ist nicht mehr klassisch,", "tokens": ["Uns\u00b7re", "Welt", "ist", "nicht", "mehr", "klas\u00b7sisch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Unsre Welt ist nicht romantisch,", "tokens": ["Uns\u00b7re", "Welt", "ist", "nicht", "ro\u00b7man\u00b7tisch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Unsre Welt ist nur modern!", "tokens": ["Uns\u00b7re", "Welt", "ist", "nur", "mo\u00b7dern", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.51": {"line.1": {"text": "Und der Mensch, der sie mit tausend,", "tokens": ["Und", "der", "Mensch", ",", "der", "sie", "mit", "tau\u00b7send", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "PPER", "APPR", "CARD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Abertausend Eisenarmen", "tokens": ["A\u00b7bert\u00b7au\u00b7send", "Ei\u00b7sen\u00b7ar\u00b7men"], "token_info": ["word", "word"], "pos": ["KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Erdverlangend wild umschn\u00fcrt h\u00e4lt,", "tokens": ["Erd\u00b7ver\u00b7lan\u00b7gend", "wild", "um\u00b7schn\u00fcrt", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VVPP", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist er gleichfalls nicht modern?", "tokens": ["Ist", "er", "gleich\u00b7falls", "nicht", "mo\u00b7dern", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.52": {"line.1": {"text": "Glaubt er wirklich noch an eure", "tokens": ["Glaubt", "er", "wirk\u00b7lich", "noch", "an", "eu\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "ADV", "APPR", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Abgedroschnen Ammenm\u00e4rchen", "tokens": ["Ab\u00b7ge\u00b7drosc\u00b7hnen", "Am\u00b7men\u00b7m\u00e4r\u00b7chen"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und dass schwarz soviel wie weiss", "tokens": ["Und", "dass", "schwarz", "so\u00b7viel", "wie", "weiss"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADJD", "PIAT", "KOKOM", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und dass zwei mal zwei gleich f\u00fcnf ist?", "tokens": ["Und", "dass", "zwei", "mal", "zwei", "gleich", "f\u00fcnf", "ist", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "CARD", "ADV", "CARD", "ADV", "CARD", "VAFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.53": {"line.1": {"text": "Macht euch auf, ihr Neunmalweisen,", "tokens": ["Macht", "euch", "auf", ",", "ihr", "Neun\u00b7mal\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKVZ", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schleicht euch n\u00e4chtlich durch die Gassen,", "tokens": ["Schleicht", "euch", "n\u00e4cht\u00b7lich", "durch", "die", "Gas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Pilgert tags durch die Fabriken", "tokens": ["Pil\u00b7gert", "tags", "durch", "die", "Fab\u00b7ri\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und den Denkern schaut ins Hirn!", "tokens": ["Und", "den", "Den\u00b7kern", "schaut", "ins", "Hirn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.54": {"line.1": {"text": "Thut's und wagt es dann zu l\u00e4ugnen,", "tokens": ["Thut's", "und", "wagt", "es", "dann", "zu", "l\u00e4ug\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dass der Mensch sich, den die Vorzeit", "tokens": ["Dass", "der", "Mensch", "sich", ",", "den", "die", "Vor\u00b7zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PRF", "$,", "PRELS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie ein Thier ins Joch geknutet,", "tokens": ["Wie", "ein", "Thier", "ins", "Joch", "ge\u00b7knu\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Endlich sehnt, ein Mensch zu werden!", "tokens": ["End\u00b7lich", "sehnt", ",", "ein", "Mensch", "zu", "wer\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ART", "NN", "PTKZU", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.55": {"line.1": {"text": "Ausgetreten hat der Tr\u00e4umer", "tokens": ["Aus\u00b7ge\u00b7tre\u00b7ten", "hat", "der", "Tr\u00e4u\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Endlich seine Kinderschuhe,", "tokens": ["End\u00b7lich", "sei\u00b7ne", "Kin\u00b7der\u00b7schu\u00b7he", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und vor seinen trunknen Blicken", "tokens": ["Und", "vor", "sei\u00b7nen", "trunk\u00b7nen", "Bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wiegt sich lachend wie ein Eiland,", "tokens": ["Wiegt", "sich", "la\u00b7chend", "wie", "ein", "Ei\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Das das Weltmeer gr\u00fcn umschaukelt,", "tokens": ["Das", "das", "Welt\u00b7meer", "gr\u00fcn", "um\u00b7schau\u00b7kelt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Seine m\u00e4rchenhafte Zukunft.", "tokens": ["Sei\u00b7ne", "m\u00e4r\u00b7chen\u00b7haf\u00b7te", "Zu\u00b7kunft", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.56": {"line.1": {"text": "Durch die W\u00e4lder Kaliforniens", "tokens": ["Durch", "die", "W\u00e4l\u00b7der", "Ka\u00b7li\u00b7for\u00b7ni\u00b7ens"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Schn\u00fcffelt wie ein Riesenwurm", "tokens": ["Schn\u00fcf\u00b7felt", "wie", "ein", "Rie\u00b7sen\u00b7wurm"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "KOKOM", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Feuerschnaubend sich sein Dampfthier,", "tokens": ["Feu\u00b7er\u00b7schnau\u00b7bend", "sich", "sein", "Dampf\u00b7thier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und ums Cap der guten Hoffnung", "tokens": ["Und", "ums", "Cap", "der", "gu\u00b7ten", "Hoff\u00b7nung"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Segeln seine Panzerschiffe.", "tokens": ["Se\u00b7geln", "sei\u00b7ne", "Pan\u00b7zer\u00b7schif\u00b7fe", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.57": {"line.1": {"text": "Seine Telegraphendr\u00e4hte", "tokens": ["Sei\u00b7ne", "Te\u00b7le\u00b7gra\u00b7phen\u00b7dr\u00e4h\u00b7te"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ueberbr\u00fccken wie ein Wasser", "tokens": ["Ue\u00b7berb\u00b7r\u00fc\u00b7cken", "wie", "ein", "Was\u00b7ser"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KOKOM", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Delhi's gr\u00fcne Palmenwipfel,", "tokens": ["Del\u00b7hi's", "gr\u00fc\u00b7ne", "Pal\u00b7men\u00b7wip\u00b7fel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und durchs ewige Eis des Nordpols", "tokens": ["Und", "durchs", "e\u00b7wi\u00b7ge", "Eis", "des", "Nord\u00b7pols"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN", "ART", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Blitzen weisslich die Gebeine", "tokens": ["Blit\u00b7zen", "weiss\u00b7lich", "die", "Ge\u00b7bei\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADJD", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Seiner neusten M\u00e4rtyrer.", "tokens": ["Sei\u00b7ner", "neus\u00b7ten", "M\u00e4r\u00b7ty\u00b7rer", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.58": {"line.1": {"text": "Tausend goldne Sacramente,", "tokens": ["Tau\u00b7send", "gold\u00b7ne", "Sa\u00b7cra\u00b7men\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "$,"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.2": {"text": "Die Kleinodien seiner Kindheit,", "tokens": ["Die", "Klein\u00b7o\u00b7di\u00b7en", "sei\u00b7ner", "Kind\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sind zersprungen wie ein Glas,", "tokens": ["Sind", "zer\u00b7sprun\u00b7gen", "wie", "ein", "Glas", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die alte, taube Nusswand", "tokens": ["Und", "die", "al\u00b7te", ",", "tau\u00b7be", "Nuss\u00b7wand"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "ADJA", "$,", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Einer abgelebten Kunstform", "tokens": ["Ei\u00b7ner", "ab\u00b7ge\u00b7leb\u00b7ten", "Kunst\u00b7form"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.6": {"text": "Sollte frech sie \u00fcberdauern?", "tokens": ["Soll\u00b7te", "frech", "sie", "\u00fc\u00b7berd\u00b7au\u00b7ern", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.59": {"line.1": {"text": "Deklamirt nur, ihr Poeten,", "tokens": ["De\u00b7kla\u00b7mirt", "nur", ",", "ihr", "Po\u00b7et\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Eure lyrischen Tiraden,", "tokens": ["Eu\u00b7re", "ly\u00b7ri\u00b7schen", "Ti\u00b7ra\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Eure wortverbohrte Nichtswelt,", "tokens": ["Eu\u00b7re", "wort\u00b7ver\u00b7bohr\u00b7te", "Nichts\u00b7welt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Mit euch selber geht sie unter!", "tokens": ["Mit", "euch", "sel\u00b7ber", "geht", "sie", "un\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "VVFIN", "PPER", "APPR", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.60": {"line.1": {"text": "Doch das thut nichts. Eine neue", "tokens": ["Doch", "das", "thut", "nichts", ".", "Ei\u00b7ne", "neu\u00b7e"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PDS", "VVFIN", "PIS", "$.", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Taucht schon l\u00e4chelnd aus den Wassern,", "tokens": ["Taucht", "schon", "l\u00e4\u00b7chelnd", "aus", "den", "Was\u00b7sern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die Wasser gehen schwanger", "tokens": ["Und", "die", "Was\u00b7ser", "ge\u00b7hen", "schwan\u00b7ger"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Noch mit hunderttausend andern.", "tokens": ["Noch", "mit", "hun\u00b7dert\u00b7tau\u00b7send", "an\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "CARD", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.61": {"line.1": {"text": "H\u00e4tte dies mein kleines Carmen", "tokens": ["H\u00e4t\u00b7te", "dies", "mein", "klei\u00b7nes", "Car\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PDS", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nicht so wohlgeschliffne Krallen,", "tokens": ["Nicht", "so", "wohl\u00b7ge\u00b7schliff\u00b7ne", "Kral\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die so unbarmherzig spitz sind,", "tokens": ["Die", "so", "un\u00b7barm\u00b7her\u00b7zig", "spitz", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ich verbr\u00e4che sans fa\u00e7on", "tokens": ["Ich", "ver\u00b7br\u00e4\u00b7che", "sans", "fa\u00e7on"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "FM", "FM"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Folgende Apostrophe:", "tokens": ["Fol\u00b7gen\u00b7de", "A\u00b7pos\u00b7tro\u00b7phe", ":"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.62": {"line.1": {"text": "\u00bbdu, mein Lied, um das mein Herz", "tokens": ["\u00bb", "du", ",", "mein", "Lied", ",", "um", "das", "mein", "Herz"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PPER", "$,", "PPOSAT", "NN", "$,", "KOUI", "ART", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Lieblich klang wie eine Glocke,", "tokens": ["Lieb\u00b7lich", "klang", "wie", "ei\u00b7ne", "Glo\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schwing Dich auf, mein goldner Liebling,", "tokens": ["Schwing", "Dich", "auf", ",", "mein", "gold\u00b7ner", "Lieb\u00b7ling", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schwing Dich auf wie eine Taube,", "tokens": ["Schwing", "Dich", "auf", "wie", "ei\u00b7ne", "Tau\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Bis die Wasser sich verlaufen!", "tokens": ["Bis", "die", "Was\u00b7ser", "sich", "ver\u00b7lau\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.63": {"line.1": {"text": "Melancholisch um mein Haupt", "tokens": ["Me\u00b7lan\u00b7cho\u00b7lisch", "um", "mein", "Haupt"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Schwingt die urweltschwangre Sintflut", "tokens": ["Schwingt", "die", "ur\u00b7welt\u00b7schwang\u00b7re", "Sint\u00b7flut"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihre dunklen Rabenfl\u00fcgel,", "tokens": ["Ih\u00b7re", "dunk\u00b7len", "Ra\u00b7ben\u00b7fl\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und durchs Schleusenmeer des Himmels", "tokens": ["Und", "durchs", "Schleu\u00b7sen\u00b7meer", "des", "Him\u00b7mels"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Br\u00fcllt noch immer das alte Chaos!", "tokens": ["Br\u00fcllt", "noch", "im\u00b7mer", "das", "al\u00b7te", "Chaos", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.64": {"line.1": {"text": "Ach, und doch! Durch mein Gehirn", "tokens": ["Ach", ",", "und", "doch", "!", "Durch", "mein", "Ge\u00b7hirn"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "KON", "ADV", "$.", "APPR", "PPOSAT", "NN"], "meter": "+-++--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Huscht es wie von goldnen Lichtern,", "tokens": ["Huscht", "es", "wie", "von", "gold\u00b7nen", "Lich\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOKOM", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die eingelullte Sehnsucht", "tokens": ["Und", "die", "ein\u00b7ge\u00b7lull\u00b7te", "Sehn\u00b7sucht"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Nach den h\u00e4ngenden G\u00e4rten der Sonne", "tokens": ["Nach", "den", "h\u00e4n\u00b7gen\u00b7den", "G\u00e4r\u00b7ten", "der", "Son\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.5": {"text": "Wachte weinend wieder auf!", "tokens": ["Wach\u00b7te", "wei\u00b7nend", "wie\u00b7der", "auf", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.65": {"line.1": {"text": "Hat mein Herzschlag mich betrogen?", "tokens": ["Hat", "mein", "Herz\u00b7schlag", "mich", "be\u00b7tro\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tauchen die ersten gr\u00fcnen Zacken", "tokens": ["Tau\u00b7chen", "die", "ers\u00b7ten", "gr\u00fc\u00b7nen", "Za\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "ADJA", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Jener heissersehnten Neuwelt,", "tokens": ["Je\u00b7ner", "heis\u00b7ser\u00b7sehn\u00b7ten", "Neu\u00b7welt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tauchen sie l\u00e4chelnd endlich auf?", "tokens": ["Tau\u00b7chen", "sie", "l\u00e4\u00b7chelnd", "end\u00b7lich", "auf", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ADV", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.66": {"line.1": {"text": "Eine Welt f\u00fcr einen Oelzweig!", "tokens": ["Ei\u00b7ne", "Welt", "f\u00fcr", "ei\u00b7nen", "O\u00b7el\u00b7zweig", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.67": {"line.1": {"text": "Drum, mein Lied, um das mein Herz", "tokens": ["Drum", ",", "mein", "Lied", ",", "um", "das", "mein", "Herz"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "$,", "PPOSAT", "NN", "$,", "KOUI", "ART", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Lieblich klang wie eine Glocke,", "tokens": ["Lieb\u00b7lich", "klang", "wie", "ei\u00b7ne", "Glo\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schwing Dich auf, mein goldner Liebling,", "tokens": ["Schwing", "Dich", "auf", ",", "mein", "gold\u00b7ner", "Lieb\u00b7ling", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schwing Dich auf wie eine Taube,", "tokens": ["Schwing", "Dich", "auf", "wie", "ei\u00b7ne", "Tau\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Bis die Wasser sich verlaufen!\u00ab", "tokens": ["Bis", "die", "Was\u00b7ser", "sich", "ver\u00b7lau\u00b7fen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "VVPP", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.68": {"line.1": {"text": "Doch dergleichen wohlfrisirte", "tokens": ["Doch", "derg\u00b7lei\u00b7chen", "wohl\u00b7fri\u00b7sir\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["KON", "PIS", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Taschenspielerst\u00fcckchen sind mir", "tokens": ["Ta\u00b7schen\u00b7spie\u00b7ler\u00b7st\u00fcck\u00b7chen", "sind", "mir"], "token_info": ["word", "word", "word"], "pos": ["NN", "VAFIN", "PPER"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Gottseidank zu abgedroschen,", "tokens": ["Gott\u00b7sei\u00b7dank", "zu", "ab\u00b7ge\u00b7dro\u00b7schen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und mein urwaldstruppig Lied", "tokens": ["Und", "mein", "ur\u00b7wald\u00b7strup\u00b7pig", "Lied"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist nichts wenger als ein T\u00e4ubchen!", "tokens": ["Ist", "nichts", "wen\u00b7ger", "als", "ein", "T\u00e4ub\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PIS", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.69": {"line.1": {"text": "Nein! Die f\u00f6hnumbr\u00fcllten Tr\u00fcmmer", "tokens": ["Nein", "!", "Die", "f\u00f6h\u00b7num\u00b7br\u00fcll\u00b7ten", "Tr\u00fcm\u00b7mer"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$.", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eurer l\u00e4ngst verkrachten Welt", "tokens": ["Eu\u00b7rer", "l\u00e4ngst", "ver\u00b7krach\u00b7ten", "Welt"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADV", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Liess es sonnenfeuertrunken", "tokens": ["Liess", "es", "son\u00b7nen\u00b7feu\u00b7er\u00b7trun\u00b7ken"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Meertief unter sich versinken", "tokens": ["Meer\u00b7tief", "un\u00b7ter", "sich", "ver\u00b7sin\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und verlor sich in den Himmel.", "tokens": ["Und", "ver\u00b7lor", "sich", "in", "den", "Him\u00b7mel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.70": {"line.1": {"text": "Fl\u00fcgelstolz, ein kleiner Kondor,", "tokens": ["Fl\u00fc\u00b7gel\u00b7stolz", ",", "ein", "klei\u00b7ner", "Kon\u00b7dor", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Schwebt's nun \u00fcber seiner lieben,", "tokens": ["Schwebt's", "nun", "\u00fc\u00b7ber", "sei\u00b7ner", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "PPOSAT", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jungen Sonnenaufgangswelt,", "tokens": ["Jun\u00b7gen", "Son\u00b7nen\u00b7auf\u00b7gangs\u00b7welt", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und zum Aerger aller griechisch", "tokens": ["Und", "zum", "A\u00b7er\u00b7ger", "al\u00b7ler", "grie\u00b7chisch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "PIAT", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Radebrechenden Philister", "tokens": ["Ra\u00b7de\u00b7bre\u00b7chen\u00b7den", "Phi\u00b7lis\u00b7ter"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Schmettert's dort wie eine Lerche", "tokens": ["Schmet\u00b7tert's", "dort", "wie", "ei\u00b7ne", "Ler\u00b7che"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "KOKOM", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Ueberm\u00fctig seinen Triller:", "tokens": ["Ue\u00b7ber\u00b7m\u00fc\u00b7tig", "sei\u00b7nen", "Tril\u00b7ler", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.71": {"line.1": {"text": "\u00bbzola, Jbsen, Leo Tolstoi,", "tokens": ["\u00bb", "zo\u00b7la", ",", "Jb\u00b7sen", ",", "Leo", "Tol\u00b7stoi", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "NE", "$,", "NE", "$,", "NE", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Eine Welt liegt in den Worten,", "tokens": ["Ei\u00b7ne", "Welt", "liegt", "in", "den", "Wor\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eine, die noch nicht verfault,", "tokens": ["Ei\u00b7ne", ",", "die", "noch", "nicht", "ver\u00b7fault", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine, die noch kerngesund ist!\u00ab", "tokens": ["Ei\u00b7ne", ",", "die", "noch", "kern\u00b7ge\u00b7sund", "ist", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "$,", "PRELS", "ADV", "ADJD", "VAFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.72": {"line.1": {"text": "So! Bis hierher und nicht weiter!", "tokens": ["So", "!", "Bis", "hier\u00b7her", "und", "nicht", "wei\u00b7ter", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "APPR", "PAV", "KON", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.73": {"line.1": {"text": "Lachend rief ich's, und die Feder", "tokens": ["La\u00b7chend", "rief", "ich's", ",", "und", "die", "Fe\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PIS", "$,", "KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Stiess ich tief ins Tintenfass.", "tokens": ["Stiess", "ich", "tief", "ins", "Tin\u00b7ten\u00b7fass", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.74": {"line.1": {"text": "Fern am Biertisch harrte schon", "tokens": ["Fern", "am", "Bier\u00b7tisch", "harr\u00b7te", "schon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPRART", "NN", "VVFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Das Trifolium meiner Freunde,", "tokens": ["Das", "Tri\u00b7fo\u00b7li\u00b7um", "mei\u00b7ner", "Freun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und im Duftkreis einer braunen", "tokens": ["Und", "im", "Duft\u00b7kreis", "ei\u00b7ner", "brau\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sobetitelten Havannah", "tokens": ["So\u00b7be\u00b7ti\u00b7tel\u00b7ten", "Ha\u00b7van\u00b7nah"], "token_info": ["word", "word"], "pos": ["NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "L\u00e4sst sich's ja, wie jeder selbst weiss,", "tokens": ["L\u00e4sst", "sich's", "ja", ",", "wie", "je\u00b7der", "selbst", "weiss", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "$,", "PWAV", "PIS", "ADV", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Ganz vortrefflich H\u00fctten baun!", "tokens": ["Ganz", "vor\u00b7treff\u00b7lich", "H\u00fct\u00b7ten", "baun", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.75": {"line.1": {"text": "Selbstverst\u00e4ndlich gab mein Opus,", "tokens": ["Selbst\u00b7ver\u00b7st\u00e4nd\u00b7lich", "gab", "mein", "O\u00b7pus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Das ich lachend ihnen vortrug,", "tokens": ["Das", "ich", "la\u00b7chend", "ih\u00b7nen", "vor\u00b7trug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADJD", "PPER", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Stoff zu einer Diskussion.", "tokens": ["Stoff", "zu", "ei\u00b7ner", "Dis\u00b7kus\u00b7si\u00b7on", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.76": {"line.1": {"text": "L\u00e4ngst verrostete Gewaffen", "tokens": ["L\u00e4ngst", "ver\u00b7ros\u00b7te\u00b7te", "Ge\u00b7waf\u00b7fen"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aus dem R\u00fcstzeug der Aesthetik", "tokens": ["Aus", "dem", "R\u00fcst\u00b7zeug", "der", "A\u00b7e\u00b7sthe\u00b7tik"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Wurden wieder blank geputzt,", "tokens": ["Wur\u00b7den", "wie\u00b7der", "blank", "ge\u00b7putzt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die k\u00f6stlichsten Sophismen", "tokens": ["Und", "die", "k\u00f6st\u00b7lichs\u00b7ten", "So\u00b7phis\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.5": {"text": "Bissen wie die jungen Hechte", "tokens": ["Bis\u00b7sen", "wie", "die", "jun\u00b7gen", "Hech\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sich vergn\u00fcgt in ihren Schwanz.", "tokens": ["Sich", "ver\u00b7gn\u00fcgt", "in", "ih\u00b7ren", "Schwanz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.77": {"line.1": {"text": "Doch was half's! Am Ende gaben", "tokens": ["Doch", "was", "ha\u00b7lf's", "!", "Am", "En\u00b7de", "ga\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PWS", "VAFIN", "$.", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie sich kleinlaut mir gefangen,", "tokens": ["Sie", "sich", "klein\u00b7laut", "mir", "ge\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+++-+-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Und die schnurgerade Klassik", "tokens": ["Und", "die", "schnur\u00b7ge\u00b7ra\u00b7de", "Klas\u00b7sik"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Fiel nicht minder gl\u00e4nzend durch", "tokens": ["Fiel", "nicht", "min\u00b7der", "gl\u00e4n\u00b7zend", "durch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "ADV", "ADJD", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Als die winklige Romantik.", "tokens": ["Als", "die", "wink\u00b7li\u00b7ge", "Ro\u00b7man\u00b7tik", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.78": {"line.1": {"text": "Nur zu meiner neuen Welt,", "tokens": ["Nur", "zu", "mei\u00b7ner", "neu\u00b7en", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Zu dem neuen Evangelium,", "tokens": ["Zu", "dem", "neu\u00b7en", "E\u00b7van\u00b7ge\u00b7li\u00b7um", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Das aus Frankreich her und Russland", "tokens": ["Das", "aus", "Fran\u00b7kreich", "her", "und", "Russ\u00b7land"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "APPR", "NE", "PTKVZ", "KON", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Unsrer Kunst gepredigt wird,", "tokens": ["Uns\u00b7rer", "Kunst", "ge\u00b7pre\u00b7digt", "wird", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Konnten sie sich nicht bekehren,", "tokens": ["Konn\u00b7ten", "sie", "sich", "nicht", "be\u00b7keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und das Kleeblatt opponirte", "tokens": ["Und", "das", "Klee\u00b7blatt", "op\u00b7po\u00b7nir\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Gegen die Verherrlichung", "tokens": ["Ge\u00b7gen", "die", "Ver\u00b7herr\u00b7li\u00b7chung"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Zola's, Jbsen's, Leo Tolstoi's.", "tokens": ["Zo\u00b7la's", ",", "Jb\u00b7sen's", ",", "Leo", "Tol\u00b7stoi'", "s."], "token_info": ["word", "punct", "word", "punct", "word", "word", "abbreviation"], "pos": ["NE", "$,", "NE", "$,", "FM.la", "FM.la", "FM.la"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.79": {"line.1": {"text": "\u00bbwenn Du ihre Welt so lieb hast,\u00ab", "tokens": ["\u00bb", "wenn", "Du", "ih\u00b7re", "Welt", "so", "lieb", "hast", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "PPOSAT", "NN", "ADV", "ADJD", "VAFIN", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Replicirten die drei K\u00e4uze,", "tokens": ["Re\u00b7pli\u00b7cir\u00b7ten", "die", "drei", "K\u00e4u\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbnun, so tritt sie doch mit F\u00fcssen!", "tokens": ["\u00bb", "nun", ",", "so", "tritt", "sie", "doch", "mit", "F\u00fcs\u00b7sen", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.80": {"line.1": {"text": "\u00bbaus der Vogelperspektive", "tokens": ["\u00bb", "aus", "der", "Vo\u00b7gel\u00b7per\u00b7spek\u00b7ti\u00b7ve"], "token_info": ["punct", "word", "word", "word"], "pos": ["$(", "APPR", "ART", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Sieht ein D\u00fcngerhaufen schliesslich", "tokens": ["Sieht", "ein", "D\u00fcn\u00b7ger\u00b7hau\u00b7fen", "schliess\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aehnlich wie ein Weizenfeld aus.", "tokens": ["A\u00b7ehn\u00b7lich", "wie", "ein", "Wei\u00b7zen\u00b7feld", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.81": {"line.1": {"text": "Willst Du ihre goldnen Fr\u00fcchte,", "tokens": ["Willst", "Du", "ih\u00b7re", "gold\u00b7nen", "Fr\u00fcch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die wie Pomeranzen lachen,", "tokens": ["Die", "wie", "Po\u00b7me\u00b7ran\u00b7zen", "la\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "KOKOM", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Dir nicht einmal n\u00e4her ansehn?", "tokens": ["Dir", "nicht", "ein\u00b7mal", "n\u00e4\u00b7her", "an\u00b7sehn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "ADJD", "VVINF", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.82": {"line.1": {"text": "Ach, am Ende sind sie giftig,", "tokens": ["Ach", ",", "am", "En\u00b7de", "sind", "sie", "gif\u00b7tig", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "APPRART", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Giftig wie die ganze Welt,", "tokens": ["Gif\u00b7tig", "wie", "die", "gan\u00b7ze", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die sie farbig \u00fcberschaukeln?", "tokens": ["Die", "sie", "far\u00b7big", "\u00fc\u00b7bersc\u00b7hau\u00b7keln", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.83": {"line.1": {"text": "Geh, Du bist ein J\u00fcnger Plato's,", "tokens": ["Geh", ",", "Du", "bist", "ein", "J\u00fcn\u00b7ger", "Pla\u00b7to's", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "ART", "NN", "NE", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "So ein Wolkenkukuksheimer,", "tokens": ["So", "ein", "Wol\u00b7ken\u00b7ku\u00b7kuks\u00b7hei\u00b7mer", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und scharwenzelst um sie her,", "tokens": ["Und", "schar\u00b7wen\u00b7zelst", "um", "sie", "her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Wie ein bl\u00f6der Schmetterling,", "tokens": ["Wie", "ein", "bl\u00f6\u00b7der", "Schmet\u00b7ter\u00b7ling", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Der um eine Rose t\u00e4ndelt!", "tokens": ["Der", "um", "ei\u00b7ne", "Ro\u00b7se", "t\u00e4n\u00b7delt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.84": {"line.1": {"text": "Ergel, wenn Du wirklich auf Dein", "tokens": ["Er\u00b7gel", ",", "wenn", "Du", "wirk\u00b7lich", "auf", "Dein"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "PPER", "ADJD", "APPR", "PPOSAT"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Neues Evangelium\u00ab schw\u00f6rst,", "tokens": ["Neu\u00b7es", "E\u00b7van\u00b7ge\u00b7li\u00b7um", "\u00ab", "schw\u00f6rst", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$(", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "\u00bbnun dann brocke Deine Verse", "tokens": ["\u00bb", "nun", "dann", "bro\u00b7cke", "Dei\u00b7ne", "Ver\u00b7se"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Nicht in seine Prosasuppe.", "tokens": ["Nicht", "in", "sei\u00b7ne", "Pro\u00b7sa\u00b7sup\u00b7pe", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.85": {"line.1": {"text": "Schl\u00e4ngle klug mit dem Notizbuch,", "tokens": ["Schl\u00e4ng\u00b7le", "klug", "mit", "dem", "No\u00b7tiz\u00b7buch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Wie ein j\u00fcdischer Reporter,", "tokens": ["Wie", "ein", "j\u00fc\u00b7di\u00b7scher", "Re\u00b7por\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dich durchs Gassenmeer der Grossstadt", "tokens": ["Dich", "durchs", "Gas\u00b7sen\u00b7meer", "der", "Gross\u00b7stadt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und edire Jahr f\u00fcr Jahr,", "tokens": ["Und", "e\u00b7di\u00b7re", "Jahr", "f\u00fcr", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Ein gedruckter Photograph,", "tokens": ["Ein", "ge\u00b7druck\u00b7ter", "Pho\u00b7to\u00b7graph", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Realistische Romane.", "tokens": ["Re\u00b7a\u00b7lis\u00b7ti\u00b7sche", "Ro\u00b7ma\u00b7ne", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.86": {"line.1": {"text": "Reime, Rhythmen und was sonst noch", "tokens": ["Rei\u00b7me", ",", "Rhyth\u00b7men", "und", "was", "sonst", "noch"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "PWS", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dich an Versen so entz\u00fcckt,", "tokens": ["Dich", "an", "Ver\u00b7sen", "so", "ent\u00b7z\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Jene knappe Condensiertheit,", "tokens": ["Je\u00b7ne", "knap\u00b7pe", "Con\u00b7den\u00b7sier\u00b7theit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Die in Einem goldnen Lichtblitz", "tokens": ["Die", "in", "Ei\u00b7nem", "gold\u00b7nen", "Licht\u00b7blitz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Tausend bunte Farben aufsaugt,", "tokens": ["Tau\u00b7send", "bun\u00b7te", "Far\u00b7ben", "auf\u00b7saugt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Musst Du dann als neuer Heiland", "tokens": ["Musst", "Du", "dann", "als", "neu\u00b7er", "Hei\u00b7land"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "KOUS", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Selbstverst\u00e4ndlich br\u00fcsk verl\u00e4ugnen.", "tokens": ["Selbst\u00b7ver\u00b7st\u00e4nd\u00b7lich", "br\u00fcsk", "ver\u00b7l\u00e4ug\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.87": {"line.1": {"text": "Englands Hamlet, Deutschlands Faust", "tokens": ["En\u00b7glands", "Ham\u00b7let", ",", "Deutschlands", "Faust"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NE", "NE", "$,", "ADJA", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Und Altgriechenlands Prometheus \u2013", "tokens": ["Und", "Alt\u00b7grie\u00b7chen\u00b7lands", "Pro\u00b7me\u00b7theus", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "NE", "$("], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "L\u00e4cherlich, dass diese Leute", "tokens": ["L\u00e4\u00b7cher\u00b7lich", ",", "dass", "die\u00b7se", "Leu\u00b7te"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADJD", "$,", "KOUS", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Verse, nichts als Verse schwabbeln!", "tokens": ["Ver\u00b7se", ",", "nichts", "als", "Ver\u00b7se", "schwab\u00b7beln", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PIS", "KOKOM", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.88": {"line.1": {"text": "Destillire Dir doch einmal", "tokens": ["Des\u00b7til\u00b7li\u00b7re", "Dir", "doch", "ein\u00b7mal"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die famose Quintessenz", "tokens": ["Die", "fa\u00b7mo\u00b7se", "Quin\u00b7tes\u00b7senz"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Henrik Ibsenscher Kritik,", "tokens": ["Hen\u00b7rik", "Ib\u00b7sen\u00b7scher", "Kri\u00b7tik", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NE", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Der im Namen Deiner Gottheit,", "tokens": ["Der", "im", "Na\u00b7men", "Dei\u00b7ner", "Got\u00b7theit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Als ihr wohlbestallter Priester,", "tokens": ["Als", "ihr", "wohl\u00b7be\u00b7stall\u00b7ter", "Pries\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Schillers Jambendramen k\u00f6pfte:", "tokens": ["Schil\u00b7lers", "Jam\u00b7ben\u00b7dra\u00b7men", "k\u00f6pf\u00b7te", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Bl\u00f6dsinn, nichts als h\u00f6hrer Bl\u00f6dsinn!", "tokens": ["Bl\u00f6d\u00b7sinn", ",", "nichts", "als", "h\u00f6h\u00b7rer", "Bl\u00f6d\u00b7sinn", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PIS", "KOKOM", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.89": {"line.1": {"text": "Deine formverliebte Seele", "tokens": ["Dei\u00b7ne", "form\u00b7ver\u00b7lieb\u00b7te", "See\u00b7le"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat sich eben schon aus tausend", "tokens": ["Hat", "sich", "e\u00b7ben", "schon", "aus", "tau\u00b7send"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PRF", "ADV", "ADV", "APPR", "CARD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Goldgeformten Henkelkr\u00fcgen", "tokens": ["Gold\u00b7ge\u00b7form\u00b7ten", "Hen\u00b7kel\u00b7kr\u00fc\u00b7gen"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gar zu heidnisch sch\u00f6n besoffen!", "tokens": ["Gar", "zu", "heid\u00b7nisch", "sch\u00f6n", "be\u00b7sof\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKA", "ADJD", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.90": {"line.1": {"text": "Hungre sie asketisch aus!", "tokens": ["Hung\u00b7re", "sie", "as\u00b7ke\u00b7tisch", "aus", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.91": {"line.1": {"text": "Verse thun's heut freilich nicht:", "tokens": ["Ver\u00b7se", "thun's", "heut", "frei\u00b7lich", "nicht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "ADV", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Prosa, Freundchen, platte Prosa!\u00ab", "tokens": ["Pro\u00b7sa", ",", "Freund\u00b7chen", ",", "plat\u00b7te", "Pro\u00b7sa", "!", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "NN", "$,", "ADJA", "NN", "$.", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.92": {"line.1": {"text": "Ach, wie wohlfeil war euch Braven", "tokens": ["Ach", ",", "wie", "wohl\u00b7feil", "war", "euch", "Bra\u00b7ven"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PWAV", "ADJD", "VAFIN", "PPER", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dieser gutgemeinte Spott!", "tokens": ["Die\u00b7ser", "gut\u00b7ge\u00b7mein\u00b7te", "Spott", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.93": {"line.1": {"text": "Harmlos wie die jungen B\u00e4ren", "tokens": ["Harm\u00b7los", "wie", "die", "jun\u00b7gen", "B\u00e4\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "KOKOM", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lebt ihr euer Leben hin;", "tokens": ["Lebt", "ihr", "eu\u00b7er", "Le\u00b7ben", "hin", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Auf die Quadratur des Cirkels", "tokens": ["Auf", "die", "Quad\u00b7ra\u00b7tur", "des", "Cir\u00b7kels"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Habt ihr als verst\u00e4ndge Leute", "tokens": ["Habt", "ihr", "als", "ver\u00b7st\u00e4nd\u00b7ge", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "KOUS", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Philosophisch schon verzichtet,", "tokens": ["Phi\u00b7lo\u00b7so\u00b7phisch", "schon", "ver\u00b7zich\u00b7tet", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und ein schief getretner Stiefel", "tokens": ["Und", "ein", "schief", "ge\u00b7tret\u00b7ner", "Stie\u00b7fel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJD", "ADJA", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.7": {"text": "Bringt euch eher aus dem H\u00e4uschen,", "tokens": ["Bringt", "euch", "e\u00b7her", "aus", "dem", "H\u00e4usc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Als das n\u00e4rrische Problem:", "tokens": ["Als", "das", "n\u00e4r\u00b7ri\u00b7sche", "Prob\u00b7lem", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.9": {"text": "Dreht die Achse dieser Welt", "tokens": ["Dreht", "die", "A\u00b7chse", "die\u00b7ser", "Welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Sich nach rechtshin oder linkshin?", "tokens": ["Sich", "nach", "rechts\u00b7hin", "o\u00b7der", "links\u00b7hin", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ADV", "KON", "ADV", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.94": {"line.1": {"text": "Anders, wenn ein Homo sapiens", "tokens": ["An\u00b7ders", ",", "wenn", "ein", "Ho\u00b7mo", "sa\u00b7pi\u00b7ens"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "ART", "NE", "NE"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Nicht, wie ihr, nur Steuern zahlt,", "tokens": ["Nicht", ",", "wie", "ihr", ",", "nur", "Steu\u00b7ern", "zahlt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "$,", "PWAV", "PPER", "$,", "ADV", "NN", "VVFIN", "$,"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Sondern, wie z.B. ich,", "tokens": ["Son\u00b7dern", ",", "wie", "z.", "B.", "ich", ","], "token_info": ["word", "punct", "word", "abbreviation", "abbreviation", "word", "punct"], "pos": ["KON", "$,", "PWAV", "APPRART", "NN", "PPER", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Nebenbei auch noch Poet ist.", "tokens": ["Ne\u00b7ben\u00b7bei", "auch", "noch", "Po\u00b7et", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "NN", "VAFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.95": {"line.1": {"text": "Werden doch in seiner Brust", "tokens": ["Wer\u00b7den", "doch", "in", "sei\u00b7ner", "Brust"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Feindlich stets zwei Seelen wohnen,", "tokens": ["Feind\u00b7lich", "stets", "zwei", "See\u00b7len", "woh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "CARD", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und vielleicht just, wenn die eine", "tokens": ["Und", "viel\u00b7leicht", "just", ",", "wenn", "die", "ei\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "ADJD", "$,", "KOUS", "ART", "ART"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Str\u00fcmpfe stopft und Hosen flickt,", "tokens": ["Str\u00fcmp\u00b7fe", "stopft", "und", "Ho\u00b7sen", "flickt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Reimt die andere ihr erstes,", "tokens": ["Reimt", "die", "an\u00b7de\u00b7re", "ihr", "ers\u00b7tes", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "PIS", "PPOSAT", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Tiefgef\u00fchltes Liebeslied.", "tokens": ["Tief\u00b7ge\u00b7f\u00fchl\u00b7tes", "Lie\u00b7bes\u00b7lied", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.96": {"line.1": {"text": "Zwar mein Kopf hat sich schon l\u00e4ngst", "tokens": ["Zwar", "mein", "Kopf", "hat", "sich", "schon", "l\u00e4ngst"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "VAFIN", "PRF", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Radikal emanzipirt;", "tokens": ["Ra\u00b7di\u00b7kal", "e\u00b7man\u00b7zi\u00b7pirt", ";"], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch in meinem Herzen bl\u00fchn noch", "tokens": ["Doch", "in", "mei\u00b7nem", "Her\u00b7zen", "bl\u00fchn", "noch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VVFIN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alle Blumen der Romantik!", "tokens": ["Al\u00b7le", "Blu\u00b7men", "der", "Ro\u00b7man\u00b7tik", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.97": {"line.1": {"text": "Kriechen soll ich, Freunde, kriechen,", "tokens": ["Krie\u00b7chen", "soll", "ich", ",", "Freun\u00b7de", ",", "krie\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "$,", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kriechen wie ein fader Wurm?", "tokens": ["Krie\u00b7chen", "wie", "ein", "fa\u00b7der", "Wurm", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.98": {"line.1": {"text": "Schaut nur, wie die alten W\u00e4lder", "tokens": ["Schaut", "nur", ",", "wie", "die", "al\u00b7ten", "W\u00e4l\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "$,", "PWAV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihre gr\u00fcnen H\u00e4upter sch\u00fctteln,", "tokens": ["Ih\u00b7re", "gr\u00fc\u00b7nen", "H\u00e4up\u00b7ter", "sch\u00fct\u00b7teln", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wie \u00fcber sie die Sterne", "tokens": ["Und", "wie", "\u00fc\u00b7ber", "sie", "die", "Ster\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "APPR", "PPER", "ART", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Kreuzweis ihre Lichter werfen:", "tokens": ["Kreuz\u00b7weis", "ih\u00b7re", "Lich\u00b7ter", "wer\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ach, sie intoniren alle", "tokens": ["Ach", ",", "sie", "in\u00b7to\u00b7ni\u00b7ren", "al\u00b7le"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "PPER", "VVFIN", "PIS"], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Ein homerisches Gel\u00e4chter!", "tokens": ["Ein", "ho\u00b7me\u00b7ri\u00b7sches", "Ge\u00b7l\u00e4ch\u00b7ter", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}}, "stanza.99": {"line.1": {"text": "Wem die Sonne dieser Gottwelt", "tokens": ["Wem", "die", "Son\u00b7ne", "die\u00b7ser", "Gott\u00b7welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Niemals bis ins Herz geschienen,", "tokens": ["Nie\u00b7mals", "bis", "ins", "Herz", "ge\u00b7schie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mag sich in den Staub verlieben,", "tokens": ["Mag", "sich", "in", "den", "Staub", "ver\u00b7lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch wer Fl\u00fcgel hat, der fliege!", "tokens": ["Doch", "wer", "Fl\u00fc\u00b7gel", "hat", ",", "der", "flie\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "NN", "VAFIN", "$,", "PRELS", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.100": {"line.1": {"text": "Weiss nicht, ob ich nicht noch einmal", "tokens": ["Weiss", "nicht", ",", "ob", "ich", "nicht", "noch", "ein\u00b7mal"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PTKNEG", "$,", "KOUS", "PPER", "PTKNEG", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sp\u00e4ter, wenn ich alt und grau bin,", "tokens": ["Sp\u00e4\u00b7ter", ",", "wenn", "ich", "alt", "und", "grau", "bin", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "PPER", "ADJD", "KON", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mich ins Prosajoch bequeme.", "tokens": ["Mich", "ins", "Pro\u00b7sa\u00b7joch", "be\u00b7que\u00b7me", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.101": {"line.1": {"text": "Ach, die Zeit ist gar zu fl\u00fcchtig,", "tokens": ["Ach", ",", "die", "Zeit", "ist", "gar", "zu", "fl\u00fcch\u00b7tig", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ART", "NN", "VAFIN", "ADV", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und wenn erst das Podagra", "tokens": ["Und", "wenn", "erst", "das", "Po\u00b7da\u00b7gra"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADV", "ART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Uns moquant an Arm und Bein zwickt,", "tokens": ["Uns", "mo\u00b7quant", "an", "Arm", "und", "Bein", "zwickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Macht die Jugend schm\u00e4hlich Pleite,", "tokens": ["Macht", "die", "Ju\u00b7gend", "schm\u00e4h\u00b7lich", "Plei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und die goldnen Ideale", "tokens": ["Und", "die", "gold\u00b7nen", "I\u00b7dea\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Drehen schnippisch uns den R\u00fccken.", "tokens": ["Dre\u00b7hen", "schnip\u00b7pisch", "uns", "den", "R\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.102": {"line.1": {"text": "Doch einstweilen dedicir ich", "tokens": ["Doch", "einst\u00b7wei\u00b7len", "de\u00b7di\u00b7cir", "ich"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dieses lachende Pr\u00e4ludium", "tokens": ["Die\u00b7ses", "la\u00b7chen\u00b7de", "Pr\u00e4\u00b7lu\u00b7di\u00b7um"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Euch, ihr wohlverbohrten Ritter", "tokens": ["Euch", ",", "ihr", "wohl\u00b7ver\u00b7bohr\u00b7ten", "Rit\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Vom romantisch blauen Strumpfband", "tokens": ["Vom", "ro\u00b7man\u00b7tisch", "blau\u00b7en", "Strumpf\u00b7band"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "ADJD", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und vom klassischen Kothurn!", "tokens": ["Und", "vom", "klas\u00b7si\u00b7schen", "Ko\u00b7thurn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}