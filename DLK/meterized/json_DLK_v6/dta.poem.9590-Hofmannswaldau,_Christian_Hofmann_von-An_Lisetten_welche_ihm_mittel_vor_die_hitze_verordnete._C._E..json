{"dta.poem.9590": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "An Lisetten/ welche ihm mittel vor die  \n hitze verordnete.  \n C. E.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.85", "af:0.14"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ich klagte neulich dir/ Lisette/ voller pein/", "tokens": ["Ich", "klag\u00b7te", "neu\u00b7lich", "dir", "/", "Li\u00b7set\u00b7te", "/", "vol\u00b7ler", "pein", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPER", "$(", "NE", "$(", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die heisse todes-angst/ die mir das hertze r\u00fchrte/", "tokens": ["Die", "heis\u00b7se", "to\u00b7des\u00b7angst", "/", "die", "mir", "das", "hert\u00b7ze", "r\u00fchr\u00b7te", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "PRELS", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und solch ein scharffes weh durch meine glieder f\u00fchrte/", "tokens": ["Und", "solch", "ein", "scharf\u00b7fes", "weh", "durch", "mei\u00b7ne", "glie\u00b7der", "f\u00fchr\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df ich dem himmel selbst um h\u00fclffe muste schreyn.", "tokens": ["Da\u00df", "ich", "dem", "him\u00b7mel", "selbst", "um", "h\u00fclf\u00b7fe", "mus\u00b7te", "schreyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "APPR", "NN", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Dich jammerte der noth/ die meine sinnen band;", "tokens": ["Dich", "jam\u00b7mer\u00b7te", "der", "noth", "/", "die", "mei\u00b7ne", "sin\u00b7nen", "band", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$(", "ART", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du schlugest mittel vor/ die zur genesung dienen:", "tokens": ["Du", "schlu\u00b7gest", "mit\u00b7tel", "vor", "/", "die", "zur", "ge\u00b7ne\u00b7sung", "die\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "$(", "ART", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Cerallen/ rosen-safft/ und was mehr gut geschienen/", "tokens": ["Ce\u00b7ral\u00b7len", "/", "ro\u00b7sen\u00b7\u00b7safft", "/", "und", "was", "mehr", "gut", "ge\u00b7schie\u00b7nen", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NE", "$(", "KON", "PWS", "ADV", "ADJD", "VVPP", "$("], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Ward zur errettung mir gantz heilsam zuerkant.", "tokens": ["Ward", "zur", "er\u00b7ret\u00b7tung", "mir", "gantz", "heil\u00b7sam", "zu\u00b7er\u00b7kant", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Corallen? fragt ich: ach! soll di\u00df ein labsal seyn?", "tokens": ["Co\u00b7ral\u00b7len", "?", "fragt", "ich", ":", "ach", "!", "soll", "di\u00df", "ein", "lab\u00b7sal", "seyn", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVFIN", "PPER", "$.", "XY", "$.", "VMFIN", "PDS", "ART", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Soll di\u00df den krancken geist von seiner marter retten/", "tokens": ["Soll", "di\u00df", "den", "kran\u00b7cken", "geist", "von", "sei\u00b7ner", "mar\u00b7ter", "ret\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "ART", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und aus der schwartzen grufft und finstren todes-ketten", "tokens": ["Und", "aus", "der", "schwart\u00b7zen", "grufft", "und", "finst\u00b7ren", "to\u00b7des\u00b7ket\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den abgeschw\u00e4chten leib erl\u00f6sen und befreyn?", "tokens": ["Den", "ab\u00b7ge\u00b7schw\u00e4ch\u00b7ten", "leib", "er\u00b7l\u00f6\u00b7sen", "und", "be\u00b7freyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Ich gieng auff dieses wort in h\u00f6chst-verwirrtem sinn/", "tokens": ["Ich", "gieng", "auff", "die\u00b7ses", "wort", "in", "h\u00f6chst\u00b7ver\u00b7wirr\u00b7tem", "sinn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit halb-zerschlagnem muth und schier erstorbnem leben/", "tokens": ["Mit", "halb\u00b7zer\u00b7schlagnem", "muth", "und", "schier", "ers\u00b7torb\u00b7nem", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJD", "PIS", "VVINF", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "In hofnung/ meine pein durch einen artzt zu heben/", "tokens": ["In", "hof\u00b7nung", "/", "mei\u00b7ne", "pein", "durch", "ei\u00b7nen", "artzt", "zu", "he\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "PPOSAT", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zur Amaranthen noch denselben abend hin.", "tokens": ["Zur", "A\u00b7ma\u00b7ran\u00b7then", "noch", "den\u00b7sel\u00b7ben", "a\u00b7bend", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ich fand sie/ wie gewohnt/ in auffgeschickter pracht;", "tokens": ["Ich", "fand", "sie", "/", "wie", "ge\u00b7wohnt", "/", "in", "auff\u00b7ge\u00b7schick\u00b7ter", "pracht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "PWAV", "VVPP", "$(", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das haar in diamant/ den leib in gold verh\u00fcllet/", "tokens": ["Das", "haar", "in", "di\u00b7a\u00b7mant", "/", "den", "leib", "in", "gold", "ver\u00b7h\u00fcl\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$(", "ART", "NN", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die augen voller glut/ draus tod und leben quillet/", "tokens": ["Die", "au\u00b7gen", "vol\u00b7ler", "glut", "/", "draus", "tod", "und", "le\u00b7ben", "quil\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$(", "PAV", "NN", "KON", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die wangen licht wie schnee/ und perlen gleich geacht/", "tokens": ["Die", "wan\u00b7gen", "licht", "wie", "schnee", "/", "und", "per\u00b7len", "gleich", "ge\u00b7acht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KOKOM", "NN", "$(", "KON", "VVFIN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Deu mund/ als einen thron von rosen auffgebaut/", "tokens": ["Deu", "mund", "/", "als", "ei\u00b7nen", "thron", "von", "ro\u00b7sen", "auff\u00b7ge\u00b7baut", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$(", "KOUS", "ART", "NN", "APPR", "NE", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und als ein rothes meer/ gemachsam sich bewegen/", "tokens": ["Und", "als", "ein", "ro\u00b7thes", "meer", "/", "ge\u00b7mach\u00b7sam", "sich", "be\u00b7we\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "$(", "ADJD", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und purpur und corall in seinen ufern hegen/", "tokens": ["Und", "pur\u00b7pur", "und", "co\u00b7rall", "in", "sei\u00b7nen", "u\u00b7fern", "he\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "NE", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dergleichen die natur nie sch\u00f6nres angeschaut.", "tokens": ["Derg\u00b7lei\u00b7chen", "die", "na\u00b7tur", "nie", "sch\u00f6n\u00b7res", "an\u00b7ge\u00b7schaut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "NN", "ADV", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Corallen? dacht ich itzt: corallen sind ja gut!", "tokens": ["Co\u00b7ral\u00b7len", "?", "dacht", "ich", "itzt", ":", "co\u00b7ral\u00b7len", "sind", "ja", "gut", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVFIN", "PPER", "ADV", "$.", "VVPP", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hier siehstu rath und trost dir durch corallen spielen;", "tokens": ["Hier", "sieh\u00b7stu", "rath", "und", "trost", "dir", "durch", "co\u00b7ral\u00b7len", "spie\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "KON", "VVFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hier kanstu deinen brand auff rosen lippen k\u00fchlen/", "tokens": ["Hier", "kans\u00b7tu", "dei\u00b7nen", "brand", "auff", "ro\u00b7sen", "lip\u00b7pen", "k\u00fch\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und findest/ was dir wohl bey deiner hitze thut.", "tokens": ["Und", "fin\u00b7dest", "/", "was", "dir", "wohl", "bey", "dei\u00b7ner", "hit\u00b7ze", "thut", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "PWS", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Auff dieses f\u00fcgt ich mich zur Amaranthen hin:", "tokens": ["Auff", "die\u00b7ses", "f\u00fcgt", "ich", "mich", "zur", "A\u00b7ma\u00b7ran\u00b7then", "hin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "PPER", "PRF", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch dr\u00fcckt ich meinen mund nur an erhitzte flammen/", "tokens": ["Doch", "dr\u00fcckt", "ich", "mei\u00b7nen", "mund", "nur", "an", "er\u00b7hitz\u00b7te", "flam\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "ADV", "APPR", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die schlagen mehr und mehr ietzt \u00fcber mich zusammen/", "tokens": ["Die", "schla\u00b7gen", "mehr", "und", "mehr", "ietzt", "\u00fc\u00b7ber", "mich", "zu\u00b7sam\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "KON", "ADV", "ADV", "APPR", "PPER", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und zeigen \u00f6ffentlich/ da\u00df ich verlohren bin.", "tokens": ["Und", "zei\u00b7gen", "\u00f6f\u00b7fent\u00b7lich", "/", "da\u00df", "ich", "ver\u00b7loh\u00b7ren", "bin", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$(", "KOUS", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Lisette/ falsches bild/ was hab ich dir gethan/", "tokens": ["Li\u00b7set\u00b7te", "/", "fal\u00b7sches", "bild", "/", "was", "hab", "ich", "dir", "ge\u00b7than", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "ADJA", "NN", "$(", "PWS", "VAFIN", "PPER", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df du mich umgef\u00fchrt/ da\u00df du mir vorgelogen/", "tokens": ["Da\u00df", "du", "mich", "um\u00b7ge\u00b7f\u00fchrt", "/", "da\u00df", "du", "mir", "vor\u00b7ge\u00b7lo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVPP", "$(", "KOUS", "PPER", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und so verr\u00e4thrisch mich hast in ein garn gezogen/", "tokens": ["Und", "so", "ver\u00b7r\u00e4t\u00b7hrisch", "mich", "hast", "in", "ein", "garn", "ge\u00b7zo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "PPER", "VAFIN", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Drau\u00df ich auff ewig mich nicht wieder finden kan?", "tokens": ["Drau\u00df", "ich", "auff", "e\u00b7wig", "mich", "nicht", "wie\u00b7der", "fin\u00b7den", "kan", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "APPR", "ADJD", "PPER", "PTKNEG", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Jtzt f\u00fchl ich meine glut durch frische glut geh\u00e4ufft/", "tokens": ["Jtzt", "f\u00fchl", "ich", "mei\u00b7ne", "glut", "durch", "fri\u00b7sche", "glut", "ge\u00b7h\u00e4ufft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den zunder/ welcher todt/ durch flammen angehitzet/", "tokens": ["Den", "zun\u00b7der", "/", "wel\u00b7cher", "todt", "/", "durch", "flam\u00b7men", "an\u00b7ge\u00b7hit\u00b7zet", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "ADJD", "$(", "APPR", "VVINF", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein feur/ das mich verzehrt/ das tieff im hertzen sitzet/", "tokens": ["Ein", "feur", "/", "das", "mich", "ver\u00b7zehrt", "/", "das", "tieff", "im", "hert\u00b7zen", "sit\u00b7zet", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "VVPP", "$(", "ART", "ADJD", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wie ein schneller strom mir durchs ge\u00e4der l\u00e4ufft.", "tokens": ["Und", "wie", "ein", "schnel\u00b7ler", "strom", "mir", "durchs", "ge\u00b7\u00e4\u00b7der", "l\u00e4ufft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "ADJA", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Ich f\u00fchle meinen geist in angst und vein verstrickt/", "tokens": ["Ich", "f\u00fch\u00b7le", "mei\u00b7nen", "geist", "in", "angst", "und", "vein", "ver\u00b7strickt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "NN", "KON", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die seele durch den todt/ den leib auffs blut erschrecket.", "tokens": ["Die", "see\u00b7le", "durch", "den", "todt", "/", "den", "leib", "auffs", "blut", "er\u00b7schre\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "ADJD", "$(", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ach! Amaranthe/ ach! du hast mich angestecket", "tokens": ["Ach", "!", "A\u00b7ma\u00b7ran\u00b7the", "/", "ach", "!", "du", "hast", "mich", "an\u00b7ge\u00b7ste\u00b7cket"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "NE", "$(", "XY", "$.", "PPER", "VAFIN", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und mir des leben selbst durch stille list entr\u00fcckt.", "tokens": ["Und", "mir", "des", "le\u00b7ben", "selbst", "durch", "stil\u00b7le", "list", "ent\u00b7r\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "VVFIN", "ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Komm mehr/ Lisette/ komm/ und steh mir tr\u00f6stlich bey!", "tokens": ["Komm", "mehr", "/", "Li\u00b7set\u00b7te", "/", "komm", "/", "und", "steh", "mir", "tr\u00f6st\u00b7lich", "bey", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$(", "NE", "$(", "VVFIN", "$(", "KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Komm ietzt/ und rei\u00df mich auch aus diesen steiffen banden!", "tokens": ["Komm", "ietzt", "/", "und", "rei\u00df", "mich", "auch", "aus", "die\u00b7sen", "steif\u00b7fen", "ban\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$(", "KON", "VVFIN", "PPER", "ADV", "APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich leide blo\u00df durch dich/ wo bist du ietzt verhanden?", "tokens": ["Ich", "lei\u00b7de", "blo\u00df", "durch", "dich", "/", "wo", "bist", "du", "ietzt", "ver\u00b7han\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPER", "$(", "PWAV", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ist niemand/ welcher spricht/ wie mir zu helffen sey?", "tokens": ["Ist", "nie\u00b7mand", "/", "wel\u00b7cher", "spricht", "/", "wie", "mir", "zu", "helf\u00b7fen", "sey", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "$(", "PWS", "VVFIN", "$(", "PWAV", "PPER", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}