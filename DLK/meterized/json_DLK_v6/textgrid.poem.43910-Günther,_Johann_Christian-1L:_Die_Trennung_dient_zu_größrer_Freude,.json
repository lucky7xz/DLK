{"textgrid.poem.43910": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Die Trennung dient zu gr\u00f6\u00dfrer Freude,", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Trennung dient zu gr\u00f6\u00dfrer Freude,", "tokens": ["Die", "Tren\u00b7nung", "dient", "zu", "gr\u00f6\u00df\u00b7rer", "Freu\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Drum thu doch nicht so sehr um mich!", "tokens": ["Drum", "thu", "doch", "nicht", "so", "sehr", "um", "mich", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "PTKNEG", "ADV", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So weit ich auch von hinnen scheide,", "tokens": ["So", "weit", "ich", "auch", "von", "hin\u00b7nen", "schei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADV", "APPR", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So nah behalt und k\u00fc\u00df ich dich,", "tokens": ["So", "nah", "be\u00b7halt", "und", "k\u00fc\u00df", "ich", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "KON", "VVFIN", "PPER", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Weil Licht und Nacht in tausend Bildern", "tokens": ["Weil", "Licht", "und", "Nacht", "in", "tau\u00b7send", "Bil\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Dem Herzen dein Ged\u00e4chtn\u00fc\u00df schildern.", "tokens": ["Dem", "Her\u00b7zen", "dein", "Ge\u00b7d\u00e4cht\u00b7n\u00fc\u00df", "schil\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Nur mir liegt etwas in Gedancken", "tokens": ["Nur", "mir", "liegt", "et\u00b7was", "in", "Ge\u00b7dan\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "ADV", "APPR", "NN"], "meter": "+-++-+-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Und martert mich so stumm als scharf:", "tokens": ["Und", "mar\u00b7tert", "mich", "so", "stumm", "als", "scharf", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "KOKOM", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man kennt des Frauenzimmers Wancken;", "tokens": ["Man", "kennt", "des", "Frau\u00b7en\u00b7zim\u00b7mers", "Wan\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich weis nicht, ob ich hofen darf", "tokens": ["Ich", "weis", "nicht", ",", "ob", "ich", "ho\u00b7fen", "darf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "PTKVZ", "PTKNEG", "$,", "KOUS", "PPER", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und ob wohl k\u00fcnftig dein Gem\u00fcthe", "tokens": ["Und", "ob", "wohl", "k\u00fcnf\u00b7tig", "dein", "Ge\u00b7m\u00fc\u00b7the"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADV", "ADJD", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sich auch mit gleicher Sorgfalt h\u00fcte.", "tokens": ["Sich", "auch", "mit", "glei\u00b7cher", "Sorg\u00b7falt", "h\u00fc\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Der Zweifel darf dich nicht betr\u00fcben,", "tokens": ["Der", "Zwei\u00b7fel", "darf", "dich", "nicht", "be\u00b7tr\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Er ist ein Zeichen zarter Treu;", "tokens": ["Er", "ist", "ein", "Zei\u00b7chen", "zar\u00b7ter", "Treu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bisher erkenn ich zwar dein Lieben", "tokens": ["Bis\u00b7her", "er\u00b7kenn", "ich", "zwar", "dein", "Lie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und weis, wie rein die Flamme sey;", "tokens": ["Und", "weis", ",", "wie", "rein", "die", "Flam\u00b7me", "sey", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "$,", "PWAV", "ADJD", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wer b\u00fcrgt mir aber vor das Gl\u00fccke,", "tokens": ["Wer", "b\u00fcrgt", "mir", "a\u00b7ber", "vor", "das", "Gl\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df keine Zeit das Ziel verr\u00fccke?", "tokens": ["Da\u00df", "kei\u00b7ne", "Zeit", "das", "Ziel", "ver\u00b7r\u00fc\u00b7cke", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ich kan dir keinen W\u00e4chter stellen,", "tokens": ["Ich", "kan", "dir", "kei\u00b7nen", "W\u00e4ch\u00b7ter", "stel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es w\u00e4re denn dein eigner Geist;", "tokens": ["Es", "w\u00e4\u00b7re", "denn", "dein", "eig\u00b7ner", "Geist", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch weil die Macht von manchen F\u00e4llen", "tokens": ["Doch", "weil", "die", "Macht", "von", "man\u00b7chen", "F\u00e4l\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Kl\u00fcgsten aus dem Circkel rei\u00dft,", "tokens": ["Die", "Kl\u00fcgs\u00b7ten", "aus", "dem", "Cir\u00b7ckel", "rei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So las dir, wiltu mein verbleiben,", "tokens": ["So", "las", "dir", ",", "wil\u00b7tu", "mein", "ver\u00b7blei\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "VMFIN", "PPOSAT", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die Regeln in das Herze schreiben.", "tokens": ["Die", "Re\u00b7geln", "in", "das", "Her\u00b7ze", "schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Die Liebe reicht auch in die Ferne,", "tokens": ["Die", "Lie\u00b7be", "reicht", "auch", "in", "die", "Fer\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und dies heist recht best\u00e4ndig seyn.", "tokens": ["Und", "dies", "heist", "recht", "be\u00b7st\u00e4n\u00b7dig", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Verehre die geneigten Sterne,", "tokens": ["Ver\u00b7eh\u00b7re", "die", "ge\u00b7neig\u00b7ten", "Ster\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und z\u00fcrnt ihr abgenommner Schein,", "tokens": ["Und", "z\u00fcrnt", "ihr", "ab\u00b7ge\u00b7nomm\u00b7ner", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So mustu mehr durch Flehn als Fluchen", "tokens": ["So", "mus\u00b7tu", "mehr", "durch", "Flehn", "als", "Flu\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADV", "APPR", "NN", "KOUS", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Den Himmel zu vers\u00f6hnen suchen.", "tokens": ["Den", "Him\u00b7mel", "zu", "ver\u00b7s\u00f6h\u00b7nen", "su\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Erwege st\u00fcndlich in der Stille", "tokens": ["Er\u00b7we\u00b7ge", "st\u00fcnd\u00b7lich", "in", "der", "Stil\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den Anfang der Zusammenkunft,", "tokens": ["Den", "An\u00b7fang", "der", "Zu\u00b7sam\u00b7men\u00b7kunft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Bedencke nur, dein eigner Wille", "tokens": ["Be\u00b7den\u00b7cke", "nur", ",", "dein", "eig\u00b7ner", "Wil\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADV", "$,", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Beschwur das B\u00fcndn\u00fc\u00df mit Vernunft;", "tokens": ["Be\u00b7schwur", "das", "B\u00fcnd\u00b7n\u00fc\u00df", "mit", "Ver\u00b7nunft", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vergi\u00df auch nicht, was mein Verlangen,", "tokens": ["Ver\u00b7gi\u00df", "auch", "nicht", ",", "was", "mein", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "PTKNEG", "$,", "PRELS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Nur dich zu sehn, oft angefangen.", "tokens": ["Nur", "dich", "zu", "sehn", ",", "oft", "an\u00b7ge\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PPER", "PTKZU", "VVINF", "$,", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Vermeide die Gelegenheiten,", "tokens": ["Ver\u00b7mei\u00b7de", "die", "Ge\u00b7le\u00b7gen\u00b7hei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wo viel Gesellschaft spielt und k\u00fcst;", "tokens": ["Wo", "viel", "Ge\u00b7sell\u00b7schaft", "spielt", "und", "k\u00fcst", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Scherz kan \u00f6fters viel bedeuten,", "tokens": ["Der", "Scherz", "kan", "\u00f6f\u00b7ters", "viel", "be\u00b7deu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Man weis, wie starck die Reizung ist;", "tokens": ["Man", "weis", ",", "wie", "starck", "die", "Rei\u00b7zung", "ist", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PTKVZ", "$,", "PWAV", "ADJD", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und mustu dich der Welt bequemen,", "tokens": ["Und", "mus\u00b7tu", "dich", "der", "Welt", "be\u00b7que\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "ART", "NN", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So las dich andrer Puz besch\u00e4men.", "tokens": ["So", "las", "dich", "an\u00b7drer", "Puz", "be\u00b7sch\u00e4\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Besuche flei\u00dfig alle G\u00e4nge,", "tokens": ["Be\u00b7su\u00b7che", "flei\u00b7\u00dfig", "al\u00b7le", "G\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wodurch ich dich bisher gef\u00fchrt,", "tokens": ["Wo\u00b7durch", "ich", "dich", "bis\u00b7her", "ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vornehmlich wo der Bircken Menge", "tokens": ["Vor\u00b7nehm\u00b7lich", "wo", "der", "Bir\u00b7cken", "Men\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PWAV", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das Ufer und die Wiesen ziert,", "tokens": ["Das", "U\u00b7fer", "und", "die", "Wie\u00b7sen", "ziert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und dort naus, wo dein sachtes K\u00fc\u00dfen", "tokens": ["Und", "dort", "naus", ",", "wo", "dein", "sach\u00b7tes", "K\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PTKVZ", "$,", "PWAV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Mich oft im Gr\u00fcnen wecken m\u00fc\u00dfen.", "tokens": ["Mich", "oft", "im", "Gr\u00fc\u00b7nen", "we\u00b7cken", "m\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPRART", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Du weist und kanst auch \u00fcberlegen,", "tokens": ["Du", "weist", "und", "kanst", "auch", "\u00fc\u00b7berl\u00b7e\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie kr\u00e4ftig mich der Mond erg\u00f6zt,", "tokens": ["Wie", "kr\u00e4f\u00b7tig", "mich", "der", "Mond", "er\u00b7g\u00f6zt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So da\u00df ich seines Schimmers wegen", "tokens": ["So", "da\u00df", "ich", "sei\u00b7nes", "Schim\u00b7mers", "we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "PPOSAT", "NN", "APPR"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Nacht dem Tage vorgesezt;", "tokens": ["Die", "Nacht", "dem", "Ta\u00b7ge", "vor\u00b7ge\u00b7sezt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Besinne dich in solchen Schatten,", "tokens": ["Be\u00b7sin\u00b7ne", "dich", "in", "sol\u00b7chen", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wie viel wir sichre Zuflucht hatten.", "tokens": ["Wie", "viel", "wir", "sich\u00b7re", "Zu\u00b7flucht", "hat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "VVFIN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Steh freudig auf, geh froh zu Bette,", "tokens": ["Steh", "freu\u00b7dig", "auf", ",", "geh", "froh", "zu", "Bet\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PTKVZ", "$,", "VVFIN", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Doch sieh vorher mein Bildn\u00fc\u00df an", "tokens": ["Doch", "sieh", "vor\u00b7her", "mein", "Bild\u00b7n\u00fc\u00df", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "ADV", "PPOSAT", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und nimm den Ring, die Liebeskette;", "tokens": ["Und", "nimm", "den", "Ring", ",", "die", "Lie\u00b7bes\u00b7ket\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVIMP", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Denn ob gleich keines reden kan,", "tokens": ["Denn", "ob", "gleich", "kei\u00b7nes", "re\u00b7den", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So wirstu doch bey ihrem Spielen", "tokens": ["So", "wirs\u00b7tu", "doch", "bey", "ih\u00b7rem", "Spie\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Viel Wachsthum sanfter Neigung f\u00fchlen.", "tokens": ["Viel", "Wach\u00b7sthum", "sanf\u00b7ter", "Nei\u00b7gung", "f\u00fch\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Dein Absehn mustu wohl verheelen;", "tokens": ["Dein", "Ab\u00b7sehn", "mus\u00b7tu", "wohl", "ver\u00b7hee\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sprich jeden, der mir Gutes g\u00f6nnt,", "tokens": ["Sprich", "je\u00b7den", ",", "der", "mir", "Gu\u00b7tes", "g\u00f6nnt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PIAT", "$,", "PRELS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und las dir stets von mir erzehlen", "tokens": ["Und", "las", "dir", "stets", "von", "mir", "er\u00b7zeh\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und liebe das, was mich nur kennt;", "tokens": ["Und", "lie\u00b7be", "das", ",", "was", "mich", "nur", "kennt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDS", "$,", "PWS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Durchbl\u00e4ttre meine Vers und Lieder", "tokens": ["Durch\u00b7bl\u00e4tt\u00b7re", "mei\u00b7ne", "Vers", "und", "Lie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und sing und leg und lis sie wieder.", "tokens": ["Und", "sing", "und", "leg", "und", "lis", "sie", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "NE", "KON", "NE", "PPER", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Geh t\u00e4glich in des Herren Tempel,", "tokens": ["Geh", "t\u00e4g\u00b7lich", "in", "des", "Her\u00b7ren", "Tem\u00b7pel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Andacht kommt der Liebe bey;", "tokens": ["Die", "An\u00b7dacht", "kommt", "der", "Lie\u00b7be", "bey", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Alterthum hat viel Exempel", "tokens": ["Das", "Al\u00b7ter\u00b7thum", "hat", "viel", "Ex\u00b7em\u00b7pel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PIAT", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Verliebter Lust und seltner Treu;", "tokens": ["Ver\u00b7lieb\u00b7ter", "Lust", "und", "selt\u00b7ner", "Treu", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bem\u00fch dich drum und lis und mercke,", "tokens": ["Be\u00b7m\u00fch", "dich", "drum", "und", "lis", "und", "mer\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PAV", "KON", "NE", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wie z\u00e4rtlich dich ihr Beyspiel st\u00e4rcke.", "tokens": ["Wie", "z\u00e4rt\u00b7lich", "dich", "ihr", "Bey\u00b7spiel", "st\u00e4r\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Las weder Post noch Boten s\u00e4umen", "tokens": ["Las", "we\u00b7der", "Post", "noch", "Bo\u00b7ten", "s\u00e4u\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "KON", "NN", "ADV", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und mi\u00df Papier und Silben nicht,", "tokens": ["Und", "mi\u00df", "Pa\u00b7pier", "und", "Sil\u00b7ben", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "KON", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Erzehle mir aus allen Tr\u00e4umen,", "tokens": ["Er\u00b7zeh\u00b7le", "mir", "aus", "al\u00b7len", "Tr\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr Schatten giebt den Klugen Licht,", "tokens": ["Ihr", "Schat\u00b7ten", "giebt", "den", "Klu\u00b7gen", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und ist dir aller Zeug benommen,", "tokens": ["Und", "ist", "dir", "al\u00b7ler", "Zeug", "be\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So schreib mir stets ums Wiederkommen.", "tokens": ["So", "schreib", "mir", "stets", "ums", "Wie\u00b7der\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Leg alles, was ich schriftlich sende,", "tokens": ["Leg", "al\u00b7les", ",", "was", "ich", "schrift\u00b7lich", "sen\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "$,", "PWS", "PPER", "ADJD", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ohn Argwohn auf dein Vortheil aus;", "tokens": ["Ohn", "Arg\u00b7wohn", "auf", "dein", "Vor\u00b7theil", "aus", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Betrachte wohl den Zug der H\u00e4nde", "tokens": ["Be\u00b7trach\u00b7te", "wohl", "den", "Zug", "der", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und suche vor das L. heraus,", "tokens": ["Und", "su\u00b7che", "vor", "das", "L.", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "abbreviation", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NE", "PTKVZ", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Ja, halt ein jegliches Ger\u00fcchte", "tokens": ["Ja", ",", "halt", "ein", "jeg\u00b7li\u00b7ches", "Ge\u00b7r\u00fcch\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Von meiner Untreu vor Gedichte.", "tokens": ["Von", "mei\u00b7ner", "Un\u00b7treu", "vor", "Ge\u00b7dich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Es braucht kein h\u00e4ufiger Geschweze,", "tokens": ["Es", "braucht", "kein", "h\u00e4u\u00b7fi\u00b7ger", "Ge\u00b7schwe\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Denn liebstu recht, so liebstu klug;", "tokens": ["Denn", "liebs\u00b7tu", "recht", ",", "so", "liebs\u00b7tu", "klug", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$,", "ADV", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich geb und halt auch die Geseze.", "tokens": ["Ich", "geb", "und", "halt", "auch", "die", "Ge\u00b7se\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kind, gute Nacht! Du hast genug.", "tokens": ["Kind", ",", "gu\u00b7te", "Nacht", "!", "Du", "hast", "ge\u00b7nug", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$.", "PPER", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Soll etwas mir dein Bild entf\u00fchren,", "tokens": ["Soll", "et\u00b7was", "mir", "dein", "Bild", "ent\u00b7f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So mu\u00df ich vor mein Herz verlieren.", "tokens": ["So", "mu\u00df", "ich", "vor", "mein", "Herz", "ver\u00b7lie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}