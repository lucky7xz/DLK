{"dta.poem.10764": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "Vi.  \n Momifenestra & crura.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1624", "urn": "urn:nbn:de:kobv:b4-200905197859", "language": ["de:0.99"], "booktitle": "Opitz, Martin: Teutsche P\u00f6emata und: Aristarchvs Wieder die verachtung Teutscher Sprach. Stra\u00dfburg, 1624."}, "poem": {"stanza.1": {"line.1": {"text": "Momus hat zwey st\u00fcck erzehlet/", "tokens": ["Mo\u00b7mus", "hat", "zwey", "st\u00fcck", "er\u00b7zeh\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "CARD", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die die G\u00f6tter hetten nicht", "tokens": ["Die", "die", "G\u00f6t\u00b7ter", "het\u00b7ten", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "VAFIN", "PTKNEG"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "An den Menschen zu gericht/", "tokens": ["An", "den", "Men\u00b7schen", "zu", "ge\u00b7richt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Erstlich meinet er/ da\u00df fehlet", "tokens": ["Erst\u00b7lich", "mei\u00b7net", "er", "/", "da\u00df", "feh\u00b7let"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "$(", "KOUS", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "In das Hertz ein Fensterlein/", "tokens": ["In", "das", "Hertz", "ein", "Fens\u00b7ter\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da man k\u00f6nte sehen ein/", "tokens": ["Da", "man", "k\u00f6n\u00b7te", "se\u00b7hen", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VMFIN", "VVINF", "ART", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Was darinnen wer zufinden/", "tokens": ["Was", "da\u00b7rin\u00b7nen", "wer", "zu\u00b7fin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PWS", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Auff da\u00df alles k\u00e4m\u2019 an Tag.", "tokens": ["Auff", "da\u00df", "al\u00b7les", "k\u00e4m'", "an", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PIS", "VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Dieses war die ander klag/", "tokens": ["Die\u00b7ses", "war", "die", "an\u00b7der", "klag", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJD", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Da\u00df die Schienbein forne st\u00fcnden/", "tokens": ["Da\u00df", "die", "Schien\u00b7bein", "for\u00b7ne", "st\u00fcn\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Da man gr\u00f6ssern schaden nehm/", "tokens": ["Da", "man", "gr\u00f6s\u00b7sern", "scha\u00b7den", "nehm", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJD", "VVINF", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "Wenn man an was hartes kem.", "tokens": ["Wenn", "man", "an", "was", "har\u00b7tes", "kem", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PRELS", "ADJA", "NN", "$."], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.13": {"text": "Hette ", "tokens": ["Het\u00b7te"], "token_info": ["word"], "pos": ["NE"], "meter": "+-", "measure": "trochaic.single"}, "line.14": {"text": "Vnd in acht genommen recht", "tokens": ["Vnd", "in", "acht", "ge\u00b7nom\u00b7men", "recht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "CARD", "VVPP", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "Vnser weibliches geschlecht/", "tokens": ["Vn\u00b7ser", "weib\u00b7li\u00b7ches", "ge\u00b7schlecht", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.16": {"text": "Keinen Gott d\u00f6rsst ernicht schmehen/", "tokens": ["Kei\u00b7nen", "Gott", "d\u00f6rsst", "er\u00b7nicht", "schme\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADJD", "VVINF", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.17": {"text": "Weil an beyden st\u00fccken hier", "tokens": ["Weil", "an", "bey\u00b7den", "st\u00fc\u00b7cken", "hier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PIAT", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.18": {"text": "Gantz keinmangel fellet f\u00fcr.", "tokens": ["Gantz", "kein\u00b7man\u00b7gel", "fel\u00b7let", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "APPR", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.19": {"text": "Hette ", "tokens": ["Het\u00b7te"], "token_info": ["word"], "pos": ["NE"], "meter": "+-", "measure": "trochaic.single"}, "line.20": {"text": "Diese beyde theil besucht/", "tokens": ["Die\u00b7se", "bey\u00b7de", "theil", "be\u00b7sucht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "PIAT", "NN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.21": {"text": "Eh erseinen G\u00f6ttern flucht/", "tokens": ["Eh", "er\u00b7sei\u00b7nen", "G\u00f6t\u00b7tern", "flucht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.22": {"text": "Wer mir nicht will glauben geben/", "tokens": ["Wer", "mir", "nicht", "will", "glau\u00b7ben", "ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "VMFIN", "VVINF", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.23": {"text": "Gehe zu dem Brautbett hin/", "tokens": ["Ge\u00b7he", "zu", "dem", "Braut\u00b7bett", "hin", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "PTKVZ", "$("], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.24": {"text": "Finden wird er bald darin/", "tokens": ["Fin\u00b7den", "wird", "er", "bald", "da\u00b7rin", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "PAV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.25": {"text": "Wie der Breutgam k\u00f6nne machen", "tokens": ["Wie", "der", "Breut\u00b7gam", "k\u00f6n\u00b7ne", "ma\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NE", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.26": {"text": "Da\u00df er dieses Fenster tieff", "tokens": ["Da\u00df", "er", "die\u00b7ses", "Fens\u00b7ter", "tieff"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PDAT", "NN", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.27": {"text": "Oeffne durch sein Perspectieff.", "tokens": ["Oeff\u00b7ne", "durch", "sein", "Per\u00b7spec\u00b7tieff", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.28": {"text": "Wie ermache seine sachen/", "tokens": ["Wie", "er\u00b7ma\u00b7che", "sei\u00b7ne", "sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.29": {"text": "Da\u00df sein liebes Breutelein", "tokens": ["Da\u00df", "sein", "lie\u00b7bes", "Breu\u00b7tel\u00b7ein"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.30": {"text": "Hinden finde zwey Schienbein.", "tokens": ["Hin\u00b7den", "fin\u00b7de", "zwey", "Schien\u00b7bein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "CARD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}