{"textgrid.poem.64170": {"metadata": {"author": {"name": "Dahn, Felix", "birth": "N.A.", "death": "N.A."}, "title": "Donna Bianca Vendramin", "genre": "verse", "period": "N.A.", "pub_year": 1873, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Durch die Stra\u00dfen von Ravenna,", "tokens": ["Durch", "die", "Stra\u00b7\u00dfen", "von", "Ra\u00b7ven\u00b7na", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Durch die Hallen und Pal\u00e4ste", "tokens": ["Durch", "die", "Hal\u00b7len", "und", "Pa\u00b7l\u00e4s\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zwischen Schwarzen l\u00e4ngst und Wei\u00dfen,", "tokens": ["Zwi\u00b7schen", "Schwar\u00b7zen", "l\u00e4ngst", "und", "Wei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ghibellinen tobt und Guelfen", "tokens": ["Ghi\u00b7bel\u00b7li\u00b7nen", "tobt", "und", "Guel\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Unvers\u00f6hnlich grimmer Streit.", "tokens": ["Un\u00b7ver\u00b7s\u00f6hn\u00b7lich", "grim\u00b7mer", "Streit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Aber heute dr\u00e4ngt sich alles,", "tokens": ["A\u00b7ber", "heu\u00b7te", "dr\u00e4ngt", "sich", "al\u00b7les", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PRF", "PIS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ritter, B\u00fcrger, Senatoren,", "tokens": ["Rit\u00b7ter", ",", "B\u00fcr\u00b7ger", ",", "Se\u00b7na\u00b7to\u00b7ren", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In die schwarz verhangne Rota,", "tokens": ["In", "die", "schwarz", "ver\u00b7hang\u00b7ne", "Ro\u00b7ta", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Wo die strengen Richter richten", "tokens": ["Wo", "die", "stren\u00b7gen", "Rich\u00b7ter", "rich\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "\u00dcber blut'ge Freveltat.", "tokens": ["\u00dc\u00b7ber", "blut'\u00b7ge", "Fre\u00b7vel\u00b7tat", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Vendramin, das Haupt der Wei\u00dfen,", "tokens": ["Ven\u00b7dra\u00b7min", ",", "das", "Haupt", "der", "Wei\u00b7\u00dfen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von Ravennas \u00e4ltstem Adel,", "tokens": ["Von", "Ra\u00b7ven\u00b7nas", "\u00e4lts\u00b7tem", "A\u00b7del", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Weise, mild, ein Greis voll Tugend,", "tokens": ["Wei\u00b7se", ",", "mild", ",", "ein", "Greis", "voll", "Tu\u00b7gend", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "$,", "ART", "NN", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Heute nacht ward er ermordet", "tokens": ["Heu\u00b7te", "nacht", "ward", "er", "er\u00b7mor\u00b7det"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVPP", "VAFIN", "PPER", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Auf der Stra\u00dfe nach Forli!", "tokens": ["Auf", "der", "Stra\u00b7\u00dfe", "nach", "For\u00b7li", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NE", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}}, "stanza.4": {"line.1": {"text": "Und in mittern\u00e4cht'ger Stunde", "tokens": ["Und", "in", "mit\u00b7ter\u00b7n\u00e4cht'\u00b7ger", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von den Wei\u00dfen ward ergriffen", "tokens": ["Von", "den", "Wei\u00b7\u00dfen", "ward", "er\u00b7grif\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nah der Casa Vendramini,", "tokens": ["Nah", "der", "Ca\u00b7sa", "Ven\u00b7dra\u00b7mi\u00b7ni", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NE", "NE", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ohne Wehrgeh\u00e4ng und G\u00fcrtel,", "tokens": ["Oh\u00b7ne", "Wehr\u00b7ge\u00b7h\u00e4ng", "und", "G\u00fcr\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Fortunato Loredan.", "tokens": ["For\u00b7tu\u00b7na\u00b7to", "Lo\u00b7re\u00b7dan", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Er, der Schwarzen junger F\u00fchrer,", "tokens": ["Er", ",", "der", "Schwar\u00b7zen", "jun\u00b7ger", "F\u00fch\u00b7rer", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ritterlich und k\u00fchn und feurig:", "tokens": ["Rit\u00b7ter\u00b7lich", "und", "k\u00fchn", "und", "feu\u00b7rig", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Niemand zieh ihn leicht des Mordes \u2013", "tokens": ["Nie\u00b7mand", "zieh", "ihn", "leicht", "des", "Mor\u00b7des", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch er weigert Wort und Auskunft", "tokens": ["Doch", "er", "wei\u00b7gert", "Wort", "und", "Aus\u00b7kunft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und den Argwohn mehrt sein Trotz.", "tokens": ["Und", "den", "Arg\u00b7wohn", "mehrt", "sein", "Trotz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "\u00bbstrenge Rota, sprich dein Urteil.", "tokens": ["\u00bb", "stren\u00b7ge", "Ro\u00b7ta", ",", "sprich", "dein", "Ur\u00b7teil", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "ADV", "PPOSAT", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Was bedarfst du weiter Zeugnis?", "tokens": ["Was", "be\u00b7darfst", "du", "wei\u00b7ter", "Zeug\u00b7nis", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Er verweigert Wort und Auskunft", "tokens": ["Er", "ver\u00b7wei\u00b7gert", "Wort", "und", "Aus\u00b7kunft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und um seine stolzen Lippen", "tokens": ["Und", "um", "sei\u00b7ne", "stol\u00b7zen", "Lip\u00b7pen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Spielt ein siegreich L\u00e4cheln noch.\u00ab", "tokens": ["Spielt", "ein", "sieg\u00b7reich", "L\u00e4\u00b7cheln", "noch", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "ADJD", "NN", "ADV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Also dr\u00e4ngt der Ha\u00df der Wei\u00dfen:", "tokens": ["Al\u00b7so", "dr\u00e4ngt", "der", "Ha\u00df", "der", "Wei\u00b7\u00dfen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch der Konsul, hoch von Ansehn,", "tokens": ["Doch", "der", "Kon\u00b7sul", ",", "hoch", "von", "An\u00b7sehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ADJD", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Spricht: \u00bbIch kann's und will's nicht glauben!", "tokens": ["Spricht", ":", "\u00bb", "Ich", "kann's", "und", "will's", "nicht", "glau\u00b7ben", "!"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "$(", "PPER", "VMFIN", "KON", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nein, du bist kein Meuchelm\u00f6rder,", "tokens": ["Nein", ",", "du", "bist", "kein", "Meu\u00b7chel\u00b7m\u00f6r\u00b7der", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Fortunato Loredan.", "tokens": ["For\u00b7tu\u00b7na\u00b7to", "Lo\u00b7re\u00b7dan", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Aber nun zum letzten Male", "tokens": ["A\u00b7ber", "nun", "zum", "letz\u00b7ten", "Ma\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Frag' ich dich \u2013 es gilt dein Leben \u2013", "tokens": ["Frag'", "ich", "dich", "\u2013", "es", "gilt", "dein", "Le\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PRF", "$(", "PPER", "VVFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sage mir, nur mir, dem Richter,", "tokens": ["Sa\u00b7ge", "mir", ",", "nur", "mir", ",", "dem", "Rich\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "ADV", "PPER", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo du diese Nacht gewesen,", "tokens": ["Wo", "du", "die\u00b7se", "Nacht", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PDAT", "NN", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Als die grause Tat geschah?\u00ab", "tokens": ["Als", "die", "grau\u00b7se", "Tat", "ge\u00b7schah", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Doch das Haupt wirft in den Nacken", "tokens": ["Doch", "das", "Haupt", "wirft", "in", "den", "Na\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Stolzen Blicks der sch\u00f6ne J\u00fcngling:", "tokens": ["Stol\u00b7zen", "Blicks", "der", "sch\u00f6\u00b7ne", "J\u00fcng\u00b7ling", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbedler Konsul, nimm mein Leben,", "tokens": ["\u00bb", "ed\u00b7ler", "Kon\u00b7sul", ",", "nimm", "mein", "Le\u00b7ben", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "VVIMP", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber Himmel nicht noch H\u00f6lle", "tokens": ["A\u00b7ber", "Him\u00b7mel", "nicht", "noch", "H\u00f6l\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "PTKNEG", "ADV", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ringt ein Wort aus meinem Mund.\u00ab", "tokens": ["Ringt", "ein", "Wort", "aus", "mei\u00b7nem", "Mund", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Und schon hebt den Stab der Konsul: \u2013", "tokens": ["Und", "schon", "hebt", "den", "Stab", "der", "Kon\u00b7sul", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "ART", "NN", "$.", "$("], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Horch, da murmelt's durch die Menge:", "tokens": ["Horch", ",", "da", "mur\u00b7melt's", "durch", "die", "Men\u00b7ge", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUS", "NE", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbplatz der Dame! La\u00dft sie nahen,", "tokens": ["\u00bb", "platz", "der", "Da\u00b7me", "!", "La\u00dft", "sie", "na\u00b7hen", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "ART", "NN", "$.", "VVIMP", "PPER", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "'s ist die Nichte des Erschlagnen,", "tokens": ["'s", "ist", "die", "Nich\u00b7te", "des", "Er\u00b7schlag\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Donna Bianca Vendramin.\u00ab", "tokens": ["Don\u00b7na", "Bi\u00b7an\u00b7ca", "Ven\u00b7dra\u00b7min", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Und mit festem raschem Schritte", "tokens": ["Und", "mit", "fes\u00b7tem", "ra\u00b7schem", "Schrit\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch die Halle schwebt das M\u00e4dchen,", "tokens": ["Durch", "die", "Hal\u00b7le", "schwebt", "das", "M\u00e4d\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schwarzen Schleier um die Locken,", "tokens": ["Schwar\u00b7zen", "Schlei\u00b7er", "um", "die", "Lo\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Marmorbleich die edeln Z\u00fcge,", "tokens": ["Mar\u00b7mor\u00b7bleich", "die", "e\u00b7deln", "Z\u00fc\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Doch im Auge Siegesstolz.", "tokens": ["Doch", "im", "Au\u00b7ge", "Sie\u00b7ges\u00b7stolz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "\u00bbedle Herrn,\u00ab spricht sie, \u00bbund Richter,\u00ab", "tokens": ["\u00bb", "ed\u00b7le", "Herrn", ",", "\u00ab", "spricht", "sie", ",", "\u00bb", "und", "Rich\u00b7ter", ",", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "KON", "NN", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u2013 Und sie breitet auf die Tafel", "tokens": ["\u2013", "Und", "sie", "brei\u00b7tet", "auf", "die", "Ta\u00b7fel"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KON", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wehrgeh\u00e4ng und Dolch und G\u00fcrtel \u2013", "tokens": ["Wehr\u00b7ge\u00b7h\u00e4ng", "und", "Dolch", "und", "G\u00fcr\u00b7tel", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00bbzeugnis komm' ich abzulegen", "tokens": ["\u00bb", "zeug\u00b7nis", "komm'", "ich", "ab\u00b7zu\u00b7le\u00b7gen"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "NN", "VVFIN", "PPER", "VVIZU"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Vom Geheimnis dieser Nacht.", "tokens": ["Vom", "Ge\u00b7heim\u00b7nis", "die\u00b7ser", "Nacht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Diese Nacht hat der Signore", "tokens": ["Die\u00b7se", "Nacht", "hat", "der", "Sig\u00b7no\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vor den Toren von Ravenna", "tokens": ["Vor", "den", "To\u00b7ren", "von", "Ra\u00b7ven\u00b7na"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "NE"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Meinen Oheim nicht ermordet,", "tokens": ["Mei\u00b7nen", "O\u00b7heim", "nicht", "er\u00b7mor\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn Signore Loredano \u2013", "tokens": ["Denn", "Sig\u00b7no\u00b7re", "Lo\u00b7re\u00b7da\u00b7no", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Diese Nacht \u2013 war er \u2013 bei mir.\u00ab", "tokens": ["Die\u00b7se", "Nacht", "\u2013", "war", "er", "\u2013", "bei", "mir", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PDAT", "NN", "$(", "VAFIN", "PPER", "$(", "APPR", "PPER", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Sprach's und aus dem G\u00fcrtel ri\u00df sie", "tokens": ["Sprach's", "und", "aus", "dem", "G\u00fcr\u00b7tel", "ri\u00df", "sie"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "KON", "APPR", "ART", "NN", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fortunatos Dolch und hob ihn: \u2013", "tokens": ["For\u00b7tu\u00b7na\u00b7tos", "Dolch", "und", "hob", "ihn", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "KON", "VVFIN", "PPER", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch es fiel von vorn der Konsul,", "tokens": ["Doch", "es", "fiel", "von", "vorn", "der", "Kon\u00b7sul", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ADV", "ART", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Von der Rechten der Geliebte", "tokens": ["Von", "der", "Rech\u00b7ten", "der", "Ge\u00b7lieb\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Selber rasch ihr in den Arm.", "tokens": ["Sel\u00b7ber", "rasch", "ihr", "in", "den", "Arm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Und es sprach der alte Konsul:", "tokens": ["Und", "es", "sprach", "der", "al\u00b7te", "Kon\u00b7sul", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "\u2013 Tr\u00e4nen standen ihm im Auge \u2013", "tokens": ["\u2013", "Tr\u00e4\u00b7nen", "stan\u00b7den", "ihm", "im", "Au\u00b7ge", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "VVFIN", "PPER", "APPRART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u2013 Tr\u00e4nen auch den andern Richtern \u2013", "tokens": ["\u2013", "Tr\u00e4\u00b7nen", "auch", "den", "an\u00b7dern", "Rich\u00b7tern", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "ADV", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00bbniemals hat ein Weib auf Erden", "tokens": ["\u00bb", "nie\u00b7mals", "hat", "ein", "Weib", "auf", "Er\u00b7den"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VAFIN", "ART", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Eine sch\u00f6nre Tat getan.", "tokens": ["Ei\u00b7ne", "sch\u00f6n\u00b7re", "Tat", "ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Heil, Ravenna, dir und Frieden!", "tokens": ["Heil", ",", "Ra\u00b7ven\u00b7na", ",", "dir", "und", "Frie\u00b7den", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NE", "$,", "PPER", "KON", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Guelfen h\u00f6rt's und Ghibellinen,", "tokens": ["Guel\u00b7fen", "h\u00f6rt's", "und", "Ghi\u00b7bel\u00b7li\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nun ist aller Streit geschlichtet", "tokens": ["Nun", "ist", "al\u00b7ler", "Streit", "ge\u00b7schlich\u00b7tet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "VVPP"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Und die Hochzeitglocken l\u00e4uten:", "tokens": ["Und", "die", "Hoch\u00b7zeit\u00b7glo\u00b7cken", "l\u00e4u\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Loredan und Vendramin.\u00ab", "tokens": ["Lo\u00b7re\u00b7dan", "und", "Ven\u00b7dra\u00b7min", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NE", "KON", "NE", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}