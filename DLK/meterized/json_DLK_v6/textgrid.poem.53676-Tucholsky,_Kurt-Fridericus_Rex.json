{"textgrid.poem.53676": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Fridericus Rex", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Fridericus Rex, unser K\u00f6nig und Herr,", "tokens": ["Fri\u00b7de\u00b7ri\u00b7cus", "Rex", ",", "un\u00b7ser", "K\u00f6\u00b7nig", "und", "Herr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "der rief uns noch einmal in das Kino daher.", "tokens": ["der", "rief", "uns", "noch", "ein\u00b7mal", "in", "das", "Ki\u00b7no", "da\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "PAV", "$."], "meter": "-+--+-+-+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Zweitausend Meter lang ist der ganze Quark \u2013", "tokens": ["Zweit\u00b7au\u00b7send", "Me\u00b7ter", "lang", "ist", "der", "gan\u00b7ze", "Quark", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "und jeder Parkettplatz, der kostet sechzehn Mark.", "tokens": ["und", "je\u00b7der", "Par\u00b7kett\u00b7platz", ",", "der", "kos\u00b7tet", "sech\u00b7zehn", "Mark", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "PRELS", "VVFIN", "CARD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "\u00bbihr verfluchten Kerls!\u00ab sprach seine Majest\u00e4t,", "tokens": ["\u00bb", "ihr", "ver\u00b7fluch\u00b7ten", "Kerls", "!", "\u00ab", "sprach", "sei\u00b7ne", "Ma\u00b7jes\u00b7t\u00e4t", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "ADJA", "NN", "$.", "$(", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "\u00bbda\u00df jeder hier im Kino seinen Mann mir steht!\u00ab", "tokens": ["\u00bb", "da\u00df", "je\u00b7der", "hier", "im", "Ki\u00b7no", "sei\u00b7nen", "Mann", "mir", "steht", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PIS", "ADV", "APPRART", "NN", "PPOSAT", "NN", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie sitzen alle stramm und k\u00f6nnen nichts daf\u00fcr", "tokens": ["Sie", "sit\u00b7zen", "al\u00b7le", "stramm", "und", "k\u00f6n\u00b7nen", "nichts", "da\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "KON", "VMFIN", "PIS", "PAV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "und freuen sich \u00fcbern K\u00f6nig und \u00fcber Geb\u00fchr.", "tokens": ["und", "freu\u00b7en", "sich", "\u00fc\u00b7bern", "K\u00f6\u00b7nig", "und", "\u00fc\u00b7ber", "Ge\u00b7b\u00fchr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPRART", "NN", "KON", "APPR", "NN", "$."], "meter": "-+--+-+--+--+", "measure": "iambic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Wir sind doch eine alte Unteroffiziernation,", "tokens": ["Wir", "sind", "doch", "ei\u00b7ne", "al\u00b7te", "Un\u00b7ter\u00b7of\u00b7fi\u00b7zi\u00b7er\u00b7na\u00b7ti\u00b7on", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.2": {"text": "und wir brauchen unsre potsdorfer Pr\u00fcgeltradition.", "tokens": ["und", "wir", "brau\u00b7chen", "uns\u00b7re", "pots\u00b7dor\u00b7fer", "Pr\u00fc\u00b7gel\u00b7tra\u00b7di\u00b7ti\u00b7on", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Kotz Mohren, Blitz und Kreuz-Element,", "tokens": ["Kotz", "Moh\u00b7ren", ",", "Blitz", "und", "Kreuz\u00b7Ele\u00b7ment", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wer den Tritt ins Ges\u00e4\u00df bei der Ausbildung nicht kennt \u2013!", "tokens": ["wer", "den", "Tritt", "ins", "Ge\u00b7s\u00e4\u00df", "bei", "der", "Aus\u00b7bil\u00b7dung", "nicht", "kennt", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "ART", "NN", "APPRART", "NN", "APPR", "ART", "NN", "PTKNEG", "VVFIN", "$(", "$."], "meter": "+-+--+---+--+", "measure": "trochaic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "Da fliegen hundert Beine im Parademarsch.", "tokens": ["Da", "flie\u00b7gen", "hun\u00b7dert", "Bei\u00b7ne", "im", "Pa\u00b7ra\u00b7de\u00b7marsch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "CARD", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und das kitzelt unsre Schenkel, und das juckt uns im Gehirn.", "tokens": ["Und", "das", "kit\u00b7zelt", "uns\u00b7re", "Schen\u00b7kel", ",", "und", "das", "juckt", "uns", "im", "Ge\u00b7hirn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PPOSAT", "NN", "$,", "KON", "PDS", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Die langen Kerls marschieren vorbei in zwei Reihn \u2013", "tokens": ["Die", "lan\u00b7gen", "Kerls", "mar\u00b7schie\u00b7ren", "vor\u00b7bei", "in", "zwei", "Reihn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "APPR", "CARD", "NN", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Wir wollen, wir wollen gepr\u00fcgelt sein!", "tokens": ["Wir", "wol\u00b7len", ",", "wir", "wol\u00b7len", "ge\u00b7pr\u00fc\u00b7gelt", "sein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "PPER", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.5": {"line.1": {"text": "Sieh hin, Lowise, wisch ab dein Gesicht!", "tokens": ["Sieh", "hin", ",", "Lo\u00b7wi\u00b7se", ",", "wisch", "ab", "dein", "Ge\u00b7sicht", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$,", "NN", "$,", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Eine jede Kugel, die trifft ja nicht.", "tokens": ["Ei\u00b7ne", "je\u00b7de", "Ku\u00b7gel", ",", "die", "trifft", "ja", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "$,", "PRELS", "VVFIN", "ADV", "PTKNEG", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Die Kugeln sind alle von Eisen und Blei \u2013", "tokens": ["Die", "Ku\u00b7geln", "sind", "al\u00b7le", "von", "Ei\u00b7sen", "und", "Blei", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIS", "APPR", "NN", "KON", "NN", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "und er kannte nur den Dolchsto\u00df und keine Partei.", "tokens": ["und", "er", "kann\u00b7te", "nur", "den", "Dolch\u00b7sto\u00df", "und", "kei\u00b7ne", "Par\u00b7tei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ART", "NN", "KON", "PIAT", "NN", "$."], "meter": "+-+-+-+--+--+", "measure": "trochaic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Fridericus tut fragend auf der Leinwand gehn.", "tokens": ["Fri\u00b7de\u00b7ri\u00b7cus", "tut", "fra\u00b7gend", "auf", "der", "Lein\u00b7wand", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "\u00bbwo ist denn mein Nachfahr? \u2013 ich kann ihn gar nicht sehn.\u00ab", "tokens": ["\u00bb", "wo", "ist", "denn", "mein", "Nach\u00b7fahr", "?", "\u2013", "ich", "kann", "ihn", "gar", "nicht", "sehn", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "VAFIN", "ADV", "PPOSAT", "NN", "$.", "$(", "PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie du fuhr nach Holland dein gutes Enkelkind,", "tokens": ["Wie", "du", "fuhr", "nach", "Hol\u00b7land", "dein", "gu\u00b7tes", "En\u00b7kel\u00b7kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "APPR", "NE", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "weil die Hohenzollern erblich belastet sind.", "tokens": ["weil", "die", "Ho\u00b7hen\u00b7zol\u00b7lern", "er\u00b7blich", "be\u00b7las\u00b7tet", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJD", "VVPP", "VAFIN", "$."], "meter": "+-+----+-+-+", "measure": "unknown.measure.penta"}}, "stanza.7": {"line.1": {"text": "Fridericus, unser K\u00f6nig, den der Lorbeerkranz ziert,", "tokens": ["Fri\u00b7de\u00b7ri\u00b7cus", ",", "un\u00b7ser", "K\u00f6\u00b7nig", ",", "den", "der", "Lor\u00b7beer\u00b7kranz", "ziert", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-++", "measure": "unknown.measure.octa.plus"}, "line.2": {"text": "du wirst f\u00fcr eine kolossale Pleite plakatiert.", "tokens": ["du", "wirst", "f\u00fcr", "ei\u00b7ne", "ko\u00b7los\u00b7sa\u00b7le", "Plei\u00b7te", "pla\u00b7ka\u00b7tiert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.3": {"text": "Dreh still dich im Grabe, verbirg dein Gesicht:", "tokens": ["Dreh", "still", "dich", "im", "Gra\u00b7be", ",", "ver\u00b7birg", "dein", "Ge\u00b7sicht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "APPRART", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Sie haben deinen Kr\u00fcckstock.", "tokens": ["Sie", "ha\u00b7ben", "dei\u00b7nen", "Kr\u00fcck\u00b7stock", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Deinen Kopf haben sie nicht.", "tokens": ["Dei\u00b7nen", "Kopf", "ha\u00b7ben", "sie", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "PTKNEG", "$."], "meter": "+-+---+", "measure": "unknown.measure.tri"}}}}}