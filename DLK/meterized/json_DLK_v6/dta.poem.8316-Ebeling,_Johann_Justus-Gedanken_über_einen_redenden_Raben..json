{"dta.poem.8316": {"metadata": {"author": {"name": "Ebeling, Johann Justus", "birth": "N.A.", "death": "N.A."}, "title": "Gedanken  \n \u00fcber einen redenden Raben.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1747", "urn": "urn:nbn:de:kobv:b4-200905198782", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ich ging zu einem Freund, der einen Ra-\nben n\u00e4hrt,", "tokens": ["Ich", "ging", "zu", "ei\u00b7nem", "Freund", ",", "der", "ei\u00b7nen", "Ra", "ben", "n\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "PRELS", "ART", "TRUNC", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den ich sonst nie vorher mit Achtsam-", "tokens": ["Den", "ich", "sonst", "nie", "vor\u00b7her", "mit", "Acht\u00b7sam"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "PPER", "ADV", "ADV", "ADV", "APPR", "TRUNC"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was seine Zunge schnarrt, weil er nicht", "tokens": ["Was", "sei\u00b7ne", "Zun\u00b7ge", "schnarrt", ",", "weil", "er", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "PPOSAT", "NN", "VVFIN", "$,", "KOUS", "PPER", "PTKNEG"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Zu reden, wenn ich sonst vor ihm vorbei gegan-", "tokens": ["Zu", "re\u00b7den", ",", "wenn", "ich", "sonst", "vor", "ihm", "vor\u00b7bei", "ge\u00b7gan"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$,", "KOUS", "PPER", "ADV", "APPR", "PPER", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch j\u00fcngst erfuhr ich es, da ich den Kefich nah,", "tokens": ["Doch", "j\u00fcngst", "er\u00b7fuhr", "ich", "es", ",", "da", "ich", "den", "Ke\u00b7fich", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPER", "$,", "KOUS", "PPER", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und er mich in das Haus von ferne kommen sah,", "tokens": ["Und", "er", "mich", "in", "das", "Haus", "von", "fer\u00b7ne", "kom\u00b7men", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PRF", "APPR", "ART", "NN", "APPR", "ADV", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Er fing in seiner Sprach ganz grob mich anzu-", "tokens": ["Er", "fing", "in", "sei\u00b7ner", "Sprach", "ganz", "grob", "mich", "an\u00b7zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "ADV", "ADJD", "PPER", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und sprach das, was er kan, er sprach von nichts", "tokens": ["Und", "sprach", "das", ",", "was", "er", "kan", ",", "er", "sprach", "von", "nichts"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PDS", "$,", "PWS", "PPER", "VMFIN", "$,", "PPER", "VVFIN", "APPR", "PIS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Ich merkte dieses Thier in seinem Kefig nicht,", "tokens": ["Ich", "merk\u00b7te", "die\u00b7ses", "Thier", "in", "sei\u00b7nem", "Ke\u00b7fig", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDAT", "NN", "APPR", "PPOSAT", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ich drehte hie und da, verwundernt mein Gesicht,", "tokens": ["Ich", "dreh\u00b7te", "hie", "und", "da", ",", "ver\u00b7wun\u00b7dernt", "mein", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "ADV", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ich dachte welcher Feind sucht dich allhie zu schm\u00e4h-", "tokens": ["Ich", "dach\u00b7te", "wel\u00b7cher", "Feind", "sucht", "dich", "all\u00b7hie", "zu", "schm\u00e4h"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PWAT", "NN", "VVFIN", "PPER", "ADV", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und durch den groben Schimpf so unverdient zu", "tokens": ["Und", "durch", "den", "gro\u00b7ben", "Schimpf", "so", "un\u00b7ver\u00b7di\u00b7ent", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ADV", "ADJD", "PTKZU"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Er schimpfte noch einmahl du Narr, da sah ich an,", "tokens": ["Er", "schimpf\u00b7te", "noch", "ein\u00b7mahl", "du", "Narr", ",", "da", "sah", "ich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "NE", "NE", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Da\u00df es der alte Schalk, der grobe Hans gethan,", "tokens": ["Da\u00df", "es", "der", "al\u00b7te", "Schalk", ",", "der", "gro\u00b7be", "Hans", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "$,", "ART", "ADJA", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Mein Zorn verkehrte sich in ein erg\u00f6zzend Lachen,", "tokens": ["Mein", "Zorn", "ver\u00b7kehr\u00b7te", "sich", "in", "ein", "er\u00b7g\u00f6z\u00b7zend", "La\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "APPR", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und dachte wer kan was aus einen Schimpfwort", "tokens": ["Und", "dach\u00b7te", "wer", "kan", "was", "aus", "ei\u00b7nen", "Schimpf\u00b7wort"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PWS", "VMFIN", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Das ein so dummes Thier, durch deine Gegen-", "tokens": ["Das", "ein", "so", "dum\u00b7mes", "Thier", ",", "durch", "dei\u00b7ne", "Ge\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "ART", "ADV", "ADJA", "NN", "$,", "APPR", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Gleichsam erz\u00fcrnet, spricht, mit vollen Eifer", "tokens": ["Gleich\u00b7sam", "er\u00b7z\u00fcr\u00b7net", ",", "spricht", ",", "mit", "vol\u00b7len", "Ei\u00b7fer"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "$,", "VVFIN", "$,", "APPR", "ADJA", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.19": {"text": "Es hat sonst nichts gelernt; ich will es ihm verge-", "tokens": ["Es", "hat", "sonst", "nichts", "ge\u00b7lernt", ";", "ich", "will", "es", "ihm", "ver\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PIS", "VVPP", "$.", "PPER", "VMFIN", "PPER", "PPER", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Ich w\u00fcnschte meinen Freund so lange nur zu leben,", "tokens": ["Ich", "w\u00fcnschte", "mei\u00b7nen", "Freund", "so", "lan\u00b7ge", "nur", "zu", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.21": {"text": "Als er noch schelten kan. Ich ging hinein ins Haus", "tokens": ["Als", "er", "noch", "schel\u00b7ten", "kan", ".", "Ich", "ging", "hin\u00b7ein", "ins", "Haus"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VMFIN", "$.", "PPER", "VVFIN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und kam hinwiederum, durch solche Th\u00fcr heraus,", "tokens": ["Und", "kam", "hin\u00b7wie\u00b7de\u00b7rum", ",", "durch", "sol\u00b7che", "Th\u00fcr", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "APPR", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Wo er durchs Gitter gukt, ich dachte was wirds", "tokens": ["Wo", "er", "durchs", "Git\u00b7ter", "gukt", ",", "ich", "dach\u00b7te", "was", "wirds"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPRART", "NN", "VVFIN", "$,", "PPER", "VVFIN", "PWS", "VAFIN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.24": {"text": "Er wird dich wiederum, vor einen Narren schelten.", "tokens": ["Er", "wird", "dich", "wie\u00b7de\u00b7rum", ",", "vor", "ei\u00b7nen", "Nar\u00b7ren", "schel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "$,", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Allein er lie\u00df mich gehn, mit stummer H\u00f6flichkeit,", "tokens": ["Al\u00b7lein", "er", "lie\u00df", "mich", "gehn", ",", "mit", "stum\u00b7mer", "H\u00f6f\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PRF", "VVINF", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Vielleicht nur blos darum, weil seine Ruhezeit", "tokens": ["Viel\u00b7leicht", "nur", "blos", "da\u00b7rum", ",", "weil", "sei\u00b7ne", "Ru\u00b7he\u00b7zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "PAV", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Schon da war, weil er m\u00fcd, und nicht mehr", "tokens": ["Schon", "da", "war", ",", "weil", "er", "m\u00fcd", ",", "und", "nicht", "mehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "$,", "KOUS", "PPER", "ADJD", "$,", "KON", "PTKNEG", "ADV"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.28": {"text": "Als er mir zu Gefalln, so grobe reden solte.", "tokens": ["Als", "er", "mir", "zu", "Ge\u00b7falln", ",", "so", "gro\u00b7be", "re\u00b7den", "sol\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPR", "NN", "$,", "ADV", "ADJA", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "So bald ich nur zu Haus fiel mir beim Raben ein,", "tokens": ["So", "bald", "ich", "nur", "zu", "Haus", "fiel", "mir", "beim", "Ra\u00b7ben", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADV", "APPR", "NN", "VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Ach! m\u00f6chten wir doch stets auch so gesinnet seyn,", "tokens": ["Ach", "!", "m\u00f6ch\u00b7ten", "wir", "doch", "stets", "auch", "so", "ge\u00b7sin\u00b7net", "seyn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VMFIN", "PPER", "ADV", "ADV", "ADV", "ADV", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Wenn uns ein L\u00e4strer schimpft, die Z\u00e4hne an uns", "tokens": ["Wenn", "uns", "ein", "L\u00e4st\u00b7rer", "schimpft", ",", "die", "Z\u00e4h\u00b7ne", "an", "uns"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "ART", "NN", "APPR", "PPER"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.32": {"text": "Und nur die eigne Ehr, nicht anderen verlezzet!", "tokens": ["Und", "nur", "die", "eig\u00b7ne", "Ehr", ",", "nicht", "an\u00b7de\u00b7ren", "ver\u00b7lez\u00b7zet", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "$,", "PTKNEG", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Ach! d\u00e4chten wir auch stets wer ists? der uns anklagt,", "tokens": ["Ach", "!", "d\u00e4ch\u00b7ten", "wir", "auch", "stets", "wer", "ists", "?", "der", "uns", "an\u00b7klagt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "ADV", "ADV", "PWS", "VAFIN", "$.", "ART", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Was hat der L\u00e4sterer uns denn zum Schimpf gesagt,", "tokens": ["Was", "hat", "der", "L\u00e4s\u00b7te\u00b7rer", "uns", "denn", "zum", "Schimpf", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "PPER", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Der Rabe spricht du Narr, wir lachen noch dar\u00fc-", "tokens": ["Der", "Ra\u00b7be", "spricht", "du", "Narr", ",", "wir", "la\u00b7chen", "noch", "dar\u00b7\u00fc"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "NN", "$,", "PPER", "VVFIN", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Und h\u00f6ren wenn er schilt, als wenn er lobet lieber,", "tokens": ["Und", "h\u00f6\u00b7ren", "wenn", "er", "schilt", ",", "als", "wenn", "er", "lo\u00b7bet", "lie\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOUS", "PPER", "VVFIN", "$,", "KOKOM", "KOUS", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Warum? wir denken so, er hat sonst nichts ge-", "tokens": ["Wa\u00b7rum", "?", "wir", "den\u00b7ken", "so", ",", "er", "hat", "sonst", "nichts", "ge"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "PPER", "VVFIN", "ADV", "$,", "PPER", "VAFIN", "ADV", "PIS", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.38": {"text": "Er h\u00f6ret wieder auf, wenn man sich nur entfernt.", "tokens": ["Er", "h\u00f6\u00b7ret", "wie\u00b7der", "auf", ",", "wenn", "man", "sich", "nur", "ent\u00b7fernt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$,", "KOUS", "PIS", "PRF", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Wie k\u00f6nten wir nicht auch so von den Menschen denken", "tokens": ["Wie", "k\u00f6n\u00b7ten", "wir", "nicht", "auch", "so", "von", "den", "Men\u00b7schen", "den\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "PPER", "PTKNEG", "ADV", "ADV", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Die uns mit L\u00e4sterung bei reiner Unschuld kr\u00e4nken?", "tokens": ["Die", "uns", "mit", "L\u00e4s\u00b7te\u00b7rung", "bei", "rei\u00b7ner", "Un\u00b7schuld", "kr\u00e4n\u00b7ken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Allein so bald ein Mensch, der warlich Raben-Art", "tokens": ["Al\u00b7lein", "so", "bald", "ein", "Mensch", ",", "der", "war\u00b7lich", "Ra\u00b7ben\u00b7Art"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "ART", "NN", "$,", "PRELS", "ADV", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Uns durch ein Schimpfwort schilt in unsrer Gegen-", "tokens": ["Uns", "durch", "ein", "Schimpf\u00b7wort", "schilt", "in", "uns\u00b7rer", "Ge\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "NN", "VVFIN", "APPR", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.43": {"text": "So werden wir ergrimmt, wir suchen ihm sein", "tokens": ["So", "wer\u00b7den", "wir", "er\u00b7grimmt", ",", "wir", "su\u00b7chen", "ihm", "sein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "PPOSAT"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.44": {"text": "Mit einer gleichen M\u00fcnz gedoppelt zu vergelten.", "tokens": ["Mit", "ei\u00b7ner", "glei\u00b7chen", "M\u00fcnz", "ge\u00b7dop\u00b7pelt", "zu", "ver\u00b7gel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Und wird uns nur gesagt, da\u00df eine L\u00e4sterzung", "tokens": ["Und", "wird", "uns", "nur", "ge\u00b7sagt", ",", "da\u00df", "ei\u00b7ne", "L\u00e4s\u00b7ter\u00b7zung"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "VVPP", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Mit Geiffer uns bespr\u00fczt, so folgt Erbitterung", "tokens": ["Mit", "Geif\u00b7fer", "uns", "be\u00b7spr\u00fczt", ",", "so", "folgt", "Er\u00b7bit\u00b7te\u00b7rung"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "PPER", "VVPP", "$,", "ADV", "VVFIN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Die gleich auf Rache denkt, wir suchen den zu", "tokens": ["Die", "gleich", "auf", "Ra\u00b7che", "denkt", ",", "wir", "su\u00b7chen", "den", "zu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "NN", "VVFIN", "$,", "PPER", "VVFIN", "ART", "PTKZU"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.48": {"text": "Der uns zur Ungeb\u00fchr, mit L\u00e4sterung beladen.", "tokens": ["Der", "uns", "zur", "Un\u00b7ge\u00b7b\u00fchr", ",", "mit", "L\u00e4s\u00b7te\u00b7rung", "be\u00b7la\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "So lieblos ist der Mensch, er zieht ein albern", "tokens": ["So", "lieb\u00b7los", "ist", "der", "Mensch", ",", "er", "zieht", "ein", "al\u00b7bern"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VAFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.50": {"text": "Das ihn mit Grobheit schimpft, selbst einem Men-", "tokens": ["Das", "ihn", "mit", "Grob\u00b7heit", "schimpft", ",", "selbst", "ei\u00b7nem", "Men"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "PPER", "APPR", "NN", "VVFIN", "$,", "ADV", "ART", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.51": {"text": "Er pflegt den Raben gern von Schimpfe frei zu", "tokens": ["Er", "pflegt", "den", "Ra\u00b7ben", "gern", "von", "Schimp\u00b7fe", "frei", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "APPR", "NN", "ADJD", "PTKZU"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.52": {"text": "Und will dagegen sich doch an den Menschen r\u00e4chen.", "tokens": ["Und", "will", "da\u00b7ge\u00b7gen", "sich", "doch", "an", "den", "Men\u00b7schen", "r\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PAV", "PRF", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Ja! sagst du das ist recht das Thier versteht es", "tokens": ["Ja", "!", "sagst", "du", "das", "ist", "recht", "das", "Thier", "ver\u00b7steht", "es"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$.", "VVFIN", "PPER", "PDS", "VAFIN", "ADJD", "ART", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.54": {"text": "Ein Rabe schimpft uns nicht, weil er als Rabe", "tokens": ["Ein", "Ra\u00b7be", "schimpft", "uns", "nicht", ",", "weil", "er", "als", "Ra\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKNEG", "$,", "KOUS", "PPER", "KOUS", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.55": {"text": "Allein ein Mensche mu\u00df auch als ein Mensche spre-", "tokens": ["Al\u00b7lein", "ein", "Men\u00b7sche", "mu\u00df", "auch", "als", "ein", "Men\u00b7sche", "spre"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VMFIN", "ADV", "KOUS", "ART", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Sonst mu\u00df man wenn er schimpft, ihm das Ge-", "tokens": ["Sonst", "mu\u00df", "man", "wenn", "er", "schimpft", ",", "ihm", "das", "Ge"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PIS", "KOUS", "PPER", "VVFIN", "$,", "PPER", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.57": {"text": "O! \u00fcbereil dich nicht, in deiner blinden Wuth,", "tokens": ["O", "!", "\u00fc\u00b7be\u00b7reil", "dich", "nicht", ",", "in", "dei\u00b7ner", "blin\u00b7den", "Wuth", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "KOUS", "PPER", "PTKNEG", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Ich zweifle noch daran, ob ers als Mensche thut.", "tokens": ["Ich", "zweif\u00b7le", "noch", "da\u00b7ran", ",", "ob", "ers", "als", "Men\u00b7sche", "thut", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PAV", "$,", "KOUS", "PIS", "KOKOM", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Ein L\u00e4strer ist ein Mensch, nach den Gesichtes Z\u00fc-", "tokens": ["Ein", "L\u00e4st\u00b7rer", "ist", "ein", "Mensch", ",", "nach", "den", "Ge\u00b7sich\u00b7tes", "Z\u00fc"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$,", "APPR", "ART", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "In seiner Seele wohnt der Geist der schwarzen L\u00fc-", "tokens": ["In", "sei\u00b7ner", "See\u00b7le", "wohnt", "der", "Geist", "der", "schwar\u00b7zen", "L\u00fc"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "NN", "ART", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Er ist auch Raben-Art, weil er nichts anders kan,", "tokens": ["Er", "ist", "auch", "Ra\u00b7ben\u00b7Art", ",", "weil", "er", "nichts", "an\u00b7ders", "kan", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "$,", "KOUS", "PPER", "PIS", "ADV", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Als da\u00df er solche schimpft, die ihn nur sehen an:", "tokens": ["Als", "da\u00df", "er", "sol\u00b7che", "schimpft", ",", "die", "ihn", "nur", "se\u00b7hen", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "PIS", "VVFIN", "$,", "PRELS", "PPER", "ADV", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Schweig still, entferne dich und la\u00df ihn immer to-", "tokens": ["Schweig", "still", ",", "ent\u00b7fer\u00b7ne", "dich", "und", "la\u00df", "ihn", "im\u00b7mer", "to"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKVZ", "$,", "VVFIN", "PPER", "KON", "VVIMP", "PPER", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Der L\u00e4strer Tadelsucht ist gut bei Schmeichlers Lo-", "tokens": ["Der", "L\u00e4st\u00b7rer", "Ta\u00b7del\u00b7sucht", "ist", "gut", "bei", "Schmeich\u00b7lers", "Lo"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VAFIN", "ADJD", "APPR", "NE", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}