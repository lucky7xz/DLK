{"dta.poem.19093": {"metadata": {"author": {"name": "Zinzendorf, Nicolaus Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "LxXV.   Auf der Gr\u00e4fin Louyse zu Solms  \n Heimhohlung.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20688-6", "language": ["de:0.99"], "booktitle": "Zinzendorf, Nicolaus Ludwig von: Teutscher Gedichte Erster Theil. Herrnhuth, 1735."}, "poem": {"stanza.1": {"line.1": {"text": "Die kleine M\u00fch, das kurtze Streiten, bringt unaus-\nsprechlich s\u00fcsse Ruh,", "tokens": ["Die", "klei\u00b7ne", "M\u00fch", ",", "das", "kurt\u00b7ze", "Strei\u00b7ten", ",", "bringt", "un\u00b7aus", "sprech\u00b7lich", "s\u00fcs\u00b7se", "Ruh", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,", "VVFIN", "TRUNC", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Die tiefste GOttes Heimlichkeiten aus Zion fliessen de-\nnen zu,", "tokens": ["Die", "tiefs\u00b7te", "Got\u00b7tes", "Heim\u00b7lich\u00b7kei\u00b7ten", "aus", "Zi\u00b7on", "flies\u00b7sen", "de", "nen", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "APPR", "NE", "VVINF", "TRUNC", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Die aller Dinge sich enthalten, auch nicht das Kleinste\nr\u00fchren an:", "tokens": ["Die", "al\u00b7ler", "Din\u00b7ge", "sich", "ent\u00b7hal\u00b7ten", ",", "auch", "nicht", "das", "Kleins\u00b7te", "r\u00fch\u00b7ren", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "PRF", "VVPP", "$,", "ADV", "PTKNEG", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.4": {"text": "L\u00e4st man den Br\u00e4utigam nur walten, so sieht man, was\ndie Liebe kan.", "tokens": ["L\u00e4st", "man", "den", "Br\u00e4u\u00b7ti\u00b7gam", "nur", "wal\u00b7ten", ",", "so", "sieht", "man", ",", "was", "die", "Lie\u00b7be", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NE", "ADV", "VVINF", "$,", "ADV", "VVFIN", "PIS", "$,", "PRELS", "ART", "NN", "VMFIN", "$."], "meter": "+--+-+-+--+-+-+-+", "measure": "iambic.octa.plus.invert"}}, "stanza.2": {"line.1": {"text": "Die Liebe cr\u00f6nt des Lamms Jungfrauen, und f\u00fchrt sie\nvor des Vaters Thron,", "tokens": ["Die", "Lie\u00b7be", "cr\u00f6nt", "des", "Lamms", "Jung\u00b7frau\u00b7en", ",", "und", "f\u00fchrt", "sie", "vor", "des", "Va\u00b7ters", "Thron", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "NN", "$,", "KON", "VVFIN", "PPER", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Den nur ein reines Hertz darf schauen, die Liebe wird\nder Keuschheit Lohn.", "tokens": ["Den", "nur", "ein", "rei\u00b7nes", "Hertz", "darf", "schau\u00b7en", ",", "die", "Lie\u00b7be", "wird", "der", "Keuschheit", "Lohn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "VMFIN", "VVINF", "$,", "ART", "NN", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+--+-+--+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Mir ists so neulich als von gestern. J\u00fcngst tratest du in unser", "tokens": ["Mir", "ists", "so", "neu\u00b7lich", "als", "von", "ge\u00b7stern", ".", "J\u00fcngst", "tra\u00b7test", "du", "in", "un\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "KOKOM", "APPR", "ADV", "$.", "NN", "VVFIN", "PPER", "APPR", "PPOSAT"], "meter": "-+-+--+-+-+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.3": {"line.1": {"text": "Kaum, da\u00df uns dein Gesicht erschienen, kaum da\u00df dein Glaub", "tokens": ["Kaum", ",", "da\u00df", "uns", "dein", "Ge\u00b7sicht", "er\u00b7schie\u00b7nen", ",", "kaum", "da\u00df", "dein", "Glaub"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVINF", "$,", "ADV", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Die wir des K\u00f6nigs Willen dienen, (doch leider! noch nicht", "tokens": ["Die", "wir", "des", "K\u00f6\u00b7nigs", "Wil\u00b7len", "die\u00b7nen", ",", "(", "doch", "lei\u00b7der", "!", "noch", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "PPER", "ART", "NN", "NN", "VVINF", "$,", "$(", "ADV", "ADV", "$.", "ADV", "PTKNEG"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "So ward es wieder weggenommen, ", "tokens": ["So", "ward", "es", "wie\u00b7der", "weg\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In Bielitz auch zur Ruhe kommen. So wolte GOtt! so ists ge-", "tokens": ["In", "Bie\u00b7litz", "auch", "zur", "Ru\u00b7he", "kom\u00b7men", ".", "So", "wol\u00b7te", "Gott", "!", "so", "ists", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "ADV", "APPRART", "NN", "VVINF", "$.", "ADV", "VMFIN", "NN", "$.", "ADV", "VAFIN", "TRUNC"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.4": {"line.1": {"text": "Wir sitzen gleich beym Abend-Essen, ", "tokens": ["Wir", "sit\u00b7zen", "gleich", "beym", "A\u00b7ben\u00b7dEs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Lonyse ist uns unvergessen, was kan uns angenehmer seyn?", "tokens": ["Lo\u00b7ny\u00b7se", "ist", "uns", "un\u00b7ver\u00b7ges\u00b7sen", ",", "was", "kan", "uns", "an\u00b7ge\u00b7neh\u00b7mer", "seyn", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADJD", "$,", "PWS", "VMFIN", "PPER", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Kommt zu uns, schreibst du, liebe Kinder! kan ich nicht\nkommen, so kommt ihr,", "tokens": ["Kommt", "zu", "uns", ",", "schreibst", "du", ",", "lie\u00b7be", "Kin\u00b7der", "!", "kan", "ich", "nicht", "kom\u00b7men", ",", "so", "kommt", "ihr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "$,", "VVFIN", "PPER", "$,", "ADJA", "NN", "$.", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,", "ADV", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+--+--+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Der Liebe, meinem Uberwinder, ist auch das Bielitzer\nRevier.", "tokens": ["Der", "Lie\u00b7be", ",", "mei\u00b7nem", "U\u00b7ber\u00b7win\u00b7der", ",", "ist", "auch", "das", "Bie\u00b7lit\u00b7zer", "Re\u00b7vier", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPOSAT", "NN", "$,", "VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+--+--+-", "measure": "iambic.septa.relaxed"}}, "stanza.5": {"line.1": {"text": "Ich kan nicht mehr, so gern ich schriebe; so schlossest du das\ntheure Blat,\nGnug, da\u00df mein Hertz euch in die Liebe die mich besitzt,\nergeben hat.", "tokens": ["Ich", "kan", "nicht", "mehr", ",", "so", "gern", "ich", "schrie\u00b7be", ";", "so", "schlos\u00b7sest", "du", "das", "theu\u00b7re", "Blat", ",", "Gnug", ",", "da\u00df", "mein", "Hertz", "euch", "in", "die", "Lie\u00b7be", "die", "mich", "be\u00b7sitzt", ",", "er\u00b7ge\u00b7ben", "hat", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "$,", "ADV", "ADV", "PPER", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,", "ADV", "$,", "KOUS", "PPOSAT", "NN", "PPER", "APPR", "ART", "NN", "ART", "PPER", "VVFIN", "$,", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+--+-+-+-++--+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Ich lieb euch aller End und Orten mit Schwesterlicher\nZ\u00e4rtlichkeit.", "tokens": ["Ich", "lieb", "euch", "al\u00b7ler", "End", "und", "Or\u00b7ten", "mit", "Schwes\u00b7ter\u00b7li\u00b7cher", "Z\u00e4rt\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "NN", "KON", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Dein Vater endigt mit den Worten: ", "tokens": ["Dein", "Va\u00b7ter", "en\u00b7digt", "mit", "den", "Wor\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "So ists! wir spielen mit dem Sterben. Die H\u00fctte ist bald", "tokens": ["So", "ists", "!", "wir", "spie\u00b7len", "mit", "dem", "Ster\u00b7ben", ".", "Die", "H\u00fct\u00b7te", "ist", "bald"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "$.", "PPER", "VVFIN", "APPR", "ART", "NN", "$.", "ART", "NN", "VAFIN", "ADV"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Wenn nur das s\u00fcndliche Verderben die Seele nicht mehr nie-", "tokens": ["Wenn", "nur", "das", "s\u00fcnd\u00b7li\u00b7che", "Ver\u00b7der\u00b7ben", "die", "See\u00b7le", "nicht", "mehr", "nie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "ART", "NN", "PTKNEG", "ADV", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Bey t\u00e4glich ausgestandnem Tode, hats mit dem Tode keine", "tokens": ["Bey", "t\u00e4g\u00b7lich", "aus\u00b7ge\u00b7stand\u00b7nem", "To\u00b7de", ",", "hats", "mit", "dem", "To\u00b7de", "kei\u00b7ne"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$,", "VAFIN", "APPR", "ART", "NN", "PIAT"], "meter": "-+-+-+-+-+--+-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Nach Josua und Calebs Mode fri\u00dft ihn ein GOttes-Mensch", "tokens": ["Nach", "Jo\u00b7sua", "und", "Ca\u00b7lebs", "Mo\u00b7de", "fri\u00dft", "ihn", "ein", "Got\u00b7tes\u00b7Mensch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "KON", "NE", "NN", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+-+--+-+", "measure": "trochaic.septa.relaxed"}}, "stanza.7": {"line.1": {"text": "Mein Hirt! wie komm ich doch hin\u00fcber. Das ist der\nHelden Glaubens-Wort,", "tokens": ["Mein", "Hirt", "!", "wie", "komm", "ich", "doch", "hin\u00b7\u00fc\u00b7ber", ".", "Das", "ist", "der", "Hel\u00b7den", "Glau\u00b7bens\u00b7Wort", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PWAV", "VVFIN", "PPER", "ADV", "ADV", "$.", "PDS", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Kaum ists geredt, so sind sie dr\u00fcber. So gehts durchs gantze", "tokens": ["Kaum", "ists", "ge\u00b7redt", ",", "so", "sind", "sie", "dr\u00fc\u00b7ber", ".", "So", "gehts", "durchs", "gant\u00b7ze"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "VVPP", "$,", "ADV", "VAFIN", "PPER", "PAV", "$.", "ADV", "VVFIN", "APPRART", "ADJA"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Gewi\u00df! wenn einem bey dem Schmertze die Zeit und Weile", "tokens": ["Ge\u00b7wi\u00df", "!", "wenn", "ei\u00b7nem", "bey", "dem", "Schmert\u00b7ze", "die", "Zeit", "und", "Wei\u00b7le"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$.", "KOUS", "ART", "APPR", "ART", "NN", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "So wird ihm gantz geraum ums Hertze, wenn er in eine Ohn-", "tokens": ["So", "wird", "ihm", "gantz", "ge\u00b7raum", "ums", "Hert\u00b7ze", ",", "wenn", "er", "in", "ei\u00b7ne", "Ohn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "APPRART", "VVFIN", "$,", "KOUS", "PPER", "APPR", "ART", "TRUNC"], "meter": "-+-+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}}, "stanza.8": {"line.1": {"text": "So dachten wir, indem wir lasen: ", "tokens": ["So", "dach\u00b7ten", "wir", ",", "in\u00b7dem", "wir", "la\u00b7sen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Uns war zum Abendmahl geblasen, ihr zur ", "tokens": ["Uns", "war", "zum", "A\u00b7bend\u00b7mahl", "ge\u00b7bla\u00b7sen", ",", "ihr", "zur"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "VVPP", "$,", "PPER", "APPRART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Verkl\u00e4rte! hier hat dein Geschwister gar hertzlich \u00fcber dir\ngethan.", "tokens": ["Ver\u00b7kl\u00e4r\u00b7te", "!", "hier", "hat", "dein", "Ge\u00b7schwis\u00b7ter", "gar", "hertz\u00b7lich", "\u00fc\u00b7ber", "dir", "ge\u00b7than", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "ADV", "VAFIN", "PPOSAT", "NN", "ADV", "ADJD", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "In unsrer Redlichen Register stehst du gewi\u00df mit oben an.", "tokens": ["In", "uns\u00b7rer", "Red\u00b7li\u00b7chen", "Re\u00b7gis\u00b7ter", "stehst", "du", "ge\u00b7wi\u00df", "mit", "o\u00b7ben", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VVFIN", "PPER", "ADV", "APPR", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+--+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Drum was ich, ", "tokens": ["Drum", "was", "ich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "PWS", "PPER", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Nach dieser Zeitung aufgeworffen, war ", "tokens": ["Nach", "die\u00b7ser", "Zei\u00b7tung", "auf\u00b7ge\u00b7worf\u00b7fen", ",", "war"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "PDAT", "NN", "VVPP", "$,", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Ein theurer Knecht der grossen Liebe, ein Bild von Christi", "tokens": ["Ein", "theu\u00b7rer", "Knecht", "der", "gros\u00b7sen", "Lie\u00b7be", ",", "ein", "Bild", "von", "Chris\u00b7ti"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "$,", "ART", "NN", "APPR", "NE"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der grosse Mann, der, weil er lebte, auch die ", "tokens": ["Der", "gros\u00b7se", "Mann", ",", "der", ",", "weil", "er", "leb\u00b7te", ",", "auch", "die"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "$,", "KOUS", "PPER", "VVFIN", "$,", "ADV", "ART"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Ein J\u00fcnger, der an JEsu klebte, der machte ihr den HErrn", "tokens": ["Ein", "J\u00fcn\u00b7ger", ",", "der", "an", "Je\u00b7su", "kleb\u00b7te", ",", "der", "mach\u00b7te", "ihr", "den", "Herrn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "NE", "VVFIN", "$,", "PRELS", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.11": {"line.1": {"text": "Sein erster Antrag war nicht gl\u00fccklich. Er warb sie vor den", "tokens": ["Sein", "ers\u00b7ter", "An\u00b7trag", "war", "nicht", "gl\u00fcck\u00b7lich", ".", "Er", "warb", "sie", "vor", "den"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "PTKNEG", "ADJD", "$.", "PPER", "VVFIN", "PPER", "APPR", "ART"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Das dauchte ihr gar ungeschicklich. Die Niedrigkeit ist uns", "tokens": ["Das", "dauch\u00b7te", "ihr", "gar", "un\u00b7ge\u00b7schick\u00b7lich", ".", "Die", "Nied\u00b7rig\u00b7keit", "ist", "uns"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADJD", "$.", "ART", "NN", "VAFIN", "PPER"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "So lang wir mit geborgten Federn, der unvern\u00fcnftgen Stan-", "tokens": ["So", "lang", "wir", "mit", "ge\u00b7borg\u00b7ten", "Fe\u00b7dern", ",", "der", "un\u00b7ver\u00b7n\u00fcnft\u00b7gen", "Stan"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "PPER", "APPR", "ADJA", "NN", "$,", "ART", "ADJA", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Uns annoch suchen aufzubl\u00e4dern; so grauet uns f\u00fcr solcher Eh.", "tokens": ["Uns", "an\u00b7noch", "su\u00b7chen", "auf\u00b7zu\u00b7bl\u00e4\u00b7dern", ";", "so", "grau\u00b7et", "uns", "f\u00fcr", "sol\u00b7cher", "Eh", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVINF", "VVINF", "$.", "ADV", "VVFIN", "PPER", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.12": {"line.1": {"text": "Der Werber sagte: Sie mu\u00df wissen, mein Principal ist auch ein", "tokens": ["Der", "Wer\u00b7ber", "sag\u00b7te", ":", "Sie", "mu\u00df", "wis\u00b7sen", ",", "mein", "Prin\u00b7ci\u00b7pal", "ist", "auch", "ein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "PPER", "VMFIN", "VVINF", "$,", "PPOSAT", "NN", "VAFIN", "ADV", "ART"], "meter": "-+-+-+-+--+-++-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Die Liebe hat ihn hergerissen, ihn hat nach unserm Heyl ged\u00fcrst.", "tokens": ["Die", "Lie\u00b7be", "hat", "ihn", "her\u00b7ge\u00b7ris\u00b7sen", ",", "ihn", "hat", "nach", "un\u00b7serm", "Heyl", "ge\u00b7d\u00fcrst", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$,", "PPER", "VAFIN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Drum must er alle Hoheit meiden, itzt prangt er in der Herr-", "tokens": ["Drum", "must", "er", "al\u00b7le", "Ho\u00b7heit", "mei\u00b7den", ",", "itzt", "prangt", "er", "in", "der", "Herr"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VMFIN", "PPER", "PIAT", "NN", "VVINF", "$,", "ADV", "VVFIN", "PPER", "APPR", "ART", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Das mochte die Comtesse leiden, doch bliebs bey Worten noch", "tokens": ["Das", "moch\u00b7te", "die", "Com\u00b7tes\u00b7se", "lei\u00b7den", ",", "doch", "bliebs", "bey", "Wor\u00b7ten", "noch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "VVINF", "$,", "ADV", "VVFIN", "APPR", "NN", "ADV"], "meter": "-+--+--+--+-+-+", "measure": "amphibrach.tetra.plus"}}, "stanza.13": {"line.1": {"text": "In mehrern Jahren kam er wieder, der Mann, der um die", "tokens": ["In", "meh\u00b7rern", "Jah\u00b7ren", "kam", "er", "wie\u00b7der", ",", "der", "Mann", ",", "der", "um", "die"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "ADV", "$,", "ART", "NN", "$,", "PRELS", "APPR", "ART"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Will sie, so sprach er, mit ihm ziehen. Jtzt ruhte Elieser\nnicht, 1. B. Mos. 14, 33.\nLouyse konte nicht entfliehen. Man wei\u00df, wie JEsus See-\nlen kriegt.", "tokens": ["Will", "sie", ",", "so", "sprach", "er", ",", "mit", "ihm", "zie\u00b7hen", ".", "Jtzt", "ruh\u00b7te", "E\u00b7lie\u00b7ser", "nicht", ",", "1.", "B.", "Mos", ".", "14", ",", "33.", "Lou\u00b7yse", "kon\u00b7te", "nicht", "ent\u00b7flie\u00b7hen", ".", "Man", "wei\u00df", ",", "wie", "Je\u00b7sus", "See", "len", "kriegt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "ordinal", "abbreviation", "word", "punct", "number", "punct", "ordinal", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "ADV", "VVFIN", "PPER", "$,", "APPR", "PPER", "VVINF", "$.", "ADV", "VVFIN", "NE", "PTKNEG", "$,", "ADJA", "NN", "NE", "$.", "CARD", "$,", "ADJA", "NN", "VMFIN", "PTKNEG", "VVINF", "$.", "PIS", "VVFIN", "$,", "PWAV", "NE", "TRUNC", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-++--+-+-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.14": {"line.1": {"text": "So giengs der Solmsischen Comtessen, die eine Erstgebohrne", "tokens": ["So", "giengs", "der", "Solm\u00b7si\u00b7schen", "Com\u00b7tes\u00b7sen", ",", "die", "ei\u00b7ne", "Erst\u00b7ge\u00b7bohr\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+--+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Gleich andern, die sich selbst vergessen, und scheun nicht Schan-", "tokens": ["Gleich", "an\u00b7dern", ",", "die", "sich", "selbst", "ver\u00b7ges\u00b7sen", ",", "und", "scheun", "nicht", "Schan"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "$,", "PRELS", "PRF", "ADV", "VVPP", "$,", "KON", "VVFIN", "PTKNEG", "TRUNC"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Denn der Durchbrecher aller Klippen, drang vor ihr hin zu", "tokens": ["Denn", "der", "Durch\u00b7bre\u00b7cher", "al\u00b7ler", "Klip\u00b7pen", ",", "drang", "vor", "ihr", "hin", "zu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PIAT", "NN", "$,", "VVFIN", "APPR", "PPER", "ADV", "APPR"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "Und in der Arche seiner Krippen durchschifte sie das wilde", "tokens": ["Und", "in", "der", "Ar\u00b7che", "sei\u00b7ner", "Krip\u00b7pen", "durch\u00b7schif\u00b7te", "sie", "das", "wil\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "PPOSAT", "NN", "VMFIN", "PPER", "ART", "ADJA"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.15": {"line.1": {"text": "Sie wuste nichts von Neben-Wegen. Es leben ja die Zeu-", "tokens": ["Sie", "wus\u00b7te", "nichts", "von", "Ne\u00b7ben\u00b7We\u00b7gen", ".", "Es", "le\u00b7ben", "ja", "die", "Zeu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "NN", "$.", "PPER", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Die sie gesehn, sich niederlegen, ans Creutz und unter JEsu", "tokens": ["Die", "sie", "ge\u00b7sehn", ",", "sich", "nie\u00b7der\u00b7le\u00b7gen", ",", "ans", "Creutz", "und", "un\u00b7ter", "Je\u00b7su"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "VVPP", "$,", "PRF", "VVINF", "$,", "APPRART", "NN", "KON", "APPR", "NE"], "meter": "-+-+-+-+--+-+--+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Nachdem sie alle Welt gewogen, und sie zu leicht befunden", "tokens": ["Nach\u00b7dem", "sie", "al\u00b7le", "Welt", "ge\u00b7wo\u00b7gen", ",", "und", "sie", "zu", "leicht", "be\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVPP", "$,", "KON", "PPER", "PTKA", "ADJD", "VVPP"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "So ist sie Christo nachgezogen durchs Jammerthal zur GOttes", "tokens": ["So", "ist", "sie", "Chris\u00b7to", "nach\u00b7ge\u00b7zo\u00b7gen", "durchs", "Jam\u00b7mer\u00b7thal", "zur", "Got\u00b7tes"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NE", "VVPP", "APPRART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.16": {"line.1": {"text": "Wie Paulus dort zu sagen wuste: Die Briefe h\u00e4tten Geistes", "tokens": ["Wie", "Pau\u00b7lus", "dort", "zu", "sa\u00b7gen", "wus\u00b7te", ":", "Die", "Brie\u00b7fe", "h\u00e4t\u00b7ten", "Geis\u00b7tes"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "NE", "ADV", "PTKZU", "VVINF", "VVFIN", "$.", "ART", "NN", "VAFIN", "NN"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Das wars, was man bekennen muste, so bald man etwas von", "tokens": ["Das", "wars", ",", "was", "man", "be\u00b7ken\u00b7nen", "mus\u00b7te", ",", "so", "bald", "man", "et\u00b7was", "von"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "$,", "PRELS", "PIS", "VVINF", "VMFIN", "$,", "ADV", "ADV", "PIS", "ADV", "APPR"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Viel Briefe werden aufgesammlet, und durch den Druck ge-", "tokens": ["Viel", "Brie\u00b7fe", "wer\u00b7den", "auf\u00b7ge\u00b7samm\u00b7let", ",", "und", "durch", "den", "Druck", "ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "VVPP", "$,", "KON", "APPR", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die gegen ihren nur gestammlet, ", "tokens": ["Die", "ge\u00b7gen", "ih\u00b7ren", "nur", "ge\u00b7stamm\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Wer ihre F\u00fchrung recht erweget, wie lieb ihr ", "tokens": ["Wer", "ih\u00b7re", "F\u00fch\u00b7rung", "recht", "er\u00b7we\u00b7get", ",", "wie", "lieb", "ihr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "PPOSAT", "NN", "ADJD", "VVFIN", "$,", "PWAV", "ADJD", "PPOSAT"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wie sie der Mutter so gepfleget; dem stellet sie ein Mu-\nster dar", "tokens": ["Wie", "sie", "der", "Mut\u00b7ter", "so", "ge\u00b7pfle\u00b7get", ";", "dem", "stel\u00b7let", "sie", "ein", "Mu", "ster", "dar"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "ADV", "VVPP", "$.", "ART", "VVFIN", "PPER", "ART", "TRUNC", "ADJD", "PTKVZ"], "meter": "-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Von Seelen, die die Tieffe gr\u00fcnden, und doch den Ansto\u00df", "tokens": ["Von", "See\u00b7len", ",", "die", "die", "Tief\u00b7fe", "gr\u00fcn\u00b7den", ",", "und", "doch", "den", "An\u00b7sto\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "PRELS", "ART", "NN", "VVINF", "$,", "KON", "ADV", "ART", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Den mehrentheils die andern finden, so gern ein heilig Leben", "tokens": ["Den", "meh\u00b7ren\u00b7theils", "die", "an\u00b7dern", "fin\u00b7den", ",", "so", "gern", "ein", "hei\u00b7lig", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "ADJA", "VVINF", "$,", "ADV", "ADV", "ART", "ADJD", "NN"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.18": {"line.1": {"text": "Nun, ", "tokens": ["Nun", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Die Treue JEsu, die erf\u00e4hrst du; Vor unsern Reden wirst", "tokens": ["Die", "Treu\u00b7e", "Je\u00b7su", ",", "die", "er\u00b7f\u00e4hrst", "du", ";", "Vor", "un\u00b7sern", "Re\u00b7den", "wirst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "$,", "PRELS", "VVFIN", "PPER", "$.", "APPR", "PPOSAT", "NN", "VAFIN"], "meter": "-+--+-+-+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Wir ruffen dir nicht deinetwegen, allein um andrer willen nach:", "tokens": ["Wir", "ruf\u00b7fen", "dir", "nicht", "dei\u00b7net\u00b7we\u00b7gen", ",", "al\u00b7lein", "um", "an\u00b7drer", "wil\u00b7len", "nach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "VVINF", "$,", "ADV", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.19": {"line.1": {"text": "Du m\u00fchtest dich, bevor du ruhtest, drum thut dir nun der", "tokens": ["Du", "m\u00fch\u00b7test", "dich", ",", "be\u00b7vor", "du", "ruh\u00b7test", ",", "drum", "thut", "dir", "nun", "der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$,", "PAV", "VVFIN", "PPER", "ADV", "ART"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Was Wunder! da\u00df du itzt nicht blutest, du k\u00e4mpftest ehmals", "tokens": ["Was", "Wun\u00b7der", "!", "da\u00df", "du", "itzt", "nicht", "blu\u00b7test", ",", "du", "k\u00e4mpf\u00b7test", "eh\u00b7mals"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "NN", "$.", "KOUS", "PPER", "ADV", "PTKNEG", "VVFIN", "$,", "PPER", "VVFIN", "ADV"], "meter": "-+---+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Petroni, Seneca, ", "tokens": ["Pet\u00b7ro\u00b7ni", ",", "Se\u00b7ne\u00b7ca", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Doch mag ein ungedrungner Treiber auch dasmal nach Ge-", "tokens": ["Doch", "mag", "ein", "un\u00b7ge\u00b7drung\u00b7ner", "Trei\u00b7ber", "auch", "das\u00b7mal", "nach", "Ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ART", "ADJA", "NN", "ADV", "ADV", "APPR", "TRUNC"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der letzten Reden JEsu Schreiber kan in so sch\u00f6nem Gleis", "tokens": ["Der", "letz\u00b7ten", "Re\u00b7den", "Je\u00b7su", "Schrei\u00b7ber", "kan", "in", "so", "sch\u00f6\u00b7nem", "Gleis"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NE", "NN", "VMFIN", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+----+-+", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Jhr Jungfern, die ihr gleiche Fahne mit seliger ", "tokens": ["Ihr", "Jung\u00b7fern", ",", "die", "ihr", "glei\u00b7che", "Fah\u00b7ne", "mit", "se\u00b7li\u00b7ger"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PPOSAT", "ADJA", "NN", "APPR", "ADJA"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "H\u00f6rt, Caroline, Bibiane, ", "tokens": ["H\u00f6rt", ",", "Ca\u00b7ro\u00b7li\u00b7ne", ",", "Bi\u00b7bi\u00b7a\u00b7ne", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "NE", "$,", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.21": {"line.1": {"text": "Jhr solt, so lieb euch eure Seelen, dem Br\u00e4utigam nicht un-", "tokens": ["Ihr", "solt", ",", "so", "lieb", "euch", "eu\u00b7re", "See\u00b7len", ",", "dem", "Br\u00e4u\u00b7ti\u00b7gam", "nicht", "un"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "$,", "ADV", "ADJD", "PPER", "PPOSAT", "NN", "$,", "ART", "NE", "PTKNEG", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Jhr solt ihm eurer Tempel H\u00f6len zugleich mit Leib und Seele", "tokens": ["Ihr", "solt", "ihm", "eu\u00b7rer", "Tem\u00b7pel", "H\u00f6\u00b7len", "zu\u00b7gleich", "mit", "Leib", "und", "See\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "PPOSAT", "NN", "NN", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Jhr solt die Lust der Welt verleugnen, wir geben euch die H\u00e4n-", "tokens": ["Ihr", "solt", "die", "Lust", "der", "Welt", "ver\u00b7leug\u00b7nen", ",", "wir", "ge\u00b7ben", "euch", "die", "H\u00e4n"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "ART", "NN", "VVINF", "$,", "PPER", "VVFIN", "PPER", "ART", "TRUNC"], "meter": "-+-+-+-+--+---+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "So wird euch GOttes Lamm bezeichnen, so ruhet ihr nach", "tokens": ["So", "wird", "euch", "Got\u00b7tes", "Lamm", "be\u00b7zeich\u00b7nen", ",", "so", "ru\u00b7het", "ihr", "nach"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NN", "NN", "VVINF", "$,", "ADV", "VVFIN", "PPER", "APPR"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.22": {"line.1": {"text": "Die ihr der Seligen Verwandte, und Vater oder Mutter seyd,", "tokens": ["Die", "ihr", "der", "Se\u00b7li\u00b7gen", "Ver\u00b7wand\u00b7te", ",", "und", "Va\u00b7ter", "o\u00b7der", "Mut\u00b7ter", "seyd", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "ADJA", "NN", "$,", "KON", "NN", "KON", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Geschwister oder sonst Bekandte, ermahnet euch zum Glau-", "tokens": ["Ge\u00b7schwis\u00b7ter", "o\u00b7der", "sonst", "Be\u00b7kand\u00b7te", ",", "er\u00b7mah\u00b7net", "euch", "zum", "Glau"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "KON", "ADV", "NN", "$,", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Jhr gantzes Hau\u00df entsagt dem Teufel, und nimmt den Mann", "tokens": ["Ihr", "gant\u00b7zes", "Hau\u00df", "ent\u00b7sagt", "dem", "Teu\u00b7fel", ",", "und", "nimmt", "den", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}}}}