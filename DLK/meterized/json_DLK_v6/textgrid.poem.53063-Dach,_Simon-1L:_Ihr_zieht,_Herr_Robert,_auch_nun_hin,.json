{"textgrid.poem.53063": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ihr zieht, Herr Robert, auch nun hin,", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ihr zieht, Herr Robert, auch nun hin,", "tokens": ["Ihr", "zieht", ",", "Herr", "Ro\u00b7bert", ",", "auch", "nun", "hin", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NN", "NE", "$,", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd ich hab' euch mein Hertz verpf\u00e4ndet,", "tokens": ["Vnd", "ich", "hab'", "euch", "mein", "Hertz", "ver\u00b7pf\u00e4n\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was ist nun, da\u00df jhr meinen Sinn", "tokens": ["Was", "ist", "nun", ",", "da\u00df", "jhr", "mei\u00b7nen", "Sinn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "ADV", "$,", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd meine Seele mir entwendet?", "tokens": ["Vnd", "mei\u00b7ne", "See\u00b7le", "mir", "ent\u00b7wen\u00b7det", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Denckt nach, wie sich mein Geist betr\u00fcbt,", "tokens": ["Denckt", "nach", ",", "wie", "sich", "mein", "Geist", "be\u00b7tr\u00fcbt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "PWAV", "PRF", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd wie sich meine Seele m\u00fchet,", "tokens": ["Vnd", "wie", "sich", "mei\u00b7ne", "See\u00b7le", "m\u00fc\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PRF", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df Ihr, den sie so hertzlich liebt,", "tokens": ["Da\u00df", "Ihr", ",", "den", "sie", "so", "hertz\u00b7lich", "liebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PRELS", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So weit vns au\u00df den Augen ziehet.", "tokens": ["So", "weit", "vns", "au\u00df", "den", "Au\u00b7gen", "zie\u00b7het", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Was n\u00fctzt es nun, da\u00df du der Welt,", "tokens": ["Was", "n\u00fctzt", "es", "nun", ",", "da\u00df", "du", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "O Leben, l\u00e4nger wilt geniessen?", "tokens": ["O", "Le\u00b7ben", ",", "l\u00e4n\u00b7ger", "wilt", "ge\u00b7nies\u00b7sen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "ADJD", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Jetzt wil ich, wenn es dir gefellt,", "tokens": ["Jetzt", "wil", "ich", ",", "wenn", "es", "dir", "ge\u00b7fellt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "$,", "KOUS", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Rechnung meiner Tage schliessen.", "tokens": ["Die", "Rech\u00b7nung", "mei\u00b7ner", "Ta\u00b7ge", "schlies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Mein Robert wil das Hertze mir,", "tokens": ["Mein", "Ro\u00b7bert", "wil", "das", "Hert\u00b7ze", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "VMFIN", "PDS", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Sinn vnd auch die Seele rauben,", "tokens": ["Den", "Sinn", "vnd", "auch", "die", "See\u00b7le", "rau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich mu\u00df hie wallen f\u00fcr vnd f\u00fcr", "tokens": ["Ich", "mu\u00df", "hie", "wal\u00b7len", "f\u00fcr", "vnd", "f\u00fcr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "VVINF", "APPR", "KON", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gleich einer waisen Turteltauben.", "tokens": ["Gleich", "ei\u00b7ner", "wai\u00b7sen", "Tur\u00b7tel\u00b7tau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Die K\u00fcnste, die ich vor geehrt,", "tokens": ["Die", "K\u00fcns\u00b7te", ",", "die", "ich", "vor", "ge\u00b7ehrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "APPR", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Seitenspiel, mein s\u00fcssen singen", "tokens": ["Mein", "Sei\u00b7ten\u00b7spiel", ",", "mein", "s\u00fcs\u00b7sen", "sin\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wird nachmahls nicht mehr angeh\u00f6rt,", "tokens": ["Wird", "nach\u00b7mahls", "nicht", "mehr", "an\u00b7ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er pflag hiezu mich auffzubringen.", "tokens": ["Er", "pflag", "hie\u00b7zu", "mich", "auff\u00b7zu\u00b7brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Er hat die Geister mir geregt,", "tokens": ["Er", "hat", "die", "Geis\u00b7ter", "mir", "ge\u00b7regt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er pflag die Seiten mir zu stimmen,", "tokens": ["Er", "pflag", "die", "Sei\u00b7ten", "mir", "zu", "stim\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich hofft' auch schon von jhm bewegt", "tokens": ["Ich", "hofft'", "auch", "schon", "von", "jhm", "be\u00b7wegt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch Kunst die Sternen zu erklimmen.", "tokens": ["Durch", "Kunst", "die", "Ster\u00b7nen", "zu", "er\u00b7klim\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Was sol mir nun mein Seitenspiel?", "tokens": ["Was", "sol", "mir", "nun", "mein", "Sei\u00b7ten\u00b7spiel", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was sol der Musen Volck zusammen?", "tokens": ["Was", "sol", "der", "Mu\u00b7sen", "Volck", "zu\u00b7sam\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie richten nichts, ich mu\u00df vnd wil", "tokens": ["Sie", "rich\u00b7ten", "nichts", ",", "ich", "mu\u00df", "vnd", "wil"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "$,", "PPER", "VMFIN", "KON", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie ins vergessen hin verdammen.", "tokens": ["Sie", "ins", "ver\u00b7ges\u00b7sen", "hin", "ver\u00b7dam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "So viel ich vor von dir gewust,", "tokens": ["So", "viel", "ich", "vor", "von", "dir", "ge\u00b7wust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "APPR", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So viel ich vor von dir gehalten,", "tokens": ["So", "viel", "ich", "vor", "von", "dir", "ge\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "APPR", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So sehr, Apollo, wird die lust", "tokens": ["So", "sehr", ",", "A\u00b7pol\u00b7lo", ",", "wird", "die", "lust"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "NE", "$,", "VAFIN", "ART", "NN"], "meter": "+-+-++-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "Zu dir hinfort bey mir erkalten.", "tokens": ["Zu", "dir", "hin\u00b7fort", "bey", "mir", "er\u00b7kal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "APPR", "PPER", "VVINF", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Wo lob vnd Ruhm der Kunst gebricht,", "tokens": ["Wo", "lob", "vnd", "Ruhm", "der", "Kunst", "ge\u00b7bricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da wird sie zum Verdru\u00df bewogen,", "tokens": ["Da", "wird", "sie", "zum", "Ver\u00b7dru\u00df", "be\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd mu\u00df verleschen, wie ein Liecht,", "tokens": ["Vnd", "mu\u00df", "ver\u00b7le\u00b7schen", ",", "wie", "ein", "Liecht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "VVINF", "$,", "PWAV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem seine Nahrung wird entzogen.", "tokens": ["Dem", "sei\u00b7ne", "Nah\u00b7rung", "wird", "ent\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Ach da\u00df ich armer doch bi\u00dfher", "tokens": ["Ach", "da\u00df", "ich", "ar\u00b7mer", "doch", "bi\u00df\u00b7her"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "KOUS", "PPER", "ADJA", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So wol nicht meiner war genommen", "tokens": ["So", "wol", "nicht", "mei\u00b7ner", "war", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PTKNEG", "PPOSAT", "VAFIN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Al\u00df ich zwar kuntt. O da\u00df ich wer'", "tokens": ["Al\u00df", "ich", "zwar", "kuntt", ".", "O", "da\u00df", "ich", "wer'"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PTKVZ", "$.", "NE", "KOUS", "PPER", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im Tage zehnmahl zu jhm kommen,", "tokens": ["Im", "Ta\u00b7ge", "zehn\u00b7mahl", "zu", "jhm", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "So hett' ich sein dies gantze Jahr", "tokens": ["So", "hett'", "ich", "sein", "dies", "gant\u00b7ze", "Jahr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "VAINF", "PDS", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vmb so viel mehr geniessen k\u00f6nnen,", "tokens": ["Vmb", "so", "viel", "mehr", "ge\u00b7nies\u00b7sen", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "ADV", "ADV", "VVINF", "VMINF", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Da ich nun wil, so wil mir gar", "tokens": ["Da", "ich", "nun", "wil", ",", "so", "wil", "mir", "gar"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VMFIN", "$,", "ADV", "VMFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Gl\u00fcck sein beysein nicht verg\u00f6nnen.", "tokens": ["Das", "Gl\u00fcck", "sein", "bey\u00b7se\u00b7in", "nicht", "ver\u00b7g\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Ein Mensch erkennet nie so wol", "tokens": ["Ein", "Mensch", "er\u00b7ken\u00b7net", "nie", "so", "wol"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das gute, so er hat auff Erden,", "tokens": ["Das", "gu\u00b7te", ",", "so", "er", "hat", "auff", "Er\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADV", "PPER", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Al\u00df damahls, wenn er dessen sol", "tokens": ["Al\u00df", "da\u00b7mahls", ",", "wenn", "er", "des\u00b7sen", "sol"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "$,", "KOUS", "PPER", "PDS", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch Flucht der Zeit beraubet werden.", "tokens": ["Durch", "Flucht", "der", "Zeit", "be\u00b7rau\u00b7bet", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVFIN", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Ich klag', vnd wei\u00df nicht was ich thu,", "tokens": ["Ich", "klag'", ",", "vnd", "wei\u00df", "nicht", "was", "ich", "thu", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "VVFIN", "PTKNEG", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Herr Robert, Ihr zieht doch von hinnen,", "tokens": ["Herr", "Ro\u00b7bert", ",", "Ihr", "zieht", "doch", "von", "hin\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "PPER", "VVFIN", "ADV", "APPR", "ADV", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Hilfft etwas, da\u00df ich ohne Ruh", "tokens": ["Hilfft", "et\u00b7was", ",", "da\u00df", "ich", "oh\u00b7ne", "Ruh"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "$,", "KOUS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mich kr\u00e4nck' vnd gr\u00e4me fast von Sinnen?", "tokens": ["Mich", "kr\u00e4nck", "vnd", "gr\u00e4\u00b7me", "fast", "von", "Sin\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Gantz nichts, wo Gott euch vnd das Gl\u00fcck", "tokens": ["Gantz", "nichts", ",", "wo", "Gott", "euch", "vnd", "das", "Gl\u00fcck"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "$,", "PWAV", "NN", "PPER", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Schon wollen hin bestellet wissen,", "tokens": ["Schon", "wol\u00b7len", "hin", "be\u00b7stel\u00b7let", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Von dannen werdet Ihr zur\u00fcck", "tokens": ["Von", "dan\u00b7nen", "wer\u00b7det", "Ihr", "zu\u00b7r\u00fcck"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "VAFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch meine Klage nicht gerissen.", "tokens": ["Durch", "mei\u00b7ne", "Kla\u00b7ge", "nicht", "ge\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Mir zweiffelt nicht, dies werde seyn", "tokens": ["Mir", "zweif\u00b7felt", "nicht", ",", "dies", "wer\u00b7de", "seyn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PDS", "VAFIN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Weg zum Lohn f\u00fcr ewre Tugend,", "tokens": ["Der", "Weg", "zum", "Lohn", "f\u00fcr", "ew\u00b7re", "Tu\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vmb die Ihr so viel Staub vnd Pein", "tokens": ["Vmb", "die", "Ihr", "so", "viel", "Staub", "vnd", "Pein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "ADV", "PIAT", "NN", "KON", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Ertrugt vom Anfang' ewrer Jugend.", "tokens": ["Er\u00b7trugt", "vom", "An\u00b7fang'", "ew\u00b7rer", "Ju\u00b7gend", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Die Ihr in aller Welt gesucht,", "tokens": ["Die", "Ihr", "in", "al\u00b7ler", "Welt", "ge\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bi\u00df da\u00df Ihr endlich sie gefunden,", "tokens": ["Bi\u00df", "da\u00df", "Ihr", "end\u00b7lich", "sie", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mit welcher Lehr' vnd g\u00fcldnen Zucht", "tokens": ["Mit", "wel\u00b7cher", "Lehr'", "vnd", "g\u00fcld\u00b7nen", "Zucht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr auffs genawest' euch verbunden.", "tokens": ["Ihr", "auffs", "ge\u00b7nawest'", "euch", "ver\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "VVFIN", "PPER", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.17": {"line.1": {"text": "Die darumb Euch so hoch schon hebt,", "tokens": ["Die", "da\u00b7rumb", "Euch", "so", "hoch", "schon", "hebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PAV", "PPER", "ADV", "ADJD", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dahin von vnten ich nicht schawe,", "tokens": ["Da\u00b7hin", "von", "vn\u00b7ten", "ich", "nicht", "scha\u00b7we", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "APPR", "VVFIN", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wo der ber\u00fchmten Nahme schwebt,", "tokens": ["Wo", "der", "be\u00b7r\u00fchm\u00b7ten", "Nah\u00b7me", "schwebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd ich zu stehn mir nicht getrawe.", "tokens": ["Vnd", "ich", "zu", "stehn", "mir", "nicht", "ge\u00b7tra\u00b7we", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PTKZU", "VVINF", "PPER", "PTKNEG", "VVPP", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.18": {"line.1": {"text": "Die Tugend, wie sie sey, hat noch", "tokens": ["Die", "Tu\u00b7gend", ",", "wie", "sie", "sey", ",", "hat", "noch"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "VAFIN", "$,", "VAFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht einen vnbelohnt gelassen,", "tokens": ["Nicht", "ei\u00b7nen", "vn\u00b7be\u00b7lohnt", "ge\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Verzeucht sie gleich, sie findt sich doch,", "tokens": ["Ver\u00b7zeucht", "sie", "gleich", ",", "sie", "findt", "sich", "doch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "PPER", "VVFIN", "PRF", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd wird die rechte Zeit wol fassen.", "tokens": ["Vnd", "wird", "die", "rech\u00b7te", "Zeit", "wol", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Drumb zieht, wohin Gott au\u00df der H\u00f6h'", "tokens": ["Drumb", "zieht", ",", "wo\u00b7hin", "Gott", "au\u00df", "der", "H\u00f6h'"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "$,", "PWAV", "NN", "APPR", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Euch winckt, die heilig' Himmels-Schaaren", "tokens": ["Euch", "winckt", ",", "die", "hei\u00b7lig'", "Him\u00b7mels\u00b7Schaa\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Seyn vmb euch her zu Land' vnd See,", "tokens": ["Seyn", "vmb", "euch", "her", "zu", "Land'", "vnd", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "APPR", "PPER", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auff da\u00df Ihr sicher m\u00f6get fahren.", "tokens": ["Auff", "da\u00df", "Ihr", "si\u00b7cher", "m\u00f6\u00b7get", "fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "ADJD", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Die harten Winde m\u00fcssen sich", "tokens": ["Die", "har\u00b7ten", "Win\u00b7de", "m\u00fcs\u00b7sen", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Au\u00df jhren Felsen gar nicht r\u00fchren,", "tokens": ["Au\u00df", "jhren", "Fel\u00b7sen", "gar", "nicht", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Du Ost-Nord-Ost nur schicke dich", "tokens": ["Du", "Ost\u00b7Nord\u00b7Ost", "nur", "schi\u00b7cke", "dich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "ADV", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihn an gew\u00fcnschten Port zu f\u00fchren.", "tokens": ["Ihn", "an", "ge\u00b7w\u00fcnschten", "Port", "zu", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.21": {"line.1": {"text": "Ihr Himmels Augen, die Ihr steht", "tokens": ["Ihr", "Him\u00b7mels", "Au\u00b7gen", ",", "die", "Ihr", "steht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "NN", "$,", "PRELS", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Meer zu stillen vnd zu regen,", "tokens": ["Das", "Meer", "zu", "stil\u00b7len", "vnd", "zu", "re\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "KON", "APPR", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "In dem mein Freund zu Segel geht,", "tokens": ["In", "dem", "mein", "Freund", "zu", "Se\u00b7gel", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Schawt, da\u00df Ihr seiner m\u00f6get pflegen.", "tokens": ["Schawt", ",", "da\u00df", "Ihr", "sei\u00b7ner", "m\u00f6\u00b7get", "pfle\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUS", "PPER", "PPOSAT", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Die dicken Wolcken halten an", "tokens": ["Die", "di\u00b7cken", "Wol\u00b7cken", "hal\u00b7ten", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr Vngemach vnd faules feuchten,", "tokens": ["Ihr", "Vn\u00b7ge\u00b7mach", "vnd", "fau\u00b7les", "feuch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df auch vmb Amphitriten Bahn", "tokens": ["Da\u00df", "auch", "vmb", "Am\u00b7phit\u00b7ri\u00b7ten", "Bahn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Kein Donner sey, kein Wetterleuchten.", "tokens": ["Kein", "Don\u00b7ner", "sey", ",", "kein", "Wet\u00b7ter\u00b7leuch\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "$,", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Nur Ihr, Herr Robert, seyd bedacht,", "tokens": ["Nur", "Ihr", ",", "Herr", "Ro\u00b7bert", ",", "seyd", "be\u00b7dacht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "NN", "NE", "$,", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df Ihr euch bald' vns wieder gebet,", "tokens": ["Da\u00df", "Ihr", "euch", "bald'", "vns", "wie\u00b7der", "ge\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd vnterdessen Tag vnd Nacht", "tokens": ["Vnd", "vn\u00b7ter\u00b7des\u00b7sen", "Tag", "vnd", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im besten vnser indenck lebet.", "tokens": ["Im", "bes\u00b7ten", "vn\u00b7ser", "in\u00b7denck", "le\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}}, "stanza.24": {"line.1": {"text": "Vnd, wie nach allem recht geb\u00fchrt,", "tokens": ["Vnd", ",", "wie", "nach", "al\u00b7lem", "recht", "ge\u00b7b\u00fchrt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "APPR", "PIS", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In dem Ihr geht au\u00df diesem Lande,", "tokens": ["In", "dem", "Ihr", "geht", "au\u00df", "die\u00b7sem", "Lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd manchem seine Seel entf\u00fchrt,", "tokens": ["Vnd", "man\u00b7chem", "sei\u00b7ne", "Seel", "ent\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So la\u00dft vns ewre hie zum Pfande.", "tokens": ["So", "la\u00dft", "vns", "ew\u00b7re", "hie", "zum", "Pfan\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}