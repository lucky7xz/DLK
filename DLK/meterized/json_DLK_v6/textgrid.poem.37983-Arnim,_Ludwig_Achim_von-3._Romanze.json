{"textgrid.poem.37983": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "3. Romanze", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbihr wisset nun zu dieser Frist,", "tokens": ["\u00bb", "ihr", "wis\u00b7set", "nun", "zu", "die\u00b7ser", "Frist", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df unser Geschlecht im Abgang ist,", "tokens": ["Da\u00df", "un\u00b7ser", "Ge\u00b7schlecht", "im", "Ab\u00b7gang", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "APPRART", "NN", "VAFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "So nehmt ein Weib, ber\u00fchmt und reich,", "tokens": ["So", "nehmt", "ein", "Weib", ",", "be\u00b7r\u00fchmt", "und", "reich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr seyd schon jedem F\u00fcrsten gleich,", "tokens": ["Ihr", "seyd", "schon", "je\u00b7dem", "F\u00fcrs\u00b7ten", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir bringen euch viel Fr\u00e4ulein sch\u00f6n,", "tokens": ["Wir", "brin\u00b7gen", "euch", "viel", "Fr\u00e4u\u00b7lein", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die euch gar gerne alle sehn.\u00ab", "tokens": ["Die", "euch", "gar", "ger\u00b7ne", "al\u00b7le", "sehn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "PIS", "VVINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Herr Peter war erschrocken sehr,", "tokens": ["Herr", "Pe\u00b7ter", "war", "er\u00b7schro\u00b7cken", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "VVPP", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sein Bruder schweiget, da sprach der Herr:", "tokens": ["Sein", "Bru\u00b7der", "schwei\u00b7get", ",", "da", "sprach", "der", "Herr", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "\u00bbich dank euch edle Br\u00fcder mein,", "tokens": ["\u00bb", "ich", "dank", "euch", "ed\u00b7le", "Br\u00fc\u00b7der", "mein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "APPR", "PPER", "ADJA", "NN", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch kann es also noch nicht seyn,", "tokens": ["Doch", "kann", "es", "al\u00b7so", "noch", "nicht", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADV", "PTKNEG", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zur Kaiserkr\u00f6nung geh ich hin,", "tokens": ["Zur", "Kai\u00b7ser\u00b7kr\u00f6\u00b7nung", "geh", "ich", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nach Ruhm und Ehre steht mein Sinn.\u00ab", "tokens": ["Nach", "Ruhm", "und", "Eh\u00b7re", "steht", "mein", "Sinn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Die Meerfey gab ihm diesen Rath,", "tokens": ["Die", "Meer\u00b7fey", "gab", "ihm", "die\u00b7sen", "Rath", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie hat es ihm voraus gesagt,", "tokens": ["Sie", "hat", "es", "ihm", "vo\u00b7raus", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie giebt ihm Gold und edlen Schmuck,", "tokens": ["Sie", "giebt", "ihm", "Gold", "und", "ed\u00b7len", "Schmuck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie keiner ihn so herrlich trug,", "tokens": ["Wie", "kei\u00b7ner", "ihn", "so", "herr\u00b7lich", "trug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie k\u00fcsset ihn und warnet ihn,", "tokens": ["Sie", "k\u00fcs\u00b7set", "ihn", "und", "war\u00b7net", "ihn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df er sich nicht geb Weibern hin.", "tokens": ["Da\u00df", "er", "sich", "nicht", "geb", "Wei\u00b7bern", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "VVFIN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}