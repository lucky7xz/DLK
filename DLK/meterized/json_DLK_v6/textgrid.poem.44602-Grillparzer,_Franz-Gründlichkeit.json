{"textgrid.poem.44602": {"metadata": {"author": {"name": "Grillparzer, Franz", "birth": "N.A.", "death": "N.A."}, "title": "Gr\u00fcndlichkeit", "genre": "verse", "period": "N.A.", "pub_year": 1856, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie viel, im Reich des Geistes gar,", "tokens": ["Wie", "viel", ",", "im", "Reich", "des", "Geis\u00b7tes", "gar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "$,", "APPRART", "NN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00e4ngt ab von Ort und Zeit,", "tokens": ["H\u00e4ngt", "ab", "von", "Ort", "und", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Was falsch einst, gilt uns heut f\u00fcr wahr,", "tokens": ["Was", "falsch", "einst", ",", "gilt", "uns", "heut", "f\u00fcr", "wahr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "ADV", "$,", "VVFIN", "PPER", "ADV", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr dumm, was sonst gescheit.", "tokens": ["F\u00fcr", "dumm", ",", "was", "sonst", "ge\u00b7scheit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "$,", "PRELS", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Und mancher, den die eigne Zeit", "tokens": ["Und", "man\u00b7cher", ",", "den", "die", "eig\u00b7ne", "Zeit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PIS", "$,", "PRELS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verspottet und verlacht,", "tokens": ["Ver\u00b7spot\u00b7tet", "und", "ver\u00b7lacht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Lebt' er in unsern Tagen, heut,", "tokens": ["Lebt'", "er", "in", "un\u00b7sern", "Ta\u00b7gen", ",", "heut", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sein Gl\u00fcck w\u00e4r l\u00e4ngst gemacht.", "tokens": ["Sein", "Gl\u00fcck", "w\u00e4r", "l\u00e4ngst", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "So jener Mathematikus", "tokens": ["So", "je\u00b7ner", "Ma\u00b7the\u00b7ma\u00b7ti\u00b7kus"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im heiteren Paris,", "tokens": ["Im", "hei\u00b7te\u00b7ren", "Pa\u00b7ris", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Setzt ins Theater nie den Fu\u00df,", "tokens": ["Setzt", "ins", "The\u00b7a\u00b7ter", "nie", "den", "Fu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da Zahlen nur gewi\u00df.", "tokens": ["Da", "Zah\u00b7len", "nur", "ge\u00b7wi\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Doch einst die Freunde brachten ihn", "tokens": ["Doch", "einst", "die", "Freun\u00b7de", "brach\u00b7ten", "ihn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ins Schauspielhaus mit Gl\u00fcck,", "tokens": ["Ins", "Schau\u00b7spiel\u00b7haus", "mit", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Man gab ein Schauspiel von Racine,", "tokens": ["Man", "gab", "ein", "Schau\u00b7spiel", "von", "Ra\u00b7ci\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Des Meisters Meisterst\u00fcck.", "tokens": ["Des", "Meis\u00b7ters", "Meis\u00b7ter\u00b7st\u00fcck", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Da wird denn rings Begeistrung laut,", "tokens": ["Da", "wird", "denn", "rings", "Be\u00b7geis\u00b7trung", "laut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man weint, man klatscht, man tobt,", "tokens": ["Man", "weint", ",", "man", "klatscht", ",", "man", "tobt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PIS", "VVFIN", "$,", "PIS", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Was man geh\u00f6rt, was man geschaut,", "tokens": ["Was", "man", "ge\u00b7h\u00f6rt", ",", "was", "man", "ge\u00b7schaut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVFIN", "$,", "PRELS", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird eines Munds gelobt.", "tokens": ["Wird", "ei\u00b7nes", "Munds", "ge\u00b7lobt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Nur unser Mathematikus", "tokens": ["Nur", "un\u00b7ser", "Ma\u00b7the\u00b7ma\u00b7ti\u00b7kus"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sah stieren Augs das Spiel,", "tokens": ["Sah", "stie\u00b7ren", "Augs", "das", "Spiel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bis ihn der Freunde Schar am Schlu\u00df", "tokens": ["Bis", "ihn", "der", "Freun\u00b7de", "Schar", "am", "Schlu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "ART", "NN", "NE", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Befragt: wies ihm gefiel,", "tokens": ["Be\u00b7fragt", ":", "wies", "ihm", "ge\u00b7fiel", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$.", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Ob ihn ergriff der Dichtung Macht,", "tokens": ["Ob", "ihn", "er\u00b7griff", "der", "Dich\u00b7tung", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Ungl\u00fccks Jammerruf?", "tokens": ["Des", "Un\u00b7gl\u00fccks", "Jam\u00b7mer\u00b7ruf", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch er erwidert mit Bedacht:", "tokens": ["Doch", "er", "er\u00b7wi\u00b7dert", "mit", "Be\u00b7dacht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbmais qu'est ce que cela prouve?\u00ab", "tokens": ["\u00bb", "mais", "qu'\u00b7est", "ce", "que", "ce\u00b7la", "prou\u00b7ve", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "FM", "FM", "FM", "FM", "FM", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.8": {"line.1": {"text": "Da t\u00f6nt Gel\u00e4chter rings umher,", "tokens": ["Da", "t\u00f6nt", "Ge\u00b7l\u00e4ch\u00b7ter", "rings", "um\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Wort durchl\u00e4uft die Stadt", "tokens": ["Das", "Wort", "durch\u00b7l\u00e4uft", "die", "Stadt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und ein Jahrhundert oder mehr", "tokens": ["Und", "ein", "Jahr\u00b7hun\u00b7dert", "o\u00b7der", "mehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Lacht sich die Welt nicht satt.", "tokens": ["Lacht", "sich", "die", "Welt", "nicht", "satt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "O armer Mann, du kamst zu fr\u00fch", "tokens": ["O", "ar\u00b7mer", "Mann", ",", "du", "kamst", "zu", "fr\u00fch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "$,", "PPER", "VVFIN", "PTKA", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und nicht am rechten Ort;", "tokens": ["Und", "nicht", "am", "rech\u00b7ten", "Ort", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "In unsers Deutschlands Angst und M\u00fch", "tokens": ["In", "un\u00b7sers", "Deutschlands", "Angst", "und", "M\u00fch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN", "KON", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Erkennt man erst dein Wort,", "tokens": ["Er\u00b7kennt", "man", "erst", "dein", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Wo man Ideen nur begehrt,", "tokens": ["Wo", "man", "I\u00b7deen", "nur", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Von Glut und Reiz entfernt,", "tokens": ["Von", "Glut", "und", "Reiz", "ent\u00b7fernt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Man, bis zum Halse schon gelehrt,", "tokens": ["Man", ",", "bis", "zum", "Hal\u00b7se", "schon", "ge\u00b7lehrt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "KOUS", "APPRART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Noch im Theater lernt \u2013", "tokens": ["Noch", "im", "The\u00b7a\u00b7ter", "lernt", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Dort ruft ein jeder Kritikus,", "tokens": ["Dort", "ruft", "ein", "je\u00b7der", "Kri\u00b7ti\u00b7kus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was auch der Dichter schuf,", "tokens": ["Was", "auch", "der", "Dich\u00b7ter", "schuf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wie jener Mathematikus:", "tokens": ["Wie", "je\u00b7ner", "Ma\u00b7the\u00b7ma\u00b7ti\u00b7kus", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbmais qu'est ce que cela prouve?\u00ab", "tokens": ["\u00bb", "mais", "qu'\u00b7est", "ce", "que", "ce\u00b7la", "prou\u00b7ve", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "FM", "FM", "FM", "FM", "FM", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}