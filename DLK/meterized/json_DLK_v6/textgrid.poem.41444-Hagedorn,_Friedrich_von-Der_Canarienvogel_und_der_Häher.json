{"textgrid.poem.41444": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Der Canarienvogel und der H\u00e4her", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Durch Fragen wird man klug. Man k\u00f6mmt damit nach Rom.", "tokens": ["Durch", "Fra\u00b7gen", "wird", "man", "klug", ".", "Man", "k\u00f6mmt", "da\u00b7mit", "nach", "Rom", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PIS", "ADJD", "$.", "PIS", "VVFIN", "PAV", "APPR", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein wahres Spr\u00fcchwort sagt's, und selbst am Tiberstrom.", "tokens": ["Ein", "wah\u00b7res", "Spr\u00fcch\u00b7wort", "sagt's", ",", "und", "selbst", "am", "Ti\u00b7ber\u00b7strom", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "KON", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Allein wir m\u00fcssen nicht mit Fragen die beehren,", "tokens": ["Al\u00b7lein", "wir", "m\u00fcs\u00b7sen", "nicht", "mit", "Fra\u00b7gen", "die", "be\u00b7eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VMFIN", "PTKNEG", "APPR", "NN", "ART", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die selbst nicht f\u00e4hig sind, was Gr\u00fcndliches zu lehren.", "tokens": ["Die", "selbst", "nicht", "f\u00e4\u00b7hig", "sind", ",", "was", "Gr\u00fcnd\u00b7li\u00b7ches", "zu", "leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PTKNEG", "ADJD", "VAFIN", "$,", "PWS", "ADJA", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kein Blinder zeigt den Weg. Ein Flaccus, ein Virgil", "tokens": ["Kein", "Blin\u00b7der", "zeigt", "den", "Weg", ".", "Ein", "Flac\u00b7cus", ",", "ein", "Vir\u00b7gil"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "ART", "NN", "$.", "ART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zieht nicht den Bav zu Rath. Sie fragen den Quintil,", "tokens": ["Zieht", "nicht", "den", "Bav", "zu", "Rath", ".", "Sie", "fra\u00b7gen", "den", "Quin\u00b7til", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "NN", "APPR", "NN", "$.", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Den ganz gelehrten Freund. Warum? Ein halber Kenner", "tokens": ["Den", "ganz", "ge\u00b7lehr\u00b7ten", "Freund", ".", "Wa\u00b7rum", "?", "Ein", "hal\u00b7ber", "Ken\u00b7ner"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADV", "ADJA", "NN", "$.", "PWAV", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Verdient, zum h\u00f6chsten, nur das Mitleid kluger M\u00e4nner,", "tokens": ["Ver\u00b7di\u00b7ent", ",", "zum", "h\u00f6chs\u00b7ten", ",", "nur", "das", "Mit\u00b7leid", "klu\u00b7ger", "M\u00e4n\u00b7ner", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "APPRART", "ADJA", "$,", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Wenn er von Meisterschaft, voll Hochmuth, Neid und Zwist,", "tokens": ["Wenn", "er", "von", "Meis\u00b7ter\u00b7schaft", ",", "voll", "Hoch\u00b7muth", ",", "Neid", "und", "Zwist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "$,", "ADJD", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "An Witz ein Polyphem, an Wahn ein Argus ist.", "tokens": ["An", "Witz", "ein", "Po\u00b7ly\u00b7phem", ",", "an", "Wahn", "ein", "Ar\u00b7gus", "ist", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$,", "APPR", "NN", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ein Vogel, der unl\u00e4ngst aus Teneriff gekommen,", "tokens": ["Ein", "Vo\u00b7gel", ",", "der", "un\u00b7l\u00e4ngst", "aus", "Te\u00b7ne\u00b7riff", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "$,", "PRELS", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Glich, Arigoni, dir, auch an Bescheidenheit,", "tokens": ["Glich", ",", "A\u00b7ri\u00b7go\u00b7ni", ",", "dir", ",", "auch", "an", "Be\u00b7schei\u00b7den\u00b7heit", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "NE", "$,", "PPER", "$,", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "War fast der einzige, der seine Trefflichkeit", "tokens": ["War", "fast", "der", "ein\u00b7zi\u00b7ge", ",", "der", "sei\u00b7ne", "Treff\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und seiner Stimme Reiz nicht g'nugsam wahrgenommen.", "tokens": ["Und", "sei\u00b7ner", "Stim\u00b7me", "Reiz", "nicht", "g'\u00b7nug\u00b7sam", "wahr\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "PTKNEG", "ADJD", "VVPP", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Der S\u00e4nger redet nun Marcolph, den Schreier, an,", "tokens": ["Der", "S\u00e4n\u00b7ger", "re\u00b7det", "nun", "Mar\u00b7col\u00b7ph", ",", "den", "Schrei\u00b7er", ",", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "NE", "$,", "ART", "NN", "$,", "PTKVZ", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Den H\u00e4her, welchem er sich auch nicht n\u00e4hern sollen.", "tokens": ["Den", "H\u00e4\u00b7her", ",", "wel\u00b7chem", "er", "sich", "auch", "nicht", "n\u00e4\u00b7hern", "sol\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PRF", "ADV", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sagt, sprach er, ob mein Ton euch recht gefallen kann:", "tokens": ["Sagt", ",", "sprach", "er", ",", "ob", "mein", "Ton", "euch", "recht", "ge\u00b7fal\u00b7len", "kann", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "$,", "KOUS", "PPOSAT", "NN", "PPER", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Entdeckt mir, ob auch mich die Kenner dulden wollen?", "tokens": ["Ent\u00b7deckt", "mir", ",", "ob", "auch", "mich", "die", "Ken\u00b7ner", "dul\u00b7den", "wol\u00b7len", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "ADV", "PPER", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich zweifle, lehrt Marcolph. Euch fehlt mein Unterricht:", "tokens": ["Ich", "zweif\u00b7le", ",", "lehrt", "Mar\u00b7col\u00b7ph", ".", "Euch", "fehlt", "mein", "Un\u00b7ter\u00b7richt", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "NE", "$.", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Von mir l\u00e4\u00dft sich noch viel erfahren.", "tokens": ["Von", "mir", "l\u00e4\u00dft", "sich", "noch", "viel", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PRF", "ADV", "ADV", "VVINF", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.11": {"text": "Die Kunstverst\u00e4ndigen, wir H\u00e4her und die Staaren,", "tokens": ["Die", "Kunst\u00b7ver\u00b7st\u00e4n\u00b7di\u00b7gen", ",", "wir", "H\u00e4\u00b7her", "und", "die", "Staa\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wir Kenner loben euch noch nicht.", "tokens": ["Wir", "Ken\u00b7ner", "lo\u00b7ben", "euch", "noch", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Folgt mir: ich singe fein, recht nach der Tonkunst Gr\u00fcnden,", "tokens": ["Folgt", "mir", ":", "ich", "sin\u00b7ge", "fein", ",", "recht", "nach", "der", "Ton\u00b7kunst", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PPER", "VVFIN", "ADJD", "$,", "ADJD", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ihr trillert fremd und falsch: man h\u00f6rt euch an, und lacht.", "tokens": ["Ihr", "tril\u00b7lert", "fremd", "und", "falsch", ":", "man", "h\u00f6rt", "euch", "an", ",", "und", "lacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "ADJD", "$.", "PIS", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Wer immer sich zum Sch\u00fcler macht,", "tokens": ["Wer", "im\u00b7mer", "sich", "zum", "Sch\u00fc\u00b7ler", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PRF", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wird immer einen Meister finden.", "tokens": ["Wird", "im\u00b7mer", "ei\u00b7nen", "Meis\u00b7ter", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}