{"textgrid.poem.53623": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Paasche", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wieder einer.", "tokens": ["Wie\u00b7der", "ei\u00b7ner", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "PIS", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Das ist nun im Reich", "tokens": ["Das", "ist", "nun", "im", "Reich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV", "APPRART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Gewohnheit schon. Es gilt ihnen gleich.", "tokens": ["Ge\u00b7wohn\u00b7heit", "schon", ".", "Es", "gilt", "ih\u00b7nen", "gleich", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$.", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "So geht das alle, alle Tage.", "tokens": ["So", "geht", "das", "al\u00b7le", ",", "al\u00b7le", "Ta\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "PIS", "$,", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Hierzuland l\u00f6st die soziale Frage", "tokens": ["Hier\u00b7zu\u00b7land", "l\u00f6st", "die", "so\u00b7zi\u00b7a\u00b7le", "Fra\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "ein Leutnant, zehn Mann. Pazifist ist der Hund?", "tokens": ["ein", "Leut\u00b7nant", ",", "zehn", "Mann", ".", "Pa\u00b7zi\u00b7fist", "ist", "der", "Hund", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "CARD", "NN", "$.", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+--+---+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Schie\u00dft ihm nicht erst die Knochen wund!", "tokens": ["Schie\u00dft", "ihm", "nicht", "erst", "die", "Kno\u00b7chen", "wund", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "ART", "NN", "ADJD", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Die Kugel ins Herz!", "tokens": ["Die", "Ku\u00b7gel", "ins", "Herz", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.9": {"text": "Und die Dienststellen logen:", "tokens": ["Und", "die", "Dienst\u00b7stel\u00b7len", "lo\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "$."], "meter": "--++-+-", "measure": "anapaest.init"}, "line.10": {"text": "Er hat sich seiner Verhaftung entzogen.", "tokens": ["Er", "hat", "sich", "sei\u00b7ner", "Ver\u00b7haf\u00b7tung", "ent\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Leitartikel. Dementi. Geschrei.", "tokens": ["Leit\u00b7ar\u00b7ti\u00b7kel", ".", "De\u00b7men\u00b7ti", ".", "Ge\u00b7schrei", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$.", "FM.la", "$.", "NN", "$."], "meter": "-+--+---+", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Und in vierzehn Tagen ist alles vorbei.", "tokens": ["Und", "in", "vier\u00b7zehn", "Ta\u00b7gen", "ist", "al\u00b7les", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "CARD", "NN", "VAFIN", "PIS", "PTKVZ", "$."], "meter": "--+-+--+---", "measure": "iambic.tri.relaxed"}, "line.13": {"text": "Wieder einer. Ein m\u00fcder Mann,", "tokens": ["Wie\u00b7der", "ei\u00b7ner", ".", "Ein", "m\u00fc\u00b7der", "Mann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "$.", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.14": {"text": "der m\u00fcde \u00fcber die Deutschen sann.", "tokens": ["der", "m\u00fc\u00b7de", "\u00fc\u00b7ber", "die", "Deut\u00b7schen", "sann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Den preu\u00dfischen Geist \u2013 er kannte ihn", "tokens": ["Den", "preu\u00b7\u00dfi\u00b7schen", "Geist", "\u2013", "er", "kann\u00b7te", "ihn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "PPER", "VVFIN", "PPER"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "aus dem Heer und aus den Kolonien,", "tokens": ["aus", "dem", "Heer", "und", "aus", "den", "Ko\u00b7lo\u00b7ni\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.17": {"text": "aus der gro\u00dfen Zeit \u2013 er mochte nicht mehr.", "tokens": ["aus", "der", "gro\u00b7\u00dfen", "Zeit", "\u2013", "er", "moch\u00b7te", "nicht", "mehr", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$(", "PPER", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.18": {"text": "Er ha\u00dfte dieses h\u00f6llische Heer.", "tokens": ["Er", "ha\u00df\u00b7te", "die\u00b7ses", "h\u00f6l\u00b7li\u00b7sche", "Heer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.19": {"text": "Er liebte die Menschen. Er ha\u00dfte Sergeanten", "tokens": ["Er", "lieb\u00b7te", "die", "Men\u00b7schen", ".", "Er", "ha\u00df\u00b7te", "Ser\u00b7ge\u00b7an\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "PPER", "VVFIN", "NN"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.20": {"text": "(das taten alle, die beide kannten).", "tokens": ["(", "das", "ta\u00b7ten", "al\u00b7le", ",", "die", "bei\u00b7de", "kann\u00b7ten", ")", "."], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PDS", "VVFIN", "PIS", "$,", "PRELS", "PIS", "VVFIN", "$(", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "Sa\u00df still auf dem Land und angelte Fische.", "tokens": ["Sa\u00df", "still", "auf", "dem", "Land", "und", "an\u00b7gel\u00b7te", "Fi\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "ART", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Las ein paar harmlose Zeitungswische . . .", "tokens": ["Las", "ein", "paar", "harm\u00b7lo\u00b7se", "Zei\u00b7tungs\u00b7wi\u00b7sche", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NE", "ART", "PIAT", "ADJA", "NN", "$.", "$.", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Spitzelmeldung. Da r\u00fccken heran", "tokens": ["Spit\u00b7zel\u00b7mel\u00b7dung", ".", "Da", "r\u00fc\u00b7cken", "he\u00b7ran"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "ADV", "VVFIN", "PTKVZ"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "zwei Offiziere und sechzig Mann.", "tokens": ["zwei", "Of\u00b7fi\u00b7zie\u00b7re", "und", "sech\u00b7zig", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "KON", "CARD", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "(tapfer sind sie immer gewesen,", "tokens": ["(", "tap\u00b7fer", "sind", "sie", "im\u00b7mer", "ge\u00b7we\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "PPER", "ADV", "VAPP", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "das kann man schon bei Herrn Sch\u00e4fer lesen.)", "tokens": ["das", "kann", "man", "schon", "bei", "Herrn", "Sch\u00e4\u00b7fer", "le\u00b7sen", ".", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VMFIN", "PIS", "ADV", "APPR", "NN", "NE", "VVINF", "$.", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Das Opfer im Badeanzug . . . Schu\u00df. In den Dreck.", "tokens": ["Das", "Op\u00b7fer", "im", "Ba\u00b7de\u00b7an\u00b7zug", ".", ".", ".", "Schu\u00df", ".", "In", "den", "Dreck", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$.", "$.", "$.", "NN", "$.", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-+--+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Wieder son Bolschewiste weg \u2013!", "tokens": ["Wie\u00b7der", "son", "Bol\u00b7sche\u00b7wis\u00b7te", "weg", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "NE", "PTKVZ", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Verbeugung. Kommandos, hart und knapp.", "tokens": ["Ver\u00b7beu\u00b7gung", ".", "Kom\u00b7man\u00b7dos", ",", "hart", "und", "knapp", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Dann r\u00fcckt die Heldengarde ab.", "tokens": ["Dann", "r\u00fcckt", "die", "Hel\u00b7den\u00b7gar\u00b7de", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ein toter Mann. Ein Stiller. Ein Reiner.", "tokens": ["Ein", "to\u00b7ter", "Mann", ".", "Ein", "Stil\u00b7ler", ".", "Ein", "Rei\u00b7ner", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "ART", "NN", "$.", "ART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Wieder einer. Wieder einer.", "tokens": ["Wie\u00b7der", "ei\u00b7ner", ".", "Wie\u00b7der", "ei\u00b7ner", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PIS", "$.", "ADV", "PIS", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Und nun \u2013?", "tokens": ["Und", "nun", "\u2013", "?"], "token_info": ["word", "word", "punct", "punct"], "pos": ["KON", "ADV", "$(", "$."], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Die Regierung wird was tun?", "tokens": ["Die", "Re\u00b7gie\u00b7rung", "wird", "was", "tun", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIS", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die Regierung ist gegen Emp\u00f6rung immun.", "tokens": ["Die", "Re\u00b7gie\u00b7rung", "ist", "ge\u00b7gen", "Em\u00b7p\u00f6\u00b7rung", "im\u00b7mun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "ADV", "$."], "meter": "--+-++--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Schlafen. Zucken die Achseln. Glauben", "tokens": ["Schla\u00b7fen", ".", "Zu\u00b7cken", "die", "Ach\u00b7seln", ".", "Glau\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word"], "pos": ["NN", "$.", "NN", "ART", "NN", "$.", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "verlogenen Berichten der Pickelhauben.", "tokens": ["ver\u00b7lo\u00b7ge\u00b7nen", "Be\u00b7rich\u00b7ten", "der", "Pi\u00b7ckel\u00b7hau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "$."], "meter": "-+---+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und du liest am n\u00e4chsten Tag in der Zeitung:", "tokens": ["Und", "du", "liest", "am", "n\u00e4chs\u00b7ten", "Tag", "in", "der", "Zei\u00b7tung", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Unschuldig der M\u00f6rder \u2013 unschuldig die Leitung.", "tokens": ["Un\u00b7schul\u00b7dig", "der", "M\u00f6r\u00b7der", "\u2013", "un\u00b7schul\u00b7dig", "die", "Lei\u00b7tung", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "$(", "ADJD", "ART", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.8": {"text": "Hausen genau wie damals in Flandern.", "tokens": ["Hau\u00b7sen", "ge\u00b7nau", "wie", "da\u00b7mals", "in", "Flan\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KOKOM", "ADV", "APPR", "NN", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Menschen? Tiere sind die andern.", "tokens": ["Men\u00b7schen", "?", "Tie\u00b7re", "sind", "die", "an\u00b7dern", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "VAFIN", "ART", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Spielen noch immer herrliche Zeiten", "tokens": ["Spie\u00b7len", "noch", "im\u00b7mer", "herr\u00b7li\u00b7che", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ADV", "ADJA", "NN"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.11": {"text": "der milit\u00e4rischen Notwendigkeiten,", "tokens": ["der", "mi\u00b7li\u00b7t\u00e4\u00b7ri\u00b7schen", "Not\u00b7wen\u00b7dig\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.12": {"text": "Und nun \u2013? Die Regierung l\u00e4\u00dft sie machen . . .", "tokens": ["Und", "nun", "\u2013", "?", "Die", "Re\u00b7gie\u00b7rung", "l\u00e4\u00dft", "sie", "ma\u00b7chen", ".", ".", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "ADV", "$(", "$.", "ART", "NN", "VVFIN", "PPER", "VVINF", "$.", "$.", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Flamm auf, du Volk! Feg sie hinweg.", "tokens": ["Flamm", "auf", ",", "du", "Volk", "!", "Feg", "sie", "hin\u00b7weg", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$,", "PPER", "NN", "$.", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Da sitzt der Bolschewistenschreck!", "tokens": ["Da", "sitzt", "der", "Bol\u00b7sche\u00b7wis\u00b7ten\u00b7schreck", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da sitzt Aufruhr. Da die Gefahr.", "tokens": ["Da", "sitzt", "Auf\u00b7ruhr", ".", "Da", "die", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "$.", "KOUS", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Alles noch so, wie es fr\u00fcher war . . .", "tokens": ["Al\u00b7les", "noch", "so", ",", "wie", "es", "fr\u00fc\u00b7her", "war", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PIS", "ADV", "ADV", "$,", "PWAV", "PPER", "ADJD", "VAFIN", "$.", "$.", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Morgen tun sies grad so wieder . . .", "tokens": ["Mor\u00b7gen", "tun", "sies", "grad", "so", "wie\u00b7der", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "VVINF", "VVFIN", "ADV", "ADV", "ADV", "$.", "$.", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Und Jesus steigt vom Himmel hernieder.", "tokens": ["Und", "Je\u00b7sus", "steigt", "vom", "Him\u00b7mel", "her\u00b7nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Breitet segnend die leuchtenden H\u00e4nde,", "tokens": ["Brei\u00b7tet", "seg\u00b7nend", "die", "leuch\u00b7ten\u00b7den", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "tritt vor den Soldatenl\u00fcmmel hin", "tokens": ["tritt", "vor", "den", "Sol\u00b7da\u00b7ten\u00b7l\u00fcm\u00b7mel", "hin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "PTKVZ"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "und sagt: \u00bbDu, es ist Zeitenwende.\u00ab", "tokens": ["und", "sagt", ":", "\u00bb", "Du", ",", "es", "ist", "Zei\u00b7ten\u00b7wen\u00b7de", ".", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PPER", "$,", "PPER", "VAFIN", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}