{"dta.poem.10751": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "Lobgesang  \n Von dem Warmen Bad zu Baden in Oe-  \n stereich.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1624", "urn": "urn:nbn:de:kobv:b4-200905197859", "language": ["de:0.99"], "booktitle": "Opitz, Martin: Teutsche P\u00f6emata und: Aristarchvs Wieder die verachtung Teutscher Sprach. Stra\u00dfburg, 1624."}, "poem": {"stanza.1": {"line.1": {"text": "Ein Frewlin hoch von Nahmen", "tokens": ["Ein", "Frew\u00b7lin", "hoch", "von", "Nah\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "APPR", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Zusagen jhr mich bat/", "tokens": ["Zu\u00b7sa\u00b7gen", "jhr", "mich", "bat", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Woher die Hitz vnd Flammen", "tokens": ["Wo\u00b7her", "die", "Hitz", "vnd", "Flam\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zu Baden kem ins Bad/", "tokens": ["Zu", "Ba\u00b7den", "kem", "ins", "Bad", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "APPRART", "NE", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Dieweil all andre Fl\u00fcsse", "tokens": ["Die\u00b7weil", "all", "and\u00b7re", "Fl\u00fcs\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Sonst von Natur sein Kalt/", "tokens": ["Sonst", "von", "Na\u00b7tur", "sein", "Kalt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "PPOSAT", "NN", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.7": {"text": "Fragt sie mich/ ob ich wisse/", "tokens": ["Fragt", "sie", "mich", "/", "ob", "ich", "wis\u00b7se", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "$(", "KOUS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Wie di\u00df hett ein gestalt?", "tokens": ["Wie", "di\u00df", "hett", "ein", "ge\u00b7stalt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDS", "VAFIN", "ART", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Es ist zwar weit der Grunde/", "tokens": ["Es", "ist", "zwar", "weit", "der", "Grun\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Natur ist reich im Reich:", "tokens": ["Na\u00b7tur", "ist", "reich", "im", "Reich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch ", "tokens": ["Doch"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Ein Landt wie Oestereich.", "tokens": ["Ein", "Landt", "wie", "O\u00b7es\u00b7te\u00b7reich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "NE", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "In Wiener Krei\u00df sie kame/", "tokens": ["In", "Wie\u00b7ner", "Krei\u00df", "sie", "ka\u00b7me", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Cupido kam mit jhr/", "tokens": ["Cu\u00b7pi\u00b7do", "kam", "mit", "jhr", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "$("], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Bald ein Spatzierweg nahme.", "tokens": ["Bald", "ein", "Spat\u00b7zier\u00b7weg", "nah\u00b7me", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$."], "meter": "--++-+-", "measure": "anapaest.init"}, "line.8": {"text": "In diesegegent hier.", "tokens": ["In", "die\u00b7se\u00b7ge\u00b7gent", "hier", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Daselbst bey einem Brunnen", "tokens": ["Da\u00b7selbst", "bey", "ei\u00b7nem", "Brun\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mit jhme sie sich setzt/", "tokens": ["Mit", "jh\u00b7me", "sie", "sich", "setzt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PPER", "PRF", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Erm\u00fcdet von der Sonnen/", "tokens": ["Er\u00b7m\u00fc\u00b7det", "von", "der", "Son\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "De\u00df Wassers sich ergetzt", "tokens": ["De\u00df", "Was\u00b7sers", "sich", "er\u00b7getzt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PRF", "VVPP"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da kam sie an ein Schlaffen/", "tokens": ["Da", "kam", "sie", "an", "ein", "Schlaf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ihr Sohn legt neben sich", "tokens": ["Ihr", "Sohn", "legt", "ne\u00b7ben", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PRF"], "meter": "-++-+-", "measure": "unknown.measure.tri"}, "line.7": {"text": "Sein Fackel/ Pfeil vnd Waffen/", "tokens": ["Sein", "Fa\u00b7ckel", "/", "Pfeil", "vnd", "Waf\u00b7fen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Schlieff vnvorsichtiglich.", "tokens": ["Schlieff", "vn\u00b7vor\u00b7sich\u00b7tig\u00b7lich", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Ein Jungfr\u00e4wlin dort nahe/", "tokens": ["Ein", "Jung\u00b7fr\u00e4w\u00b7lin", "dort", "na\u00b7he", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wartendt auff jhren Buel/", "tokens": ["War\u00b7tendt", "auff", "jhren", "Bu\u00b7el", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Schleich hin/ die betde sahe", "tokens": ["Schleich", "hin", "/", "die", "bet\u00b7de", "sa\u00b7he"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "PTKVZ", "$(", "ART", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Schlaffendt beim Bronnen k\u00fcel/", "tokens": ["Schlaf\u00b7fendt", "beim", "Bron\u00b7nen", "k\u00fcel", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "NE", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.5": {"text": "Die Pfeil vnd Fackel kennet/", "tokens": ["Die", "Pfeil", "vnd", "Fa\u00b7ckel", "ken\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Sprach: Ach das ist mein Gott/", "tokens": ["Sprach", ":", "Ach", "das", "ist", "mein", "Gott", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ITJ", "PDS", "VAFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Der mein Hertz also brennet/", "tokens": ["Der", "mein", "Hertz", "al\u00b7so", "bren\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "VVFIN", "$("], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Ich will jhm thun ein Spott.", "tokens": ["Ich", "will", "jhm", "thun", "ein", "Spott", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Mit Listen sie erw\u00fcschet", "tokens": ["Mit", "Lis\u00b7ten", "sie", "er\u00b7w\u00fc\u00b7schet"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "PPER", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Fackel Flammen hell/", "tokens": ["Die", "Fa\u00b7ckel", "Flam\u00b7men", "hell", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Stie\u00df vnder sich/ da\u00df zischet/", "tokens": ["Stie\u00df", "vn\u00b7der", "sich", "/", "da\u00df", "zi\u00b7schet", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "PRF", "$(", "KOUS", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Tief in den Bronen quell/", "tokens": ["Tief", "in", "den", "Bro\u00b7nen", "quell", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "ADJD", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.5": {"text": "Gleich ist entz\u00fcndet worden", "tokens": ["Gleich", "ist", "ent\u00b7z\u00fcn\u00b7det", "wor\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "VVPP", "VAPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Durch vnau\u00dfl\u00f6schlich Flamm", "tokens": ["Durch", "vn\u00b7au\u00df\u00b7l\u00f6\u00b7schlich", "Flamm"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJD", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Das wasser diser orten/", "tokens": ["Das", "was\u00b7ser", "di\u00b7ser", "or\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "So Baden hat den Nahm.", "tokens": ["So", "Ba\u00b7den", "hat", "den", "Nahm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Amor wischt vff im Schrecken/", "tokens": ["A\u00b7mor", "wischt", "vff", "im", "Schre\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "APPRART", "NN", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Nach seiner Fackel sah/", "tokens": ["Nach", "sei\u00b7ner", "Fa\u00b7ckel", "sah", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Im Brunnen fand ers stecken/", "tokens": ["Im", "Brun\u00b7nen", "fand", "ers", "ste\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PIS", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zog sie herau\u00df/ vnd sprach:", "tokens": ["Zog", "sie", "her\u00b7au\u00df", "/", "vnd", "sprach", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "$(", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Rechen will ich die thaten/", "tokens": ["Re\u00b7chen", "will", "ich", "die", "tha\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "ART", "VVFIN", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.6": {"text": "Soll sicher sein niemandt:", "tokens": ["Soll", "si\u00b7cher", "sein", "nie\u00b7mandt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "VAINF", "PIS", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Wer sich darin wil baden/", "tokens": ["Wer", "sich", "da\u00b7rin", "wil", "ba\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "PAV", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Soll f\u00fchlen meinen Brandt.", "tokens": ["Soll", "f\u00fch\u00b7len", "mei\u00b7nen", "Brandt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Daher hat dise Tugendt", "tokens": ["Da\u00b7her", "hat", "di\u00b7se", "Tu\u00b7gendt"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PDAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Vnd Krafft di\u00df Badt erlangt/", "tokens": ["Vnd", "Krafft", "di\u00df", "Badt", "er\u00b7langt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PDS", "NN", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das Alter vnd die Jugent", "tokens": ["Das", "Al\u00b7ter", "vnd", "die", "Ju\u00b7gent"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Es stercket vnverlangt/", "tokens": ["Es", "ster\u00b7cket", "vn\u00b7ver\u00b7langt", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Offt manches mattes Hertze", "tokens": ["Offt", "man\u00b7ches", "mat\u00b7tes", "Hert\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PIAT", "ADJA", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Erquickt di\u00df Warme Badt/", "tokens": ["Er\u00b7quickt", "di\u00df", "War\u00b7me", "Badt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "NN", "NE", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Offt manch geheimer Schmertze", "tokens": ["Offt", "manch", "ge\u00b7hei\u00b7mer", "Schmert\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Darinnen findet Raht.", "tokens": ["Da\u00b7rin\u00b7nen", "fin\u00b7det", "Raht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Zu Baden kan man frischen", "tokens": ["Zu", "Ba\u00b7den", "kan", "man", "fri\u00b7schen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VMFIN", "PIS", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die A\u00fcglin trefflich wohl/", "tokens": ["Die", "A\u00b7\u00fcg\u00b7lin", "treff\u00b7lich", "wohl", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADV", "$("], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Amor sich thut drein mischen/", "tokens": ["A\u00b7mor", "sich", "thut", "drein", "mi\u00b7schen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PRF", "VVFIN", "ADV", "VVFIN", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Hat auch sein Mauth vnd Zoll/", "tokens": ["Hat", "auch", "sein", "Mauth", "vnd", "Zoll", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "KON", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ein irrdisch Paradeise", "tokens": ["Ein", "irr\u00b7disch", "Pa\u00b7ra\u00b7dei\u00b7se"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ist dieser Brunnenquell/", "tokens": ["Ist", "die\u00b7ser", "Brun\u00b7nen\u00b7quell", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Erquickt lieblicher weise", "tokens": ["Er\u00b7quickt", "lieb\u00b7li\u00b7cher", "wei\u00b7se"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "ADJA", "NN"], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Leib/ Leben/ Muth/ vnd Seel.", "tokens": ["Leib", "/", "Le\u00b7ben", "/", "Muth", "/", "vnd", "Seel", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NN", "$(", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}