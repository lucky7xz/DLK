{"textgrid.poem.67861": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "9. Zelindaja", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Acht und acht, und Tag' auf Tage", "tokens": ["Acht", "und", "acht", ",", "und", "Tag'", "auf", "Ta\u00b7ge"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["CARD", "KON", "CARD", "$,", "KON", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Spielen Kampf die Sarrazinen,", "tokens": ["Spie\u00b7len", "Kampf", "die", "Sar\u00b7ra\u00b7zi\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die Aljataren gegen", "tokens": ["Und", "die", "Al\u00b7ja\u00b7ta\u00b7ren", "ge\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alarifen und Asargen.", "tokens": ["A\u00b7la\u00b7ri\u00b7fen", "und", "As\u00b7ar\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}}, "stanza.2": {"line.1": {"text": "Denn der K\u00f6nig in Toledo", "tokens": ["Denn", "der", "K\u00f6\u00b7nig", "in", "To\u00b7le\u00b7do"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "NE"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Feiert den beschwornen Frieden", "tokens": ["Fei\u00b7ert", "den", "be\u00b7schwor\u00b7nen", "Frie\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Von Belchitens K\u00f6nig, Zaid", "tokens": ["Von", "Be\u00b7lchi\u00b7tens", "K\u00f6\u00b7nig", ",", "Zaid"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["APPR", "NE", "NN", "$,", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und Atarfen von Granada.", "tokens": ["Und", "A\u00b7tar\u00b7fen", "von", "Gra\u00b7na\u00b7da", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NE", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.3": {"line.1": {"text": "Andre sagen, dieses Fest sey", "tokens": ["And\u00b7re", "sa\u00b7gen", ",", "die\u00b7ses", "Fest", "sey"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVINF", "$,", "PDAT", "NN", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00fcr den K\u00f6nig von Achagues;", "tokens": ["F\u00fcr", "den", "K\u00f6\u00b7nig", "von", "A\u00b7cha\u00b7gues", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NE", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Zelindaja hab's geordnet \u2013", "tokens": ["Ze\u00b7lin\u00b7da\u00b7ja", "hab's", "ge\u00b7ord\u00b7net", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NE", "VVPP", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ihr zulezt zu eignem Ungl\u00fcck.", "tokens": ["Ihr", "zu\u00b7lezt", "zu", "eig\u00b7nem", "Un\u00b7gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Ein zum Kampf die Sarrazinen", "tokens": ["Ein", "zum", "Kampf", "die", "Sar\u00b7ra\u00b7zi\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf hellbraunen Pferden zogen;", "tokens": ["Auf", "hell\u00b7brau\u00b7nen", "Pfer\u00b7den", "zo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+++-+-+-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Pommeranzenfarb' und gr\u00fcn sind", "tokens": ["Pom\u00b7meran\u00b7zen\u00b7fa\u00b7rb'", "und", "gr\u00fcn", "sind"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "ADJD", "VAFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ihre M\u00e4ntel, ihre Kleider.", "tokens": ["Ih\u00b7re", "M\u00e4n\u00b7tel", ",", "ih\u00b7re", "Klei\u00b7der", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Und das Sinnbild auf den Tartschen", "tokens": ["Und", "das", "Sinn\u00b7bild", "auf", "den", "Tart\u00b7schen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist ihr S\u00e4bel; Amors Bogen", "tokens": ["Ist", "ihr", "S\u00e4\u00b7bel", ";", "A\u00b7mors", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "$.", "NE", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist gekr\u00fcmmet aus dem S\u00e4bel,", "tokens": ["Ist", "ge\u00b7kr\u00fcm\u00b7met", "aus", "dem", "S\u00e4\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und das Wort ist: Feur und Blut!", "tokens": ["Und", "das", "Wort", "ist", ":", "Feur", "und", "Blut", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "$.", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Gleicherweise folgten ihnen", "tokens": ["Glei\u00b7cher\u00b7wei\u00b7se", "folg\u00b7ten", "ih\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zu dem Kampf die Aljatanen (lies: Aljataren),", "tokens": ["Zu", "dem", "Kampf", "die", "Al\u00b7ja\u00b7ta\u00b7nen", "(", "lies", ":", "Al\u00b7ja\u00b7ta\u00b7ren", ")", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$(", "VVFIN", "$.", "NN", "$(", "$,"], "meter": "--+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "R\u00f6thlich ihre Ritterkleider,", "tokens": ["R\u00f6th\u00b7lich", "ih\u00b7re", "Rit\u00b7ter\u00b7klei\u00b7der", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und bes\u00e4t mit weissen Bl\u00e4ttern.", "tokens": ["Und", "be\u00b7s\u00e4t", "mit", "weis\u00b7sen", "Bl\u00e4t\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Und ihr Sinnbild ist ein Himmel", "tokens": ["Und", "ihr", "Sinn\u00b7bild", "ist", "ein", "Him\u00b7mel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf den Schultern des Atlanten,", "tokens": ["Auf", "den", "Schul\u00b7tern", "des", "At\u00b7lan\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die Schrift dabei hie\u00df also:", "tokens": ["Und", "die", "Schrift", "da\u00b7bei", "hie\u00df", "al\u00b7so", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PAV", "VVFIN", "ADV", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "\u00bbwerd ihn halten, bis er sinkt!\u00ab", "tokens": ["\u00bb", "werd", "ihn", "hal\u00b7ten", ",", "bis", "er", "sinkt", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "PPER", "VVINF", "$,", "KOUS", "PPER", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Ihnen nach die Alarifen", "tokens": ["Ih\u00b7nen", "nach", "die", "A\u00b7la\u00b7ri\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Folgten, k\u00f6stlich angekleidet,", "tokens": ["Folg\u00b7ten", ",", "k\u00f6st\u00b7lich", "an\u00b7ge\u00b7klei\u00b7det", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gelb und r\u00f6thlich Kleid und Mantel,", "tokens": ["Gelb", "und", "r\u00f6th\u00b7lich", "Kleid", "und", "Man\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Einen Schleier statt des Ermels.", "tokens": ["Ei\u00b7nen", "Schlei\u00b7er", "statt", "des", "Er\u00b7mels", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Und ihr Sinnbild war ein Knote,", "tokens": ["Und", "ihr", "Sinn\u00b7bild", "war", "ein", "Kno\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Den ein wilder Mann zerreisset,", "tokens": ["Den", "ein", "wil\u00b7der", "Mann", "zer\u00b7reis\u00b7set", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und auf dem Kommandostabe", "tokens": ["Und", "auf", "dem", "Kom\u00b7man\u00b7dost\u00b7a\u00b7be"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Stand: Die Tapferkeit gewinnet!", "tokens": ["Stand", ":", "Die", "Tap\u00b7fer\u00b7keit", "ge\u00b7win\u00b7net", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Jezt die acht Asargen folgten,", "tokens": ["Jezt", "die", "acht", "As\u00b7ar\u00b7gen", "folg\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "CARD", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Stolzer sie, als alle jene;", "tokens": ["Stol\u00b7zer", "sie", ",", "als", "al\u00b7le", "je\u00b7ne", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "KOUS", "PIAT", "PDS", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Violett und blau und gelbe,", "tokens": ["Vi\u00b7o\u00b7lett", "und", "blau", "und", "gel\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "KON", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Statt der Federn gr\u00fcne Bl\u00e4tter.", "tokens": ["Statt", "der", "Fe\u00b7dern", "gr\u00fc\u00b7ne", "Bl\u00e4t\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Gr\u00fcne Tartschen, und auf ihnen", "tokens": ["Gr\u00fc\u00b7ne", "Tart\u00b7schen", ",", "und", "auf", "ih\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "KON", "APPR", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Blauer Himmel, in dem Himmel", "tokens": ["Blau\u00b7er", "Him\u00b7mel", ",", "in", "dem", "Him\u00b7mel"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schlungen sich zwo H\u00e4nd', das Wort war:", "tokens": ["Schlun\u00b7gen", "sich", "zwo", "H\u00e4nd'", ",", "das", "Wort", "war", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "CARD", "NN", "$,", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00bballes f\u00e4llt dem Gr\u00fcnen zu!\u00ab", "tokens": ["\u00bb", "al\u00b7les", "f\u00e4llt", "dem", "Gr\u00fc\u00b7nen", "zu", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PIS", "VVFIN", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Und dem K\u00f6nig war's zuwider,", "tokens": ["Und", "dem", "K\u00f6\u00b7nig", "wa\u00b7r's", "zu\u00b7wi\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Da\u00df sie so vor seinen Augen", "tokens": ["Da\u00df", "sie", "so", "vor", "sei\u00b7nen", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Seine M\u00fch zu Spotte machten,", "tokens": ["Sei\u00b7ne", "M\u00fch", "zu", "Spot\u00b7te", "mach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Machten seinen Wunsch zunicht.", "tokens": ["Mach\u00b7ten", "sei\u00b7nen", "Wunsch", "zu\u00b7nicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Sprach, als er den Trupp ersahe,", "tokens": ["Sprach", ",", "als", "er", "den", "Trupp", "er\u00b7sa\u00b7he", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sprach zu Selim, dem Alcaiden:", "tokens": ["Sprach", "zu", "Se\u00b7lim", ",", "dem", "Al\u00b7cai\u00b7den", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$,", "ART", "NN", "$."], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "\u00bbuntergehen soll die Sonne;", "tokens": ["\u00bb", "un\u00b7ter\u00b7ge\u00b7hen", "soll", "die", "Son\u00b7ne", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVINF", "VMFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn sie blendet mein Gesicht.\u00ab", "tokens": ["Denn", "sie", "blen\u00b7det", "mein", "Ge\u00b7sicht", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Der Asarge warf Behorden,", "tokens": ["Der", "As\u00b7ar\u00b7ge", "warf", "Be\u00b7hor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die sich in der Luft verlohren,", "tokens": ["Die", "sich", "in", "der", "Luft", "ver\u00b7loh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df das Aug' es nicht verfolgte", "tokens": ["Da\u00df", "das", "Aug'", "es", "nicht", "ver\u00b7folg\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPER", "PTKNEG", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo sie blieben, wo sie fielen.", "tokens": ["Wo", "sie", "blie\u00b7ben", ",", "wo", "sie", "fie\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "In der Stadt an allen Fenstern", "tokens": ["In", "der", "Stadt", "an", "al\u00b7len", "Fens\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Standen schauend alle Damen;", "tokens": ["Stan\u00b7den", "schau\u00b7end", "al\u00b7le", "Da\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Auf des Schlosses Gallerien", "tokens": ["Auf", "des", "Schlos\u00b7ses", "Gal\u00b7le\u00b7ri\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bogen sich hervor die Damen.", "tokens": ["Bo\u00b7gen", "sich", "her\u00b7vor", "die", "Da\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Trat er vor und trat zur\u00fccke,", "tokens": ["Trat", "er", "vor", "und", "trat", "zu\u00b7r\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Immer rief das ganze Volk ihm:", "tokens": ["Im\u00b7mer", "rief", "das", "gan\u00b7ze", "Volk", "ihm", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bballa mit dir! Alla mit dir!\u00ab", "tokens": ["\u00bb", "al\u00b7la", "mit", "dir", "!", "Al\u00b7la", "mit", "dir", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "APPR", "PPER", "$.", "NE", "APPR", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und der K\u00f6nig: \u00bbWeg mit dir!\u00ab", "tokens": ["Und", "der", "K\u00f6\u00b7nig", ":", "\u00bb", "Weg", "mit", "dir", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "$.", "$(", "NN", "APPR", "PPER", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Zelindaja unvorsichtig", "tokens": ["Ze\u00b7lin\u00b7da\u00b7ja", "un\u00b7vor\u00b7sich\u00b7tig"], "token_info": ["word", "word"], "pos": ["NE", "ADJD"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Go\u00df auf ihn, als er vorbeiflog,", "tokens": ["Go\u00df", "auf", "ihn", ",", "als", "er", "vor\u00b7bei\u00b7flog", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kostbar Wasser, ihn zu k\u00fchlen,", "tokens": ["Kost\u00b7bar", "Was\u00b7ser", ",", "ihn", "zu", "k\u00fch\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da rief schnell der K\u00f6nig: Halt!", "tokens": ["Da", "rief", "schnell", "der", "K\u00f6\u00b7nig", ":", "Halt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "ART", "NN", "$.", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.18": {"line.1": {"text": "Alle meinen, weil es sp\u00e4t sey,", "tokens": ["Al\u00b7le", "mei\u00b7nen", ",", "weil", "es", "sp\u00e4t", "sey", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Soll das Spiel zu Ende gehen;", "tokens": ["Soll", "das", "Spiel", "zu", "En\u00b7de", "ge\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch der eifers\u00fcchtge K\u00f6nig", "tokens": ["Doch", "der", "ei\u00b7fer\u00b7s\u00fccht\u00b7ge", "K\u00f6\u00b7nig"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Rufet: \u00bbNehmt ihn, den Verr\u00e4ther!\u00ab", "tokens": ["Ru\u00b7fet", ":", "\u00bb", "Nehmt", "ihn", ",", "den", "Ver\u00b7r\u00e4\u00b7ther", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["VVFIN", "$.", "$(", "VVFIN", "PPER", "$,", "ART", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Schnell die beiden andern Z\u00fcge", "tokens": ["Schnell", "die", "bei\u00b7den", "an\u00b7dern", "Z\u00fc\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "ART", "PIAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Werfen weg die R\u00f6hre, nehmen", "tokens": ["Wer\u00b7fen", "weg", "die", "R\u00f6h\u00b7re", ",", "neh\u00b7men"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["NN", "ADV", "ART", "NN", "$,", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lanzen, fliegen auf ihn, wollen", "tokens": ["Lan\u00b7zen", ",", "flie\u00b7gen", "auf", "ihn", ",", "wol\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word"], "pos": ["NN", "$,", "VVFIN", "APPR", "PPER", "$,", "VMFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alle den Asargen fangen. \u2013", "tokens": ["Al\u00b7le", "den", "As\u00b7ar\u00b7gen", "fan\u00b7gen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "ART", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn wer ist es, der dem Willen", "tokens": ["Denn", "wer", "ist", "es", ",", "der", "dem", "Wil\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PWS", "VAFIN", "PPER", "$,", "PRELS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Eines K\u00f6nigs in der Liebe widerstrebe?", "tokens": ["Ei\u00b7nes", "K\u00f6\u00b7nigs", "in", "der", "Lie\u00b7be", "wi\u00b7der\u00b7stre\u00b7be", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.20": {"line.1": {"text": "Und die andern beiden Z\u00fcge", "tokens": ["Und", "die", "an\u00b7dern", "bei\u00b7den", "Z\u00fc\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Stehn entgegen; der Asarge", "tokens": ["Stehn", "ent\u00b7ge\u00b7gen", ";", "der", "As\u00b7ar\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "PTKVZ", "$.", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Spricht: \u00bbDie Liebe kennet freilich", "tokens": ["Spricht", ":", "\u00bb", "Die", "Lie\u00b7be", "ken\u00b7net", "frei\u00b7lich"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$.", "$(", "ART", "NN", "VVFIN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kein Gesez, doch soll sie's kennen!", "tokens": ["Kein", "Ge\u00b7sez", ",", "doch", "soll", "sie's", "ken\u00b7nen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "ADV", "VMFIN", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Legt die Lanzen, meine Freunde,", "tokens": ["Legt", "die", "Lan\u00b7zen", ",", "mei\u00b7ne", "Freun\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lasset sie die Lanzen heben!\u00ab", "tokens": ["Las\u00b7set", "sie", "die", "Lan\u00b7zen", "he\u00b7ben", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mit Mitleid und mit Siege", "tokens": ["Und", "mit", "Mit\u00b7leid", "und", "mit", "Sie\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "KON", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schwiegen diese, jene weinten.", "tokens": ["Schwie\u00b7gen", "die\u00b7se", ",", "je\u00b7ne", "wein\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "$,", "PDS", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn wer ist es, der dem Willen", "tokens": ["Denn", "wer", "ist", "es", ",", "der", "dem", "Wil\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PWS", "VAFIN", "PPER", "$,", "PRELS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Eines K\u00f6nigs in der Liebe widerstrebe?", "tokens": ["Ei\u00b7nes", "K\u00f6\u00b7nigs", "in", "der", "Lie\u00b7be", "wi\u00b7der\u00b7stre\u00b7be", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.22": {"line.1": {"text": "Endlich nahmen sie den Mohren,", "tokens": ["End\u00b7lich", "nah\u00b7men", "sie", "den", "Moh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und das Volk, ihn zu befreien,", "tokens": ["Und", "das", "Volk", ",", "ihn", "zu", "be\u00b7frei\u00b7en", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Theilt sich in verschiedne Haufen,", "tokens": ["Theilt", "sich", "in", "ver\u00b7schied\u00b7ne", "Hau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sondert, sammlet, theilt sich wieder.", "tokens": ["Son\u00b7dert", ",", "samm\u00b7let", ",", "theilt", "sich", "wie\u00b7der", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "$,", "VVFIN", "PRF", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Doch da ihm ein F\u00fchrer fehlet,", "tokens": ["Doch", "da", "ihm", "ein", "F\u00fch\u00b7rer", "feh\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Der sie f\u00fchre, sie ermuntre,", "tokens": ["Der", "sie", "f\u00fch\u00b7re", ",", "sie", "er\u00b7munt\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gehn die Haufen auseinander,", "tokens": ["Gehn", "die", "Hau\u00b7fen", "aus\u00b7ein\u00b7an\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und das Murmeln hat ein Ende;", "tokens": ["Und", "das", "Mur\u00b7meln", "hat", "ein", "En\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn wer ist es, der dem Willen", "tokens": ["Denn", "wer", "ist", "es", ",", "der", "dem", "Wil\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PWS", "VAFIN", "PPER", "$,", "PRELS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Eines K\u00f6nigs in der Liebe widerstrebe?", "tokens": ["Ei\u00b7nes", "K\u00f6\u00b7nigs", "in", "der", "Lie\u00b7be", "wi\u00b7der\u00b7stre\u00b7be", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.24": {"line.1": {"text": "Einzig nur die Zelindaja", "tokens": ["Ein\u00b7zig", "nur", "die", "Ze\u00b7lin\u00b7da\u00b7ja"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "ADV", "ART", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Rufft: \u00bbBefreit, befreit den Mohren!\u00ab", "tokens": ["Rufft", ":", "\u00bb", "Be\u00b7freit", ",", "be\u00b7freit", "den", "Moh\u00b7ren", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "$.", "$(", "NN", "$,", "VVFIN", "ART", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Will von ihrem Balkon nieder", "tokens": ["Will", "von", "ih\u00b7rem", "Bal\u00b7kon", "nie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "PPOSAT", "NN", "PTKVZ"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "St\u00fcrzen sich, ihn zu befreien.", "tokens": ["St\u00fcr\u00b7zen", "sich", ",", "ihn", "zu", "be\u00b7frei\u00b7en", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Ihre Mutter, sie umfassend", "tokens": ["Ih\u00b7re", "Mut\u00b7ter", ",", "sie", "um\u00b7fas\u00b7send"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPER", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Spricht: \u00bbWas hast, was hast du Th\u00f6rin?", "tokens": ["Spricht", ":", "\u00bb", "Was", "hast", ",", "was", "hast", "du", "Th\u00f6\u00b7rin", "?"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "$(", "PWS", "VAFIN", "$,", "PWS", "VAFIN", "PPER", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Sterb' er, ohne da\u00df du zeigest,", "tokens": ["Sterb'", "er", ",", "oh\u00b7ne", "da\u00df", "du", "zei\u00b7gest", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUI", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df du nur sein Ungl\u00fcck wissest!", "tokens": ["Da\u00df", "du", "nur", "sein", "Un\u00b7gl\u00fcck", "wis\u00b7sest", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn wer ist es, der dem Willen", "tokens": ["Denn", "wer", "ist", "es", ",", "der", "dem", "Wil\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PWS", "VAFIN", "PPER", "$,", "PRELS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Eines K\u00f6nigs in der Liebe widerstrebe?\u00ab", "tokens": ["Ei\u00b7nes", "K\u00f6\u00b7nigs", "in", "der", "Lie\u00b7be", "wi\u00b7der\u00b7stre\u00b7be", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.26": {"line.1": {"text": "Schnell ein Bote kam vom K\u00f6nig,", "tokens": ["Schnell", "ein", "Bo\u00b7te", "kam", "vom", "K\u00f6\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der befahl, da\u00df bei den Ihren", "tokens": ["Der", "be\u00b7fahl", ",", "da\u00df", "bei", "den", "Ih\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "$,", "KOUS", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eine Wohnung ihr zum Kerker", "tokens": ["Ei\u00b7ne", "Woh\u00b7nung", "ihr", "zum", "Ker\u00b7ker"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Angewiesen werden sollte.", "tokens": ["An\u00b7ge\u00b7wie\u00b7sen", "wer\u00b7den", "soll\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "VAINF", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Schnell sprach Zelindaja: \u00bbSaget", "tokens": ["Schnell", "sprach", "Ze\u00b7lin\u00b7da\u00b7ja", ":", "\u00bb", "Sa\u00b7get"], "token_info": ["word", "word", "word", "punct", "punct", "word"], "pos": ["ADJD", "VVFIN", "NE", "$.", "$(", "VVFIN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Eurem Herrn: mich nie zu \u00e4ndern", "tokens": ["Eu\u00b7rem", "Herrn", ":", "mich", "nie", "zu", "\u00e4n\u00b7dern"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$.", "PPER", "ADV", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00e4hl' ich mir das Angedenken", "tokens": ["W\u00e4hl'", "ich", "mir", "das", "An\u00b7ge\u00b7den\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Des Asargen zum Gef\u00e4ngni\u00df;", "tokens": ["Des", "As\u00b7ar\u00b7gen", "zum", "Ge\u00b7f\u00e4ng\u00b7ni\u00df", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und ich wei\u00df wohl, wer dem Willen", "tokens": ["Und", "ich", "wei\u00df", "wohl", ",", "wer", "dem", "Wil\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "$,", "PWS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Eines K\u00f6nigs in der Liebe widerstrebe.\u00ab", "tokens": ["Ei\u00b7nes", "K\u00f6\u00b7nigs", "in", "der", "Lie\u00b7be", "wi\u00b7der\u00b7stre\u00b7be", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}}}}