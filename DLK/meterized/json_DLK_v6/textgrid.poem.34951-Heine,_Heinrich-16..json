{"textgrid.poem.34951": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "16.", "genre": "verse", "period": "N.A.", "pub_year": 1826, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gelegt hat sich der starke Wind,", "tokens": ["Ge\u00b7legt", "hat", "sich", "der", "star\u00b7ke", "Wind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PRF", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wieder stille wird's daheime;", "tokens": ["Und", "wie\u00b7der", "stil\u00b7le", "wird's", "da\u00b7hei\u00b7me", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Germania, das gro\u00dfe Kind,", "tokens": ["Ger\u00b7ma\u00b7nia", ",", "das", "gro\u00b7\u00dfe", "Kind", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Erfreut sich wieder seiner Weihnachtsb\u00e4ume.", "tokens": ["Er\u00b7freut", "sich", "wie\u00b7der", "sei\u00b7ner", "Weih\u00b7nachts\u00b7b\u00e4u\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Wir treiben jetzt Familiengl\u00fcck \u2013", "tokens": ["Wir", "trei\u00b7ben", "jetzt", "Fa\u00b7mi\u00b7li\u00b7en\u00b7gl\u00fcck", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NN", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Was h\u00f6her lockt, das ist vom \u00dcbel \u2013", "tokens": ["Was", "h\u00f6\u00b7her", "lockt", ",", "das", "ist", "vom", "\u00dc\u00b7bel", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VVFIN", "$,", "PDS", "VAFIN", "APPRART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Friedensschwalbe kehrt zur\u00fcck,", "tokens": ["Die", "Frie\u00b7dens\u00b7schwal\u00b7be", "kehrt", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die einst genistet in des Hauses Giebel.", "tokens": ["Die", "einst", "ge\u00b7nis\u00b7tet", "in", "des", "Hau\u00b7ses", "Gie\u00b7bel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVPP", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Gem\u00fctlich ruhen Wald und Flu\u00df,", "tokens": ["Ge\u00b7m\u00fct\u00b7lich", "ru\u00b7hen", "Wald", "und", "Flu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von sanftem Mondlicht \u00fcbergossen;", "tokens": ["Von", "sanf\u00b7tem", "Mond\u00b7licht", "\u00fc\u00b7ber\u00b7gos\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nur manchmal knallt's \u2013 Ist das ein Schu\u00df? \u2013", "tokens": ["Nur", "manch\u00b7mal", "knallt's", "\u2013", "Ist", "das", "ein", "Schu\u00df", "?", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "VVFIN", "$(", "VAFIN", "PDS", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es ist vielleicht ein Freund, den man erschossen.", "tokens": ["Es", "ist", "viel\u00b7leicht", "ein", "Freund", ",", "den", "man", "er\u00b7schos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$,", "PRELS", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Vielleicht mit Waffen in der Hand", "tokens": ["Viel\u00b7leicht", "mit", "Waf\u00b7fen", "in", "der", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat man den Tollkopf angetroffen", "tokens": ["Hat", "man", "den", "Toll\u00b7kopf", "an\u00b7ge\u00b7trof\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "(nicht jeder hat soviel Verstand", "tokens": ["(", "nicht", "je\u00b7der", "hat", "so\u00b7viel", "Ver\u00b7stand"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PTKNEG", "PIS", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie Flaccus, der so k\u00fchn davongeloffen).", "tokens": ["Wie", "Flac\u00b7cus", ",", "der", "so", "k\u00fchn", "da\u00b7von\u00b7ge\u00b7lof\u00b7fen", ")", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "NE", "$,", "PRELS", "ADV", "ADJD", "VVPP", "$(", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Es knallt. Es ist ein Fest vielleicht,", "tokens": ["Es", "knallt", ".", "Es", "ist", "ein", "Fest", "viel\u00b7leicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VAFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Feuerwerk zur Goethefeier! \u2013", "tokens": ["Ein", "Feu\u00b7er\u00b7werk", "zur", "Goe\u00b7the\u00b7fei\u00b7er", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Sontag, die dem Grab entsteigt,", "tokens": ["Die", "Son\u00b7tag", ",", "die", "dem", "Grab", "ent\u00b7steigt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Begr\u00fc\u00dft Raketenl\u00e4rm \u2013 die alte Leier.", "tokens": ["Be\u00b7gr\u00fc\u00dft", "Ra\u00b7ke\u00b7ten\u00b7l\u00e4rm", "\u2013", "die", "al\u00b7te", "Lei\u00b7er", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$(", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Auch Liszt taucht wieder auf, der Franz,", "tokens": ["Auch", "Liszt", "taucht", "wie\u00b7der", "auf", ",", "der", "Franz", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "ADV", "PTKVZ", "$,", "ART", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er lebt, er liegt nicht blutger\u00f6tet", "tokens": ["Er", "lebt", ",", "er", "liegt", "nicht", "blut\u00b7ge\u00b7r\u00f6\u00b7tet"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PTKNEG", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Auf einem Schlachtfeld Ungarlands;", "tokens": ["Auf", "ei\u00b7nem", "Schlacht\u00b7feld", "Un\u00b7gar\u00b7lands", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kein Russe noch Kroat' hat ihn get\u00f6tet.", "tokens": ["Kein", "Rus\u00b7se", "noch", "Kro\u00b7at'", "hat", "ihn", "ge\u00b7t\u00f6\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.7": {"line.1": {"text": "Es fiel der Freiheit letzte Schanz',", "tokens": ["Es", "fiel", "der", "Frei\u00b7heit", "letz\u00b7te", "Schanz'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Ungarn blutet sich zu Tode \u2013", "tokens": ["Und", "Un\u00b7garn", "blu\u00b7tet", "sich", "zu", "To\u00b7de", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PRF", "APPR", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch unversehrt blieb Ritter Franz,", "tokens": ["Doch", "un\u00b7ver\u00b7sehrt", "blieb", "Rit\u00b7ter", "Franz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sein S\u00e4bel auch \u2013 er liegt in der Kommode.", "tokens": ["Sein", "S\u00e4\u00b7bel", "auch", "\u2013", "er", "liegt", "in", "der", "Kom\u00b7mo\u00b7de", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "$(", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Er lebt, der Franz, und wird als Greis", "tokens": ["Er", "lebt", ",", "der", "Franz", ",", "und", "wird", "als", "Greis"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "ART", "NE", "$,", "KON", "VAFIN", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vom Ungarkriege Wunderdinge", "tokens": ["Vom", "Un\u00b7gar\u00b7krie\u00b7ge", "Wun\u00b7der\u00b7din\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Erz\u00e4hlen in der Enkel Kreis \u2013", "tokens": ["Er\u00b7z\u00e4h\u00b7len", "in", "der", "En\u00b7kel", "Kreis", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbso lag ich und so f\u00fchrt ich meine Klinge!\u00ab", "tokens": ["\u00bb", "so", "lag", "ich", "und", "so", "f\u00fchrt", "ich", "mei\u00b7ne", "Klin\u00b7ge", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "KON", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Wenn ich den Namen Ungarn h\u00f6r,", "tokens": ["Wenn", "ich", "den", "Na\u00b7men", "Un\u00b7garn", "h\u00f6r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wird mir das deutsche Wams zu enge,", "tokens": ["Wird", "mir", "das", "deut\u00b7sche", "Wams", "zu", "en\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "APPR", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es braust darunter wie ein Meer,", "tokens": ["Es", "braust", "da\u00b7run\u00b7ter", "wie", "ein", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mir ist, als gr\u00fc\u00dften mich Trompetenkl\u00e4nge!", "tokens": ["Mir", "ist", ",", "als", "gr\u00fc\u00df\u00b7ten", "mich", "Trom\u00b7pe\u00b7ten\u00b7kl\u00e4n\u00b7ge", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "ADJA", "PPER", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Es klirrt mir wieder im Gem\u00fct", "tokens": ["Es", "klirrt", "mir", "wie\u00b7der", "im", "Ge\u00b7m\u00fct"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Heldensage, l\u00e4ngst verklungen,", "tokens": ["Die", "Hel\u00b7den\u00b7sa\u00b7ge", ",", "l\u00e4ngst", "ver\u00b7klun\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das eisern wilde K\u00e4mpenlied \u2013", "tokens": ["Das", "ei\u00b7sern", "wil\u00b7de", "K\u00e4m\u00b7pen\u00b7lied", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Lied vom Untergang der Nibelungen.", "tokens": ["Das", "Lied", "vom", "Un\u00b7ter\u00b7gang", "der", "Ni\u00b7be\u00b7lun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Es ist dasselbe Heldenlos,", "tokens": ["Es", "ist", "das\u00b7sel\u00b7be", "Hel\u00b7den\u00b7los", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es sind dieselben alten M\u00e4ren,", "tokens": ["Es", "sind", "die\u00b7sel\u00b7ben", "al\u00b7ten", "M\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Namen sind ver\u00e4ndert blo\u00df,", "tokens": ["Die", "Na\u00b7men", "sind", "ver\u00b7\u00e4n\u00b7dert", "blo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch sind's dieselben \u00bbHelden lobeb\u00e4ren\u00ab.", "tokens": ["Doch", "sin\u00b7d's", "die\u00b7sel\u00b7ben", "\u00bb", "Hel\u00b7den", "lo\u00b7be\u00b7b\u00e4\u00b7ren", "\u00ab", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "PDAT", "$(", "NN", "VVINF", "$(", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.12": {"line.1": {"text": "Es ist dasselbe Schicksal auch \u2013", "tokens": ["Es", "ist", "das\u00b7sel\u00b7be", "Schick\u00b7sal", "auch", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDAT", "NN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie stolz und frei die Fahnen fliegen,", "tokens": ["Wie", "stolz", "und", "frei", "die", "Fah\u00b7nen", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "KON", "ADJD", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es mu\u00df der Held, nach altem Brauch,", "tokens": ["Es", "mu\u00df", "der", "Held", ",", "nach", "al\u00b7tem", "Brauch", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den tierisch rohen M\u00e4chten unterliegen.", "tokens": ["Den", "tie\u00b7risch", "ro\u00b7hen", "M\u00e4ch\u00b7ten", "un\u00b7ter\u00b7lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Und diesmal hat der Ochse gar", "tokens": ["Und", "dies\u00b7mal", "hat", "der", "O\u00b7chse", "gar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit B\u00e4ren einen Bund geschlossen \u2013", "tokens": ["Mit", "B\u00e4\u00b7ren", "ei\u00b7nen", "Bund", "ge\u00b7schlos\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Du f\u00e4llst; doch tr\u00f6ste dich, Magyar,", "tokens": ["Du", "f\u00e4llst", ";", "doch", "tr\u00f6s\u00b7te", "dich", ",", "Ma\u00b7gyar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "$,", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wir andre haben schlimmre Schmach genossen.", "tokens": ["Wir", "and\u00b7re", "ha\u00b7ben", "schlimm\u00b7re", "Schmach", "ge\u00b7nos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "VAFIN", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Anst\u00e4nd'ge Bestien sind es doch,", "tokens": ["An\u00b7st\u00e4n\u00b7d'\u00b7ge", "Be\u00b7sti\u00b7en", "sind", "es", "doch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "PPER", "ADV", "$,"], "meter": "+----+-+-+", "measure": "dactylic.init"}, "line.2": {"text": "Die ganz honett dich \u00fcberwunden;", "tokens": ["Die", "ganz", "ho\u00b7nett", "dich", "\u00fc\u00b7berw\u00b7un\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch wir geraten in das Joch", "tokens": ["Doch", "wir", "ge\u00b7ra\u00b7ten", "in", "das", "Joch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von W\u00f6lfen, Schweinen und gemeinen Hunden.", "tokens": ["Von", "W\u00f6l\u00b7fen", ",", "Schwei\u00b7nen", "und", "ge\u00b7mei\u00b7nen", "Hun\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Das heult und bellt und grunzt \u2013 ich kann", "tokens": ["Das", "heult", "und", "bellt", "und", "grunzt", "\u2013", "ich", "kann"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "KON", "VVFIN", "KON", "VVFIN", "$(", "PPER", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ertragen kaum den Duft der Sieger.", "tokens": ["Er\u00b7tra\u00b7gen", "kaum", "den", "Duft", "der", "Sie\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch still, Poet, das greift dich an \u2013", "tokens": ["Doch", "still", ",", "Po\u00b7et", ",", "das", "greift", "dich", "an", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "NN", "$,", "PDS", "VVFIN", "PPER", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du bist so krank, und schweigen w\u00e4re kl\u00fcger.", "tokens": ["Du", "bist", "so", "krank", ",", "und", "schwei\u00b7gen", "w\u00e4\u00b7re", "kl\u00fc\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "KON", "VVFIN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}