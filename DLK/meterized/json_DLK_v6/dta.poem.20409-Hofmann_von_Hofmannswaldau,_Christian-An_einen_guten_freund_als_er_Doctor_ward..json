{"dta.poem.20409": {"metadata": {"author": {"name": "Hofmann von Hofmannswaldau, Christian", "birth": "N.A.", "death": "N.A."}, "title": "An einen guten freund als er Doctor  \n ward.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1695", "urn": "urn:nbn:de:kobv:b4-200905197751", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Mein freund/ sein grosser ruhm braucht zwar kein fremdes", "tokens": ["Mein", "freund", "/", "sein", "gros\u00b7ser", "ruhm", "braucht", "zwar", "kein", "frem\u00b7des"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$(", "PPOSAT", "ADJA", "NN", "VVFIN", "ADV", "PIAT", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "licht:", "tokens": ["licht", ":"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Denn ein geschminckter Vers macht keinen Doctor nicht.", "tokens": ["Denn", "ein", "ge\u00b7schminck\u00b7ter", "Vers", "macht", "kei\u00b7nen", "Doc\u00b7tor", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "PIAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Jedoch der alte brauch/ der wohl nach uns wird bleiben/", "tokens": ["Je\u00b7doch", "der", "al\u00b7te", "brauch", "/", "der", "wohl", "nach", "uns", "wird", "blei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$(", "ART", "ADV", "APPR", "PPER", "VAFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Heist mich auff diesen tag auch wider willen schreiben.", "tokens": ["Heist", "mich", "auff", "die\u00b7sen", "tag", "auch", "wi\u00b7der", "wil\u00b7len", "schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PDAT", "NN", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Was aber schreib ich doch? da\u00df er so tag als nacht", "tokens": ["Was", "a\u00b7ber", "schreib", "ich", "doch", "?", "da\u00df", "er", "so", "tag", "als", "nacht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "VVFIN", "PPER", "ADV", "$.", "KOUS", "PPER", "ADV", "NN", "KOUS", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die b\u00fccher durchgesucht/ den rechten nachgedacht/", "tokens": ["Die", "b\u00fc\u00b7cher", "durch\u00b7ge\u00b7sucht", "/", "den", "rech\u00b7ten", "nach\u00b7ge\u00b7dacht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und nun mit ehren kan die doctor-krone tragen?", "tokens": ["Und", "nun", "mit", "eh\u00b7ren", "kan", "die", "doc\u00b7tor\u00b7kro\u00b7ne", "tra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "VVINF", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nein! dieses werden ihm viel 100. heute sagen.", "tokens": ["Nein", "!", "die\u00b7ses", "wer\u00b7den", "ihm", "viel", "100.", "heu\u00b7te", "sa\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "ordinal", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PDS", "VAFIN", "PPER", "PIAT", "ADJA", "ADV", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Und ist schon/ schweig ich gleich/ der klugen welt bekandt.", "tokens": ["Und", "ist", "schon", "/", "schweig", "ich", "gleich", "/", "der", "klu\u00b7gen", "welt", "be\u00b7kandt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "$(", "VVFIN", "PPER", "ADV", "$(", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was ist es endlich denn? di\u00df/ da\u00df ihn seine hand", "tokens": ["Was", "ist", "es", "end\u00b7lich", "denn", "?", "di\u00df", "/", "da\u00df", "ihn", "sei\u00b7ne", "hand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "ADV", "$.", "PDS", "$(", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Durch ihre feder zwar bi\u00df an die sterne f\u00fchret/", "tokens": ["Durch", "ih\u00b7re", "fe\u00b7der", "zwar", "bi\u00df", "an", "die", "ster\u00b7ne", "f\u00fch\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "ADV", "APPR", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch lange nicht so sehr/ als sein gem\u00fcthe/ zieret.", "tokens": ["Doch", "lan\u00b7ge", "nicht", "so", "sehr", "/", "als", "sein", "ge\u00b7m\u00fc\u00b7the", "/", "zie\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "ADV", "ADV", "$(", "KOUS", "PPOSAT", "ADJA", "$(", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}