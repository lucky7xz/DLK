{"dta.poem.19711": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Die Seer\u00e4uber .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1808", "urn": "urn:nbn:de:kobv:b4-20090519168", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "St\u00f6rtebecher und G\u00f6dte Michael,               ", "tokens": ["St\u00f6r\u00b7te\u00b7be\u00b7cher", "und", "G\u00f6d\u00b7te", "Mic\u00b7hael", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "NE", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Die raubten beide zu gleichem Theil", "tokens": ["Die", "raub\u00b7ten", "bei\u00b7de", "zu", "glei\u00b7chem", "Theil"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PIS", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Zu Wasser und nicht zu Lande,", "tokens": ["Zu", "Was\u00b7ser", "und", "nicht", "zu", "Lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "PTKNEG", "APPR", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Bis das es Gott vom Himmel verdro\u00df,", "tokens": ["Bis", "das", "es", "Gott", "vom", "Him\u00b7mel", "ver\u00b7dro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Des musten sie leiden gro\u00dfe Schande.", "tokens": ["Des", "mus\u00b7ten", "sie", "lei\u00b7den", "gro\u00b7\u00dfe", "Schan\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VMFIN", "PPER", "VVFIN", "ADJA", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Sie zogen vor den Heidnischen Soldan,", "tokens": ["Sie", "zo\u00b7gen", "vor", "den", "Heid\u00b7ni\u00b7schen", "Sol\u00b7dan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Heiden wolten ein Wirthschaft han;", "tokens": ["Die", "Hei\u00b7den", "wol\u00b7ten", "ein", "Wirth\u00b7schaft", "han", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ART", "NN", "VAFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Seine Tochter wolt er berathen,", "tokens": ["Sei\u00b7ne", "Toch\u00b7ter", "wolt", "er", "be\u00b7ra\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Sie rissn und splissen wie zwei wilde Thier,", "tokens": ["Sie", "rissn", "und", "splis\u00b7sen", "wie", "zwei", "wil\u00b7de", "Thier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "KOKOM", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Hamburger Bier trunken sie gerne.", "tokens": ["Ham\u00b7bur\u00b7ger", "Bier", "trun\u00b7ken", "sie", "ger\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.3": {"line.1": {"text": "St\u00f6rtebecher der sprach alzuhand:", "tokens": ["St\u00f6r\u00b7te\u00b7be\u00b7cher", "der", "sprach", "al\u00b7zu\u00b7hand", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "VVFIN", "NE", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Die West-See ist mir wol bekannt,", "tokens": ["Die", "West\u00b7See", "ist", "mir", "wol", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das will ich uns wol holen;", "tokens": ["Das", "will", "ich", "uns", "wol", "ho\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die reichen Kaufleut von Hamburg", "tokens": ["Die", "rei\u00b7chen", "Kauf\u00b7leut", "von", "Ham\u00b7burg"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "NE"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Die sollen das Gelach bezahlen.", "tokens": ["Die", "sol\u00b7len", "das", "Ge\u00b7lach", "be\u00b7zah\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Sie liefen ostwerts l\u00e4ngst des Lick:", "tokens": ["Sie", "lie\u00b7fen", "ost\u00b7werts", "l\u00e4ngst", "des", "Lick", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hamburg, Hamburg thu deinen Flei\u00df,", "tokens": ["Ham\u00b7burg", ",", "Ham\u00b7burg", "thu", "dei\u00b7nen", "Flei\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "An uns kannst du nichts gewinnen,", "tokens": ["An", "uns", "kannst", "du", "nichts", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VMFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was wir auch wollen bei dir thun,", "tokens": ["Was", "wir", "auch", "wol\u00b7len", "bei", "dir", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VMFIN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das wolln wir bald beginnen.", "tokens": ["Das", "wolln", "wir", "bald", "be\u00b7gin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Und das erh\u00f6rt ein schneller Both,", "tokens": ["Und", "das", "er\u00b7h\u00f6rt", "ein", "schnel\u00b7ler", "Both", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der war von klugem Rath,", "tokens": ["Der", "war", "von", "klu\u00b7gem", "Rath", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Kam in Hamburg gelaufen,", "tokens": ["Kam", "in", "Ham\u00b7burg", "ge\u00b7lau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "VVPP", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Er fragte nach des \u00e4ltsten B\u00fcrgemeistern Haus,", "tokens": ["Er", "frag\u00b7te", "nach", "des", "\u00e4lts\u00b7ten", "B\u00fcr\u00b7ge\u00b7meis\u00b7tern", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Den Rath fand er zu Hausse.", "tokens": ["Den", "Rath", "fand", "er", "zu", "Haus\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+---+-", "measure": "dactylic.init"}}, "stanza.6": {"line.1": {"text": "\u201eihr lieben Herrn all durch Gott,", "tokens": ["\u201e", "ihr", "lie\u00b7ben", "Herrn", "all", "durch", "Gott", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "ADJA", "NN", "PIAT", "APPR", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "\u201enehmt diese Red nicht auf f\u00fcr Spott,", "tokens": ["\u201e", "nehmt", "die\u00b7se", "Red", "nicht", "auf", "f\u00fcr", "Spott", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PDAT", "NN", "PTKNEG", "APPR", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201edie ich euch wil sagen,", "tokens": ["\u201e", "die", "ich", "euch", "wil", "sa\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PRELS", "PPER", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "\u201edie Feinde liegen euch nahe bei,", "tokens": ["\u201e", "die", "Fein\u00b7de", "lie\u00b7gen", "euch", "na\u00b7he", "bei", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "\u201esie liegen am wilden Have.", "tokens": ["\u201e", "sie", "lie\u00b7gen", "am", "wil\u00b7den", "Ha\u00b7ve", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "\u201edie Feinde liegen euch hart vor der Th\u00fcr,", "tokens": ["\u201e", "die", "Fein\u00b7de", "lie\u00b7gen", "euch", "hart", "vor", "der", "Th\u00fcr", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+--++-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "\u201edes habt ihr edlen Herrn zweier K\u00fchr,", "tokens": ["\u201e", "des", "habt", "ihr", "ed\u00b7len", "Herrn", "zwei\u00b7er", "K\u00fchr", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "\u201esie liegen dar' am Sande,", "tokens": ["\u201e", "sie", "lie\u00b7gen", "dar'", "am", "San\u00b7de", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PAV", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u201elast ihr sie wieder von hinnen ziehn,", "tokens": ["\u201e", "last", "ihr", "sie", "wie\u00b7der", "von", "hin\u00b7nen", "ziehn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "PPER", "ADV", "APPR", "ADV", "VVINF", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.5": {"text": "\u201edes habt ihr Hamburger Schande.\u201c", "tokens": ["\u201e", "des", "habt", "ihr", "Ham\u00b7bur\u00b7ger", "Schan\u00b7de", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Der \u00e4ltste Burgermeister sprach allzuhand:", "tokens": ["Der", "\u00e4lts\u00b7te", "Bur\u00b7ger\u00b7meis\u00b7ter", "sprach", "all\u00b7zu\u00b7hand", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PIS", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "\u201egut Gesell du bist uns unbekannt,", "tokens": ["\u201e", "gut", "Ge\u00b7sell", "du", "bist", "uns", "un\u00b7be\u00b7kannt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "NN", "PPER", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "\u201ewor\u00fcber solln wir dir gl\u00e4uben?\u201c", "tokens": ["\u201e", "wo\u00b7r\u00fc\u00b7ber", "solln", "wir", "dir", "gl\u00e4u\u00b7ben", "?", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "VMFIN", "PPER", "PPER", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "\u201edes solt ihr edlen Herren thun,", "tokens": ["\u201e", "des", "solt", "ihr", "ed\u00b7len", "Her\u00b7ren", "thun", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VMFIN", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u201ebei meinem treuen Eide.", "tokens": ["\u201e", "bei", "mei\u00b7nem", "treu\u00b7en", "Ei\u00b7de", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "\u201eihr sollet mich setzn auf das Vorkastel,", "tokens": ["\u201e", "ihr", "sol\u00b7let", "mich", "setzn", "auf", "das", "Vor\u00b7kas\u00b7tel", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.2": {"text": "\u201ebis das ihr eure Feinde seht", "tokens": ["\u201e", "bis", "das", "ihr", "eu\u00b7re", "Fein\u00b7de", "seht"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "APPR", "PRELS", "PPER", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201ewohl zu derselben Stunde,", "tokens": ["\u201e", "wohl", "zu", "der\u00b7sel\u00b7ben", "Stun\u00b7de", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "\u201eund sp\u00fcret ihr einigen Wankel an mir,", "tokens": ["\u201e", "und", "sp\u00fc\u00b7ret", "ihr", "ei\u00b7ni\u00b7gen", "Wan\u00b7kel", "an", "mir", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VVFIN", "PPER", "PIAT", "NN", "APPR", "PPER", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "\u201eso senket mich zu Grunde.\u201c", "tokens": ["\u201e", "so", "sen\u00b7ket", "mich", "zu", "Grun\u00b7de", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Die Herrn von Hamburg zogen aus,", "tokens": ["Die", "Herrn", "von", "Ham\u00b7burg", "zo\u00b7gen", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie gingen zu Segel mit der Fluth,", "tokens": ["Sie", "gin\u00b7gen", "zu", "Se\u00b7gel", "mit", "der", "Fluth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wol nach dem neuen Werke,", "tokens": ["Wol", "nach", "dem", "neu\u00b7en", "Wer\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Vor Nebel konnten sie nicht sehn,", "tokens": ["Vor", "Ne\u00b7bel", "konn\u00b7ten", "sie", "nicht", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So finster waren die Schwerken.", "tokens": ["So", "fins\u00b7ter", "wa\u00b7ren", "die", "Schwer\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Die Schwerken brachen durch,", "tokens": ["Die", "Schwer\u00b7ken", "bra\u00b7chen", "durch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Die Wolken wurden klar,", "tokens": ["Die", "Wol\u00b7ken", "wur\u00b7den", "klar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie segelten fort und kamen dar,", "tokens": ["Sie", "se\u00b7gel\u00b7ten", "fort", "und", "ka\u00b7men", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Grossen Preis wollten sie erwerben,", "tokens": ["Gros\u00b7sen", "Preis", "woll\u00b7ten", "sie", "er\u00b7wer\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "St\u00f6rtebecher und G\u00f6dte Michael musten darinnen", "tokens": ["St\u00f6r\u00b7te\u00b7be\u00b7cher", "und", "G\u00f6d\u00b7te", "Mic\u00b7hael", "mus\u00b7ten", "da\u00b7rin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "NE", "VMFIN", "ADV"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.6": {"text": "sterben.", "tokens": ["ster\u00b7ben", "."], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.12": {"line.1": {"text": "Sie hatten einen H\u00f6lck mit Wein genommen,", "tokens": ["Sie", "hat\u00b7ten", "ei\u00b7nen", "H\u00f6lck", "mit", "Wein", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Darmit waren sie auf die Weser gekommen,", "tokens": ["Dar\u00b7mit", "wa\u00b7ren", "sie", "auf", "die", "We\u00b7ser", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Dem Kaufmann dar zu leide,", "tokens": ["Dem", "Kauf\u00b7mann", "dar", "zu", "lei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie wollten darmit in Flandern,", "tokens": ["Sie", "woll\u00b7ten", "dar\u00b7mit", "in", "Flan\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PAV", "APPR", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Sie musten dar noch scheiden.", "tokens": ["Sie", "mus\u00b7ten", "dar", "noch", "schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PAV", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "H\u00f6rt auf Geselle, trinket nun nicht mehr,", "tokens": ["H\u00f6rt", "auf", "Ge\u00b7sel\u00b7le", ",", "trin\u00b7ket", "nun", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "$,", "VVFIN", "ADV", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dort laufen drey Schiffe in jener See,", "tokens": ["Dort", "lau\u00b7fen", "drey", "Schif\u00b7fe", "in", "je\u00b7ner", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "CARD", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Uns grauet vor den Hamburger Knechten,", "tokens": ["Uns", "grau\u00b7et", "vor", "den", "Ham\u00b7bur\u00b7ger", "Knech\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Kommen uns die von Hamburg an Bord,", "tokens": ["Kom\u00b7men", "uns", "die", "von", "Ham\u00b7burg", "an", "Bord", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "APPR", "NE", "APPR", "NN", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Mit ihnen m\u00fcssen wir fechten.", "tokens": ["Mit", "ih\u00b7nen", "m\u00fcs\u00b7sen", "wir", "fech\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "Sie brachten die B\u00fcchsen an den Bord,", "tokens": ["Sie", "brach\u00b7ten", "die", "B\u00fcch\u00b7sen", "an", "den", "Bord", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zu allem Schiessen gingen sie fort,", "tokens": ["Zu", "al\u00b7lem", "Schies\u00b7sen", "gin\u00b7gen", "sie", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Da h\u00f6rt man die B\u00fcchsen klingen;", "tokens": ["Da", "h\u00f6rt", "man", "die", "B\u00fcch\u00b7sen", "klin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da sah man so manchen stolzen Held", "tokens": ["Da", "sah", "man", "so", "man\u00b7chen", "stol\u00b7zen", "Held"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "PIAT", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sein Leben zu Ende bringen.", "tokens": ["Sein", "Le\u00b7ben", "zu", "En\u00b7de", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.15": {"line.1": {"text": "Sie schlugen sich drei Tag und auch drei Nacht,", "tokens": ["Sie", "schlu\u00b7gen", "sich", "drei", "Tag", "und", "auch", "drei", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "CARD", "NN", "KON", "ADV", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Hamburg dir ist ein B\u00f6ses gedacht", "tokens": ["Ham\u00b7burg", "dir", "ist", "ein", "B\u00f6\u00b7ses", "ge\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "PPER", "VAFIN", "ART", "NN", "VVPP"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "All zu derselben Stunde,", "tokens": ["All", "zu", "der\u00b7sel\u00b7ben", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das uns ist lang zuvor gesagt,", "tokens": ["Das", "uns", "ist", "lang", "zu\u00b7vor", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "VAFIN", "ADJD", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das kommen wir hie zu Funde.", "tokens": ["Das", "kom\u00b7men", "wir", "hie", "zu", "Fun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPR", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "Die bunte Kuh aus Flandern kam,", "tokens": ["Die", "bun\u00b7te", "Kuh", "aus", "Flan\u00b7dern", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie bald sie das Ger\u00fccht vernahm,", "tokens": ["Wie", "bald", "sie", "das", "Ge\u00b7r\u00fccht", "ver\u00b7nahm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit ihren starken H\u00f6rnern,", "tokens": ["Mit", "ih\u00b7ren", "star\u00b7ken", "H\u00f6r\u00b7nern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie ging sich brausen durch die See,", "tokens": ["Sie", "ging", "sich", "brau\u00b7sen", "durch", "die", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den H\u00f6lck wollte sie verst\u00f6ren.", "tokens": ["Den", "H\u00f6lck", "woll\u00b7te", "sie", "ver\u00b7st\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.17": {"line.1": {"text": "Der Schiffer sprach zu dem Steurmann,", "tokens": ["Der", "Schif\u00b7fer", "sprach", "zu", "dem", "Steur\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Treib auf das Ruder zum Steurbort an,", "tokens": ["Treib", "auf", "das", "Ru\u00b7der", "zum", "Steur\u00b7bort", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "So bleibt der Holck bei dem Winde,", "tokens": ["So", "bleibt", "der", "Holck", "bei", "dem", "Win\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wir wollen ihn laufen sein Vorkastel entzwei,", "tokens": ["Wir", "wol\u00b7len", "ihn", "lau\u00b7fen", "sein", "Vor\u00b7kas\u00b7tel", "ent\u00b7zwei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+--+--++--+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Das soll er wol empfinden.", "tokens": ["Das", "soll", "er", "wol", "emp\u00b7fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Sie liefen ihm sein Vorkastel entzwei.", "tokens": ["Sie", "lie\u00b7fen", "ihm", "sein", "Vor\u00b7kas\u00b7tel", "ent\u00b7zwei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-++--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "\u201etrauen, sprach sich G\u00f6dte Michael,", "tokens": ["\u201e", "trau\u00b7en", ",", "sprach", "sich", "G\u00f6d\u00b7te", "Mic\u00b7hael", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVINF", "$,", "VVFIN", "PRF", "NE", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u201edie Zeit ist nun gekommen,", "tokens": ["\u201e", "die", "Zeit", "ist", "nun", "ge\u00b7kom\u00b7men", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u201eda\u00df wir m\u00fcssen fechten um unser beider Leib,", "tokens": ["\u201e", "da\u00df", "wir", "m\u00fcs\u00b7sen", "fech\u00b7ten", "um", "un\u00b7ser", "bei\u00b7der", "Leib", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "VMFIN", "VVINF", "APPR", "PPOSAT", "PIAT", "NN", "$,"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.5": {"text": "\u201ees mag uns schaden oder frommen.\u201c", "tokens": ["\u201e", "es", "mag", "uns", "scha\u00b7den", "o\u00b7der", "from\u00b7men", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VMFIN", "PPER", "VVINF", "KON", "ADJA", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "St\u00fcrzebecher sprach sich allzuhand:", "tokens": ["St\u00fcr\u00b7ze\u00b7be\u00b7cher", "sprach", "sich", "all\u00b7zu\u00b7hand", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "PIS", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "\u201eihr Herrn von Hamburg thut uns kein Gewalt,", "tokens": ["\u201e", "ihr", "Herrn", "von", "Ham\u00b7burg", "thut", "uns", "kein", "Ge\u00b7walt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "APPR", "NE", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u201ewir wollen euch das Gut aufgeben,", "tokens": ["\u201e", "wir", "wol\u00b7len", "euch", "das", "Gut", "auf\u00b7ge\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u201ewollt ihr uns stehen f\u00fcr Leib und Gestalt", "tokens": ["\u201e", "wollt", "ihr", "uns", "ste\u00b7hen", "f\u00fcr", "Leib", "und", "Ge\u00b7stalt"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VMFIN", "PPER", "PPER", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.5": {"text": "\u201eund fristen unser junges Leben?\u201c", "tokens": ["\u201e", "und", "fris\u00b7ten", "un\u00b7ser", "jun\u00b7ges", "Le\u00b7ben", "?", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "VVFIN", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "\u201eja traun, sprach sich Herr Simon von Utrecht,", "tokens": ["\u201e", "ja", "traun", ",", "sprach", "sich", "Herr", "Si\u00b7mon", "von", "Ut\u00b7recht", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVINF", "$,", "VVFIN", "PRF", "NN", "NE", "APPR", "NE", "$,"], "meter": "-+---+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "\u201egebet euch gefangen auf ein Recht,", "tokens": ["\u201e", "ge\u00b7bet", "euch", "ge\u00b7fan\u00b7gen", "auf", "ein", "Recht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "\u201elast euch das nicht verdriessen,", "tokens": ["\u201e", "last", "euch", "das", "nicht", "ver\u00b7dries\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "PDS", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u201ehabt ihr dem Kaufmann kein Leid gethan,", "tokens": ["\u201e", "habt", "ihr", "dem", "Kauf\u00b7mann", "kein", "Leid", "ge\u00b7than", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "ART", "NN", "PIAT", "NN", "VVPP", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.5": {"text": "\u201eso werdet ihrs wol geniessen.\u201c", "tokens": ["\u201e", "so", "wer\u00b7det", "ihrs", "wol", "ge\u00b7nies\u00b7sen", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VAFIN", "NN", "ADV", "VVPP", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.21": {"line.1": {"text": "Da sie gegen die Richtstadt kamen,", "tokens": ["Da", "sie", "ge\u00b7gen", "die", "Richt\u00b7stadt", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Nicht viel Gutes sie da vernahmen,", "tokens": ["Nicht", "viel", "Gu\u00b7tes", "sie", "da", "ver\u00b7nah\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIAT", "NN", "PPER", "ADV", "VVFIN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Sie sahn die K\u00f6pfe stecken.", "tokens": ["Sie", "sahn", "die", "K\u00f6p\u00b7fe", "ste\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u201eihr Herren, das sind unsere Mitkompans!\u201c", "tokens": ["\u201e", "ihr", "Her\u00b7ren", ",", "das", "sind", "un\u00b7se\u00b7re", "Mit\u00b7kom\u00b7pans", "!", "\u201c"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "PDS", "VAFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "So sprach sich St\u00fcrzebecher.", "tokens": ["So", "sprach", "sich", "St\u00fcr\u00b7ze\u00b7be\u00b7cher", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Sie wurden zu Hamburg in die Haft gebracht,", "tokens": ["Sie", "wur\u00b7den", "zu", "Ham\u00b7burg", "in", "die", "Haft", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NE", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Sie sassen nicht l\u00e4nger als eine Nacht,", "tokens": ["Sie", "sas\u00b7sen", "nicht", "l\u00e4n\u00b7ger", "als", "ei\u00b7ne", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Wohl zu derselben Stunde,", "tokens": ["Wohl", "zu", "der\u00b7sel\u00b7ben", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ihr Todt wurd also sehr beklagt,", "tokens": ["Ihr", "Todt", "wurd", "al\u00b7so", "sehr", "be\u00b7klagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von Frauen und Jungfrauen.", "tokens": ["Von", "Frau\u00b7en", "und", "Jung\u00b7frau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+-+++-", "measure": "unknown.measure.tetra"}}, "stanza.23": {"line.1": {"text": "\u201eihr Herrn von Hamburg wir bitten um eine", "tokens": ["\u201e", "ihr", "Herrn", "von", "Ham\u00b7burg", "wir", "bit\u00b7ten", "um", "ei\u00b7ne"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPOSAT", "NN", "APPR", "NE", "PPER", "VVFIN", "APPR", "ART"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Bitt,", "tokens": ["Bitt", ","], "token_info": ["word", "punct"], "pos": ["PTKANT", "$,"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "\u201edie wolt ihr uns versagen nicht,", "tokens": ["\u201e", "die", "wolt", "ihr", "uns", "ver\u00b7sa\u00b7gen", "nicht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VMFIN", "PPER", "PPER", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eund mag euch auch nicht schaden,", "tokens": ["\u201e", "und", "mag", "euch", "auch", "nicht", "scha\u00b7den", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "\u201eda\u00df wir m\u00f6gen den Trauerberg", "tokens": ["\u201e", "da\u00df", "wir", "m\u00f6\u00b7gen", "den", "Trau\u00b7er\u00b7berg"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "KOUS", "PPER", "VMFIN", "ART", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "\u201eangehn in unserm besten Gewande.\u201c", "tokens": ["\u201e", "an\u00b7gehn", "in", "un\u00b7serm", "bes\u00b7ten", "Ge\u00b7wan\u00b7de", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVPP", "APPR", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.24": {"line.1": {"text": "Die Herrn von Hamburg th\u00e4ten die Ehr,", "tokens": ["Die", "Herrn", "von", "Ham\u00b7burg", "th\u00e4\u00b7ten", "die", "Ehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Sie liessen ihn Pfeiffen und Trummeln vorgehn,", "tokens": ["Sie", "lies\u00b7sen", "ihn", "Pfeif\u00b7fen", "und", "Trum\u00b7meln", "vor\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Sie h\u00e4ttens wol lieber entbehret,", "tokens": ["Sie", "h\u00e4t\u00b7tens", "wol", "lie\u00b7ber", "ent\u00b7beh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Ja w\u00e4ren sie wieder in der Heidenschaft gewest,", "tokens": ["Ja", "w\u00e4\u00b7ren", "sie", "wie\u00b7der", "in", "der", "Hei\u00b7den\u00b7schaft", "ge\u00b7west", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VAFIN", "PPER", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Sie w\u00e4ren nicht wiederkehret.", "tokens": ["Sie", "w\u00e4\u00b7ren", "nicht", "wie\u00b7der\u00b7keh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.25": {"line.1": {"text": "Der Scharfrichter hie\u00df sich Rosenfeld,", "tokens": ["Der", "Schar\u00b7frich\u00b7ter", "hie\u00df", "sich", "Ro\u00b7sen\u00b7feld", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "NE", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er haute so manchen stolzen Held", "tokens": ["Er", "hau\u00b7te", "so", "man\u00b7chen", "stol\u00b7zen", "Held"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mit einem frischen Muthe,", "tokens": ["Mit", "ei\u00b7nem", "fri\u00b7schen", "Mu\u00b7the", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er stund mit seinen geschn\u00fcrten Schuen", "tokens": ["Er", "stund", "mit", "sei\u00b7nen", "ge\u00b7schn\u00fcr\u00b7ten", "Schu\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Zu den Enkel in dem Blute.", "tokens": ["Zu", "den", "En\u00b7kel", "in", "dem", "Blu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Hamburg, Hamburg, des geb ich dir den Prei\u00df,", "tokens": ["Ham\u00b7burg", ",", "Ham\u00b7burg", ",", "des", "geb", "ich", "dir", "den", "Prei\u00df", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "ART", "VVFIN", "PPER", "PPER", "ART", "NN", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Die Seer\u00e4uber waren nie so wei\u00df,", "tokens": ["Die", "See\u00b7r\u00e4u\u00b7ber", "wa\u00b7ren", "nie", "so", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Um deinet Willen musten sie sterben,", "tokens": ["Um", "dei\u00b7net", "Wil\u00b7len", "mus\u00b7ten", "sie", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das machst du von Gold ein Krone tragn,", "tokens": ["Das", "machst", "du", "von", "Gold", "ein", "Kro\u00b7ne", "tragn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Den Prei\u00df hast du erworben.", "tokens": ["Den", "Prei\u00df", "hast", "du", "er\u00b7wor\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}