{"textgrid.poem.36948": {"metadata": {"author": {"name": "Gla\u00dfbrenner, Adolf", "birth": "N.A.", "death": "N.A."}, "title": "1L: Er weis't sich nicht geschichtlich nach,", "genre": "verse", "period": "N.A.", "pub_year": 1843, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Er weis't sich nicht geschichtlich nach,", "tokens": ["Er", "weis't", "sich", "nicht", "ge\u00b7schicht\u00b7lich", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PTKNEG", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kann sich nicht legitimiren.", "tokens": ["Kann", "sich", "nicht", "le\u00b7gi\u00b7ti\u00b7mi\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und doch bewundernd, o der Schmach!", "tokens": ["Und", "doch", "be\u00b7wun\u00b7dernd", ",", "o", "der", "Schmach", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "$,", "FM", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Aller Augen nach ihm stieren.", "tokens": ["Al\u00b7ler", "Au\u00b7gen", "nach", "ihm", "stie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "So pl\u00f6tzlich will er mit gl\u00e4nzendem Schweif", "tokens": ["So", "pl\u00f6tz\u00b7lich", "will", "er", "mit", "gl\u00e4n\u00b7zen\u00b7dem", "Schweif"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VMFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Am hohen Himmel regieren?", "tokens": ["Am", "ho\u00b7hen", "Him\u00b7mel", "re\u00b7gie\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Nein, nein, wir haben von ihm nichts gewu\u00dft,", "tokens": ["Nein", ",", "nein", ",", "wir", "ha\u00b7ben", "von", "ihm", "nichts", "ge\u00b7wu\u00dft", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "PPER", "VAFIN", "APPR", "PPER", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Er darf nicht existiren!", "tokens": ["Er", "darf", "nicht", "e\u00b7xis\u00b7ti\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Es ist ein Nebel, es ist ein Phantom!", "tokens": ["Es", "ist", "ein", "Ne\u00b7bel", ",", "es", "ist", "ein", "Phan\u00b7tom", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein Komet ist es nun und nimmer!", "tokens": ["Ein", "Ko\u00b7met", "ist", "es", "nun", "und", "nim\u00b7mer", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So gro\u00df war'n die Kometen alle nicht,", "tokens": ["So", "gro\u00df", "wa\u00b7r'n", "die", "Ko\u00b7me\u00b7ten", "al\u00b7le", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ART", "NN", "PIS", "PTKNEG", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Er ist ein falsches Geflimmer!", "tokens": ["Er", "ist", "ein", "fal\u00b7sches", "Ge\u00b7flim\u00b7mer", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "In unserm Register ist er nicht da,", "tokens": ["In", "un\u00b7serm", "Re\u00b7gis\u00b7ter", "ist", "er", "nicht", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wir k\u00f6nn'n ihn nicht geltn elassen;", "tokens": ["Wir", "k\u00f6nn'n", "ihn", "nicht", "geltn", "e\u00b7las\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wir bringen ihn nach St. Helena,", "tokens": ["Wir", "brin\u00b7gen", "ihn", "nach", "St.", "He\u00b7le\u00b7na", ","], "token_info": ["word", "word", "word", "word", "abbreviation", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das hei\u00dft, sobald wir ihn fassen!", "tokens": ["Das", "hei\u00dft", ",", "so\u00b7bald", "wir", "ihn", "fas\u00b7sen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "KOUS", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}}}}