{"textgrid.poem.57342": {"metadata": {"author": {"name": "Klopstock, Friedrich Gottlieb", "birth": "N.A.", "death": "N.A."}, "title": "1L: Du fragest sie auch die ernste Frage, die schreckliche:", "genre": "verse", "period": "N.A.", "pub_year": 1786, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du fragest sie auch die ernste Frage, die schreckliche:", "tokens": ["Du", "fra\u00b7gest", "sie", "auch", "die", "erns\u00b7te", "Fra\u00b7ge", ",", "die", "schreck\u00b7li\u00b7che", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,", "ART", "ADJA", "$."], "meter": "-+--+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Auf welcher Stufe der Geister", "tokens": ["Auf", "wel\u00b7cher", "Stu\u00b7fe", "der", "Geis\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "NN", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Steht, wer den Gottesleugner", "tokens": ["Steht", ",", "wer", "den", "Got\u00b7tes\u00b7leug\u00b7ner"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "PWS", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nicht f\u00fcr rasend h\u00e4lt?", "tokens": ["Nicht", "f\u00fcr", "ra\u00b7send", "h\u00e4lt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ADJD", "VVFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "\u00bbdie schreckliche?\u00ab Ja die schreckliche!", "tokens": ["\u00bb", "die", "schreck\u00b7li\u00b7che", "?", "\u00ab", "Ja", "die", "schreck\u00b7li\u00b7che", "!"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "$.", "$(", "PTKANT", "ART", "ADJA", "$."], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Denn h\u00e4ltst du ihn, der ein Stolzer ist! ein Emp\u00f6rer ist!", "tokens": ["Denn", "h\u00e4ltst", "du", "ihn", ",", "der", "ein", "Stol\u00b7zer", "ist", "!", "ein", "Em\u00b7p\u00f6\u00b7rer", "ist", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "$,", "PRELS", "ART", "NN", "VAFIN", "$.", "ART", "NN", "VAFIN", "$."], "meter": "-+-+--+-++-+-+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Weiter nichts ist! f\u00fcr einen Denker den;", "tokens": ["Wei\u00b7ter", "nichts", "ist", "!", "f\u00fcr", "ei\u00b7nen", "Den\u00b7ker", "den", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VAFIN", "$.", "APPR", "ART", "NN", "ART", "$."], "meter": "+-+--+-+--", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "So ist die Stufe, worauf du stehest, zu tief!", "tokens": ["So", "ist", "die", "Stu\u00b7fe", ",", "wo\u00b7rauf", "du", "ste\u00b7hest", ",", "zu", "tief", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,", "PTKA", "ADJD", "$."], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "So kanst du werden, was er ist,", "tokens": ["So", "kanst", "du", "wer\u00b7den", ",", "was", "er", "ist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VAINF", "$,", "PWS", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Rasender!", "tokens": ["Ein", "Ra\u00b7sen\u00b7der", "!"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Ein Feiger, (Rasende sinds) so Vernichtung", "tokens": ["Ein", "Fei\u00b7ger", ",", "(", "Ra\u00b7sen\u00b7de", "sinds", ")", "so", "Ver\u00b7nich\u00b7tung"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "$(", "NN", "VAFIN", "$(", "ADV", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Glaubet, leben mag, sich nicht vernichtet!", "tokens": ["Glau\u00b7bet", ",", "le\u00b7ben", "mag", ",", "sich", "nicht", "ver\u00b7nich\u00b7tet", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVINF", "VMFIN", "$,", "PRF", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "Aber ich sucht', und ich fand Entschuldigung", "tokens": ["A\u00b7ber", "ich", "sucht'", ",", "und", "ich", "fand", "Ent\u00b7schul\u00b7di\u00b7gung"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "$,", "KON", "PPER", "VVFIN", "NN"], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "F\u00fcr den Feigen, der ist, und dem doch Gott nicht ist.", "tokens": ["F\u00fcr", "den", "Fei\u00b7gen", ",", "der", "ist", ",", "und", "dem", "doch", "Gott", "nicht", "ist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "VAFIN", "$,", "KON", "ART", "ADV", "NN", "PTKNEG", "VAFIN", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Entscheid', ob ich die rechte fand. Er denket sich,", "tokens": ["Ent\u00b7scheid'", ",", "ob", "ich", "die", "rech\u00b7te", "fand", ".", "Er", "den\u00b7ket", "sich", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "ART", "ADJA", "VVFIN", "$.", "PPER", "VVFIN", "PRF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ohne Gott! hat sich dadurch nur nicht ganz vernichtet!", "tokens": ["Oh\u00b7ne", "Gott", "!", "hat", "sich", "da\u00b7durch", "nur", "nicht", "ganz", "ver\u00b7nich\u00b7tet", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$.", "VAFIN", "PRF", "PAV", "ADV", "PTKNEG", "ADV", "VVPP", "$."], "meter": "+--+---+-+-+-", "measure": "dactylic.di.plus"}}, "stanza.5": {"line.1": {"text": "Schleichet, bebt, zweifelt umher;", "tokens": ["Schlei\u00b7chet", ",", "bebt", ",", "zwei\u00b7felt", "um\u00b7her", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Des Gespenstes Gedanke (sein Wort leugt Tiefsinn)", "tokens": ["Des", "Ge\u00b7spens\u00b7tes", "Ge\u00b7dan\u00b7ke", "(", "sein", "Wort", "leugt", "Tief\u00b7sinn", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "PPOSAT", "NN", "VVFIN", "NN", "$("], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Ist dem Traume gleich,", "tokens": ["Ist", "dem", "Trau\u00b7me", "gleich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Welcher vom Traume tr\u00e4umt.", "tokens": ["Wel\u00b7cher", "vom", "Trau\u00b7me", "tr\u00e4umt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "APPRART", "NN", "VVFIN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}}}}