{"dta.poem.21797": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "N.A.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Soll/ Zahrt-l\u00e4nder/ ich von dir hier was", "tokens": ["Soll", "/", "Zahr\u00b7tl\u00e4n\u00b7der", "/", "ich", "von", "dir", "hier", "was"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "$(", "NN", "$(", "PPER", "APPR", "PPER", "ADV", "PWS"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "melden oder schweigen?", "tokens": ["mel\u00b7den", "o\u00b7der", "schwei\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVINF", "KON", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Jens verbeut der Freundschafft Menge", "tokens": ["Jens", "ver\u00b7beut", "der", "Freund\u00b7schafft", "Men\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "dieses wehrt der Ubelstand", "tokens": ["die\u00b7ses", "wehrt", "der", "U\u00b7bel\u00b7stand"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und bezeugt mich des Vergessens. H\u00e4tt\u2019 ich", "tokens": ["und", "be\u00b7zeugt", "mich", "des", "Ver\u00b7ges\u00b7sens", ".", "H\u00e4tt'", "ich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ART", "NN", "$.", "VVFIN", "PPER"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "nur Apelles Hand/", "tokens": ["nur", "A\u00b7pel\u00b7les", "Hand", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NE", "NN", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "wolt\u2019 ich d", "tokens": ["wolt'", "ich", "d"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "PPER", "XY"], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "stillen F\u00fcrhang zeigen.", "tokens": ["stil\u00b7len", "F\u00fcr\u00b7hang", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.9": {"text": "Jezt sey dieser Strich genug. Weilmein A-", "tokens": ["Jezt", "sey", "die\u00b7ser", "Strich", "ge\u00b7nug", ".", "Weil\u00b7mein", "A"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VAFIN", "PDAT", "NN", "ADV", "$.", "NN", "TRUNC"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "tem sich wird regen", "tokens": ["tem", "sich", "wird", "re\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "PRF", "VAFIN", "ADJA"], "meter": "---+-", "measure": "unknown.measure.single"}, "line.11": {"text": "ist mein dancken zu geringe gegen deiner", "tokens": ["ist", "mein", "dan\u00b7cken", "zu", "ge\u00b7rin\u00b7ge", "ge\u00b7gen", "dei\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "VVINF", "PTKZU", "ADJA", "APPR", "PPOSAT"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.12": {"text": "Guttaht Zahl/", "tokens": ["Gut\u00b7taht", "Zahl", "/"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.13": {"text": "die du hast an mir erwiesen. Leben/ Leib und", "tokens": ["die", "du", "hast", "an", "mir", "er\u00b7wie\u00b7sen", ".", "Le\u00b7ben", "/", "Leib", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "PPER", "VAFIN", "APPR", "PPER", "VVINF", "$.", "NN", "$(", "NN", "KON"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.14": {"text": "allzumahl", "tokens": ["all\u00b7zu\u00b7mahl"], "token_info": ["word"], "pos": ["ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.15": {"text": "was in meinen Kr\u00e4fften wohnt/ wil ich dir zu", "tokens": ["was", "in", "mei\u00b7nen", "Kr\u00e4ff\u00b7ten", "wohnt", "/", "wil", "ich", "dir", "zu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "PPOSAT", "NN", "VVFIN", "$(", "VMFIN", "PPER", "PPER", "APPR"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.16": {"text": "Diensten hegen.", "tokens": ["Diens\u00b7ten", "he\u00b7gen", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.17": {"text": "Du/ Hirander/ Deutsches Herz hast mich ie", "tokens": ["Du", "/", "Hi\u00b7ran\u00b7der", "/", "Deut\u00b7sches", "Herz", "hast", "mich", "ie"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "$(", "NN", "$(", "ADJA", "NN", "VAFIN", "PPER", "ADV"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.18": {"text": "und ie geliebet/", "tokens": ["und", "ie", "ge\u00b7lie\u00b7bet", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.19": {"text": "seit ich Liebens wehrt gewesen/ du bist mir", "tokens": ["seit", "ich", "Lie\u00b7bens", "wehrt", "ge\u00b7we\u00b7sen", "/", "du", "bist", "mir"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "NN", "VVFIN", "VAPP", "$(", "PPER", "VAFIN", "PPER"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.20": {"text": "der erste Freund/", "tokens": ["der", "ers\u00b7te", "Freund", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.21": {"text": "wirst auch wol der lezte bleiben/ wie dus hast", "tokens": ["wirst", "auch", "wol", "der", "lez\u00b7te", "blei\u00b7ben", "/", "wie", "dus", "hast"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "ART", "ADJA", "VVINF", "$(", "KOKOM", "PDS", "VAFIN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.22": {"text": "mit mir gemeint/", "tokens": ["mit", "mir", "ge\u00b7meint", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "$("], "meter": "+--+", "measure": "iambic.di.chol"}, "line.23": {"text": "hat so leicht die alte Welt gegen Freunde nicht", "tokens": ["hat", "so", "leicht", "die", "al\u00b7te", "Welt", "ge\u00b7gen", "Freun\u00b7de", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADJD", "ART", "ADJA", "NN", "APPR", "NN", "PTKNEG"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.24": {"text": "ge\u00fcbet.", "tokens": ["ge\u00b7\u00fc\u00b7bet", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.25": {"text": "z\u00fcrne nicht/ Nephelidor da\u00df ich dich zulezt ver-", "tokens": ["z\u00fcr\u00b7ne", "nicht", "/", "Ne\u00b7phe\u00b7li\u00b7dor", "da\u00df", "ich", "dich", "zu\u00b7lezt", "ver"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "$(", "NE", "KOUS", "PPER", "PRF", "ADV", "TRUNC"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.26": {"text": "melde/", "tokens": ["mel\u00b7de", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.27": {"text": "dich/ den Nord-stern meiner Freunde/ der", "tokens": ["dich", "/", "den", "Nord\u00b7stern", "mei\u00b7ner", "Freun\u00b7de", "/", "der"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "$(", "ART", "NN", "PPOSAT", "NN", "$(", "ART"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.28": {"text": "weit ob den Wolken steht", "tokens": ["weit", "ob", "den", "Wol\u00b7ken", "steht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "KOUS", "ART", "NN", "VVFIN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.29": {"text": "und den dunkeln Nebel truzzet/ wenn des", "tokens": ["und", "den", "dun\u00b7keln", "Ne\u00b7bel", "truz\u00b7zet", "/", "wenn", "des"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "$(", "KOUS", "ART"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.30": {"text": "Neides Herbst entsteht/", "tokens": ["Nei\u00b7des", "Herbst", "ent\u00b7steht", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.31": {"text": "Edler/ z\u00fcrne/ z\u00fcrne nicht! weil Apollo in dem", "tokens": ["Ed\u00b7ler", "/", "z\u00fcr\u00b7ne", "/", "z\u00fcr\u00b7ne", "nicht", "!", "weil", "A\u00b7pol\u00b7lo", "in", "dem"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$(", "VVFIN", "$(", "VVFIN", "PTKNEG", "$.", "KOUS", "NE", "APPR", "ART"], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.32": {"text": "Felde", "tokens": ["Fel\u00b7de"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.33": {"text": "des beblauten Himmels blizzt/ sollstu mir der", "tokens": ["des", "be\u00b7blau\u00b7ten", "Him\u00b7mels", "blizzt", "/", "soll\u00b7stu", "mir", "der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$(", "VMFIN", "PPER", "ART"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.34": {"text": "gr\u00f6ste heissen.", "tokens": ["gr\u00f6s\u00b7te", "heis\u00b7sen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.35": {"text": "Um so viel du meinem Nahmen/ der hier-", "tokens": ["Um", "so", "viel", "du", "mei\u00b7nem", "Nah\u00b7men", "/", "der", "hier"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUI", "ADV", "ADV", "PPER", "PPOSAT", "NN", "$(", "ART", "TRUNC"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.36": {"text": "unten/ n\u00e4her bist:", "tokens": ["un\u00b7ten", "/", "n\u00e4\u00b7her", "bist", ":"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADV", "$(", "ADJD", "VAFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.37": {"text": "nun mit so viel treuern dr\u00fckken sollstu sein", "tokens": ["nun", "mit", "so", "viel", "treu\u00b7ern", "dr\u00fck\u00b7ken", "soll\u00b7stu", "sein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADV", "ADV", "VVINF", "VVINF", "VMFIN", "PPOSAT"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.38": {"text": "von mir gek\u00fc\u00dft.", "tokens": ["von", "mir", "ge\u00b7k\u00fc\u00dft", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.39": {"text": "La\u00df mir zu/ da\u00df ich dich mag mit zu meinen bei-", "tokens": ["La\u00df", "mir", "zu", "/", "da\u00df", "ich", "dich", "mag", "mit", "zu", "mei\u00b7nen", "bei"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PTKZU", "$(", "KOUS", "PPER", "PPER", "VMFIN", "APPR", "APPR", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "den reissen!", "tokens": ["den", "reis\u00b7sen", "!"], "token_info": ["word", "word", "punct"], "pos": ["ART", "VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.41": {"text": "Dein gekr\u00f6nter Lorber-Kranz hat sich mir ge-", "tokens": ["Dein", "ge\u00b7kr\u00f6n\u00b7ter", "Lor\u00b7ber\u00b7Kranz", "hat", "sich", "mir", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "PRF", "PPER", "TRUNC"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.42": {"text": "neigt erwiesen:", "tokens": ["neigt", "er\u00b7wie\u00b7sen", ":"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "VVPP", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.43": {"text": "war schon nichts an mir zu finden/ welches", "tokens": ["war", "schon", "nichts", "an", "mir", "zu", "fin\u00b7den", "/", "wel\u00b7ches"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "ADV", "PIS", "APPR", "PPER", "PTKZU", "VVINF", "$(", "PWS"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.44": {"text": "dieser kleinen Welt/", "tokens": ["die\u00b7ser", "klei\u00b7nen", "Welt", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.45": {"text": "die nu ganz Merkurisch lebet/ in die stolzen", "tokens": ["die", "nu", "ganz", "Mer\u00b7ku\u00b7risch", "le\u00b7bet", "/", "in", "die", "stol\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADV", "ADV", "ADJD", "VVFIN", "$(", "APPR", "ART", "NN"], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.46": {"text": "Augen f\u00e4llt.", "tokens": ["Au\u00b7gen", "f\u00e4llt", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.47": {"text": "Du hast selbst di\u00df gantze Werk erst gestraffet/", "tokens": ["Du", "hast", "selbst", "di\u00df", "gant\u00b7ze", "Werk", "erst", "ge\u00b7straf\u00b7fet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PDS", "ADJA", "NN", "ADV", "VVPP", "$("], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.48": {"text": "denn gepriesen.", "tokens": ["denn", "ge\u00b7prie\u00b7sen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVPP", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.49": {"text": "Bleib\u2019 auch dieses Zehens Freund/ steiffe Ve-", "tokens": ["Bleib'", "auch", "die\u00b7ses", "Ze\u00b7hens", "Freund", "/", "steif\u00b7fe", "Ve"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "ADV", "PDAT", "NN", "NN", "$(", "VVFIN", "TRUNC"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.50": {"text": "nus Myrten-Zweige/", "tokens": ["nus", "Myr\u00b7ten\u00b7Zwei\u00b7ge", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.51": {"text": "halte deine Dafnen-Bl\u00e4tter \u00fcber ihren", "tokens": ["hal\u00b7te", "dei\u00b7ne", "Daf\u00b7nen\u00b7Bl\u00e4t\u00b7ter", "\u00fc\u00b7ber", "ih\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.52": {"text": "Glanz empor/", "tokens": ["Glanz", "em\u00b7por", "/"], "token_info": ["word", "word", "punct"], "pos": ["NN", "PTKVZ", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.53": {"text": "halt auch/ Retter/ \u00fcber mir/ deinem Diener/", "tokens": ["halt", "auch", "/", "Ret\u00b7ter", "/", "\u00fc\u00b7ber", "mir", "/", "dei\u00b7nem", "Die\u00b7ner", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$(", "NN", "$(", "APPR", "PPER", "$(", "PPOSAT", "NN", "$("], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.54": {"text": "Filidor.", "tokens": ["Fi\u00b7li\u00b7dor", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.55": {"text": "Nehmet endlich inngesamt g\u00fcnstig an/ was", "tokens": ["Neh\u00b7met", "end\u00b7lich", "inn\u00b7ge\u00b7samt", "g\u00fcns\u00b7tig", "an", "/", "was"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "ADV", "ADJD", "ADJD", "PTKVZ", "$(", "PWS"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.56": {"text": "ich euch zeige.", "tokens": ["ich", "euch", "zei\u00b7ge", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PPER", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.57": {"text": "Sch\u00fczzet diese zarte Schrifft/ die nur au\u00df der", "tokens": ["Sch\u00fcz\u00b7zet", "die\u00b7se", "zar\u00b7te", "Schrifft", "/", "die", "nur", "au\u00df", "der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PDAT", "ADJA", "NN", "$(", "PRELS", "ADV", "APPR", "ART"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.58": {"text": "Feder fleusset/", "tokens": ["Fe\u00b7der", "fleus\u00b7set", "/"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.59": {"text": "derer jungen Dinten-n\u00e4sse kaum kaum noch", "tokens": ["de\u00b7rer", "jun\u00b7gen", "Din\u00b7ten\u00b7n\u00e4s\u00b7se", "kaum", "kaum", "noch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADJA", "NN", "ADV", "ADV", "ADV"], "meter": "--+-+-+-+-+", "measure": "anapaest.init"}, "line.60": {"text": "vertruknet klebt.", "tokens": ["ver\u00b7truk\u00b7net", "klebt", "."], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.61": {"text": "Ist es/ da\u00df mein schwaches Dichten seine", "tokens": ["Ist", "es", "/", "da\u00df", "mein", "schwa\u00b7ches", "Dich\u00b7ten", "sei\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "$(", "KOUS", "PPOSAT", "ADJA", "NN", "PPOSAT"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.62": {"text": "Kindheit \u00fcberlebt:", "tokens": ["Kind\u00b7heit", "\u00fc\u00b7ber\u00b7lebt", ":"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.63": {"text": "Denn so hoffet auch auff Gold/ da\u00df di\u00df nicht", "tokens": ["Denn", "so", "hof\u00b7fet", "auch", "auff", "Gold", "/", "da\u00df", "di\u00df", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ADV", "APPR", "NN", "$(", "KOUS", "PDS", "PTKNEG"], "meter": "+-+---+--+", "measure": "iambic.tetra.chol"}, "line.64": {"text": "ist/ noch so gleisset.", "tokens": ["ist", "/", "noch", "so", "gleis\u00b7set", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$(", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}}}}