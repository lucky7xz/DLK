{"dta.poem.2753": {"metadata": {"author": {"name": "M\u00fchlpfort, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Bey Beerdigung eines jungen S\u00f6hnleins E.  \n E. v. G. den 28. Novembr. 1680.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1686", "urn": "urn:nbn:de:kobv:b4-20414-7", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Au\u00df/ werthster Freund/ sein Paradie\u00df der Erden?", "tokens": ["Au\u00df", "/", "werths\u00b7ter", "Freund", "/", "sein", "Pa\u00b7ra\u00b7die\u00df", "der", "Er\u00b7den", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ADJA", "NN", "$(", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So unverhofft ein Kirchhof seyn?", "tokens": ["So", "un\u00b7ver\u00b7hofft", "ein", "Kirch\u00b7hof", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist denn die Wieg\u2019 ein Leichenstein?", "tokens": ["Ist", "denn", "die", "Wieg'", "ein", "Lei\u00b7chen\u00b7stein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und seh ich jetzt die Augen Muscheln werden/", "tokens": ["Und", "seh", "ich", "jetzt", "die", "Au\u00b7gen", "Mu\u00b7scheln", "wer\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wo die Natur die Perlen nicht gebiehrt/", "tokens": ["Wo", "die", "Na\u00b7tur", "die", "Per\u00b7len", "nicht", "ge\u00b7biehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Indem sie nichts als runde Thr\u00e4nen f\u00fchrt?", "tokens": ["In\u00b7dem", "sie", "nichts", "als", "run\u00b7de", "Thr\u00e4\u00b7nen", "f\u00fchrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "KOKOM", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Ja freylich Ach! ein G\u00e4rtner steht best\u00fcrtzet/", "tokens": ["Ja", "frey\u00b7lich", "Ach", "!", "ein", "G\u00e4rt\u00b7ner", "steht", "be\u00b7st\u00fcrt\u00b7zet", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ITJ", "$.", "ART", "NN", "VVFIN", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn er die Hoffnung seiner Zeit/", "tokens": ["Wenn", "er", "die", "Hoff\u00b7nung", "sei\u00b7ner", "Zeit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Blumen Schmuck und Lieblichkeit", "tokens": ["Der", "Blu\u00b7men", "Schmuck", "und", "Lieb\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Siht durch den Sturm des Nordens abgek\u00fcrtzet;", "tokens": ["Siht", "durch", "den", "Sturm", "des", "Nor\u00b7dens", "ab\u00b7ge\u00b7k\u00fcrt\u00b7zet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wenn er die M\u00fch und seiner Arbeit Flei\u00df", "tokens": ["Wenn", "er", "die", "M\u00fch", "und", "sei\u00b7ner", "Ar\u00b7beit", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "KON", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Schaut ausgetilgt durch Regen/ Schnee und Ei\u00df.", "tokens": ["Schaut", "aus\u00b7ge\u00b7tilgt", "durch", "Re\u00b7gen", "/", "Schnee", "und", "Ei\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVPP", "APPR", "NN", "$(", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Und wird uns nicht der herbe Blick betr\u00fcben/", "tokens": ["Und", "wird", "uns", "nicht", "der", "her\u00b7be", "Blick", "be\u00b7tr\u00fc\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn vor des Lentzens g\u00fcldne Zier/", "tokens": ["Wenn", "vor", "des", "Lent\u00b7zens", "g\u00fcld\u00b7ne", "Zier", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da Hyacinthen sprossen f\u00fcr/", "tokens": ["Da", "Hya\u00b7cin\u00b7then", "spros\u00b7sen", "f\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "APPR", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Nichts weiter sind als blasse Rauten blieben?", "tokens": ["Nichts", "wei\u00b7ter", "sind", "als", "blas\u00b7se", "Rau\u00b7ten", "blie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "VAFIN", "KOKOM", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Der Lilgen Haupt/ der Rosen Scharlach bricht", "tokens": ["Der", "Lil\u00b7gen", "Haupt", "/", "der", "Ro\u00b7sen", "Schar\u00b7lach", "bricht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$(", "ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Die Nelcke stirbt/ wenn Wermuth sie umflicht.", "tokens": ["Die", "Nel\u00b7cke", "stirbt", "/", "wenn", "Wer\u00b7muth", "sie", "um\u00b7flicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$(", "KOUS", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Nicht anders ists/ hochwerther Freund bestellet/", "tokens": ["Nicht", "an\u00b7ders", "ists", "/", "hoch\u00b7wert\u00b7her", "Freund", "be\u00b7stel\u00b7let", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VAFIN", "$(", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sein Weinstock/ da er zin\u00dfbahr bl\u00fcht/", "tokens": ["Sein", "Wein\u00b7stock", "/", "da", "er", "zin\u00df\u00b7bahr", "bl\u00fcht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "KOUS", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Von dem er eine Traube sieht/", "tokens": ["Von", "dem", "er", "ei\u00b7ne", "Trau\u00b7be", "sieht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die seinem Aug und Hertzen wolgef\u00e4llet/", "tokens": ["Die", "sei\u00b7nem", "Aug", "und", "Hert\u00b7zen", "wol\u00b7ge\u00b7f\u00e4l\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "KON", "NN", "VMFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Nun er die Blum erfreut in Armen tr\u00e4gt/", "tokens": ["Nun", "er", "die", "Blum", "er\u00b7freut", "in", "Ar\u00b7men", "tr\u00e4gt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "NE", "VVFIN", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "In die sein Bild und Aehnlichkeit gepr\u00e4gt;", "tokens": ["In", "die", "sein", "Bild", "und", "A\u00b7ehn\u00b7lich\u00b7keit", "ge\u00b7pr\u00e4gt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPOSAT", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-++-+-+", "measure": "unknown.measure.hexa"}}, "stanza.5": {"line.1": {"text": "So k\u00f6mmt der Tod/ O grimmiges Geschicke!", "tokens": ["So", "k\u00f6mmt", "der", "Tod", "/", "O", "grim\u00b7mi\u00b7ges", "Ge\u00b7schi\u00b7cke", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$(", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und reisst des Hauses Pfeiler ein/", "tokens": ["Und", "reisst", "des", "Hau\u00b7ses", "Pfei\u00b7ler", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "ART", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des wahren Adels edlen Stein/", "tokens": ["Des", "wah\u00b7ren", "A\u00b7dels", "ed\u00b7len", "Stein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Ahnen Bild/ der Tugend Meister-St\u00fccke/", "tokens": ["Der", "Ah\u00b7nen", "Bild", "/", "der", "Tu\u00b7gend", "Meis\u00b7ter\u00b7St\u00fc\u00b7cke", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$(", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Der Cedern Baum wird ihm zur Aloe", "tokens": ["Der", "Ce\u00b7dern", "Baum", "wird", "ihm", "zur", "A\u00b7loe"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "VAFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die erste Bl\u00fcth\u2019 verwandelt sich in Schnee.", "tokens": ["Die", "ers\u00b7te", "Bl\u00fcth'", "ver\u00b7wan\u00b7delt", "sich", "in", "Schnee", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Allein\u2019 ich wei\u00df: die Schmertzen k\u00f6nnen zwingen/", "tokens": ["Al\u00b7lein'", "ich", "wei\u00df", ":", "die", "Schmert\u00b7zen", "k\u00f6n\u00b7nen", "zwin\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVFIN", "$.", "ART", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zeigt einen rechten Helden-Muth;", "tokens": ["Zeigt", "ei\u00b7nen", "rech\u00b7ten", "Hel\u00b7den\u00b7Muth", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So steht ein unerschrocknes Blut", "tokens": ["So", "steht", "ein", "un\u00b7er\u00b7schrock\u00b7nes", "Blut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Getrost im Sturm/ l\u00e4st Pfeil auf Pfeile dringen.", "tokens": ["Ge\u00b7trost", "im", "Sturm", "/", "l\u00e4st", "Pfeil", "auf", "Pfei\u00b7le", "drin\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$(", "VVFIN", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und wei\u00df gewi\u00df/ da\u00df nach dem Donnerschlag", "tokens": ["Und", "wei\u00df", "ge\u00b7wi\u00df", "/", "da\u00df", "nach", "dem", "Don\u00b7ner\u00b7schlag"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "$(", "KOUS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der Sonnen Licht gew\u00e4hrt den sch\u00f6nsten Tag.", "tokens": ["Der", "Son\u00b7nen", "Licht", "ge\u00b7w\u00e4hrt", "den", "sch\u00f6ns\u00b7ten", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Der liebste Sohn ist zu dem Ursprung kommen/", "tokens": ["Der", "liebs\u00b7te", "Sohn", "ist", "zu", "dem", "Ur\u00b7sprung", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sein Stamm-Hau\u00df ist die Ewigkeit.", "tokens": ["Sein", "Stam\u00b7mHau\u00df", "ist", "die", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nur blo\u00df der Seelen irdisch Kleid", "tokens": ["Nur", "blo\u00df", "der", "See\u00b7len", "ir\u00b7disch", "Kleid"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hat in Beschlu\u00df der Erden Schos genommen.", "tokens": ["Hat", "in", "Be\u00b7schlu\u00df", "der", "Er\u00b7den", "Schos", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ein Erdmann wird nicht eh ein Himmels-Mann", "tokens": ["Ein", "Erd\u00b7mann", "wird", "nicht", "eh", "ein", "Him\u00b7mels\u00b7Mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Bi\u00df er die Last des Leibes weggethan.", "tokens": ["Bi\u00df", "er", "die", "Last", "des", "Lei\u00b7bes", "weg\u00b7ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Denn kan der Tohn mit seinem T\u00f6pffer zancken?", "tokens": ["Denn", "kan", "der", "Tohn", "mit", "sei\u00b7nem", "T\u00f6pf\u00b7fer", "zan\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Hand/ so ihn zu erst gemacht", "tokens": ["Die", "Hand", "/", "so", "ihn", "zu", "erst", "ge\u00b7macht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "ADV", "PPER", "APPR", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ihm die Formen zugedacht/", "tokens": ["Und", "ihm", "die", "For\u00b7men", "zu\u00b7ge\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Weicht nicht von Recht und ihren Meister-Schrancken.", "tokens": ["Weicht", "nicht", "von", "Recht", "und", "ih\u00b7ren", "Meis\u00b7ter\u00b7Schran\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "APPR", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Jtzt bildet sie/ bald schl\u00e4gt sie wieder ein/", "tokens": ["Jtzt", "bil\u00b7det", "sie", "/", "bald", "schl\u00e4gt", "sie", "wie\u00b7der", "ein", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$(", "ADV", "VVFIN", "PPER", "ADV", "ART", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und weist uns klar/ da\u00df wir nun Scherben seyn.", "tokens": ["Und", "weist", "uns", "klar", "/", "da\u00df", "wir", "nun", "Scher\u00b7ben", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "$(", "KOUS", "PPER", "ADV", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Doch tragen wir in irdenen Gef\u00e4ssen", "tokens": ["Doch", "tra\u00b7gen", "wir", "in", "ir\u00b7de\u00b7nen", "Ge\u00b7f\u00e4s\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den Schatz der grossen Herrlichkeit;", "tokens": ["Den", "Schatz", "der", "gros\u00b7sen", "Herr\u00b7lich\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Kleinod der Vollkommenheit:", "tokens": ["Das", "Klei\u00b7nod", "der", "Voll\u00b7kom\u00b7men\u00b7heit", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df/ ob wir schon bey Mogols Renten s\u00e4ssen/", "tokens": ["Da\u00df", "/", "ob", "wir", "schon", "bey", "Mo\u00b7gols", "Ren\u00b7ten", "s\u00e4s\u00b7sen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "KOUS", "PPER", "ADV", "APPR", "NE", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und Indien sein Gold uns liefert ein/", "tokens": ["Und", "In\u00b7di\u00b7en", "sein", "Gold", "uns", "lie\u00b7fert", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "PPOSAT", "NN", "PPER", "VVFIN", "ART", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der Seelen nach gar weit Stein-reicher seyn.", "tokens": ["Der", "See\u00b7len", "nach", "gar", "weit", "Stein\u00b7rei\u00b7cher", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADV", "ADJD", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Ein rother Klo\u00df von schlechtem Sand und Staube", "tokens": ["Ein", "ro\u00b7ther", "Klo\u00df", "von", "schlech\u00b7tem", "Sand", "und", "Stau\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Stellt\u2019 uns den ersten Erdmann f\u00fcr/", "tokens": ["Stellt'", "uns", "den", "ers\u00b7ten", "Erd\u00b7mann", "f\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Welt-Gesch\u00f6pffe h\u00f6chste Zier/", "tokens": ["Der", "Welt\u00b7Ge\u00b7sch\u00f6pf\u00b7fe", "h\u00f6chs\u00b7te", "Zier", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Indem noch ist versigelt unser Glaube;", "tokens": ["In\u00b7dem", "noch", "ist", "ver\u00b7si\u00b7gelt", "un\u00b7ser", "Glau\u00b7be", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VAFIN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Doch hat der Tod/ den An-Herrn\u2019 dieser Welt", "tokens": ["Doch", "hat", "der", "Tod", "/", "den", "An\u00b7Herrn'", "die\u00b7ser", "Welt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN", "$(", "ART", "NN", "PDAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "So/ als wie uns/ gebrechliche gef\u00e4llt.", "tokens": ["So", "/", "als", "wie", "uns", "/", "ge\u00b7brech\u00b7li\u00b7che", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$(", "KOUS", "PWAV", "PPER", "$(", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Wiewol ich wei\u00df sein treffliches Gem\u00fcthe/", "tokens": ["Wie\u00b7wol", "ich", "wei\u00df", "sein", "treff\u00b7li\u00b7ches", "Ge\u00b7m\u00fc\u00b7the", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und kluger Geist f\u00e4llt mir zwar bey", "tokens": ["Und", "klu\u00b7ger", "Geist", "f\u00e4llt", "mir", "zwar", "bey"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "VVFIN", "PPER", "ADV", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mein Freund/ er wei\u00df da\u00df ewig sey", "tokens": ["Mein", "Freund", "/", "er", "wei\u00df", "da\u00df", "e\u00b7wig", "sey"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$(", "PPER", "VVFIN", "KOUS", "ADJD", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des grossen GOttes Wunder-reiche G\u00fcte.", "tokens": ["Des", "gros\u00b7sen", "Got\u00b7tes", "Wun\u00b7der\u00b7rei\u00b7che", "G\u00fc\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Was aber heilt der Frau Gro\u00df-Mutter Leyd?", "tokens": ["Was", "a\u00b7ber", "heilt", "der", "Frau", "Gro\u00df\u00b7Mut\u00b7ter", "Leyd", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "ART", "NN", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Was stillet der Frau Mutter Traurigkeit?", "tokens": ["Was", "stil\u00b7let", "der", "Frau", "Mut\u00b7ter", "Trau\u00b7rig\u00b7keit", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Das zarte Kind so sie offt angelachet/", "tokens": ["Das", "zar\u00b7te", "Kind", "so", "sie", "offt", "an\u00b7ge\u00b7la\u00b7chet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Mund so halbe Wort ausstie\u00df/", "tokens": ["Der", "Mund", "so", "hal\u00b7be", "Wort", "aus\u00b7stie\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Fingern nach den Eltern wie\u00df/", "tokens": ["Mit", "Fin\u00b7gern", "nach", "den", "El\u00b7tern", "wie\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und tausend Lust beh\u00e4glich hat gemachet/", "tokens": ["Und", "tau\u00b7send", "Lust", "be\u00b7h\u00e4g\u00b7lich", "hat", "ge\u00b7ma\u00b7chet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "ADJD", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die Anmuth selbst/ das War der zarten Jahr/", "tokens": ["Die", "An\u00b7muth", "selbst", "/", "das", "War", "der", "zar\u00b7ten", "Jahr", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$(", "PDS", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Zerschmeltzet nur auff einer Todten-Bahr.", "tokens": ["Zer\u00b7schmelt\u00b7zet", "nur", "auff", "ei\u00b7ner", "Tod\u00b7ten\u00b7Bahr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Hilff GOtt! was gab der Knabe nicht vor Minen?", "tokens": ["Hilff", "Gott", "!", "was", "gab", "der", "Kna\u00b7be", "nicht", "vor", "Mi\u00b7nen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "PWS", "VVFIN", "ART", "NN", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Ahnen Helm/ Spie\u00df/ Schild und Schwerdt/", "tokens": ["Der", "Ah\u00b7nen", "Helm", "/", "Spie\u00df", "/", "Schild", "und", "Schwerdt", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$(", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und was sonst ihren Ruhm bewehrt/", "tokens": ["Und", "was", "sonst", "ih\u00b7ren", "Ruhm", "be\u00b7wehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sah man in ihm als wie von neuem gr\u00fcnen.", "tokens": ["Sah", "man", "in", "ihm", "als", "wie", "von", "neu\u00b7em", "gr\u00fc\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "PPER", "KOUS", "KOKOM", "APPR", "ADJA", "VVINF", "$."], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.5": {"text": "Ein Adler weist bald seines gleichen Art", "tokens": ["Ein", "Ad\u00b7ler", "weist", "bald", "sei\u00b7nes", "glei\u00b7chen", "Art"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Ein junger L\u00f6w hat nie die Klau gespart.", "tokens": ["Ein", "jun\u00b7ger", "L\u00f6w", "hat", "nie", "die", "Klau", "ge\u00b7spart", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Di\u00df/ klagt mein Freund samt hohen Anverwandten/", "tokens": ["Di\u00df", "/", "klagt", "mein", "Freund", "samt", "ho\u00b7hen", "An\u00b7ver\u00b7wand\u00b7ten", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$(", "VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sey alles in den Sarg gethan.", "tokens": ["Sey", "al\u00b7les", "in", "den", "Sarg", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nein/ Erdmann ist ein Rittersmann/", "tokens": ["Nein", "/", "Erd\u00b7mann", "ist", "ein", "Rit\u00b7ters\u00b7mann", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "NN", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Diener sind die himmlischen Trabanten.", "tokens": ["Die", "Die\u00b7ner", "sind", "die", "himm\u00b7li\u00b7schen", "Tra\u00b7ban\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Der Ewigkeit Schnee-weisses Feld-Panier", "tokens": ["Der", "E\u00b7wig\u00b7keit", "Schnee\u00b7weis\u00b7ses", "Feld\u00b7Pa\u00b7nier"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Ist jetzt sein Schmuck und auserle\u00dfne Zier.", "tokens": ["Ist", "jetzt", "sein", "Schmuck", "und", "au\u00b7ser\u00b7le\u00df\u00b7ne", "Zier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Sein Erdmann steht im h\u00f6chsten Ritter-Orden/", "tokens": ["Sein", "Erd\u00b7mann", "steht", "im", "h\u00f6chs\u00b7ten", "Rit\u00b7ter\u00b7Or\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Er ist es bey dem heil\u2019gen Grab/", "tokens": ["Er", "ist", "es", "bey", "dem", "heil'\u00b7gen", "Grab", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er bricht der Tauben Oel-Zweig ab/", "tokens": ["Er", "bricht", "der", "Tau\u00b7ben", "O\u00b7el\u00b7Zweig", "ab", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NE", "PTKVZ", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Sein Band ist roth von JEsus Blute worden!", "tokens": ["Sein", "Band", "ist", "roth", "von", "Je\u00b7sus", "Blu\u00b7te", "wor\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "APPR", "NE", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Hochwerther Freund/ das stille seine Pein/", "tokens": ["Hoch\u00b7wert\u00b7her", "Freund", "/", "das", "stil\u00b7le", "sei\u00b7ne", "Pein", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "PDS", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Da\u00df Christen schon als Kinder Ritter seyn.", "tokens": ["Da\u00df", "Chris\u00b7ten", "schon", "als", "Kin\u00b7der", "Rit\u00b7ter", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "KOUS", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}