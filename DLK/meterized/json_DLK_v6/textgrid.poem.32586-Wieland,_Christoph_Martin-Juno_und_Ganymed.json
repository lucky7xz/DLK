{"textgrid.poem.32586": {"metadata": {"author": {"name": "Wieland, Christoph Martin", "birth": "N.A.", "death": "N.A."}, "title": "Juno und Ganymed", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Secundus, der Pythagor\u00e4er,", "tokens": ["Se\u00b7cun\u00b7dus", ",", "der", "Py\u00b7tha\u00b7go\u00b7r\u00e4\u00b7er", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Sagt, und erfuhr's an seinem eignen Leib,", "tokens": ["Sagt", ",", "und", "er\u00b7fuhr's", "an", "sei\u00b7nem", "eig\u00b7nen", "Leib", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KON", "NE", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Es sei ein grillenhaftes Weib", "tokens": ["Es", "sei", "ein", "gril\u00b7len\u00b7haf\u00b7tes", "Weib"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bei Tag, oft auch bei Nacht, ein schlimmer Zeitvertreib;", "tokens": ["Bei", "Tag", ",", "oft", "auch", "bei", "Nacht", ",", "ein", "schlim\u00b7mer", "Zeit\u00b7ver\u00b7treib", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADV", "ADV", "APPR", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ist sie noch sch\u00f6n, so steigt das \u00dcbel h\u00f6her;", "tokens": ["Ist", "sie", "noch", "sch\u00f6n", ",", "so", "steigt", "das", "\u00dc\u00b7bel", "h\u00f6\u00b7her", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "$,", "ADV", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Belesen, witzig \u2013 Quellen neuer Pein", "tokens": ["Be\u00b7le\u00b7sen", ",", "wit\u00b7zig", "\u2013", "Quel\u00b7len", "neu\u00b7er", "Pein"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVPP", "$,", "ADJD", "$(", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "F\u00fcr ihren Job! er mu\u00df zu b\u00f6sem Spiel oft lachen;", "tokens": ["F\u00fcr", "ih\u00b7ren", "Job", "!", "er", "mu\u00df", "zu", "b\u00f6\u00b7sem", "Spiel", "oft", "la\u00b7chen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NE", "$.", "PPER", "VMFIN", "APPR", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Doch gibt ihr gar sein schwarzer D\u00e4mon ein,", "tokens": ["Doch", "gibt", "ihr", "gar", "sein", "schwar\u00b7zer", "D\u00e4\u00b7mon", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PPOSAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "(f\u00e4hrt unser Autor fort) den Drachen", "tokens": ["(", "f\u00e4hrt", "un\u00b7ser", "Au\u00b7tor", "fort", ")", "den", "Dra\u00b7chen"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$(", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Von Ehrbarkeit und strenger Zucht zu machen,", "tokens": ["Von", "Ehr\u00b7bar\u00b7keit", "und", "stren\u00b7ger", "Zucht", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Dann m\u00f6gen ihm die G\u00f6tter gn\u00e4dig sein!", "tokens": ["Dann", "m\u00f6\u00b7gen", "ihm", "die", "G\u00f6t\u00b7ter", "gn\u00e4\u00b7dig", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Der Wunsch ist gut und fromm; allein,", "tokens": ["Der", "Wunsch", "ist", "gut", "und", "fromm", ";", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$.", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Glaubt man der alten Dichter Sage,", "tokens": ["Glaubt", "man", "der", "al\u00b7ten", "Dich\u00b7ter", "Sa\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "(und Leuten die bei hellem Tage", "tokens": ["(", "und", "Leu\u00b7ten", "die", "bei", "hel\u00b7lem", "Ta\u00b7ge"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KON", "NN", "ART", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gespenster sehn, wird allerdings geglaubt)", "tokens": ["Ge\u00b7spens\u00b7ter", "sehn", ",", "wird", "al\u00b7ler\u00b7dings", "ge\u00b7glaubt", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "$,", "VAFIN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "So war selbst Zeus, der G\u00f6tter Haupt,", "tokens": ["So", "war", "selbst", "Zeus", ",", "der", "G\u00f6t\u00b7ter", "Haupt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "NE", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nicht immer frei von dieser Ehstands-Plage.", "tokens": ["Nicht", "im\u00b7mer", "frei", "von", "die\u00b7ser", "Eh\u00b7stands\u00b7Pla\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Homer sagt's ungescheut: Frau Juno war", "tokens": ["Ho\u00b7mer", "sagt's", "un\u00b7ge\u00b7scheut", ":", "Frau", "Ju\u00b7no", "war"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADJD", "$.", "NN", "NE", "VAFIN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.8": {"text": "Ein sch\u00f6nes Weib, das mu\u00dfte man ihr lassen;", "tokens": ["Ein", "sch\u00f6\u00b7nes", "Weib", ",", "das", "mu\u00df\u00b7te", "man", "ihr", "las\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PDS", "VMFIN", "PIS", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Hoch, wohlgewachsen, schwarz von Aug und Haar,", "tokens": ["Hoch", ",", "wohl\u00b7ge\u00b7wach\u00b7sen", ",", "schwarz", "von", "Aug", "und", "Haar", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "$,", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Im Gang und Anstand, ja sogar", "tokens": ["Im", "Gang", "und", "An\u00b7stand", ",", "ja", "so\u00b7gar"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "KON", "NN", "$,", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "In ihren spr\u00f6desten Grimassen,", "tokens": ["In", "ih\u00b7ren", "spr\u00f6\u00b7des\u00b7ten", "Gri\u00b7mas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+--++-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Viel Majest\u00e4t; im langen Rocke war", "tokens": ["Viel", "Ma\u00b7jes\u00b7t\u00e4t", ";", "im", "lan\u00b7gen", "Ro\u00b7cke", "war"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "$.", "APPRART", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Der sch\u00f6nste Fu\u00df und manches unsichtbar", "tokens": ["Der", "sch\u00f6ns\u00b7te", "Fu\u00df", "und", "man\u00b7ches", "un\u00b7sicht\u00b7bar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "KON", "PIS", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Was sie den Paris einst auf Ida sehen lassen;", "tokens": ["Was", "sie", "den", "Pa\u00b7ris", "einst", "auf", "I\u00b7da", "se\u00b7hen", "las\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NE", "ADV", "APPR", "NE", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Allein um alles das lie\u00df ihr Gemahl und Herr", "tokens": ["Al\u00b7lein", "um", "al\u00b7les", "das", "lie\u00df", "ihr", "Ge\u00b7mahl", "und", "Herr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PIS", "PDS", "VVFIN", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Die sch\u00f6ne Nacht, in welcher er", "tokens": ["Die", "sch\u00f6\u00b7ne", "Nacht", ",", "in", "wel\u00b7cher", "er"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "PRELS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Vom Jungfern-Gurt sie zu befreien,", "tokens": ["Vom", "Jung\u00b7fern\u00b7Gurt", "sie", "zu", "be\u00b7frei\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "So hastig war, nicht seltner sich gereuen.", "tokens": ["So", "has\u00b7tig", "war", ",", "nicht", "selt\u00b7ner", "sich", "ge\u00b7reu\u00b7en", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "$,", "PTKNEG", "ADJD", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Wer ihn f\u00fcr gl\u00fccklich hielt, der sah die Dame nicht", "tokens": ["Wer", "ihn", "f\u00fcr", "gl\u00fcck\u00b7lich", "hielt", ",", "der", "sah", "die", "Da\u00b7me", "nicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "APPR", "ADJD", "VVFIN", "$,", "PRELS", "VVFIN", "ART", "NN", "PTKNEG"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Im Schlafgemach und hinter den Gardinen.", "tokens": ["Im", "Schlaf\u00b7ge\u00b7mach", "und", "hin\u00b7ter", "den", "Gar\u00b7di\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Dort pflegte sie beim Sternen-Licht", "tokens": ["Dort", "pfleg\u00b7te", "sie", "beim", "Ster\u00b7nen\u00b7Licht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des Weiber-Rechts sich ernstlich zu bedienen;", "tokens": ["Des", "Wei\u00b7ber\u00b7Rechts", "sich", "ernst\u00b7lich", "zu", "be\u00b7die\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Dort wies sie ihm ein anders Angesicht,", "tokens": ["Dort", "wies", "sie", "ihm", "ein", "an\u00b7ders", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Als das am G\u00f6tter-Tisch so angenehm geschienen.", "tokens": ["Als", "das", "am", "G\u00f6t\u00b7ter\u00b7Tisch", "so", "an\u00b7ge\u00b7nehm", "ge\u00b7schie\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "APPRART", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wo Juno lag, da schlief sich's selten viel,", "tokens": ["Wo", "Ju\u00b7no", "lag", ",", "da", "schlief", "sich's", "sel\u00b7ten", "viel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "VVFIN", "$,", "ADV", "VVFIN", "PIS", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da lie\u00df die ganze Nacht als wie ein Glockenspiel", "tokens": ["Da", "lie\u00df", "die", "gan\u00b7ze", "Nacht", "als", "wie", "ein", "Glo\u00b7cken\u00b7spiel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "KOUS", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sich ihre sch\u00f6ne Stimme h\u00f6ren;", "tokens": ["Sich", "ih\u00b7re", "sch\u00f6\u00b7ne", "Stim\u00b7me", "h\u00f6\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und konnte gleich bei ihren Sittenlehren", "tokens": ["Und", "konn\u00b7te", "gleich", "bei", "ih\u00b7ren", "Sit\u00b7ten\u00b7leh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ihr Mann sich oft des Schlummers nicht erwehren,", "tokens": ["Ihr", "Mann", "sich", "oft", "des", "Schlum\u00b7mers", "nicht", "er\u00b7weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PRF", "ADV", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So wu\u00dfte sie ihn doch bald wieder aufzust\u00f6ren,", "tokens": ["So", "wu\u00df\u00b7te", "sie", "ihn", "doch", "bald", "wie\u00b7der", "auf\u00b7zu\u00b7st\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "ADV", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und \u00fcberschrie, wenn's ihr gefiel,", "tokens": ["Und", "\u00fc\u00b7bersc\u00b7hrie", ",", "wenn's", "ihr", "ge\u00b7fiel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sogar die Nacht-Musik der Sph\u00e4ren.", "tokens": ["So\u00b7gar", "die", "Nacht\u00b7Mu\u00b7sik", "der", "Sph\u00e4\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ein Scherz beim Nektar, den er liebt,", "tokens": ["Ein", "Scherz", "beim", "Nek\u00b7tar", ",", "den", "er", "liebt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Seitenblick, den er der Ceres gibt,", "tokens": ["Ein", "Sei\u00b7ten\u00b7blick", ",", "den", "er", "der", "Ce\u00b7res", "gibt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ART", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wenn sich ihr Palatin verschoben;", "tokens": ["Wenn", "sich", "ihr", "Pa\u00b7la\u00b7tin", "ver\u00b7scho\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Ein Knieband, das er j\u00fcngst der Venus aufgehoben,", "tokens": ["Ein", "Knie\u00b7band", ",", "das", "er", "j\u00fcngst", "der", "Ve\u00b7nus", "auf\u00b7ge\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ja wenn er nur Dianens rundes Knie", "tokens": ["Ja", "wenn", "er", "nur", "Di\u00b7a\u00b7nens", "run\u00b7des", "Knie"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "KOUS", "PPER", "ADV", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Von ungef\u00e4hr (mit Flei\u00df geschah es nie)", "tokens": ["Von", "un\u00b7ge\u00b7f\u00e4hr", "(", "mit", "Flei\u00df", "ge\u00b7schah", "es", "nie", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "$(", "APPR", "NN", "VVFIN", "PPER", "ADV", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Beim Spiel mit seinen Knien dr\u00fcckt,", "tokens": ["Beim", "Spiel", "mit", "sei\u00b7nen", "Kni\u00b7en", "dr\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und, kommt die Reih an ihn zu passen,", "tokens": ["Und", ",", "kommt", "die", "Reih", "an", "ihn", "zu", "pas\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "ART", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Der Iris, die indes im Vorsaal sitzt und stickt,", "tokens": ["Der", "I\u00b7ris", ",", "die", "in\u00b7des", "im", "Vor\u00b7saal", "sitzt", "und", "stickt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "$,", "PRELS", "ADV", "APPRART", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.10": {"text": "Die Backen im Vorbeigehn zwickt;", "tokens": ["Die", "Ba\u00b7cken", "im", "Vor\u00b7bei\u00b7gehn", "zwickt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.11": {"text": "So darf er sich darauf verlassen,", "tokens": ["So", "darf", "er", "sich", "da\u00b7rauf", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "PAV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Da\u00df ihn Madam, wie sich's geb\u00fchrt,", "tokens": ["Da\u00df", "ihn", "Ma\u00b7dam", ",", "wie", "sich's", "ge\u00b7b\u00fchrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "$,", "PWAV", "PIS", "VVPP", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.13": {"text": "Die n\u00e4chste Nacht hindurch moralisieren wird;", "tokens": ["Die", "n\u00e4chs\u00b7te", "Nacht", "hin\u00b7durch", "mo\u00b7ra\u00b7li\u00b7sie\u00b7ren", "wird", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PAV", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "In diesem St\u00fcck war nicht mit ihr zu spa\u00dfen.", "tokens": ["In", "die\u00b7sem", "St\u00fcck", "war", "nicht", "mit", "ihr", "zu", "spa\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "PTKNEG", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Wie teuer mu\u00df der gute Mann", "tokens": ["Wie", "teu\u00b7er", "mu\u00df", "der", "gu\u00b7te", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Tugend seiner Frau bezahlen!", "tokens": ["Die", "Tu\u00b7gend", "sei\u00b7ner", "Frau", "be\u00b7zah\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Beim kleinsten Anla\u00df f\u00e4ngt sie an", "tokens": ["Beim", "kleins\u00b7ten", "An\u00b7la\u00df", "f\u00e4ngt", "sie", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit ihrer keuschen Treu zu prahlen,", "tokens": ["Mit", "ih\u00b7rer", "keu\u00b7schen", "Treu", "zu", "prah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wirft die ger\u00fcmpfte Nas empor,", "tokens": ["Wirft", "die", "ge\u00b7r\u00fcmpf\u00b7te", "Nas", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und r\u00fcckt ihm den Ixion vor,", "tokens": ["Und", "r\u00fcckt", "ihm", "den", "I\u00b7xion", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Den einzgen Fall in ihrem Leben,", "tokens": ["Den", "einz\u00b7gen", "Fall", "in", "ih\u00b7rem", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Da sich ein Buhler angegeben", "tokens": ["Da", "sich", "ein", "Buh\u00b7ler", "an\u00b7ge\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Der sein Latein bei ihr verlor.", "tokens": ["Der", "sein", "La\u00b7tein", "bei", "ihr", "ver\u00b7lor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Nach Junons weisen Ehgesetzen", "tokens": ["Nach", "Ju\u00b7nons", "wei\u00b7sen", "Eh\u00b7ge\u00b7set\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Soll sich ein Mann f\u00fcr allzugl\u00fccklich sch\u00e4tzen,", "tokens": ["Soll", "sich", "ein", "Mann", "f\u00fcr", "all\u00b7zu\u00b7gl\u00fcck\u00b7lich", "sch\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "ART", "NN", "APPR", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wenn seine Frau aus eigner freier Wahl", "tokens": ["Wenn", "sei\u00b7ne", "Frau", "aus", "eig\u00b7ner", "frei\u00b7er", "Wahl"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Dem Recht entsagt, ihn in die edle Zahl", "tokens": ["Dem", "Recht", "ent\u00b7sagt", ",", "ihn", "in", "die", "ed\u00b7le", "Zahl"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "$,", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Der Br\u00fcder des Vulcans zu setzen.", "tokens": ["Der", "Br\u00fc\u00b7der", "des", "Vul\u00b7cans", "zu", "set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Sie tut durch dies allein der Tugend schon genug,", "tokens": ["Sie", "tut", "durch", "dies", "al\u00b7lein", "der", "Tu\u00b7gend", "schon", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PDS", "ADV", "ART", "NN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und fodert zum Ersatz mit Fug,", "tokens": ["Und", "fo\u00b7dert", "zum", "Er\u00b7satz", "mit", "Fug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "APPR", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.8": {"text": "(denn gratis wird sie nicht wie eine Nonne leben)", "tokens": ["(", "denn", "gra\u00b7tis", "wird", "sie", "nicht", "wie", "ei\u00b7ne", "Non\u00b7ne", "le\u00b7ben", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "NE", "VAFIN", "PPER", "PTKNEG", "KOKOM", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Da\u00df ihr Gemahl so dankbar sei", "tokens": ["Da\u00df", "ihr", "Ge\u00b7mahl", "so", "dank\u00b7bar", "sei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ADJD", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ihr alle Grillen zu vergeben;", "tokens": ["Ihr", "al\u00b7le", "Gril\u00b7len", "zu", "ver\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Und sie der ganzen Litanei", "tokens": ["Und", "sie", "der", "gan\u00b7zen", "Li\u00b7ta\u00b7nei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Der andern Pflichten zu entheben.", "tokens": ["Der", "an\u00b7dern", "Pflich\u00b7ten", "zu", "ent\u00b7he\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Daf\u00fcr erh\u00e4lt sie auch die Macht", "tokens": ["Da\u00b7f\u00fcr", "er\u00b7h\u00e4lt", "sie", "auch", "die", "Macht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Ihn als leibeigen zu behandeln,", "tokens": ["Ihn", "als", "leib\u00b7ei\u00b7gen", "zu", "be\u00b7han\u00b7deln", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KOKOM", "VVINF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Und richterlich in jeder Nacht", "tokens": ["Und", "rich\u00b7ter\u00b7lich", "in", "je\u00b7der", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Die Fehler, die er Tags gemacht und nicht gemacht,", "tokens": ["Die", "Feh\u00b7ler", ",", "die", "er", "Tags", "ge\u00b7macht", "und", "nicht", "ge\u00b7macht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVPP", "KON", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Durch strenge Bu\u00dfen abzuwandeln.", "tokens": ["Durch", "stren\u00b7ge", "Bu\u00b7\u00dfen", "ab\u00b7zu\u00b7wan\u00b7deln", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Das Mittel selbst, das in dergleichen Spann", "tokens": ["Das", "Mit\u00b7tel", "selbst", ",", "das", "in", "derg\u00b7lei\u00b7chen", "Spann"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "$,", "PRELS", "APPR", "PIS", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ovidius den M\u00e4nnern sehr empfiehlet,", "tokens": ["O\u00b7vi\u00b7dius", "den", "M\u00e4n\u00b7nern", "sehr", "emp\u00b7fieh\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Das sonst den Gift der Z\u00e4nkerinnen k\u00fchlet,", "tokens": ["Das", "sonst", "den", "Gift", "der", "Z\u00e4n\u00b7ke\u00b7rin\u00b7nen", "k\u00fch\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und L\u00f6winnen zu T\u00e4ubchen machen kann,", "tokens": ["Und", "L\u00f6\u00b7win\u00b7nen", "zu", "T\u00e4ub\u00b7chen", "ma\u00b7chen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NN", "VVINF", "VMFIN", "$,"], "meter": "-++--+-+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Wird oft vom Zeus, doch immer ohne Frucht", "tokens": ["Wird", "oft", "vom", "Zeus", ",", "doch", "im\u00b7mer", "oh\u00b7ne", "Frucht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "APPRART", "NE", "$,", "ADV", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und endlich gar nicht mehr versucht.", "tokens": ["Und", "end\u00b7lich", "gar", "nicht", "mehr", "ver\u00b7sucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "PTKNEG", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ob er dadurch die Sache nicht verschlimmert", "tokens": ["Ob", "er", "da\u00b7durch", "die", "Sa\u00b7che", "nicht", "ver\u00b7schlim\u00b7mert"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PAV", "ART", "NN", "PTKNEG", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Das lassen wir dahingestellt.", "tokens": ["Das", "las\u00b7sen", "wir", "da\u00b7hin\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Es ist, wie Sancho sagt, nicht alles Gold was schimmert.", "tokens": ["Es", "ist", ",", "wie", "San\u00b7cho", "sagt", ",", "nicht", "al\u00b7les", "Gold", "was", "schim\u00b7mert", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PWAV", "NE", "VVFIN", "$,", "PTKNEG", "PIAT", "NN", "PWS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Zwar tut sie, ob ihr in der Welt", "tokens": ["Zwar", "tut", "sie", ",", "ob", "ihr", "in", "der", "Welt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Nichts angenehmers sei als ungek\u00fc\u00dft zu bleiben;", "tokens": ["Nichts", "an\u00b7ge\u00b7neh\u00b7mers", "sei", "als", "un\u00b7ge\u00b7k\u00fc\u00dft", "zu", "blei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADJA", "VAFIN", "KOKOM", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Sie war nie keine G\u00f6nnerin", "tokens": ["Sie", "war", "nie", "kei\u00b7ne", "G\u00f6n\u00b7ne\u00b7rin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Von solchen eiteln Zeitvertreiben;", "tokens": ["Von", "sol\u00b7chen", "ei\u00b7teln", "Zeit\u00b7ver\u00b7trei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Doch bringt der Mann die Nacht nicht desto besser hin.", "tokens": ["Doch", "bringt", "der", "Mann", "die", "Nacht", "nicht", "des\u00b7to", "bes\u00b7ser", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ART", "NN", "PTKNEG", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Der gute Zeus, dem ihrer Zunge Lauf", "tokens": ["Der", "gu\u00b7te", "Zeus", ",", "dem", "ih\u00b7rer", "Zun\u00b7ge", "Lauf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NE", "$,", "PRELS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Beschwerlich war, stund oft vor Unmut auf,", "tokens": ["Be\u00b7schwer\u00b7lich", "war", ",", "stund", "oft", "vor", "Un\u00b7mut", "auf", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "$,", "VVFIN", "ADV", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und fing (was tut nicht ein geplagter Mann?)", "tokens": ["Und", "fing", "(", "was", "tut", "nicht", "ein", "ge\u00b7plag\u00b7ter", "Mann", "?", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "$(", "PWS", "VVFIN", "PTKNEG", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Vor Langerweil zu Donnern an.", "tokens": ["Vor", "Lan\u00b7ger\u00b7weil", "zu", "Don\u00b7nern", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Cedern auf dem Libanon,", "tokens": ["Die", "Ce\u00b7dern", "auf", "dem", "Li\u00b7ba\u00b7non", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Alpen wei\u00dfes Haupt, der steile Helikon", "tokens": ["Der", "Al\u00b7pen", "wei\u00b7\u00dfes", "Haupt", ",", "der", "stei\u00b7le", "He\u00b7li\u00b7kon"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Empfanden schuldlos seine St\u00f6\u00dfe:", "tokens": ["Emp\u00b7fan\u00b7den", "schuld\u00b7los", "sei\u00b7ne", "St\u00f6\u00b7\u00dfe", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Es zitterten die armen Erdenkl\u00f6\u00dfe;", "tokens": ["Es", "zit\u00b7ter\u00b7ten", "die", "ar\u00b7men", "Er\u00b7den\u00b7kl\u00f6\u00b7\u00dfe", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Doch schlug er nur in Felsen, Meer und Wald", "tokens": ["Doch", "schlug", "er", "nur", "in", "Fel\u00b7sen", ",", "Meer", "und", "Wald"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und alle Streiche waren kalt.", "tokens": ["Und", "al\u00b7le", "Strei\u00b7che", "wa\u00b7ren", "kalt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Einst als sie ihn in einer Sommernacht", "tokens": ["Einst", "als", "sie", "ihn", "in", "ei\u00b7ner", "Som\u00b7mer\u00b7nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mehr als gew\u00f6hnlich aufgebracht,", "tokens": ["Mehr", "als", "ge\u00b7w\u00f6hn\u00b7lich", "auf\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wird vom Get\u00f6s, so dieses Eh-Paar macht,", "tokens": ["Wird", "vom", "Ge\u00b7t\u00f6s", ",", "so", "die\u00b7ses", "Eh\u00b7Paar", "macht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "$,", "ADV", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Aus ihrem Schlummer aufgeschreckt,", "tokens": ["Aus", "ih\u00b7rem", "Schlum\u00b7mer", "auf\u00b7ge\u00b7schreckt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die sch\u00f6ne Jo von ihm entdeckt.", "tokens": ["Die", "sch\u00f6\u00b7ne", "Jo", "von", "ihm", "ent\u00b7deckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Sie lag vom Mondschein angestrahlt,", "tokens": ["Sie", "lag", "vom", "Mond\u00b7schein", "an\u00b7ge\u00b7strahlt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach Nymphen-Art nur leicht bedeckt,", "tokens": ["Nach", "Nym\u00b7phen\u00b7Art", "nur", "leicht", "be\u00b7deckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "An ihrem Wasser-Krug auf Blumen hingestreckt.", "tokens": ["An", "ih\u00b7rem", "Was\u00b7ser\u00b7Krug", "auf", "Blu\u00b7men", "hin\u00b7ge\u00b7streckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Reiz, den nur ein Guido f\u00fchlt und malt,", "tokens": ["Der", "Reiz", ",", "den", "nur", "ein", "Gui\u00b7do", "f\u00fchlt", "und", "malt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ART", "NE", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Die erste Jugend scheint auf ihren frischen Wangen", "tokens": ["Die", "ers\u00b7te", "Ju\u00b7gend", "scheint", "auf", "ih\u00b7ren", "fri\u00b7schen", "Wan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Halboffnen Rosen gleich nur eben aufgegangen,", "tokens": ["Hal\u00b7boff\u00b7nen", "Ro\u00b7sen", "gleich", "nur", "e\u00b7ben", "auf\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und ihre Brust und ihren sch\u00f6nen Leib", "tokens": ["Und", "ih\u00b7re", "Brust", "und", "ih\u00b7ren", "sch\u00f6\u00b7nen", "Leib"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Schwellt Fr\u00fchlings-Lust und ahnendes Verlangen.", "tokens": ["Schwellt", "Fr\u00fch\u00b7lings\u00b7Lust", "und", "ah\u00b7nen\u00b7des", "Ver\u00b7lan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Ein Sanct Hilarion, f\u00fcr den das sch\u00f6nste Weib", "tokens": ["Ein", "Sanct", "Hi\u00b7la\u00b7ri\u00b7on", ",", "f\u00fcr", "den", "das", "sch\u00f6ns\u00b7te", "Weib"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "$,", "APPR", "ART", "ART", "ADJA", "NN"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Memento mori war, w\u00e4r euch vorbeigegangen,", "tokens": ["Me\u00b7men\u00b7to", "mo\u00b7ri", "war", ",", "w\u00e4r", "euch", "vor\u00b7bei\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "$,", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und h\u00e4tte nichts gef\u00fchlt; selbst vom Xenokrates", "tokens": ["Und", "h\u00e4t\u00b7te", "nichts", "ge\u00b7f\u00fchlt", ";", "selbst", "vom", "Xe\u00b7no\u00b7kra\u00b7tes"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VAFIN", "PIS", "VVPP", "$.", "ADV", "APPRART", "NN"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "H\u00e4tt eine Jo sich keinen Blick erworben;", "tokens": ["H\u00e4tt", "ei\u00b7ne", "Jo", "sich", "kei\u00b7nen", "Blick", "er\u00b7wor\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NE", "PRF", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die lange Nacht bezeuget es,", "tokens": ["Die", "lan\u00b7ge", "Nacht", "be\u00b7zeu\u00b7get", "es", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Phryne neben ihm verdorben;", "tokens": ["Die", "Phry\u00b7ne", "ne\u00b7ben", "ihm", "ver\u00b7dor\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Doch solche Weisheit schenkt die sparsame Natur", "tokens": ["Doch", "sol\u00b7che", "Weis\u00b7heit", "schenkt", "die", "spar\u00b7sa\u00b7me", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Gemeiniglich dem grauen Alter nur.", "tokens": ["Ge\u00b7mei\u00b7nig\u00b7lich", "dem", "grau\u00b7en", "Al\u00b7ter", "nur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Ein Ajax sucht den Feind, vor dem ein Nestor zittert,", "tokens": ["Ein", "A\u00b7jax", "sucht", "den", "Feind", ",", "vor", "dem", "ein", "Nes\u00b7tor", "zit\u00b7tert", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ART", "NN", "$,", "APPR", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und, mit Ambrosia und Nektar satt gef\u00fcttert,", "tokens": ["Und", ",", "mit", "A\u00b7mbro\u00b7sia", "und", "Nek\u00b7tar", "satt", "ge\u00b7f\u00fct\u00b7tert", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "NE", "KON", "NN", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.11": {"text": "Wird Jupiter sobald er Nymphen wittert", "tokens": ["Wird", "Ju\u00b7pi\u00b7ter", "so\u00b7bald", "er", "Nym\u00b7phen", "wit\u00b7tert"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "KOUS", "PPER", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Vom Wirbel bis zum Zehn ersch\u00fcttert;", "tokens": ["Vom", "Wir\u00b7bel", "bis", "zum", "Zehn", "er\u00b7sch\u00fct\u00b7tert", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Die Hunger-Kur, die einen Ephraim", "tokens": ["Die", "Hun\u00b7ger\u00b7Kur", ",", "die", "ei\u00b7nen", "Eph\u00b7raim"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NE"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.14": {"text": "Zum Engel macht, macht Joven zum Satyren.", "tokens": ["Zum", "En\u00b7gel", "macht", ",", "macht", "Jo\u00b7ven", "zum", "Sa\u00b7ty\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,", "VVFIN", "NE", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Die Nymphe sehn, begehren und entf\u00fchren,", "tokens": ["Die", "Nym\u00b7phe", "sehn", ",", "be\u00b7geh\u00b7ren", "und", "ent\u00b7f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "War, wie beim C\u00e4sar, eins bei ihm.", "tokens": ["War", ",", "wie", "beim", "C\u00e4\u00b7sar", ",", "eins", "bei", "ihm", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWAV", "APPRART", "NE", "$,", "PIS", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Die Eifersucht der Juno zu betr\u00fcgen", "tokens": ["Die", "Ei\u00b7fer\u00b7sucht", "der", "Ju\u00b7no", "zu", "be\u00b7tr\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Verbirgt ein Schirm von siebenfacher Nacht", "tokens": ["Ver\u00b7birgt", "ein", "Schirm", "von", "sie\u00b7ben\u00b7fa\u00b7cher", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Dem sch\u00e4rfsten Blick sein str\u00e4fliches Vergn\u00fcgen.", "tokens": ["Dem", "sch\u00e4rfs\u00b7ten", "Blick", "sein", "str\u00e4f\u00b7li\u00b7ches", "Ver\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Von diesem Anfang k\u00fchn gemacht,", "tokens": ["Von", "die\u00b7sem", "An\u00b7fang", "k\u00fchn", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "L\u00e4\u00dft Vater Zeus es nicht dabei verbleiben;", "tokens": ["L\u00e4\u00dft", "Va\u00b7ter", "Zeus", "es", "nicht", "da\u00b7bei", "ver\u00b7blei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "NE", "PPER", "PTKNEG", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Das Mittel scheint ihm gut und leicht,", "tokens": ["Das", "Mit\u00b7tel", "scheint", "ihm", "gut", "und", "leicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Milzbeschwerung zu vertreiben,", "tokens": ["Die", "Milz\u00b7be\u00b7schwe\u00b7rung", "zu", "ver\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die oft die G\u00f6tter von ihm scheucht.", "tokens": ["Die", "oft", "die", "G\u00f6t\u00b7ter", "von", "ihm", "scheucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das \u00dcbel k\u00f6nnte um sich greifen", "tokens": ["Das", "\u00dc\u00b7bel", "k\u00f6nn\u00b7te", "um", "sich", "grei\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "APPR", "PRF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und b\u00f6se Folgen nach sich ziehn;", "tokens": ["Und", "b\u00f6\u00b7se", "Fol\u00b7gen", "nach", "sich", "ziehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "In solchen F\u00e4llen r\u00e4t selbst Scheik Al-Hosain,", "tokens": ["In", "sol\u00b7chen", "F\u00e4l\u00b7len", "r\u00e4t", "selbst", "Scheik", "Al\u00b7Ho\u00b7sa\u00b7in", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "ADV", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Des Sina Sohn, zuweilen auszuschweifen;", "tokens": ["Des", "Si\u00b7na", "Sohn", ",", "zu\u00b7wei\u00b7len", "aus\u00b7zu\u00b7schwei\u00b7fen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NE", "NN", "$,", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Doch stets mit Ma\u00df. Zeus folget gutem Rat.", "tokens": ["Doch", "stets", "mit", "Ma\u00df", ".", "Zeus", "fol\u00b7get", "gu\u00b7tem", "Rat", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "$.", "NE", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Sobald der Schlaf sein Weib bes\u00e4nftigt hat,", "tokens": ["So\u00b7bald", "der", "Schlaf", "sein", "Weib", "be\u00b7s\u00e4nf\u00b7tigt", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPOSAT", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "(denn immer kann sie doch nicht keifen)", "tokens": ["(", "denn", "im\u00b7mer", "kann", "sie", "doch", "nicht", "kei\u00b7fen", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ADV", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "So schleicht er sich, begleitet vom Mercur,", "tokens": ["So", "schleicht", "er", "sich", ",", "be\u00b7glei\u00b7tet", "vom", "Mer\u00b7cur", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$,", "VVPP", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Zur Unterwelt, durch Hain und Flur", "tokens": ["Zur", "Un\u00b7ter\u00b7welt", ",", "durch", "Hain", "und", "Flur"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Den sch\u00f6nsten Nymphen nachzustreifen.", "tokens": ["Den", "sch\u00f6ns\u00b7ten", "Nym\u00b7phen", "nach\u00b7zu\u00b7strei\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Er sch\u00e4mt sich nicht, zu bessrer Sicherheit", "tokens": ["Er", "sch\u00e4mt", "sich", "nicht", ",", "zu", "bess\u00b7rer", "Si\u00b7cher\u00b7heit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "PTKNEG", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Der G\u00f6tterschaft sich zu entladen.", "tokens": ["Der", "G\u00f6t\u00b7ter\u00b7schaft", "sich", "zu", "ent\u00b7la\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Man hat in einen Schwan verkleidt,", "tokens": ["Man", "hat", "in", "ei\u00b7nen", "Schwan", "ver\u00b7kleidt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Bei jungen M\u00e4dchen, die sich baden,", "tokens": ["Bei", "jun\u00b7gen", "M\u00e4d\u00b7chen", ",", "die", "sich", "ba\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "PRELS", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Sehr viel voraus; man gaffet ungescheut;", "tokens": ["Sehr", "viel", "vo\u00b7raus", ";", "man", "gaf\u00b7fet", "un\u00b7ge\u00b7scheut", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKVZ", "$.", "PIS", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Welch ein Triumph f\u00fcr ihre Eitelkeit", "tokens": ["Welch", "ein", "Tri\u00b7umph", "f\u00fcr", "ih\u00b7re", "Ei\u00b7tel\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "In Tieren selbst verliebte L\u00fcsternheit", "tokens": ["In", "Tie\u00b7ren", "selbst", "ver\u00b7lieb\u00b7te", "L\u00fcs\u00b7tern\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADV", "VVFIN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Und k\u00fchne Sehnsucht zu erwecken?", "tokens": ["Und", "k\u00fch\u00b7ne", "Sehn\u00b7sucht", "zu", "er\u00b7we\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Man darf sich nahn, sie mit dem Schnabel necken,", "tokens": ["Man", "darf", "sich", "nahn", ",", "sie", "mit", "dem", "Schna\u00b7bel", "ne\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PRF", "ADJA", "$,", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Man darf noch mehr, sie werden nicht erschrecken;", "tokens": ["Man", "darf", "noch", "mehr", ",", "sie", "wer\u00b7den", "nicht", "er\u00b7schre\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "ADV", "$,", "PPER", "VAFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Es hei\u00dft ein Spiel \u2013 das arme, kleine Tier!", "tokens": ["Es", "hei\u00dft", "ein", "Spiel", "\u2013", "das", "ar\u00b7me", ",", "klei\u00b7ne", "Tier", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$(", "ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "Wie zahm es tut! Gewi\u00df, man d\u00e4chte schier", "tokens": ["Wie", "zahm", "es", "tut", "!", "Ge\u00b7wi\u00df", ",", "man", "d\u00e4ch\u00b7te", "schier"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PPER", "VVFIN", "$.", "PTKANT", "$,", "PIS", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Da\u00df es den Wert von seinem Gl\u00fccke f\u00fchlte.", "tokens": ["Da\u00df", "es", "den", "Wert", "von", "sei\u00b7nem", "Gl\u00fc\u00b7cke", "f\u00fchl\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Wie oft Herr Zeus als Adler oder Stier", "tokens": ["Wie", "oft", "Herr", "Zeus", "als", "Ad\u00b7ler", "o\u00b7der", "Stier"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "NN", "NE", "KOUS", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sein Lieblings-Spiel mit Menschen-Kindern spielte,", "tokens": ["Sein", "Lieb\u00b7lings\u00b7Spiel", "mit", "Men\u00b7schen\u00b7Kin\u00b7dern", "spiel\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Erz\u00e4hlt Ovid, und ihm Sedletzky nach.", "tokens": ["Er\u00b7z\u00e4hlt", "O\u00b7vid", ",", "und", "ihm", "Sed\u00b7letz\u00b7ky", "nach", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$,", "KON", "PPER", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Allein der Krug ging, wie man pflegt zu sagen,", "tokens": ["Al\u00b7lein", "der", "Krug", "ging", ",", "wie", "man", "pflegt", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$,", "PWAV", "PIS", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "So lang zum Wasser bis er brach.", "tokens": ["So", "lang", "zum", "Was\u00b7ser", "bis", "er", "brach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPRART", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein oftgelungnes Gl\u00fcck reizt oft zuviel zu wagen;", "tokens": ["Ein", "oft\u00b7ge\u00b7lung\u00b7nes", "Gl\u00fcck", "reizt", "oft", "zu\u00b7viel", "zu", "wa\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und kurz, als ihm in einer Sommer-Nacht", "tokens": ["Und", "kurz", ",", "als", "ihm", "in", "ei\u00b7ner", "Som\u00b7mer\u00b7Nacht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "$,", "KOUS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Latona einst die Zeit zu kurz gemacht,", "tokens": ["La\u00b7to\u00b7na", "einst", "die", "Zeit", "zu", "kurz", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "NN", "PTKA", "ADJD", "VVPP", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.9": {"text": "Lie\u00df er, f\u00fcr einen Freund vom Naschen", "tokens": ["Lie\u00df", "er", ",", "f\u00fcr", "ei\u00b7nen", "Freund", "vom", "Na\u00b7schen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "APPR", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Sich, wie die Chronik sagt, recht sch\u00fclerhaft erhaschen.", "tokens": ["Sich", ",", "wie", "die", "Chro\u00b7nik", "sagt", ",", "recht", "sch\u00fc\u00b7ler\u00b7haft", "er\u00b7ha\u00b7schen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "$,", "PWAV", "ART", "NN", "VVFIN", "$,", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wir geben zu, den Stand der wohl behagt", "tokens": ["Wir", "ge\u00b7ben", "zu", ",", "den", "Stand", "der", "wohl", "be\u00b7hagt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "ART", "NN", "ART", "ADV", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Pflegt niemand gerne zu verlassen;", "tokens": ["Pflegt", "nie\u00b7mand", "ger\u00b7ne", "zu", "ver\u00b7las\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Allein nicht merken wenn es tagt", "tokens": ["Al\u00b7lein", "nicht", "mer\u00b7ken", "wenn", "es", "tagt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PTKNEG", "VVINF", "KOUS", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Hei\u00dft vom Affekt sich \u00fcbernehmen lassen.", "tokens": ["Hei\u00dft", "vom", "Af\u00b7fekt", "sich", "\u00fc\u00b7ber\u00b7neh\u00b7men", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "PRF", "VVINF", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.15": {"text": "Ein Weiser soll, wie Flaccus weislich sagt,", "tokens": ["Ein", "Wei\u00b7ser", "soll", ",", "wie", "Flac\u00b7cus", "weis\u00b7lich", "sagt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "$,", "PWAV", "NE", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Die Abzugs-Stunde nie verpassen.", "tokens": ["Die", "Ab\u00b7zugs\u00b7Stun\u00b7de", "nie", "ver\u00b7pas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Was Juno ihm f\u00fcr ein Gesicht verlieh,", "tokens": ["Was", "Ju\u00b7no", "ihm", "f\u00fcr", "ein", "Ge\u00b7sicht", "ver\u00b7lieh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Begreift durch die Analogie,", "tokens": ["Be\u00b7greift", "durch", "die", "A\u00b7nal\u00b7o\u00b7gie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Zimmermann uns preist, ein jeder ohne M\u00fch", "tokens": ["Die", "Zim\u00b7mer\u00b7mann", "uns", "preist", ",", "ein", "je\u00b7der", "oh\u00b7ne", "M\u00fch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPER", "VVFIN", "$,", "ART", "PIS", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der einst sich langsam finden lassen.", "tokens": ["Der", "einst", "sich", "lang\u00b7sam", "fin\u00b7den", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PRF", "ADJD", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Kein Drohn, kein Flehn erweichet sie,", "tokens": ["Kein", "Drohn", ",", "kein", "Flehn", "er\u00b7wei\u00b7chet", "sie", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Umsonst umfa\u00dft er ihre Knie,", "tokens": ["Um\u00b7sonst", "um\u00b7fa\u00dft", "er", "ih\u00b7re", "Knie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sie schw\u00f6rt, die Tat der Strenge nach zu r\u00e4chen;", "tokens": ["Sie", "schw\u00f6rt", ",", "die", "Tat", "der", "Stren\u00b7ge", "nach", "zu", "r\u00e4\u00b7chen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "ART", "NN", "APPR", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und da\u00df sie ja den Schlu\u00df nicht \u00e4ndern kann,", "tokens": ["Und", "da\u00df", "sie", "ja", "den", "Schlu\u00df", "nicht", "\u00e4n\u00b7dern", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ART", "NN", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Schw\u00f6rt sie den Schwur, den G\u00f6tter niemals brechen.", "tokens": ["Schw\u00f6rt", "sie", "den", "Schwur", ",", "den", "G\u00f6t\u00b7ter", "nie\u00b7mals", "bre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "VVFIN", "$,", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Sein Leben hebt mit jedem Sonnenlicht", "tokens": ["Sein", "Le\u00b7ben", "hebt", "mit", "je\u00b7dem", "Son\u00b7nen\u00b7licht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Sich richtig an, und endet Abends nicht", "tokens": ["Sich", "rich\u00b7tig", "an", ",", "und", "en\u00b7det", "A\u00b7bends", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PRF", "ADJD", "PTKVZ", "$,", "KON", "VVFIN", "ADV", "PTKNEG"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Ihm gellen Tag und Nacht die Ohren;", "tokens": ["Ihm", "gel\u00b7len", "Tag", "und", "Nacht", "die", "Oh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "KON", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Sie nimmt ihn selbst bei Tisch, wo er", "tokens": ["Sie", "nimmt", "ihn", "selbst", "bei", "Tisch", ",", "wo", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "NN", "$,", "PWAV", "PPER"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.14": {"text": "Sein Ansehn spielen mu\u00df, oft unbarmherzig her;", "tokens": ["Sein", "An\u00b7sehn", "spie\u00b7len", "mu\u00df", ",", "oft", "un\u00b7barm\u00b7her\u00b7zig", "her", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "VMFIN", "$,", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Je mehr sie Zeugen hat, je mehr wird Zeus geschoren.", "tokens": ["Je", "mehr", "sie", "Zeu\u00b7gen", "hat", ",", "je", "mehr", "wird", "Zeus", "ge\u00b7scho\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "NN", "VAFIN", "$,", "ADV", "ADV", "VAFIN", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Mich wundert es wahrhaftig nicht,", "tokens": ["Mich", "wun\u00b7dert", "es", "wahr\u00b7haf\u00b7tig", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "PTKNEG", "$,"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Da\u00df er die Essenslust verloren.", "tokens": ["Da\u00df", "er", "die", "Es\u00b7sens\u00b7lust", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.18": {"text": "Der Gram verg\u00e4llt das niedlichste Gericht,", "tokens": ["Der", "Gram", "ver\u00b7g\u00e4llt", "das", "nied\u00b7lichs\u00b7te", "Ge\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Und zum Verdru\u00df sind G\u00f6tter nicht geboren.", "tokens": ["Und", "zum", "Ver\u00b7dru\u00df", "sind", "G\u00f6t\u00b7ter", "nicht", "ge\u00b7bo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VAFIN", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Auch ist er klug, und bleibt vom Nektarschmaus", "tokens": ["Auch", "ist", "er", "klug", ",", "und", "bleibt", "vom", "Nek\u00b7tarsc\u00b7hmaus"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,", "KON", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Von Zeit zu Zeit oft ganze Wochen aus,", "tokens": ["Von", "Zeit", "zu", "Zeit", "oft", "gan\u00b7ze", "Wo\u00b7chen", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "ADV", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Schw\u00e4rmt mit dem Gott, der Fl\u00fcgel an den Ohren", "tokens": ["Schw\u00e4rmt", "mit", "dem", "Gott", ",", "der", "Fl\u00fc\u00b7gel", "an", "den", "Oh\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Und an den Fersen tr\u00e4gt, von H\u00fctte zu Palast,", "tokens": ["Und", "an", "den", "Fer\u00b7sen", "tr\u00e4gt", ",", "von", "H\u00fct\u00b7te", "zu", "Pa\u00b7last", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$,", "APPR", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Und bittet bald bei Baucis sich zu Gast,", "tokens": ["Und", "bit\u00b7tet", "bald", "bei", "Bau\u00b7cis", "sich", "zu", "Gast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NE", "PRF", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Bald bei den tadellosen Mohren.", "tokens": ["Bald", "bei", "den", "ta\u00b7del\u00b7lo\u00b7sen", "Moh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Einst da er wohlbezecht (der Mohren Wein war's wert)", "tokens": ["Einst", "da", "er", "wohl\u00b7be\u00b7zecht", "(", "der", "Moh\u00b7ren", "Wein", "wa\u00b7r's", "wert", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "$(", "ART", "NN", "NN", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.27": {"text": "Von einem solchen Schmause kehrt,", "tokens": ["Von", "ei\u00b7nem", "sol\u00b7chen", "Schmau\u00b7se", "kehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Sieht er bei Schwanen-wei\u00dfen Schafen", "tokens": ["Sieht", "er", "bei", "Schwa\u00b7nen\u00b7wei\u00b7\u00dfen", "Scha\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Den jungen Ganymed an einer Quelle schlafen.", "tokens": ["Den", "jun\u00b7gen", "Ga\u00b7ny\u00b7med", "an", "ei\u00b7ner", "Quel\u00b7le", "schla\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Er bleibt auf einer Wolke stehn,", "tokens": ["Er", "bleibt", "auf", "ei\u00b7ner", "Wol\u00b7ke", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Und denkt, vom ersten Blick verwirrt:", "tokens": ["Und", "denkt", ",", "vom", "ers\u00b7ten", "Blick", "ver\u00b7wirrt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "APPRART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Hat Amor sich auf Idas H\u00f6hn", "tokens": ["Hat", "A\u00b7mor", "sich", "auf", "I\u00b7das", "H\u00f6hn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NE", "PRF", "APPR", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Von seinen Grazien verirrt?", "tokens": ["Von", "sei\u00b7nen", "Gra\u00b7zi\u00b7en", "ver\u00b7irrt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Er winkt Mercuren her, der schon vorausgeflogen,", "tokens": ["Er", "winkt", "Mer\u00b7cu\u00b7ren", "her", ",", "der", "schon", "vor\u00b7aus\u00b7ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PTKVZ", "$,", "PRELS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Und zeigt ihm den entdeckten Fund.", "tokens": ["Und", "zeigt", "ihm", "den", "ent\u00b7deck\u00b7ten", "Fund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "\u00bbwenn sieht die Liebe doch gesund?", "tokens": ["\u00bb", "wenn", "sieht", "die", "Lie\u00b7be", "doch", "ge\u00b7sund", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "VVFIN", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.37": {"text": "(ruft sein Gespan) wo sind denn Pfeil und Bogen", "tokens": ["(", "ruft", "sein", "Ge\u00b7span", ")", "wo", "sind", "denn", "Pfeil", "und", "Bo\u00b7gen"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "PPOSAT", "NN", "$(", "PWAV", "VAFIN", "ADV", "NN", "KON", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.38": {"text": "Wenn's Amor ist, und wo sein Fl\u00fcgel-Paar?\u00ab", "tokens": ["Wenn's", "A\u00b7mor", "ist", ",", "und", "wo", "sein", "Fl\u00fc\u00b7gel\u00b7Paar", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "NE", "VAFIN", "$,", "KON", "PWAV", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.39": {"text": "\u00bbgesteh\u00ab, spricht Zeus, \u00bbsein lockicht gelbes Haar,", "tokens": ["\u00bb", "ge\u00b7steh", "\u00ab", ",", "spricht", "Zeus", ",", "\u00bb", "sein", "lo\u00b7ckicht", "gel\u00b7bes", "Haar", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "$(", "$,", "VVFIN", "NE", "$,", "$(", "VAINF", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.40": {"text": "Sein rund Gesicht und Stirn und Mund, f\u00fcrwahr!", "tokens": ["Sein", "rund", "Ge\u00b7sicht", "und", "Stirn", "und", "Mund", ",", "f\u00fcr\u00b7wahr", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "KON", "NN", "KON", "NN", "$,", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.41": {"text": "H\u00e4tt Erycinen selbst betrogen;", "tokens": ["H\u00e4tt", "E\u00b7ry\u00b7ci\u00b7nen", "selbst", "be\u00b7tro\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.42": {"text": "Sie h\u00e4tt ihn wenigstens dem J\u00e4ger vorgezogen,", "tokens": ["Sie", "h\u00e4tt", "ihn", "we\u00b7nigs\u00b7tens", "dem", "J\u00e4\u00b7ger", "vor\u00b7ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Von dem sie einst so stark bezaubert war.\u00ab", "tokens": ["Von", "dem", "sie", "einst", "so", "stark", "be\u00b7zau\u00b7bert", "war", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "ADV", "ADJD", "VVPP", "VAFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.44": {"text": "\u00bbdas eben nicht\u00ab, versetzt, der Maja Sohn,", "tokens": ["\u00bb", "das", "e\u00b7ben", "nicht", "\u00ab", ",", "ver\u00b7setzt", ",", "der", "Ma\u00b7ja", "Sohn", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "ADV", "PTKNEG", "$(", "$,", "VVPP", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.45": {"text": "\u00bbein kluges Weib wei\u00df besser Haus zu halten;", "tokens": ["\u00bb", "ein", "klu\u00b7ges", "Weib", "wei\u00df", "bes\u00b7ser", "Haus", "zu", "hal\u00b7ten", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "VVFIN", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.46": {"text": "Wir kennen ja die Frau Vulcanin schon;", "tokens": ["Wir", "ken\u00b7nen", "ja", "die", "Frau", "Vul\u00b7ca\u00b7nin", "schon", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "NE", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.47": {"text": "Sie h\u00e4tte den gew\u00e4hlt und jenen beibehalten.\u00ab", "tokens": ["Sie", "h\u00e4t\u00b7te", "den", "ge\u00b7w\u00e4hlt", "und", "je\u00b7nen", "bei\u00b7be\u00b7hal\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ART", "VVPP", "KON", "PDS", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Indem er's sagt, h\u00e4lt Zeus noch unverwandt,", "tokens": ["In\u00b7dem", "er's", "sagt", ",", "h\u00e4lt", "Zeus", "noch", "un\u00b7ver\u00b7wandt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "$,", "VVFIN", "NE", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.49": {"text": "Auf Ganymed den scharfen Blick gespannt.", "tokens": ["Auf", "Ga\u00b7ny\u00b7med", "den", "schar\u00b7fen", "Blick", "ge\u00b7spannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.50": {"text": "Allein ein Pfau an Junons Muschel-Wagen,", "tokens": ["Al\u00b7lein", "ein", "Pfau", "an", "Ju\u00b7nons", "Mu\u00b7schel\u00b7Wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.51": {"text": "Die eben itzt spazieren fuhr,", "tokens": ["Die", "e\u00b7ben", "itzt", "spa\u00b7zie\u00b7ren", "fuhr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.52": {"text": "Entdeckt dem lauschenden Mercur", "tokens": ["Ent\u00b7deckt", "dem", "lau\u00b7schen\u00b7den", "Mer\u00b7cur"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.53": {"text": "Durch sein' Gesang, zu gro\u00dfem Mi\u00dfbehagen", "tokens": ["Durch", "sein'", "Ge\u00b7sang", ",", "zu", "gro\u00b7\u00dfem", "Mi\u00df\u00b7be\u00b7ha\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "APPR", "ADJA", "NN"], "meter": "++-+-+-+-+-", "measure": "iambic.penta.spondeus"}, "line.54": {"text": "Des Donnerers, da\u00df hier das beste sei", "tokens": ["Des", "Don\u00b7ne\u00b7rers", ",", "da\u00df", "hier", "das", "bes\u00b7te", "sei"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KOUS", "ADV", "ART", "ADJA", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.55": {"text": "Sich sachte linker Hand zu schlagen.", "tokens": ["Sich", "sach\u00b7te", "lin\u00b7ker", "Hand", "zu", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.56": {"text": "Sie schleichen unerkannt vorbei", "tokens": ["Sie", "schlei\u00b7chen", "un\u00b7er\u00b7kannt", "vor\u00b7bei"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.57": {"text": "Und steigen zum Olymp; man l\u00e4\u00dft die Ankunft wissen;", "tokens": ["Und", "stei\u00b7gen", "zum", "O\u00b7lymp", ";", "man", "l\u00e4\u00dft", "die", "An\u00b7kunft", "wis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "$.", "PIS", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Die Schar der G\u00f6tter eilt herbei,", "tokens": ["Die", "Schar", "der", "G\u00f6t\u00b7ter", "eilt", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.59": {"text": "Dem Prinzipal die Hand zu k\u00fcssen.", "tokens": ["Dem", "Prin\u00b7zi\u00b7pal", "die", "Hand", "zu", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.60": {"text": "Man schwatzt, er fragt nach vielerlei,", "tokens": ["Man", "schwatzt", ",", "er", "fragt", "nach", "vie\u00b7ler\u00b7lei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PPER", "VVFIN", "APPR", "PIAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.61": {"text": "Und h\u00f6rt mit andern neuen Sachen", "tokens": ["Und", "h\u00f6rt", "mit", "an\u00b7dern", "neu\u00b7en", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.62": {"text": "Was Heben erst begegnet sei.", "tokens": ["Was", "He\u00b7ben", "erst", "be\u00b7geg\u00b7net", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.63": {"text": "Silen, der Wanst, erz\u00e4hlt's, mit vielem Lachen,", "tokens": ["Si\u00b7len", ",", "der", "Wanst", ",", "er\u00b7z\u00e4hlt's", ",", "mit", "vie\u00b7lem", "La\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "$,", "VVFIN", "$,", "APPR", "PIS", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.64": {"text": "Nach seiner Art nicht allzufein,", "tokens": ["Nach", "sei\u00b7ner", "Art", "nicht", "all\u00b7zu\u00b7fein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.65": {"text": "Und streut, den Spa\u00df kurzweiliger zu machen,", "tokens": ["Und", "streut", ",", "den", "Spa\u00df", "kurz\u00b7wei\u00b7li\u00b7ger", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.66": {"text": "Viel Doppelsinn und k\u00fchlen Witz hinein.", "tokens": ["Viel", "Dop\u00b7pel\u00b7sinn", "und", "k\u00fch\u00b7len", "Witz", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "\u00bbja, (fangt er an, und alle G\u00f6tter lachen,", "tokens": ["\u00bb", "ja", ",", "(", "fangt", "er", "an", ",", "und", "al\u00b7le", "G\u00f6t\u00b7ter", "la\u00b7chen", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "$(", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Er selbst zuerst) beim Styx! es war ein Spa\u00df!", "tokens": ["Er", "selbst", "zu\u00b7erst", ")", "beim", "Styx", "!", "es", "war", "ein", "Spa\u00df", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "$(", "APPRART", "NN", "$.", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein Haupt-Spa\u00df war's; ihr h\u00e4ttet's sehen sollen \u2013", "tokens": ["Ein", "Haup\u00b7tSpa\u00df", "wa\u00b7r's", ";", "ihr", "h\u00e4t\u00b7tet's", "se\u00b7hen", "sol\u00b7len", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$.", "PPER", "VAFIN", "VVINF", "VMFIN", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Wie Hebe fiel \u2013 ha, ha! mein bestes Fa\u00df,", "tokens": ["Wie", "He\u00b7be", "fiel", "\u2013", "ha", ",", "ha", "!", "mein", "bes\u00b7tes", "Fa\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "VVFIN", "$(", "ITJ", "$,", "ITJ", "$.", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Bei meinem Horn! h\u00e4tt ich drum geben wollen.", "tokens": ["Bei", "mei\u00b7nem", "Horn", "!", "h\u00e4tt", "ich", "drum", "ge\u00b7ben", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "VAFIN", "PPER", "PAV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So sa\u00dfen wir, hier Juno, hier Dian,", "tokens": ["So", "sa\u00b7\u00dfen", "wir", ",", "hier", "Ju\u00b7no", ",", "hier", "Di\u00b7an", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADV", "NN", "$,", "ADV", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Hier Bacchus, hier \u2013 was wei\u00df ich's, doch daran,", "tokens": ["Hier", "Bac\u00b7chus", ",", "hier", "\u2013", "was", "wei\u00df", "ich's", ",", "doch", "da\u00b7ran", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NE", "$,", "ADV", "$(", "PWS", "VVFIN", "PIS", "$,", "ADV", "PAV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Liegt itzo nichts \u2013 wir trinken wie die Scythen", "tokens": ["Liegt", "it\u00b7zo", "nichts", "\u2013", "wir", "trin\u00b7ken", "wie", "die", "Scyt\u00b7hen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PIS", "$(", "PPER", "VVFIN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Und jauchzen laut \u2013 Nun h\u00f6rt einmal den Spa\u00df!", "tokens": ["Und", "jauch\u00b7zen", "laut", "\u2013", "Nun", "h\u00f6rt", "ein\u00b7mal", "den", "Spa\u00df", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$(", "ADV", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Indem wir schon von altem Nektar gl\u00fchten,", "tokens": ["In\u00b7dem", "wir", "schon", "von", "al\u00b7tem", "Nek\u00b7tar", "gl\u00fch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Ruft Bromius, \u203adas gro\u00dfe Deckel-Glas;", "tokens": ["Ruft", "Bro\u00b7mi\u00b7us", ",", "\u203a", "das", "gro\u00b7\u00dfe", "De\u00b7ckel\u00b7Glas", ";"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$,", "$(", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "He! M\u00e4dchen, flink! mit diesen Fingerh\u00fcten", "tokens": ["He", "!", "M\u00e4d\u00b7chen", ",", "flink", "!", "mit", "die\u00b7sen", "Fin\u00b7ger\u00b7h\u00fc\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "$.", "NN", "$,", "VVFIN", "$.", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Macht man ja kaum die Lippen na\u00df;", "tokens": ["Macht", "man", "ja", "kaum", "die", "Lip\u00b7pen", "na\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "ADV", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Der Tag ist sch\u00f6n, wir wollen heut eins w\u00fcten.\u2039", "tokens": ["Der", "Tag", "ist", "sch\u00f6n", ",", "wir", "wol\u00b7len", "heut", "eins", "w\u00fc\u00b7ten", ".", "\u2039"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "PPER", "VMFIN", "ADV", "PIS", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "\u203atop!\u2039 rufen wir, es kommt, man f\u00fcllt es oben an,", "tokens": ["\u203a", "top", "!", "\u2039", "ru\u00b7fen", "wir", ",", "es", "kommt", ",", "man", "f\u00fcllt", "es", "o\u00b7ben", "an", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$.", "$(", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "$,", "PIS", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Apollo singt, der ganze Chor der Musen", "tokens": ["A\u00b7pol\u00b7lo", "singt", ",", "der", "gan\u00b7ze", "Chor", "der", "Mu\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "$,", "ART", "ADJA", "NN", "ART", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.17": {"text": "Sperrt auch die M\u00e4uler auf, wie g\u00e4hnende Medusen,", "tokens": ["Sperrt", "auch", "die", "M\u00e4u\u00b7ler", "auf", ",", "wie", "g\u00e4h\u00b7nen\u00b7de", "Me\u00b7du\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "PTKVZ", "$,", "PWAV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Wir fallen ein, und wer nicht singen kann", "tokens": ["Wir", "fal\u00b7len", "ein", ",", "und", "wer", "nicht", "sin\u00b7gen", "kann"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "KON", "PWS", "PTKNEG", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Der leirt: Das Glas kommt nun von Mann zu Mann", "tokens": ["Der", "leirt", ":", "Das", "Glas", "kommt", "nun", "von", "Mann", "zu", "Mann"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "$.", "ART", "NN", "VVFIN", "ADV", "APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "(die Weiber mitgez\u00e4hlt) zu mir herum \u2013 wohlan!", "tokens": ["(", "die", "Wei\u00b7ber", "mit\u00b7ge\u00b7z\u00e4hlt", ")", "zu", "mir", "he\u00b7rum", "\u2013", "wo\u00b7hlan", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ART", "NN", "VVPP", "$(", "APPR", "PPER", "PTKVZ", "$(", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Sie reicht mir's hin, ich tu als nehm ich's an,", "tokens": ["Sie", "reicht", "mir's", "hin", ",", "ich", "tu", "als", "nehm", "ich's", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "PTKVZ", "$,", "PPER", "VVFIN", "KOKOM", "VVFIN", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Und lang indes nach ihrem Strau\u00df am Busen.", "tokens": ["Und", "lang", "in\u00b7des", "nach", "ih\u00b7rem", "Strau\u00df", "am", "Bu\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "APPR", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Sie schreit, als h\u00e4tt ich ihr wer wei\u00df was angetan,", "tokens": ["Sie", "schreit", ",", "als", "h\u00e4tt", "ich", "ihr", "wer", "wei\u00df", "was", "an\u00b7ge\u00b7tan", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOKOM", "VAFIN", "PPER", "PPOSAT", "PWS", "VVFIN", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Dreht sich zur\u00fcck, und schl\u00fcpft (das Estrich schwamm in Weine", "tokens": ["Dreht", "sich", "zu\u00b7r\u00fcck", ",", "und", "schl\u00fcpft", "(", "das", "Est\u00b7rich", "schwamm", "in", "Wei\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "PTKVZ", "$,", "KON", "VVFIN", "$(", "ART", "NN", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "War glatt wie Eis) kurz, eure arme Kleine", "tokens": ["War", "glatt", "wie", "Eis", ")", "kurz", ",", "eu\u00b7re", "ar\u00b7me", "Klei\u00b7ne"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "KOKOM", "NN", "$(", "ADJD", "$,", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Entschl\u00fcpft im drehn, glitscht r\u00fcckw\u00e4rts aus und st\u00fcrzt", "tokens": ["Ent\u00b7schl\u00fcpft", "im", "drehn", ",", "glitscht", "r\u00fcck\u00b7w\u00e4rts", "aus", "und", "st\u00fcrzt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPRART", "VVINF", "$,", "VVFIN", "ADV", "PTKVZ", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "So lang sie war, und leicht genug gesch\u00fcrzt,", "tokens": ["So", "lang", "sie", "war", ",", "und", "leicht", "ge\u00b7nug", "ge\u00b7sch\u00fcrzt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VAFIN", "$,", "KON", "ADJD", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Und streckt euch wie ein Frosch die Beine.\u00ab", "tokens": ["Und", "streckt", "euch", "wie", "ein", "Frosch", "die", "Bei\u00b7ne", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "KOKOM", "ART", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Was sie die G\u00f6tter sehen lie\u00df", "tokens": ["Was", "sie", "die", "G\u00f6t\u00b7ter", "se\u00b7hen", "lie\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "ART", "NN", "VVINF", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "L\u00e4\u00dft ohne Dreifu\u00df sich erraten;", "tokens": ["L\u00e4\u00dft", "oh\u00b7ne", "Drei\u00b7fu\u00df", "sich", "er\u00b7ra\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "\u00bbwir lachten \u00fcberlaut, doch unsre Damen taten", "tokens": ["\u00bb", "wir", "lach\u00b7ten", "\u00fc\u00b7berl\u00b7aut", ",", "doch", "uns\u00b7re", "Da\u00b7men", "ta\u00b7ten"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "ADJD", "$,", "ADV", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Als s\u00e4hn sie nicht was Hebe sch\u00f6nes wies,", "tokens": ["Als", "s\u00e4hn", "sie", "nicht", "was", "He\u00b7be", "sch\u00f6\u00b7nes", "wies", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "PTKNEG", "PWS", "NE", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.33": {"text": "(vielleicht aus Neid, wie oft genug geschiehet)", "tokens": ["(", "viel\u00b7leicht", "aus", "Neid", ",", "wie", "oft", "ge\u00b7nug", "ge\u00b7schie\u00b7het", ")"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "APPR", "NN", "$,", "PWAV", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.34": {"text": "Denn kurz, sie wurden rot und hielten euch geschwind", "tokens": ["Denn", "kurz", ",", "sie", "wur\u00b7den", "rot", "und", "hiel\u00b7ten", "euch", "ge\u00b7schwind"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "$,", "PPER", "VAFIN", "ADJD", "KON", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Die H\u00e4nde vor; was half's? Wer durch ein Sieb nicht siehet,", "tokens": ["Die", "H\u00e4n\u00b7de", "vor", ";", "was", "ha\u00b7lf's", "?", "Wer", "durch", "ein", "Sieb", "nicht", "sie\u00b7het", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$.", "PWS", "VAFIN", "$.", "PWS", "APPR", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.36": {"text": "Ist, wie man sagt unfehlbar blind.", "tokens": ["Ist", ",", "wie", "man", "sagt", "un\u00b7fehl\u00b7bar", "blind", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWAV", "PIS", "VVFIN", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.37": {"text": "Indem wir nun uns au\u00dfer Atem lachen,", "tokens": ["In\u00b7dem", "wir", "nun", "uns", "au\u00b7\u00dfer", "A\u00b7tem", "la\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.38": {"text": "Lauft Bacchus zu und will den Stutzer machen;", "tokens": ["Lauft", "Bac\u00b7chus", "zu", "und", "will", "den", "Stut\u00b7zer", "ma\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "PTKVZ", "KON", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.39": {"text": "Er liest sie auf; doch, wie man denken kann,", "tokens": ["Er", "liest", "sie", "auf", ";", "doch", ",", "wie", "man", "den\u00b7ken", "kann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$.", "ADV", "$,", "PWAV", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.40": {"text": "Greift er's so plump und Faunen-m\u00e4\u00dfig an \u2013", "tokens": ["Greift", "er's", "so", "plump", "und", "Fau\u00b7nen\u00b7m\u00e4\u00b7\u00dfig", "an", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "ADJD", "KON", "NE", "PTKVZ", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.41": {"text": "Da\u00df wir nur mehr zu lachen kriegen;", "tokens": ["Da\u00df", "wir", "nur", "mehr", "zu", "la\u00b7chen", "krie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.42": {"text": "Bei meinem Esel!\u00ab \u2013 \u00bbStill!\u00ab fiel Vater Zeus ihm ein,", "tokens": ["Bei", "mei\u00b7nem", "E\u00b7sel", "!", "\u00ab", "\u2013", "\u00bb", "Still", "!", "\u00ab", "fiel", "Va\u00b7ter", "Zeus", "ihm", "ein", ","], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "$(", "$(", "$(", "ADJD", "$.", "$(", "VVFIN", "NN", "NE", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Und sch\u00fcttelt seinen Kopf, da\u00df ihm die Haare fliegen;", "tokens": ["Und", "sch\u00fct\u00b7telt", "sei\u00b7nen", "Kopf", ",", "da\u00df", "ihm", "die", "Haa\u00b7re", "flie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$,", "KOUS", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "\u00bbich wei\u00df genug! Ihr Herren insgemein,", "tokens": ["\u00bb", "ich", "wei\u00df", "ge\u00b7nug", "!", "Ihr", "Her\u00b7ren", "ins\u00b7ge\u00b7mein", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "$.", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.45": {"text": "Sagt mir einmal, sind dieses auch Vergn\u00fcgen", "tokens": ["Sagt", "mir", "ein\u00b7mal", ",", "sind", "die\u00b7ses", "auch", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$,", "VAFIN", "PDS", "ADV", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.46": {"text": "F\u00fcr G\u00f6tter, wie ihr seid, Beim Styx! es t\u00f6nte fein,", "tokens": ["F\u00fcr", "G\u00f6t\u00b7ter", ",", "wie", "ihr", "seid", ",", "Beim", "Styx", "!", "es", "t\u00f6n\u00b7te", "fein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PWAV", "PPER", "VAFIN", "$,", "APPRART", "NN", "$.", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Wenn Menschen solche Dinge wi\u00dften!", "tokens": ["Wenn", "Men\u00b7schen", "sol\u00b7che", "Din\u00b7ge", "wi\u00df\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.48": {"text": "Die Schwalben w\u00fcrden bald in unsern Bildern nisten,", "tokens": ["Die", "Schwal\u00b7ben", "w\u00fcr\u00b7den", "bald", "in", "un\u00b7sern", "Bil\u00b7dern", "nis\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Und unsre Tempel B\u00e4der sein,", "tokens": ["Und", "uns\u00b7re", "Tem\u00b7pel", "B\u00e4\u00b7der", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.50": {"text": "Vielleicht was \u00e4rgers noch. Allein", "tokens": ["Viel\u00b7leicht", "was", "\u00e4r\u00b7gers", "noch", ".", "Al\u00b7lein"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "PWS", "ADV", "ADV", "$.", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.51": {"text": "Wir wollen uns nicht ohne Not entr\u00fcsten.", "tokens": ["Wir", "wol\u00b7len", "uns", "nicht", "oh\u00b7ne", "Not", "ent\u00b7r\u00fcs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.52": {"text": "Wi\u00dft, wir entlassen hier Mi\u00df Hebe ihrer Pflicht,", "tokens": ["Wi\u00dft", ",", "wir", "ent\u00b7las\u00b7sen", "hier", "Mi\u00df", "He\u00b7be", "ih\u00b7rer", "Pflicht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "VVFIN", "ADV", "NN", "NE", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Das Schenken-Amt schickt sich f\u00fcr M\u00e4dchen nicht,", "tokens": ["Das", "Schen\u00b7ken\u00b7Amt", "schickt", "sich", "f\u00fcr", "M\u00e4d\u00b7chen", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "NN", "PTKNEG", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.54": {"text": "Man wird es zu bestellen wissen. \u00ab", "tokens": ["Man", "wird", "es", "zu", "be\u00b7stel\u00b7len", "wis\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "VAFIN", "PPER", "PTKZU", "VVINF", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.55": {"text": "Herr Zeus beschlie\u00dft mit einem Amts-Gesicht;", "tokens": ["Herr", "Zeus", "be\u00b7schlie\u00dft", "mit", "ei\u00b7nem", "Amts\u00b7Ge\u00b7sicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.56": {"text": "Die G\u00f6tter lassen sich's gefallen, weil sie m\u00fcssen,", "tokens": ["Die", "G\u00f6t\u00b7ter", "las\u00b7sen", "sich's", "ge\u00b7fal\u00b7len", ",", "weil", "sie", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "VVPP", "$,", "KOUS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Und schleichen ab. Wie sehr ist Zeus erfreut!", "tokens": ["Und", "schlei\u00b7chen", "ab", ".", "Wie", "sehr", "ist", "Zeus", "er\u00b7freut", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "$.", "PWAV", "ADV", "VAFIN", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.58": {"text": "Wie wohl kommt ihm der Hebe Fall zu statten!", "tokens": ["Wie", "wohl", "kommt", "ihm", "der", "He\u00b7be", "Fall", "zu", "stat\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.59": {"text": "Was Witz und Macht zu schwer gefunden hatten,", "tokens": ["Was", "Witz", "und", "Macht", "zu", "schwer", "ge\u00b7fun\u00b7den", "hat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "PTKA", "ADJD", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.60": {"text": "Das hebt oft eine Kleinigkeit.", "tokens": ["Das", "hebt", "oft", "ei\u00b7ne", "Klei\u00b7nig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.61": {"text": "Auch Juno kann itzt nichts dagegen haben;", "tokens": ["Auch", "Ju\u00b7no", "kann", "itzt", "nichts", "da\u00b7ge\u00b7gen", "ha\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VMFIN", "ADV", "PIS", "PAV", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.62": {"text": "Das \u00c4rgernis mu\u00df ja gehoben sein.", "tokens": ["Das", "\u00c4r\u00b7ger\u00b7nis", "mu\u00df", "ja", "ge\u00b7ho\u00b7ben", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.63": {"text": "Gedacht, getan! er raubt den Hirten-Knaben,", "tokens": ["Ge\u00b7dacht", ",", "ge\u00b7tan", "!", "er", "raubt", "den", "Hir\u00b7ten\u00b7Kna\u00b7ben", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVPP", "$.", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.64": {"text": "Und setzt ihn ungehindert ein.", "tokens": ["Und", "setzt", "ihn", "un\u00b7ge\u00b7hin\u00b7dert", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Zween Tage ging's nicht schlimm; die G\u00f6tter alle schienen", "tokens": ["Zween", "Ta\u00b7ge", "ging's", "nicht", "schlimm", ";", "die", "G\u00f6t\u00b7ter", "al\u00b7le", "schie\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NN", "VVFIN", "PTKNEG", "ADJD", "$.", "ART", "NN", "PIAT", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit ihm vergn\u00fcgt, die Damen noch weit mehr;", "tokens": ["Mit", "ihm", "ver\u00b7gn\u00fcgt", ",", "die", "Da\u00b7men", "noch", "weit", "mehr", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "$,", "ART", "NN", "ADV", "ADJD", "ADV", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Man lobte seine Art zu dienen,", "tokens": ["Man", "lob\u00b7te", "sei\u00b7ne", "Art", "zu", "die\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und sein bescheidnes Wesen sehr.", "tokens": ["Und", "sein", "be\u00b7scheid\u00b7nes", "We\u00b7sen", "sehr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Selbst Amor liebt den anmutsvollen Knaben,", "tokens": ["Selbst", "A\u00b7mor", "liebt", "den", "an\u00b7muts\u00b7vol\u00b7len", "Kna\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "(ob Venus gleich ihm fast den Vorzug gibt)", "tokens": ["(", "ob", "Ve\u00b7nus", "gleich", "ihm", "fast", "den", "Vor\u00b7zug", "gibt", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "NN", "ADV", "PPER", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und will ihn stets zum Spielgesellen haben.", "tokens": ["Und", "will", "ihn", "stets", "zum", "Spiel\u00b7ge\u00b7sel\u00b7len", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Kurz, Ganymed wird wegen seiner Gaben", "tokens": ["Kurz", ",", "Ga\u00b7ny\u00b7med", "wird", "we\u00b7gen", "sei\u00b7ner", "Ga\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "NE", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Im ganzen Himmel bald beliebt.", "tokens": ["Im", "gan\u00b7zen", "Him\u00b7mel", "bald", "be\u00b7liebt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Nur Juno murrt. Doch Zeus l\u00e4\u00dft, ohne Schrecken,", "tokens": ["Nur", "Ju\u00b7no", "murrt", ".", "Doch", "Zeus", "l\u00e4\u00dft", ",", "oh\u00b7ne", "Schre\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "$.", "KON", "NE", "VVFIN", "$,", "KOUI", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Den Nektar sich nur desto besser schmecken,", "tokens": ["Den", "Nek\u00b7tar", "sich", "nur", "des\u00b7to", "bes\u00b7ser", "schme\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADV", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "Den ihm sein Liebling l\u00e4chelnd reicht.", "tokens": ["Den", "ihm", "sein", "Lieb\u00b7ling", "l\u00e4\u00b7chelnd", "reicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPOSAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Die G\u00f6ttin staunt, bemerkt, vergleicht,", "tokens": ["Die", "G\u00f6t\u00b7tin", "staunt", ",", "be\u00b7merkt", ",", "ver\u00b7gleicht", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "VVPP", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Macht manchen Schlu\u00df und glaubt zuletzt zu sehen,", "tokens": ["Macht", "man\u00b7chen", "Schlu\u00df", "und", "glaubt", "zu\u00b7letzt", "zu", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "KON", "VVFIN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Da\u00df Ganymed und ihr geliebter Mann", "tokens": ["Da\u00df", "Ga\u00b7ny\u00b7med", "und", "ihr", "ge\u00b7lieb\u00b7ter", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Einander mehr als n\u00f6tig ist verstehen.", "tokens": ["Ein\u00b7an\u00b7der", "mehr", "als", "n\u00f6\u00b7tig", "ist", "ver\u00b7ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "KOKOM", "ADJD", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Da\u00df eine Frau so was nicht leiden kann,", "tokens": ["Da\u00df", "ei\u00b7ne", "Frau", "so", "was", "nicht", "lei\u00b7den", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "PWS", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Ist ausgemacht; es mu\u00df in kurzem brechen.", "tokens": ["Ist", "aus\u00b7ge\u00b7macht", ";", "es", "mu\u00df", "in", "kur\u00b7zem", "bre\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$.", "PPER", "VMFIN", "APPR", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Sie harrt nur auf Gelegenheit,", "tokens": ["Sie", "harrt", "nur", "auf", "Ge\u00b7le\u00b7gen\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Denn Zeus ist schlau, und weicht, wer wei\u00df wie weit", "tokens": ["Denn", "Zeus", "ist", "schlau", ",", "und", "weicht", ",", "wer", "wei\u00df", "wie", "weit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NE", "VAFIN", "ADJD", "$,", "KON", "VVFIN", "$,", "PWS", "VVFIN", "KOKOM", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Den Anla\u00df aus; doch da er einst sich beut", "tokens": ["Den", "An\u00b7la\u00df", "aus", ";", "doch", "da", "er", "einst", "sich", "beut"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$.", "ADV", "KOUS", "PPER", "ADV", "PRF", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "F\u00e4ngt sie im Ton der strengsten Sittlichkeit", "tokens": ["F\u00e4ngt", "sie", "im", "Ton", "der", "strengs\u00b7ten", "Sitt\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Sehr matronalisch an mit ihm, wie folgt, zu sprechen:", "tokens": ["Sehr", "mat\u00b7ro\u00b7na\u00b7lisch", "an", "mit", "ihm", ",", "wie", "folgt", ",", "zu", "spre\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "APPR", "PPER", "$,", "PWAV", "VVFIN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "\u00bbzu lange schon hab ich mit kaltem Blut,", "tokens": ["\u00bb", "zu", "lan\u00b7ge", "schon", "hab", "ich", "mit", "kal\u00b7tem", "Blut", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKA", "ADV", "ADV", "VAFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Mein Herr, von euch Beschimpfungen ertragen,", "tokens": ["Mein", "Herr", ",", "von", "euch", "Be\u00b7schimp\u00b7fun\u00b7gen", "er\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "APPR", "PPER", "NN", "VVINF", "$,"], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Wobei ein Weib nicht leicht gelassen tut.", "tokens": ["Wo\u00b7bei", "ein", "Weib", "nicht", "leicht", "ge\u00b7las\u00b7sen", "tut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PTKNEG", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Doch durch Geduld wird euer \u00dcbermut", "tokens": ["Doch", "durch", "Ge\u00b7duld", "wird", "eu\u00b7er", "\u00dc\u00b7ber\u00b7mut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Nur k\u00fchner, immer mehr zu wagen.", "tokens": ["Nur", "k\u00fch\u00b7ner", ",", "im\u00b7mer", "mehr", "zu", "wa\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "$,", "ADV", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr s\u00fcndigt, wie es scheint, auf meine Tugend hin", "tokens": ["Ihr", "s\u00fcn\u00b7digt", ",", "wie", "es", "scheint", ",", "auf", "mei\u00b7ne", "Tu\u00b7gend", "hin"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und trotzt, weil ich zu gro\u00df zu jener Rache bin,", "tokens": ["Und", "trotzt", ",", "weil", "ich", "zu", "gro\u00df", "zu", "je\u00b7ner", "Ra\u00b7che", "bin", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "PTKA", "ADJD", "APPR", "PDAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die sich die Wenigsten in meinem Fall versagen.", "tokens": ["Die", "sich", "die", "We\u00b7nigs\u00b7ten", "in", "mei\u00b7nem", "Fall", "ver\u00b7sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ART", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.9": {"text": "Ich wei\u00df es, blo\u00df mein keuscher Sinn", "tokens": ["Ich", "wei\u00df", "es", ",", "blo\u00df", "mein", "keu\u00b7scher", "Sinn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "$,", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Hat diesen \u00dcberdru\u00df geboren,", "tokens": ["Hat", "die\u00b7sen", "\u00dc\u00b7berd\u00b7ru\u00df", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Durch den ich zwar, das glaubt mir, nichts verloren,", "tokens": ["Durch", "den", "ich", "zwar", ",", "das", "glaubt", "mir", ",", "nichts", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "$,", "PDS", "VVFIN", "PPER", "$,", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Als dessen ich sehr gern ent\u00fcbrigt bin.", "tokens": ["Als", "des\u00b7sen", "ich", "sehr", "gern", "ent\u00b7\u00fcb\u00b7rigt", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "PPER", "ADV", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Ihr suchtet eine Buhlerin", "tokens": ["Ihr", "such\u00b7tet", "ei\u00b7ne", "Buh\u00b7le\u00b7rin"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "In meinem Bett und ausgela\u00dfne Freuden;", "tokens": ["In", "mei\u00b7nem", "Bett", "und", "aus\u00b7ge\u00b7la\u00df\u00b7ne", "Freu\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Ich geb es zu, ihr irrtet euch darin:", "tokens": ["Ich", "geb", "es", "zu", ",", "ihr", "irr\u00b7tet", "euch", "da\u00b7rin", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "PPER", "VVFIN", "PPER", "PAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Die Pflicht allein zwang mich, nicht ohne Scham zu leiden,", "tokens": ["Die", "Pflicht", "al\u00b7lein", "zwang", "mich", ",", "nicht", "oh\u00b7ne", "Scham", "zu", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PPER", "$,", "PTKNEG", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Was mir mein Stand verbot zu meiden.", "tokens": ["Was", "mir", "mein", "Stand", "ver\u00b7bot", "zu", "mei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPOSAT", "NN", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Gesteh es, \u00dcppiger, der Frauen sch\u00f6nste Zier,", "tokens": ["Ge\u00b7steh", "es", ",", "\u00dcp\u00b7pi\u00b7ger", ",", "der", "Frau\u00b7en", "sch\u00f6ns\u00b7te", "Zier", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "NN", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Die Sittsamkeit, entw\u00f6hnte dich von mir.", "tokens": ["Die", "Sitt\u00b7sam\u00b7keit", ",", "ent\u00b7w\u00f6hn\u00b7te", "dich", "von", "mir", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "PRF", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Dir schmecken nur verstohlne Wasser s\u00fc\u00dfe,", "tokens": ["Dir", "schme\u00b7cken", "nur", "ver\u00b7stohl\u00b7ne", "Was\u00b7ser", "s\u00fc\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Und deiner Dirnen geile Bisse", "tokens": ["Und", "dei\u00b7ner", "Dir\u00b7nen", "gei\u00b7le", "Bis\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Und Zungen-Spiel verg\u00e4llte dir", "tokens": ["Und", "Zun\u00b7gen\u00b7Spiel", "ver\u00b7g\u00e4ll\u00b7te", "dir"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Der kalten Tugend ernste K\u00fcsse.", "tokens": ["Der", "kal\u00b7ten", "Tu\u00b7gend", "erns\u00b7te", "K\u00fcs\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Dies zog dich deinen Nymphen nach", "tokens": ["Dies", "zog", "dich", "dei\u00b7nen", "Nym\u00b7phen", "nach"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "PPOSAT", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Die sich gelehriger und reger finden lie\u00dfen;", "tokens": ["Die", "sich", "ge\u00b7leh\u00b7ri\u00b7ger", "und", "re\u00b7ger", "fin\u00b7den", "lie\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADJD", "KON", "ADJA", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Dies schmiegte dich zu deiner Lede F\u00fc\u00dfen", "tokens": ["Dies", "schmieg\u00b7te", "dich", "zu", "dei\u00b7ner", "Le\u00b7de", "F\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Und hinterlie\u00df an jedem Bach", "tokens": ["Und", "hin\u00b7ter\u00b7lie\u00df", "an", "je\u00b7dem", "Bach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "In jedem Hain, an allen Fl\u00fcssen,", "tokens": ["In", "je\u00b7dem", "Hain", ",", "an", "al\u00b7len", "Fl\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Die Spuren deiner \u00dcppigkeit.", "tokens": ["Die", "Spu\u00b7ren", "dei\u00b7ner", "\u00dcp\u00b7pig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Doch dieses konnte dir von meiner G\u00fctigkeit", "tokens": ["Doch", "die\u00b7ses", "konn\u00b7te", "dir", "von", "mei\u00b7ner", "G\u00fc\u00b7tig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VMFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Vielleicht noch \u00fcbersehen werden.", "tokens": ["Viel\u00b7leicht", "noch", "\u00fc\u00b7ber\u00b7se\u00b7hen", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Du stahlest Ort, Gestalt und Zeit,", "tokens": ["Du", "stah\u00b7lest", "Ort", ",", "Ge\u00b7stalt", "und", "Zeit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Lie\u00df'st deine Dirnen auf der Erden", "tokens": ["Lie\u00df'st", "dei\u00b7ne", "Dir\u00b7nen", "auf", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "Und den Olymp noch unentweiht.", "tokens": ["Und", "den", "O\u00b7lymp", "noch", "un\u00b7ent\u00b7weiht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Dies zeigte doch noch einen Rest von Scham.", "tokens": ["Dies", "zeig\u00b7te", "doch", "noch", "ei\u00b7nen", "Rest", "von", "Scham", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.36": {"text": "Allein seit dem auch Nymphen nichts mehr haben", "tokens": ["Al\u00b7lein", "seit", "dem", "auch", "Nym\u00b7phen", "nichts", "mehr", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PRELS", "ADV", "NN", "PIS", "ADV", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.37": {"text": "Das dich versucht, und dir der Einfall kam", "tokens": ["Das", "dich", "ver\u00b7sucht", ",", "und", "dir", "der", "Ein\u00b7fall", "kam"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "VVPP", "$,", "KON", "PPER", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.38": {"text": "Mit diesem bl\u00f6den Hirten-Knaben", "tokens": ["Mit", "die\u00b7sem", "bl\u00f6\u00b7den", "Hir\u00b7ten\u00b7Kna\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Aus Phrygien den Himmel zu begaben,", "tokens": ["Aus", "Phry\u00b7gi\u00b7en", "den", "Him\u00b7mel", "zu", "be\u00b7ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.40": {"text": "Scheint deine Ausgelassenheit", "tokens": ["Scheint", "dei\u00b7ne", "Aus\u00b7ge\u00b7las\u00b7sen\u00b7heit"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "Den h\u00f6chsten Grad erreicht zu haben.", "tokens": ["Den", "h\u00f6chs\u00b7ten", "Grad", "er\u00b7reicht", "zu", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.42": {"text": "Um einer armen Kleinigkeit", "tokens": ["Um", "ei\u00b7ner", "ar\u00b7men", "Klei\u00b7nig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.43": {"text": "Wird Hebe ungeh\u00f6rt von ihrem Amt verdrungen,", "tokens": ["Wird", "He\u00b7be", "un\u00b7ge\u00b7h\u00f6rt", "von", "ih\u00b7rem", "Amt", "ver\u00b7drun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADJD", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Damit dein l\u00fcstern Aug an einem nackten Jungen", "tokens": ["Da\u00b7mit", "dein", "l\u00fcs\u00b7tern", "Aug", "an", "ei\u00b7nem", "nack\u00b7ten", "Jun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "PPOSAT", "ADJA", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Sich t\u00e4glich weiden kann.", "tokens": ["Sich", "t\u00e4g\u00b7lich", "wei\u00b7den", "kann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.46": {"text": "Wie weit treibt ihr das Spiel so gar am G\u00f6tter-Tische?", "tokens": ["Wie", "weit", "treibt", "ihr", "das", "Spiel", "so", "gar", "am", "G\u00f6t\u00b7ter\u00b7Ti\u00b7sche", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "ART", "NN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Wir essen nie vor euch in Ruh,", "tokens": ["Wir", "es\u00b7sen", "nie", "vor", "euch", "in", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.48": {"text": "Stets w\u00e4hrt das T\u00e4ndeln und Gezische,", "tokens": ["Stets", "w\u00e4hrt", "das", "T\u00e4n\u00b7deln", "und", "Ge\u00b7zi\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.49": {"text": "Man lacht, man winkt, man wirft sich K\u00fcsse zu;", "tokens": ["Man", "lacht", ",", "man", "winkt", ",", "man", "wirft", "sich", "K\u00fcs\u00b7se", "zu", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PIS", "VVFIN", "$,", "PIS", "VVFIN", "PRF", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.50": {"text": "Und soll dein Nektar-Punsch dir schmecken,", "tokens": ["Und", "soll", "dein", "Nek\u00b7ta\u00b7rPunsch", "dir", "schme\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPOSAT", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.51": {"text": "So mu\u00df dir Ganymed den Becher erst belecken.", "tokens": ["So", "mu\u00df", "dir", "Ga\u00b7ny\u00b7med", "den", "Be\u00b7cher", "erst", "be\u00b7le\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NN", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Kaum setzt er an, so rei\u00dfest du", "tokens": ["Kaum", "setzt", "er", "an", ",", "so", "rei\u00b7\u00dfest", "du"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "ADV", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.53": {"text": "Den Kelch ihm aus der Hand, die Spur hinwegzusaugen,", "tokens": ["Den", "Kelch", "ihm", "aus", "der", "Hand", ",", "die", "Spur", "hin\u00b7weg\u00b7zu\u00b7sau\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "APPR", "ART", "NN", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Wo er den Mund im Trinken hingedr\u00fcckt,", "tokens": ["Wo", "er", "den", "Mund", "im", "Trin\u00b7ken", "hin\u00b7ge\u00b7dr\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.55": {"text": "Und siehst ihn schmatzend an, und rollst entz\u00fcckt,", "tokens": ["Und", "siehst", "ihn", "schmat\u00b7zend", "an", ",", "und", "rollst", "ent\u00b7z\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.56": {"text": "Wie ein Bacchant, die liebestrunknen Augen.", "tokens": ["Wie", "ein", "Bac\u00b7chant", ",", "die", "lie\u00b7be\u00b7strunk\u00b7nen", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.57": {"text": "Ja heute scheutest du dich nicht,", "tokens": ["Ja", "heu\u00b7te", "scheu\u00b7test", "du", "dich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "VVFIN", "PPER", "PRF", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.58": {"text": "Vor unser aller Angesicht", "tokens": ["Vor", "un\u00b7ser", "al\u00b7ler", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.59": {"text": "Ihn gar zu k\u00fcssen und zu herzen.", "tokens": ["Ihn", "gar", "zu", "k\u00fcs\u00b7sen", "und", "zu", "her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.60": {"text": "Ihr nennt es ohne Zweifel scherzen;", "tokens": ["Ihr", "nennt", "es", "oh\u00b7ne", "Zwei\u00b7fel", "scher\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.61": {"text": "Doch glaubet mir, da\u00df eurer Majest\u00e4t", "tokens": ["Doch", "glau\u00b7bet", "mir", ",", "da\u00df", "eu\u00b7rer", "Ma\u00b7jes\u00b7t\u00e4t"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.62": {"text": "Dies Kindisch-Tun nicht gar zu artig steht.", "tokens": ["Dies", "Kin\u00b7dischTun", "nicht", "gar", "zu", "ar\u00b7tig", "steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "PTKNEG", "ADV", "PTKA", "ADJD", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.63": {"text": "Wiewohl, was mag ich davon Sagen?", "tokens": ["Wie\u00b7wohl", ",", "was", "mag", "ich", "da\u00b7von", "Sa\u00b7gen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PWS", "VMFIN", "PPER", "PAV", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.64": {"text": "Wie lang ist's wohl, (du kannst Silenen fragen)", "tokens": ["Wie", "lang", "ist's", "wohl", ",", "(", "du", "kannst", "Si\u00b7le\u00b7nen", "fra\u00b7gen", ")"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ADV", "$,", "$(", "PPER", "VMFIN", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.65": {"text": "Da\u00df man mit Ganymed und Amor dich", "tokens": ["Da\u00df", "man", "mit", "Ga\u00b7ny\u00b7med", "und", "A\u00b7mor", "dich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "NN", "KON", "NE", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.66": {"text": "(den Donnerer!) beim G\u00e4nsespiel erschlich?", "tokens": ["(", "den", "Don\u00b7ne\u00b7rer", "!", ")", "beim", "G\u00e4n\u00b7se\u00b7spiel", "er\u00b7schlich", "?"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$.", "$(", "APPRART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.67": {"text": "Fi! Herr Gemahl, es ist nicht zum ertragen!", "tokens": ["Fi", "!", "Herr", "Ge\u00b7mahl", ",", "es", "ist", "nicht", "zum", "er\u00b7tra\u00b7gen", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "NN", "NN", "$,", "PPER", "VAFIN", "PTKNEG", "APPRART", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.68": {"text": "Ist das auch eine Lebensart", "tokens": ["Ist", "das", "auch", "ei\u00b7ne", "Le\u00b7ben\u00b7sart"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PDS", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.69": {"text": "F\u00fcr jenen Gott, durch den die Riesen fielen?", "tokens": ["F\u00fcr", "je\u00b7nen", "Gott", ",", "durch", "den", "die", "Rie\u00b7sen", "fie\u00b7len", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "APPR", "ART", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.70": {"text": "So alt, so einen gro\u00dfen Bart,", "tokens": ["So", "alt", ",", "so", "ei\u00b7nen", "gro\u00b7\u00dfen", "Bart", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.71": {"text": "Und noch mit kleinen Buben spielen!\u00ab", "tokens": ["Und", "noch", "mit", "klei\u00b7nen", "Bu\u00b7ben", "spie\u00b7len", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Hier schwieg Madam, und tat sehr wohl daran.", "tokens": ["Hier", "schwieg", "Ma\u00b7dam", ",", "und", "tat", "sehr", "wohl", "da\u00b7ran", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "$,", "KON", "VVFIN", "ADV", "ADV", "PAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Es flo\u00df ihr, wie man sieht, vortrefflich von der Zunge;", "tokens": ["Es", "flo\u00df", "ihr", ",", "wie", "man", "sieht", ",", "vor\u00b7treff\u00b7lich", "von", "der", "Zun\u00b7ge", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PWAV", "PIS", "VVFIN", "$,", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Unstreitig hatte sie die beste Lunge", "tokens": ["Un\u00b7strei\u00b7tig", "hat\u00b7te", "sie", "die", "bes\u00b7te", "Lun\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "ART", "ADJA", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Im ganzen G\u00f6tter-Volk, und diese Probe kann", "tokens": ["Im", "gan\u00b7zen", "G\u00f6t\u00b7ter\u00b7Volk", ",", "und", "die\u00b7se", "Pro\u00b7be", "kann"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "$,", "KON", "PDAT", "NN", "VMFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die obbesagten Ehbett-Wachen", "tokens": ["Die", "ob\u00b7be\u00b7sag\u00b7ten", "Eh\u00b7bet\u00b7tWa\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Des guten Zeus uns sehr begreiflich machen.", "tokens": ["Des", "gu\u00b7ten", "Zeus", "uns", "sehr", "be\u00b7greif\u00b7lich", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Doch diesmal h\u00f6rt' er sie mit gro\u00dfem Kaltsinn an,", "tokens": ["Doch", "dies\u00b7mal", "h\u00f6rt'", "er", "sie", "mit", "gro\u00b7\u00dfem", "Kal\u00b7tsinn", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPER", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Streicht l\u00e4chelnd seinen Bart, betrachtet seine Waden,", "tokens": ["Streicht", "l\u00e4\u00b7chelnd", "sei\u00b7nen", "Bart", ",", "be\u00b7trach\u00b7tet", "sei\u00b7ne", "Wa\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PPOSAT", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und fangt drauf an sein Herz, wie folget, zu entladen:", "tokens": ["Und", "fangt", "drauf", "an", "sein", "Herz", ",", "wie", "fol\u00b7get", ",", "zu", "ent\u00b7la\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "APPR", "PPOSAT", "NN", "$,", "PWAV", "VVFIN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u00bbob Eure strenge Sittsamkeit,", "tokens": ["\u00bb", "ob", "Eu\u00b7re", "stren\u00b7ge", "Sitt\u00b7sam\u00b7keit", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Zucht, Kaltsinn, Unbeweglichkeit,", "tokens": ["Zucht", ",", "Kal\u00b7tsinn", ",", "Un\u00b7be\u00b7weg\u00b7lich\u00b7keit", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Und gro\u00dfer Abscheu vor den Freuden", "tokens": ["Und", "gro\u00b7\u00dfer", "Ab\u00b7scheu", "vor", "den", "Freu\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Womit sich, wie ihr sagt, nur kleine Geister weiden,", "tokens": ["Wo\u00b7mit", "sich", ",", "wie", "ihr", "sagt", ",", "nur", "klei\u00b7ne", "Geis\u00b7ter", "wei\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "$,", "PWAV", "PPER", "VVFIN", "$,", "ADV", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Uns, liebes Weib, bisher entzweit,", "tokens": ["Uns", ",", "lie\u00b7bes", "Weib", ",", "bis\u00b7her", "ent\u00b7zweit", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "ADJA", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Das will ich itzo nicht entscheiden.", "tokens": ["Das", "will", "ich", "it\u00b7zo", "nicht", "ent\u00b7schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Genug, da\u00df sich mein alter Sinn", "tokens": ["Ge\u00b7nug", ",", "da\u00df", "sich", "mein", "al\u00b7ter", "Sinn"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PRF", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Ge\u00e4ndert hat, und \u00fcber diese Freuden", "tokens": ["Ge\u00b7\u00e4n\u00b7dert", "hat", ",", "und", "\u00fc\u00b7ber", "die\u00b7se", "Freu\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "VAFIN", "$,", "KON", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Ich selbst nunmehr ganz deiner Meinung bin.", "tokens": ["Ich", "selbst", "nun\u00b7mehr", "ganz", "dei\u00b7ner", "Mei\u00b7nung", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "ADV", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Vordem, mein Schatz, ich will dir's frei gestehen,", "tokens": ["Vor\u00b7dem", ",", "mein", "Schatz", ",", "ich", "will", "dir's", "frei", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$,", "PPER", "VMFIN", "PIS", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "War ich, (der Ruhm klingt freilich nicht gar fein:)", "tokens": ["War", "ich", ",", "(", "der", "Ruhm", "klingt", "frei\u00b7lich", "nicht", "gar", "fein", ":)"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "emoticon"], "pos": ["VAFIN", "PPER", "$,", "$(", "ART", "NN", "VVFIN", "ADV", "PTKNEG", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "In diesem St\u00fcck ein epikurisch Schwein.", "tokens": ["In", "die\u00b7sem", "St\u00fcck", "ein", "e\u00b7pi\u00b7ku\u00b7risch", "Schwein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Ich k\u00fc\u00dfte, was ich sah, Prinzessinnen und Feen,", "tokens": ["Ich", "k\u00fc\u00df\u00b7te", ",", "was", "ich", "sah", ",", "Prin\u00b7zes\u00b7sin\u00b7nen", "und", "Feen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWS", "PPER", "VVFIN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+--+", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Sylphiden, Nixen, Galatheen,", "tokens": ["Syl\u00b7phi\u00b7den", ",", "Ni\u00b7xen", ",", "Ga\u00b7la\u00b7theen", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.24": {"text": "Gras-Nymphen, alles insgemein,", "tokens": ["Gras\u00b7Nym\u00b7phen", ",", "al\u00b7les", "ins\u00b7ge\u00b7mein", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PIS", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Sie mochten schm\u00e4chtig, dick, hochst\u00e4mmicht oder klein,", "tokens": ["Sie", "moch\u00b7ten", "schm\u00e4ch\u00b7tig", ",", "dick", ",", "hoch\u00b7st\u00e4m\u00b7micht", "o\u00b7der", "klein", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "$,", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Blond, nu\u00dfbraun oder beides sein;", "tokens": ["Blond", ",", "nu\u00df\u00b7braun", "o\u00b7der", "bei\u00b7des", "sein", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "KON", "PIS", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Ich wu\u00dfte mich mit allen zu begehen.", "tokens": ["Ich", "wu\u00df\u00b7te", "mich", "mit", "al\u00b7len", "zu", "be\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Da sah ich ohne Regung nie", "tokens": ["Da", "sah", "ich", "oh\u00b7ne", "Re\u00b7gung", "nie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Ein sch\u00f6nes Kind aus einem Brunnen steigen;", "tokens": ["Ein", "sch\u00f6\u00b7nes", "Kind", "aus", "ei\u00b7nem", "Brun\u00b7nen", "stei\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "Man konnte mir ein rundes Knie", "tokens": ["Man", "konn\u00b7te", "mir", "ein", "run\u00b7des", "Knie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "So unnachteilig nicht als einem Tithon zeigen.", "tokens": ["So", "un\u00b7nach\u00b7tei\u00b7lig", "nicht", "als", "ei\u00b7nem", "Ti\u00b7thon", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKNEG", "KOUS", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Ob ihre Seele reizend sei,", "tokens": ["Ob", "ih\u00b7re", "See\u00b7le", "rei\u00b7zend", "sei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Das lie\u00df mich damals unbek\u00fcmmert,", "tokens": ["Das", "lie\u00df", "mich", "da\u00b7mals", "un\u00b7be\u00b7k\u00fcm\u00b7mert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "Verst\u00e4ndig oder nicht, mir galt es einerlei;", "tokens": ["Ver\u00b7st\u00e4n\u00b7dig", "o\u00b7der", "nicht", ",", "mir", "galt", "es", "ei\u00b7ner\u00b7lei", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "PTKNEG", "$,", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Von diesem h\u00f6hern Reiz der aus dem Innern schimmert", "tokens": ["Von", "die\u00b7sem", "h\u00f6\u00b7hern", "Reiz", "der", "aus", "dem", "In\u00b7nern", "schim\u00b7mert"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN", "ART", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Empfand ich nichts; mit einem Wort, ich sah", "tokens": ["Emp\u00b7fand", "ich", "nichts", ";", "mit", "ei\u00b7nem", "Wort", ",", "ich", "sah"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "PIS", "$.", "APPR", "ART", "NN", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.37": {"text": "An Pallas selbst, und allen Musen,", "tokens": ["An", "Pal\u00b7las", "selbst", ",", "und", "al\u00b7len", "Mu\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "$,", "KON", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.38": {"text": "Was an der bl\u00f6dsten Sylvia,", "tokens": ["Was", "an", "der", "bl\u00f6ds\u00b7ten", "Syl\u00b7via", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "ADJA", "NE", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.39": {"text": "Ein lockend Aug voll jugendlicher Glut,", "tokens": ["Ein", "lo\u00b7ckend", "Aug", "voll", "ju\u00b7gend\u00b7li\u00b7cher", "Glut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.40": {"text": "Ein wei\u00dfes Fell und einen vollen Busen.", "tokens": ["Ein", "wei\u00b7\u00dfes", "Fell", "und", "ei\u00b7nen", "vol\u00b7len", "Bu\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.41": {"text": "Allein von diesem rohen Mut,", "tokens": ["Al\u00b7lein", "von", "die\u00b7sem", "ro\u00b7hen", "Mut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Bin ich, versichre dich's, vollkommen,", "tokens": ["Bin", "ich", ",", "ver\u00b7sich\u00b7re", "dich's", ",", "voll\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "VVFIN", "PIS", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.43": {"text": "Und nicht erst heut, zur\u00fcckgekommen.", "tokens": ["Und", "nicht", "erst", "heut", ",", "zu\u00b7r\u00fcck\u00b7ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "ADV", "$,", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.44": {"text": "Erfahrung k\u00fchlt ein allzufeurig Blut.", "tokens": ["Er\u00b7fah\u00b7rung", "k\u00fchlt", "ein", "all\u00b7zu\u00b7feu\u00b7rig", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.45": {"text": "Mich l\u00e4\u00dft, zur Zeit, die loseste Najade,", "tokens": ["Mich", "l\u00e4\u00dft", ",", "zur", "Zeit", ",", "die", "lo\u00b7ses\u00b7te", "Na\u00b7ja\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPRART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.46": {"text": "Die j\u00fcngste Grazie, und Venus selbst im Bade", "tokens": ["Die", "j\u00fcngs\u00b7te", "Gra\u00b7zie", ",", "und", "Ve\u00b7nus", "selbst", "im", "Ba\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "NN", "ADV", "APPRART", "NN"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.47": {"text": "So ruhig als ein Marmorstein.", "tokens": ["So", "ru\u00b7hig", "als", "ein", "Mar\u00b7mor\u00b7stein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.48": {"text": "Das sch\u00f6nste Weib von Fleisch und Bein", "tokens": ["Das", "sch\u00f6ns\u00b7te", "Weib", "von", "Fleisch", "und", "Bein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.49": {"text": "Ist wie das Sonnenbild, das sich in Wolken malet,", "tokens": ["Ist", "wie", "das", "Son\u00b7nen\u00b7bild", ",", "das", "sich", "in", "Wol\u00b7ken", "ma\u00b7let", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ART", "NN", "$,", "PRELS", "PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "F\u00fcr mich ein blo\u00dfer Widerschein", "tokens": ["F\u00fcr", "mich", "ein", "blo\u00b7\u00dfer", "Wi\u00b7der\u00b7schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.51": {"text": "Der Sch\u00f6nheit, die, dem reinen Geist allein", "tokens": ["Der", "Sch\u00f6n\u00b7heit", ",", "die", ",", "dem", "rei\u00b7nen", "Geist", "al\u00b7lein"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "$,", "ART", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.52": {"text": "Beschaulich, aus dem Innern strahlet.", "tokens": ["Be\u00b7schau\u00b7lich", ",", "aus", "dem", "In\u00b7nern", "strah\u00b7let", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.53": {"text": "Ein weiser Mann, ein Grieche lehrte mich", "tokens": ["Ein", "wei\u00b7ser", "Mann", ",", "ein", "Grie\u00b7che", "lehr\u00b7te", "mich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.54": {"text": "Das wesentliche Sch\u00f6ne kennen;", "tokens": ["Das", "we\u00b7sent\u00b7li\u00b7che", "Sch\u00f6\u00b7ne", "ken\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.55": {"text": "Selbst unser Nektar wird mir schon zu k\u00f6rperlich;", "tokens": ["Selbst", "un\u00b7ser", "Nek\u00b7tar", "wird", "mir", "schon", "zu", "k\u00f6r\u00b7per\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Und lern ich erst den Plato recht verstehen,", "tokens": ["Und", "lern", "ich", "erst", "den", "Pla\u00b7to", "recht", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NE", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.57": {"text": "So n\u00e4hrt sich einst mein abgezogner Geist,", "tokens": ["So", "n\u00e4hrt", "sich", "einst", "mein", "ab\u00b7ge\u00b7zog\u00b7ner", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.58": {"text": "Der Grille gleich, die drum den G\u00f6ttern \u00e4hnlich hei\u00dft,", "tokens": ["Der", "Gril\u00b7le", "gleich", ",", "die", "drum", "den", "G\u00f6t\u00b7tern", "\u00e4hn\u00b7lich", "hei\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "PRELS", "PAV", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Allein von Luft und von Ideen.", "tokens": ["Al\u00b7lein", "von", "Luft", "und", "von", "I\u00b7deen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.60": {"text": "In diesem Licht m\u00fc\u00dft ihr die Liebe sehen", "tokens": ["In", "die\u00b7sem", "Licht", "m\u00fc\u00dft", "ihr", "die", "Lie\u00b7be", "se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VMFIN", "PPER", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.61": {"text": "Die mich zu Ganymeden zieht.", "tokens": ["Die", "mich", "zu", "Ga\u00b7ny\u00b7me\u00b7den", "zieht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.62": {"text": "Sein sch\u00f6ner Geist, sein tugendlich Gem\u00fct,", "tokens": ["Sein", "sch\u00f6\u00b7ner", "Geist", ",", "sein", "tu\u00b7gend\u00b7lich", "Ge\u00b7m\u00fct", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.63": {"text": "Die Grazien, die seine Sitten schm\u00fccken,", "tokens": ["Die", "Gra\u00b7zi\u00b7en", ",", "die", "sei\u00b7ne", "Sit\u00b7ten", "schm\u00fc\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.64": {"text": "Die Unschuld, die ihm aus den Augen sieht;", "tokens": ["Die", "Un\u00b7schuld", ",", "die", "ihm", "aus", "den", "Au\u00b7gen", "sieht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.65": {"text": "Dies, nicht sein blondes Haar nicht seine Rosenwangen,", "tokens": ["Dies", ",", "nicht", "sein", "blon\u00b7des", "Haar", "nicht", "sei\u00b7ne", "Ro\u00b7sen\u00b7wan\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PTKNEG", "PPOSAT", "ADJA", "NN", "PTKNEG", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Ist, glaube mir, der Reiz wodurch er mich gefangen.", "tokens": ["Ist", ",", "glau\u00b7be", "mir", ",", "der", "Reiz", "wo\u00b7durch", "er", "mich", "ge\u00b7fan\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "VVFIN", "PPER", "$,", "ART", "NN", "PWAV", "PPER", "PRF", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Du siehst, da\u00df hier der Leib gar keine Rolle spielt.", "tokens": ["Du", "siehst", ",", "da\u00df", "hier", "der", "Leib", "gar", "kei\u00b7ne", "Rol\u00b7le", "spielt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ADV", "ART", "NN", "ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Zum mindsten wird bei dieser Art von Liebe", "tokens": ["Zum", "minds\u00b7ten", "wird", "bei", "die\u00b7ser", "Art", "von", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "VAFIN", "APPR", "PDAT", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.69": {"text": "Nichts k\u00f6rperliches abgezielt.", "tokens": ["Nichts", "k\u00f6r\u00b7per\u00b7li\u00b7ches", "ab\u00b7ge\u00b7zielt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.70": {"text": "Das wahre Sch\u00f6ne wird nur vom Verstand gef\u00fchlt,", "tokens": ["Das", "wah\u00b7re", "Sch\u00f6\u00b7ne", "wird", "nur", "vom", "Ver\u00b7stand", "ge\u00b7f\u00fchlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Und zeuget nie gemeine Triebe.", "tokens": ["Und", "zeu\u00b7get", "nie", "ge\u00b7mei\u00b7ne", "Trie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.72": {"text": "Kurz, Ganymed, so sehr er Amorn gleicht,", "tokens": ["Kurz", ",", "Ga\u00b7ny\u00b7med", ",", "so", "sehr", "er", "A\u00b7morn", "gleicht", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "NE", "$,", "ADV", "ADV", "PPER", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.73": {"text": "So ungern ihm Dian ihr keusches Aug entzeucht,", "tokens": ["So", "un\u00b7gern", "ihm", "Di\u00b7an", "ihr", "keu\u00b7sches", "Aug", "ent\u00b7zeucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "NE", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "So oft ich, wenn er ihr den vollen Becher reicht", "tokens": ["So", "oft", "ich", ",", "wenn", "er", "ihr", "den", "vol\u00b7len", "Be\u00b7cher", "reicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PPER", "$,", "KOUS", "PPER", "PPER", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Die alte Vesta selbst beim Augenspiel ertappe,", "tokens": ["Die", "al\u00b7te", "Ves\u00b7ta", "selbst", "beim", "Au\u00b7gen\u00b7spiel", "er\u00b7tap\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "So ist er doch mit alle dem,", "tokens": ["So", "ist", "er", "doch", "mit", "al\u00b7le", "dem", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "PIS", "ART", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.77": {"text": "Nach meinem itzigen System", "tokens": ["Nach", "mei\u00b7nem", "it\u00b7zi\u00b7gen", "Sys\u00b7tem"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.78": {"text": "Ein blo\u00dfer Geist in einer Nebel-Kappe.\u00ab", "tokens": ["Ein", "blo\u00b7\u00dfer", "Geist", "in", "ei\u00b7ner", "Ne\u00b7bel\u00b7Kap\u00b7pe", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "\u00bbein blo\u00dfer Geist?\u00ab f\u00e4llt Juno h\u00f6hnisch ein,", "tokens": ["\u00bb", "ein", "blo\u00b7\u00dfer", "Geist", "?", "\u00ab", "f\u00e4llt", "Ju\u00b7no", "h\u00f6h\u00b7nisch", "ein", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "$.", "$(", "VVFIN", "NE", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbund pflegen Geister auch zu k\u00fcssen?\u00ab", "tokens": ["\u00bb", "und", "pfle\u00b7gen", "Geis\u00b7ter", "auch", "zu", "k\u00fcs\u00b7sen", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "ADJA", "NN", "ADV", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbwarum\u00ab, spricht Zeus, \u00bbsoll das nicht m\u00f6glich sein?", "tokens": ["\u00bb", "wa\u00b7rum", "\u00ab", ",", "spricht", "Zeus", ",", "\u00bb", "soll", "das", "nicht", "m\u00f6g\u00b7lich", "sein", "?"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "$(", "$,", "VVFIN", "NE", "$,", "$(", "VMFIN", "PDS", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "-----+-+-+", "measure": "unknown.measure.tri"}, "line.4": {"text": "Man mu\u00df hier nur zu unterscheiden wissen.", "tokens": ["Man", "mu\u00df", "hier", "nur", "zu", "un\u00b7ter\u00b7schei\u00b7den", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "ADV", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Gemeine Buhler schn\u00e4beln sich,", "tokens": ["Ge\u00b7mei\u00b7ne", "Buh\u00b7ler", "schn\u00e4\u00b7beln", "sich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nach Spatzen-Art, blo\u00df ihre Lust zu b\u00fc\u00dfen;", "tokens": ["Nach", "Spat\u00b7zen\u00b7Art", ",", "blo\u00df", "ih\u00b7re", "Lust", "zu", "b\u00fc\u00b7\u00dfen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADV", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Allein wie Ganymed und ich", "tokens": ["Al\u00b7lein", "wie", "Ga\u00b7ny\u00b7med", "und", "ich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "NE", "KON", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Abstract und metaphysisch k\u00fcssen,", "tokens": ["A\u00b7bstract", "und", "me\u00b7ta\u00b7phy\u00b7sisch", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Ist eine Lust, die uns, versichre dich,", "tokens": ["Ist", "ei\u00b7ne", "Lust", ",", "die", "uns", ",", "ver\u00b7sich\u00b7re", "dich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "PRELS", "PPER", "$,", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Gemeine Buhler lassen m\u00fcssen,", "tokens": ["Ge\u00b7mei\u00b7ne", "Buh\u00b7ler", "las\u00b7sen", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Die Seelen, Frau, die Seelen sind's, die sich", "tokens": ["Die", "See\u00b7len", ",", "Frau", ",", "die", "See\u00b7len", "sin\u00b7d's", ",", "die", "sich"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "NN", "$,", "ART", "NN", "VAFIN", "$,", "PRELS", "PRF"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.12": {"text": "In einem solchen Ku\u00df ergie\u00dfen;", "tokens": ["In", "ei\u00b7nem", "sol\u00b7chen", "Ku\u00df", "er\u00b7gie\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Und ganz dabei vom Leib entbl\u00f6\u00dft,", "tokens": ["Und", "ganz", "da\u00b7bei", "vom", "Leib", "ent\u00b7bl\u00f6\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PAV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Ganz in Entz\u00fcckung aufgel\u00f6st,", "tokens": ["Ganz", "in", "Ent\u00b7z\u00fc\u00b7ckung", "auf\u00b7ge\u00b7l\u00f6st", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Sich mischen und zusammenflie\u00dfen.", "tokens": ["Sich", "mi\u00b7schen", "und", "zu\u00b7sam\u00b7men\u00b7flie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "KON", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Doch ich besinne mich, da\u00df dies ins Tiefe geht.", "tokens": ["Doch", "ich", "be\u00b7sin\u00b7ne", "mich", ",", "da\u00df", "dies", "ins", "Tie\u00b7fe", "geht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$,", "KOUS", "PDS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Dein Mi\u00dfverstand ist sehr verzeihlich;", "tokens": ["Dein", "Mi\u00df\u00b7ver\u00b7stand", "ist", "sehr", "ver\u00b7zeih\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Das sind Geheimnisse, die freilich", "tokens": ["Das", "sind", "Ge\u00b7heim\u00b7nis\u00b7se", ",", "die", "frei\u00b7lich"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "VAFIN", "NN", "$,", "PRELS", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Ein Ungeweihtes nicht versteht.", "tokens": ["Ein", "Un\u00b7ge\u00b7weih\u00b7tes", "nicht", "ver\u00b7steht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Wenn \u00fcbrigens mein Spiel mit jungen Knaben", "tokens": ["Wenn", "\u00fcb\u00b7ri\u00b7gens", "mein", "Spiel", "mit", "jun\u00b7gen", "Kna\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Dein ekles Herz ge\u00e4rgert sollte haben,", "tokens": ["Dein", "ek\u00b7les", "Herz", "ge\u00b7\u00e4r\u00b7gert", "soll\u00b7te", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "VMFIN", "VAINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "So wi\u00dft, da\u00df mir hierin kein schlechtrer Mann", "tokens": ["So", "wi\u00dft", ",", "da\u00df", "mir", "hie\u00b7rin", "kein", "schlecht\u00b7rer", "Mann"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "PPER", "ADV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Als Sokrates zum Vorstand dienen kann.", "tokens": ["Als", "Sok\u00b7ra\u00b7tes", "zum", "Vor\u00b7stand", "die\u00b7nen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Ein Weiser ist, wie Seneca beteuret,", "tokens": ["Ein", "Wei\u00b7ser", "ist", ",", "wie", "Se\u00b7ne\u00b7ca", "be\u00b7teu\u00b7ret", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "PWAV", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Ein Gott, ja noch ein wenig mehr;", "tokens": ["Ein", "Gott", ",", "ja", "noch", "ein", "we\u00b7nig", "mehr", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ADV", "ART", "PIS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Wenn Sokrates mit kleinen Knaben leiret,", "tokens": ["Wenn", "Sok\u00b7ra\u00b7tes", "mit", "klei\u00b7nen", "Kna\u00b7ben", "lei\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "So darf ich wenigstens was er.\u00ab", "tokens": ["So", "darf", "ich", "we\u00b7nigs\u00b7tens", "was", "er", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PWS", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Hier endet Zeus, verneigt sich tief und geht;", "tokens": ["Hier", "en\u00b7det", "Zeus", ",", "ver\u00b7neigt", "sich", "tief", "und", "geht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "$,", "VVFIN", "PRF", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Das weitre kann Madam nun mit sich selber sprechen.", "tokens": ["Das", "weit\u00b7re", "kann", "Ma\u00b7dam", "nun", "mit", "sich", "sel\u00b7ber", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VMFIN", "NN", "ADV", "APPR", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie rief ihm nach, doch schon zu sp\u00e4t;", "tokens": ["Sie", "rief", "ihm", "nach", ",", "doch", "schon", "zu", "sp\u00e4t", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "ADV", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er fand f\u00fcr gut, wie man den Dichtern r\u00e4t,", "tokens": ["Er", "fand", "f\u00fcr", "gut", ",", "wie", "man", "den", "Dich\u00b7tern", "r\u00e4t", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJD", "$,", "PWAV", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Beim sch\u00f6nsten Einfall abzubrechen,", "tokens": ["Beim", "sch\u00f6ns\u00b7ten", "Ein\u00b7fall", "ab\u00b7zu\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und suchte seinen Ganymed.", "tokens": ["Und", "such\u00b7te", "sei\u00b7nen", "Ga\u00b7ny\u00b7med", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Der G\u00f6ttin schwillt der Kamm, sie wei\u00df sich kaum zu fassen.", "tokens": ["Der", "G\u00f6t\u00b7tin", "schwillt", "der", "Kamm", ",", "sie", "wei\u00df", "sich", "kaum", "zu", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "PRF", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zum Schaden sich noch gar verspotten lassen!", "tokens": ["Zum", "Scha\u00b7den", "sich", "noch", "gar", "ver\u00b7spot\u00b7ten", "las\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PRF", "ADV", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wo ist die Tugend in der Welt", "tokens": ["Wo", "ist", "die", "Tu\u00b7gend", "in", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die so gereizt die Probe h\u00e4lt'", "tokens": ["Die", "so", "ge\u00b7reizt", "die", "Pro\u00b7be", "h\u00e4lt'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADJD", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das mu\u00df gerochen sein! Doch nein, sie nennt es strafen,", "tokens": ["Das", "mu\u00df", "ge\u00b7ro\u00b7chen", "sein", "!", "Doch", "nein", ",", "sie", "nennt", "es", "stra\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "VVPP", "VAINF", "$.", "KON", "PTKANT", "$,", "PPER", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und schw\u00f6rt, sie will nicht eher schlafen,", "tokens": ["Und", "schw\u00f6rt", ",", "sie", "will", "nicht", "e\u00b7her", "schla\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPER", "VMFIN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Bis er gez\u00fcchtigt ist; und da\u00df auch hier", "tokens": ["Bis", "er", "ge\u00b7z\u00fcch\u00b7tigt", "ist", ";", "und", "da\u00df", "auch", "hier"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "$.", "KON", "KOUS", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Die Tugend nicht ihr Recht verlier,", "tokens": ["Die", "Tu\u00b7gend", "nicht", "ihr", "Recht", "ver\u00b7lier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Soll ihn f\u00fcr solche Ungeb\u00fchr", "tokens": ["Soll", "ihn", "f\u00fcr", "sol\u00b7che", "Un\u00b7ge\u00b7b\u00fchr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Das Werkzeug seiner S\u00fcnde strafen.", "tokens": ["Das", "Werk\u00b7zeug", "sei\u00b7ner", "S\u00fcn\u00b7de", "stra\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Sie klingelt; Iris kommt und h\u00f6rt", "tokens": ["Sie", "klin\u00b7gelt", ";", "I\u00b7ris", "kommt", "und", "h\u00f6rt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "NE", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was zwischen ihnen vorgegangen,", "tokens": ["Was", "zwi\u00b7schen", "ih\u00b7nen", "vor\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch neues wird sie nichts belehrt,", "tokens": ["Doch", "neu\u00b7es", "wird", "sie", "nichts", "be\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "VAFIN", "PPER", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie hatte vor der T\u00fcr schon alles aufgefangen.", "tokens": ["Sie", "hat\u00b7te", "vor", "der", "T\u00fcr", "schon", "al\u00b7les", "auf\u00b7ge\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mi\u00df Iris spricht, nach Zofen-Art, sehr scharf", "tokens": ["Mi\u00df", "I\u00b7ris", "spricht", ",", "nach", "Zo\u00b7fen\u00b7Art", ",", "sehr", "scharf"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "NE", "VVFIN", "$,", "APPR", "NE", "$,", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Von Jupitern und seinen Buhlereien:", "tokens": ["Von", "Ju\u00b7pi\u00b7tern", "und", "sei\u00b7nen", "Buh\u00b7le\u00b7rei\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "\u00bbmein Treu! Madam (wenn man es sagen darf)", "tokens": ["\u00bb", "mein", "Treu", "!", "Ma\u00b7dam", "(", "wenn", "man", "es", "sa\u00b7gen", "darf", ")"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$.", "NN", "$(", "KOUS", "PIS", "PPER", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ist gar zu gut, ihm immer zu verzeihen;", "tokens": ["Ist", "gar", "zu", "gut", ",", "ihm", "im\u00b7mer", "zu", "ver\u00b7zei\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKA", "ADJD", "$,", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Er wird dadurch verbuhlter als ein Spatz,", "tokens": ["Er", "wird", "da\u00b7durch", "ver\u00b7buhl\u00b7ter", "als", "ein", "Spatz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und h\u00e4uft Verbrechen auf Verbrechen;", "tokens": ["Und", "h\u00e4uft", "Ver\u00b7bre\u00b7chen", "auf", "Ver\u00b7bre\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Beim Styx, w\u00e4r ich an euer Gnaden Platz,", "tokens": ["Beim", "Styx", ",", "w\u00e4r", "ich", "an", "eu\u00b7er", "Gna\u00b7den", "Platz", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "VAFIN", "PPER", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Eh sollte mich der n\u00e4chste Satyr r\u00e4chen!", "tokens": ["Eh", "soll\u00b7te", "mich", "der", "n\u00e4chs\u00b7te", "Sa\u00b7tyr", "r\u00e4\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PRF", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Doch bei Madam hat's wahrlich keine Not,", "tokens": ["Doch", "bei", "Ma\u00b7dam", "hat's", "wahr\u00b7lich", "kei\u00b7ne", "Not", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VAFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Ihr kann es nie an R\u00e4chern fehlen,", "tokens": ["Ihr", "kann", "es", "nie", "an", "R\u00e4\u00b7chern", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Es kostet nichts als nach Geschmack zu w\u00e4hlen,", "tokens": ["Es", "kos\u00b7tet", "nichts", "als", "nach", "Ge\u00b7schmack", "zu", "w\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "KOKOM", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Ihr stehn auf jeden Wink die Sch\u00f6nsten zu Gebot.\u00ab", "tokens": ["Ihr", "stehn", "auf", "je\u00b7den", "Wink", "die", "Sch\u00f6ns\u00b7ten", "zu", "Ge\u00b7bot", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN", "ART", "NN", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Die G\u00f6ttin wird bei diesen freien Reden", "tokens": ["Die", "G\u00f6t\u00b7tin", "wird", "bei", "die\u00b7sen", "frei\u00b7en", "Re\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Bis an die Ohren-L\u00e4ppchen rot,", "tokens": ["Bis", "an", "die", "Oh\u00b7ren\u00b7L\u00e4pp\u00b7chen", "rot", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und Iris wird sehr hart bedroht", "tokens": ["Und", "I\u00b7ris", "wird", "sehr", "hart", "be\u00b7droht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "VAFIN", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nichts solches mehr sich zu entbl\u00f6den.", "tokens": ["Nichts", "sol\u00b7ches", "mehr", "sich", "zu", "ent\u00b7bl\u00f6\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PIS", "ADV", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die Zofe merkt es sich, und f\u00e4llt,", "tokens": ["Die", "Zo\u00b7fe", "merkt", "es", "sich", ",", "und", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PRF", "$,", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sobald sie es f\u00fcr schicklich h\u00e4lt,", "tokens": ["So\u00b7bald", "sie", "es", "f\u00fcr", "schick\u00b7lich", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPR", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mit guter Art auf Ganymeden.", "tokens": ["Mit", "gu\u00b7ter", "Art", "auf", "Ga\u00b7ny\u00b7me\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Der Einfall gl\u00fcckt; man scheint zerstreut,", "tokens": ["Der", "Ein\u00b7fall", "gl\u00fcckt", ";", "man", "scheint", "zer\u00b7streut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PIS", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Man gibt nicht acht, von wem sie schwatze,", "tokens": ["Man", "gibt", "nicht", "acht", ",", "von", "wem", "sie", "schwat\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKNEG", "CARD", "$,", "APPR", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und t\u00e4ndelt alle diese Zeit", "tokens": ["Und", "t\u00e4n\u00b7delt", "al\u00b7le", "die\u00b7se", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIS", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Sehr ernsthaft mit der kleinen Katze.", "tokens": ["Sehr", "ernst\u00b7haft", "mit", "der", "klei\u00b7nen", "Kat\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Doch da\u00df kein Wort von dem was Iris spricht", "tokens": ["Doch", "da\u00df", "kein", "Wort", "von", "dem", "was", "I\u00b7ris", "spricht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PIAT", "NN", "APPR", "ART", "PRELS", "NE", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Vor ihrem Ohr vorbeigegangen,", "tokens": ["Vor", "ih\u00b7rem", "Ohr", "vor\u00b7bei\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Verr\u00e4t der Augen funkelnd Licht,", "tokens": ["Ver\u00b7r\u00e4t", "der", "Au\u00b7gen", "fun\u00b7kelnd", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVPP", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Des Halstuchs Schwulst und brennendrote Wangen.", "tokens": ["Des", "Hal\u00b7stuchs", "Schwulst", "und", "bren\u00b7nen\u00b7dro\u00b7te", "Wan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Die G\u00f6ttin war vom ersten Anblick an", "tokens": ["Die", "G\u00f6t\u00b7tin", "war", "vom", "ers\u00b7ten", "An\u00b7blick", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPRART", "ADJA", "NN", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Von Ganymed nicht unger\u00fchrt geblieben;", "tokens": ["Von", "Ga\u00b7ny\u00b7med", "nicht", "un\u00b7ge\u00b7r\u00fchrt", "ge\u00b7blie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKNEG", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Sie ha\u00dft' ihn anfangs nur, aus Furcht sie m\u00f6cht ihn lieben;", "tokens": ["Sie", "ha\u00dft'", "ihn", "an\u00b7fangs", "nur", ",", "aus", "Furcht", "sie", "m\u00f6cht", "ihn", "lie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "$,", "APPR", "NN", "PPER", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Allein der Sprung vom Ha\u00df zu sanftern Trieben", "tokens": ["Al\u00b7lein", "der", "Sprung", "vom", "Ha\u00df", "zu", "sanf\u00b7tern", "Trie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "APPRART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Wird leichter als man glaubt getan.", "tokens": ["Wird", "leich\u00b7ter", "als", "man", "glaubt", "ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KOKOM", "PIS", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Wir sagten's schon, der Junge war zum Malen,", "tokens": ["Wir", "sag\u00b7ten's", "schon", ",", "der", "Jun\u00b7ge", "war", "zum", "Ma\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "ART", "NN", "VAFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Sch\u00f6n wie ein Wachs-Bild, wei\u00df und rot;", "tokens": ["Sch\u00f6n", "wie", "ein", "Wachs\u00b7Bild", ",", "wei\u00df", "und", "rot", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "$,", "VVFIN", "KON", "ADJD", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.23": {"text": "Ihm fehlten zum Apoll nur Strahlen,", "tokens": ["Ihm", "fehl\u00b7ten", "zum", "A\u00b7poll", "nur", "Strah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.24": {"text": "Und Fl\u00fcgel nur zum Liebes-Gott.", "tokens": ["Und", "Fl\u00fc\u00b7gel", "nur", "zum", "Lie\u00b7bes\u00b7Gott", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Nehmt noch dazu, was aus bekannten Gr\u00fcnden", "tokens": ["Nehmt", "noch", "da\u00b7zu", ",", "was", "aus", "be\u00b7kann\u00b7ten", "Gr\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PAV", "$,", "PRELS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Die Spr\u00f6den nicht am mindsten r\u00fchrt,", "tokens": ["Die", "Spr\u00f6\u00b7den", "nicht", "am", "minds\u00b7ten", "r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "APPRART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Das Alter, wo wir uns wie neuerschaffen finden,", "tokens": ["Das", "Al\u00b7ter", ",", "wo", "wir", "uns", "wie", "neu\u00b7er\u00b7schaf\u00b7fen", "fin\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "PRF", "KOKOM", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Wo alles reizt, und l\u00e4chelt und verf\u00fchrt;", "tokens": ["Wo", "al\u00b7les", "reizt", ",", "und", "l\u00e4\u00b7chelt", "und", "ver\u00b7f\u00fchrt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "$,", "KON", "VVFIN", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "Das Alter, wo der Knab im J\u00fcngling sich verliert,", "tokens": ["Das", "Al\u00b7ter", ",", "wo", "der", "Knab", "im", "J\u00fcng\u00b7ling", "sich", "ver\u00b7liert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ART", "NN", "APPRART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Und hier und da, was ehmals glatt gewesen,", "tokens": ["Und", "hier", "und", "da", ",", "was", "eh\u00b7mals", "glatt", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KON", "ADV", "$,", "PRELS", "ADV", "ADJD", "VAPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.31": {"text": "Mit weichem Pflaum sich schm\u00fcckt und sanft beschattet wird.", "tokens": ["Mit", "wei\u00b7chem", "Pflaum", "sich", "schm\u00fcckt", "und", "sanft", "be\u00b7schat\u00b7tet", "wird", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PRF", "VVFIN", "KON", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "F\u00fcr junge sch\u00fcchterne Agnesen", "tokens": ["F\u00fcr", "jun\u00b7ge", "sch\u00fcch\u00b7ter\u00b7ne", "Ag\u00b7ne\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.33": {"text": "Ist dieses Alter nicht gemacht,", "tokens": ["Ist", "die\u00b7ses", "Al\u00b7ter", "nicht", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Schon in der Sch\u00e4ferwelt, wie wir beim Longus lesen,", "tokens": ["Schon", "in", "der", "Sch\u00e4\u00b7fer\u00b7welt", ",", "wie", "wir", "beim", "Lon\u00b7gus", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "PWAV", "PPER", "APPRART", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "War eines Daphnis erste Nacht", "tokens": ["War", "ei\u00b7nes", "Daph\u00b7nis", "ers\u00b7te", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Ein J\u00e4ger-Recht, das Chloen, die nichts wu\u00dften,", "tokens": ["Ein", "J\u00e4\u00b7ger\u00b7Recht", ",", "das", "Chloen", ",", "die", "nichts", "wu\u00df\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "PRELS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.37": {"text": "Erfahrnern Sch\u00f6nen lassen mu\u00dften.", "tokens": ["Er\u00b7fahr\u00b7nern", "Sch\u00f6\u00b7nen", "las\u00b7sen", "mu\u00df\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "\u00bbbei Ganymed ist's w\u00fcrklich hohe Zeit,\u00ab", "tokens": ["\u00bb", "bei", "Ga\u00b7ny\u00b7med", "ist's", "w\u00fcrk\u00b7lich", "ho\u00b7he", "Zeit", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "NE", "VAFIN", "ADJD", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Fuhr Iris fort, \u00bbGelegenheit macht Diebe;", "tokens": ["Fuhr", "I\u00b7ris", "fort", ",", "\u00bb", "Ge\u00b7le\u00b7gen\u00b7heit", "macht", "Die\u00b7be", ";"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKVZ", "$,", "$(", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ein Knabe findt, trotz seiner Bl\u00f6digkeit,", "tokens": ["Ein", "Kna\u00b7be", "findt", ",", "trotz", "sei\u00b7ner", "Bl\u00f6\u00b7dig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Nichts leichter als den Weg der Liebe.", "tokens": ["Nichts", "leich\u00b7ter", "als", "den", "Weg", "der", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADJD", "KOKOM", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "J\u00fcngst hat Idalia ihm einen Blick verliehn,", "tokens": ["J\u00fcngst", "hat", "I\u00b7da\u00b7lia", "ihm", "ei\u00b7nen", "Blick", "ver\u00b7liehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.6": {"text": "Der feurig war, und fast ein Antrag schien;", "tokens": ["Der", "feu\u00b7rig", "war", ",", "und", "fast", "ein", "An\u00b7trag", "schien", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "$,", "KON", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Die dicke Ceres selbst lieb\u00e4ugelt scharf auf ihn,", "tokens": ["Die", "di\u00b7cke", "Ce\u00b7res", "selbst", "lie\u00b7b\u00e4u\u00b7gelt", "scharf", "auf", "ihn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVFIN", "ADJD", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Was ihren Augen fehlt, ersetzen andre Waffen;", "tokens": ["Was", "ih\u00b7ren", "Au\u00b7gen", "fehlt", ",", "er\u00b7set\u00b7zen", "and\u00b7re", "Waf\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVFIN", "$,", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Sie hat, so oft er bei ihr steht", "tokens": ["Sie", "hat", ",", "so", "oft", "er", "bei", "ihr", "steht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "ADV", "ADV", "PPER", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "An ihrem Halstuch was zu schaffen,", "tokens": ["An", "ih\u00b7rem", "Hal\u00b7stuch", "was", "zu", "schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Und neu, Madam, wie Ganymed,", "tokens": ["Und", "neu", ",", "Ma\u00b7dam", ",", "wie", "Ga\u00b7ny\u00b7med", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "NN", "$,", "PWAV", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Kann man sich gar zu leicht vergaffen.", "tokens": ["Kann", "man", "sich", "gar", "zu", "leicht", "ver\u00b7gaf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PRF", "ADV", "PTKA", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Ihr breiter Busen k\u00f6nnte bald", "tokens": ["Ihr", "brei\u00b7ter", "Bu\u00b7sen", "k\u00f6nn\u00b7te", "bald"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VMFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Den gr\u00f6\u00dften Reizungen den Vorsprung abgewinnen;", "tokens": ["Den", "gr\u00f6\u00df\u00b7ten", "Rei\u00b7zun\u00b7gen", "den", "Vor\u00b7sprung", "ab\u00b7ge\u00b7win\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.15": {"text": "Bei solchem Kram bleibt zwar das Herze kalt,", "tokens": ["Bei", "sol\u00b7chem", "Kram", "bleibt", "zwar", "das", "Her\u00b7ze", "kalt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "ADV", "PDS", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Doch reizt er destomehr die Sinnen:", "tokens": ["Doch", "reizt", "er", "des\u00b7to\u00b7mehr", "die", "Sin\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Und das ist alles doch zuletzt", "tokens": ["Und", "das", "ist", "al\u00b7les", "doch", "zu\u00b7letzt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VAFIN", "PIS", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Was eine Ceres sucht, und alles was sie sch\u00e4tzt.", "tokens": ["Was", "ei\u00b7ne", "Ce\u00b7res", "sucht", ",", "und", "al\u00b7les", "was", "sie", "sch\u00e4tzt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NE", "VVFIN", "$,", "KON", "PIS", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Kurz, d\u00fcrft ich meine Meinung sagen,", "tokens": ["Kurz", ",", "d\u00fcrft", "ich", "mei\u00b7ne", "Mei\u00b7nung", "sa\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "So ist Gefahr im k\u00fcrzesten Verzug;", "tokens": ["So", "ist", "Ge\u00b7fahr", "im", "k\u00fcr\u00b7zes\u00b7ten", "Ver\u00b7zug", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Mich deucht in diesem Fall die alte Regel klug:", "tokens": ["Mich", "deucht", "in", "die\u00b7sem", "Fall", "die", "al\u00b7te", "Re\u00b7gel", "klug", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "NN", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Um Alles mu\u00df man alles wagen.\u00ab", "tokens": ["Um", "Al\u00b7les", "mu\u00df", "man", "al\u00b7les", "wa\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PIS", "VMFIN", "PIS", "PIS", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Der Rat war gut; allein, so schnell als Iris r\u00e4t", "tokens": ["Der", "Rat", "war", "gut", ";", "al\u00b7lein", ",", "so", "schnell", "als", "I\u00b7ris", "r\u00e4t"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "ADV", "$,", "ADV", "ADJD", "KOKOM", "NE", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vom Zeremoniell der Tugend nachzulassen,", "tokens": ["Vom", "Ze\u00b7re\u00b7mo\u00b7ni\u00b7ell", "der", "Tu\u00b7gend", "nach\u00b7zu\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Schon der Gedank emp\u00f6rt der G\u00f6ttin Majest\u00e4t.", "tokens": ["Schon", "der", "Ge\u00b7dank", "em\u00b7p\u00f6rt", "der", "G\u00f6t\u00b7tin", "Ma\u00b7jes\u00b7t\u00e4t", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u00bbund doch, Madam, ist's leicht zu fassen,", "tokens": ["\u00bb", "und", "doch", ",", "Ma\u00b7dam", ",", "ist's", "leicht", "zu", "fas\u00b7sen", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ADV", "$,", "NN", "$,", "VAFIN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df Ganymede sich nicht anders fangen lassen.", "tokens": ["Da\u00df", "Ga\u00b7ny\u00b7me\u00b7de", "sich", "nicht", "an\u00b7ders", "fan\u00b7gen", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PRF", "PTKNEG", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was eines Tithons lahmen Arm", "tokens": ["Was", "ei\u00b7nes", "Ti\u00b7thons", "lah\u00b7men", "Arm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mit Jugend-Kraft begeistern w\u00fcrde;", "tokens": ["Mit", "Ju\u00b7gend\u00b7Kraft", "be\u00b7geis\u00b7tern", "w\u00fcr\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was einen Hippolyt verf\u00fchrte,", "tokens": ["Was", "ei\u00b7nen", "Hip\u00b7po\u00b7lyt", "ver\u00b7f\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Macht zwar dem bl\u00f6den Neuling warm,", "tokens": ["Macht", "zwar", "dem", "bl\u00f6\u00b7den", "Neu\u00b7ling", "warm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Doch keinen Mut; er seufzt und darf nichts wagen,", "tokens": ["Doch", "kei\u00b7nen", "Mut", ";", "er", "seufzt", "und", "darf", "nichts", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$.", "PPER", "VVFIN", "KON", "VMFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Er wird durch keinen Wink belehrt,", "tokens": ["Er", "wird", "durch", "kei\u00b7nen", "Wink", "be\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Kein L\u00e4cheln macht ihn k\u00fchn, er h\u00f6rt", "tokens": ["Kein", "L\u00e4\u00b7cheln", "macht", "ihn", "k\u00fchn", ",", "er", "h\u00f6rt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "ADJD", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Die Sch\u00e4ferstunde niemals schlagen;", "tokens": ["Die", "Sch\u00e4\u00b7fer\u00b7stun\u00b7de", "nie\u00b7mals", "schla\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Ihm mag ein schmelzend Aug es noch so deutlich sagen,", "tokens": ["Ihm", "mag", "ein", "schmel\u00b7zend", "Aug", "es", "noch", "so", "deut\u00b7lich", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJD", "NN", "PPER", "ADV", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Man mag ihn noch so sanft, warum er zittre, fragen,", "tokens": ["Man", "mag", "ihn", "noch", "so", "sanft", ",", "wa\u00b7rum", "er", "zitt\u00b7re", ",", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "ADV", "ADV", "ADJD", "$,", "PWAV", "PPER", "VVFIN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Er zittert fort, und wo er danken soll", "tokens": ["Er", "zit\u00b7tert", "fort", ",", "und", "wo", "er", "dan\u00b7ken", "soll"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "KON", "PWAV", "PPER", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Da wirft er sich verzweiflungsvoll", "tokens": ["Da", "wirft", "er", "sich", "ver\u00b7zwei\u00b7flungs\u00b7voll"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Zu euern F\u00fc\u00dfen hin, und stottert bittre Klagen.", "tokens": ["Zu", "eu\u00b7ern", "F\u00fc\u00b7\u00dfen", "hin", ",", "und", "stot\u00b7tert", "bitt\u00b7re", "Kla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$,", "KON", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Er sieht den Vorteil nicht, den eine Stellung gibt,", "tokens": ["Er", "sieht", "den", "Vor\u00b7teil", "nicht", ",", "den", "ei\u00b7ne", "Stel\u00b7lung", "gibt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKNEG", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Die, wie mich deucht, die Ehrfurcht nicht erfunden;", "tokens": ["Die", ",", "wie", "mich", "deucht", ",", "die", "Ehr\u00b7furcht", "nicht", "er\u00b7fun\u00b7den", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PWAV", "PPER", "VVFIN", "$,", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "So sehr ihr Halstuch sich verschiebt,", "tokens": ["So", "sehr", "ihr", "Hal\u00b7stuch", "sich", "ver\u00b7schiebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "So bleibt ihm doch die Hand gebunden:", "tokens": ["So", "bleibt", "ihm", "doch", "die", "Hand", "ge\u00b7bun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Ihn reizt zu seiner Qual ein halbentdeckter Fu\u00df;", "tokens": ["Ihn", "reizt", "zu", "sei\u00b7ner", "Qual", "ein", "hal\u00b7bent\u00b7deck\u00b7ter", "Fu\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Er sieht's und lechzt, wie Tantalus,", "tokens": ["Er", "sieht's", "und", "lechzt", ",", "wie", "Tan\u00b7ta\u00b7lus", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "NE", "KON", "VVFIN", "$,", "PWAV", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Am Quell der Lust vor durstigem Verlangen;", "tokens": ["Am", "Quell", "der", "Lust", "vor", "durs\u00b7ti\u00b7gem", "Ver\u00b7lan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Ihm pocht sein Herz, und gro\u00dfe Tropfen hangen", "tokens": ["Ihm", "pocht", "sein", "Herz", ",", "und", "gro\u00b7\u00dfe", "Trop\u00b7fen", "han\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "KON", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "In seinem Aug, und auf den hei\u00dfen Wangen;", "tokens": ["In", "sei\u00b7nem", "Aug", ",", "und", "auf", "den", "hei\u00b7\u00dfen", "Wan\u00b7gen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KON", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Vielleicht entschlie\u00dft sich allgemach", "tokens": ["Viel\u00b7leicht", "ent\u00b7schlie\u00dft", "sich", "all\u00b7ge\u00b7mach"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Sein matter Arm, sie sterbend zu umfangen;", "tokens": ["Sein", "mat\u00b7ter", "Arm", ",", "sie", "ster\u00b7bend", "zu", "um\u00b7fan\u00b7gen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "Die Sch\u00f6ne str\u00e4ubt sich, zwar nur schwach,", "tokens": ["Die", "Sch\u00f6\u00b7ne", "str\u00e4ubt", "sich", ",", "zwar", "nur", "schwach", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "$,", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Ihr Auge lockt, ein wollustatmend Ach", "tokens": ["Ihr", "Au\u00b7ge", "lockt", ",", "ein", "wol\u00b7lus\u00b7tat\u00b7mend", "Ach"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Bekennt ihm seinen Sieg, und hei\u00dft ihn k\u00fchner werden;", "tokens": ["Be\u00b7kennt", "ihm", "sei\u00b7nen", "Sieg", ",", "und", "hei\u00dft", "ihn", "k\u00fch\u00b7ner", "wer\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,", "KON", "VVFIN", "PPER", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Doch er \u2013 Madam, bei meiner Treu!", "tokens": ["Doch", "er", "\u2013", "Ma\u00b7dam", ",", "bei", "mei\u00b7ner", "Treu", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$(", "NN", "$,", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Ich glaubt es andern nicht, allein ich war dabei", "tokens": ["Ich", "glaubt", "es", "an\u00b7dern", "nicht", ",", "al\u00b7lein", "ich", "war", "da\u00b7bei"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "PTKNEG", "$,", "ADV", "PPER", "VAFIN", "PAV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Er denkt, sie z\u00fcrnt, macht kl\u00e4gliche Geb\u00e4rden,", "tokens": ["Er", "denkt", ",", "sie", "z\u00fcrnt", ",", "macht", "kl\u00e4g\u00b7li\u00b7che", "Ge\u00b7b\u00e4r\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.36": {"text": "Und weint, da\u00df sie so grausam sei.\u00ab", "tokens": ["Und", "weint", ",", "da\u00df", "sie", "so", "grau\u00b7sam", "sei", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Mi\u00df Iris malte nach dem Leben \u2013", "tokens": ["Mi\u00df", "I\u00b7ris", "mal\u00b7te", "nach", "dem", "Le\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Warum? \u2013 Der Grund ist leicht \u2013 weil sie", "tokens": ["Wa\u00b7rum", "?", "\u2013", "Der", "Grund", "ist", "leicht", "\u2013", "weil", "sie"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "$.", "$(", "ART", "NN", "VAFIN", "ADJD", "$(", "KOUS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und Ganymed die Poesie", "tokens": ["Und", "Ga\u00b7ny\u00b7med", "die", "Poe\u00b7sie"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zu dem Gem\u00e4lde hergegeben.", "tokens": ["Zu", "dem", "Ge\u00b7m\u00e4l\u00b7de", "her\u00b7ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "\u00bbaus allem\u00ab, fuhr sie fort, \u00bbMadam,", "tokens": ["\u00bb", "aus", "al\u00b7lem", "\u00ab", ",", "fuhr", "sie", "fort", ",", "\u00bb", "Ma\u00b7dam", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["$(", "APPR", "PIS", "$(", "$,", "VVFIN", "PPER", "PTKVZ", "$,", "$(", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist, deucht mich, klar, da\u00df diese falsche Scham,", "tokens": ["Ist", ",", "deucht", "mich", ",", "klar", ",", "da\u00df", "die\u00b7se", "fal\u00b7sche", "Scham", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "VVFIN", "PPER", "$,", "ADJD", "$,", "KOUS", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Bl\u00f6digkeit, und wenn man will die Tugend", "tokens": ["Die", "Bl\u00f6\u00b7dig\u00b7keit", ",", "und", "wenn", "man", "will", "die", "Tu\u00b7gend"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KON", "KOUS", "PIS", "VMFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der ersten unversuchten Jugend", "tokens": ["Der", "ers\u00b7ten", "un\u00b7ver\u00b7such\u00b7ten", "Ju\u00b7gend"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Den st\u00e4rksten Reizungen schon oft die Macht benahm;", "tokens": ["Den", "st\u00e4rks\u00b7ten", "Rei\u00b7zun\u00b7gen", "schon", "oft", "die", "Macht", "be\u00b7nahm", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.6": {"text": "Sie wird nur durch Ermunterungen", "tokens": ["Sie", "wird", "nur", "durch", "Er\u00b7mun\u00b7te\u00b7run\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Nur durch Gef\u00e4lligkeit und schlaue List bezwungen.", "tokens": ["Nur", "durch", "Ge\u00b7f\u00e4l\u00b7lig\u00b7keit", "und", "schlau\u00b7e", "List", "be\u00b7zwun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Man mu\u00df, so schwer's dem Stolze f\u00e4llt,", "tokens": ["Man", "mu\u00df", ",", "so", "schwer's", "dem", "Stol\u00b7ze", "f\u00e4llt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "$,", "ADV", "VVFIN", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die ersten Schritte tun\u00ab \u2013 \u00bbIch, sollte mich entschlie\u00dfen", "tokens": ["Die", "ers\u00b7ten", "Schrit\u00b7te", "tun", "\u00ab", "\u2013", "\u00bb", "Ich", ",", "soll\u00b7te", "mich", "ent\u00b7schlie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVINF", "$(", "$(", "$(", "PPER", "$,", "VMFIN", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den ersten Schritt zu tun? Da wird er warten m\u00fcssen!", "tokens": ["Den", "ers\u00b7ten", "Schritt", "zu", "tun", "?", "Da", "wird", "er", "war\u00b7ten", "m\u00fcs\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$.", "ADV", "VAFIN", "PPER", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Das t\u00e4t ich nicht um alles in der Welt.\u00ab", "tokens": ["Das", "t\u00e4t", "ich", "nicht", "um", "al\u00b7les", "in", "der", "Welt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKNEG", "APPR", "PIS", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "\u00bbmadam, Madam, was f\u00fcr Bedenklichkeiten!", "tokens": ["\u00bb", "ma\u00b7dam", ",", "Ma\u00b7dam", ",", "was", "f\u00fcr", "Be\u00b7denk\u00b7lich\u00b7kei\u00b7ten", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$,", "NN", "$,", "PRELS", "APPR", "NN", "$."], "meter": "---+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.13": {"text": "Sie bleiben also, scheint's, bei ihrem Vorsatz fest,", "tokens": ["Sie", "blei\u00b7ben", "al\u00b7so", ",", "scheint's", ",", "bei", "ih\u00b7rem", "Vor\u00b7satz", "fest", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und nehmen demutsvoll was Ceres \u00fcbrig l\u00e4\u00dft?\u00ab", "tokens": ["Und", "neh\u00b7men", "de\u00b7muts\u00b7voll", "was", "Ce\u00b7res", "\u00fcb\u00b7rig", "l\u00e4\u00dft", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVINF", "VMFIN", "PWS", "NE", "ADJD", "VVFIN", "$.", "$("], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}}, "stanza.29": {"line.1": {"text": "Gewi\u00df \u2013\u00ab \u00bbSo sei es dann! Ich will nicht l\u00e4nger streiten,", "tokens": ["Ge\u00b7wi\u00df", "\u2013", "\u00ab", "\u00bb", "So", "sei", "es", "dann", "!", "Ich", "will", "nicht", "l\u00e4n\u00b7ger", "strei\u00b7ten", ","], "token_info": ["word", "punct", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "$(", "$(", "ADV", "VAFIN", "PPER", "ADV", "$.", "PPER", "VMFIN", "PTKNEG", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich sagte dir's, gerochen mu\u00df ich sein!", "tokens": ["Ich", "sag\u00b7te", "dir's", ",", "ge\u00b7ro\u00b7chen", "mu\u00df", "ich", "sein", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$,", "VVINF", "VMFIN", "PPER", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Er ist es wert zu Fehlern zu verleiten", "tokens": ["Er", "ist", "es", "wert", "zu", "Feh\u00b7lern", "zu", "ver\u00b7lei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "APPR", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Doch nehm ich's nicht auf mich allein;", "tokens": ["Doch", "nehm", "ich's", "nicht", "auf", "mich", "al\u00b7lein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PTKNEG", "APPR", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du mu\u00dft ihn doch ein wenig vorbereiten.\u00ab", "tokens": ["Du", "mu\u00dft", "ihn", "doch", "ein", "we\u00b7nig", "vor\u00b7be\u00b7rei\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ART", "PIS", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "Die Zofe, wie man denken kann,", "tokens": ["Die", "Zo\u00b7fe", ",", "wie", "man", "den\u00b7ken", "kann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nimmt diesen Auftrag willig an;", "tokens": ["Nimmt", "die\u00b7sen", "Auf\u00b7trag", "wil\u00b7lig", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und da\u00df sie keine Zeit verliert", "tokens": ["Und", "da\u00df", "sie", "kei\u00b7ne", "Zeit", "ver\u00b7liert"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird er noch diese Nacht sehr kl\u00fcglich ausgef\u00fchrt.", "tokens": ["Wird", "er", "noch", "die\u00b7se", "Nacht", "sehr", "kl\u00fcg\u00b7lich", "aus\u00b7ge\u00b7f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PDAT", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein kleiner Hain von Myrten und Schasminen", "tokens": ["Ein", "klei\u00b7ner", "Hain", "von", "Myr\u00b7ten", "und", "Schas\u00b7mi\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Erbietet sich, nicht weit vom G\u00f6tter-Sitz,", "tokens": ["Er\u00b7bie\u00b7tet", "sich", ",", "nicht", "weit", "vom", "G\u00f6t\u00b7ter\u00b7Sitz", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$,", "PTKNEG", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Zum Vorbereitungs-Ort zu dienen.", "tokens": ["Zum", "Vor\u00b7be\u00b7rei\u00b7tungs\u00b7Ort", "zu", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ob auch der Mond fein h\u00fcbsch dazu geschienen,", "tokens": ["Ob", "auch", "der", "Mond", "fein", "h\u00fcbsch", "da\u00b7zu", "ge\u00b7schie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADJD", "ADJD", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Das gilt uns gleich; genug des M\u00e4dchens Witz", "tokens": ["Das", "gilt", "uns", "gleich", ";", "ge\u00b7nug", "des", "M\u00e4d\u00b7chens", "Witz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "$.", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Fand diesesmal, zu jeden Teils Vergn\u00fcgen,", "tokens": ["Fand", "die\u00b7ses\u00b7mal", ",", "zu", "je\u00b7den", "Teils", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "APPR", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Den Weg, die Bl\u00f6digkeit des Knaben zu besiegen.", "tokens": ["Den", "Weg", ",", "die", "Bl\u00f6\u00b7dig\u00b7keit", "des", "Kna\u00b7ben", "zu", "be\u00b7sie\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Kaum war die erste Schwierigkeit", "tokens": ["Kaum", "war", "die", "ers\u00b7te", "Schwie\u00b7rig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Durch ihren Beistand \u00fcberwunden,", "tokens": ["Durch", "ih\u00b7ren", "Bei\u00b7stand", "\u00fc\u00b7berw\u00b7un\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "So war auch seine Sch\u00fcchternheit", "tokens": ["So", "war", "auch", "sei\u00b7ne", "Sch\u00fcch\u00b7tern\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Bis auf die kleinste Spur verschwunden.", "tokens": ["Bis", "auf", "die", "kleins\u00b7te", "Spur", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Mi\u00df Iris selbst, die ziemlich kritisch war,", "tokens": ["Mi\u00df", "I\u00b7ris", "selbst", ",", "die", "ziem\u00b7lich", "kri\u00b7tisch", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ADV", "$,", "PRELS", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Fand seine Gaben wunderbar;", "tokens": ["Fand", "sei\u00b7ne", "Ga\u00b7ben", "wun\u00b7der\u00b7bar", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Auch tat sie was man kann, sie v\u00f6llig zu entfalten.", "tokens": ["Auch", "tat", "sie", "was", "man", "kann", ",", "sie", "v\u00f6l\u00b7lig", "zu", "ent\u00b7fal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PWS", "PIS", "VMFIN", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Sie wu\u00dft ihn unverr\u00fcckt im Atem zu erhalten;", "tokens": ["Sie", "wu\u00dft", "ihn", "un\u00b7ver\u00b7r\u00fcckt", "im", "A\u00b7tem", "zu", "er\u00b7hal\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und niemals ward vielleicht in einer Sommer-Nacht", "tokens": ["Und", "nie\u00b7mals", "ward", "viel\u00b7leicht", "in", "ei\u00b7ner", "Som\u00b7mer\u00b7Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ein Sch\u00fcler halb so weit gebracht.", "tokens": ["Ein", "Sch\u00fc\u00b7ler", "halb", "so", "weit", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Indes verk\u00fcndt dem G\u00f6tter-Hofe", "tokens": ["In\u00b7des", "ver\u00b7k\u00fcndt", "dem", "G\u00f6t\u00b7ter\u00b7Ho\u00b7fe"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Glocke Klang des neuen Tages Licht.", "tokens": ["Der", "Glo\u00b7cke", "Klang", "des", "neu\u00b7en", "Ta\u00b7ges", "Licht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie schleichen aus dem Hain, und die getreue Zofe", "tokens": ["Sie", "schlei\u00b7chen", "aus", "dem", "Hain", ",", "und", "die", "ge\u00b7treu\u00b7e", "Zo\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Erstattet bald, nach ihrer Pflicht,", "tokens": ["Er\u00b7stat\u00b7tet", "bald", ",", "nach", "ih\u00b7rer", "Pflicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "An Junons Bett umst\u00e4ndlichen Bericht \u2013", "tokens": ["An", "Ju\u00b7nons", "Bett", "um\u00b7st\u00e4nd\u00b7li\u00b7chen", "Be\u00b7richt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Von allem? \u2013 Nun! das eben nicht!", "tokens": ["Von", "al\u00b7lem", "?", "\u2013", "Nun", "!", "das", "e\u00b7ben", "nicht", "!"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$.", "$(", "ADV", "$.", "ART", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Hingegen wird mit gro\u00dfem Wort-Gepr\u00e4nge", "tokens": ["Hin\u00b7ge\u00b7gen", "wird", "mit", "gro\u00b7\u00dfem", "Wor\u00b7tGe\u00b7pr\u00e4n\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Das stumme Feuer abgemalt,", "tokens": ["Das", "stum\u00b7me", "Feu\u00b7er", "ab\u00b7ge\u00b7malt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Das in Geheim sein z\u00e4rtlich Herz versenge,", "tokens": ["Das", "in", "Ge\u00b7heim", "sein", "z\u00e4rt\u00b7lich", "Herz", "ver\u00b7sen\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "NN", "PPOSAT", "ADJD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Seitdem zum erstenmal die unbegrenzte Menge", "tokens": ["Seit\u00b7dem", "zum", "ers\u00b7ten\u00b7mal", "die", "un\u00b7be\u00b7grenz\u00b7te", "Men\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "APPRART", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Von Junons Reizungen ihm ins Gesicht gestrahlt.", "tokens": ["Von", "Ju\u00b7nons", "Rei\u00b7zun\u00b7gen", "ihm", "ins", "Ge\u00b7sicht", "ge\u00b7strahlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-++-++-+-+", "measure": "unknown.measure.septa"}, "line.12": {"text": "\u00bbes brauchte viele M\u00fch, Madam,", "tokens": ["\u00bb", "es", "brauch\u00b7te", "vie\u00b7le", "M\u00fch", ",", "Ma\u00b7dam", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PIAT", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Ihm sein Geheimnis abzuzwingen,", "tokens": ["Ihm", "sein", "Ge\u00b7heim\u00b7nis", "ab\u00b7zu\u00b7zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Er wand, er kr\u00fcmmte sich, doch mu\u00dft er endlich singen.", "tokens": ["Er", "wand", ",", "er", "kr\u00fcmm\u00b7te", "sich", ",", "doch", "mu\u00dft", "er", "end\u00b7lich", "sin\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PRF", "$,", "ADV", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Das arme Kind! es gl\u00fchte ganz vor Scham;", "tokens": ["Das", "ar\u00b7me", "Kind", "!", "es", "gl\u00fch\u00b7te", "ganz", "vor", "Scham", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "PPER", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Ich denk ich bracht ihn gar zu Tr\u00e4nen.", "tokens": ["Ich", "denk", "ich", "bracht", "ihn", "gar", "zu", "Tr\u00e4\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "PPER", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Ich nannt ihm alle unsre Sch\u00f6nen,", "tokens": ["Ich", "nannt", "ihm", "al\u00b7le", "uns\u00b7re", "Sch\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "\u203aist's Pallas, Cypria, Pomona Ceres?\u2039 \u2013 \u203aNein!\u2039", "tokens": ["\u203a", "ist's", "Pal\u00b7las", ",", "Cyp\u00b7ria", ",", "Po\u00b7mo\u00b7na", "Ce\u00b7res", "?", "\u2039", "\u2013", "\u203a", "Nein", "!", "\u2039"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "punct", "punct", "word", "punct", "punct"], "pos": ["$(", "NE", "NE", "$,", "NE", "$,", "NE", "NE", "$.", "$(", "$(", "$(", "PTKANT", "$.", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.19": {"text": "\u203adiana, Flora, Hebe,\u2039 \u2013 \u203aNein!\u2039", "tokens": ["\u203a", "di\u00b7a\u00b7na", ",", "Flo\u00b7ra", ",", "He\u00b7be", ",", "\u2039", "\u2013", "\u203a", "Nein", "!", "\u2039"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "punct", "punct", "punct", "word", "punct", "punct"], "pos": ["FM", "FM", "$,", "NN", "$,", "NE", "$,", "$(", "$(", "$(", "PTKANT", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "\u203abei Amors Pfeil! So mu\u00df es Juno sein!\u2039", "tokens": ["\u203a", "bei", "A\u00b7mors", "Pfeil", "!", "So", "mu\u00df", "es", "Ju\u00b7no", "sein", "!", "\u2039"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "NE", "NN", "$.", "ADV", "VMFIN", "PPER", "NN", "VAINF", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Hier wurd er bl\u00e4sser als Narzissen,", "tokens": ["Hier", "wurd", "er", "bl\u00e4s\u00b7ser", "als", "Nar\u00b7zis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Und pl\u00f6tzlich wieder Feuer-rot.", "tokens": ["Und", "pl\u00f6tz\u00b7lich", "wie\u00b7der", "Feu\u00b7er\u00b7rot", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Doch ich verschwatze mich, Madam soll das nicht wissen", "tokens": ["Doch", "ich", "ver\u00b7schwat\u00b7ze", "mich", ",", "Ma\u00b7dam", "soll", "das", "nicht", "wis\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$,", "NN", "VMFIN", "PDS", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Sie glauben nicht, wie scharf er mich bedroht.", "tokens": ["Sie", "glau\u00b7ben", "nicht", ",", "wie", "scharf", "er", "mich", "be\u00b7droht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "VVFIN", "PPER", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Er r\u00fchrte mich, ich will es frei gestehn,", "tokens": ["Er", "r\u00fchr\u00b7te", "mich", ",", "ich", "will", "es", "frei", "ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PPER", "VMFIN", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Auch lie\u00df ich ihn nicht trostlos von mir gehn,", "tokens": ["Auch", "lie\u00df", "ich", "ihn", "nicht", "trost\u00b7los", "von", "mir", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PTKNEG", "ADJD", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "Er seufzte gar zu sch\u00f6n! und kurz, das hei\u00df ich lieben!", "tokens": ["Er", "seufz\u00b7te", "gar", "zu", "sch\u00f6n", "!", "und", "kurz", ",", "das", "hei\u00df", "ich", "lie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKA", "ADJD", "$.", "KON", "ADJD", "$,", "PRELS", "ADJD", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "So liebt man nur das erstemal!", "tokens": ["So", "liebt", "man", "nur", "das", "ers\u00b7te\u00b7mal", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ART", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Ich bitte sehr die Lindrung seiner Qual", "tokens": ["Ich", "bit\u00b7te", "sehr", "die", "Lind\u00b7rung", "sei\u00b7ner", "Qual"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "ADV", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Aus Eigensinn nicht l\u00e4nger aufzuschieben.", "tokens": ["Aus", "Ei\u00b7gen\u00b7sinn", "nicht", "l\u00e4n\u00b7ger", "auf\u00b7zu\u00b7schie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKNEG", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.31": {"text": "Was zaudern sie, H\u00e4lt sich der Herr Gemahl", "tokens": ["Was", "zau\u00b7dern", "sie", ",", "H\u00e4lt", "sich", "der", "Herr", "Ge\u00b7mahl"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "$,", "VVFIN", "PRF", "ART", "NN", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.32": {"text": "An sein gegebnes Wort gebunden?", "tokens": ["An", "sein", "ge\u00b7geb\u00b7nes", "Wort", "ge\u00b7bun\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.33": {"text": "Sie irren sehr, er ist aufs neu verschwunden.", "tokens": ["Sie", "ir\u00b7ren", "sehr", ",", "er", "ist", "aufs", "neu", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VAFIN", "APPRART", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.34": {"text": "Ich h\u00f6rt es kaum von einer unsrer Stunden,", "tokens": ["Ich", "h\u00f6rt", "es", "kaum", "von", "ei\u00b7ner", "uns\u00b7rer", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.35": {"text": "Im Vorgemach, die just durchs Fenster sah;", "tokens": ["Im", "Vor\u00b7ge\u00b7mach", ",", "die", "just", "durchs", "Fens\u00b7ter", "sah", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.36": {"text": "Er schlich sich mit Mercur ganz leise", "tokens": ["Er", "schlich", "sich", "mit", "Mer\u00b7cur", "ganz", "lei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "NE", "ADV", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.37": {"text": "Durchs Hinter-T\u00fcrchen auf die Reise;", "tokens": ["Durchs", "Hin\u00b7ter\u00b7T\u00fcr\u00b7chen", "auf", "die", "Rei\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.38": {"text": "Wohin? das wei\u00df man nicht, genug, er ist nicht da.", "tokens": ["Wo\u00b7hin", "?", "das", "wei\u00df", "man", "nicht", ",", "ge\u00b7nug", ",", "er", "ist", "nicht", "da", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "PDS", "VVFIN", "PIS", "PTKNEG", "$,", "ADV", "$,", "PPER", "VAFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Vermutlich wird er itzt, wer wei\u00df in welchen Hecken", "tokens": ["Ver\u00b7mut\u00b7lich", "wird", "er", "itzt", ",", "wer", "wei\u00df", "in", "wel\u00b7chen", "He\u00b7cken"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "ADV", "$,", "PWS", "VVFIN", "APPR", "PWAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Als Truthahn oder Schwan ein neues Ledchen decken.", "tokens": ["Als", "Trut\u00b7hahn", "o\u00b7der", "Schwan", "ein", "neu\u00b7es", "Led\u00b7chen", "de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Was hindert, da\u00df Madam von ihm ein Beispiel nimmt?", "tokens": ["Was", "hin\u00b7dert", ",", "da\u00df", "Ma\u00b7dam", "von", "ihm", "ein", "Bei\u00b7spiel", "nimmt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "NN", "APPR", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Der Tag ist sch\u00f6n, und recht dazu bestimmt", "tokens": ["Der", "Tag", "ist", "sch\u00f6n", ",", "und", "recht", "da\u00b7zu", "be\u00b7stimmt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "KON", "ADJD", "PAV", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.43": {"text": "stillen Freuden wegzuflie\u00dfen.", "tokens": ["stil\u00b7len", "Freu\u00b7den", "weg\u00b7zu\u00b7flie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.44": {"text": "Wie wenn sie sich nach einem kleinen Bad", "tokens": ["Wie", "wenn", "sie", "sich", "nach", "ei\u00b7nem", "klei\u00b7nen", "Bad"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOKOM", "KOUS", "PPER", "PRF", "APPR", "ART", "ADJA", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.45": {"text": "Im Schlummer \u00fcberraschen lie\u00dfen?", "tokens": ["Im", "Schlum\u00b7mer", "\u00fc\u00b7berr\u00b7a\u00b7schen", "lie\u00b7\u00dfen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.46": {"text": "Sie schlafen fest, selbst unter seinen K\u00fcssen;", "tokens": ["Sie", "schla\u00b7fen", "fest", ",", "selbst", "un\u00b7ter", "sei\u00b7nen", "K\u00fcs\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.47": {"text": "Dies muntert auf, man steigt von Grad zu Grad,", "tokens": ["Dies", "mun\u00b7tert", "auf", ",", "man", "steigt", "von", "Grad", "zu", "Grad", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKVZ", "$,", "PIS", "VVFIN", "APPR", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.48": {"text": "Und alles, was Madam dabei zu sorgen hat,", "tokens": ["Und", "al\u00b7les", ",", "was", "Ma\u00b7dam", "da\u00b7bei", "zu", "sor\u00b7gen", "hat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PWS", "NN", "PAV", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Ist, da\u00df sie nicht zu fr\u00fch erwache:", "tokens": ["Ist", ",", "da\u00df", "sie", "nicht", "zu", "fr\u00fch", "er\u00b7wa\u00b7che", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "KOUS", "PPER", "PTKNEG", "PTKA", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.50": {"text": "F\u00fcr seinen Bl\u00f6dsinn wei\u00df ich Rat,", "tokens": ["F\u00fcr", "sei\u00b7nen", "Bl\u00f6d\u00b7sinn", "wei\u00df", "ich", "Rat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.51": {"text": "Ihr Jawort nur! der Rest ist meine Sache!\u00ab", "tokens": ["Ihr", "Ja\u00b7wort", "nur", "!", "der", "Rest", "ist", "mei\u00b7ne", "Sa\u00b7che", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "ADV", "$.", "ART", "NN", "VAFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.32": {"line.1": {"text": "Die G\u00f6ttin nickt ein l\u00e4chelndes Verbot,", "tokens": ["Die", "G\u00f6t\u00b7tin", "nickt", "ein", "l\u00e4\u00b7cheln\u00b7des", "Ver\u00b7bot", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und wird dabei bis an den Busen rot;", "tokens": ["Und", "wird", "da\u00b7bei", "bis", "an", "den", "Bu\u00b7sen", "rot", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PAV", "ADV", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch Iris hat Verstand, und geht mit Ganymeden", "tokens": ["Doch", "I\u00b7ris", "hat", "Ver\u00b7stand", ",", "und", "geht", "mit", "Ga\u00b7ny\u00b7me\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NE", "VAFIN", "NN", "$,", "KON", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was Juno will, und nicht will, abzureden.", "tokens": ["Was", "Ju\u00b7no", "will", ",", "und", "nicht", "will", ",", "ab\u00b7zu\u00b7re\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "NE", "VMFIN", "$,", "KON", "PTKNEG", "VMFIN", "$,", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Der Abend kommt; Frau Juno schleicht ins Bad,", "tokens": ["Der", "A\u00b7bend", "kommt", ";", "Frau", "Ju\u00b7no", "schleicht", "ins", "Bad", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "NN", "NE", "VVFIN", "APPRART", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "L\u00e4\u00dft von den Stunden sich bedienen,", "tokens": ["L\u00e4\u00dft", "von", "den", "Stun\u00b7den", "sich", "be\u00b7die\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und schickt sie weislich, da sie ihnen", "tokens": ["Und", "schickt", "sie", "weis\u00b7lich", ",", "da", "sie", "ih\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PPER", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nichts weiter zu befehlen hat.", "tokens": ["Nichts", "wei\u00b7ter", "zu", "be\u00b7feh\u00b7len", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Nur Iris bleibt, besorgt was n\u00f6tig ist,", "tokens": ["Nur", "I\u00b7ris", "bleibt", ",", "be\u00b7sorgt", "was", "n\u00f6\u00b7tig", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "$,", "VVFIN", "PWS", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "W\u00fcnscht angenehme Ruh und schlie\u00dft", "tokens": ["W\u00fcnscht", "an\u00b7ge\u00b7neh\u00b7me", "Ruh", "und", "schlie\u00dft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADJA", "NN", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Die T\u00fcre zu; vermutlich nur zum Schein;", "tokens": ["Die", "T\u00fc\u00b7re", "zu", ";", "ver\u00b7mut\u00b7lich", "nur", "zum", "Schein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$.", "ADJD", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Denn Ganymed, (wie wir uns sagen lassen)", "tokens": ["Denn", "Ga\u00b7ny\u00b7med", ",", "(", "wie", "wir", "uns", "sa\u00b7gen", "las\u00b7sen", ")"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "$(", "PWAV", "PPER", "PRF", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Kam nicht durchs Schl\u00fcssel-Loch hinein.", "tokens": ["Kam", "nicht", "durchs", "Schl\u00fcs\u00b7sel\u00b7Loch", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Saturnia lag, abgeredter Ma\u00dfen,", "tokens": ["Sa\u00b7tur\u00b7nia", "lag", ",", "ab\u00b7ge\u00b7red\u00b7ter", "Ma\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "In tiefem Schlaf, als er erschien,", "tokens": ["In", "tie\u00b7fem", "Schlaf", ",", "als", "er", "er\u00b7schien", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Vom Bade matt, auf einem Ruhebette,", "tokens": ["Vom", "Ba\u00b7de", "matt", ",", "auf", "ei\u00b7nem", "Ru\u00b7he\u00b7bet\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Ein Liebes-Gott, doch nur von Marmor, schien", "tokens": ["Ein", "Lie\u00b7bes\u00b7Gott", ",", "doch", "nur", "von", "Mar\u00b7mor", ",", "schien"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "ADV", "ADV", "APPR", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Mit k\u00fchner Hand den Vorhang wegzuziehn.", "tokens": ["Mit", "k\u00fch\u00b7ner", "Hand", "den", "Vor\u00b7hang", "weg\u00b7zu\u00b7ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Sie lag in leichten Silber-Flor", "tokens": ["Sie", "lag", "in", "leich\u00b7ten", "Sil\u00b7ber\u00b7Flor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Mit vieler Kunst geh\u00fcllt, und eine Blumen-Kette", "tokens": ["Mit", "vie\u00b7ler", "Kunst", "ge\u00b7h\u00fcllt", ",", "und", "ei\u00b7ne", "Blu\u00b7men\u00b7Ket\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVPP", "$,", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Versteckte halb, was ihr Gewand", "tokens": ["Ver\u00b7steck\u00b7te", "halb", ",", "was", "ihr", "Ge\u00b7wand"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Den Augen noch geg\u00f6nnet h\u00e4tte;", "tokens": ["Den", "Au\u00b7gen", "noch", "ge\u00b7g\u00f6n\u00b7net", "h\u00e4t\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Doch steigt halb unverh\u00fcllt die sch\u00f6ne Brust empor,", "tokens": ["Doch", "steigt", "halb", "un\u00b7ver\u00b7h\u00fcllt", "die", "sch\u00f6\u00b7ne", "Brust", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ADJD", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Dort reizt ein wei\u00dfer Arm, und eine kleine Hand,", "tokens": ["Dort", "reizt", "ein", "wei\u00b7\u00dfer", "Arm", ",", "und", "ei\u00b7ne", "klei\u00b7ne", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Hier ragt ein Knie wie Wachs hervor,", "tokens": ["Hier", "ragt", "ein", "Knie", "wie", "Wachs", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KOKOM", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Und noch was mehr, das wenn er's itzt erblickte", "tokens": ["Und", "noch", "was", "mehr", ",", "das", "wenn", "er's", "itzt", "er\u00b7blick\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PWS", "ADV", "$,", "PRELS", "KOUS", "PIS", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Selbst Jupitern so sehr entz\u00fcckte", "tokens": ["Selbst", "Ju\u00b7pi\u00b7tern", "so", "sehr", "ent\u00b7z\u00fcck\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "NN", "ADV", "ADV", "VVFIN"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.28": {"text": "Als seinen Freund, dem, fast von Lust entseelt,", "tokens": ["Als", "sei\u00b7nen", "Freund", ",", "dem", ",", "fast", "von", "Lust", "ent\u00b7seelt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "PRELS", "$,", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "Das Auge schwimmt, der Atem fehlt.", "tokens": ["Das", "Au\u00b7ge", "schwimmt", ",", "der", "A\u00b7tem", "fehlt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Er wagt's, es wird auf das was ihn entz\u00fcckt", "tokens": ["Er", "wagt's", ",", "es", "wird", "auf", "das", "was", "ihn", "ent\u00b7z\u00fcckt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "APPR", "ART", "PRELS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.31": {"text": "Der feuervollste Ku\u00df gedr\u00fcckt.", "tokens": ["Der", "feu\u00b7er\u00b7volls\u00b7te", "Ku\u00df", "ge\u00b7dr\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Wie zittert er, sie werde dran erwachen!", "tokens": ["Wie", "zit\u00b7tert", "er", ",", "sie", "wer\u00b7de", "dran", "er\u00b7wa\u00b7chen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.33": {"text": "Allein sie schl\u00e4ft zu hart; nur z\u00fccket sie im Schlaf", "tokens": ["Al\u00b7lein", "sie", "schl\u00e4ft", "zu", "hart", ";", "nur", "z\u00fc\u00b7cket", "sie", "im", "Schlaf"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "PTKA", "ADJD", "$.", "ADV", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Den sch\u00f6nen Ort, den seine K\u00fchnheit traf", "tokens": ["Den", "sch\u00f6\u00b7nen", "Ort", ",", "den", "sei\u00b7ne", "K\u00fchn\u00b7heit", "traf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.35": {"text": "Er wird versteckt \u2013 um sch\u00f6nre Sachen", "tokens": ["Er", "wird", "ver\u00b7steckt", "\u2013", "um", "sch\u00f6n\u00b7re", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "$(", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.36": {"text": "Dem trunknen Blick nicht l\u00e4nger zu entziehn.", "tokens": ["Dem", "trunk\u00b7nen", "Blick", "nicht", "l\u00e4n\u00b7ger", "zu", "ent\u00b7ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.37": {"text": "Wer h\u00e4tte hier den Mut zum fliehn?", "tokens": ["Wer", "h\u00e4t\u00b7te", "hier", "den", "Mut", "zum", "fliehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "ART", "NN", "APPRART", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Wen machte nicht ein solcher Anblick k\u00fchn?", "tokens": ["Wen", "mach\u00b7te", "nicht", "ein", "sol\u00b7cher", "An\u00b7blick", "k\u00fchn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "ART", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.39": {"text": "Der J\u00fcngling wird's, und decket sie mit K\u00fcssen.", "tokens": ["Der", "J\u00fcng\u00b7ling", "wird's", ",", "und", "de\u00b7cket", "sie", "mit", "K\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "KON", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.40": {"text": "Nun wird sie wohl erwachen m\u00fcssen!", "tokens": ["Nun", "wird", "sie", "wohl", "er\u00b7wa\u00b7chen", "m\u00fcs\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.41": {"text": "Ihr Schlaf war freilich hart, doch endlich wird sie wach,", "tokens": ["Ihr", "Schlaf", "war", "frei\u00b7lich", "hart", ",", "doch", "end\u00b7lich", "wird", "sie", "wach", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "$,", "ADV", "ADV", "VAFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Und hebt mit einem s\u00fc\u00dfen \u00bbAch!\u00ab", "tokens": ["Und", "hebt", "mit", "ei\u00b7nem", "s\u00fc\u00b7\u00dfen", "\u00bb", "Ach", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "$(", "ITJ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.43": {"text": "Ein irrend Aug \u2013 es wieder zuzuschlie\u00dfen.", "tokens": ["Ein", "ir\u00b7rend", "Aug", "\u2013", "es", "wie\u00b7der", "zu\u00b7zu\u00b7schlie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$(", "PPER", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.44": {"text": "Zum Unstern kam in diesem Augenblick", "tokens": ["Zum", "Uns\u00b7tern", "kam", "in", "die\u00b7sem", "Au\u00b7gen\u00b7blick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.45": {"text": "Herr Jupiter von seiner Fahrt zur\u00fcck.", "tokens": ["Herr", "Ju\u00b7pi\u00b7ter", "von", "sei\u00b7ner", "Fahrt", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.46": {"text": "Der Tag war schw\u00fcl. Sich zu erfrischen,", "tokens": ["Der", "Tag", "war", "schw\u00fcl", ".", "Sich", "zu", "er\u00b7fri\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.47": {"text": "Und w\u00e4r's auch nur von seiner Hoheit Fu\u00df", "tokens": ["Und", "w\u00e4r's", "auch", "nur", "von", "sei\u00b7ner", "Ho\u00b7heit", "Fu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.48": {"text": "Den Staub der Erden abzuwischen,", "tokens": ["Den", "Staub", "der", "Er\u00b7den", "ab\u00b7zu\u00b7wi\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.49": {"text": "Ermuntert ihn Mercurius", "tokens": ["Er\u00b7mun\u00b7tert", "ihn", "Mer\u00b7cu\u00b7rius"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "NE"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.50": {"text": "Dem Bad, aus dem sie noch die D\u00fcnste steigen sehen,", "tokens": ["Dem", "Bad", ",", "aus", "dem", "sie", "noch", "die", "D\u00fcns\u00b7te", "stei\u00b7gen", "se\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "$,", "APPR", "PRELS", "PPER", "ADV", "ART", "NN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "im G\u00f6tter-Garten zuzugehen.", "tokens": ["im", "G\u00f6t\u00b7ter\u00b7Gar\u00b7ten", "zu\u00b7zu\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Sie kommen an \u2013 und Iris sah sie nicht?", "tokens": ["Sie", "kom\u00b7men", "an", "\u2013", "und", "I\u00b7ris", "sah", "sie", "nicht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$(", "KON", "NE", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wo hatte dann das M\u00e4dchen seine Augen?", "tokens": ["Wo", "hat\u00b7te", "dann", "das", "M\u00e4d\u00b7chen", "sei\u00b7ne", "Au\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ADV", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Hier lerne man, was H\u00fcterinnen taugen!", "tokens": ["Hier", "ler\u00b7ne", "man", ",", "was", "H\u00fc\u00b7te\u00b7rin\u00b7nen", "tau\u00b7gen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$,", "PWS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Entzog vielleicht der Schlaf sie ihrer Pflicht?", "tokens": ["Ent\u00b7zog", "viel\u00b7leicht", "der", "Schlaf", "sie", "ih\u00b7rer", "Pflicht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Nichts weniger \u2013 ich will es euch wohl sagen,", "tokens": ["Nichts", "we\u00b7ni\u00b7ger", "\u2013", "ich", "will", "es", "euch", "wohl", "sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "$(", "PPER", "VMFIN", "PPER", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Doch im Vertraun \u2013 der junge Zephyr fand", "tokens": ["Doch", "im", "Ver\u00b7traun", "\u2013", "der", "jun\u00b7ge", "Ze\u00b7phyr", "fand"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "$(", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Das gute Ding, das flei\u00dfig Wache stand,", "tokens": ["Das", "gu\u00b7te", "Ding", ",", "das", "flei\u00b7\u00dfig", "Wa\u00b7che", "stand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADJD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Vor langer Weil an seinen Fingern nagen.", "tokens": ["Vor", "lan\u00b7ger", "Weil", "an", "sei\u00b7nen", "Fin\u00b7gern", "na\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Der junge Zephyr war galant,", "tokens": ["Der", "jun\u00b7ge", "Ze\u00b7phyr", "war", "ga\u00b7lant", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Das M\u00e4dchen h\u00fcbsch, und (ohne sie zu schimpfen)", "tokens": ["Das", "M\u00e4d\u00b7chen", "h\u00fcbsch", ",", "und", "(", "oh\u00b7ne", "sie", "zu", "schimp\u00b7fen", ")"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "KON", "$(", "APPR", "PPER", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Verbuhlt genug \u2013 wir sehn bei diesem Lob", "tokens": ["Ver\u00b7buhlt", "ge\u00b7nug", "\u2013", "wir", "sehn", "bei", "die\u00b7sem", "Lob"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "$(", "PPER", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Sich hundert kleine Nasen r\u00fcmpfen,", "tokens": ["Sich", "hun\u00b7dert", "klei\u00b7ne", "Na\u00b7sen", "r\u00fcmp\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "CARD", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Doch Dichtern liegt die Pflicht der Wahrheit ob.", "tokens": ["Doch", "Dich\u00b7tern", "liegt", "die", "Pflicht", "der", "Wahr\u00b7heit", "ob", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ART", "NN", "ART", "NN", "KOUS", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Genug, der junge Zephyr nahm", "tokens": ["Ge\u00b7nug", ",", "der", "jun\u00b7ge", "Ze\u00b7phyr", "nahm"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Sie bei der Hand, sie schwatzten tausend Sachen,", "tokens": ["Sie", "bei", "der", "Hand", ",", "sie", "schwatz\u00b7ten", "tau\u00b7send", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "$,", "PPER", "VVFIN", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Und setzten sich, vielleicht ein Spiel zu machen,", "tokens": ["Und", "setz\u00b7ten", "sich", ",", "viel\u00b7leicht", "ein", "Spiel", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "$,", "ADV", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Sie wu\u00dfte selbst nicht wie es kam,", "tokens": ["Sie", "wu\u00df\u00b7te", "selbst", "nicht", "wie", "es", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Zuletzt in einem Busche nieder.", "tokens": ["Zu\u00b7letzt", "in", "ei\u00b7nem", "Bu\u00b7sche", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Das war das Ganze! Hin und wieder", "tokens": ["Das", "war", "das", "Gan\u00b7ze", "!", "Hin", "und", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "$.", "NN", "KON", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Mag wohl ein Ku\u00df mit unterloffen sein;", "tokens": ["Mag", "wohl", "ein", "Ku\u00df", "mit", "un\u00b7ter\u00b7lof\u00b7fen", "sein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "APPR", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Doch mehr gestand Mi\u00df Iris niemals ein.", "tokens": ["Doch", "mehr", "ge\u00b7stand", "Mi\u00df", "I\u00b7ris", "nie\u00b7mals", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "NN", "NE", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.34": {"line.1": {"text": "Indes kommt Vater Zeus, und findt die T\u00fcr verschlossen,", "tokens": ["In\u00b7des", "kommt", "Va\u00b7ter", "Zeus", ",", "und", "findt", "die", "T\u00fcr", "ver\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "NE", "$,", "KON", "VVFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dies sagt ihm schon, da\u00df jemand drinnen sei.", "tokens": ["Dies", "sagt", "ihm", "schon", ",", "da\u00df", "je\u00b7mand", "drin\u00b7nen", "sei", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PIS", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Er schleicht, anstatt sie aufzusto\u00dfen,", "tokens": ["Er", "schleicht", ",", "an\u00b7statt", "sie", "auf\u00b7zu\u00b7sto\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUI", "PPER", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Aus Vorwitz oder Sch\u00e4kerei", "tokens": ["Aus", "Vor\u00b7witz", "o\u00b7der", "Sch\u00e4\u00b7ke\u00b7rei"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dem Fenster zu \u2013 der Vorhang war gezogen,", "tokens": ["Dem", "Fens\u00b7ter", "zu", "\u2013", "der", "Vor\u00b7hang", "war", "ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "$(", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Doch h\u00f6rten sie (denn G\u00f6tter h\u00f6ren fein)", "tokens": ["Doch", "h\u00f6r\u00b7ten", "sie", "(", "denn", "G\u00f6t\u00b7ter", "h\u00f6\u00b7ren", "fein", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$(", "KON", "NN", "VVFIN", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ich wei\u00df nicht was, das sie zum Schlu\u00df bewogen,", "tokens": ["Ich", "wei\u00df", "nicht", "was", ",", "das", "sie", "zum", "Schlu\u00df", "be\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PIS", "$,", "PRELS", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Die Dame sei im Bade nicht allein.", "tokens": ["Die", "Da\u00b7me", "sei", "im", "Ba\u00b7de", "nicht", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Das Ding k\u00f6mmt Jupitern nicht gar zu richtig vor,", "tokens": ["Das", "Ding", "k\u00f6mmt", "Ju\u00b7pi\u00b7tern", "nicht", "gar", "zu", "rich\u00b7tig", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "PTKNEG", "ADV", "PTKA", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ihm j\u00fcckts am Vorderhaupt, ihm singt das rechte Ohr,", "tokens": ["Ihm", "j\u00fcckts", "am", "Vor\u00b7der\u00b7haupt", ",", "ihm", "singt", "das", "rech\u00b7te", "Ohr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPRART", "NN", "$,", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und kurz, es steigt ein kleiner Zweifel", "tokens": ["Und", "kurz", ",", "es", "steigt", "ein", "klei\u00b7ner", "Zwei\u00b7fel"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "$,", "PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Aus seiner linken Brust an seine Stirn empor.", "tokens": ["Aus", "sei\u00b7ner", "lin\u00b7ken", "Brust", "an", "sei\u00b7ne", "Stirn", "em\u00b7por", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Er macht sich klein, wie Miltons kleinsten Teufel,", "tokens": ["Er", "macht", "sich", "klein", ",", "wie", "Mil\u00b7tons", "kleins\u00b7ten", "Teu\u00b7fel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "$,", "PWAV", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Schl\u00fcpft in den Saal und sieht in stiller Ruh,", "tokens": ["Schl\u00fcpft", "in", "den", "Saal", "und", "sieht", "in", "stil\u00b7ler", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "KON", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "++-+-+-+-+", "measure": "iambic.penta.spondeus"}, "line.15": {"text": "Wie einem Weisen ziemt, dem sch\u00f6nen Lustspiel zu,", "tokens": ["Wie", "ei\u00b7nem", "Wei\u00b7sen", "ziemt", ",", "dem", "sch\u00f6\u00b7nen", "Lust\u00b7spiel", "zu", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$,", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Was arme Sterbliche in Feur und Flammen setzt,", "tokens": ["Was", "ar\u00b7me", "Sterb\u00b7li\u00b7che", "in", "Feur", "und", "Flam\u00b7men", "setzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Wird oft von G\u00f6ttern kaum des L\u00e4chelns wert gesch\u00e4tzt.", "tokens": ["Wird", "oft", "von", "G\u00f6t\u00b7tern", "kaum", "des", "L\u00e4\u00b7chelns", "wert", "ge\u00b7sch\u00e4tzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "ADV", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Nur wundert ihn, die ungemeine Gaben,", "tokens": ["Nur", "wun\u00b7dert", "ihn", ",", "die", "un\u00b7ge\u00b7mei\u00b7ne", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Die seine liebe Frau bei diesem Anla\u00df zeigt,", "tokens": ["Die", "sei\u00b7ne", "lie\u00b7be", "Frau", "bei", "die\u00b7sem", "An\u00b7la\u00df", "zeigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "APPR", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Noch nie an ihr entdeckt zu haben.", "tokens": ["Noch", "nie", "an", "ihr", "ent\u00b7deckt", "zu", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Sein Wunder, sein Erstaunen steigt;", "tokens": ["Sein", "Wun\u00b7der", ",", "sein", "Er\u00b7stau\u00b7nen", "steigt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Je mehr er sieht, je mehr er h\u00f6ret,", "tokens": ["Je", "mehr", "er", "sieht", ",", "je", "mehr", "er", "h\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "VVFIN", "$,", "ADV", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "So deutlich ward er nie belehret,", "tokens": ["So", "deut\u00b7lich", "ward", "er", "nie", "be\u00b7leh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Wie sehr der \u00e4u\u00dfre Schein betr\u00fcgt.", "tokens": ["Wie", "sehr", "der", "\u00e4u\u00df\u00b7re", "Schein", "be\u00b7tr\u00fcgt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Nachdem er nun mit ihrem Zeitvertreibe", "tokens": ["Nach\u00b7dem", "er", "nun", "mit", "ih\u00b7rem", "Zeit\u00b7ver\u00b7trei\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sich lange was zu gut getan,", "tokens": ["Sich", "lan\u00b7ge", "was", "zu", "gut", "ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "PWS", "PTKA", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So zeigt dem tugendreichen Weibe", "tokens": ["So", "zeigt", "dem", "tu\u00b7gen\u00b7drei\u00b7chen", "Wei\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Donnerschlag des Mannes Ankunft an.", "tokens": ["Ein", "Don\u00b7ner\u00b7schlag", "des", "Man\u00b7nes", "An\u00b7kunft", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ihr erster Augenblick war Schrecken,", "tokens": ["Ihr", "ers\u00b7ter", "Au\u00b7gen\u00b7blick", "war", "Schre\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Doch Junons fassen sich gar bald.", "tokens": ["Doch", "Ju\u00b7nons", "fas\u00b7sen", "sich", "gar", "bald", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PRF", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ein bi\u00dfchen Angst in beiden zu erwecken,", "tokens": ["Ein", "bi\u00df\u00b7chen", "Angst", "in", "bei\u00b7den", "zu", "er\u00b7we\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Erscheint itzt Zeus in eigenster Gestalt.", "tokens": ["Er\u00b7scheint", "itzt", "Zeus", "in", "ei\u00b7gens\u00b7ter", "Ge\u00b7stalt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NE", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "\u00bbgl\u00fcck zu, Madam! was zeigt ihr meinen Blicken?", "tokens": ["\u00bb", "gl\u00fcck", "zu", ",", "Ma\u00b7dam", "!", "was", "zeigt", "ihr", "mei\u00b7nen", "Bli\u00b7cken", "?"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PTKVZ", "$,", "NN", "$.", "PWS", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.10": {"text": "Wir haben, scheint's, uns wenig vorzur\u00fccken,", "tokens": ["Wir", "ha\u00b7ben", ",", "scheint's", ",", "uns", "we\u00b7nig", "vor\u00b7zu\u00b7r\u00fc\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "VVFIN", "$,", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Und eure Tugend, wie ich seh,", "tokens": ["Und", "eu\u00b7re", "Tu\u00b7gend", ",", "wie", "ich", "seh", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Schmilzt, kalt und dauerhaft, wie Schnee,", "tokens": ["Schmilzt", ",", "kalt", "und", "dau\u00b7er\u00b7haft", ",", "wie", "Schnee", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJD", "KON", "ADJD", "$,", "PWAV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "An fremdem Feur in strudelndes Entz\u00fccken?", "tokens": ["An", "frem\u00b7dem", "Feur", "in", "stru\u00b7deln\u00b7des", "Ent\u00b7z\u00fc\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Ihr pochtet noch vor kurzer Zeit", "tokens": ["Ihr", "poch\u00b7tet", "noch", "vor", "kur\u00b7zer", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Auf eure Unbeweglichkeit;", "tokens": ["Auf", "eu\u00b7re", "Un\u00b7be\u00b7weg\u00b7lich\u00b7keit", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Ich h\u00e4tte selbst f\u00fcr euch geschworen!", "tokens": ["Ich", "h\u00e4t\u00b7te", "selbst", "f\u00fcr", "euch", "ge\u00b7schwo\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Kein k\u00e4lter Weib sei nie geboren!", "tokens": ["Kein", "k\u00e4l\u00b7ter", "Weib", "sei", "nie", "ge\u00b7bo\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Allein, Herr Ganymed, mein Kind,", "tokens": ["Al\u00b7lein", ",", "Herr", "Ga\u00b7ny\u00b7med", ",", "mein", "Kind", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "NN", "NE", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Kann besser von der Sache reden;", "tokens": ["Kann", "bes\u00b7ser", "von", "der", "Sa\u00b7che", "re\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Beim Styx! wenn alle meine Leden", "tokens": ["Beim", "Styx", "!", "wenn", "al\u00b7le", "mei\u00b7ne", "Le\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "$.", "KOUS", "PIS", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Nicht gegen euch von Marmor sind,", "tokens": ["Nicht", "ge\u00b7gen", "euch", "von", "Mar\u00b7mor", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "PPER", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "So werde noch in dieser sch\u00f6nen Nacht", "tokens": ["So", "wer\u00b7de", "noch", "in", "die\u00b7ser", "sch\u00f6\u00b7nen", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Silen an meiner statt zum Donnerer gemacht!", "tokens": ["Si\u00b7len", "an", "mei\u00b7ner", "statt", "zum", "Don\u00b7ne\u00b7rer", "ge\u00b7macht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.24": {"text": "Jedoch im Ernst\u00ab \u2013 \u00bb Im Ernst, mein Herr Gemahl", "tokens": ["Je\u00b7doch", "im", "Ernst", "\u00ab", "\u2013", "\u00bb", "Im", "Ernst", ",", "mein", "Herr", "Ge\u00b7mahl"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "APPRART", "NN", "$(", "$(", "$(", "APPRART", "NN", "$,", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Ihr t\u00e4tet wohl, die Predigt hier zu schlie\u00dfen.", "tokens": ["Ihr", "t\u00e4\u00b7tet", "wohl", ",", "die", "Pre\u00b7digt", "hier", "zu", "schlie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "ART", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Ich hoff ihr werdet meine Wahl", "tokens": ["Ich", "hoff", "ihr", "wer\u00b7det", "mei\u00b7ne", "Wahl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Bei kaltem Blut noch selber loben m\u00fcssen.", "tokens": ["Bei", "kal\u00b7tem", "Blut", "noch", "sel\u00b7ber", "lo\u00b7ben", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "ADV", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Sprich, wenn man bitten darf, schickt Ganymedes sich", "tokens": ["Sprich", ",", "wenn", "man", "bit\u00b7ten", "darf", ",", "schickt", "Ga\u00b7ny\u00b7me\u00b7des", "sich"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "$,", "KOUS", "PIS", "VVINF", "VMFIN", "$,", "VVFIN", "NN", "PRF"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.29": {"text": "F\u00fcr mich nicht besser als f\u00fcr dich'", "tokens": ["F\u00fcr", "mich", "nicht", "bes\u00b7ser", "als", "f\u00fcr", "dich'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "PTKNEG", "ADJD", "KOKOM", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Wer von uns kann ihn wohl mit besserm Anstand k\u00fcssen?\u00ab", "tokens": ["Wer", "von", "uns", "kann", "ihn", "wohl", "mit", "bes\u00b7serm", "An\u00b7stand", "k\u00fcs\u00b7sen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "APPR", "PPER", "VMFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "\u00bbmadame\u00ab, versetzt ihr Zeus, \u00bbdie Frag ist \u00fcberlei;", "tokens": ["\u00bb", "ma\u00b7da\u00b7me", "\u00ab", ",", "ver\u00b7setzt", "ihr", "Zeus", ",", "\u00bb", "die", "Frag", "ist", "\u00fc\u00b7berl\u00b7ei", ";"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "$(", "$,", "VVFIN", "PPER", "NE", "$,", "$(", "ART", "NN", "VAFIN", "ADV", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.32": {"text": "Ich sagt euch ja, da\u00df ich hiebei", "tokens": ["Ich", "sagt", "euch", "ja", ",", "da\u00df", "ich", "hie\u00b7bei"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Den Sokrates zum Muster mir erw\u00e4hle,", "tokens": ["Den", "Sok\u00b7ra\u00b7tes", "zum", "Mus\u00b7ter", "mir", "er\u00b7w\u00e4h\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "APPRART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.34": {"text": "Und sch\u00f6ner Knaben sch\u00f6ne Seele", "tokens": ["Und", "sch\u00f6\u00b7ner", "Kna\u00b7ben", "sch\u00f6\u00b7ne", "See\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.35": {"text": "Allein der Gegenstand von meiner Liebe sei \u00ab -", "tokens": ["Al\u00b7lein", "der", "Ge\u00b7gen\u00b7stand", "von", "mei\u00b7ner", "Lie\u00b7be", "sei", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "VAFIN", "$(", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "\u00bbganz gut, mein Herr, es steht euch frei", "tokens": ["\u00bb", "ganz", "gut", ",", "mein", "Herr", ",", "es", "steht", "euch", "frei"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADV", "ADJD", "$,", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.37": {"text": "An ihren Seelen euch nach Herzenslust zu weiden;", "tokens": ["An", "ih\u00b7ren", "See\u00b7len", "euch", "nach", "Her\u00b7zens\u00b7lust", "zu", "wei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Ich g\u00f6nn euch diesen edeln Trieb,", "tokens": ["Ich", "g\u00f6nn", "euch", "die\u00b7sen", "e\u00b7deln", "Trieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.39": {"text": "Und nehme, wie ihr seht, bescheiden,", "tokens": ["Und", "neh\u00b7me", ",", "wie", "ihr", "seht", ",", "be\u00b7schei\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.40": {"text": "Mit ihrem gr\u00f6bern Teil vorlieb.\u00ab", "tokens": ["Mit", "ih\u00b7rem", "gr\u00f6\u00b7bern", "Teil", "vor\u00b7lieb", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}