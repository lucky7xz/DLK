{"dta.poem.1174": {"metadata": {"author": {"name": "Abschatz, Hans Assmann von", "birth": "N.A.", "death": "N.A."}, "title": "Er l\u00e4st sie rathen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1704", "urn": "urn:nbn:de:kobv:b4-200905199889", "language": ["de:0.99"], "booktitle": "Abschatz, Hans Assmann von: Poetische Ubersetzungen und Gedichte. Leipzig, 1704."}, "poem": {"stanza.1": {"line.1": {"text": "Wei\u00df Fillis nicht den Ursprung meiner Plagen?", "tokens": ["Wei\u00df", "Fil\u00b7lis", "nicht", "den", "Ur\u00b7sprung", "mei\u00b7ner", "Pla\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKNEG", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Gegend hier wird mein Ver\u00e4ther seyn:", "tokens": ["Die", "Ge\u00b7gend", "hier", "wird", "mein", "Ve\u00b7r\u00e4t\u00b7her", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Di\u00df Holtz/ die Bach/ die Aue wird dir sagen/", "tokens": ["Di\u00df", "Holtz", "/", "die", "Bach", "/", "die", "Au\u00b7e", "wird", "dir", "sa\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "$(", "ART", "NN", "$(", "ART", "NN", "VAFIN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wie ich bey Tag und Nacht pfleg auszuschreyn", "tokens": ["Wie", "ich", "bey", "Tag", "und", "Nacht", "pfleg", "aus\u00b7zu\u00b7schreyn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "NN", "KON", "NN", "NE", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Die Menge meiner Pein.", "tokens": ["Die", "Men\u00b7ge", "mei\u00b7ner", "Pein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Den stummen Ort nehm ich zu meinem Zeugen/", "tokens": ["Den", "stum\u00b7men", "Ort", "nehm", "ich", "zu", "mei\u00b7nem", "Zeu\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df Liebe mir entz\u00fcndet Brust und Geist.", "tokens": ["Da\u00df", "Lie\u00b7be", "mir", "ent\u00b7z\u00fcn\u00b7det", "Brust", "und", "Geist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Er wei\u00df/ was ich sonst pflege zu verschweigen/", "tokens": ["Er", "wei\u00df", "/", "was", "ich", "sonst", "pfle\u00b7ge", "zu", "ver\u00b7schwei\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PWS", "PPER", "ADV", "VVFIN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Den Feind/ der mich zu qu\u00e4len sich befleisst:", "tokens": ["Den", "Feind", "/", "der", "mich", "zu", "qu\u00e4\u00b7len", "sich", "be\u00b7fleisst", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "PTKZU", "VVINF", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Rath/ ob er Fillis heist!", "tokens": ["Rath", "/", "ob", "er", "Fil\u00b7lis", "heist", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KOUS", "PPER", "NE", "VVFIN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.3": {"line.1": {"text": "Mein Leben ist/ wenn ich bey ihr kan leben/", "tokens": ["Mein", "Le\u00b7ben", "ist", "/", "wenn", "ich", "bey", "ihr", "kan", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "$(", "KOUS", "PPER", "APPR", "PPER", "VMFIN", "VVINF", "$("], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mein Tod/ wenn ich mu\u00df ihre Gegend fliehn.", "tokens": ["Mein", "Tod", "/", "wenn", "ich", "mu\u00df", "ih\u00b7re", "Ge\u00b7gend", "fliehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "KOUS", "PPER", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wilt du auff mein Verhalten Achtung geben/", "tokens": ["Wilt", "du", "auff", "mein", "Ver\u00b7hal\u00b7ten", "Ach\u00b7tung", "ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So kanst du leicht daraus ein Urtheil ziehn/", "tokens": ["So", "kanst", "du", "leicht", "da\u00b7raus", "ein", "Ur\u00b7theil", "ziehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "PAV", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Da\u00df ich dein eigen bin.", "tokens": ["Da\u00df", "ich", "dein", "ei\u00b7gen", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}