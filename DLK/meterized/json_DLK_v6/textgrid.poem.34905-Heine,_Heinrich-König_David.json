{"textgrid.poem.34905": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "K\u00f6nig David", "genre": "verse", "period": "N.A.", "pub_year": 1826, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "L\u00e4chelnd scheidet der Despot,", "tokens": ["L\u00e4\u00b7chelnd", "schei\u00b7det", "der", "Des\u00b7pot", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Denn er wei\u00df, nach seinem Tod", "tokens": ["Denn", "er", "wei\u00df", ",", "nach", "sei\u00b7nem", "Tod"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "$,", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wechselt Willk\u00fcr nur die H\u00e4nde,", "tokens": ["Wech\u00b7selt", "Will\u00b7k\u00fcr", "nur", "die", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "ART", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Und die Knechtschaft hat kein Ende.", "tokens": ["Und", "die", "Knecht\u00b7schaft", "hat", "kein", "En\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Armes Volk! wie Pferd und Farr'n", "tokens": ["Ar\u00b7mes", "Volk", "!", "wie", "Pferd", "und", "Farr'n"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$.", "PWAV", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bleibt es angeschirrt am Karr'n,", "tokens": ["Bleibt", "es", "an\u00b7ge\u00b7schirrt", "am", "Karr'n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVPP", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und der Nacken wird gebrochen,", "tokens": ["Und", "der", "Na\u00b7cken", "wird", "ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der sich nicht bequemt den Jochen.", "tokens": ["Der", "sich", "nicht", "be\u00b7quemt", "den", "Jo\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "PTKNEG", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Sterbend spricht zu Salomo", "tokens": ["Ster\u00b7bend", "spricht", "zu", "Sa\u00b7lo\u00b7mo"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "APPR", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00f6nig David: \u00bbApropos,", "tokens": ["K\u00f6\u00b7nig", "Da\u00b7vid", ":", "\u00bb", "A\u00b7pro\u00b7pos", ","], "token_info": ["word", "word", "punct", "punct", "word", "punct"], "pos": ["NN", "NE", "$.", "$(", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ich Joab dir empfehle,", "tokens": ["Da\u00df", "ich", "Joab", "dir", "emp\u00b7feh\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "PPER", "VVFIN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Einen meiner Gener\u00e4le.", "tokens": ["Ei\u00b7nen", "mei\u00b7ner", "Ge\u00b7ne\u00b7r\u00e4\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Dieser tapfre General", "tokens": ["Die\u00b7ser", "tapf\u00b7re", "Ge\u00b7ne\u00b7ral"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist seit Jahren mir fatal,", "tokens": ["Ist", "seit", "Jah\u00b7ren", "mir", "fa\u00b7tal", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch ich wagte den Verha\u00dften", "tokens": ["Doch", "ich", "wag\u00b7te", "den", "Ver\u00b7ha\u00df\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Niemals ernstlich anzutasten.", "tokens": ["Nie\u00b7mals", "ernst\u00b7lich", "an\u00b7zu\u00b7tas\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Du, mein Sohn, bist fromm und klug,", "tokens": ["Du", ",", "mein", "Sohn", ",", "bist", "fromm", "und", "klug", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$,", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Gottesf\u00fcrchtig, stark genug,", "tokens": ["Got\u00b7tes\u00b7f\u00fcrch\u00b7tig", ",", "stark", "ge\u00b7nug", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und es wird dir leicht gelingen,", "tokens": ["Und", "es", "wird", "dir", "leicht", "ge\u00b7lin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jenen Joab umzubringen.\u00ab", "tokens": ["Je\u00b7nen", "Joab", "um\u00b7zu\u00b7brin\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PDAT", "NN", "VVIZU", "$.", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}}}}