{"dta.poem.18623": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "D ie neuste  A rt zu   compli-  \n mentiren.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1702", "urn": "urn:nbn:de:kobv:b4-200905197766", "language": ["de:0.99"], "booktitle": "Hunold, Christian Friedrich: Die Edle Bem\u00fchung m\u00fcssiger Stunden. Hamburg, 1702."}, "poem": {"stanza.1": {"line.1": {"text": "Die H\u00f6fflichkeit bringt wenig ein/", "tokens": ["Die", "H\u00f6ff\u00b7lich\u00b7keit", "bringt", "we\u00b7nig", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "ART", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das kan Rosander wohl beweisen/", "tokens": ["Das", "kan", "Ro\u00b7san\u00b7der", "wohl", "be\u00b7wei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Er wolte so gef\u00e4llig seyn/", "tokens": ["Er", "wol\u00b7te", "so", "ge\u00b7f\u00e4l\u00b7lig", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und einer Damen Diener heissen;", "tokens": ["Und", "ei\u00b7ner", "Da\u00b7men", "Die\u00b7ner", "heis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Allein Monsieur/ sprach sie hierzu/", "tokens": ["Al\u00b7lein", "Mon\u00b7si\u00b7eur", "/", "sprach", "sie", "hier\u00b7zu", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$(", "VVFIN", "PPER", "PAV", "$("], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.6": {"text": "Will er sich meinen Diener nennen/", "tokens": ["Will", "er", "sich", "mei\u00b7nen", "Die\u00b7ner", "nen\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So putz er mir auch meine Schuh.", "tokens": ["So", "putz", "er", "mir", "auch", "mei\u00b7ne", "Schuh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PPER", "PPER", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das hie\u00df: er soll sich nicht verbrennen.", "tokens": ["Das", "hie\u00df", ":", "er", "soll", "sich", "nicht", "ver\u00b7bren\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$.", "PPER", "VMFIN", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Mortbleu! das war ein scharffer Stich/", "tokens": ["Mort\u00b7bleu", "!", "das", "war", "ein", "scharf\u00b7fer", "Stich", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PDS", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Dr\u00fcm mu\u00df er auf ", "tokens": ["Dr\u00fcm", "mu\u00df", "er", "auf"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "APPR"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.11": {"text": "Theilt sie die A\u0364mbter unter sich/", "tokens": ["Theilt", "sie", "die", "A\u0364mb\u00b7ter", "un\u00b7ter", "sich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "PRF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "So will er ihr eins wieder schencken/", "tokens": ["So", "will", "er", "ihr", "eins", "wie\u00b7der", "schen\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "PIS", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Damit es nun ein jeder wei\u00df/", "tokens": ["Da\u00b7mit", "es", "nun", "ein", "je\u00b7der", "wei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "So putzt er ihr die Schuh/ und sie putzt ihm den St - -.", "tokens": ["So", "putzt", "er", "ihr", "die", "Schuh", "/", "und", "sie", "putzt", "ihm", "den", "St", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "$(", "KON", "PPER", "VVFIN", "PPER", "ART", "NN", "$(", "$(", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}}}}}