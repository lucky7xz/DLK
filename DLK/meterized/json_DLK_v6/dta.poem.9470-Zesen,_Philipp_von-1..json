{"dta.poem.9470": {"metadata": {"author": {"name": "Zesen, Philipp von", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-20684-8", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "So recht! Jhr wohlgetrautes Paar/", "tokens": ["So", "recht", "!", "Ihr", "wohl\u00b7ge\u00b7trau\u00b7tes", "Paar", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es w\u00fcndscht Euch gl\u00fcck der Musen-schaar/", "tokens": ["Es", "w\u00fcnd\u00b7scht", "Euch", "gl\u00fcck", "der", "Mu\u00b7sen\u00b7schaar", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "ART", "NN", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Gantz Bitterfeld erschallet/", "tokens": ["Gantz", "Bit\u00b7ter\u00b7feld", "er\u00b7schal\u00b7let", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Mulda leufft zum Elbenflu\u00df/", "tokens": ["Die", "Mul\u00b7da", "leufft", "zum", "El\u00b7ben\u00b7flu\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df man sich dr\u00fcber wundern mu\u00df/", "tokens": ["Da\u00df", "man", "sich", "dr\u00fc\u00b7ber", "wun\u00b7dern", "mu\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "PAV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie sie vor freuden wallet;", "tokens": ["Wie", "sie", "vor", "freu\u00b7den", "wal\u00b7let", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Jhr sch\u00f6n geth\u00f6n", "tokens": ["Ihr", "sch\u00f6n", "ge\u00b7th\u00f6n"], "token_info": ["word", "word", "word"], "pos": ["PPER", "ADJD", "ADJD"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Cherubienen/ Seraphinen", "tokens": ["Che\u00b7ru\u00b7bie\u00b7nen", "/", "Se\u00b7ra\u00b7phi\u00b7nen"], "token_info": ["word", "punct", "word"], "pos": ["NE", "$(", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Hoch erschwingen/", "tokens": ["Hoch", "er\u00b7schwin\u00b7gen", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.10": {"text": "und dem HErrn ein Dancklied singen.", "tokens": ["und", "dem", "Herrn", "ein", "Danck\u00b7lied", "sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Gleichwie der Perlen-tau verj\u00fcngt", "tokens": ["Gleich\u00b7wie", "der", "Per\u00b7len\u00b7tau", "ver\u00b7j\u00fcngt"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Her aus der Morgenr\u00f6th entspringt/", "tokens": ["Her", "aus", "der", "Mor\u00b7gen\u00b7r\u00f6th", "ent\u00b7springt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gra\u00df/ Laub und Kreuter zieret/", "tokens": ["Gra\u00df", "/", "Laub", "und", "Kreu\u00b7ter", "zie\u00b7ret", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So wird auch zieren Euren Tisch/", "tokens": ["So", "wird", "auch", "zie\u00b7ren", "Eu\u00b7ren", "Tisch", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die kleine Schaar gesund und frisch/", "tokens": ["Die", "klei\u00b7ne", "Schaar", "ge\u00b7sund", "und", "frisch", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn Gott die Lust duplieret.", "tokens": ["Wenn", "Gott", "die", "Lust", "du\u00b7plie\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Ehlich/ fr\u00f6lich/", "tokens": ["Eh\u00b7lich", "/", "fr\u00f6\u00b7lich", "/"], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$(", "ADJD", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "Lebt und schertzet/ liebt und hertzet", "tokens": ["Lebt", "und", "schert\u00b7zet", "/", "liebt", "und", "hert\u00b7zet"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "KON", "VVFIN", "$(", "VVFIN", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Euch in Ehren/", "tokens": ["Euch", "in", "Eh\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.10": {"text": "Da\u00df wir diesen Wundsch vermehren.", "tokens": ["Da\u00df", "wir", "die\u00b7sen", "Wund\u00b7sch", "ver\u00b7meh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDAT", "NN", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Nun gute Nacht und schlafft Euch satt/", "tokens": ["Nun", "gu\u00b7te", "Nacht", "und", "schlafft", "Euch", "satt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "KON", "VVFIN", "PPER", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weil Jhr vielleicht von Liebe matt", "tokens": ["Weil", "Ihr", "viel\u00b7leicht", "von", "Lie\u00b7be", "matt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und lescht die heissen schmertzen/", "tokens": ["und", "lescht", "die", "heis\u00b7sen", "schmert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Himmel gibt Euch seine gunst", "tokens": ["Der", "Him\u00b7mel", "gibt", "Euch", "sei\u00b7ne", "gunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und hatt die keusche Liebes-brunst", "tokens": ["und", "hatt", "die", "keu\u00b7sche", "Lie\u00b7bes\u00b7brunst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Entz\u00fcndt in euren Hertzen.", "tokens": ["Ent\u00b7z\u00fcndt", "in", "eu\u00b7ren", "Hert\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Liebt Euch zugleich/", "tokens": ["Liebt", "Euch", "zu\u00b7gleich", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Lebt in freuden ohne Leiden/", "tokens": ["Lebt", "in", "freu\u00b7den", "oh\u00b7ne", "Lei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "APPR", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Wie wir alle", "tokens": ["Wie", "wir", "al\u00b7le"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "PPER", "PIAT"], "meter": "+-+-", "measure": "trochaic.di"}, "line.10": {"text": "W\u00fcndschen ingesam\u0303t mit schalle!", "tokens": ["W\u00fcnd\u00b7schen", "in\u00b7ge\u00b7sam\u0303t", "mit", "schal\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}