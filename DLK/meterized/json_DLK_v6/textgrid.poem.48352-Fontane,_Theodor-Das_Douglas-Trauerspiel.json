{"textgrid.poem.48352": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Das Douglas-Trauerspiel", "genre": "verse", "period": "N.A.", "pub_year": 1854, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbzu Ro\u00df, Mylord! leg Waffen an", "tokens": ["\u00bb", "zu", "Ro\u00df", ",", "My\u00b7lord", "!", "leg", "Waf\u00b7fen", "an"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["$(", "APPR", "NN", "$,", "NE", "$.", "NE", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und r\u00e4ch' unsres Hauses Schmach;", "tokens": ["Und", "r\u00e4ch'", "uns\u00b7res", "Hau\u00b7ses", "Schmach", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Lord William entf\u00fchrt unsre Tochter \u2013", "tokens": ["Lord", "Wil\u00b7li\u00b7am", "ent\u00b7f\u00fchrt", "uns\u00b7re", "Toch\u00b7ter", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Auf, auf, und den Fl\u00fcchtigen nach.", "tokens": ["Auf", ",", "auf", ",", "und", "den", "Fl\u00fcch\u00b7ti\u00b7gen", "nach", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$,", "PTKVZ", "$,", "KON", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.2": {"line.1": {"text": "Und zu Ro\u00df! meine sieben S\u00f6hne,", "tokens": ["Und", "zu", "Ro\u00df", "!", "mei\u00b7ne", "sie\u00b7ben", "S\u00f6h\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "$.", "PPOSAT", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und hinaus, und hinein in die Nacht,", "tokens": ["Und", "hin\u00b7aus", ",", "und", "hin\u00b7ein", "in", "die", "Nacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "$,", "KON", "ADV", "APPR", "ART", "NN", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Und eurer j\u00fcngsten Schwester", "tokens": ["Und", "eu\u00b7rer", "j\u00fcng\u00b7sten", "Schwes\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Habet besser Acht!\u00ab", "tokens": ["Ha\u00b7bet", "bes\u00b7ser", "Acht", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADJD", "CARD", "$.", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Lady Douglas rief's. Sie fuhren all' auf,", "tokens": ["La\u00b7dy", "Doug\u00b7las", "rie\u00b7f'", "s.", "Sie", "fuh\u00b7ren", "all'", "auf", ","], "token_info": ["word", "word", "word", "abbreviation", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "VVIMP", "PPER", "VVFIN", "PIS", "PTKVZ", "$,"], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Legten Helm und Waffen an:", "tokens": ["Leg\u00b7ten", "Helm", "und", "Waf\u00b7fen", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lord William und Lady Margret,", "tokens": ["Lord", "Wil\u00b7li\u00b7am", "und", "La\u00b7dy", "Marg\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "KON", "NE", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die waren noch kaum von dann.", "tokens": ["Die", "wa\u00b7ren", "noch", "kaum", "von", "dann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "APPR", "ADV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Er hob sie auf ein milchwei\u00df Ro\u00df,", "tokens": ["Er", "hob", "sie", "auf", "ein", "milch\u00b7wei\u00df", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Jagdhorn zu Seiten ihm hing,", "tokens": ["Ein", "Jagd\u00b7horn", "zu", "Sei\u00b7ten", "ihm", "hing", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "PPER", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Einen Apfelschimmel bestieg er selbst,", "tokens": ["Ei\u00b7nen", "Ap\u00b7fel\u00b7schim\u00b7mel", "be\u00b7stieg", "er", "selbst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Und \u00fcber die Heid' es ging.", "tokens": ["Und", "\u00fc\u00b7ber", "die", "Heid'", "es", "ging", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Oft, \u00fcber die linke Schulter hinweg,", "tokens": ["Oft", ",", "\u00fc\u00b7ber", "die", "lin\u00b7ke", "Schul\u00b7ter", "hin\u00b7weg", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Im Reiten er r\u00fcckw\u00e4rts sah,", "tokens": ["Im", "Rei\u00b7ten", "er", "r\u00fcck\u00b7w\u00e4rts", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Den Alten und seine S\u00f6hne", "tokens": ["Den", "Al\u00b7ten", "und", "sei\u00b7ne", "S\u00f6h\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "PPOSAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ansprengen sah er da.", "tokens": ["An\u00b7spren\u00b7gen", "sah", "er", "da", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "\u00bbsteig' ab, steig' ab, liebe Lady mein,", "tokens": ["\u00bb", "steig'", "ab", ",", "steig'", "ab", ",", "lie\u00b7be", "La\u00b7dy", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$,", "VVFIN", "NE", "PPOSAT", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und nimm mein Ro\u00df an die Hand,", "tokens": ["Und", "nimm", "mein", "Ro\u00df", "an", "die", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Deinem Vater und deinen Br\u00fcdern", "tokens": ["Dei\u00b7nem", "Va\u00b7ter", "und", "dei\u00b7nen", "Br\u00fc\u00b7dern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Mu\u00df ich nun halten Stand.\u00ab", "tokens": ["Mu\u00df", "ich", "nun", "hal\u00b7ten", "Stand", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Sie nahm sein Ro\u00df; hernieder rann", "tokens": ["Sie", "nahm", "sein", "Ro\u00df", ";", "her\u00b7nie\u00b7der", "rann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$.", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Keine Tr\u00e4ne auf den Hag,", "tokens": ["Kei\u00b7ne", "Tr\u00e4\u00b7ne", "auf", "den", "Hag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bis neben ihren Br\u00fcdern", "tokens": ["Bis", "ne\u00b7ben", "ih\u00b7ren", "Br\u00fc\u00b7dern"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ihr Vater im Blute lag.", "tokens": ["Ihr", "Va\u00b7ter", "im", "Blu\u00b7te", "lag", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "\u00bbhalt ein, halt ein, Lord William,", "tokens": ["\u00bb", "halt", "ein", ",", "halt", "ein", ",", "Lord", "Wil\u00b7li\u00b7am", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$,", "NN", "NE", "$,"], "meter": "+-+-++-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Deine Streiche treffen zu schwer,", "tokens": ["Dei\u00b7ne", "Strei\u00b7che", "tref\u00b7fen", "zu", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "PTKA", "ADJD", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Ich f\u00e4nde wohl manchen Liebsten noch,", "tokens": ["Ich", "f\u00e4n\u00b7de", "wohl", "man\u00b7chen", "Liebs\u00b7ten", "noch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN", "ADV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Einen Vater nimmermehr.\u00ab", "tokens": ["Ei\u00b7nen", "Va\u00b7ter", "nim\u00b7mer\u00b7mehr", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Sie nahm aus dem Mieder ein wei\u00dfes Tuch", "tokens": ["Sie", "nahm", "aus", "dem", "Mie\u00b7der", "ein", "wei\u00b7\u00dfes", "Tuch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Von niederl\u00e4ndischem Lein,", "tokens": ["Von", "nie\u00b7der\u00b7l\u00e4n\u00b7di\u00b7schem", "Lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Sie wusch ihres Vaters Wunden damit,", "tokens": ["Sie", "wusch", "ih\u00b7res", "Va\u00b7ters", "Wun\u00b7den", "da\u00b7mit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "NN", "PAV", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die waren r\u00f6ter als Wein.", "tokens": ["Die", "wa\u00b7ren", "r\u00f6\u00b7ter", "als", "Wein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "KOKOM", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.10": {"line.1": {"text": "\u00bbnun w\u00e4hle, lieb' Lady, und w\u00e4hle schnell:", "tokens": ["\u00bb", "nun", "w\u00e4h\u00b7le", ",", "lieb'", "La\u00b7dy", ",", "und", "w\u00e4h\u00b7le", "schnell", ":"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "$,", "VVFIN", "NE", "$,", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Willst du gehn oder bleiben, sprich!\u00ab", "tokens": ["Willst", "du", "gehn", "o\u00b7der", "blei\u00b7ben", ",", "sprich", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "KON", "VVINF", "$,", "ADJD", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "\u00bbich will mit dir gehn, ich mu\u00df mit dir gehn,", "tokens": ["\u00bb", "ich", "will", "mit", "dir", "gehn", ",", "ich", "mu\u00df", "mit", "dir", "gehn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "APPR", "PPER", "VVINF", "$,", "PPER", "VMFIN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich habe ja nur noch dich.\u00ab", "tokens": ["Ich", "ha\u00b7be", "ja", "nur", "noch", "dich", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "PPER", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Er hob sie auf ihr milchwei\u00df Ro\u00df,", "tokens": ["Er", "hob", "sie", "auf", "ihr", "milch\u00b7wei\u00df", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf der Heide lag Vollmondschein;", "tokens": ["Auf", "der", "Hei\u00b7de", "lag", "Voll\u00b7mond\u00b7schein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "VVFIN", "NN", "$."], "meter": "+-+-+++-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Seinen Apfelschimmel bestieg er selbst,", "tokens": ["Sei\u00b7nen", "Ap\u00b7fel\u00b7schim\u00b7mel", "be\u00b7stieg", "er", "selbst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Und so ritten sie querfeldein.", "tokens": ["Und", "so", "rit\u00b7ten", "sie", "quer\u00b7fel\u00b7dein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.12": {"line.1": {"text": "Sie ritten feldein bei Mondenschein,", "tokens": ["Sie", "rit\u00b7ten", "feld\u00b7ein", "bei", "Mon\u00b7den\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "NE", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Im Schritt halb, halb im Trab;", "tokens": ["Im", "Schritt", "halb", ",", "halb", "im", "Trab", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "$,", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und als sie kamen an einen Quell,", "tokens": ["Und", "als", "sie", "ka\u00b7men", "an", "ei\u00b7nen", "Quell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da stiegen sie langsam ab.", "tokens": ["Da", "stie\u00b7gen", "sie", "lang\u00b7sam", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.13": {"line.1": {"text": "Sie wollten trinken; vor\u00fcber rann", "tokens": ["Sie", "woll\u00b7ten", "trin\u00b7ken", ";", "vor\u00b7\u00fc\u00b7ber", "rann"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VMFIN", "VVINF", "$.", "ADV", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wie Silber die klare Flut,", "tokens": ["Wie", "Sil\u00b7ber", "die", "kla\u00b7re", "Flut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und als sich Lord William b\u00fcckte,", "tokens": ["Und", "als", "sich", "Lord", "Wil\u00b7li\u00b7am", "b\u00fcck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PRF", "NN", "NE", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Da wurde sie rot von Blut.", "tokens": ["Da", "wur\u00b7de", "sie", "rot", "von", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "APPR", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "\u00bbhalt an, halt an, Lord William,", "tokens": ["\u00bb", "halt", "an", ",", "halt", "an", ",", "Lord", "Wil\u00b7li\u00b7am", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$,", "NN", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Du bist wund bis auf den Tod!\u00ab", "tokens": ["Du", "bist", "wund", "bis", "auf", "den", "Tod", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "ADV", "APPR", "ART", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbes ist mein Scharlachmantel,", "tokens": ["\u00bb", "es", "ist", "mein", "Schar\u00b7lach\u00b7man\u00b7tel", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der scheint im Wasser so rot. \u00ab", "tokens": ["Der", "scheint", "im", "Was\u00b7ser", "so", "rot", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "APPRART", "NN", "ADV", "ADJD", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.15": {"line.1": {"text": "Sie ritten feldein bei Mondenschein,", "tokens": ["Sie", "rit\u00b7ten", "feld\u00b7ein", "bei", "Mon\u00b7den\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "NE", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Im Schritt halb, halb im Trab,", "tokens": ["Im", "Schritt", "halb", ",", "halb", "im", "Trab", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "$,", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und als sie kamen an sein Schlo\u00df,", "tokens": ["Und", "als", "sie", "ka\u00b7men", "an", "sein", "Schlo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da stiegen sie langsam ab.", "tokens": ["Da", "stie\u00b7gen", "sie", "lang\u00b7sam", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "\u00bbsteh' auf, steh' auf, liebe Mutter mein,", "tokens": ["\u00bb", "steh'", "auf", ",", "steh'", "auf", ",", "lie\u00b7be", "Mut\u00b7ter", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$,", "ADJA", "NN", "PPOSAT", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Steh' auf und \u00f6ffne das Tor,", "tokens": ["Steh'", "auf", "und", "\u00f6ff\u00b7ne", "das", "Tor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ich hab' mein Lieb gewonnen,", "tokens": ["Ich", "hab'", "mein", "Lieb", "ge\u00b7won\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und wir halten beide davor.", "tokens": ["Und", "wir", "hal\u00b7ten", "bei\u00b7de", "da\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIS", "PAV", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}}, "stanza.17": {"line.1": {"text": "Und mache mein Bett, liebe Mutter,", "tokens": ["Und", "ma\u00b7che", "mein", "Bett", ",", "lie\u00b7be", "Mut\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und ein zweites dicht daran;", "tokens": ["Und", "ein", "zwei\u00b7tes", "dicht", "da\u00b7ran", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "ADJD", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lady Margret mu\u00df dicht bei mir sein,", "tokens": ["La\u00b7dy", "Marg\u00b7ret", "mu\u00df", "dicht", "bei", "mir", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VMFIN", "ADJD", "APPR", "PPER", "VAINF", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Auf da\u00df ich schlafen kann.\u00ab", "tokens": ["Auf", "da\u00df", "ich", "schla\u00b7fen", "kann", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "KOUS", "PPER", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Lord William starb vor Mitternacht,", "tokens": ["Lord", "Wil\u00b7li\u00b7am", "starb", "vor", "Mit\u00b7ter\u00b7nacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "APPR", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Lady Margret vor Tagesfr\u00fch;", "tokens": ["La\u00b7dy", "Marg\u00b7ret", "vor", "Ta\u00b7ges\u00b7fr\u00fch", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Man trug sie nach Sankt Marien hin,", "tokens": ["Man", "trug", "sie", "nach", "Sankt", "Ma\u00b7ri\u00b7en", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "VVFIN", "NE", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da standen drei Tage sie.", "tokens": ["Da", "stan\u00b7den", "drei", "Ta\u00b7ge", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "CARD", "NN", "PPER", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.19": {"line.1": {"text": "Er wurde begraben im Kirchenschiff", "tokens": ["Er", "wur\u00b7de", "be\u00b7gra\u00b7ben", "im", "Kir\u00b7chen\u00b7schiff"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "APPRART", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Und sie in der Halle vorn,", "tokens": ["Und", "sie", "in", "der", "Hal\u00b7le", "vorn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Eine Rose wuchs aus ihrem Grab,", "tokens": ["Ei\u00b7ne", "Ro\u00b7se", "wuchs", "aus", "ih\u00b7rem", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Aus seinem ein Hagedorn.", "tokens": ["Aus", "sei\u00b7nem", "ein", "Ha\u00b7ge\u00b7dorn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.20": {"line.1": {"text": "Sie wuchsen hoch am Gew\u00f6lb entlang,", "tokens": ["Sie", "wuch\u00b7sen", "hoch", "am", "Ge\u00b7w\u00f6lb", "ent\u00b7lang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Als w\u00e4ren sie gern sich nah,", "tokens": ["Als", "w\u00e4\u00b7ren", "sie", "gern", "sich", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ADV", "PRF", "ADJD", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und jeder sagte: \u00bbZwei Liebende sind's!\u00ab", "tokens": ["Und", "je\u00b7der", "sag\u00b7te", ":", "\u00bb", "Zwei", "Lie\u00b7ben\u00b7de", "sin\u00b7d's", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PIS", "VVFIN", "$.", "$(", "CARD", "NN", "VAFIN", "$.", "$("], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wer sie so wachsen sah.", "tokens": ["Wer", "sie", "so", "wach\u00b7sen", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Bis endlich der schwarze Douglas kam,", "tokens": ["Bis", "end\u00b7lich", "der", "schwar\u00b7ze", "Doug\u00b7las", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Im Herzen Wut und Weh,", "tokens": ["Im", "Her\u00b7zen", "Wut", "und", "Weh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der ri\u00df die beiden Str\u00e4ucher heraus", "tokens": ["Der", "ri\u00df", "die", "bei\u00b7den", "Str\u00e4u\u00b7cher", "he\u00b7raus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "PIAT", "NN", "PTKVZ"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und schleuderte sie in den See.", "tokens": ["Und", "schleu\u00b7der\u00b7te", "sie", "in", "den", "See", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}