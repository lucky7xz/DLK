{"textgrid.poem.31767": {"metadata": {"author": {"name": "Weerth, Georg", "birth": "N.A.", "death": "N.A."}, "title": "5.", "genre": "verse", "period": "N.A.", "pub_year": 1839, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Da klang durch die Berge ein Posthorn hell;", "tokens": ["Da", "klang", "durch", "die", "Ber\u00b7ge", "ein", "Post\u00b7horn", "hell", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "ADJD", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Es klang immer lust'ger und froher.", "tokens": ["Es", "klang", "im\u00b7mer", "lust'\u00b7ger", "und", "fro\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "\u00bbdas ist, ich wette, der Postillon", "tokens": ["\u00bb", "das", "ist", ",", "ich", "wet\u00b7te", ",", "der", "Pos\u00b7til\u00b7lon"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "PDS", "VAFIN", "$,", "PPER", "VVFIN", "$,", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Von Lonjumeau, lieber Herr Soherr!\u00ab", "tokens": ["Von", "Lon\u00b7ju\u00b7mea\u00b7u", ",", "lie\u00b7ber", "Herr", "So\u00b7herr", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NE", "$,", "ADV", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Doch Soherr spitzte sein Ohr und sprach:", "tokens": ["Doch", "So\u00b7herr", "spitz\u00b7te", "sein", "Ohr", "und", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "$."], "meter": "--+---+-+", "measure": "anapaest.init"}, "line.2": {"text": "\u00bbsie irren sich! An den hellen", "tokens": ["\u00bb", "sie", "ir\u00b7ren", "sich", "!", "An", "den", "hel\u00b7len"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "PRF", "$.", "APPR", "ART", "ADJA"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "T\u00f6nen, da h\u00f6r ich, es ist die Post,", "tokens": ["T\u00f6\u00b7nen", ",", "da", "h\u00f6r", "ich", ",", "es", "ist", "die", "Post", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "ART", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Die kommt von der heil'gen Stadt K\u00f6llen!", "tokens": ["Die", "kommt", "von", "der", "heil'\u00b7gen", "Stadt", "K\u00f6l\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "ADJA", "NN", "NE", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.3": {"line.1": {"text": "Die bringt uns die K\u00f6lnische Zeitung.\u00ab \u2013 Und", "tokens": ["Die", "bringt", "uns", "die", "K\u00f6l\u00b7ni\u00b7sche", "Zei\u00b7tung", ".", "\u00ab", "\u2013", "Und"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word"], "pos": ["PDS", "VVFIN", "PPER", "ART", "ADJA", "NN", "$.", "$(", "$(", "KON"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Mein Jubel, der wollte nicht enden.", "tokens": ["Mein", "Ju\u00b7bel", ",", "der", "woll\u00b7te", "nicht", "en\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Und wahrlich, nach zehn Minuten hielt", "tokens": ["Und", "wahr\u00b7lich", ",", "nach", "zehn", "Mi\u00b7nu\u00b7ten", "hielt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "APPR", "CARD", "NN", "VVFIN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ich das teure Blatt in den H\u00e4nden.", "tokens": ["Ich", "das", "teu\u00b7re", "Blatt", "in", "den", "H\u00e4n\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Und freute mich, da\u00df die ehrliche Stadt", "tokens": ["Und", "freu\u00b7te", "mich", ",", "da\u00df", "die", "ehr\u00b7li\u00b7che", "Stadt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Noch steh auf demselben Flecke", "tokens": ["Noch", "steh", "auf", "dem\u00b7sel\u00b7ben", "Fle\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und da\u00df man noch Piesporter trinke daheim", "tokens": ["Und", "da\u00df", "man", "noch", "Pies\u00b7por\u00b7ter", "trin\u00b7ke", "da\u00b7heim"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PIS", "ADV", "NN", "VVFIN", "ADV"], "meter": "-+---+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Zu k\u00f6stlichem Schnepfendrecke.", "tokens": ["Zu", "k\u00f6st\u00b7li\u00b7chem", "Schnep\u00b7fen\u00b7dre\u00b7cke", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Und da\u00df die Bev\u00f6lkrung sich keineswegs", "tokens": ["Und", "da\u00df", "die", "Be\u00b7v\u00f6l\u00b7krung", "sich", "kei\u00b7nes\u00b7wegs"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "PRF", "ADV"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "\u00dcber all ihr Mi\u00dfgeschick h\u00e4rme,", "tokens": ["\u00dc\u00b7ber", "all", "ihr", "Mi\u00df\u00b7ge\u00b7schick", "h\u00e4r\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Ja, da\u00df man f\u00fcr die Soldaten jetzt", "tokens": ["Ja", ",", "da\u00df", "man", "f\u00fcr", "die", "Sol\u00b7da\u00b7ten", "jetzt"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "KOUS", "PIS", "APPR", "ART", "NN", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wie f\u00fcr kleine M\u00e4dchen schw\u00e4rme.", "tokens": ["Wie", "f\u00fcr", "klei\u00b7ne", "M\u00e4d\u00b7chen", "schw\u00e4r\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Und da\u00df die Heuler am Leben noch", "tokens": ["Und", "da\u00df", "die", "Heu\u00b7ler", "am", "Le\u00b7ben", "noch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "APPRART", "NN", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und die W\u00fchler gekrochen zu Kreuze,", "tokens": ["Und", "die", "W\u00fch\u00b7ler", "ge\u00b7kro\u00b7chen", "zu", "Kreu\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVPP", "APPR", "NN", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Da\u00df der Herr Joseph gesund noch \u2013 und obenauf", "tokens": ["Da\u00df", "der", "Herr", "Jo\u00b7se\u00b7ph", "ge\u00b7sund", "noch", "\u2013", "und", "o\u00b7ben\u00b7auf"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "ART", "NN", "NE", "ADJD", "ADV", "$(", "KON", "ADV"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Seine vier literarischen K\u00e4uze.", "tokens": ["Sei\u00b7ne", "vier", "li\u00b7te\u00b7ra\u00b7ri\u00b7schen", "K\u00e4u\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "CARD", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "Da\u00df Herr Levy noch schreibe die Feuilletons,", "tokens": ["Da\u00df", "Herr", "Le\u00b7vy", "noch", "schrei\u00b7be", "die", "Feu\u00b7il\u00b7le\u00b7tons", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "NE", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Da\u00df der Witz des Herrn Wolffers nicht holpre", "tokens": ["Da\u00df", "der", "Witz", "des", "Herrn", "Wolf\u00b7fers", "nicht", "holp\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "NE", "PTKNEG", "VVFIN"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Und da\u00df der Herr Br\u00fcggemann wieder herum", "tokens": ["Und", "da\u00df", "der", "Herr", "Br\u00fcg\u00b7ge\u00b7mann", "wie\u00b7der", "he\u00b7rum"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "NE", "ADV", "PTKVZ"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Auf dem alten Rechtsboden stolpre.", "tokens": ["Auf", "dem", "al\u00b7ten", "Rechts\u00b7bo\u00b7den", "stol\u00b7pre", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}}, "stanza.8": {"line.1": {"text": "Ja, die K\u00f6lnische las ich! Drin annonciert", "tokens": ["Ja", ",", "die", "K\u00f6l\u00b7ni\u00b7sche", "las", "ich", "!", "Drin", "an\u00b7non\u00b7ciert"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PTKANT", "$,", "ART", "NN", "VVFIN", "PPER", "$.", "ADV", "VVFIN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Zitrone und Pumpernickel \u2013", "tokens": ["Zit\u00b7ro\u00b7ne", "und", "Pum\u00b7per\u00b7ni\u00b7ckel", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "In ihren Annoncen ist's, wo sie gibt", "tokens": ["In", "ih\u00b7ren", "An\u00b7non\u00b7cen", "ist's", ",", "wo", "sie", "gibt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "$,", "PWAV", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ihre besten polit'schen Artikel.", "tokens": ["Ih\u00b7re", "bes\u00b7ten", "po\u00b7lit'\u00b7schen", "Ar\u00b7ti\u00b7kel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "ADJA", "NN", "$."], "meter": "+-+--+-+--", "measure": "trochaic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Bescheidenheit ist's, da\u00df stets sie versteckt", "tokens": ["Be\u00b7schei\u00b7den\u00b7heit", "ist's", ",", "da\u00df", "stets", "sie", "ver\u00b7steckt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "$,", "KOUS", "ADV", "PPER", "VVPP"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ihr Bestes nur produzieret \u2013", "tokens": ["Ihr", "Bes\u00b7tes", "nur", "pro\u00b7du\u00b7zie\u00b7ret", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVFIN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Die Rheinische trug es frech auf der Stirn,", "tokens": ["Die", "Rhei\u00b7ni\u00b7sche", "trug", "es", "frech", "auf", "der", "Stirn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Drum ward sie suspendieret.", "tokens": ["Drum", "ward", "sie", "sus\u00b7pen\u00b7die\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.10": {"line.1": {"text": "Die arme Rheinische \u2013 ach! schon tot!", "tokens": ["Die", "ar\u00b7me", "Rhei\u00b7ni\u00b7sche", "\u2013", "ach", "!", "schon", "tot", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ITJ", "$.", "ADV", "ADJD", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Doch wartet: Empor einst r\u00fctteln", "tokens": ["Doch", "war\u00b7tet", ":", "Em\u00b7por", "einst", "r\u00fct\u00b7teln"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "$.", "NE", "ADV", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wird die zur H\u00f6lle Gefahrene sich", "tokens": ["Wird", "die", "zur", "H\u00f6l\u00b7le", "Ge\u00b7fah\u00b7re\u00b7ne", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "APPRART", "NN", "NN", "PRF"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Und keck ihre Locken sch\u00fctteln.", "tokens": ["Und", "keck", "ih\u00b7re", "Lo\u00b7cken", "sch\u00fct\u00b7teln", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Ja, sch\u00fcttelnd ihr ambrosisch Gelock,", "tokens": ["Ja", ",", "sch\u00fct\u00b7telnd", "ihr", "am\u00b7bro\u00b7sisch", "Ge\u00b7lock", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADJD", "PPER", "ADJD", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Wird hoch zu Gerichte sie sitzen:", "tokens": ["Wird", "hoch", "zu", "Ge\u00b7rich\u00b7te", "sie", "sit\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "NN", "PPER", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Zu spielen mit ihrem Donnerkeil", "tokens": ["Zu", "spie\u00b7len", "mit", "ih\u00b7rem", "Don\u00b7ner\u00b7keil"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und mit ihren schlechten Witzen.", "tokens": ["Und", "mit", "ih\u00b7ren", "schlech\u00b7ten", "Wit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}