{"textgrid.poem.52828": {"metadata": {"author": {"name": "Eichrodt, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Der verlorene Sohn", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In dem Land Mesopotamien,", "tokens": ["In", "dem", "Land", "Me\u00b7so\u00b7po\u00b7ta\u00b7mi\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Fruchtbar durch des Euphrat Schlamien,", "tokens": ["Frucht\u00b7bar", "durch", "des", "Eu\u00b7ph\u00b7rat", "Schla\u00b7mi\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NE", "NE", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Lebt' einst, fern von Babylon,", "tokens": ["Lebt'", "einst", ",", "fern", "von", "Ba\u00b7by\u00b7lon", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "ADJD", "APPR", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Damian ein Oekonom.", "tokens": ["Da\u00b7mi\u00b7an", "ein", "O\u00b7e\u00b7ko\u00b7nom", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Ungeheuer reich war selbiger,", "tokens": ["Un\u00b7ge\u00b7heu\u00b7er", "reich", "war", "sel\u00b7bi\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VAFIN", "ADJD", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Hatte tausend K\u00fch und K\u00e4lbiger,", "tokens": ["Hat\u00b7te", "tau\u00b7send", "K\u00fch", "und", "K\u00e4l\u00b7bi\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "CARD", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Pferd und Esel, Schaaf und Rind,", "tokens": ["Pferd", "und", "E\u00b7sel", ",", "Schaaf", "und", "Rind", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und zwei S\u00f6hnlein auch zum Kind.", "tokens": ["Und", "zwei", "S\u00f6hn\u00b7lein", "auch", "zum", "Kind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "ADV", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Kinder gleichen sich nicht allemal,", "tokens": ["Kin\u00b7der", "glei\u00b7chen", "sich", "nicht", "al\u00b7le\u00b7mal", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "PTKNEG", "ADV", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Sagt der weise K\u00f6nig Salemal;", "tokens": ["Sagt", "der", "wei\u00b7se", "K\u00f6\u00b7nig", "Sa\u00b7le\u00b7mal", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "NE", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Ist auch \u00e4hnlich das Gesicht", "tokens": ["Ist", "auch", "\u00e4hn\u00b7lich", "das", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADJD", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gleichen sich die Herzen nicht.", "tokens": ["Glei\u00b7chen", "sich", "die", "Her\u00b7zen", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ART", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Also war auch bei des Damian", "tokens": ["Al\u00b7so", "war", "auch", "bei", "des", "Da\u00b7mi\u00b7an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Zwofach aufgespro\u00dftem Samian", "tokens": ["Zwo\u00b7fach", "auf\u00b7ge\u00b7spro\u00df\u00b7tem", "Sa\u00b7mi\u00b7an"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Aehnlich zwar das Angesicht,", "tokens": ["A\u00b7ehn\u00b7lich", "zwar", "das", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Aber ihre Herzen nicht.", "tokens": ["A\u00b7ber", "ih\u00b7re", "Her\u00b7zen", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Morgens fr\u00fch schon ging der Michael", "tokens": ["Mor\u00b7gens", "fr\u00fch", "schon", "ging", "der", "Mic\u00b7hael"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ADV", "VVFIN", "ART", "NE"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "In das Feld mit seiner Sichael,", "tokens": ["In", "das", "Feld", "mit", "sei\u00b7ner", "Sic\u00b7hael", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "PPOSAT", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Half den Knechten beim Gesch\u00e4ft", "tokens": ["Half", "den", "Knech\u00b7ten", "beim", "Ge\u00b7sch\u00e4ft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "ART", "NN", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und wies auch die M\u00e4gd zurecht.", "tokens": ["Und", "wies", "auch", "die", "M\u00e4gd", "zu\u00b7recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Balzers Muth stand freilich anderweit,", "tokens": ["Bal\u00b7zers", "Muth", "stand", "frei\u00b7lich", "an\u00b7der\u00b7weit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "ADV", "ADV", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Ihm mi\u00dffiel die rauhe Handarbeit,", "tokens": ["Ihm", "mi\u00df\u00b7fiel", "die", "rau\u00b7he", "Hand\u00b7ar\u00b7beit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Der Herr Pfarrer meinte drum:", "tokens": ["Der", "Herr", "Pfar\u00b7rer", "mein\u00b7te", "drum", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Thut ihn auf das Studium!", "tokens": ["Thut", "ihn", "auf", "das", "Stu\u00b7di\u00b7um", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Seine Mutter Athanasia", "tokens": ["Sei\u00b7ne", "Mut\u00b7ter", "A\u00b7tha\u00b7na\u00b7sia"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "NE"], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.2": {"text": "Liebt' ihn ohne Ziel und Ma\u00dfia,", "tokens": ["Liebt'", "ihn", "oh\u00b7ne", "Ziel", "und", "Ma\u00b7\u00dfia", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "KON", "NE", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Hat's beim Vater durchgedr\u00fcckt,", "tokens": ["Hat's", "beim", "Va\u00b7ter", "durch\u00b7ge\u00b7dr\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df er ihn zur Hochschul schickt.", "tokens": ["Da\u00df", "er", "ihn", "zur", "Hoch\u00b7schul", "schickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Man erz\u00e4hlt vom alten Babylon", "tokens": ["Man", "er\u00b7z\u00e4hlt", "vom", "al\u00b7ten", "Ba\u00b7by\u00b7lon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPRART", "ADJA", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Wundersame Pracht und Fabylon,", "tokens": ["Wun\u00b7der\u00b7sa\u00b7me", "Pracht", "und", "Fa\u00b7by\u00b7lon", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Dort schrieb man ihn ein als Fuchs,", "tokens": ["Dort", "schrieb", "man", "ihn", "ein", "als", "Fuchs", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "PTKVZ", "KOKOM", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Doch statt Jus trieb er nur Jux.", "tokens": ["Doch", "statt", "Jus", "trieb", "er", "nur", "Jux", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "VVFIN", "PPER", "ADV", "NE", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.9": {"line.1": {"text": "Und er lebt in dulci Jubilo", "tokens": ["Und", "er", "lebt", "in", "dul\u00b7ci", "Ju\u00b7bi\u00b7lo"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NE", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und in einem ew'gen Nubilo,", "tokens": ["Und", "in", "ei\u00b7nem", "ew'\u00b7gen", "Nu\u00b7bi\u00b7lo", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Wein und Bier wie auch Lik\u00f6r", "tokens": ["Wein", "und", "Bier", "wie", "auch", "Li\u00b7k\u00f6r"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "KOKOM", "ADV", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Trank er t\u00e4glich mehr und m\u00f6hr.", "tokens": ["Trank", "er", "t\u00e4g\u00b7lich", "mehr", "und", "m\u00f6hr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ADV", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Leider aber die Kollegien", "tokens": ["Lei\u00b7der", "a\u00b7ber", "die", "Kol\u00b7le\u00b7gi\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Lie\u00df er g\u00e4nzlich unterwegien,", "tokens": ["Lie\u00df", "er", "g\u00e4nz\u00b7lich", "un\u00b7ter\u00b7we\u00b7gi\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Von dem Babylonier-Corps", "tokens": ["Von", "dem", "Ba\u00b7by\u00b7lo\u00b7ni\u00b7er\u00b7Corps"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Ward er bald der Senior.", "tokens": ["Ward", "er", "bald", "der", "Se\u00b7ni\u00b7or", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "In den G\u00e4rten der Semiramis", "tokens": ["In", "den", "G\u00e4r\u00b7ten", "der", "Se\u00b7mi\u00b7ra\u00b7mis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Spielt' er manchen Schlauch und Bierramis", "tokens": ["Spielt'", "er", "man\u00b7chen", "Schlauch", "und", "Bier\u00b7ra\u00b7mis"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "KON", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Und ergab sich allgemach", "tokens": ["Und", "er\u00b7gab", "sich", "all\u00b7ge\u00b7mach"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Pharao und derlei Sach.", "tokens": ["Pha\u00b7rao", "und", "der\u00b7lei", "Sach", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Auch der Liebe that er huldigen,", "tokens": ["Auch", "der", "Lie\u00b7be", "that", "er", "hul\u00b7di\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Dies bracht' ihn zumeist in Schuldigen", "tokens": ["Dies", "bracht'", "ihn", "zu\u00b7meist", "in", "Schul\u00b7di\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPR", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und der schlimme Zeitvertreib", "tokens": ["Und", "der", "schlim\u00b7me", "Zeit\u00b7ver\u00b7treib"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ruinirt ihm Seel und Leib.", "tokens": ["Ru\u00b7i\u00b7nirt", "ihm", "Seel", "und", "Leib", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "----+-+", "measure": "unknown.measure.di"}}, "stanza.13": {"line.1": {"text": "Endlich war er gar zu liederlich,", "tokens": ["End\u00b7lich", "war", "er", "gar", "zu", "lie\u00b7der\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Seine Bein und H\u00e4nde zitterlich,", "tokens": ["Sei\u00b7ne", "Bein", "und", "H\u00e4n\u00b7de", "zit\u00b7ter\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Und auf seinem Haupte war", "tokens": ["Und", "auf", "sei\u00b7nem", "Haup\u00b7te", "war"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Auch nicht mehr ein einzig Haar.", "tokens": ["Auch", "nicht", "mehr", "ein", "ein\u00b7zig", "Haar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADV", "ART", "ADJD", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.14": {"line.1": {"text": "Sich zu machen zahlungsf\u00e4higer,", "tokens": ["Sich", "zu", "ma\u00b7chen", "zah\u00b7lungs\u00b7f\u00e4\u00b7hi\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKZU", "VVINF", "ADJA", "$,"], "meter": "+-+-+-++-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Kam er an die Manich\u00e4iger,", "tokens": ["Kam", "er", "an", "die", "Ma\u00b7nich\u00b7\u00e4i\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dies hat ihn so weit gebracht,", "tokens": ["Dies", "hat", "ihn", "so", "weit", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da\u00df er aus dem Staub sich macht.", "tokens": ["Da\u00df", "er", "aus", "dem", "Staub", "sich", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "PRF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Da er n\u00e4chtlich schied von Babylon,", "tokens": ["Da", "er", "n\u00e4cht\u00b7lich", "schied", "von", "Ba\u00b7by\u00b7lon", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VVFIN", "APPR", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "War's ihm ziemlich miserabylon,", "tokens": ["Wa\u00b7r's", "ihm", "ziem\u00b7lich", "mi\u00b7se\u00b7ra\u00b7by\u00b7lon", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und er ging hinaus auf's Land,", "tokens": ["Und", "er", "ging", "hin\u00b7aus", "auf's", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wurde ein Kom\u00f6diant.", "tokens": ["Wur\u00b7de", "ein", "Ko\u00b7m\u00f6\u00b7di\u00b7ant", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Jetzt als Priester von der Thalia,", "tokens": ["Jetzt", "als", "Pries\u00b7ter", "von", "der", "Tha\u00b7lia", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "NN", "APPR", "ART", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Trieb er allerlei Skandalia,", "tokens": ["Trieb", "er", "al\u00b7ler\u00b7lei", "Skan\u00b7da\u00b7lia", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Zog von Dorf zu Dorf herum", "tokens": ["Zog", "von", "Dorf", "zu", "Dorf", "he\u00b7rum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "APPR", "NN", "APZR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und entsetzt das Publikum.", "tokens": ["Und", "ent\u00b7setzt", "das", "Pub\u00b7li\u00b7kum", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Schweinepriester war er immerdar,", "tokens": ["Schwei\u00b7ne\u00b7pries\u00b7ter", "war", "er", "im\u00b7mer\u00b7dar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und ein schlaues Frauenzimmer war,", "tokens": ["Und", "ein", "schlau\u00b7es", "Frau\u00b7en\u00b7zim\u00b7mer", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Wenn er sich zu fassen schien,", "tokens": ["Wenn", "er", "sich", "zu", "fas\u00b7sen", "schien", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Immer wieder sein Ruin.", "tokens": ["Im\u00b7mer", "wie\u00b7der", "sein", "Ru\u00b7in", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Da geschah zu seiner L\u00e4uterung", "tokens": ["Da", "ge\u00b7schah", "zu", "sei\u00b7ner", "L\u00e4u\u00b7te\u00b7rung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Eine gro\u00dfe Noth und Theuerung,", "tokens": ["Ei\u00b7ne", "gro\u00b7\u00dfe", "Noth", "und", "Theu\u00b7e\u00b7rung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Eine Vieh- und Menschenplag'", "tokens": ["Ei\u00b7ne", "Vieh", "und", "Men\u00b7schen\u00b7plag'"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "TRUNC", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie man's kaum gedenken mag.", "tokens": ["Wie", "man's", "kaum", "ge\u00b7den\u00b7ken", "mag."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["PWAV", "PIS", "ADV", "VVINF", "VMFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.19": {"line.1": {"text": "Niemand ging mehr in Kom\u00f6dien,", "tokens": ["Nie\u00b7mand", "ging", "mehr", "in", "Ko\u00b7m\u00f6\u00b7di\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und sein letztes Hemde fl\u00f6digen,", "tokens": ["Und", "sein", "letz\u00b7tes", "Hem\u00b7de", "fl\u00f6\u00b7di\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Als ein Schwein", "tokens": ["Als", "ein", "Schwein"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Trebern, wie die Schweine thun.", "tokens": ["Tre\u00b7bern", ",", "wie", "die", "Schwei\u00b7ne", "thun", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Solche Kost kann nicht wohl s\u00e4ttigen,", "tokens": ["Sol\u00b7che", "Kost", "kann", "nicht", "wohl", "s\u00e4t\u00b7ti\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Mager bald wie ein Skelettigen,", "tokens": ["Ma\u00b7ger", "bald", "wie", "ein", "Ske\u00b7let\u00b7ti\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "KOKOM", "ART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Sehnt nach Hause sich sein Geist", "tokens": ["Sehnt", "nach", "Hau\u00b7se", "sich", "sein", "Geist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "PRF", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Zu des Vaters Hammelfleisch.", "tokens": ["Zu", "des", "Va\u00b7ters", "Ham\u00b7mel\u00b7fleisch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Und er wandert mit Geschwindigkeit,", "tokens": ["Und", "er", "wan\u00b7dert", "mit", "Ge\u00b7schwin\u00b7dig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Tief bereuend seine S\u00fcndigkeit,", "tokens": ["Tief", "be\u00b7reu\u00b7end", "sei\u00b7ne", "S\u00fcn\u00b7dig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Ohne Str\u00fcmpfe, Hemd und Hut,", "tokens": ["Oh\u00b7ne", "Str\u00fcmp\u00b7fe", ",", "Hemd", "und", "Hut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Fort nach seines Vaters Gut.", "tokens": ["Fort", "nach", "sei\u00b7nes", "Va\u00b7ters", "Gut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Da man's Vieh zu Mittag tr\u00e4nkete,", "tokens": ["Da", "man's", "Vieh", "zu", "Mit\u00b7tag", "tr\u00e4n\u00b7ke\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Damian an gar nichts denkete,", "tokens": ["Da\u00b7mi\u00b7an", "an", "gar", "nichts", "den\u00b7ke\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "In der K\u00fcch' die Mutter war,", "tokens": ["In", "der", "K\u00fc\u00b7ch'", "die", "Mut\u00b7ter", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sieh da kommt der Balthasar.", "tokens": ["Sieh", "da", "kommt", "der", "Balt\u00b7ha\u00b7sar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Ei du Strolch und Erzlumpazius,", "tokens": ["Ei", "du", "Strolch", "und", "Erz\u00b7lum\u00b7pa\u00b7zius", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NN", "KON", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Galgenstrick und Hauptkujazius,", "tokens": ["Gal\u00b7gen\u00b7strick", "und", "Haupt\u00b7ku\u00b7ja\u00b7zius", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Welcher Wind f\u00fchrt dich in's Reich,", "tokens": ["Wel\u00b7cher", "Wind", "f\u00fchrt", "dich", "in's", "Reich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ei, wo ist mein Farrenschweif?", "tokens": ["Ei", ",", "wo", "ist", "mein", "Far\u00b7ren\u00b7schweif", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Balthasar warf sich auf's Esterich:", "tokens": ["Balt\u00b7ha\u00b7sar", "warf", "sich", "auf's", "Es\u00b7te\u00b7rich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "APPRART", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Hau' nur zu, denn ich trieb's l\u00e4sterig!", "tokens": ["Hau'", "nur", "zu", ",", "denn", "ich", "trie\u00b7b's", "l\u00e4s\u00b7te\u00b7rig", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKVZ", "$,", "KON", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch die Mutter kommt, zum Gl\u00fcck,", "tokens": ["Doch", "die", "Mut\u00b7ter", "kommt", ",", "zum", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$,", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und der Vater weicht zur\u00fcck.", "tokens": ["Und", "der", "Va\u00b7ter", "weicht", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Und in hei\u00dfen Thr\u00e4nen bitterlich", "tokens": ["Und", "in", "hei\u00b7\u00dfen", "Thr\u00e4\u00b7nen", "bit\u00b7ter\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "ADJD"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Klaget laut das gute M\u00fctterlich,", "tokens": ["Kla\u00b7get", "laut", "das", "gu\u00b7te", "M\u00fct\u00b7ter\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "K\u00fc\u00dft' ihn und ruft ohne End':", "tokens": ["K\u00fc\u00dft'", "ihn", "und", "ruft", "oh\u00b7ne", "End'", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KON", "VVFIN", "APPR", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.4": {"text": "Ach, mein Balzer, mein Student!", "tokens": ["Ach", ",", "mein", "Bal\u00b7zer", ",", "mein", "Stu\u00b7dent", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.26": {"line.1": {"text": "Und der Vater alsbald umgewandt", "tokens": ["Und", "der", "Va\u00b7ter", "als\u00b7bald", "um\u00b7ge\u00b7wandt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV", "VVPP"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Hat zu allen Nachbarn 'rumgesandt,", "tokens": ["Hat", "zu", "al\u00b7len", "Nach\u00b7barn", "'r\u00b7um\u00b7ge\u00b7sandt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIAT", "NN", "NE", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Und zur gro\u00dfen Gasterei", "tokens": ["Und", "zur", "gro\u00b7\u00dfen", "Gas\u00b7te\u00b7rei"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Seinen Sohn bekleidet neu.", "tokens": ["Sei\u00b7nen", "Sohn", "be\u00b7klei\u00b7det", "neu", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Um den Mondschein zu beseitigen", "tokens": ["Um", "den", "Mond\u00b7schein", "zu", "be\u00b7sei\u00b7ti\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUI", "ART", "NN", "PTKZU", "VVINF"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Seines Sch\u00e4dels f\u00fcr den Heutigen,", "tokens": ["Sei\u00b7nes", "Sch\u00e4\u00b7dels", "f\u00fcr", "den", "Heu\u00b7ti\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Mu\u00dft' ein altes Handschuhpaar", "tokens": ["Mu\u00dft'", "ein", "al\u00b7tes", "Hand\u00b7schuh\u00b7paar"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lassen seines Pelzes Haar.", "tokens": ["Las\u00b7sen", "sei\u00b7nes", "Pel\u00b7zes", "Haar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Sp\u00e4t kam, als der Abend d\u00e4mmerte,", "tokens": ["Sp\u00e4t", "kam", ",", "als", "der", "A\u00b7bend", "d\u00e4m\u00b7mer\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Michel heim vom Feld und j\u00e4mmerte,", "tokens": ["Mi\u00b7chel", "heim", "vom", "Feld", "und", "j\u00e4m\u00b7mer\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "APPRART", "NN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Weil Musik er h\u00f6rt' und Tanz,", "tokens": ["Weil", "Mu\u00b7sik", "er", "h\u00f6rt'", "und", "Tanz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "VVFIN", "KON", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sparsam war er gar und ganz.", "tokens": ["Spar\u00b7sam", "war", "er", "gar", "und", "ganz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "ADV", "KON", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Euer Bruder kam, der Balthasar,", "tokens": ["Eu\u00b7er", "Bru\u00b7der", "kam", ",", "der", "Balt\u00b7ha\u00b7sar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Darum tanzen sie den Waltasar,", "tokens": ["Da\u00b7rum", "tan\u00b7zen", "sie", "den", "Wal\u00b7ta\u00b7sar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Haben auch ein Kalb gemetzt;", "tokens": ["Ha\u00b7ben", "auch", "ein", "Kalb", "ge\u00b7metzt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hat ihm drauf ein Knecht versetzt.", "tokens": ["Hat", "ihm", "drauf", "ein", "Knecht", "ver\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PAV", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Zornig stampfte da der Michael;", "tokens": ["Zor\u00b7nig", "stampf\u00b7te", "da", "der", "Mic\u00b7hael", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ART", "NE", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Knecht' und M\u00e4gd' und das Gefl\u00fcchael", "tokens": ["Knecht'", "und", "M\u00e4gd'", "und", "das", "Ge\u00b7fl\u00fcch\u00b7ael"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "KON", "NN", "KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Flohen hocherschreckt in's Haus,", "tokens": ["Flo\u00b7hen", "ho\u00b7cher\u00b7schreckt", "in's", "Haus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und der Vater trat heraus.", "tokens": ["Und", "der", "Va\u00b7ter", "trat", "he\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Micheln wieder zu beg\u00fctigen,", "tokens": ["Mi\u00b7cheln", "wie\u00b7der", "zu", "be\u00b7g\u00fc\u00b7ti\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Trat er schmunzelnd zu dem W\u00fcthigen,", "tokens": ["Trat", "er", "schmun\u00b7zelnd", "zu", "dem", "W\u00fct\u00b7hi\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Redet ihm in's Herz gelind:", "tokens": ["Re\u00b7det", "ihm", "in's", "Herz", "ge\u00b7lind", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Komm herein und sei kein Kind!", "tokens": ["Komm", "her\u00b7ein", "und", "sei", "kein", "Kind", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VAFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Komm herein und tanz den Schottischen", "tokens": ["Komm", "her\u00b7ein", "und", "tanz", "den", "Schot\u00b7ti\u00b7schen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKVZ", "KON", "ADV", "ART", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Mit des Jakobs rothem Lottichen,", "tokens": ["Mit", "des", "Ja\u00b7kobs", "ro\u00b7them", "Lot\u00b7ti\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "ADJA", "NN", "$,"], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Zwanzigtausend bringt sie mit,", "tokens": ["Zwan\u00b7zig\u00b7tau\u00b7send", "bringt", "sie", "mit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wirb um sie, weil ich dich bitt'.", "tokens": ["Wirb", "um", "sie", ",", "weil", "ich", "dich", "bitt'", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "APPR", "PPER", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Geb' dir gleichfalls soviel Baaria,", "tokens": ["Geb'", "dir", "gleich\u00b7falls", "so\u00b7viel", "Baa\u00b7ria", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PIAT", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Aber la\u00df die Larifaria,", "tokens": ["A\u00b7ber", "la\u00df", "die", "La\u00b7ri\u00b7fa\u00b7ria", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "ART", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Geb' das halbe Gut dir gleich,", "tokens": ["Geb'", "das", "hal\u00b7be", "Gut", "dir", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber komm herein und schweig!", "tokens": ["A\u00b7ber", "komm", "her\u00b7ein", "und", "schweig", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Komm herein und la\u00df dich s\u00e4nftigen,", "tokens": ["Komm", "her\u00b7ein", "und", "la\u00df", "dich", "s\u00e4nf\u00b7ti\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Spiele nicht den Unvern\u00e4nftigen,", "tokens": ["Spie\u00b7le", "nicht", "den", "Un\u00b7ver\u00b7n\u00e4nf\u00b7ti\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Freu dich, weil der Herr Student,", "tokens": ["Freu", "dich", ",", "weil", "der", "Herr", "Stu\u00b7dent", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Wiederum zu Hause send!", "tokens": ["Wie\u00b7de\u00b7rum", "zu", "Hau\u00b7se", "send", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}