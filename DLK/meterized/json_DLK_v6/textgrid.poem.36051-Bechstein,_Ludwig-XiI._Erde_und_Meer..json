{"textgrid.poem.36051": {"metadata": {"author": {"name": "Bechstein, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "XiI. Erde und Meer.", "genre": "verse", "period": "N.A.", "pub_year": 1830, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Des Fr\u00fchlings warmer Odem weht \u00fcbers weisse Land,", "tokens": ["Des", "Fr\u00fch\u00b7lings", "war\u00b7mer", "O\u00b7dem", "weht", "\u00fc\u00b7bers", "weis\u00b7se", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da l\u00f6s't sich von den Str\u00f6men des starren Eises Band.", "tokens": ["Da", "l\u00f6s't", "sich", "von", "den", "Str\u00f6\u00b7men", "des", "star\u00b7ren", "Ei\u00b7ses", "Band", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "ART", "NN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da gr\u00fcnen neu die Matten, da knospet Baum und Strauch,", "tokens": ["Da", "gr\u00fc\u00b7nen", "neu", "die", "Mat\u00b7ten", ",", "da", "knos\u00b7pet", "Baum", "und", "Strauch", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "ART", "NN", "$,", "ADV", "VVFIN", "NE", "KON", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Erwachen tausend Schl\u00e4fer vom lebenvollen Hauch.", "tokens": ["Er\u00b7wa\u00b7chen", "tau\u00b7send", "Schl\u00e4\u00b7fer", "vom", "le\u00b7ben\u00b7vol\u00b7len", "Hauch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "Doch wie dem Leben immer der Tod zur Seite geht,", "tokens": ["Doch", "wie", "dem", "Le\u00b7ben", "im\u00b7mer", "der", "Tod", "zur", "Sei\u00b7te", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ADV", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-++-+-+-+", "measure": "unknown.measure.septa"}, "line.2": {"text": "Und um den Tag der Freude mit dunklem Fl\u00fcgel weht,", "tokens": ["Und", "um", "den", "Tag", "der", "Freu\u00b7de", "mit", "dunk\u00b7lem", "Fl\u00fc\u00b7gel", "weht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "So zieht auch mit dem Lenze Verderben wild heran,", "tokens": ["So", "zieht", "auch", "mit", "dem", "Len\u00b7ze", "Ver\u00b7der\u00b7ben", "wild", "he\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "ART", "NN", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und rollt in Stromeswellen, und brauset im Orkan.", "tokens": ["Und", "rollt", "in", "Stro\u00b7mes\u00b7wel\u00b7len", ",", "und", "brau\u00b7set", "im", "Or\u00b7kan", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$,", "KON", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Und k\u00fcndet Krieg den H\u00fctten, wirft Br\u00fccken in den Grund;", "tokens": ["Und", "k\u00fcn\u00b7det", "Krieg", "den", "H\u00fct\u00b7ten", ",", "wirft", "Br\u00fc\u00b7cken", "in", "den", "Grund", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "ART", "NN", "$,", "VVFIN", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Verzweiflungsruf thut heulend die Noth, die grosse, kund.", "tokens": ["Ver\u00b7zwei\u00b7flungs\u00b7ruf", "thut", "heu\u00b7lend", "die", "Noth", ",", "die", "gros\u00b7se", ",", "kund", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "ART", "NN", "$,", "ART", "ADJA", "$,", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Die finstern Wogen rollen, brausend in dunkler Nacht;", "tokens": ["Die", "fins\u00b7tern", "Wo\u00b7gen", "rol\u00b7len", ",", "brau\u00b7send", "in", "dunk\u00b7ler", "Nacht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Des Eises scharfe Schollen sind ihre Heeresmacht.", "tokens": ["Des", "Ei\u00b7ses", "schar\u00b7fe", "Schol\u00b7len", "sind", "ih\u00b7re", "Hee\u00b7res\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Das Ungl\u00fcck wird zum Schauspiel, und jeder eilt hinaus;", "tokens": ["Das", "Un\u00b7gl\u00fcck", "wird", "zum", "Schau\u00b7spiel", ",", "und", "je\u00b7der", "eilt", "hin\u00b7aus", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "$,", "KON", "PIS", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Drei M\u00e4nner stehn von ferne, hinblickend nach dem Graus.", "tokens": ["Drei", "M\u00e4n\u00b7ner", "stehn", "von", "fer\u00b7ne", ",", "hin\u00b7bli\u00b7ckend", "nach", "dem", "Graus", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "APPR", "ADJA", "$,", "VVPP", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u00bbgross ist,\u00ab beginnt der Eine: \u00bbNatur, Dein hoher Gang,", "tokens": ["\u00bb", "gross", "ist", ",", "\u00ab", "be\u00b7ginnt", "der", "Ei\u00b7ne", ":", "\u00bb", "Na\u00b7tur", ",", "Dein", "ho\u00b7her", "Gang", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "$,", "$(", "VVFIN", "ART", "NN", "$.", "$(", "NN", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Er heisse Fr\u00fchlingss\u00e4useln, er heisse Wogendrang!\u00ab", "tokens": ["Er", "heis\u00b7se", "Fr\u00fch\u00b7lings\u00b7s\u00e4u\u00b7seln", ",", "er", "heis\u00b7se", "Wo\u00b7gen\u00b7drang", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "PPER", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "\u00bbja, Herr!\u00ab spricht drauf der Zweite bescheiden: \u00bbWunderbar!", "tokens": ["\u00bb", "ja", ",", "Herr", "!", "\u00ab", "spricht", "drauf", "der", "Zwei\u00b7te", "be\u00b7schei\u00b7den", ":", "\u00bb", "Wun\u00b7der\u00b7bar", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "NN", "$.", "$(", "VVFIN", "PAV", "ART", "ADJA", "VVINF", "$.", "$(", "NN", "$."], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Wir nehmen hier den Weltgeist in seinen Werken wahr.", "tokens": ["Wir", "neh\u00b7men", "hier", "den", "Welt\u00b7geist", "in", "sei\u00b7nen", "Wer\u00b7ken", "wahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und mehr ergreift's die Seele, wenn wir ihn z\u00fcrnen sehn,", "tokens": ["Und", "mehr", "er\u00b7greift's", "die", "See\u00b7le", ",", "wenn", "wir", "ihn", "z\u00fcr\u00b7nen", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "$,", "KOUS", "PPER", "PPER", "VVINF", "VVINF", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Als wenn von seinem L\u00e4cheln die Bl\u00fcmlein auferstehn!\u00ab", "tokens": ["Als", "wenn", "von", "sei\u00b7nem", "L\u00e4\u00b7cheln", "die", "Bl\u00fcm\u00b7lein", "auf\u00b7er\u00b7stehn", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "KOUS", "APPR", "PPOSAT", "NN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Und d\u00fcster spricht der Dritte: \u00bbWas Euch das Herz bewegt,", "tokens": ["Und", "d\u00fcs\u00b7ter", "spricht", "der", "Drit\u00b7te", ":", "\u00bb", "Was", "Euch", "das", "Herz", "be\u00b7wegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "ART", "NN", "$.", "$(", "PWS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Das Herz, vom kleinsten Anlass zum Springen aufgeregt,", "tokens": ["Das", "Herz", ",", "vom", "kleins\u00b7ten", "An\u00b7lass", "zum", "Sprin\u00b7gen", "auf\u00b7ge\u00b7regt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPRART", "ADJA", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Das geht an mir vor\u00fcber, ich sehe nichts erneut;", "tokens": ["Das", "geht", "an", "mir", "vor\u00b7\u00fc\u00b7ber", ",", "ich", "se\u00b7he", "nichts", "er\u00b7neut", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PPER", "PTKVZ", "$,", "PPER", "VVFIN", "PIS", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Vor mehr denn tausend Jahren war's eben so, wie heut.\u00ab", "tokens": ["Vor", "mehr", "denn", "tau\u00b7send", "Jah\u00b7ren", "wa\u00b7r's", "e\u00b7ben", "so", ",", "wie", "heut", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPR", "ADV", "ADV", "CARD", "NN", "VAFIN", "ADV", "ADV", "$,", "PWAV", "ADV", "$.", "$("], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.7": {"line.1": {"text": "Drauf Faustus zum Begleiter, dem H\u00f6hnenden, gewandt:", "tokens": ["Drauf", "Faus\u00b7tus", "zum", "Be\u00b7glei\u00b7ter", ",", "dem", "H\u00f6h\u00b7nen\u00b7den", ",", "ge\u00b7wandt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PAV", "NE", "APPRART", "NN", "$,", "ART", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbist Dir der Dinge Werden vom Anbeginn bekannt,", "tokens": ["\u00bb", "ist", "Dir", "der", "Din\u00b7ge", "Wer\u00b7den", "vom", "An\u00b7be\u00b7ginn", "be\u00b7kannt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "ART", "NN", "VAFIN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "So gieb uns dess Belehrung, wir bitten Dich gar sehr!", "tokens": ["So", "gieb", "uns", "dess", "Be\u00b7leh\u00b7rung", ",", "wir", "bit\u00b7ten", "Dich", "gar", "sehr", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ART", "NN", "$,", "PPER", "VVFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wie sind die Berge worden? Wie wurden Land und Meer?\u00ab", "tokens": ["Wie", "sind", "die", "Ber\u00b7ge", "wor\u00b7den", "?", "Wie", "wur\u00b7den", "Land", "und", "Meer", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "VAPP", "$.", "PWAV", "VAFIN", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.8": {"line.1": {"text": "Da zieht Mephisto h\u00f6hnisch in Falten das Gesicht,", "tokens": ["Da", "zieht", "Me\u00b7phis\u00b7to", "h\u00f6h\u00b7nisch", "in", "Fal\u00b7ten", "das", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "ADJD", "APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und neigt sich bis zur Erde vorm Frager, eh' er spricht.", "tokens": ["Und", "neigt", "sich", "bis", "zur", "Er\u00b7de", "vorm", "Fra\u00b7ger", ",", "eh'", "er", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "APPRART", "NN", "APPRART", "NN", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Wie Wetterleuchten loht es in seiner Augen Stern,", "tokens": ["Wie", "Wet\u00b7ter\u00b7leuch\u00b7ten", "loht", "es", "in", "sei\u00b7ner", "Au\u00b7gen", "Stern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und unwillkommen ist ihm der Wille seines Herrn.", "tokens": ["Und", "un\u00b7will\u00b7kom\u00b7men", "ist", "ihm", "der", "Wil\u00b7le", "sei\u00b7nes", "Herrn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.9": {"line.1": {"text": "\u00bbdie Welt ist uranf\u00e4nglich, so was Ihr \u2013 ewig heisst,", "tokens": ["\u00bb", "die", "Welt", "ist", "u\u00b7ran\u00b7f\u00e4ng\u00b7lich", ",", "so", "was", "Ihr", "\u2013", "e\u00b7wig", "heisst", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADJD", "$,", "ADV", "PWS", "PPER", "$(", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ein Leib, der unverg\u00e4nglich, und ", "tokens": ["Ein", "Leib", ",", "der", "un\u00b7ver\u00b7g\u00e4ng\u00b7lich", ",", "und"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "$,", "KON"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Sonnen, die Planeten, die Stern' am Himmelszelt", "tokens": ["Die", "Son\u00b7nen", ",", "die", "Pla\u00b7ne\u00b7ten", ",", "die", "Stern'", "am", "Him\u00b7mels\u00b7zelt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "APPRART", "NN"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Das sind zerfallne Glieder des grossen Wesens ", "tokens": ["Das", "sind", "zer\u00b7fall\u00b7ne", "Glie\u00b7der", "des", "gros\u00b7sen", "We\u00b7sens"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADJA", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.10": {"line.1": {"text": "\u00bbeinst war das All nur eines, ein sch\u00f6nes dunkles Graun,", "tokens": ["\u00bb", "einst", "war", "das", "All", "nur", "ei\u00b7nes", ",", "ein", "sch\u00f6\u00b7nes", "dunk\u00b7les", "Graun", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "ART", "NN", "ADV", "PIS", "$,", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Nichts Grosses und nichts Kleines, nicht Herr, nicht Knecht zu schaun.", "tokens": ["Nichts", "Gros\u00b7ses", "und", "nichts", "Klei\u00b7nes", ",", "nicht", "Herr", ",", "nicht", "Knecht", "zu", "schaun", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "NN", "KON", "PIS", "ADJA", "$,", "PTKNEG", "NN", "$,", "PTKNEG", "NN", "PTKZU", "VVINF", "$."], "meter": "-+---+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Da hat es Wer geschieden, der wies den Sternen Bahn,", "tokens": ["Da", "hat", "es", "Wer", "ge\u00b7schie\u00b7den", ",", "der", "wies", "den", "Ster\u00b7nen", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "VVPP", "$,", "PRELS", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und bald war's um den Frieden im ew'gen All gethan.\u00ab", "tokens": ["Und", "bald", "wa\u00b7r's", "um", "den", "Frie\u00b7den", "im", "ew'\u00b7gen", "All", "ge\u00b7than", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VAFIN", "APPR", "ART", "NN", "APPRART", "ADJA", "NN", "VVPP", "$.", "$("], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.11": {"line.1": {"text": "\u00bbauch Feuer, Meer und Erde war mit dem Firmament", "tokens": ["\u00bb", "auch", "Feu\u00b7er", ",", "Meer", "und", "Er\u00b7de", "war", "mit", "dem", "Fir\u00b7ma\u00b7ment"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "NN", "$,", "NN", "KON", "NN", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ein friederf\u00fclltes Ganzes, bis alles sich getrennt,", "tokens": ["Ein", "frie\u00b7der\u00b7f\u00fcll\u00b7tes", "Gan\u00b7zes", ",", "bis", "al\u00b7les", "sich", "ge\u00b7trennt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "KOUS", "PIS", "PRF", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Die Massen sich zerschlugen, Licht mit dem Dunkel rang,", "tokens": ["Die", "Mas\u00b7sen", "sich", "zer\u00b7schlu\u00b7gen", ",", "Licht", "mit", "dem", "Dun\u00b7kel", "rang", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "VVPP", "$,", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Doch Meer und Land vertrugen sich damals noch gar lang.\u00ab", "tokens": ["Doch", "Meer", "und", "Land", "ver\u00b7tru\u00b7gen", "sich", "da\u00b7mals", "noch", "gar", "lang", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "PRF", "ADV", "ADV", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.12": {"line.1": {"text": "\u00bbbis dass auch sie sich schieden; da sprach das Meer zum Land:", "tokens": ["\u00bb", "bis", "dass", "auch", "sie", "sich", "schie\u00b7den", ";", "da", "sprach", "das", "Meer", "zum", "Land", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PDS", "ADV", "PPER", "PRF", "VVINF", "$.", "ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Lass scheiden uns im Frieden, wir bleiben doch verwandt.", "tokens": ["Lass", "schei\u00b7den", "uns", "im", "Frie\u00b7den", ",", "wir", "blei\u00b7ben", "doch", "ver\u00b7wandt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "APPRART", "NN", "$,", "PPER", "VVFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "In meinem Schoos getragen hab' ich als Mutter Dich,", "tokens": ["In", "mei\u00b7nem", "Schoos", "ge\u00b7tra\u00b7gen", "hab'", "ich", "als", "Mut\u00b7ter", "Dich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "VAFIN", "PPER", "KOUS", "NN", "PPER", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Doch Deine Berge ragen zu stolz schon \u00fcber mich.\u00ab", "tokens": ["Doch", "Dei\u00b7ne", "Ber\u00b7ge", "ra\u00b7gen", "zu", "stolz", "schon", "\u00fc\u00b7ber", "mich", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PTKA", "ADJD", "ADV", "APPR", "PPER", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.13": {"line.1": {"text": "\u00bbwir theilen; nimm die V\u00f6gel, nimm, was in L\u00fcften schwimmt!", "tokens": ["\u00bb", "wir", "thei\u00b7len", ";", "nimm", "die", "V\u00f6\u00b7gel", ",", "nimm", ",", "was", "in", "L\u00fcf\u00b7ten", "schwimmt", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$.", "VVIMP", "ART", "NN", "$,", "VVIMP", "$,", "PRELS", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Was sich im Wasser freuet sei f\u00fcrder mir bestimmt.", "tokens": ["Was", "sich", "im", "Was\u00b7ser", "freu\u00b7et", "sei", "f\u00fcr\u00b7der", "mir", "be\u00b7stimmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPRART", "NN", "VVFIN", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+----+-+", "measure": "unknown.measure.penta"}, "line.3": {"text": "Dich m\u00f6gen Greif und Lindwurm und Elephant erfreun;", "tokens": ["Dich", "m\u00f6\u00b7gen", "Greif", "und", "Lind\u00b7wurm", "und", "E\u00b7le\u00b7phant", "er\u00b7freun", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NE", "KON", "NN", "KON", "NN", "VVINF", "$."], "meter": "+--+-++-+-+-+", "measure": "iambic.septa.invert"}, "line.4": {"text": "Mein sei die Wasserschlange, der Leviathan mein!\u00ab", "tokens": ["Mein", "sei", "die", "Was\u00b7ser\u00b7schlan\u00b7ge", ",", "der", "Le\u00b7vi\u00b7a\u00b7than", "mein", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "VAFIN", "ART", "NN", "$,", "ART", "NN", "PPOSAT", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "\u00bbich lasse dir die Str\u00e4ucher, die B\u00e4um' und Blumen all';", "tokens": ["\u00bb", "ich", "las\u00b7se", "dir", "die", "Str\u00e4u\u00b7cher", ",", "die", "B\u00e4um'", "und", "Blu\u00b7men", "all'", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ART", "NN", "$,", "ART", "NN", "KON", "NN", "PIS", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Lass mir daf\u00fcr den Kraken, den Behemoth, das Wall.", "tokens": ["Lass", "mir", "da\u00b7f\u00fcr", "den", "Kra\u00b7ken", ",", "den", "Be\u00b7he\u00b7moth", ",", "das", "Wall", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PAV", "ART", "NN", "$,", "ART", "NN", "$,", "PRELS", "NE", "$."], "meter": "---+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Will mir schon B\u00e4ume schaffen, auch Blumen, tief im Schooss", "tokens": ["Will", "mir", "schon", "B\u00e4u\u00b7me", "schaf\u00b7fen", ",", "auch", "Blu\u00b7men", ",", "tief", "im", "Scho\u00b7oss"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "NN", "VVINF", "$,", "ADV", "NN", "$,", "ADJD", "APPRART", "NN"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "An purpurrothem Strauchwerk gr\u00fcnt mein Korallenmoos.\u00ab", "tokens": ["An", "pur\u00b7pur\u00b7ro\u00b7them", "Strauch\u00b7werk", "gr\u00fcnt", "mein", "Ko\u00b7ral\u00b7len\u00b7moos", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$.", "$("], "meter": "+--+-+-+--+-+", "measure": "iambic.hexa.invert"}}, "stanza.15": {"line.1": {"text": "\u00bbund lass uns Pf\u00e4nder tauschen, Erinnrung alter Zeit;", "tokens": ["\u00bb", "und", "lass", "uns", "Pf\u00e4n\u00b7der", "tau\u00b7schen", ",", "E\u00b7rinn\u00b7rung", "al\u00b7ter", "Zeit", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VVFIN", "PPER", "NN", "VVINF", "$,", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+----+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Ich will um Inseln rauschen, die bleiben mir geweiht,", "tokens": ["Ich", "will", "um", "In\u00b7seln", "rau\u00b7schen", ",", "die", "blei\u00b7ben", "mir", "ge\u00b7weiht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "NN", "VVINF", "$,", "PRELS", "VVFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Du magst mit gr\u00fcnen Ringen von Blumen und Gestein", "tokens": ["Du", "magst", "mit", "gr\u00fc\u00b7nen", "Rin\u00b7gen", "von", "Blu\u00b7men", "und", "Ge\u00b7stein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "ADJA", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Um manchen See Dich schlingen, er soll Dein eigen sein.\u00ab", "tokens": ["Um", "man\u00b7chen", "See", "Dich", "schlin\u00b7gen", ",", "er", "soll", "Dein", "ei\u00b7gen", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUI", "PIAT", "NN", "PPER", "VVFIN", "$,", "PPER", "VMFIN", "PPOSAT", "ADJD", "VAINF", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.16": {"line.1": {"text": "\u00bbso sprach das Meer zum Lande, das that nach diesem Wort,", "tokens": ["\u00bb", "so", "sprach", "das", "Meer", "zum", "Lan\u00b7de", ",", "das", "that", "nach", "die\u00b7sem", "Wort", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "$,", "PDS", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und Str\u00f6m' und Fl\u00fcsse sandte zum Meer es gr\u00fcssend fort.", "tokens": ["Und", "Str\u00f6m'", "und", "Fl\u00fcs\u00b7se", "sand\u00b7te", "zum", "Meer", "es", "gr\u00fcs\u00b7send", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "APPRART", "NN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Das Halbtheil der Gesch\u00f6pfe der Ozean empfing,", "tokens": ["Das", "Halb\u00b7theil", "der", "Ge\u00b7sch\u00f6p\u00b7fe", "der", "O\u00b7ze\u00b7an", "emp\u00b7fing", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Indess auf festem Boden die zweite H\u00e4lfte ging.\u00ab", "tokens": ["In\u00b7dess", "auf", "fes\u00b7tem", "Bo\u00b7den", "die", "zwei\u00b7te", "H\u00e4lf\u00b7te", "ging", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "APPR", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.17": {"line.1": {"text": "\u00bbnun ward der erste Fr\u00fchling dem armen nackten Land", "tokens": ["\u00bb", "nun", "ward", "der", "ers\u00b7te", "Fr\u00fch\u00b7ling", "dem", "ar\u00b7men", "nack\u00b7ten", "Land"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VAFIN", "ART", "ADJA", "NN", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Als eine reiche Buhle vom Himmel zugesandt;", "tokens": ["Als", "ei\u00b7ne", "rei\u00b7che", "Buh\u00b7le", "vom", "Him\u00b7mel", "zu\u00b7ge\u00b7sandt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie kommt daher gezogen mit k\u00f6stlichem Geschmeid,", "tokens": ["Sie", "kommt", "da\u00b7her", "ge\u00b7zo\u00b7gen", "mit", "k\u00f6st\u00b7li\u00b7chem", "Ge\u00b7schmeid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und deckt den dunklen Riesen mit ihrem Blumenkleid.\u00ab", "tokens": ["Und", "deckt", "den", "dunk\u00b7len", "Rie\u00b7sen", "mit", "ih\u00b7rem", "Blu\u00b7men\u00b7kleid", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.18": {"line.1": {"text": "\u00bbdes Fr\u00fchlings warmer Odem l\u00e4sst Blumen auferstehn;", "tokens": ["\u00bb", "des", "Fr\u00fch\u00b7lings", "war\u00b7mer", "O\u00b7dem", "l\u00e4sst", "Blu\u00b7men", "auf\u00b7er\u00b7stehn", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "ADJA", "NN", "VVFIN", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Doch mit dem Hauch des Todes das Leben ", "tokens": ["Doch", "mit", "dem", "Hauch", "des", "To\u00b7des", "das", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "ART", "NN"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Und was da knospt und bl\u00fchet, es bl\u00fcht nur kurze Zeit,", "tokens": ["Und", "was", "da", "knospt", "und", "bl\u00fc\u00b7het", ",", "es", "bl\u00fcht", "nur", "kur\u00b7ze", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "VVFIN", "KON", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Der baldigen Vernichtung ists schon im Keim geweiht.\u00ab \u2013", "tokens": ["Der", "bal\u00b7di\u00b7gen", "Ver\u00b7nich\u00b7tung", "ists", "schon", "im", "Keim", "ge\u00b7weiht", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "APPRART", "NN", "VVPP", "$.", "$(", "$("], "meter": "-+---+--+-+-+", "measure": "iambic.penta.relaxed"}}}}}