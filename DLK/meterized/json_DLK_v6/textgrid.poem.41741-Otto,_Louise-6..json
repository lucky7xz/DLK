{"textgrid.poem.41741": {"metadata": {"author": {"name": "Otto, Louise", "birth": "N.A.", "death": "N.A."}, "title": "6.", "genre": "verse", "period": "N.A.", "pub_year": 1857, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sinnend trat ich hinaus", "tokens": ["Sin\u00b7nend", "trat", "ich", "hin\u00b7aus"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "APZR"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.2": {"text": "In den mauerumgebenen Schlo\u00dfhof,", "tokens": ["In", "den", "mau\u00b7e\u00b7rum\u00b7ge\u00b7be\u00b7nen", "Schlo\u00df\u00b7hof", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Wo junge Gr\u00e4ser spro\u00dften, ", "tokens": ["Wo", "jun\u00b7ge", "Gr\u00e4\u00b7ser", "spro\u00df\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die nichts gesehen von der vergangenen Tage Herrlichkeit,", "tokens": ["Die", "nichts", "ge\u00b7se\u00b7hen", "von", "der", "ver\u00b7gan\u00b7ge\u00b7nen", "Ta\u00b7ge", "Herr\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVPP", "APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+--+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.5": {"text": "Von der vergangenen Tage Leid.", "tokens": ["Von", "der", "ver\u00b7gan\u00b7ge\u00b7nen", "Ta\u00b7ge", "Leid", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Hinter den wallenden Wolken", "tokens": ["Hin\u00b7ter", "den", "wal\u00b7len\u00b7den", "Wol\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Schaute noch einmal ruhig strahlend hervor,", "tokens": ["Schau\u00b7te", "noch", "ein\u00b7mal", "ru\u00b7hig", "strah\u00b7lend", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ADJD", "ADJD", "PTKVZ", "$,"], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Die unverg\u00e4ngliche Klarheit der Sonne.", "tokens": ["Die", "un\u00b7ver\u00b7g\u00e4ng\u00b7li\u00b7che", "Klar\u00b7heit", "der", "Son\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und beleuchtete zu meinen F\u00fc\u00dfen,", "tokens": ["Und", "be\u00b7leuch\u00b7te\u00b7te", "zu", "mei\u00b7nen", "F\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Ein Werk der spielenden Natur,", "tokens": ["Ein", "Werk", "der", "spie\u00b7len\u00b7den", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Im dreigebl\u00e4tterten Klee \u2013 ", "tokens": ["Im", "drei\u00b7ge\u00b7bl\u00e4t\u00b7ter\u00b7ten", "Klee", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.3": {"line.1": {"text": "Ich pfl\u00fcckt' es als Angedenken \u2013 als vierfaches", "tokens": ["Ich", "pfl\u00fcckt'", "es", "als", "An\u00b7ge\u00b7den\u00b7ken", "\u2013", "als", "vier\u00b7fa\u00b7ches"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "KOUS", "NN", "$(", "KOUS", "PIS"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "An diese Burg, die erinnerungsreiche,", "tokens": ["An", "die\u00b7se", "Burg", ",", "die", "e\u00b7rin\u00b7ne\u00b7rungs\u00b7rei\u00b7che", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "PRELS", "VVFIN", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.3": {"text": "Und that dabei einen Schwur, einen vierfachen:", "tokens": ["Und", "that", "da\u00b7bei", "ei\u00b7nen", "Schwur", ",", "ei\u00b7nen", "vier\u00b7fa\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "ART", "NN", "$,", "ART", "ADJA", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}, "stanza.4": {"line.1": {"text": "Elisabeth, die Heilige,", "tokens": ["E\u00b7lis\u00b7a\u00b7beth", ",", "die", "Hei\u00b7li\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sei mir ein Vorbild in stiller Demut", "tokens": ["Sei", "mir", "ein", "Vor\u00b7bild", "in", "stil\u00b7ler", "De\u00b7mut"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "In allumfassender Menschenliebe", "tokens": ["In", "al\u00b7lum\u00b7fas\u00b7sen\u00b7der", "Men\u00b7schen\u00b7lie\u00b7be"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PIAT", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der Armen mich zu erbarmen.", "tokens": ["Der", "Ar\u00b7men", "mich", "zu", "er\u00b7bar\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Und in dem S\u00e4ngerkrieg, dem neuen, heiligen", "tokens": ["Und", "in", "dem", "S\u00e4n\u00b7ger\u00b7krieg", ",", "dem", "neu\u00b7en", ",", "hei\u00b7li\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KON", "APPR", "ART", "NN", "$,", "ART", "ADJA", "$,", "ADJA"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Will ich stehen und fechten, bis mit dem letzten Lied", "tokens": ["Will", "ich", "ste\u00b7hen", "und", "fech\u00b7ten", ",", "bis", "mit", "dem", "letz\u00b7ten", "Lied"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "VVFIN", "KON", "VVINF", "$,", "KOUS", "APPR", "ART", "ADJA", "NN"], "meter": "+-+--+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Der letzte Odemzug der Brust entwallt!", "tokens": ["Der", "letz\u00b7te", "O\u00b7dem\u00b7zug", "der", "Brust", "ent\u00b7wallt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Und protestieren will ich nach Luthers Wort,", "tokens": ["Und", "pro\u00b7tes\u00b7tie\u00b7ren", "will", "ich", "nach", "Lu\u00b7thers", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VMFIN", "PPER", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und f\u00fcr den freien Glauben", "tokens": ["Und", "f\u00fcr", "den", "frei\u00b7en", "Glau\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mit freier Rede in die Schranken treten! \u2013", "tokens": ["Mit", "frei\u00b7er", "Re\u00b7de", "in", "die", "Schran\u00b7ken", "tre\u00b7ten", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Und fest verbr\u00fcdert mit der deutschen Jugend", "tokens": ["Und", "fest", "ver\u00b7br\u00fc\u00b7dert", "mit", "der", "deut\u00b7schen", "Ju\u00b7gend"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVPP", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Weih' ich dem Vaterlande all mein Streben, \u2013", "tokens": ["Weih'", "ich", "dem", "Va\u00b7ter\u00b7lan\u00b7de", "all", "mein", "Stre\u00b7ben", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PIAT", "PPOSAT", "NN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So steh ich ernst und frei vor allem Volk.", "tokens": ["So", "steh", "ich", "ernst", "und", "frei", "vor", "al\u00b7lem", "Volk", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "APPR", "PIS", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Und wollt Ihr nun mich h\u00f6hnen und verdammen,", "tokens": ["Und", "wollt", "Ihr", "nun", "mich", "h\u00f6h\u00b7nen", "und", "ver\u00b7dam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "PPER", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Weil nur die schwache Jungfrau zu Euch spricht:", "tokens": ["Weil", "nur", "die", "schwa\u00b7che", "Jung\u00b7frau", "zu", "Euch", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nicht l\u00f6schen k\u00f6nnt Ihr der Begeist'rung Flammen,", "tokens": ["Nicht", "l\u00f6\u00b7schen", "k\u00f6nnt", "Ihr", "der", "Be\u00b7geist'\u00b7rung", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "VMFIN", "PPER", "ART", "NN", "NN", "$,"], "meter": "-+--++-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "K\u00f6nnt sie nur schm\u00e4hen, aber d\u00e4mpfen ", "tokens": ["K\u00f6nnt", "sie", "nur", "schm\u00e4\u00b7hen", ",", "a\u00b7ber", "d\u00e4mp\u00b7fen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "VVINF", "$,", "ADV", "VVINF"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Und wenn mein Herz von Euch versto\u00dfen, bricht,", "tokens": ["Und", "wenn", "mein", "Herz", "von", "Euch", "ver\u00b7sto\u00b7\u00dfen", ",", "bricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "APPR", "PPER", "VVINF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "So bricht's mit Luthers Worten doch zusammen:", "tokens": ["So", "bricht's", "mit", "Lu\u00b7thers", "Wor\u00b7ten", "doch", "zu\u00b7sam\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ADJA", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "\u00bbgott helfe mir! \u2013 doch anders konnt ich nicht!\u00ab \u2013", "tokens": ["\u00bb", "gott", "hel\u00b7fe", "mir", "!", "\u2013", "doch", "an\u00b7ders", "konnt", "ich", "nicht", "!", "\u00ab", "\u2013"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ADJD", "VVFIN", "PPER", "$.", "$(", "ADV", "ADV", "VMFIN", "PPER", "PTKNEG", "$.", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}