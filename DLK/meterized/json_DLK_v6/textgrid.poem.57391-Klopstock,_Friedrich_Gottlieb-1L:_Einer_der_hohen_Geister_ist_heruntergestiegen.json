{"textgrid.poem.57391": {"metadata": {"author": {"name": "Klopstock, Friedrich Gottlieb", "birth": "N.A.", "death": "N.A."}, "title": "1L: Einer der hohen Geister ist heruntergestiegen", "genre": "verse", "period": "N.A.", "pub_year": 1796, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Einer der hohen Geister ist heruntergestiegen", "tokens": ["Ei\u00b7ner", "der", "ho\u00b7hen", "Geis\u00b7ter", "ist", "her\u00b7un\u00b7ter\u00b7ges\u00b7tie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "ART", "ADJA", "NN", "VAFIN", "VVPP"], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "In die Versamlung der V\u00e4ter, die Galliens Freyheit erschufen,", "tokens": ["In", "die", "Ver\u00b7sam\u00b7lung", "der", "V\u00e4\u00b7ter", ",", "die", "Gal\u00b7li\u00b7ens", "Frey\u00b7heit", "er\u00b7schu\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,", "ART", "NN", "NN", "VVPP", "$,"], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.3": {"text": "Und der Unsterbliche hat die gl\u00fccklichen, durch Eingebung,", "tokens": ["Und", "der", "U\u00b7nsterb\u00b7li\u00b7che", "hat", "die", "gl\u00fcck\u00b7li\u00b7chen", ",", "durch", "Ein\u00b7ge\u00b7bung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ART", "ADJA", "$,", "APPR", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "\u00dcber der Menschheit Loos erh\u00f6ht.", "tokens": ["\u00dc\u00b7ber", "der", "Menschheit", "Loos", "er\u00b7h\u00f6ht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Wonne! er gab den Versammelten ein die erhabne Verheissung:", "tokens": ["Won\u00b7ne", "!", "er", "gab", "den", "Ver\u00b7sam\u00b7mel\u00b7ten", "ein", "die", "er\u00b7hab\u00b7ne", "Ver\u00b7heis\u00b7sung", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VVFIN", "ART", "NN", "ART", "ART", "ADJA", "NN", "$."], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.2": {"text": "\u00bbnie f\u00fchrt unser Volk den Krieg der Erobrung!\u00ab Ihr Antliz", "tokens": ["\u00bb", "nie", "f\u00fchrt", "un\u00b7ser", "Volk", "den", "Krieg", "der", "E\u00b7rob\u00b7rung", "!", "\u00ab", "Ihr", "Ant\u00b7liz"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["$(", "ADV", "VVFIN", "PPOSAT", "NN", "ART", "NN", "ART", "NN", "$.", "$(", "PPOSAT", "NN"], "meter": "+-+-+-+--+--+-", "measure": "hexameter"}, "line.3": {"text": "Wurde heller, sch\u00f6ner der Blick, und ihr neues Ansehn", "tokens": ["Wur\u00b7de", "hel\u00b7ler", ",", "sch\u00f6\u00b7ner", "der", "Blick", ",", "und", "ihr", "neu\u00b7es", "An\u00b7sehn"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "$,", "ADJA", "ART", "NN", "$,", "KON", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+--+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "War beynah nicht der Sterblichen,", "tokens": ["War", "bey\u00b7nah", "nicht", "der", "Sterb\u00b7li\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Da sie das heilige Wort aussprachen; auch wandelten ihnen,", "tokens": ["Da", "sie", "das", "hei\u00b7li\u00b7ge", "Wort", "aus\u00b7spra\u00b7chen", ";", "auch", "wan\u00b7del\u00b7ten", "ih\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVINF", "$.", "ADV", "VVFIN", "PPER", "$,"], "meter": "-+-+--+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da sie redeten, sich in sanftere Laute die Stimmen:", "tokens": ["Da", "sie", "re\u00b7de\u00b7ten", ",", "sich", "in", "sanf\u00b7te\u00b7re", "Lau\u00b7te", "die", "Stim\u00b7men", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PRF", "APPR", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und sie gruben es nicht in Felsen; denn selbst der Fels sinkt", "tokens": ["Und", "sie", "gru\u00b7ben", "es", "nicht", "in", "Fel\u00b7sen", ";", "denn", "selbst", "der", "Fels", "sinkt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "$.", "KON", "ADV", "ART", "NN", "VVFIN"], "meter": "--+--+-+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Tr\u00fcmmer dem l\u00f6senden Arm der Zeit.", "tokens": ["Tr\u00fcm\u00b7mer", "dem", "l\u00f6\u00b7sen\u00b7den", "Arm", "der", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.4": {"line.1": {"text": "Aber sie haben's geschrieben mit Erzt' auf Bl\u00e4tter; und dieser", "tokens": ["A\u00b7ber", "sie", "ha\u00b7ben's", "ge\u00b7schrie\u00b7ben", "mit", "Erzt'", "auf", "Bl\u00e4t\u00b7ter", ";", "und", "die\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "VVPP", "APPR", "NN", "APPR", "NN", "$.", "KON", "PDAT"], "meter": "+-+-+-+--+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Waren tausendmal tausend: so schrieben's auch andere V\u00f6lker.", "tokens": ["Wa\u00b7ren", "tau\u00b7send\u00b7mal", "tau\u00b7send", ":", "so", "schrie\u00b7ben's", "auch", "an\u00b7de\u00b7re", "V\u00f6l\u00b7ker", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "$.", "ADV", "VVFIN", "ADV", "ADJA", "NN", "$."], "meter": "+-+--+---+-+--+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "W\u00fcte die Flamme denn unter den Bl\u00e4ttern; sie steigen niemals", "tokens": ["W\u00fc\u00b7te", "die", "Flam\u00b7me", "denn", "un\u00b7ter", "den", "Bl\u00e4t\u00b7tern", ";", "sie", "stei\u00b7gen", "nie\u00b7mals"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "KON", "APPR", "ART", "NN", "$.", "PPER", "VVFIN", "ADV"], "meter": "+--+--+--+--+-+-", "measure": "dactylic.tetra.plus"}, "line.4": {"text": "Alle zerfliessend im Dampf empor.", "tokens": ["Al\u00b7le", "zer\u00b7flies\u00b7send", "im", "Dampf", "em\u00b7por", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVPP", "APPRART", "NN", "PTKVZ", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.5": {"line.1": {"text": "Wehe! nun kam ein h\u00f6herer Geist herab zu dem Freunde", "tokens": ["We\u00b7he", "!", "nun", "kam", "ein", "h\u00f6\u00b7he\u00b7rer", "Geist", "her\u00b7ab", "zu", "dem", "Freun\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "ADV", "VVFIN", "ART", "ADJA", "NN", "ADV", "APPR", "ART", "NN"], "meter": "+--+-+--+-+--+-", "measure": "hexameter"}, "line.2": {"text": "In die Versamlung der V\u00e4ter, die Galliens Freyheit erschufen.", "tokens": ["In", "die", "Ver\u00b7sam\u00b7lung", "der", "V\u00e4\u00b7ter", ",", "die", "Gal\u00b7li\u00b7ens", "Frey\u00b7heit", "er\u00b7schu\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,", "ART", "NN", "NN", "VVINF", "$."], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.3": {"text": "Und er stehet und schaut den Begeisterer an, und zeiget", "tokens": ["Und", "er", "ste\u00b7het", "und", "schaut", "den", "Be\u00b7geis\u00b7te\u00b7rer", "an", ",", "und", "zei\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$,", "KON", "VVFIN"], "meter": "--+--+--+--+-+-", "measure": "anapaest.tetra.plus"}, "line.4": {"text": "Rings mit dem winkenden Stab' umher.", "tokens": ["Rings", "mit", "dem", "win\u00b7ken\u00b7den", "Stab'", "um\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.6": {"line.1": {"text": "Jener sah es jetzt in der Halle sich r\u00f6then; es war nicht", "tokens": ["Je\u00b7ner", "sah", "es", "jetzt", "in", "der", "Hal\u00b7le", "sich", "r\u00f6\u00b7then", ";", "es", "war", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDAT", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "PRF", "VVINF", "$.", "PPER", "VAFIN", "PTKNEG"], "meter": "+-+-+--+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "R\u00f6the des kommenden Tags; sah's weiss dann werden, es war nicht", "tokens": ["R\u00f6\u00b7the", "des", "kom\u00b7men\u00b7den", "Tags", ";", "sah's", "weiss", "dann", "wer\u00b7den", ",", "es", "war", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN", "$.", "PIS", "VVFIN", "ADV", "VAINF", "$,", "PPER", "VAFIN", "PTKNEG"], "meter": "+--+--+-+-+-+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Farbe der Bl\u00fcthen, oder der Lilien; denn nicht diese", "tokens": ["Far\u00b7be", "der", "Bl\u00fc\u00b7then", ",", "o\u00b7der", "der", "Li\u00b7li\u00b7en", ";", "denn", "nicht", "die\u00b7se"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "KON", "ART", "NN", "$.", "ADV", "PTKNEG", "PDAT"], "meter": "+--+-++-+-+--+-", "measure": "iambic.septa.invert"}, "line.4": {"text": "Liebliche Weisse hat Gebein.", "tokens": ["Lieb\u00b7li\u00b7che", "Weis\u00b7se", "hat", "Ge\u00b7bein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.7": {"line.1": {"text": "Und sie entflohn der Erde mit schweigender Trauer, und wandten", "tokens": ["Und", "sie", "ent\u00b7flohn", "der", "Er\u00b7de", "mit", "schwei\u00b7gen\u00b7der", "Trau\u00b7er", ",", "und", "wand\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$,", "KON", "VVFIN"], "meter": "-+-+-+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ernster ihr Auge weg von den Landen und Meeren, wo bald nun", "tokens": ["Erns\u00b7ter", "ihr", "Au\u00b7ge", "weg", "von", "den", "Lan\u00b7den", "und", "Mee\u00b7ren", ",", "wo", "bald", "nun"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "KON", "NN", "$,", "PWAV", "ADV", "ADV"], "meter": "+--+-+--+--+-+-+", "measure": "iambic.septa.invert"}, "line.3": {"text": "Werde der Kriegesdonner Verk\u00fcndiger seyn des sch\u00f6nen,", "tokens": ["Wer\u00b7de", "der", "Krie\u00b7ges\u00b7don\u00b7ner", "Ver\u00b7k\u00fcn\u00b7di\u00b7ger", "seyn", "des", "sch\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "NN", "PPOSAT", "ART", "ADJA", "$,"], "meter": "+--+-+--+--+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Heiligen, nicht gehaltnen Worts.", "tokens": ["Hei\u00b7li\u00b7gen", ",", "nicht", "ge\u00b7halt\u00b7nen", "Worts", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PTKNEG", "ADJA", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}}}}