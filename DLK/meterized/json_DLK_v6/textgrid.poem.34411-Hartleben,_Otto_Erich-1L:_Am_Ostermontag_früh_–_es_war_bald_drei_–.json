{"textgrid.poem.34411": {"metadata": {"author": {"name": "Hartleben, Otto Erich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Am Ostermontag fr\u00fch \u2013 es war bald drei \u2013", "genre": "verse", "period": "N.A.", "pub_year": 1884, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Am Ostermontag fr\u00fch \u2013 es war bald drei \u2013", "tokens": ["Am", "Os\u00b7ter\u00b7mon\u00b7tag", "fr\u00fch", "\u2013", "es", "war", "bald", "drei", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "$(", "PPER", "VAFIN", "ADV", "CARD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "kam der Student, der heut im Kreis der Freunde", "tokens": ["kam", "der", "Stu\u00b7dent", ",", "der", "heut", "im", "Kreis", "der", "Freun\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$,", "PRELS", "ADV", "APPRART", "NN", "ART", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "das Fest beim Gl\u00e4serklang gefeiert hatte,", "tokens": ["das", "Fest", "beim", "Gl\u00e4\u00b7ser\u00b7klang", "ge\u00b7fei\u00b7ert", "hat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "vergn\u00fcgt und aufger\u00e4umt nach Hause.", "tokens": ["ver\u00b7gn\u00fcgt", "und", "auf\u00b7ge\u00b7r\u00e4umt", "nach", "Hau\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Tastend", "tokens": ["Tas\u00b7tend"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "sucht er das Feuerzeug auf seinem Nachttisch.", "tokens": ["sucht", "er", "das", "Feu\u00b7er\u00b7zeug", "auf", "sei\u00b7nem", "Nacht\u00b7tisch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Er streicht ein Z\u00fcndholz an \u2013 Was?", "tokens": ["Er", "streicht", "ein", "Z\u00fcnd\u00b7holz", "an", "\u2013", "Was", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$(", "PWS", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.3": {"line.1": {"text": "Und sofort", "tokens": ["Und", "so\u00b7fort"], "token_info": ["word", "word"], "pos": ["KON", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "l\u00e4sst er es wieder fallen. Was war das? \u2013", "tokens": ["l\u00e4sst", "er", "es", "wie\u00b7der", "fal\u00b7len", ".", "Was", "war", "das", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "VVINF", "$.", "PWS", "VAFIN", "PDS", "$.", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "S ist wieder dunkel. \u2013 Bin ich denn bezecht?", "tokens": ["S", "ist", "wie\u00b7der", "dun\u00b7kel", ".", "\u2013", "Bin", "ich", "denn", "be\u00b7zecht", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADJD", "$.", "$(", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Und wiederum streicht er ein Z\u00fcndholz an.", "tokens": ["Und", "wie\u00b7de\u00b7rum", "streicht", "er", "ein", "Z\u00fcnd\u00b7holz", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Es zittert seine Hand dabei. Er sieht", "tokens": ["Es", "zit\u00b7tert", "sei\u00b7ne", "Hand", "da\u00b7bei", ".", "Er", "sieht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PAV", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "nicht auf das Bett, bevor die Kerze nicht", "tokens": ["nicht", "auf", "das", "Bett", ",", "be\u00b7vor", "die", "Ker\u00b7ze", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "APPR", "ART", "NN", "$,", "KOUS", "ART", "NN", "PTKNEG"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "brennt \u2013 Himmel!", "tokens": ["brennt", "\u2013", "Him\u00b7mel", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["VVFIN", "$(", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.4": {"line.1": {"text": "Auf dem offnen Bette liegt", "tokens": ["Auf", "dem", "off\u00b7nen", "Bet\u00b7te", "liegt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "in festem Schlafe Gretchen: noch geschm\u00fcckt,", "tokens": ["in", "fes\u00b7tem", "Schla\u00b7fe", "Gret\u00b7chen", ":", "noch", "ge\u00b7schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NE", "$.", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "wie man es Gott zu ehren that. Das Kleid", "tokens": ["wie", "man", "es", "Gott", "zu", "eh\u00b7ren", "that", ".", "Das", "Kleid"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "PIS", "PPER", "NN", "PTKZU", "VVINF", "VVFIN", "$.", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "ist aufgekn\u00f6pft \u2013 in ihrem Schoosse liegt", "tokens": ["ist", "auf\u00b7ge\u00b7kn\u00f6pft", "\u2013", "in", "ih\u00b7rem", "Schoos\u00b7se", "liegt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "VVPP", "$(", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "noch der verwelkte Strauss, und heitrer Friede", "tokens": ["noch", "der", "ver\u00b7welk\u00b7te", "Strauss", ",", "und", "hei\u00b7trer", "Frie\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "$,", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "ruht auf dem blassen Antlitz. Halb ge\u00f6ffnet", "tokens": ["ruht", "auf", "dem", "blas\u00b7sen", "Ant\u00b7litz", ".", "Halb", "ge\u00b7\u00f6ff\u00b7net"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$.", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "sind ihre Kinderlippen, und ein Traum", "tokens": ["sind", "ih\u00b7re", "Kin\u00b7der\u00b7lip\u00b7pen", ",", "und", "ein", "Traum"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "KON", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "spielt wie ein Bl\u00fcthenduft um ihre Lippen.", "tokens": ["spielt", "wie", "ein", "Bl\u00fc\u00b7then\u00b7duft", "um", "ih\u00b7re", "Lip\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.5": {"line.1": {"text": "Minutenlang betrachtet er dies Bild,", "tokens": ["Mi\u00b7nu\u00b7ten\u00b7lang", "be\u00b7trach\u00b7tet", "er", "dies", "Bild", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PDS", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "starr, ohne Denken. Gl\u00fchend heiss f\u00fchlt er", "tokens": ["starr", ",", "oh\u00b7ne", "Den\u00b7ken", ".", "Gl\u00fc\u00b7hend", "heiss", "f\u00fchlt", "er"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "KOUI", "NN", "$.", "NN", "NE", "VVFIN", "PPER"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "das Blut in seinen Adern, wieder dann", "tokens": ["das", "Blut", "in", "sei\u00b7nen", "A\u00b7dern", ",", "wie\u00b7der", "dann"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$,", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "sp\u00fcrt er ein eiskalt Schauern bis ins Mark.", "tokens": ["sp\u00fcrt", "er", "ein", "eis\u00b7kalt", "Schau\u00b7ern", "bis", "ins", "Mark", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJD", "NN", "APPR", "APPRART", "NN", "$."], "meter": "---+-+-+-+", "measure": "zehnsilber"}, "line.5": {"text": "Doch dann besinnt er sich und f\u00e4hrt sich \u00fcber", "tokens": ["Doch", "dann", "be\u00b7sinnt", "er", "sich", "und", "f\u00e4hrt", "sich", "\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PRF", "KON", "VVFIN", "PRF", "APPR"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "die Stirne mit der Hand und sucht zu lachen.", "tokens": ["die", "Stir\u00b7ne", "mit", "der", "Hand", "und", "sucht", "zu", "la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "KON", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Gretchen! Sie l\u00e4chelt still im Traume. Gretchen!", "tokens": ["Gret\u00b7chen", "!", "Sie", "l\u00e4\u00b7chelt", "still", "im", "Trau\u00b7me", ".", "Gret\u00b7chen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "$.", "PPER", "VVFIN", "ADJD", "APPRART", "NN", "$.", "NE", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Sie f\u00e4hrt empor. Der Friede ist gewichen,", "tokens": ["Sie", "f\u00e4hrt", "em\u00b7por", ".", "Der", "Frie\u00b7de", "ist", "ge\u00b7wi\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und Schreck und Scham malt sich auf ihren Wangen.", "tokens": ["und", "Schreck", "und", "Scham", "malt", "sich", "auf", "ih\u00b7ren", "Wan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mein liebes Kind, wie kommst du denn hierher?", "tokens": ["Mein", "lie\u00b7bes", "Kind", ",", "wie", "kommst", "du", "denn", "hier\u00b7her", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PWAV", "VVFIN", "PPER", "ADV", "PAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Hast du im Zimmer dich geirrt? \u2013 Sie h\u00e4lt verwirrt", "tokens": ["Hast", "du", "im", "Zim\u00b7mer", "dich", "ge\u00b7irrt", "?", "\u2013", "Sie", "h\u00e4lt", "ver\u00b7wirrt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "PPER", "VVPP", "$.", "$(", "PPER", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "ihr Kleid zusammen, senkt das K\u00f6pfchen. Nein,", "tokens": ["ihr", "Kleid", "zu\u00b7sam\u00b7men", ",", "senkt", "das", "K\u00f6pf\u00b7chen", ".", "Nein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "$,", "VVFIN", "ART", "NN", "$.", "PTKANT", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "sagt sie, die Mutter schickte mich hierher.", "tokens": ["sagt", "sie", ",", "die", "Mut\u00b7ter", "schick\u00b7te", "mich", "hier\u00b7her", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "NN", "VVFIN", "PRF", "PAV", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.8": {"text": "Ich sollte Sie erwarten .. Ihnen danken ..", "tokens": ["Ich", "soll\u00b7te", "Sie", "er\u00b7war\u00b7ten", "..", "Ih\u00b7nen", "dan\u00b7ken", ".."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "$.", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Sie h\u00e4ttens so gew\u00fcnscht \u2013", "tokens": ["Sie", "h\u00e4t\u00b7tens", "so", "ge\u00b7w\u00fcnscht", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Ich?! \u2013 Doch, jawohl ...", "tokens": ["Ich", "?!", "\u2013", "Doch", ",", "ja\u00b7wohl", "..."], "token_info": ["word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "$.", "$(", "KON", "$,", "KOUS", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Ich .. wollte dich noch ", "tokens": ["Ich", "..", "woll\u00b7te", "dich", "noch"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PPER", "$.", "VMFIN", "PRF", "ADV"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "ich dachte nicht .. es ist so sp\u00e4t geworden.", "tokens": ["ich", "dach\u00b7te", "nicht", "..", "es", "ist", "so", "sp\u00e4t", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$(", "PPER", "VAFIN", "ADV", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ja, und .. der Pastor gab euch jedem doch", "tokens": ["Ja", ",", "und", "..", "der", "Pas\u00b7tor", "gab", "euch", "je\u00b7dem", "doch"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "KON", "$.", "ART", "NN", "VVFIN", "PPER", "PIS", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "ein Bibelwort, nicht wahr? Wie hiess denn deins?", "tokens": ["ein", "Bi\u00b7bel\u00b7wort", ",", "nicht", "wahr", "?", "Wie", "hiess", "denn", "deins", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PTKNEG", "PTKVZ", "$.", "PWAV", "VVFIN", "KON", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Sie kn\u00f6pft an ihrem Kleide: Selig sind,", "tokens": ["Sie", "kn\u00f6pft", "an", "ih\u00b7rem", "Klei\u00b7de", ":", "Se\u00b7lig", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "NE", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "die reines Herzens sind. Sie sitzt und kn\u00f6pft", "tokens": ["die", "rei\u00b7nes", "Her\u00b7zens", "sind", ".", "Sie", "sitzt", "und", "kn\u00f6pft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$.", "PPER", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "an ihrem Kleide.", "tokens": ["an", "ih\u00b7rem", "Klei\u00b7de", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "Komm, nun geh hin\u00fcber.", "tokens": ["Komm", ",", "nun", "geh", "hin\u00b7\u00fc\u00b7ber", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADV", "VVFIN", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und schlafe weiter: bist gewiss recht m\u00fcde.", "tokens": ["Und", "schla\u00b7fe", "wei\u00b7ter", ":", "bist", "ge\u00b7wiss", "recht", "m\u00fc\u00b7de", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "$.", "VAFIN", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Er f\u00fchrt sie an der Hand zur Th\u00fcr. Da tritt", "tokens": ["Er", "f\u00fchrt", "sie", "an", "der", "Hand", "zur", "Th\u00fcr.", "Da", "tritt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "APPRART", "NN", "ADV", "VVFIN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "die Alte ein.", "tokens": ["die", "Al\u00b7te", "ein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "Sie lacht \u2013 ver\u00e4chtlich fast:", "tokens": ["Sie", "lacht", "\u2013", "ver\u00b7\u00e4cht\u00b7lich", "fast", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "ADJD", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Sie wolln sie nicht? Auch gut. Es kommt ein andrer.", "tokens": ["Sie", "wolln", "sie", "nicht", "?", "Auch", "gut", ".", "Es", "kommt", "ein", "an\u00b7drer", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "$.", "ADV", "ADJD", "$.", "PPER", "VVFIN", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Andere, der immer kommt. Gut Nacht!", "tokens": ["Der", "An\u00b7de\u00b7re", ",", "der", "im\u00b7mer", "kommt", ".", "Gut", "Nacht", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PIS", "$,", "PRELS", "ADV", "VVFIN", "$.", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wir wollten uns nicht lumpen lassen ... Komm! \u2013", "tokens": ["Wir", "woll\u00b7ten", "uns", "nicht", "lum\u00b7pen", "las\u00b7sen", "...", "Komm", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "VVINF", "$(", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Und hinter ihnen f\u00e4llt die Th\u00fcr ins Schloss.", "tokens": ["Und", "hin\u00b7ter", "ih\u00b7nen", "f\u00e4llt", "die", "Th\u00fcr", "ins", "Schloss", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}