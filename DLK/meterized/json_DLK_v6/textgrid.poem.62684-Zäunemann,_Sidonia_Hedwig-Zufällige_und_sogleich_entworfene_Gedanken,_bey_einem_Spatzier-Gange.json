{"textgrid.poem.62684": {"metadata": {"author": {"name": "Z\u00e4unemann, Sidonia Hedwig", "birth": "N.A.", "death": "N.A."}, "title": "Zuf\u00e4llige und sogleich entworfene Gedanken, bey einem Spatzier-Gange", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Minerva ginge j\u00fcngst aufs bunte Weisen-Feld,", "tokens": ["Mi\u00b7ner\u00b7va", "gin\u00b7ge", "j\u00fcngst", "aufs", "bun\u00b7te", "Wei\u00b7sen\u00b7Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Und sahe Ceres Pracht, die Seegens-schwangren Aecker,", "tokens": ["Und", "sa\u00b7he", "Ce\u00b7res", "Pracht", ",", "die", "See\u00b7gens\u00b7schwan\u00b7gren", "A\u00b7e\u00b7cker", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie sagte zu sich selbst: das sind die Lust-Erwecker,", "tokens": ["Sie", "sag\u00b7te", "zu", "sich", "selbst", ":", "das", "sind", "die", "Lust\u00b7Er\u00b7we\u00b7cker", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PRF", "ADV", "$.", "PDS", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hier freuet sich der Baur, der B\u00fcrger und der Held.", "tokens": ["Hier", "freu\u00b7et", "sich", "der", "Baur", ",", "der", "B\u00fcr\u00b7ger", "und", "der", "Held", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie satzte sich darauf an eine klare Quelle,", "tokens": ["Sie", "satz\u00b7te", "sich", "da\u00b7rauf", "an", "ei\u00b7ne", "kla\u00b7re", "Quel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PAV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und sprach: Ist Echo nicht allhier mein Sprach-Geselle?", "tokens": ["Und", "sprach", ":", "Ist", "E\u00b7cho", "nicht", "all\u00b7hier", "mein", "Sprach\u00b7Ge\u00b7sel\u00b7le", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "VAFIN", "NN", "PTKNEG", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Nachdem sie die\u00df gesagt, so wande sie sich um,", "tokens": ["Nach\u00b7dem", "sie", "die\u00df", "ge\u00b7sagt", ",", "so", "wan\u00b7de", "sie", "sich", "um", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDS", "VVPP", "$,", "ADV", "VVFIN", "PPER", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und sah zur rechten Hand die werthen Caritinen/", "tokens": ["Und", "sah", "zur", "rech\u00b7ten", "Hand", "die", "wert\u00b7hen", "Ca\u00b7ri\u00b7ti\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "ADJA", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie gr\u00fc\u00dften selbige mit Ehrfurchtsvollen Mienen.", "tokens": ["Sie", "gr\u00fc\u00df\u00b7ten", "sel\u00b7bi\u00b7ge", "mit", "Ehr\u00b7furchts\u00b7vol\u00b7len", "Mie\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie? sprach sie, find ich euch in Ceres Eigenthum?", "tokens": ["Wie", "?", "sprach", "sie", ",", "find", "ich", "euch", "in", "Ce\u00b7res", "Ei\u00b7gen\u00b7thum", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "PRF", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihr liebsten! setzet euch, ich will euch etwas fragen,", "tokens": ["Ihr", "liebs\u00b7ten", "!", "set\u00b7zet", "euch", ",", "ich", "will", "euch", "et\u00b7was", "fra\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "VVFIN", "PPER", "$,", "PPER", "VMFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ihr solt mir euren Spruch und eure Meinung sagen.", "tokens": ["Ihr", "solt", "mir", "eu\u00b7ren", "Spruch", "und", "eu\u00b7re", "Mei\u00b7nung", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Aglaja! sage mir: ", "tokens": ["Ag\u00b7la\u00b7ja", "!", "sa\u00b7ge", "mir", ":"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$.", "VVFIN", "PPER", "$."], "meter": "++-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Worauf dieselbe sprach: Wer Weisheit auserlesen", "tokens": ["Wo\u00b7rauf", "die\u00b7sel\u00b7be", "sprach", ":", "Wer", "Weis\u00b7heit", "au\u00b7ser\u00b7le\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "PDAT", "VVFIN", "$.", "PWS", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den Ehren K\u00f6nige, sie lassen weit und breit,", "tokens": ["Den", "Eh\u00b7ren", "K\u00f6\u00b7ni\u00b7ge", ",", "sie", "las\u00b7sen", "weit", "und", "breit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PPER", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Von vielen Orten her, gelehrte M\u00e4nner hohlen,", "tokens": ["Von", "vie\u00b7len", "Or\u00b7ten", "her", ",", "ge\u00b7lehr\u00b7te", "M\u00e4n\u00b7ner", "hoh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PTKVZ", "$,", "ADJA", "NN", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und haben ihren Staat denselben anbefohlen.", "tokens": ["Und", "ha\u00b7ben", "ih\u00b7ren", "Staat", "den\u00b7sel\u00b7ben", "an\u00b7be\u00b7foh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "PDS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Es wird des K\u00f6nigs Thron durch diese unterst\u00fctzt:", "tokens": ["Es", "wird", "des", "K\u00f6\u00b7nigs", "Thron", "durch", "die\u00b7se", "un\u00b7ter\u00b7st\u00fctzt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "APPR", "PDAT", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denn ein Gelehrter kan auch andre gl\u00fccklich machen,", "tokens": ["Denn", "ein", "Ge\u00b7lehr\u00b7ter", "kan", "auch", "and\u00b7re", "gl\u00fcck\u00b7lich", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VMFIN", "ADV", "PIS", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wofern er ihnen lehrt die ihm vertraute Sachen,", "tokens": ["Wo\u00b7fern", "er", "ih\u00b7nen", "lehrt", "die", "ihm", "ver\u00b7trau\u00b7te", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "ART", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und treulich offenbahrt was Staats Ministern n\u00fctzt.", "tokens": ["Und", "treu\u00b7lich", "of\u00b7fen\u00b7bahrt", "was", "Staats", "Mi\u00b7nis\u00b7tern", "n\u00fctzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PIS", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gelehrter Leute Witz ist jedermann beliebet,", "tokens": ["Ge\u00b7lehr\u00b7ter", "Leu\u00b7te", "Witz", "ist", "je\u00b7der\u00b7mann", "be\u00b7lie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "VAFIN", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So, da\u00df sich Herz und Geist denselben \u00fcbergiebet.", "tokens": ["So", ",", "da\u00df", "sich", "Herz", "und", "Geist", "den\u00b7sel\u00b7ben", "\u00fc\u00b7berg\u00b7ie\u00b7bet", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PRF", "NN", "KON", "NN", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Und sterben sie, so ist ihr Name doch nicht todt,", "tokens": ["Und", "ster\u00b7ben", "sie", ",", "so", "ist", "ihr", "Na\u00b7me", "doch", "nicht", "todt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "ADV", "VAFIN", "PPOSAT", "NN", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Man l\u00e4sset ihnen Denk- und Ehren-Maale bauen,", "tokens": ["Man", "l\u00e4s\u00b7set", "ih\u00b7nen", "Denk", "und", "Eh\u00b7ren\u00b7Maa\u00b7le", "bau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "TRUNC", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drum sind sie freylich auch vor edel anzuschauen.", "tokens": ["Drum", "sind", "sie", "frey\u00b7lich", "auch", "vor", "e\u00b7del", "an\u00b7zu\u00b7schau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "ADV", "APPR", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Allein Beredsamkeit rei\u00dft auch aus vieler Noth:", "tokens": ["Al\u00b7lein", "Be\u00b7red\u00b7sam\u00b7keit", "rei\u00dft", "auch", "aus", "vie\u00b7ler", "Noth", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Seht Abgesandte an, wenn sie gleich viel verstehen,", "tokens": ["Seht", "Ab\u00b7ge\u00b7sand\u00b7te", "an", ",", "wenn", "sie", "gleich", "viel", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PTKVZ", "$,", "KOUS", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und doch nicht Redner sind, wie schlecht die Sachen gehen.", "tokens": ["Und", "doch", "nicht", "Red\u00b7ner", "sind", ",", "wie", "schlecht", "die", "Sa\u00b7chen", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "NN", "VAFIN", "$,", "PWAV", "ADJD", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ein Lehrer, der den Kern der Weisheit in sich hat,", "tokens": ["Ein", "Leh\u00b7rer", ",", "der", "den", "Kern", "der", "Weis\u00b7heit", "in", "sich", "hat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "ART", "NN", "APPR", "PRF", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist aber nicht geschickt dieselbe vorzutragen;", "tokens": ["Ist", "a\u00b7ber", "nicht", "ge\u00b7schickt", "die\u00b7sel\u00b7be", "vor\u00b7zu\u00b7tra\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "VVPP", "PDAT", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kan denn der Sch\u00fcler wohl von Nutz und Wachsthum sagen?", "tokens": ["Kan", "denn", "der", "Sch\u00fc\u00b7ler", "wohl", "von", "Nutz", "und", "Wach\u00b7sthum", "sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "ADV", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie kan ein Advocat, der bald von Reden matt,", "tokens": ["Wie", "kan", "ein", "Ad\u00b7vo\u00b7cat", ",", "der", "bald", "von", "Re\u00b7den", "matt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ART", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und arm an Worten wird, den Gegner widerlegen,", "tokens": ["Und", "arm", "an", "Wor\u00b7ten", "wird", ",", "den", "Geg\u00b7ner", "wi\u00b7der\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "NN", "VAFIN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und seines Richters Sinn zum guten Schlu\u00df bewegen?", "tokens": ["Und", "sei\u00b7nes", "Rich\u00b7ters", "Sinn", "zum", "gu\u00b7ten", "Schlu\u00df", "be\u00b7we\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Was kan ein Redner nicht, vor Vortheil nach sich ziehn?", "tokens": ["Was", "kan", "ein", "Red\u00b7ner", "nicht", ",", "vor", "Vor\u00b7theil", "nach", "sich", "ziehn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "PTKNEG", "$,", "APPR", "NN", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hat einer gleich nicht viel gelernet und studiret,", "tokens": ["Hat", "ei\u00b7ner", "gleich", "nicht", "viel", "ge\u00b7ler\u00b7net", "und", "stu\u00b7di\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADV", "PTKNEG", "ADV", "VVPP", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Wofern er Mundwerk hat, und guten Einfall sp\u00fchret:", "tokens": ["Wo\u00b7fern", "er", "Mund\u00b7werk", "hat", ",", "und", "gu\u00b7ten", "Ein\u00b7fall", "sp\u00fch\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VAFIN", "$,", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So mu\u00df sein Gl\u00fcck und Wohl trotz dem Gelehrtsten bl\u00fchn:", "tokens": ["So", "mu\u00df", "sein", "Gl\u00fcck", "und", "Wohl", "trotz", "dem", "Ge\u00b7lehrts\u00b7ten", "bl\u00fchn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "KON", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Warum? Er weis sein Thun bey nur vorhandnen F\u00e4llen,", "tokens": ["Wa\u00b7rum", "?", "Er", "weis", "sein", "Thun", "bey", "nur", "vor\u00b7hand\u00b7nen", "F\u00e4l\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "PPER", "PTKVZ", "PPOSAT", "NN", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nachsinnlich darzuthun und an das Licht zu stellen.", "tokens": ["Nach\u00b7sinn\u00b7lich", "dar\u00b7zu\u00b7thun", "und", "an", "das", "Licht", "zu", "stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "KON", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Man liebt und ehret den, der fertge Lippen hat.", "tokens": ["Man", "liebt", "und", "eh\u00b7ret", "den", ",", "der", "fert\u00b7ge", "Lip\u00b7pen", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "ART", "$,", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "F\u00fcrwahr, ich weis fast nicht bey sogestallten Sachen", "tokens": ["F\u00fcr\u00b7wahr", ",", "ich", "weis", "fast", "nicht", "bey", "so\u00b7ge\u00b7stall\u00b7ten", "Sa\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PPER", "PTKVZ", "ADV", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Den Schlu\u00df, wie sichs geb\u00fchrt, nach Billigkeit zu machen,", "tokens": ["Den", "Schlu\u00df", ",", "wie", "sichs", "ge\u00b7b\u00fchrt", ",", "nach", "Bil\u00b7lig\u00b7keit", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PIS", "VVPP", "$,", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es findet immer noch der Zweifel bey mir statt.", "tokens": ["Es", "fin\u00b7det", "im\u00b7mer", "noch", "der", "Zwei\u00b7fel", "bey", "mir", "statt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Jedoch noch eins! Sind schon gelehrt- und kluge M\u00e4nner", "tokens": ["Je\u00b7doch", "noch", "eins", "!", "Sind", "schon", "ge\u00b7lehr\u00b7t", "und", "klu\u00b7ge", "M\u00e4n\u00b7ner"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PIS", "$.", "VAFIN", "ADV", "TRUNC", "KON", "ADJA", "NN"], "meter": "+---+--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Nicht von Demosthens Art und Svada Freund und Kenner:", "tokens": ["Nicht", "von", "De\u00b7mos\u00b7thens", "Art", "und", "Sva\u00b7da", "Freund", "und", "Ken\u00b7ner", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "KON", "NE", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "So sind der Federn Zahl und Finger in dem Stand", "tokens": ["So", "sind", "der", "Fe\u00b7dern", "Zahl", "und", "Fin\u00b7ger", "in", "dem", "Stand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "NN", "KON", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zu zeigen, was der Mund nicht kan geschickt erzehlen;", "tokens": ["Zu", "zei\u00b7gen", ",", "was", "der", "Mund", "nicht", "kan", "ge\u00b7schickt", "er\u00b7zeh\u00b7len", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "PRELS", "ART", "NN", "PTKNEG", "VMFIN", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Mund verschweigts; der Kiel kan solches nicht verhehlen,", "tokens": ["Der", "Mund", "ver\u00b7schweigts", ";", "der", "Kiel", "kan", "sol\u00b7ches", "nicht", "ver\u00b7heh\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "ART", "NN", "VMFIN", "PIS", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und macht es oftermahls nachdr\u00fccklicher bekannt:", "tokens": ["Und", "macht", "es", "of\u00b7ter\u00b7mahls", "nach\u00b7dr\u00fcck\u00b7li\u00b7cher", "be\u00b7kannt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum wenn Beredsamkeit nicht bey Gelehrten wohnet,", "tokens": ["Drum", "wenn", "Be\u00b7red\u00b7sam\u00b7keit", "nicht", "bey", "Ge\u00b7lehr\u00b7ten", "woh\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "KOUS", "NN", "PTKNEG", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So schadet es doch nicht, weil Hand und Feder frohnet.", "tokens": ["So", "scha\u00b7det", "es", "doch", "nicht", ",", "weil", "Hand", "und", "Fe\u00b7der", "froh\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKNEG", "$,", "KOUS", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Die B\u00fccher werden ja aufs theuerste bezahlt,", "tokens": ["Die", "B\u00fc\u00b7cher", "wer\u00b7den", "ja", "aufs", "theu\u00b7ers\u00b7te", "be\u00b7zahlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPRART", "ADJA", "VVPP", "$,"], "meter": "-+-+-+-+---+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Den Perlen gleich gesch\u00e4tzt, und heilig aufgehoben,", "tokens": ["Den", "Per\u00b7len", "gleich", "ge\u00b7sch\u00e4tzt", ",", "und", "hei\u00b7lig", "auf\u00b7ge\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "$,", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So, da\u00df die Nachwelt mu\u00df und kan Gelehrte loben,", "tokens": ["So", ",", "da\u00df", "die", "Nach\u00b7welt", "mu\u00df", "und", "kan", "Ge\u00b7lehr\u00b7te", "lo\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ART", "NN", "VMFIN", "KON", "VMFIN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weil jedem ihr Verdienst in Aug und Antlitz strahlt.", "tokens": ["Weil", "je\u00b7dem", "ihr", "Ver\u00b7dienst", "in", "Aug", "und", "Ant\u00b7litz", "strahlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Minerva nahm hierauf, Thalien bey der Hand,", "tokens": ["Mi\u00b7ner\u00b7va", "nahm", "hier\u00b7auf", ",", "Tha\u00b7li\u00b7en", "bey", "der", "Hand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PAV", "$,", "NN", "APPR", "ART", "NN", "$,"], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.2": {"text": "Und warf die Frage auf: Mein! sage ", "tokens": ["Und", "warf", "die", "Fra\u00b7ge", "auf", ":", "Mein", "!", "sa\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$.", "PPOSAT", "$.", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was meinst du, ", "tokens": ["Was", "meinst", "du", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Die Antwort folgte gleich: Sucht jemand was zu richten,", "tokens": ["Die", "Ant\u00b7wort", "folg\u00b7te", "gleich", ":", "Sucht", "je\u00b7mand", "was", "zu", "rich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$.", "VVFIN", "PIS", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So pflegt er erst bey sich zu sinnen und zu dichten.", "tokens": ["So", "pflegt", "er", "erst", "bey", "sich", "zu", "sin\u00b7nen", "und", "zu", "dich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PRF", "PTKZU", "VVINF", "KON", "APPR", "ADJA", "$."], "meter": "-+-+++-+-+-+-", "measure": "unknown.measure.septa"}}, "stanza.12": {"line.1": {"text": "Er fragt sich, bey sich selbst: Ist die\u00df zu meinem Nutz?", "tokens": ["Er", "fragt", "sich", ",", "bey", "sich", "selbst", ":", "Ist", "die\u00df", "zu", "mei\u00b7nem", "Nutz", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "$,", "APPR", "PRF", "ADV", "$.", "VAFIN", "PDS", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bringt mir auch diese That das Gl\u00fcck und Wohlergehen?", "tokens": ["Bringt", "mir", "auch", "die\u00b7se", "That", "das", "Gl\u00fcck", "und", "Woh\u00b7ler\u00b7ge\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PDAT", "NN", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da mu\u00df bey dem Verstand der Untersuch geschehen,", "tokens": ["Da", "mu\u00df", "bey", "dem", "Ver\u00b7stand", "der", "Un\u00b7ter\u00b7such", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "APPR", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und dieser fasset denn den Willen in dem Schutz;", "tokens": ["Und", "die\u00b7ser", "fas\u00b7set", "denn", "den", "Wil\u00b7len", "in", "dem", "Schutz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ADV", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Befindets der Verstand vor gut, so wirds vollzogen;", "tokens": ["Be\u00b7fin\u00b7dets", "der", "Ver\u00b7stand", "vor", "gut", ",", "so", "wirds", "voll\u00b7zo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "ADJD", "$,", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wo nicht, so kriegt der Will', mit Recht, den Scheide-Bogen.", "tokens": ["Wo", "nicht", ",", "so", "kriegt", "der", "Will'", ",", "mit", "Recht", ",", "den", "Schei\u00b7de\u00b7Bo\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$,", "ADV", "VVFIN", "ART", "NN", "$,", "APPR", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Verstand ist Herr und Haupt, der Wille ist sein Knecht,", "tokens": ["Ver\u00b7stand", "ist", "Herr", "und", "Haupt", ",", "der", "Wil\u00b7le", "ist", "sein", "Knecht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "KON", "NN", "$,", "ART", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer ist, dem dieser Satz und Schlu\u00df zuwider w\u00e4re:", "tokens": ["Wer", "ist", ",", "dem", "die\u00b7ser", "Satz", "und", "Schlu\u00df", "zu\u00b7wi\u00b7der", "w\u00e4\u00b7re", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$,", "PRELS", "PDAT", "NN", "KON", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df nur dem Herrn die Macht und W\u00fcrde zugeh\u00f6re,", "tokens": ["Da\u00df", "nur", "dem", "Herrn", "die", "Macht", "und", "W\u00fcr\u00b7de", "zu\u00b7ge\u00b7h\u00f6\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was der Verstand erkennt/ das ist dem Willen recht.", "tokens": ["Was", "der", "Ver\u00b7stand", "er\u00b7kennt", "/", "das", "ist", "dem", "Wil\u00b7len", "recht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$(", "PDS", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Wille ist gebeugt, und der Verstand obsieget,", "tokens": ["Der", "Wil\u00b7le", "ist", "ge\u00b7beugt", ",", "und", "der", "Ver\u00b7stand", "ob\u00b7sie\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "KON", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was Wunder, da\u00df der Will die Lorbern hier nicht krieget.", "tokens": ["Was", "Wun\u00b7der", ",", "da\u00df", "der", "Will", "die", "Lor\u00b7bern", "hier", "nicht", "krie\u00b7get", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$,", "KOUS", "ART", "VMFIN", "ART", "NN", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Gesetzt, es k\u00e4m jemand und sagte mir ins Ohr:", "tokens": ["Ge\u00b7setzt", ",", "es", "k\u00e4m", "je\u00b7mand", "und", "sag\u00b7te", "mir", "ins", "Ohr", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PPER", "VVFIN", "PIS", "KON", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Der Rhein lief auf den Berg und auf die h\u00f6chsten H\u00fcgel;", "tokens": ["Der", "Rhein", "lief", "auf", "den", "Berg", "und", "auf", "die", "h\u00f6chs\u00b7ten", "H\u00fc\u00b7gel", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "APPR", "ART", "NN", "KON", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das Eisen schwebte stets im Wasser hoch empor;", "tokens": ["Das", "Ei\u00b7sen", "schweb\u00b7te", "stets", "im", "Was\u00b7ser", "hoch", "em\u00b7por", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPRART", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Bienen k\u00f6nten nicht verwesen noch vermodern.", "tokens": ["Die", "Bie\u00b7nen", "k\u00f6n\u00b7ten", "nicht", "ver\u00b7we\u00b7sen", "noch", "ver\u00b7mo\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PTKNEG", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gesetzt, man wolte nun den Beyfall von mir fordern:", "tokens": ["Ge\u00b7setzt", ",", "man", "wol\u00b7te", "nun", "den", "Bey\u00b7fall", "von", "mir", "for\u00b7dern", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PIS", "VMFIN", "ADV", "ART", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "So g\u00e4b ich solchem Wind bey weiten kein Geh\u00f6r:", "tokens": ["So", "g\u00e4b", "ich", "sol\u00b7chem", "Wind", "bey", "wei\u00b7ten", "kein", "Ge\u00b7h\u00f6r", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "APPR", "ADJA", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Warum? denn mein Verstand kan solches nicht begreifen,", "tokens": ["Wa\u00b7rum", "?", "denn", "mein", "Ver\u00b7stand", "kan", "sol\u00b7ches", "nicht", "be\u00b7grei\u00b7fen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "KON", "PPOSAT", "NN", "VMFIN", "PIS", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es will der Widerspruch die Sinnen \u00fcberh\u00e4ufen.", "tokens": ["Es", "will", "der", "Wi\u00b7der\u00b7spruch", "die", "Sin\u00b7nen", "\u00fc\u00b7berh\u00b7\u00e4u\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Alleine, wenn man mir hierbey zuwider w\u00e4r,", "tokens": ["Al\u00b7lei\u00b7ne", ",", "wenn", "man", "mir", "hier\u00b7bey", "zu\u00b7wi\u00b7der", "w\u00e4r", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PIS", "PPER", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es spr\u00e4ch ein M\u00e4chtiger und Grosser dieser Erden", "tokens": ["Es", "spr\u00e4ch", "ein", "M\u00e4ch\u00b7ti\u00b7ger", "und", "Gros\u00b7ser", "die\u00b7ser", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "NN", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zu mir: Bejahe das; sonst must du Asche werden!", "tokens": ["Zu", "mir", ":", "Be\u00b7ja\u00b7he", "das", ";", "sonst", "must", "du", "A\u00b7sche", "wer\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$.", "VVFIN", "PDS", "$.", "ADV", "VMFIN", "PPER", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Die Furcht des Marters-Pein; der angedrohte Todt", "tokens": ["Die", "Furcht", "des", "Mar\u00b7ter\u00b7sPein", ";", "der", "an\u00b7ge\u00b7droh\u00b7te", "Todt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bewegten mich darzu, da\u00df ich mit gutem Willen", "tokens": ["Be\u00b7weg\u00b7ten", "mich", "dar\u00b7zu", ",", "da\u00df", "ich", "mit", "gu\u00b7tem", "Wil\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PAV", "$,", "KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Solch Zeug bejahete, und spr\u00e4ch: Man kans erf\u00fcllen;", "tokens": ["Solch", "Zeug", "be\u00b7ja\u00b7he\u00b7te", ",", "und", "spr\u00e4ch", ":", "Man", "kans", "er\u00b7f\u00fcl\u00b7len", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$,", "KON", "VVFIN", "$.", "PIS", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch aber der Verstand besorgt sich keiner Noth,", "tokens": ["Doch", "a\u00b7ber", "der", "Ver\u00b7stand", "be\u00b7sorgt", "sich", "kei\u00b7ner", "Noth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "PRF", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er glaubt das alles nicht. Drum ist gar leicht zu schliessen,", "tokens": ["Er", "glaubt", "das", "al\u00b7les", "nicht", ".", "Drum", "ist", "gar", "leicht", "zu", "schlies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "PIS", "PTKNEG", "$.", "PAV", "VAFIN", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Hier schwieg Thalia still, Minerva fuhre fort,", "tokens": ["Hier", "schwieg", "Tha\u00b7lia", "still", ",", "Mi\u00b7ner\u00b7va", "fuh\u00b7re", "fort", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "PTKVZ", "$,", "NE", "VVFIN", "PTKVZ", "$,"], "meter": "-++-+---+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Sah Euphrosinen an, und sprach: H\u00f6r was ich sage!", "tokens": ["Sah", "Eu\u00b7phro\u00b7si\u00b7nen", "an", ",", "und", "sprach", ":", "H\u00f6r", "was", "ich", "sa\u00b7ge", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "PTKVZ", "$,", "KON", "VVFIN", "$.", "NE", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie sagte: Freylich ist die\u00df wohl ein wahres Wort:", "tokens": ["Sie", "sag\u00b7te", ":", "Frey\u00b7lich", "ist", "die\u00df", "wohl", "ein", "wah\u00b7res", "Wort", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ADV", "VAFIN", "PDS", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Man stell nur einen Narrn zu liebenden Personen,", "tokens": ["Man", "stell", "nur", "ei\u00b7nen", "Narrn", "zu", "lie\u00b7ben\u00b7den", "Per\u00b7so\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADJD", "ADV", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er wird, wenn man ihn fragt, die Wahrheit wohl nicht schonen.", "tokens": ["Er", "wird", ",", "wenn", "man", "ihn", "fragt", ",", "die", "Wahr\u00b7heit", "wohl", "nicht", "scho\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$,", "ART", "NN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Setzt ferner einen Narrn zu dem, der B\u00f6ses liebt,", "tokens": ["Setzt", "fer\u00b7ner", "ei\u00b7nen", "Narrn", "zu", "dem", ",", "der", "B\u00f6\u00b7ses", "liebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR", "ART", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er wird gewi\u00df sein Thun mit allen seinen Werken,", "tokens": ["Er", "wird", "ge\u00b7wi\u00df", "sein", "Thun", "mit", "al\u00b7len", "sei\u00b7nen", "Wer\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPOSAT", "NN", "APPR", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auf die genauste Art erlauschen und bemerken:", "tokens": ["Auf", "die", "ge\u00b7naus\u00b7te", "Art", "er\u00b7lau\u00b7schen", "und", "be\u00b7mer\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dann glaube, da\u00df er dir vollkommne Nachricht giebt.", "tokens": ["Dann", "glau\u00b7be", ",", "da\u00df", "er", "dir", "voll\u00b7komm\u00b7ne", "Nach\u00b7richt", "giebt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "PPER", "PPER", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So trift das Sprichwort ein: Die Kinder und die Narren", "tokens": ["So", "trift", "das", "Sprich\u00b7wort", "ein", ":", "Die", "Kin\u00b7der", "und", "die", "Nar\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$.", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sehn blo\u00df der Wahrheit nach, und h\u00e4tten sie zw\u00f6lf Sparren.", "tokens": ["Sehn", "blo\u00df", "der", "Wahr\u00b7heit", "nach", ",", "und", "h\u00e4t\u00b7ten", "sie", "zw\u00f6lf", "Spar\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "PTKVZ", "$,", "KON", "VAFIN", "PPER", "CARD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Ja auch der gr\u00f6\u00dfte Narr, der noch so n\u00e4rrisch scheint,", "tokens": ["Ja", "auch", "der", "gr\u00f6\u00df\u00b7te", "Narr", ",", "der", "noch", "so", "n\u00e4r\u00b7risch", "scheint", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der ganz umnebelt ist, von Tollheit und von Rasen,", "tokens": ["Der", "ganz", "um\u00b7ne\u00b7belt", "ist", ",", "von", "Toll\u00b7heit", "und", "von", "Ra\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVPP", "VAFIN", "$,", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kan auf gewisse Art doch mit der Klugheit spasen,", "tokens": ["Kan", "auf", "ge\u00b7wis\u00b7se", "Art", "doch", "mit", "der", "Klug\u00b7heit", "spa\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ADJA", "NN", "ADV", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es wird nach meinem Sinn der David hier gemeint:", "tokens": ["Es", "wird", "nach", "mei\u00b7nem", "Sinn", "der", "Da\u00b7vid", "hier", "ge\u00b7meint", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "ART", "NE", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Derselbe war einmahl zu Gath am K\u00f6nigs-Hofe,", "tokens": ["Der\u00b7sel\u00b7be", "war", "ein\u00b7mahl", "zu", "Gath", "am", "K\u00f6\u00b7nigs\u00b7Ho\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "APPR", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Kaum sah ihn Herr und Frau, wie auch der Knecht und Zofe.", "tokens": ["Kaum", "sah", "ihn", "Herr", "und", "Frau", ",", "wie", "auch", "der", "Knecht", "und", "Zo\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "KON", "NN", "$,", "PWAV", "ADV", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "So schrie man alsobald: Da\u00df mu\u00df der David seyn,", "tokens": ["So", "schrie", "man", "al\u00b7so\u00b7bald", ":", "Da\u00df", "mu\u00df", "der", "Da\u00b7vid", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "$.", "KOUS", "VMFIN", "ART", "NE", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von dem der Weiber-Chor mit h\u00f6chst-erfreuten Zungen,", "tokens": ["Von", "dem", "der", "Wei\u00b7ber\u00b7Chor", "mit", "h\u00f6chst\u00b7er\u00b7freu\u00b7ten", "Zun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein frohes Sieges-Lied vor dem in Reihen sungen!", "tokens": ["Ein", "fro\u00b7hes", "Sie\u00b7ges\u00b7Lied", "vor", "dem", "in", "Rei\u00b7hen", "sun\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Drum stellt er sich so n\u00e4rrisch; jedoch nur blo\u00df zum Schein.", "tokens": ["Drum", "stellt", "er", "sich", "so", "n\u00e4r\u00b7risch", ";", "je\u00b7doch", "nur", "blo\u00df", "zum", "Schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "ADV", "ADJD", "$.", "ADV", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Wodurch ihn denn das Gl\u00fcck in seine Fl\u00fcgel nahme,", "tokens": ["Wo\u00b7durch", "ihn", "denn", "das", "Gl\u00fcck", "in", "sei\u00b7ne", "Fl\u00fc\u00b7gel", "nah\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und er auf diese Art der Todes-Noth entkame.", "tokens": ["Und", "er", "auf", "die\u00b7se", "Art", "der", "To\u00b7des\u00b7Noth", "ent\u00b7ka\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PDAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Wie mancher stellt sich n\u00e4rrsch um etwas zu vollziehn?", "tokens": ["Wie", "man\u00b7cher", "stellt", "sich", "n\u00e4rrsch", "um", "et\u00b7was", "zu", "voll\u00b7ziehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "PRF", "ADJD", "APPR", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die List, der tolle Wuth ist sein Habit und Kappe,", "tokens": ["Die", "List", ",", "der", "tol\u00b7le", "Wuth", "ist", "sein", "Ha\u00b7bit", "und", "Kap\u00b7pe", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er denkt, wenn ich nur was durch Raserey erschnappe", "tokens": ["Er", "denkt", ",", "wenn", "ich", "nur", "was", "durch", "Ra\u00b7se\u00b7rey", "er\u00b7schnap\u00b7pe"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "ADV", "PRELS", "APPR", "NN", "VVFIN"], "meter": "-+-+++-+-+---", "measure": "unknown.measure.hexa"}, "line.4": {"text": "So frag ich nichts darnach; kan nur mein Gl\u00fccke bliehn.", "tokens": ["So", "frag", "ich", "nichts", "dar\u00b7nach", ";", "kan", "nur", "mein", "Gl\u00fc\u00b7cke", "bliehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "PIS", "PAV", "$.", "VMFIN", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der ungereimte Sinn und Narren gleiches sprechen,", "tokens": ["Der", "un\u00b7ge\u00b7reim\u00b7te", "Sinn", "und", "Nar\u00b7ren", "glei\u00b7ches", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Betr\u00fcgt, besiegt und kan die allerkl\u00fcgsten schw\u00e4chen.", "tokens": ["Be\u00b7tr\u00fcgt", ",", "be\u00b7siegt", "und", "kan", "die", "al\u00b7ler\u00b7kl\u00fcgs\u00b7ten", "schw\u00e4\u00b7chen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVPP", "KON", "VMFIN", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Noch weiter: Mancher hat auch eine Missethat", "tokens": ["Noch", "wei\u00b7ter", ":", "Man\u00b7cher", "hat", "auch", "ei\u00b7ne", "Mis\u00b7se\u00b7that"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PTKVZ", "$.", "PIS", "VAFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gethan und ausge\u00fcbt, weshalber das Verbrechen", "tokens": ["Ge\u00b7than", "und", "aus\u00b7ge\u00b7\u00fcbt", ",", "we\u00b7shal\u00b7ber", "das", "Ver\u00b7bre\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVPP", "KON", "VVPP", "$,", "PWAV", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Richter mit Verhaft und Tode sucht zu r\u00e4chen,", "tokens": ["Der", "Rich\u00b7ter", "mit", "Ver\u00b7haft", "und", "To\u00b7de", "sucht", "zu", "r\u00e4\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und l\u00e4\u00dft kein Zeichen sehn, da\u00df Lindrung und Genad", "tokens": ["Und", "l\u00e4\u00dft", "kein", "Zei\u00b7chen", "sehn", ",", "da\u00df", "Lind\u00b7rung", "und", "Ge\u00b7nad"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIAT", "NN", "VVINF", "$,", "KOUS", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vor sein ver\u00fcbtes Werk zu merken, und zu hoffen:", "tokens": ["Vor", "sein", "ver\u00b7\u00fcb\u00b7tes", "Werk", "zu", "mer\u00b7ken", ",", "und", "zu", "hof\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$,", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Er wird von Furcht und Harm in seiner Noth betroffen;", "tokens": ["Er", "wird", "von", "Furcht", "und", "Harm", "in", "sei\u00b7ner", "Noth", "be\u00b7trof\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "So thut er, als obs ihm recht sehr zu Herzen ging,", "tokens": ["So", "thut", "er", ",", "als", "obs", "ihm", "recht", "sehr", "zu", "Her\u00b7zen", "ging", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOKOM", "KOUS", "PPER", "ADV", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Als ob er w\u00fcrklich schon in melancholschen Orden,", "tokens": ["Als", "ob", "er", "w\u00fcrk\u00b7lich", "schon", "in", "me\u00b7lan\u00b7chol\u00b7schen", "Or\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADJD", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und in der Narren-Zunft ein wahres Mitglied worden,", "tokens": ["Und", "in", "der", "Nar\u00b7ren\u00b7Zunft", "ein", "wah\u00b7res", "Mit\u00b7glied", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vermeint, da\u00df er dadurch was Linderung empfing:", "tokens": ["Ver\u00b7meint", ",", "da\u00df", "er", "da\u00b7durch", "was", "Lin\u00b7de\u00b7rung", "emp\u00b7fing", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "PAV", "PWS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gedenkt durch diese List dem Kerker zu entgehen,", "tokens": ["Ge\u00b7denkt", "durch", "die\u00b7se", "List", "dem", "Ker\u00b7ker", "zu", "ent\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "PDAT", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und hoft, es w\u00fcrde nicht so \u00fcbel um ihn stehen.", "tokens": ["Und", "hoft", ",", "es", "w\u00fcr\u00b7de", "nicht", "so", "\u00fc\u00b7bel", "um", "ihn", "ste\u00b7hen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPER", "VAFIN", "PTKNEG", "ADV", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Minerva fiel ihr drein, und sagte: H\u00f6ret auf!", "tokens": ["Mi\u00b7ner\u00b7va", "fiel", "ihr", "drein", ",", "und", "sag\u00b7te", ":", "H\u00f6\u00b7ret", "auf", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "$.", "VVFIN", "PTKVZ", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Ihr Wehrten! euer Wort und Spruch hat mich vergn\u00fcget,", "tokens": ["Ihr", "Wehr\u00b7ten", "!", "eu\u00b7er", "Wort", "und", "Spruch", "hat", "mich", "ver\u00b7gn\u00fc\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPOSAT", "NN", "KON", "NN", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "We\u00dfhalber meine Huld gedoppelt auf euch lieget.", "tokens": ["We\u00df\u00b7hal\u00b7ber", "mei\u00b7ne", "Huld", "ge\u00b7dop\u00b7pelt", "auf", "euch", "lie\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wohlan! ich schreibe nun, und nehme meinen Lauf", "tokens": ["Wo\u00b7hlan", "!", "ich", "schrei\u00b7be", "nun", ",", "und", "neh\u00b7me", "mei\u00b7nen", "Lauf"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$.", "PPER", "VVFIN", "ADV", "$,", "KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Von dieser Quelle fort, noch Pindus hohen Spitzen.", "tokens": ["Von", "die\u00b7ser", "Quel\u00b7le", "fort", ",", "noch", "Pin\u00b7dus", "ho\u00b7hen", "Spit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PTKVZ", "$,", "ADV", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Drauf fuhr sie in die H\u00f6h, und lie\u00df das Kleeblat sitzen.", "tokens": ["Drauf", "fuhr", "sie", "in", "die", "H\u00f6h", ",", "und", "lie\u00df", "das", "Klee\u00b7blat", "sit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "KON", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}