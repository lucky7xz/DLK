{"dta.poem.21783": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "ViII.  \n  Liebe glaubt keinem Neide.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Und/ wo ich dirs/ Zelinde/ schenke\nso hei\u00df' ich Peilkarastres nicht.", "tokens": ["Und", "/", "wo", "ich", "dirs", "/", "Ze\u00b7lin\u00b7de", "/", "schen\u00b7ke", "so", "hei\u00df'", "ich", "Peil\u00b7ka\u00b7rast\u00b7res", "nicht", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "PWAV", "PPER", "PIS", "$(", "NN", "$(", "VVFIN", "ADV", "VVFIN", "PPER", "NE", "PTKNEG", "$."], "meter": "-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Es denke doch nur einer/ denke/", "tokens": ["Es", "den\u00b7ke", "doch", "nur", "ei\u00b7ner", "/", "den\u00b7ke", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "$(", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "was diese Marigelle spricht.", "tokens": ["was", "die\u00b7se", "Ma\u00b7ri\u00b7gel\u00b7le", "spricht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich w\u00e4r\u2019 in ihr Gemach geschlichen", "tokens": ["Ich", "w\u00e4r'", "in", "ihr", "Ge\u00b7mach", "ge\u00b7schli\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "gleich als der Sonnen Gold verblichen", "tokens": ["gleich", "als", "der", "Son\u00b7nen", "Gold", "ver\u00b7bli\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "ART", "NN", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "da h\u00e4tt\u2019 ich mich wohin gelegt", "tokens": ["da", "h\u00e4tt'", "ich", "mich", "wo\u00b7hin", "ge\u00b7legt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "PWAV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "wo sie geheim zuschlaffen pflegt.", "tokens": ["wo", "sie", "ge\u00b7heim", "zu\u00b7schlaf\u00b7fen", "pflegt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADJD", "VVIZU", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Mein! worzu dienen doch die L\u00fcgen?", "tokens": ["Mein", "!", "wor\u00b7zu", "die\u00b7nen", "doch", "die", "L\u00fc\u00b7gen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$.", "PWAV", "PDS", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der Teuffel hat di\u00df Spiel gesehn.", "tokens": ["der", "Teuf\u00b7fel", "hat", "di\u00df", "Spiel", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PDS", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "h\u00f6r! knarrten damahls auch die Stiegen", "tokens": ["h\u00f6r", "!", "knarr\u00b7ten", "da\u00b7mahls", "auch", "die", "Stie\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$.", "VVFIN", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "als ich wolt\u2019 in die Kammer gehn?", "tokens": ["als", "ich", "wolt'", "in", "die", "Kam\u00b7mer", "gehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Gefiel dies/ da ich dich umschlunge", "tokens": ["Ge\u00b7fiel", "dies", "/", "da", "ich", "dich", "um\u00b7schlun\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PDS", "$(", "KOUS", "PPER", "PRF", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und mich an deine Seite drunge?", "tokens": ["und", "mich", "an", "dei\u00b7ne", "Sei\u00b7te", "drun\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Sich/ Ruhm-maul/ wie bestehstu nu/", "tokens": ["Sich", "/", "Ruhm\u00b7maul", "/", "wie", "be\u00b7steh\u00b7stu", "nu", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "$(", "NE", "$(", "PWAV", "ADJD", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "wer traute dir die Schnitte zu!", "tokens": ["wer", "trau\u00b7te", "dir", "die", "Schnit\u00b7te", "zu", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Jezt f\u00e4llt mirs ein. Das s\u00fcsse Lieben/", "tokens": ["Jezt", "f\u00e4llt", "mirs", "ein", ".", "Das", "s\u00fcs\u00b7se", "Lie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "PTKVZ", "$.", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "da\u00df ich mit Rosilen gef\u00fchrt/", "tokens": ["da\u00df", "ich", "mit", "Ro\u00b7si\u00b7len", "ge\u00b7f\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "hat dich zu solchem Fund getrieben", "tokens": ["hat", "dich", "zu", "sol\u00b7chem", "Fund", "ge\u00b7trie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "PIAT", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und mit der Neides-sucht ger\u00fchrt.", "tokens": ["und", "mit", "der", "Nei\u00b7des\u00b7sucht", "ge\u00b7r\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nu merk\u2019 ich was es soll bedeuten/", "tokens": ["Nu", "merk'", "ich", "was", "es", "soll", "be\u00b7deu\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PWS", "PPER", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "da\u00df du so neulich sachst zur Seiten/", "tokens": ["da\u00df", "du", "so", "neu\u00b7lich", "sachst", "zur", "Sei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVFIN", "APPRART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "als meine Lust/ Rosille kahm/", "tokens": ["als", "mei\u00b7ne", "Lust", "/", "Ro\u00b7sil\u00b7le", "kahm", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$(", "NE", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "und mich sanfft in die Arme nahm.", "tokens": ["und", "mich", "sanfft", "in", "die", "Ar\u00b7me", "nahm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Es war nur um mich zuverstossen/", "tokens": ["Es", "war", "nur", "um", "mich", "zu\u00b7ver\u00b7stos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "meinstu/ Rosille glaube dir?", "tokens": ["meins\u00b7tu", "/", "Ro\u00b7sil\u00b7le", "glau\u00b7be", "dir", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "NE", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcrwahr/ du schl\u00e4gest einen blossen/", "tokens": ["F\u00fcr\u00b7wahr", "/", "du", "schl\u00e4\u00b7gest", "ei\u00b7nen", "blos\u00b7sen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PPER", "VVFIN", "ART", "ADJA", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "mein Augen-wink gilt mehr bey ihr", "tokens": ["mein", "Au\u00b7gen\u00b7wink", "gilt", "mehr", "bey", "ihr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "APPR", "PPOSAT"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "als wenn du hundert-tausend Eyde", "tokens": ["als", "wenn", "du", "hun\u00b7der\u00b7ttau\u00b7send", "Ey\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOKOM", "KOUS", "PPER", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "w\u00fcrdst schweeren mir und ihr zu Leide.", "tokens": ["w\u00fcrdst", "schwee\u00b7ren", "mir", "und", "ihr", "zu", "Lei\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVFIN", "PPER", "KON", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Rosille merkt es zugeschwind", "tokens": ["Ro\u00b7sil\u00b7le", "merkt", "es", "zu\u00b7ge\u00b7schwind"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "was Falschheit/ Trug und Finten sind.", "tokens": ["was", "Falschheit", "/", "Trug", "und", "Fin\u00b7ten", "sind", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$(", "NN", "KON", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Du willst uns zwar zusammen hezzen", "tokens": ["Du", "willst", "uns", "zwar", "zu\u00b7sam\u00b7men", "hez\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "kommst aber he\u00dflich kaal darvon.", "tokens": ["kommst", "a\u00b7ber", "he\u00df\u00b7lich", "kaal", "dar\u00b7von", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "ADJD", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wir lachen der bescheinten Nezzen/", "tokens": ["wir", "la\u00b7chen", "der", "be\u00b7schein\u00b7ten", "Nez\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und sprechem allem Neide Hohn/", "tokens": ["und", "spre\u00b7chem", "al\u00b7lem", "Nei\u00b7de", "Hohn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "kein Fels ist je so fest gegr\u00fcndet", "tokens": ["kein", "Fels", "ist", "je", "so", "fest", "ge\u00b7gr\u00fcn\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "als unsre Liebe sich befindet.", "tokens": ["als", "uns\u00b7re", "Lie\u00b7be", "sich", "be\u00b7fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "St\u00fcrm immer zu. Wir stehen fest", "tokens": ["St\u00fcrm", "im\u00b7mer", "zu", ".", "Wir", "ste\u00b7hen", "fest"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ADV", "PTKVZ", "$.", "PPER", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "als sich kein Berg bewegen l\u00e4st.", "tokens": ["als", "sich", "kein", "Berg", "be\u00b7we\u00b7gen", "l\u00e4st", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PIAT", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Drum denke nicht/ Zelinde/ denke", "tokens": ["Drum", "den\u00b7ke", "nicht", "/", "Ze\u00b7lin\u00b7de", "/", "den\u00b7ke"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PAV", "VVFIN", "PTKNEG", "$(", "NN", "$(", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "da\u00df ein verf\u00e4lschtes L\u00fcgen-Kind", "tokens": ["da\u00df", "ein", "ver\u00b7f\u00e4lschtes", "L\u00fc\u00b7gen\u00b7Kind"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Rosillen von mir abelenke.", "tokens": ["Ro\u00b7sil\u00b7len", "von", "mir", "a\u00b7be\u00b7len\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "H\u00e4ttstu noch duppelt mehr ersinnt/", "tokens": ["H\u00e4tts\u00b7tu", "noch", "dup\u00b7pelt", "mehr", "er\u00b7sinnt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "wird doch mein Schaz mich nimmer hassen", "tokens": ["wird", "doch", "mein", "Schaz", "mich", "nim\u00b7mer", "has\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Gott lob/ da\u00df ich nicht sch\u00fcldig bin", "tokens": ["Gott", "lob", "/", "da\u00df", "ich", "nicht", "sch\u00fcl\u00b7dig", "bin"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "NN", "$(", "KOUS", "PPER", "PTKNEG", "ADJD", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}