{"textgrid.poem.48748": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "35. Auf Mons. Herman von Staden, den 11. Augusti 1636, \u00fcber Casan", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Freund, k\u00f6mmt dein Name her von Harren oder H\u00e4rmen,", "tokens": ["Freund", ",", "k\u00f6mmt", "dein", "Na\u00b7me", "her", "von", "Har\u00b7ren", "o\u00b7der", "H\u00e4r\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPOSAT", "NN", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "die beide traurig sind und hei\u00dfen traurig sein?", "tokens": ["die", "bei\u00b7de", "trau\u00b7rig", "sind", "und", "hei\u00b7\u00dfen", "trau\u00b7rig", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADJD", "VAFIN", "KON", "VVFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der keines dient f\u00fcr uns auf diesen Sonnenschein,", "tokens": ["Der", "kei\u00b7nes", "dient", "f\u00fcr", "uns", "auf", "die\u00b7sen", "Son\u00b7nen\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "APPR", "PPER", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "der dir zu Ehren k\u00f6mmt. Mars liebe seinen Lermen,", "tokens": ["der", "dir", "zu", "Eh\u00b7ren", "k\u00f6mmt", ".", "Mars", "lie\u00b7be", "sei\u00b7nen", "Ler\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "$.", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "wer melankolisch ist, der mag sich tolle schwermen.", "tokens": ["wer", "me\u00b7lan\u00b7ko\u00b7lisch", "ist", ",", "der", "mag", "sich", "tol\u00b7le", "schwer\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$,", "PRELS", "VMFIN", "PRF", "ADJA", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "La\u00df du uns bringen her, was Spanien und der Rhein", "tokens": ["La\u00df", "du", "uns", "brin\u00b7gen", "her", ",", "was", "Spa\u00b7ni\u00b7en", "und", "der", "Rhein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PRF", "VVINF", "PTKVZ", "$,", "PRELS", "NE", "KON", "ART", "NE"], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "uns S\u00fc\u00dfes schicken zu. Hier, Kleiner, schenk uns ein!", "tokens": ["uns", "S\u00fc\u00b7\u00dfes", "schi\u00b7cken", "zu", ".", "Hier", ",", "Klei\u00b7ner", ",", "schenk", "uns", "ein", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVFIN", "PTKVZ", "$.", "ADV", "$,", "NN", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wir wollen unsern Sinn mit einem Trunk erw\u00e4rmen.", "tokens": ["Wir", "wol\u00b7len", "un\u00b7sern", "Sinn", "mit", "ei\u00b7nem", "Trunk", "er\u00b7w\u00e4r\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Was aber wil ich das bei wilden ", "tokens": ["Was", "a\u00b7ber", "wil", "ich", "das", "bei", "wil\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "VMFIN", "PPER", "PDS", "APPR", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "von denen Bacchus nichts, sie nichts von Bacchus wissen?", "tokens": ["von", "de\u00b7nen", "Bac\u00b7chus", "nichts", ",", "sie", "nichts", "von", "Bac\u00b7chus", "wis\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "NE", "PIS", "$,", "PPER", "PIS", "APPR", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch sprich dein Mutterfa\u00df und Flaschenfutter an.", "tokens": ["Doch", "sprich", "dein", "Mut\u00b7ter\u00b7fa\u00df", "und", "Fla\u00b7schen\u00b7fut\u00b7ter", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Schenkst du nicht allzuvoll, so darf man nichts versch\u00fctten.", "tokens": ["Schenkst", "du", "nicht", "all\u00b7zu\u00b7voll", ",", "so", "darf", "man", "nichts", "ver\u00b7sch\u00fct\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADJD", "$,", "ADV", "VMFIN", "PIS", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "F\u00fcr englisches Konfect gib Rigschen Lachs und Butten.", "tokens": ["F\u00fcr", "eng\u00b7li\u00b7sches", "Kon\u00b7fect", "gib", "Rig\u00b7schen", "Lachs", "und", "But\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVIMP", "NE", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer dann nicht ist vergn\u00fcgt, der ist kein guter Man.", "tokens": ["Wer", "dann", "nicht", "ist", "ver\u00b7gn\u00fcgt", ",", "der", "ist", "kein", "gu\u00b7ter", "Man", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PTKNEG", "VAFIN", "VVPP", "$,", "PRELS", "VAFIN", "PIAT", "ADJA", "PIS", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}