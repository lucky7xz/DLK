{"textgrid.poem.44244": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "[mein Reichthum ist ein ehrlich Herz]", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mein Reichthum ist ein ehrlich Herz,", "tokens": ["Mein", "Reicht\u00b7hum", "ist", "ein", "ehr\u00b7lich", "Herz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Schild ein unverzagt Gewi\u00dfen.", "tokens": ["Mein", "Schild", "ein", "un\u00b7ver\u00b7zagt", "Ge\u00b7wi\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dies d\u00e4mpft den eu\u00dferlichen Schmerz", "tokens": ["Dies", "d\u00e4mpft", "den", "eu\u00b7\u00dfer\u00b7li\u00b7chen", "Schmerz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und ist mein sanftes Ruhek\u00fc\u00dfen,", "tokens": ["Und", "ist", "mein", "sanf\u00b7tes", "Ru\u00b7he\u00b7k\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn Feind, Verfolgung, Gram und Neid", "tokens": ["Wenn", "Feind", ",", "Ver\u00b7fol\u00b7gung", ",", "Gram", "und", "Neid"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die angebohrne Z\u00e4rtligkeit", "tokens": ["Die", "an\u00b7ge\u00b7bohr\u00b7ne", "Z\u00e4rt\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Des schwachen Fleisches schmei\u00dfen wollen;", "tokens": ["Des", "schwa\u00b7chen", "Flei\u00b7sches", "schmei\u00b7\u00dfen", "wol\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und gieng es noch so scharf und bunt,", "tokens": ["Und", "gieng", "es", "noch", "so", "scharf", "und", "bunt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So schw\u00f6r ich, da\u00df sie doch den Mund", "tokens": ["So", "schw\u00f6r", "ich", ",", "da\u00df", "sie", "doch", "den", "Mund"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Zu keinem Fluche zwingen sollen.", "tokens": ["Zu", "kei\u00b7nem", "Flu\u00b7che", "zwin\u00b7gen", "sol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Dies thu nicht ich aus eigner Kraft,", "tokens": ["Dies", "thu", "nicht", "ich", "aus", "eig\u00b7ner", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKNEG", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dies thut des Allerh\u00f6chsten G\u00fcte,", "tokens": ["Dies", "thut", "des", "Al\u00b7ler\u00b7h\u00f6chs\u00b7ten", "G\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Durch Kunst, Vernunft und Wi\u00dfenschaft", "tokens": ["Durch", "Kunst", ",", "Ver\u00b7nunft", "und", "Wi\u00b7\u00dfen\u00b7schaft"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Erh\u00e4lt und st\u00e4rckt sie mein Gem\u00fcthe.", "tokens": ["Er\u00b7h\u00e4lt", "und", "st\u00e4rckt", "sie", "mein", "Ge\u00b7m\u00fc\u00b7the", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was ringt man so nach Ruhm und Geld?", "tokens": ["Was", "ringt", "man", "so", "nach", "Ruhm", "und", "Geld", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Man seh die Gro\u00dfen dieser Welt,", "tokens": ["Man", "seh", "die", "Gro\u00b7\u00dfen", "die\u00b7ser", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sie haben beides doch zur B\u00fcrde.", "tokens": ["Sie", "ha\u00b7ben", "bei\u00b7des", "doch", "zur", "B\u00fcr\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wer mit sich selbst zufrieden lebt,", "tokens": ["Wer", "mit", "sich", "selbst", "zu\u00b7frie\u00b7den", "lebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PRF", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Aus Faulheit nicht sein Pfund vergr\u00e4bt,", "tokens": ["Aus", "Faul\u00b7heit", "nicht", "sein", "Pfund", "ver\u00b7gr\u00e4bt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKNEG", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Hat mehr als Sclaven hoher W\u00fcrde.", "tokens": ["Hat", "mehr", "als", "Scla\u00b7ven", "ho\u00b7her", "W\u00fcr\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "KOUS", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Und darum las, erfahrner Scholl,", "tokens": ["Und", "da\u00b7rum", "las", ",", "er\u00b7fahr\u00b7ner", "Scholl", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das, was nicht bleiben will, entrinnen.", "tokens": ["Das", ",", "was", "nicht", "blei\u00b7ben", "will", ",", "ent\u00b7rin\u00b7nen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PTKNEG", "VVINF", "VMFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der P\u00f6bel wird bey Schaden toll,", "tokens": ["Der", "P\u00f6\u00b7bel", "wird", "bey", "Scha\u00b7den", "toll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du hast ja edler Blut und Sinnen.", "tokens": ["Du", "hast", "ja", "ed\u00b7ler", "Blut", "und", "Sin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Verliere nicht mit Hab und Gut", "tokens": ["Ver\u00b7lie\u00b7re", "nicht", "mit", "Hab", "und", "Gut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den christlich-weisen Heldenmuth,", "tokens": ["Den", "christ\u00b7lich\u00b7wei\u00b7sen", "Hel\u00b7den\u00b7muth", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der \u00fcber Neid und Ungl\u00fcck sieget;", "tokens": ["Der", "\u00fc\u00b7ber", "Neid", "und", "Un\u00b7gl\u00fcck", "sie\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Du siehst ja t\u00e4glich Unbestand,", "tokens": ["Du", "siehst", "ja", "t\u00e4g\u00b7lich", "Un\u00b7be\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Man wendet \u00f6fters kaum die Hand,", "tokens": ["Man", "wen\u00b7det", "\u00f6f\u00b7ters", "kaum", "die", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Da der, so gestern stieg, schon lieget.", "tokens": ["Da", "der", ",", "so", "ge\u00b7stern", "stieg", ",", "schon", "lie\u00b7get", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ART", "$,", "ADV", "ADV", "VVFIN", "$,", "ADV", "VVFIN", "$."], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Der Himmel hat dich einer Last,", "tokens": ["Der", "Him\u00b7mel", "hat", "dich", "ei\u00b7ner", "Last", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Gl\u00fccke seines Jochs entladen;", "tokens": ["Das", "Gl\u00fc\u00b7cke", "sei\u00b7nes", "Jochs", "ent\u00b7la\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So lange du die Feder hast,", "tokens": ["So", "lan\u00b7ge", "du", "die", "Fe\u00b7der", "hast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So lange kommstu nicht zu Schaden.", "tokens": ["So", "lan\u00b7ge", "komms\u00b7tu", "nicht", "zu", "Scha\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dein Wiz, dein Eifer und Verstand", "tokens": ["Dein", "Wiz", ",", "dein", "Ei\u00b7fer", "und", "Ver\u00b7stand"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hilft auch vor unser Vaterland", "tokens": ["Hilft", "auch", "vor", "un\u00b7ser", "Va\u00b7ter\u00b7land"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "In seiner Stille Brodt erwerben;", "tokens": ["In", "sei\u00b7ner", "Stil\u00b7le", "Brodt", "er\u00b7wer\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Du wachst und sinnst vor andrer Heil,", "tokens": ["Du", "wachst", "und", "sinnst", "vor", "an\u00b7drer", "Heil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Nimmst t\u00e4glich dein bescheiden Theil", "tokens": ["Nimmst", "t\u00e4g\u00b7lich", "dein", "be\u00b7schei\u00b7den", "Theil"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und kanst dereinst mit Frieden sterben.", "tokens": ["Und", "kanst", "de\u00b7reinst", "mit", "Frie\u00b7den", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Was n\u00fczt ein gro\u00dfer \u00dcberflu\u00df?", "tokens": ["Was", "n\u00fczt", "ein", "gro\u00b7\u00dfer", "\u00dc\u00b7berf\u00b7lu\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er macht uns vor der Welt verd\u00e4chtig,", "tokens": ["Er", "macht", "uns", "vor", "der", "Welt", "ver\u00b7d\u00e4ch\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Zeugt Hochmuth, Sorgen und Verdru\u00df,", "tokens": ["Zeugt", "Hoch\u00b7muth", ",", "Sor\u00b7gen", "und", "Ver\u00b7dru\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Man ist dabey sein selbst nicht m\u00e4chtig.", "tokens": ["Man", "ist", "da\u00b7bey", "sein", "selbst", "nicht", "m\u00e4ch\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PAV", "PPOSAT", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wer Herz und Wuntsch an Kasten henckt,", "tokens": ["Wer", "Herz", "und", "Wunt\u00b7sch", "an", "Kas\u00b7ten", "henckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-++-+-+", "measure": "unknown.measure.penta"}, "line.6": {"text": "Der wird gedr\u00fcckt, versucht, gekr\u00e4nckt,", "tokens": ["Der", "wird", "ge\u00b7dr\u00fcckt", ",", "ver\u00b7sucht", ",", "ge\u00b7kr\u00e4nckt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PDS", "VAFIN", "VVPP", "$,", "VVPP", "$,", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der Geiz verfolgt ihn bis zur Kr\u00fccke;", "tokens": ["Der", "Geiz", "ver\u00b7folgt", "ihn", "bis", "zur", "Kr\u00fc\u00b7cke", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Er scharrt vor fremde Schwelgerey,", "tokens": ["Er", "scharrt", "vor", "frem\u00b7de", "Schwel\u00b7ge\u00b7rey", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Legt oft den Fluch mit Thalern bey", "tokens": ["Legt", "oft", "den", "Fluch", "mit", "Tha\u00b7lern", "bey"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und wird ein Knecht vom blinden Gl\u00fccke.", "tokens": ["Und", "wird", "ein", "Knecht", "vom", "blin\u00b7den", "Gl\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "O Herrschaft, die uns sch\u00e4rfer qu\u00e4lt,", "tokens": ["O", "Herr\u00b7schaft", ",", "die", "uns", "sch\u00e4r\u00b7fer", "qu\u00e4lt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PRELS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als immermehr Tyrannen pflegen!", "tokens": ["Als", "im\u00b7mer\u00b7mehr", "Ty\u00b7ran\u00b7nen", "pfle\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wie mancher kluger Anschlag fehlt?", "tokens": ["Wie", "man\u00b7cher", "klu\u00b7ger", "An\u00b7schlag", "fehlt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie mancher f\u00e4llt auf graden Wegen?", "tokens": ["Wie", "man\u00b7cher", "f\u00e4llt", "auf", "gra\u00b7den", "We\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wer b\u00fcrgt uns vor Betrug und List,", "tokens": ["Wer", "b\u00fcrgt", "uns", "vor", "Be\u00b7trug", "und", "List", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die allzeit klug und munter ist,", "tokens": ["Die", "all\u00b7zeit", "klug", "und", "mun\u00b7ter", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "KON", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Uns, wo man nicht gedenckt, zu greifen?", "tokens": ["Uns", ",", "wo", "man", "nicht", "ge\u00b7denckt", ",", "zu", "grei\u00b7fen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "PWAV", "PIS", "PTKNEG", "VVPP", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wer sieht zum Voraus Sturm und Glut,", "tokens": ["Wer", "sieht", "zum", "Vo\u00b7raus", "Sturm", "und", "Glut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPRART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und welcher Wechsel spricht uns gut,", "tokens": ["Und", "wel\u00b7cher", "Wech\u00b7sel", "spricht", "uns", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wenn Schwerd und Bley Pall\u00e4ste schleifen?", "tokens": ["Wenn", "Schwerd", "und", "Bley", "Pal\u00b7l\u00e4s\u00b7te", "schlei\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Die Armuth, spricht man, pflegt der Spott", "tokens": ["Die", "Ar\u00b7muth", ",", "spricht", "man", ",", "pflegt", "der", "Spott"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "VVFIN", "PIS", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie Rauch die Flamme zu begleiten.", "tokens": ["Wie", "Rauch", "die", "Flam\u00b7me", "zu", "be\u00b7glei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "O nein, die Ehre kommt von Gott,", "tokens": ["O", "nein", ",", "die", "Eh\u00b7re", "kommt", "von", "Gott", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKANT", "$,", "ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vom Rechtthun und von weisen Leuten.", "tokens": ["Vom", "Recht\u00b7thun", "und", "von", "wei\u00b7sen", "Leu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Du hast schon manchem treu gedient,", "tokens": ["Du", "hast", "schon", "man\u00b7chem", "treu", "ge\u00b7dient", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der jezt an Stand und Wucher gr\u00fcnt;", "tokens": ["Der", "jezt", "an", "Stand", "und", "Wu\u00b7cher", "gr\u00fcnt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Erg\u00f6ze dich an fremden Fr\u00fcchten,", "tokens": ["Er\u00b7g\u00f6\u00b7ze", "dich", "an", "frem\u00b7den", "Fr\u00fcch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sie sind des Saamens wegen dein", "tokens": ["Sie", "sind", "des", "Saa\u00b7mens", "we\u00b7gen", "dein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und k\u00f6nnen dir viel Trost verleihn,", "tokens": ["Und", "k\u00f6n\u00b7nen", "dir", "viel", "Trost", "ver\u00b7leihn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Das Haupt im Alter aufzurichten.", "tokens": ["Das", "Haupt", "im", "Al\u00b7ter", "auf\u00b7zu\u00b7rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Nimm dies Ged\u00e4chtn\u00fc\u00df von Papier,", "tokens": ["Nimm", "dies", "Ge\u00b7d\u00e4cht\u00b7n\u00fc\u00df", "von", "Pa\u00b7pier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PDS", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es wird so lange bl\u00fchn und leben,", "tokens": ["Es", "wird", "so", "lan\u00b7ge", "bl\u00fchn", "und", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als Schickung, Zeit und Nachwelt mir", "tokens": ["Als", "Schi\u00b7ckung", ",", "Zeit", "und", "Nach\u00b7welt", "mir"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "$,", "NN", "KON", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und meiner Muse Kr\u00e4nze geben.", "tokens": ["Und", "mei\u00b7ner", "Mu\u00b7se", "Kr\u00e4n\u00b7ze", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dein klug-, ge\u00fcbt- und frommer Geist", "tokens": ["Dein", "klug", ",", "ge\u00b7\u00fcb\u00b7t", "und", "from\u00b7mer", "Geist"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "TRUNC", "$,", "TRUNC", "KON", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Hat oft mein Ohr mit Lust gespeist", "tokens": ["Hat", "oft", "mein", "Ohr", "mit", "Lust", "ge\u00b7speist"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "APPR", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und Herz und Neigung eingenommen,", "tokens": ["Und", "Herz", "und", "Nei\u00b7gung", "ein\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mein Herz, das jezt viel Freud erf\u00e4hrt,", "tokens": ["Mein", "Herz", ",", "das", "jezt", "viel", "Freud", "er\u00b7f\u00e4hrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Indem es deines Nahmens Werth", "tokens": ["In\u00b7dem", "es", "dei\u00b7nes", "Nah\u00b7mens", "Werth"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Auch in sein Freundschaftsbuch bekommen.", "tokens": ["Auch", "in", "sein", "Freund\u00b7schafts\u00b7buch", "be\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "O w\u00fcrdestu nur etwas jung,", "tokens": ["O", "w\u00fcr\u00b7des\u00b7tu", "nur", "et\u00b7was", "jung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was wollt ich nicht von dir noch h\u00f6ren!", "tokens": ["Was", "wollt", "ich", "nicht", "von", "dir", "noch", "h\u00f6\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "PTKNEG", "APPR", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Erfahrung kommt nicht durch den Sprung,", "tokens": ["Er\u00b7fah\u00b7rung", "kommt", "nicht", "durch", "den", "Sprung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKNEG", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Noch von sich selbst und ohne Lehren.", "tokens": ["Noch", "von", "sich", "selbst", "und", "oh\u00b7ne", "Leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PRF", "ADV", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Du kennst Gem\u00fcther, Art und Welt,", "tokens": ["Du", "kennst", "Ge\u00b7m\u00fc\u00b7ther", ",", "Art", "und", "Welt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Du weist, was Stich' und Farben h\u00e4lt", "tokens": ["Du", "weist", ",", "was", "Stich'", "und", "Far\u00b7ben", "h\u00e4lt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PWS", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und wie so k\u00fcnstlich viel betriegen.", "tokens": ["Und", "wie", "so", "k\u00fcnst\u00b7lich", "viel", "be\u00b7trie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "In allem sollte mich dein Rath,", "tokens": ["In", "al\u00b7lem", "soll\u00b7te", "mich", "dein", "Rath", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VMFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Auch in der Ferne durch ein Blat,", "tokens": ["Auch", "in", "der", "Fer\u00b7ne", "durch", "ein", "Blat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Erinnern, be\u00dfern und vergn\u00fcgen.", "tokens": ["E\u00b7rin\u00b7nern", ",", "be\u00b7\u00dfern", "und", "ver\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJD", "KON", "VVINF", "$."], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "Dein Ziel, mein G\u00f6nner, steh noch weit,", "tokens": ["Dein", "Ziel", ",", "mein", "G\u00f6n\u00b7ner", ",", "steh", "noch", "weit", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Himmel st\u00e4rcke dir die Glieder", "tokens": ["Der", "Him\u00b7mel", "st\u00e4r\u00b7cke", "dir", "die", "Glie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und gebe dir noch in der Zeit", "tokens": ["Und", "ge\u00b7be", "dir", "noch", "in", "der", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dein Wachsthum an dem Sohne wieder.", "tokens": ["Dein", "Wach\u00b7sthum", "an", "dem", "Soh\u00b7ne", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Du aber las jezt mit Bedacht,", "tokens": ["Du", "a\u00b7ber", "las", "jezt", "mit", "Be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was einmahl hin ist, aus der Acht", "tokens": ["Was", "ein\u00b7mahl", "hin", "ist", ",", "aus", "der", "Acht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "ADV", "ADV", "VAFIN", "$,", "APPR", "ART", "CARD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und kehre deiner Qual den R\u00fccken.", "tokens": ["Und", "keh\u00b7re", "dei\u00b7ner", "Qual", "den", "R\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wer Gott ohn Aberglauben liebt,", "tokens": ["Wer", "Gott", "ohn", "A\u00b7berg\u00b7lau\u00b7ben", "liebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Dem Nechsten hilft und gern vergiebt,", "tokens": ["Dem", "Nechs\u00b7ten", "hilft", "und", "gern", "ver\u00b7giebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Dem mu\u00df sich alles gl\u00fccklich schicken.", "tokens": ["Dem", "mu\u00df", "sich", "al\u00b7les", "gl\u00fcck\u00b7lich", "schi\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PRF", "PIS", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}