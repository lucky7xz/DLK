{"dta.poem.7024": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1730", "urn": "urn:nbn:de:kobv:b4-20087-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "O GOTT! aus Dessen Wort Lufft, Meer und Erde", "tokens": ["O", "GoTT", "!", "aus", "Des\u00b7sen", "Wort", "Lufft", ",", "Meer", "und", "Er\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NE", "$.", "APPR", "PDAT", "NN", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "quillet,", "tokens": ["quil\u00b7let", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Der Erde, Meer und Lufft, allgegenw\u00e4rtig f\u00fcllet;", "tokens": ["Der", "Er\u00b7de", ",", "Meer", "und", "Lufft", ",", "all\u00b7ge\u00b7gen\u00b7w\u00e4r\u00b7tig", "f\u00fcl\u00b7let", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "KON", "NN", "$,", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich lobe Deine Lieb\u2019, und preise Deine Macht,", "tokens": ["Ich", "lo\u00b7be", "Dei\u00b7ne", "Lieb'", ",", "und", "prei\u00b7se", "Dei\u00b7ne", "Macht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Auch da, beym schnellen Blitz, der strenge Donner kracht.", "tokens": ["Auch", "da", ",", "beym", "schnel\u00b7len", "Blitz", ",", "der", "stren\u00b7ge", "Don\u00b7ner", "kracht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "APPRART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Dreut gleich der Grund der Welt zu wancken, zu vergehen,", "tokens": ["Dreut", "gleich", "der", "Grund", "der", "Welt", "zu", "wan\u00b7cken", ",", "zu", "ver\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "L\u00e4sst die geborstne Lufft gleich nichts, als Flammen, sehen,", "tokens": ["L\u00e4sst", "die", "ge\u00b7borst\u00b7ne", "Lufft", "gleich", "nichts", ",", "als", "Flam\u00b7men", ",", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "ADV", "PIS", "$,", "KOUS", "NN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Rauscht gleich der Winde Wuth, netzt gleich ein Regen-", "tokens": ["Rauscht", "gleich", "der", "Win\u00b7de", "Wuth", ",", "netzt", "gleich", "ein", "Re\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "NN", "NN", "$,", "VVFIN", "ADV", "ART", "TRUNC"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Schwall", "tokens": ["Schwall"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Das \u00fcberstr\u00f6mte Land mit Wassern \u00fcberall.", "tokens": ["Das", "\u00fc\u00b7ber\u00b7str\u00f6m\u00b7te", "Land", "mit", "Was\u00b7sern", "\u00fc\u00b7be\u00b7rall", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "So zittert, blitzt und rauscht, doch alles GOTT zu Ehren,", "tokens": ["So", "zit\u00b7tert", ",", "blitzt", "und", "rauscht", ",", "doch", "al\u00b7les", "GoTT", "zu", "Eh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,", "ADV", "PIAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er l\u00e4sset seine Stimm\u2019 im Donner gleichsam h\u00f6ren,", "tokens": ["Er", "l\u00e4s\u00b7set", "sei\u00b7ne", "Stimm'", "im", "Don\u00b7ner", "gleich\u00b7sam", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPRART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er zeiget seine Krafft und seine Lieb\u2019, es bricht,", "tokens": ["Er", "zei\u00b7get", "sei\u00b7ne", "Krafft", "und", "sei\u00b7ne", "Lieb'", ",", "es", "bricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Selbst durch den lichten Blitz, des Sch\u00f6pfers Weisheits-", "tokens": ["Selbst", "durch", "den", "lich\u00b7ten", "Blitz", ",", "des", "Sch\u00f6p\u00b7fers", "Weis\u00b7heits"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Licht.", "tokens": ["Licht", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+", "measure": "single.up"}}, "stanza.4": {"line.1": {"text": "Denn, der durch schw\u00fclen Dunst zu heisser Schwefel-D\u00fcffte,", "tokens": ["Denn", ",", "der", "durch", "schw\u00fc\u00b7len", "Dunst", "zu", "heis\u00b7ser", "Schwe\u00b7fel\u00b7D\u00fcff\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Aus seinem Gleich-Gewicht gepresste, Creis\u2019 der L\u00fcffte", "tokens": ["Aus", "sei\u00b7nem", "Gleich\u00b7Ge\u00b7wicht", "ge\u00b7press\u00b7te", ",", "Creis'", "der", "L\u00fcff\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "$,", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wird durch den regen Blitz gereinigt, ausgeleert,", "tokens": ["Wird", "durch", "den", "re\u00b7gen", "Blitz", "ge\u00b7rei\u00b7nigt", ",", "aus\u00b7ge\u00b7leert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "NN", "VVPP", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und durch das schnelle Feur zertheilt und aufgekl\u00e4rt.", "tokens": ["Und", "durch", "das", "schnel\u00b7le", "Feur", "zer\u00b7theilt", "und", "auf\u00b7ge\u00b7kl\u00e4rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Das, durch der Sonnen Gluht, und ihrer Strahlen Blitze,", "tokens": ["Das", ",", "durch", "der", "Son\u00b7nen", "Gluht", ",", "und", "ih\u00b7rer", "Strah\u00b7len", "Blit\u00b7ze", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "APPR", "ART", "NN", "NN", "$,", "KON", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Fast gantz versengte Gras, das, durch so stete Hitze", "tokens": ["Fast", "gantz", "ver\u00b7seng\u00b7te", "Gras", ",", "das", ",", "durch", "so", "ste\u00b7te", "Hit\u00b7ze"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADJA", "NN", "$,", "PDS", "$,", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gantz aufgeborstne Land w\u00fcrd\u2019 Asche, Sand und Stein,", "tokens": ["Gantz", "auf\u00b7ge\u00b7borst\u00b7ne", "Land", "w\u00fcrd'", "A\u00b7sche", ",", "Sand", "und", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VAFIN", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und folglich Mensch und Vieh bald ausgerottet seyn.", "tokens": ["Und", "folg\u00b7lich", "Mensch", "und", "Vieh", "bald", "aus\u00b7ge\u00b7rot\u00b7tet", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "KON", "NN", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "So aber f\u00fchret GOTT, zum Heil, und nicht zur Ruhten,", "tokens": ["So", "a\u00b7ber", "f\u00fch\u00b7ret", "GoTT", ",", "zum", "Heil", ",", "und", "nicht", "zur", "Ruh\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "NE", "$,", "APPRART", "NN", "$,", "KON", "PTKNEG", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Wolcken feuchte Frucht, die Seegens-reiche Fluhten,", "tokens": ["Der", "Wol\u00b7cken", "feuch\u00b7te", "Frucht", ",", "die", "See\u00b7gens\u00b7rei\u00b7che", "Fluh\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Durch Wind und Wetter her, macht durch der Blitze", "tokens": ["Durch", "Wind", "und", "Wet\u00b7ter", "her", ",", "macht", "durch", "der", "Blit\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "PTKVZ", "$,", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Brand", "tokens": ["Brand"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Nicht nur die L\u00fcffte rein, tr\u00e4nckt auch das d\u00fcrre Land.", "tokens": ["Nicht", "nur", "die", "L\u00fcff\u00b7te", "rein", ",", "tr\u00e4nckt", "auch", "das", "d\u00fcr\u00b7re", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "ADJD", "$,", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "O Weisheit sonder Ziel! O Allmacht sonder Gleichen!", "tokens": ["O", "Weis\u00b7heit", "son\u00b7der", "Ziel", "!", "O", "All\u00b7macht", "son\u00b7der", "Glei\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "$.", "NE", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "O wahrer Vater-Lieb untr\u00fcglich-helles Zeichen!", "tokens": ["O", "wah\u00b7rer", "Va\u00b7ter\u00b7Lieb", "u\u00b7ntr\u00fcg\u00b7lich\u00b7hel\u00b7les", "Zei\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ach m\u00f6chten wir es doch in froher Ehrfurcht sehn,", "tokens": ["Ach", "m\u00f6ch\u00b7ten", "wir", "es", "doch", "in", "fro\u00b7her", "Ehr\u00b7furcht", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VMFIN", "PPER", "PPER", "ADV", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und auch im Wetter selbst der GOttheit Huld verstehn!", "tokens": ["Und", "auch", "im", "Wet\u00b7ter", "selbst", "der", "Got\u00b7theit", "Huld", "ver\u00b7stehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "ADV", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Denn ob dar\u00fcber gleich Lufft, Meer und Erd\u2019 ersch\u00fcttern,", "tokens": ["Denn", "ob", "da\u00b7r\u00fc\u00b7ber", "gleich", "Lufft", ",", "Meer", "und", "Erd'", "er\u00b7sch\u00fct\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PAV", "ADV", "NN", "$,", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So darff ein frommes Hertz doch darum nicht erzittern:", "tokens": ["So", "darff", "ein", "from\u00b7mes", "Hertz", "doch", "da\u00b7rum", "nicht", "er\u00b7zit\u00b7tern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "ADV", "PAV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Schreckt dich des Sch\u00f6pfers Macht; so dencke doch darbey:", "tokens": ["Schreckt", "dich", "des", "Sch\u00f6p\u00b7fers", "Macht", ";", "so", "den\u00b7cke", "doch", "dar\u00b7bey", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "NN", "$.", "ADV", "VVFIN", "ADV", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df Er, zu deinem Schutz, nicht minder m\u00e4chtig sey.", "tokens": ["Da\u00df", "Er", ",", "zu", "dei\u00b7nem", "Schutz", ",", "nicht", "min\u00b7der", "m\u00e4ch\u00b7tig", "sey", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,", "PTKNEG", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Gewi\u00df, du ehrst Jhn nicht, wenn ein zu starckes Schrecken,", "tokens": ["Ge\u00b7wi\u00df", ",", "du", "ehrst", "Jhn", "nicht", ",", "wenn", "ein", "zu", "star\u00b7ckes", "Schre\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,", "KOUS", "ART", "PTKZU", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Blitz, Hagel, Knall und Strahl, dem scheuchen Sinn er-", "tokens": ["Blitz", ",", "Ha\u00b7gel", ",", "Knall", "und", "Strahl", ",", "dem", "scheu\u00b7chen", "Sinn", "er"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,", "ART", "ADJA", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "wecken,", "tokens": ["we\u00b7cken", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Sieh deinen starcken GOTT doch nicht so schw\u00e4chlich an,", "tokens": ["Sieh", "dei\u00b7nen", "star\u00b7cken", "GoTT", "doch", "nicht", "so", "schw\u00e4ch\u00b7lich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "ADJA", "NN", "ADV", "PTKNEG", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da\u00df er im Wetter dich nicht auch beschirmen kan.", "tokens": ["Da\u00df", "er", "im", "Wet\u00b7ter", "dich", "nicht", "auch", "be\u00b7schir\u00b7men", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "PPER", "PTKNEG", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Es w\u00fcrcke Seine Macht ein Ehrfurcht-volles Grauen;", "tokens": ["Es", "w\u00fcr\u00b7cke", "Sei\u00b7ne", "Macht", "ein", "Ehr\u00b7furcht\u00b7vol\u00b7les", "Grau\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch auch nicht weniger ein kindliches Vertrauen!", "tokens": ["Doch", "auch", "nicht", "we\u00b7ni\u00b7ger", "ein", "kind\u00b7li\u00b7ches", "Ver\u00b7trau\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "An uns liebt unser GOTT zwar Ehrerbietigkeit,", "tokens": ["An", "uns", "liebt", "un\u00b7ser", "GoTT", "zwar", "Ehr\u00b7er\u00b7bie\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PPOSAT", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch mehr noch Zuversicht, noch mehr Gelassenheit.", "tokens": ["Doch", "mehr", "noch", "Zu\u00b7ver\u00b7sicht", ",", "noch", "mehr", "Ge\u00b7las\u00b7sen\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "NN", "$,", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Denn solltest du dadurch auch Schaden nehmen k\u00f6nnen;", "tokens": ["Denn", "soll\u00b7test", "du", "da\u00b7durch", "auch", "Scha\u00b7den", "neh\u00b7men", "k\u00f6n\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PAV", "ADV", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So la\u00df dich dennoch nicht von deinem Sch\u00f6pfer trennen!", "tokens": ["So", "la\u00df", "dich", "den\u00b7noch", "nicht", "von", "dei\u00b7nem", "Sch\u00f6p\u00b7fer", "tren\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ohn Jhn kann nichts geschehn: und was durch Jhn ge-", "tokens": ["Ohn", "Jhn", "kann", "nichts", "ge\u00b7schehn", ":", "und", "was", "durch", "Jhn", "ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUI", "PPER", "VMFIN", "PIS", "VVPP", "$.", "KON", "PWS", "APPR", "PPER", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "schicht,", "tokens": ["schicht", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Ist alles n\u00fctz und gut, begreifft man es gleich nicht.", "tokens": ["Ist", "al\u00b7les", "n\u00fctz", "und", "gut", ",", "be\u00b7greifft", "man", "es", "gleich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADJD", "KON", "ADJD", "$,", "VVFIN", "PIS", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Wann aber dieses nicht in unfern H\u00e4nden stehet,", "tokens": ["Wann", "a\u00b7ber", "die\u00b7ses", "nicht", "in", "un\u00b7fern", "H\u00e4n\u00b7den", "ste\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PDS", "PTKNEG", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und man sich blo\u00df, o HERR! durch Dich, zu Dir erh\u00f6het,", "tokens": ["Und", "man", "sich", "blo\u00df", ",", "o", "HeRR", "!", "durch", "Dich", ",", "zu", "Dir", "er\u00b7h\u00f6\u00b7het", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PRF", "ADV", "$,", "FM", "NN", "$.", "APPR", "PPER", "$,", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So fleh\u2019 ich inniglich: Gieb mir die Eigenschafft,", "tokens": ["So", "fleh'", "ich", "in\u00b7nig\u00b7lich", ":", "Gieb", "mir", "die", "Ei\u00b7gen\u00b7schafft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$.", "VVIMP", "PPER", "ART", "NN", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Die Dir gef\u00e4llig ist, und des Vertrauens Krafft.", "tokens": ["Die", "Dir", "ge\u00b7f\u00e4l\u00b7lig", "ist", ",", "und", "des", "Ver\u00b7trau\u00b7ens", "Krafft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "VAFIN", "$,", "KON", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "So offt wir blitzen sehn, so offt wir donnern h\u00f6ren,", "tokens": ["So", "offt", "wir", "blit\u00b7zen", "sehn", ",", "so", "offt", "wir", "don\u00b7nern", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "VVFIN", "VVINF", "$,", "ADV", "ADV", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "La\u00df uns, HERR Zebaoth, Dich lieben, f\u00fcrchten, ehren!", "tokens": ["La\u00df", "uns", ",", "HeRR", "Ze\u00b7bao\u00b7th", ",", "Dich", "lie\u00b7ben", ",", "f\u00fcrch\u00b7ten", ",", "eh\u00b7ren", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "NN", "NE", "$,", "PPER", "VVINF", "$,", "VVFIN", "$,", "VVINF", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Denn ob im Wetter gleich uns GOTTES Lieb anlacht,", "tokens": ["Denn", "ob", "im", "Wet\u00b7ter", "gleich", "uns", "GoT\u00b7TES", "Lieb", "an\u00b7lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "APPRART", "NN", "ADV", "PPER", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sind Blitz und Donner doch auch Proben Seiner Macht.", "tokens": ["Sind", "Blitz", "und", "Don\u00b7ner", "doch", "auch", "Pro\u00b7ben", "Sei\u00b7ner", "Macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "ADV", "ADV", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Von unserm Nichts kan nichts so klar uns \u00fcberf\u00fchren,", "tokens": ["Von", "un\u00b7serm", "Nichts", "kan", "nichts", "so", "klar", "uns", "\u00fc\u00b7berf\u00b7\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "PIS", "ADV", "ADJD", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als wenn wir die Gewalt der Elementen sp\u00fcren.", "tokens": ["Als", "wenn", "wir", "die", "Ge\u00b7walt", "der", "E\u00b7le\u00b7men\u00b7ten", "sp\u00fc\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Die ungeheure Macht erweiset, wie so klein,", "tokens": ["Die", "un\u00b7ge\u00b7heu\u00b7re", "Macht", "er\u00b7wei\u00b7set", ",", "wie", "so", "klein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PWAV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So elend, so gering und arm wir Menschen seyn.", "tokens": ["So", "e\u00b7lend", ",", "so", "ge\u00b7ring", "und", "arm", "wir", "Men\u00b7schen", "seyn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "KON", "ADJD", "PPER", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Drum HERR erbarme Dich! erbarme Dich aus Gnaden,", "tokens": ["Drum", "HeRR", "er\u00b7bar\u00b7me", "Dich", "!", "er\u00b7bar\u00b7me", "Dich", "aus", "Gna\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NN", "VVFIN", "PPER", "$.", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "La\u00df dies Gewitter doch den Unsrigen nicht schaden!", "tokens": ["La\u00df", "dies", "Ge\u00b7wit\u00b7ter", "doch", "den", "Uns\u00b7ri\u00b7gen", "nicht", "scha\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PDS", "NN", "ADV", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Gieb da\u00df der grause Sturm, gieb da\u00df der Schlossen Heer", "tokens": ["Gieb", "da\u00df", "der", "grau\u00b7se", "Sturm", ",", "gieb", "da\u00df", "der", "Schlos\u00b7sen", "Heer"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "KOUS", "ART", "ADJA", "NN", "$,", "VVIMP", "KOUS", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Uns weder Leib noch Gut besch\u00e4dig\u2019 und versehr.", "tokens": ["Uns", "we\u00b7der", "Leib", "noch", "Gut", "be\u00b7sch\u00e4\u00b7dig'", "und", "ver\u00b7sehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "NN", "ADV", "ADJD", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Gieb, da\u00df der wilde Blitz, so Feld-als Garten-Fr\u00fcchte,", "tokens": ["Gieb", ",", "da\u00df", "der", "wil\u00b7de", "Blitz", ",", "so", "Feld\u00b7als", "Gar\u00b7ten\u00b7Fr\u00fcch\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "KOUS", "ART", "ADJA", "NN", "$,", "ADV", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nicht treffe, nicht verseng' und sonst zu Grunde richte!", "tokens": ["Nicht", "tref\u00b7fe", ",", "nicht", "ver\u00b7seng'", "und", "sonst", "zu", "Grun\u00b7de", "rich\u00b7te", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "$,", "PTKNEG", "VVFIN", "KON", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kein Rach-Strahl st\u00fcrtz und kehr', im wohlverdienten", "tokens": ["Kein", "Rach\u00b7Strahl", "st\u00fcrtz", "und", "kehr'", ",", "im", "wohl\u00b7ver\u00b7dien\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "ADJD", "KON", "VVFIN", "$,", "APPRART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Grimm,", "tokens": ["Grimm", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Haus, G\u00e4rten, B\u00e4ume, Korn und andre G\u00fcter \u00fcm!", "tokens": ["Haus", ",", "G\u00e4r\u00b7ten", ",", "B\u00e4u\u00b7me", ",", "Korn", "und", "and\u00b7re", "G\u00fc\u00b7ter", "\u00fcm", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Ach la\u00df in dieser Noth, im Donner, Blitz und St\u00fcrmen,", "tokens": ["Ach", "la\u00df", "in", "die\u00b7ser", "Noth", ",", "im", "Don\u00b7ner", ",", "Blitz", "und", "St\u00fcr\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "APPR", "PDAT", "NN", "$,", "APPRART", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Uns deine Lieb und Macht, o Vater, doch beschirmen!", "tokens": ["Uns", "dei\u00b7ne", "Lieb", "und", "Macht", ",", "o", "Va\u00b7ter", ",", "doch", "be\u00b7schir\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "KON", "NN", "$,", "FM", "NN", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vor allem aber gieb, wenn die Gefahr vorbey,", "tokens": ["Vor", "al\u00b7lem", "a\u00b7ber", "gieb", ",", "wenn", "die", "Ge\u00b7fahr", "vor\u00b7bey", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "ADV", "VVIMP", "$,", "KOUS", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df so vor Schutz als Nutz Dir jeder danckbar sey!", "tokens": ["Da\u00df", "so", "vor", "Schutz", "als", "Nutz", "Dir", "je\u00b7der", "dan\u00b7ck\u00b7bar", "sey", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "NN", "KOUS", "NN", "PPER", "PIS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}}}}