{"textgrid.poem.53382": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Betracht ich br\u00fcnstig im Gem\u00fcth,", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Betracht ich br\u00fcnstig im Gem\u00fcth,", "tokens": ["Be\u00b7tracht", "ich", "br\u00fcns\u00b7tig", "im", "Ge\u00b7m\u00fcth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Herr, allen Reichthum deiner G\u00fct'", "tokens": ["Herr", ",", "al\u00b7len", "Reicht\u00b7hum", "dei\u00b7ner", "G\u00fct'"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PIAT", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und was du mir erwiesen,", "tokens": ["Und", "was", "du", "mir", "er\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "An Lieb und Trew", "tokens": ["An", "Lieb", "und", "Trew"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Die t\u00e4glich new", "tokens": ["Die", "t\u00e4g\u00b7lich", "new"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJD", "ADJD"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Und nie gnug ist gepriesen,", "tokens": ["Und", "nie", "gnug", "ist", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Brech' ich mit allem Recht heraus,", "tokens": ["Brech'", "ich", "mit", "al\u00b7lem", "Recht", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "PIS", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gott, was ich bin, was ist mein Hau\u00df,", "tokens": ["Gott", ",", "was", "ich", "bin", ",", "was", "ist", "mein", "Hau\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "PPER", "VAFIN", "$,", "PWS", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Da\u00df du mich hieher f\u00fchrest,", "tokens": ["Da\u00df", "du", "mich", "hie\u00b7her", "f\u00fch\u00b7rest", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Beschirmest mich,", "tokens": ["Be\u00b7schir\u00b7mest", "mich", ","], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Und v\u00e4terlich", "tokens": ["Und", "v\u00e4\u00b7ter\u00b7lich"], "token_info": ["word", "word"], "pos": ["KON", "ADJD"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Mit dieser Gnade zierest:", "tokens": ["Mit", "die\u00b7ser", "Gna\u00b7de", "zie\u00b7rest", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ich bin der wunderlichen Ding',", "tokens": ["Ich", "bin", "der", "wun\u00b7der\u00b7li\u00b7chen", "Ding'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Herr, viel zu unwehrt und gering,", "tokens": ["Herr", ",", "viel", "zu", "un\u00b7wehrt", "und", "ge\u00b7ring", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "PTKA", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was ist der Mensch, die Erde,", "tokens": ["Was", "ist", "der", "Mensch", ",", "die", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Was seine Zier,", "tokens": ["Was", "sei\u00b7ne", "Zier", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Da\u00df er von dir", "tokens": ["Da\u00df", "er", "von", "dir"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Gro\u00df angesehen werde?", "tokens": ["Gro\u00df", "an\u00b7ge\u00b7se\u00b7hen", "wer\u00b7de", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Was hat er da\u00df dich fangen kan?", "tokens": ["Was", "hat", "er", "da\u00df", "dich", "fan\u00b7gen", "kan", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "KOUS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und du nimst sein dich also an,", "tokens": ["Und", "du", "nimst", "sein", "dich", "al\u00b7so", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df du dein Hertz und Leben", "tokens": ["Da\u00df", "du", "dein", "Hertz", "und", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "In alle Noth,", "tokens": ["In", "al\u00b7le", "Noth", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Ja in den Todt", "tokens": ["Ja", "in", "den", "Todt"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKANT", "APPR", "ART", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Des Creutzes hast gegeben.", "tokens": ["Des", "Creut\u00b7zes", "hast", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Du deckest sein Gebrechen zu,", "tokens": ["Du", "de\u00b7ckest", "sein", "Ge\u00b7bre\u00b7chen", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und kr\u00f6nest ihn mit Gn\u00fcg vnd Ruh,", "tokens": ["Und", "kr\u00f6\u00b7nest", "ihn", "mit", "Gn\u00fcg", "vnd", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Legst deiner Engel Wache", "tokens": ["Legst", "dei\u00b7ner", "En\u00b7gel", "Wa\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Rings vmb ihn her,", "tokens": ["Rings", "vmb", "ihn", "her", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Da\u00df kein Beschwer", "tokens": ["Da\u00df", "kein", "Be\u00b7schwer"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PIAT", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Ohn dich an Ihn sich mache.", "tokens": ["Ohn", "dich", "an", "Ihn", "sich", "ma\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "APPR", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Die\u00df alles thust du auch bey mir,", "tokens": ["Die\u00df", "al\u00b7les", "thust", "du", "auch", "bey", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was bin ich wieder schuldig dir?", "tokens": ["Was", "bin", "ich", "wie\u00b7der", "schul\u00b7dig", "dir", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "ADJD", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Hertz was dich nur liebet,", "tokens": ["Ein", "Hertz", "was", "dich", "nur", "lie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PWS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und dir allein", "tokens": ["Und", "dir", "al\u00b7lein"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPER", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "In Lieb und Pein", "tokens": ["In", "Lieb", "und", "Pein"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Dem\u00fctig sich ergiebet.", "tokens": ["De\u00b7m\u00fc\u00b7tig", "sich", "er\u00b7gie\u00b7bet", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Ich aber wolte deine Ruth,", "tokens": ["Ich", "a\u00b7ber", "wol\u00b7te", "dei\u00b7ne", "Ruth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus Z\u00e4rtligkeit vnd Vbermuth", "tokens": ["Aus", "Z\u00e4rt\u00b7lig\u00b7keit", "vnd", "Vber\u00b7muth"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Jtzt nicht gehorsam k\u00fcssen,", "tokens": ["Jtzt", "nicht", "ge\u00b7hor\u00b7sam", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da doch die Zucht", "tokens": ["Da", "doch", "die", "Zucht"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Mein Bestes sucht", "tokens": ["Mein", "Bes\u00b7tes", "sucht"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Und seelig mich wil wissen?", "tokens": ["Und", "see\u00b7lig", "mich", "wil", "wis\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Ja Gott, du zeuchst aus dieser Noth", "tokens": ["Ja", "Gott", ",", "du", "zeuchst", "aus", "die\u00b7ser", "Noth"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "NN", "$,", "PPER", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Liebstes durch so fr\u00fchen Tod", "tokens": ["Mein", "Liebs\u00b7tes", "durch", "so", "fr\u00fc\u00b7hen", "Tod"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hinauff in jenes Leben,", "tokens": ["Hin\u00b7auff", "in", "je\u00b7nes", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df ich auch dort", "tokens": ["Da\u00df", "ich", "auch", "dort"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Sol fort vnd fort", "tokens": ["Sol", "fort", "vnd", "fort"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PTKVZ", "KON", "PTKVZ"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Mit meinem Hertzen schweben.", "tokens": ["Mit", "mei\u00b7nem", "Hert\u00b7zen", "schwe\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "So lass dasselb' auch vmb dich seyn,", "tokens": ["So", "lass", "das\u00b7selb'", "auch", "vmb", "dich", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PAV", "ADV", "APPR", "PPER", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Halt es von aller Welt-sucht rein", "tokens": ["Halt", "es", "von", "al\u00b7ler", "Welt\u00b7sucht", "rein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "APPR", "PIAT", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd deinem Dienst befohlen,", "tokens": ["Vnd", "dei\u00b7nem", "Dienst", "be\u00b7foh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bi\u00df mit der Zeit", "tokens": ["Bi\u00df", "mit", "der", "Zeit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "APPR", "ART", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Mich dein Geleit", "tokens": ["Mich", "dein", "Ge\u00b7leit"], "token_info": ["word", "word", "word"], "pos": ["PPER", "PPOSAT", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Den Meinen nach wird holen.", "tokens": ["Den", "Mei\u00b7nen", "nach", "wird", "ho\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}