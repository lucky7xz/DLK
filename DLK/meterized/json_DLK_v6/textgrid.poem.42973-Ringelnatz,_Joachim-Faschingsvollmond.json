{"textgrid.poem.42973": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Faschingsvollmond", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein Freund, ein Dieb aus der N\u00e4he von Metz,", "tokens": ["Ein", "Freund", ",", "ein", "Dieb", "aus", "der", "N\u00e4\u00b7he", "von", "Metz", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wollte mich betrunken machen.", "tokens": ["Woll\u00b7te", "mich", "be\u00b7trun\u00b7ken", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Es gelang ihm durch dauerndes Ansto\u00dfen.", "tokens": ["Es", "ge\u00b7lang", "ihm", "durch", "dau\u00b7ern\u00b7des", "An\u00b7sto\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Wir stolperten \u00fcber ein Polizeigesetz,", "tokens": ["Wir", "stol\u00b7per\u00b7ten", "\u00fc\u00b7ber", "ein", "Po\u00b7li\u00b7zei\u00b7ge\u00b7setz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Lagen dann in zwei stecknadelgro\u00dfen", "tokens": ["La\u00b7gen", "dann", "in", "zwei", "steck\u00b7na\u00b7del\u00b7gro\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "APPR", "CARD", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Blutlachen.", "tokens": ["Blut\u00b7la\u00b7chen", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.2": {"line.1": {"text": "\u00bbwarum willst du mich denn betrunken machen?\u00ab", "tokens": ["\u00bb", "wa\u00b7rum", "willst", "du", "mich", "denn", "be\u00b7trun\u00b7ken", "ma\u00b7chen", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "VMFIN", "PPER", "PRF", "ADV", "ADJD", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Frug ich. \u2013 \u00bbUm Dich zu berauben!\u00ab \u2013", "tokens": ["Frug", "ich", ".", "\u2013", "\u00bb", "Um", "Dich", "zu", "be\u00b7rau\u00b7ben", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "PPER", "$.", "$(", "$(", "KOUI", "PPER", "PTKZU", "VVINF", "$.", "$(", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Diesem Freunde konnte ich glauben;", "tokens": ["Die\u00b7sem", "Freun\u00b7de", "konn\u00b7te", "ich", "glau\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Er k\u00fc\u00dfte mir oft die H\u00e4nde, in Wien. \u2013", "tokens": ["Er", "k\u00fc\u00df\u00b7te", "mir", "oft", "die", "H\u00e4n\u00b7de", ",", "in", "Wi\u00b7en", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "APPR", "NE", "$.", "$("], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Nun lag er mit r\u00fchrend blutender Nase", "tokens": ["Nun", "lag", "er", "mit", "r\u00fch\u00b7rend", "blu\u00b7ten\u00b7der", "Na\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJD", "ADJA", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Mitten in der Theresienstra\u00dfe", "tokens": ["Mit\u00b7ten", "in", "der", "The\u00b7re\u00b7si\u00b7ens\u00b7tra\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Neben mir. Wo uns der Vollmond beschien.", "tokens": ["Ne\u00b7ben", "mir", ".", "Wo", "uns", "der", "Voll\u00b7mond", "be\u00b7schien", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$.", "PWAV", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "+------+-+", "measure": "dactylic.init"}}, "stanza.3": {"line.1": {"text": "Wir wollten einander aufraffen,", "tokens": ["Wir", "woll\u00b7ten", "ein\u00b7an\u00b7der", "auf\u00b7raf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Aber Der Mann im Monde trat", "tokens": ["A\u00b7ber", "Der", "Mann", "im", "Mon\u00b7de", "trat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPRART", "NE", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Eben in den Hof seines Mondes", "tokens": ["E\u00b7ben", "in", "den", "Hof", "sei\u00b7nes", "Mon\u00b7des"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Und signalisierte uns: Lohnt es", "tokens": ["Und", "sig\u00b7na\u00b7li\u00b7sier\u00b7te", "uns", ":", "Lohnt", "es"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$.", "VVFIN", "PPER"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Sich, einen Hofhund hier anzuschaffen?", "tokens": ["Sich", ",", "ei\u00b7nen", "Hof\u00b7hund", "hier", "an\u00b7zu\u00b7schaf\u00b7fen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "$,", "ART", "NN", "ADV", "VVIZU", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Oder empfehlen Sie Stacheldraht?", "tokens": ["O\u00b7der", "emp\u00b7feh\u00b7len", "Sie", "Sta\u00b7chel\u00b7draht", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.4": {"line.1": {"text": "Ein Schutzmann kam und nahm eins von uns beiden.", "tokens": ["Ein", "Schutz\u00b7mann", "kam", "und", "nahm", "eins", "von", "uns", "bei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "PIS", "APPR", "PPER", "PIAT", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich lie\u00df meinem Freunde zur Aufbewahrung", "tokens": ["Ich", "lie\u00df", "mei\u00b7nem", "Freun\u00b7de", "zur", "Auf\u00b7be\u00b7wah\u00b7rung"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPRART", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Die Brieftasche. Aber nicht nur das Scheiden,", "tokens": ["Die", "Brief\u00b7ta\u00b7sche", ".", "A\u00b7ber", "nicht", "nur", "das", "Schei\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "KON", "PTKNEG", "ADV", "ART", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Auch andres tut weh. Zum Beispiel Erfahrung.", "tokens": ["Auch", "and\u00b7res", "tut", "weh", ".", "Zum", "Bei\u00b7spiel", "Er\u00b7fah\u00b7rung", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "PTKVZ", "$.", "APPRART", "NN", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Ich kann die Gegend um Metz nicht leiden.", "tokens": ["Ich", "kann", "die", "Ge\u00b7gend", "um", "Metz", "nicht", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "APPR", "NE", "PTKNEG", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}}}}