{"textgrid.poem.62907": {"metadata": {"author": {"name": "Pfeffel, Gottlieb Konrad", "birth": "N.A.", "death": "N.A."}, "title": "1L: \u00bbgott gr\u00fc\u00df euch Alter! \u2013 schmeckt das Pfeifchen?", "genre": "verse", "period": "N.A.", "pub_year": 1782, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbgott gr\u00fc\u00df euch Alter! \u2013 schmeckt das Pfeifchen?", "tokens": ["\u00bb", "gott", "gr\u00fc\u00df", "euch", "Al\u00b7ter", "!", "\u2013", "schmeckt", "das", "Pfei\u00b7fchen", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VVFIN", "PPER", "NN", "$.", "$(", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wei\u00dft her! \u2013 Ein Blumentopf", "tokens": ["Wei\u00dft", "her", "!", "\u2013", "Ein", "Blu\u00b7men\u00b7topf"], "token_info": ["word", "word", "punct", "punct", "word", "word"], "pos": ["VVFIN", "PTKVZ", "$.", "$(", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Von rothem Thon, mit goldnen Reifchen? \u2013", "tokens": ["Von", "ro\u00b7them", "Thon", ",", "mit", "gold\u00b7nen", "Reif\u00b7chen", "?", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Was wollt ihr f\u00fcr den Kopf?\u00ab", "tokens": ["Was", "wollt", "ihr", "f\u00fcr", "den", "Kopf", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VMFIN", "PPER", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "O Herr, den Kopf kann ich nicht lassen!", "tokens": ["O", "Herr", ",", "den", "Kopf", "kann", "ich", "nicht", "las\u00b7sen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "ART", "NN", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Er k\u00f6mmt vom br\u00e4vsten Mann,", "tokens": ["Er", "k\u00f6mmt", "vom", "br\u00e4vs\u00b7ten", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der ihn, Gott wei\u00df es, einem Bassen", "tokens": ["Der", "ihn", ",", "Gott", "wei\u00df", "es", ",", "ei\u00b7nem", "Bas\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "PPER", "$,", "NN", "VVFIN", "PPER", "$,", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bey Belgrad abgewann.", "tokens": ["Bey", "Bel\u00b7grad", "ab\u00b7ge\u00b7wann", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Da, Herr, da gab es rechte Beute!", "tokens": ["Da", ",", "Herr", ",", "da", "gab", "es", "rech\u00b7te", "Beu\u00b7te", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NN", "$,", "ADV", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es lebe Prinz Eugen!", "tokens": ["Es", "le\u00b7be", "Prinz", "Eu\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "NE", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Wie Grummet sah man unsre Leute", "tokens": ["Wie", "Grum\u00b7met", "sah", "man", "uns\u00b7re", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "VVFIN", "PIS", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der T\u00fcrken Glieder m\u00e4hn. \u2013", "tokens": ["Der", "T\u00fcr\u00b7ken", "Glie\u00b7der", "m\u00e4hn", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "\u00bbein andermal von euren Thaten;", "tokens": ["\u00bb", "ein", "an\u00b7der\u00b7mal", "von", "eu\u00b7ren", "Tha\u00b7ten", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hier, Alter, seyd kein Tropf,", "tokens": ["Hier", ",", "Al\u00b7ter", ",", "seyd", "kein", "Tropf", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NN", "$,", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Nehmt diesen doppelten Dukaten", "tokens": ["Nehmt", "die\u00b7sen", "dop\u00b7pel\u00b7ten", "Du\u00b7ka\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PDAT", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "F\u00fcr euren Pfeifenkopf.\u00ab", "tokens": ["F\u00fcr", "eu\u00b7ren", "Pfei\u00b7fen\u00b7kopf", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Ich bin ein armer Kerl und lebe", "tokens": ["Ich", "bin", "ein", "ar\u00b7mer", "Kerl", "und", "le\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "KON", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von meinem Gnadensold;", "tokens": ["Von", "mei\u00b7nem", "Gna\u00b7den\u00b7sold", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch, Herr, den Pfeifenkopf, den gebe", "tokens": ["Doch", ",", "Herr", ",", "den", "Pfei\u00b7fen\u00b7kopf", ",", "den", "ge\u00b7be"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "$,", "NN", "$,", "ART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich nicht um alles Gold.", "tokens": ["Ich", "nicht", "um", "al\u00b7les", "Gold", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "H\u00f6rt nur: Einst jagten wir Husaren", "tokens": ["H\u00f6rt", "nur", ":", "Einst", "jag\u00b7ten", "wir", "Hu\u00b7sa\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "$.", "ADV", "VVFIN", "PPER", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den Feind nach Herzenslust,", "tokens": ["Den", "Feind", "nach", "Her\u00b7zens\u00b7lust", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da scho\u00df ein Hund von Janitscharen", "tokens": ["Da", "scho\u00df", "ein", "Hund", "von", "Ja\u00b7nit\u00b7scha\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den Hauptmann in die Brust.", "tokens": ["Den", "Haupt\u00b7mann", "in", "die", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Ich heb ihn flugs auf meinen Schimmel \u2013", "tokens": ["Ich", "heb", "ihn", "flugs", "auf", "mei\u00b7nen", "Schim\u00b7mel", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Er h\u00e4tt' es auch gethan \u2013", "tokens": ["Er", "h\u00e4tt'", "es", "auch", "ge\u00b7than", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und trag ihn sanft aus dem Get\u00fcmmel", "tokens": ["Und", "trag", "ihn", "sanft", "aus", "dem", "Ge\u00b7t\u00fcm\u00b7mel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu einem Edelmann.", "tokens": ["Zu", "ei\u00b7nem", "E\u00b7del\u00b7mann", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Ich pflegte sein. Vor seinem Ende", "tokens": ["Ich", "pfleg\u00b7te", "sein", ".", "Vor", "sei\u00b7nem", "En\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "VAINF", "$.", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Reicht er mir all sein Geld", "tokens": ["Reicht", "er", "mir", "all", "sein", "Geld"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "PIAT", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und diesen Kopf, dr\u00fcckt mir die H\u00e4nde,", "tokens": ["Und", "die\u00b7sen", "Kopf", ",", "dr\u00fcckt", "mir", "die", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "$,", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und blieb im Tod noch Held.", "tokens": ["Und", "blieb", "im", "Tod", "noch", "Held", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ADV", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Das Geld mu\u00dft du dem Wirthe schenken,", "tokens": ["Das", "Geld", "mu\u00dft", "du", "dem", "Wirt\u00b7he", "schen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der dreymal Pl\u00fcndrung litt,", "tokens": ["Der", "drey\u00b7mal", "Pl\u00fcn\u00b7drung", "litt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So dacht ich, und zum Angedenken", "tokens": ["So", "dacht", "ich", ",", "und", "zum", "An\u00b7ge\u00b7den\u00b7ken"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KON", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nahm ich die Pfeife mit.", "tokens": ["Nahm", "ich", "die", "Pfei\u00b7fe", "mit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Ich trug auf allen meinen Z\u00fcgen", "tokens": ["Ich", "trug", "auf", "al\u00b7len", "mei\u00b7nen", "Z\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie wie ein Heiligthum,", "tokens": ["Sie", "wie", "ein", "Hei\u00b7lig\u00b7thum", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wir mochten weichen oder siegen,", "tokens": ["Wir", "moch\u00b7ten", "wei\u00b7chen", "o\u00b7der", "sie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Im Stiefel mit herum.", "tokens": ["Im", "Stie\u00b7fel", "mit", "he\u00b7rum", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Vor Prag verlor ich auf der Streife", "tokens": ["Vor", "Prag", "ver\u00b7lor", "ich", "auf", "der", "Strei\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das Bein durch einen Schu\u00df,", "tokens": ["Das", "Bein", "durch", "ei\u00b7nen", "Schu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da griff ich erst nach meiner Pfeife,", "tokens": ["Da", "griff", "ich", "erst", "nach", "mei\u00b7ner", "Pfei\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und dann nach meinem Fu\u00df.", "tokens": ["Und", "dann", "nach", "mei\u00b7nem", "Fu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "\u00bbsch\u00f6n, Vater, ihr entlockt mir Z\u00e4hren.", "tokens": ["\u00bb", "sch\u00f6n", ",", "Va\u00b7ter", ",", "ihr", "ent\u00b7lockt", "mir", "Z\u00e4h\u00b7ren", "."], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "NN", "$,", "PPER", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "O sagt, wie hie\u00df der Mann,", "tokens": ["O", "sagt", ",", "wie", "hie\u00df", "der", "Mann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "PWAV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Damit auch mein Herz ihn verehren", "tokens": ["Da\u00b7mit", "auch", "mein", "Herz", "ihn", "ver\u00b7eh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "PPOSAT", "NN", "PPER", "VVFIN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Und ihn beneiden kann.\u00ab", "tokens": ["Und", "ihn", "be\u00b7nei\u00b7den", "kann", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Man hie\u00df ihn nur den tapfern Walter:", "tokens": ["Man", "hie\u00df", "ihn", "nur", "den", "tap\u00b7fern", "Wal\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dort lag sein Gut am Rhein ...", "tokens": ["Dort", "lag", "sein", "Gut", "am", "Rhein", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "APPRART", "NE", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbdas war mein Ahne, lieber Alter,", "tokens": ["\u00bb", "das", "war", "mein", "Ah\u00b7ne", ",", "lie\u00b7ber", "Al\u00b7ter", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "PPOSAT", "NN", "$,", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und jenes Gut ist mein.\u00ab", "tokens": ["Und", "je\u00b7nes", "Gut", "ist", "mein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PDS", "ADJD", "VAFIN", "PPOSAT", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "\u00bbkommt, Freund, ihr sollt bey mir nun leben!", "tokens": ["\u00bb", "kommt", ",", "Freund", ",", "ihr", "sollt", "bey", "mir", "nun", "le\u00b7ben", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "NN", "$,", "PPER", "VMFIN", "APPR", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vergesset eure Noth:", "tokens": ["Ver\u00b7ges\u00b7set", "eu\u00b7re", "Noth", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Kommt, trinkt mit mir von Walters Reben", "tokens": ["Kommt", ",", "trinkt", "mit", "mir", "von", "Wal\u00b7ters", "Re\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "VVFIN", "APPR", "PPER", "APPR", "NE", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und e\u00dft von Walters Brod.\u00ab", "tokens": ["Und", "e\u00dft", "von", "Wal\u00b7ters", "Brod", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "APPR", "NE", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Nun top! Ihr seyd sein wahrer Erbe!", "tokens": ["Nun", "top", "!", "Ihr", "seyd", "sein", "wah\u00b7rer", "Er\u00b7be", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich ziehe morgen ein,", "tokens": ["Ich", "zie\u00b7he", "mor\u00b7gen", "ein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und euer Dank soll, wenn ich sterbe,", "tokens": ["Und", "eu\u00b7er", "Dank", "soll", ",", "wenn", "ich", "ster\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VMFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die T\u00fcrkenpfeife seyn.", "tokens": ["Die", "T\u00fcr\u00b7ken\u00b7pfei\u00b7fe", "seyn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}