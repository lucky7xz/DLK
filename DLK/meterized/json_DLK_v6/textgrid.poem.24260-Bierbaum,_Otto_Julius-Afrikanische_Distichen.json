{"textgrid.poem.24260": {"metadata": {"author": {"name": "Bierbaum, Otto Julius", "birth": "N.A.", "death": "N.A."}, "title": "Afrikanische Distichen", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbwir auch wollen\u00ab, so sprach der pudelbegleitete Kanzler,", "tokens": ["\u00bb", "wir", "auch", "wol\u00b7len", "\u00ab", ",", "so", "sprach", "der", "pu\u00b7del\u00b7be\u00b7glei\u00b7te\u00b7te", "Kanz\u00b7ler", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADV", "VMFIN", "$(", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "\u00bban der Sonne den Platz, der uns Deutschen geb\u00fchrt.\u00ab", "tokens": ["\u00bb", "an", "der", "Son\u00b7ne", "den", "Platz", ",", "der", "uns", "Deut\u00b7schen", "ge\u00b7b\u00fchrt", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "ART", "NN", "ART", "NN", "$,", "PRELS", "PPER", "NN", "VVPP", "$.", "$("], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}}, "stanza.2": {"line.1": {"text": "Sch\u00f6n. Wir nahmen ihn ein. Es steckten die Assessoren,", "tokens": ["Sch\u00f6n", ".", "Wir", "nah\u00b7men", "ihn", "ein", ".", "Es", "steck\u00b7ten", "die", "As\u00b7ses\u00b7so\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PPER", "VVFIN", "PPER", "PTKVZ", "$.", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+--+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Steckten die Leutenants ihn ab mit schneidiger Hand.", "tokens": ["Steck\u00b7ten", "die", "Leu\u00b7ten\u00b7ants", "ihn", "ab", "mit", "schnei\u00b7di\u00b7ger", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "PTKVZ", "APPR", "ADJA", "NN", "$."], "meter": "+--+-+-+-+--+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Schwarz im Gehrock und schwarz in der hochgeschlo\u00dfnen Soutane", "tokens": ["Schwarz", "im", "Ge\u00b7hrock", "und", "schwarz", "in", "der", "hoch\u00b7ge\u00b7schlo\u00df\u00b7nen", "Sou\u00b7ta\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "APPRART", "NN", "KON", "ADJD", "APPR", "ART", "ADJA", "NN"], "meter": "+--+-+--+-+--+-", "measure": "hexameter"}, "line.4": {"text": "Folgten des Christentums Boten der Staatsgewalt.", "tokens": ["Folg\u00b7ten", "des", "Chris\u00b7ten\u00b7tums", "Bo\u00b7ten", "der", "Staats\u00b7ge\u00b7walt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "NN", "ART", "NN", "$."], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.5": {"text": "Streng in zwei Lager geteilt, Konkurrenten auf Tod und Leben,", "tokens": ["Streng", "in", "zwei", "La\u00b7ger", "ge\u00b7teilt", ",", "Kon\u00b7kur\u00b7ren\u00b7ten", "auf", "Tod", "und", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "CARD", "NN", "VVPP", "$,", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+--+--+-+---+-+-", "measure": "dactylic.di.plus"}, "line.6": {"text": "Aber im \u00fcbrigen ganz himmlicher Liebesbrunst voll.", "tokens": ["A\u00b7ber", "im", "\u00fcb\u00b7ri\u00b7gen", "ganz", "himm\u00b7li\u00b7cher", "Lie\u00b7bes\u00b7brunst", "voll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "ADJA", "ADV", "ADJA", "NN", "ADJD", "$."], "meter": "+--+---+--+--+", "measure": "dactylic.di.plus"}}, "stanza.3": {"line.1": {"text": "Ordnung herrschte fortan, Disziplin, Polizei und Gesittung,", "tokens": ["Ord\u00b7nung", "herrschte", "for\u00b7tan", ",", "Dis\u00b7zip\u00b7lin", ",", "Po\u00b7li\u00b7zei", "und", "Ge\u00b7sit\u00b7tung", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKVZ", "$,", "NE", "$,", "NN", "KON", "NN", "$,"], "meter": "---+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wo der Wilde bisher Greuel auf Greuel geh\u00e4uft.", "tokens": ["Wo", "der", "Wil\u00b7de", "bis\u00b7her", "Greu\u00b7el", "auf", "Greu\u00b7el", "ge\u00b7h\u00e4uft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "NE", "APPR", "NE", "VVPP", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.3": {"text": "Lieblich am Palmenstamm hing die k\u00fchn stilisierte Verordnung,", "tokens": ["Lieb\u00b7lich", "am", "Pal\u00b7men\u00b7stamm", "hing", "die", "k\u00fchn", "sti\u00b7li\u00b7sier\u00b7te", "Ver\u00b7ord\u00b7nung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "VVFIN", "ART", "ADJD", "ADJA", "NN", "$,"], "meter": "+--+-+--+--+--+-", "measure": "hexameter"}, "line.4": {"text": "Jede Giraffe erhielt Halsband und Mark und Korb.", "tokens": ["Je\u00b7de", "Gir\u00b7af\u00b7fe", "er\u00b7hielt", "Hals\u00b7band", "und", "Mark", "und", "Korb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "+-+-+-++--+-+", "measure": "trochaic.septa.relaxed"}, "line.5": {"text": "Aktenregale, vom Holz der Urwaldb\u00e4ume gezimmert,", "tokens": ["Ak\u00b7ten\u00b7re\u00b7ga\u00b7le", ",", "vom", "Holz", "der", "Ur\u00b7wald\u00b7b\u00e4u\u00b7me", "ge\u00b7zim\u00b7mert", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPRART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.6": {"text": "Bogen sich bald von der Last emsig beschriebenen Papiers,", "tokens": ["Bo\u00b7gen", "sich", "bald", "von", "der", "Last", "em\u00b7sig", "be\u00b7schrie\u00b7be\u00b7nen", "Pa\u00b7piers", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ADV", "APPR", "ART", "NN", "ADJD", "ADJA", "NN", "$,"], "meter": "+--+--+-+-+-+-+", "measure": "dactylic.di.plus"}, "line.7": {"text": "Und es fungierte genau das l\u00f6bliche Steuerkataster,", "tokens": ["Und", "es", "fun\u00b7gier\u00b7te", "ge\u00b7nau", "das", "l\u00f6b\u00b7li\u00b7che", "Steu\u00b7er\u00b7ka\u00b7tas\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "ART", "ADJA", "NN", "$,"], "meter": "--+---+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Jeder Knopf ward gebucht, der einer Hose entsprang.", "tokens": ["Je\u00b7der", "Knopf", "ward", "ge\u00b7bucht", ",", "der", "ei\u00b7ner", "Ho\u00b7se", "ent\u00b7sprang", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "VVPP", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+--+", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Denn (das versteht sich von selbst) es wurde die ruchlose Bl\u00f6\u00dfe", "tokens": ["Denn", "(", "das", "ver\u00b7steht", "sich", "von", "selbst", ")", "es", "wur\u00b7de", "die", "ruch\u00b7lo\u00b7se", "Bl\u00f6\u00b7\u00dfe"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$(", "PDS", "VVFIN", "PRF", "APPR", "ADV", "$(", "PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+--+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Jedes Wilden fortan von der Regierung behost,", "tokens": ["Je\u00b7des", "Wil\u00b7den", "for\u00b7tan", "von", "der", "Re\u00b7gie\u00b7rung", "be\u00b7host", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+--+--+", "measure": "trochaic.hexa.relaxed"}, "line.11": {"text": "Und mit keuschem Kattun ward verh\u00fcllt, was das s\u00fcdliche Klima", "tokens": ["Und", "mit", "keu\u00b7schem", "Kat\u00b7tun", "ward", "ver\u00b7h\u00fcllt", ",", "was", "das", "s\u00fcd\u00b7li\u00b7che", "Kli\u00b7ma"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "VAFIN", "VVPP", "$,", "PRELS", "ART", "ADJA", "NN"], "meter": "--+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.12": {"text": "Leider den Weibern dort allzu \u00fcppig beschert.", "tokens": ["Lei\u00b7der", "den", "Wei\u00b7bern", "dort", "all\u00b7zu", "\u00fcp\u00b7pig", "be\u00b7schert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "PTKA", "ADJD", "VVPP", "$."], "meter": "+--+-++-+--+", "measure": "iambic.hexa.invert"}, "line.13": {"text": "Emsig kauerte nun vorm Tintenfa\u00dfe die Jugend,", "tokens": ["Em\u00b7sig", "kau\u00b7er\u00b7te", "nun", "vorm", "Tin\u00b7ten\u00b7fa\u00b7\u00dfe", "die", "Ju\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "APPRART", "NN", "ART", "NN", "$,"], "meter": "+----+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.14": {"text": "Lernte das Abc, lernte die Wacht am Rhein,", "tokens": ["Lern\u00b7te", "das", "Abc", ",", "lern\u00b7te", "die", "Wacht", "am", "Rhein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "VVFIN", "ART", "NN", "APPRART", "NE", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.15": {"text": "Heil dir im Siegerkranz, Vater unser, du sollst nicht begehren", "tokens": ["Heil", "dir", "im", "Sie\u00b7ger\u00b7kranz", ",", "Va\u00b7ter", "un\u00b7ser", ",", "du", "sollst", "nicht", "be\u00b7geh\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "APPRART", "NN", "$,", "NN", "PPOSAT", "$,", "PPER", "VMFIN", "PTKNEG", "VVINF"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.16": {"text": "Deines N\u00e4chsten Weib, kurz, was den Menschen erhebt.", "tokens": ["Dei\u00b7nes", "N\u00e4chs\u00b7ten", "Weib", ",", "kurz", ",", "was", "den", "Men\u00b7schen", "er\u00b7hebt", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "ADJD", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.17": {"text": "Aber, auf da\u00df nicht blo\u00df die ", "tokens": ["A\u00b7ber", ",", "auf", "da\u00df", "nicht", "blo\u00df", "die"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "APPR", "KOUS", "PTKNEG", "ADV", "ART"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.18": {"text": "Sondern der K\u00f6rper auch wisse, was sich geh\u00f6rt,", "tokens": ["Son\u00b7dern", "der", "K\u00f6r\u00b7per", "auch", "wis\u00b7se", ",", "was", "sich", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "VVFIN", "$,", "PRELS", "PRF", "VVFIN", "$,"], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.19": {"text": "Drillte der Herr Sergeant mit vaterl\u00e4ndischen Fl\u00fcchen,", "tokens": ["Drill\u00b7te", "der", "Herr", "Ser\u00b7ge\u00b7ant", "mit", "va\u00b7ter\u00b7l\u00e4n\u00b7di\u00b7schen", "Fl\u00fc\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.20": {"text": "Tritten in das Ges\u00e4\u00df, oder woandershin,", "tokens": ["Trit\u00b7ten", "in", "das", "Ge\u00b7s\u00e4\u00df", ",", "o\u00b7der", "woan\u00b7der\u00b7shin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,", "KON", "PWAV", "$,"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.21": {"text": "Streng nach dem Reglement die waffenf\u00e4hige Menge", "tokens": ["Streng", "nach", "dem", "Re\u00b7gle\u00b7ment", "die", "waf\u00b7fen\u00b7f\u00e4\u00b7hi\u00b7ge", "Men\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}, "line.22": {"text": "In der adligen Kunst disziplinarischen Mords.", "tokens": ["In", "der", "ad\u00b7li\u00b7gen", "Kunst", "dis\u00b7zip\u00b7li\u00b7na\u00b7ri\u00b7schen", "Mords", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "--+--+-+-+--+", "measure": "anapaest.di.plus"}, "line.23": {"text": "Also geschah, was der Geist der Kultur w\u00fcnscht, da\u00df es geschehe,", "tokens": ["Al\u00b7so", "ge\u00b7schah", ",", "was", "der", "Geist", "der", "Kul\u00b7tur", "w\u00fcnscht", ",", "da\u00df", "es", "ge\u00b7sche\u00b7he", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PRELS", "ART", "NN", "ART", "NN", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+--+--+-+-+-+-+-", "measure": "dactylic.di.plus"}, "line.24": {"text": "Wurde des Alkohols auch mitnichten gespart,", "tokens": ["Wur\u00b7de", "des", "Al\u00b7ko\u00b7hols", "auch", "mit\u00b7nich\u00b7ten", "ge\u00b7spart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.25": {"text": "Ebensowenig wie der trefflichen Nilpferdpeitsche,", "tokens": ["E\u00b7ben\u00b7so\u00b7we\u00b7nig", "wie", "der", "treff\u00b7li\u00b7chen", "Nil\u00b7pferd\u00b7peit\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+--+-+-", "measure": "iambic.hexa.invert"}, "line.26": {"text": "Die die Arbeit vers\u00fc\u00dft, wenn sie sonst sauer schmeckt.", "tokens": ["Die", "die", "Ar\u00b7beit", "ver\u00b7s\u00fc\u00dft", ",", "wenn", "sie", "sonst", "sau\u00b7er", "schmeckt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVPP", "$,", "KOUS", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.27": {"text": "Kurz, es entwickelte sich die allersch\u00f6nste Idylle,", "tokens": ["Kurz", ",", "es", "ent\u00b7wi\u00b7ckel\u00b7te", "sich", "die", "al\u00b7ler\u00b7sch\u00f6ns\u00b7te", "I\u00b7dyl\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PPER", "VVFIN", "PRF", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.28": {"text": "Tr\u00e4nen weinte der Lust Neger und Negerin,", "tokens": ["Tr\u00e4\u00b7nen", "wein\u00b7te", "der", "Lust", "Ne\u00b7ger", "und", "Ne\u00b7ge\u00b7rin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "+-+--++--+-+", "measure": "asklepiade"}, "line.29": {"text": "Tr\u00e4nen der R\u00fchrung aber benetzten die Brillengl\u00e4ser", "tokens": ["Tr\u00e4\u00b7nen", "der", "R\u00fch\u00b7rung", "a\u00b7ber", "be\u00b7netz\u00b7ten", "die", "Bril\u00b7len\u00b7gl\u00e4\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "ADV", "VVFIN", "ART", "NN"], "meter": "+--+-+--+--+-+-", "measure": "iambic.hexa.invert"}, "line.30": {"text": "Manchem Geheimen Rat, der in Berlin residiert.", "tokens": ["Man\u00b7chem", "Ge\u00b7hei\u00b7men", "Rat", ",", "der", "in", "Ber\u00b7lin", "re\u00b7si\u00b7diert", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,", "PRELS", "APPR", "NE", "VVFIN", "$."], "meter": "+--+-+--++--+", "measure": "iambic.hexa.invert"}}, "stanza.4": {"line.1": {"text": "Wie? Und jetzt? Was ist das? Das klingt ja wie Sch\u00fcsse? Herr Lehmann,", "tokens": ["Wie", "?", "Und", "jetzt", "?", "Was", "ist", "das", "?", "Das", "klingt", "ja", "wie", "Sch\u00fcs\u00b7se", "?", "Herr", "Leh\u00b7mann", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "$.", "KON", "ADV", "$.", "PWS", "VAFIN", "PDS", "$.", "PDS", "VVFIN", "ADV", "KOKOM", "NN", "$.", "NN", "NE", "$,"], "meter": "--+-+--+--+-++-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Riechen Sie nichts? Das riecht brenzlig, wie mich bed\u00fcnkt?", "tokens": ["Rie\u00b7chen", "Sie", "nichts", "?", "Das", "riecht", "brenz\u00b7lig", ",", "wie", "mich", "be\u00b7d\u00fcnkt", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIS", "$.", "PDS", "VVFIN", "ADJD", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Aufruhr? Was ist denn los? Warum denn? Wieso denn? Weshalb denn?", "tokens": ["Auf\u00b7ruhr", "?", "Was", "ist", "denn", "los", "?", "Wa\u00b7rum", "denn", "?", "Wie\u00b7so", "denn", "?", "We\u00b7shalb", "denn", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "PWS", "VAFIN", "ADV", "PTKVZ", "$.", "PWAV", "ADV", "$.", "PWAV", "ADV", "$.", "PWAV", "ADV", "$."], "meter": "+-----+-+-+-+-+", "measure": "dactylic.init"}, "line.4": {"text": "Wie? Ein Leutenant hat seinen Schwarzen gepf\u00e4hlt?", "tokens": ["Wie", "?", "Ein", "Leu\u00b7ten\u00b7ant", "hat", "sei\u00b7nen", "Schwar\u00b7zen", "ge\u00b7pf\u00e4hlt", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "ART", "NN", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "--+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "Ja, und die Schufte schie\u00dfen mit ", "tokens": ["Ja", ",", "und", "die", "Schuf\u00b7te", "schie\u00b7\u00dfen", "mit"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "KON", "ART", "NN", "VVFIN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Jetzt auf ", "tokens": ["Jetzt", "auf"], "token_info": ["word", "word"], "pos": ["ADV", "APPR"], "meter": "-+", "measure": "iambic.single"}}, "stanza.5": {"line.1": {"text": "Undank! Haben wir drum sie im Christentum unterwiesen,", "tokens": ["Un\u00b7dank", "!", "Ha\u00b7ben", "wir", "drum", "sie", "im", "Chris\u00b7ten\u00b7tum", "un\u00b7ter\u00b7wie\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VAFIN", "PPER", "PAV", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+--+-+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Da\u00df sie als Christen tun, was sie als Heiden getan?", "tokens": ["Da\u00df", "sie", "als", "Chris\u00b7ten", "tun", ",", "was", "sie", "als", "Hei\u00b7den", "ge\u00b7tan", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "KOUS", "NN", "VVINF", "$,", "PRELS", "PPER", "KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.3": {"text": "Sehen Sie, das ist der Lohn! Wir haben zu gut sie behandelt.", "tokens": ["Se\u00b7hen", "Sie", ",", "das", "ist", "der", "Lohn", "!", "Wir", "ha\u00b7ben", "zu", "gut", "sie", "be\u00b7han\u00b7delt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PDS", "VAFIN", "ART", "NN", "$.", "PPER", "VAFIN", "PTKA", "ADJD", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "\u2013 Aber das Pf\u00e4hlen? \u2013 Ach Gott, daran sind sie gew\u00f6hnt.", "tokens": ["\u2013", "A\u00b7ber", "das", "Pf\u00e4h\u00b7len", "?", "\u2013", "Ach", "Gott", ",", "da\u00b7ran", "sind", "sie", "ge\u00b7w\u00f6hnt", "."], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ART", "NN", "$.", "$(", "ITJ", "NN", "$,", "PAV", "VAFIN", "PPER", "VVPP", "$."], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}}, "stanza.6": {"line.1": {"text": "Nein, das Pf\u00e4hlen ists nicht, auch die Peitsche nicht. Recht hat Herr Lehmann;", "tokens": ["Nein", ",", "das", "Pf\u00e4h\u00b7len", "ists", "nicht", ",", "auch", "die", "Peit\u00b7sche", "nicht", ".", "Recht", "hat", "Herr", "Leh\u00b7mann", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "NN", "VAFIN", "PTKNEG", "$,", "ADV", "ART", "NN", "PTKNEG", "$.", "NN", "VAFIN", "NN", "NE", "$."], "meter": "+-+-+-+-+--+--+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Daran sind sie gew\u00f6hnt: Aber das Standesamt,", "tokens": ["Da\u00b7ran", "sind", "sie", "ge\u00b7w\u00f6hnt", ":", "A\u00b7ber", "das", "Stan\u00b7des\u00b7amt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "VVPP", "$.", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Aber die Hosen, der Drill, die Verordnungen und die Gebete,", "tokens": ["A\u00b7ber", "die", "Ho\u00b7sen", ",", "der", "Drill", ",", "die", "Ver\u00b7ord\u00b7nun\u00b7gen", "und", "die", "Ge\u00b7be\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.4": {"text": "Das macht sie so rabiat: preu\u00dfisch wolln sie nicht sein.", "tokens": ["Das", "macht", "sie", "so", "ra\u00b7biat", ":", "preu\u00b7\u00dfisch", "wolln", "sie", "nicht", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "VVFIN", "$.", "ADJD", "VMFIN", "PPER", "PTKNEG", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Was im Sande der Mark Assessorengenerationen", "tokens": ["Was", "im", "San\u00b7de", "der", "Mark", "As\u00b7ses\u00b7so\u00b7ren\u00b7ge\u00b7ne\u00b7ra\u00b7ti\u00b7o\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "APPRART", "NN", "ART", "NN", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Langsam nur fertig gebracht, geht doch in Afrika", "tokens": ["Lang\u00b7sam", "nur", "fer\u00b7tig", "ge\u00b7bracht", ",", "geht", "doch", "in", "Af\u00b7ri\u00b7ka"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "ADV", "ADJD", "VVPP", "$,", "VVFIN", "ADV", "APPR", "NE"], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Nicht in einem Jahrzehnt; die schwarzen Halunken haben", "tokens": ["Nicht", "in", "ei\u00b7nem", "Jahr\u00b7zehnt", ";", "die", "schwar\u00b7zen", "Ha\u00b7lun\u00b7ken", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "APPR", "ART", "NN", "$.", "ART", "ADJA", "NN", "VAFIN"], "meter": "+-+-+--+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Allzulange sich nackt frei wie die Teufel gef\u00fchlt.", "tokens": ["A\u00b7llzu\u00b7lan\u00b7ge", "sich", "nackt", "frei", "wie", "die", "Teu\u00b7fel", "ge\u00b7f\u00fchlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADJD", "ADJD", "KOKOM", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}}, "stanza.8": {"line.1": {"text": "Und nun sollen sie flugs vor jedem Amtsschimmel Ehrfurcht", "tokens": ["Und", "nun", "sol\u00b7len", "sie", "flugs", "vor", "je\u00b7dem", "Amts\u00b7schim\u00b7mel", "Ehr\u00b7furcht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VMFIN", "PPER", "ADV", "APPR", "PIAT", "NN", "NN"], "meter": "--+--+-+-++--+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Haben, wie Piefke sie hat? Nein, Herr Assessor, das ist", "tokens": ["Ha\u00b7ben", ",", "wie", "Pief\u00b7ke", "sie", "hat", "?", "Nein", ",", "Herr", "As\u00b7ses\u00b7sor", ",", "das", "ist"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "$,", "PWAV", "NN", "PPER", "VAFIN", "$.", "PTKANT", "$,", "NN", "NE", "$,", "PDS", "VAFIN"], "meter": "+--+-+-+-+-+-+", "measure": "iambic.septa.invert"}, "line.3": {"text": "So unm\u00f6glich, als wie, da\u00df ", "tokens": ["So", "un\u00b7m\u00f6g\u00b7lich", ",", "als", "wie", ",", "da\u00df"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "ADJD", "$,", "KOUS", "KOKOM", "$,", "KOUS"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lernten die Kunst, ein Mensch ohne Polizei zu sein.", "tokens": ["Lern\u00b7ten", "die", "Kunst", ",", "ein", "Mensch", "oh\u00b7ne", "Po\u00b7li\u00b7zei", "zu", "sein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "ART", "NN", "APPR", "NN", "PTKZU", "VAINF", "$."], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}}, "stanza.9": {"line.1": {"text": "Eines schickt sich, sagt Goethe, f\u00fcr alle nicht. Bester Assessor,", "tokens": ["Ei\u00b7nes", "schickt", "sich", ",", "sagt", "Goe\u00b7the", ",", "f\u00fcr", "al\u00b7le", "nicht", ".", "Bes\u00b7ter", "As\u00b7ses\u00b7sor", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "$,", "VVFIN", "NE", "$,", "APPR", "PIS", "PTKNEG", "$.", "NN", "NN", "$,"], "meter": "+-+--+--+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Entassessoren Sie sich, wenn Sie in Afrika sind,", "tokens": ["En\u00b7tas\u00b7ses\u00b7so\u00b7ren", "Sie", "sich", ",", "wenn", "Sie", "in", "Af\u00b7ri\u00b7ka", "sind", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "$,", "KOUS", "PPER", "APPR", "NE", "VAFIN", "$,"], "meter": "-+-+-+-++-+-+-", "measure": "unknown.measure.septa"}, "line.3": {"text": "Blo\u00df ein ganz klein wenig, und denken Sie dran, da\u00df Neger", "tokens": ["Blo\u00df", "ein", "ganz", "klein", "we\u00b7nig", ",", "und", "den\u00b7ken", "Sie", "dran", ",", "da\u00df", "Ne\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ART", "ADV", "ADJD", "PIS", "$,", "KON", "VVFIN", "PPER", "PAV", "$,", "KOUS", "NN"], "meter": "+---+--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Keine Piefkes sind. Dann wird es besser gehn.", "tokens": ["Kei\u00b7ne", "Pief\u00b7kes", "sind", ".", "Dann", "wird", "es", "bes\u00b7ser", "gehn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "$.", "ADV", "VAFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Unsern Platz an der Sonne, gewi\u00df, den wollen wir suchen,", "tokens": ["Un\u00b7sern", "Platz", "an", "der", "Son\u00b7ne", ",", "ge\u00b7wi\u00df", ",", "den", "wol\u00b7len", "wir", "su\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "$,", "ADV", "$,", "ART", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.6": {"text": "Aber verd\u00fcstert ihn, bitte, nicht gleich mit euch.", "tokens": ["A\u00b7ber", "ver\u00b7d\u00fcs\u00b7tert", "ihn", ",", "bit\u00b7te", ",", "nicht", "gleich", "mit", "euch", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PTKANT", "$,", "PTKNEG", "ADV", "APPR", "PPER", "$."], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}}}}}