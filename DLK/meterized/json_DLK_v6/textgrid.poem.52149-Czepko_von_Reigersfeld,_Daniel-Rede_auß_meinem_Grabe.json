{"textgrid.poem.52149": {"metadata": {"author": {"name": "Czepko von Reigersfeld, Daniel", "birth": "N.A.", "death": "N.A."}, "title": "Rede au\u00df meinem Grabe", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O Mensch/ du Grab der Eitelkeit", "tokens": ["O", "Mensch", "/", "du", "Grab", "der", "Ei\u00b7tel\u00b7keit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "$(", "PPER", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Triet her zu diesem Grabe:", "tokens": ["Triet", "her", "zu", "die\u00b7sem", "Gra\u00b7be", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APZR", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Schau was ich dir/ du Raub der Zeit/", "tokens": ["Schau", "was", "ich", "dir", "/", "du", "Raub", "der", "Zeit", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PWS", "PPER", "PPER", "$(", "PPER", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Darein geleget habe.", "tokens": ["Da\u00b7rein", "ge\u00b7le\u00b7get", "ha\u00b7be", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Was du ietzt bist und dann wirst seyn/", "tokens": ["Was", "du", "ietzt", "bist", "und", "dann", "wirst", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VAFIN", "KON", "ADV", "VAFIN", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nihm von mir/ dir zur Warnung ein.", "tokens": ["Nihm", "von", "mir", "/", "dir", "zur", "War\u00b7nung", "ein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPER", "$(", "PPER", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ein kleiner H\u00fcgel ist mein Reich/", "tokens": ["Ein", "klei\u00b7ner", "H\u00fc\u00b7gel", "ist", "mein", "Reich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Orth von dreyen Ehlen:", "tokens": ["Ein", "Orth", "von", "drey\u00b7en", "Eh\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "CARD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vier Brether einem Kasten gleich/", "tokens": ["Vier", "Bre\u00b7ther", "ei\u00b7nem", "Kas\u00b7ten", "gleich", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ART", "NN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verwahrn mich und viel quehlen:", "tokens": ["Ver\u00b7wahrn", "mich", "und", "viel", "queh\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "KON", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sechs Schauffeln Erd'/ O sanffte Ruh!", "tokens": ["Sechs", "Schauf\u00b7feln", "Erd'", "/", "O", "sanff\u00b7te", "Ruh", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "NN", "$(", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Scharrn mich/ und auch viel Sorgen zu.", "tokens": ["Scharrn", "mich", "/", "und", "auch", "viel", "Sor\u00b7gen", "zu", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$(", "KON", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ich war ein Mensch/ wie du auch bist", "tokens": ["Ich", "war", "ein", "Mensch", "/", "wie", "du", "auch", "bist"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "$(", "PWAV", "PPER", "ADV", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Stand und vom Verstande:", "tokens": ["Von", "Stand", "und", "vom", "Ver\u00b7stan\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dein gleiches Bild/ dein neben Christ:", "tokens": ["Dein", "glei\u00b7ches", "Bild", "/", "dein", "ne\u00b7ben", "Christ", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$(", "PPOSAT", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Jetzt lieg ich hier im Sande.", "tokens": ["Jetzt", "lieg", "ich", "hier", "im", "San\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Kein Marmel darff mein Grab erh\u00f6hn/", "tokens": ["Kein", "Mar\u00b7mel", "darff", "mein", "Grab", "er\u00b7h\u00f6hn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df ich kan leichter aufferstehn.", "tokens": ["Da\u00df", "ich", "kan", "leich\u00b7ter", "auf\u00b7fer\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Was ist der Mensch? de\u00df Todes Ziehl:", "tokens": ["Was", "ist", "der", "Mensch", "?", "de\u00df", "To\u00b7des", "Ziehl", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "$.", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "De\u00df Irrthums Wirbel wende.", "tokens": ["De\u00df", "Irr\u00b7thums", "Wir\u00b7bel", "wen\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sein Thun? der Eitelkeiten Spiel/", "tokens": ["Sein", "Thun", "?", "der", "Ei\u00b7tel\u00b7kei\u00b7ten", "Spiel", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Vorsatz sonder Ende.", "tokens": ["Ein", "Vor\u00b7satz", "son\u00b7der", "En\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sein Geist? ein halber Mund voll Lufft", "tokens": ["Sein", "Geist", "?", "ein", "hal\u00b7ber", "Mund", "voll", "Lufft"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$.", "ART", "ADJA", "NN", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der so viel denckt und schafft und hofft.", "tokens": ["Der", "so", "viel", "denckt", "und", "schafft", "und", "hofft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Kein K\u00f6nig: solt' Er gleich an Schein", "tokens": ["Kein", "K\u00f6\u00b7nig", ":", "solt'", "Er", "gleich", "an", "Schein"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "$.", "VMFIN", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Alexander pochen/", "tokens": ["Den", "A\u00b7lex\u00b7an\u00b7der", "po\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NE", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein neuer Welt Beherrscher seyn/", "tokens": ["Ein", "neu\u00b7er", "Welt", "Be\u00b7herr\u00b7scher", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und noch mehr Welten suchen.", "tokens": ["Und", "noch", "mehr", "Wel\u00b7ten", "su\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Kein Bettelman vor deiner Th\u00fcr/", "tokens": ["Kein", "Bet\u00b7tel\u00b7man", "vor", "dei\u00b7ner", "Th\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Darff einen gr\u00f6ssern Raum vor mir.", "tokens": ["Darff", "ei\u00b7nen", "gr\u00f6s\u00b7sern", "Raum", "vor", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "ADJA", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Hier ist der Gr\u00e4ntzstein aller Macht/", "tokens": ["Hier", "ist", "der", "Gr\u00e4ntz\u00b7stein", "al\u00b7ler", "Macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Zohl-Haus aller Sachen:", "tokens": ["Das", "Zohl\u00b7Haus", "al\u00b7ler", "Sa\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Kunst/ Sch\u00f6nheit/ Herrligkeit und Pracht/", "tokens": ["Kunst", "/", "Sch\u00f6n\u00b7heit", "/", "Herr\u00b7lig\u00b7keit", "und", "Pracht", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Darff sich nicht dr\u00fcber machen.", "tokens": ["Darff", "sich", "nicht", "dr\u00fc\u00b7ber", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "PTKNEG", "PAV", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.5": {"text": "Ein Schwerd/ ein Buch/ ein Pflug/ ein Stab/", "tokens": ["Ein", "Schwerd", "/", "ein", "Buch", "/", "ein", "Pflug", "/", "ein", "Stab", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "$(", "ART", "NN", "$(", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sucht unter einem Staub ein Grab.", "tokens": ["Sucht", "un\u00b7ter", "ei\u00b7nem", "Staub", "ein", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "So weit/ so weit hast du zu mir/", "tokens": ["So", "weit", "/", "so", "weit", "hast", "du", "zu", "mir", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "ADV", "ADJD", "VAFIN", "PPER", "APPR", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Fu\u00df hat zu der Erden:", "tokens": ["Dein", "Fu\u00df", "hat", "zu", "der", "Er\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Tod/ dein steter Gast winckt dir:", "tokens": ["Der", "Tod", "/", "dein", "ste\u00b7ter", "Gast", "winckt", "dir", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Folg ihm: wiltu klug werden.", "tokens": ["Folg", "ihm", ":", "wil\u00b7tu", "klug", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$.", "VMFIN", "ADJD", "VAINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Was du sonst suchest weit und breit", "tokens": ["Was", "du", "sonst", "su\u00b7chest", "weit", "und", "breit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "ADV", "VVFIN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist nichts als eitel Eitelkeit.", "tokens": ["Ist", "nichts", "als", "ei\u00b7tel", "Ei\u00b7tel\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "KOKOM", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Der Leib/ das Haus/ in dem der Geist", "tokens": ["Der", "Leib", "/", "das", "Haus", "/", "in", "dem", "der", "Geist"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "ART", "NN", "$(", "APPR", "PRELS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Beherbergt so viel Jahre:", "tokens": ["Be\u00b7her\u00b7bergt", "so", "viel", "Jah\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der in der \u00dcbung ward gepreist/", "tokens": ["Der", "in", "der", "\u00dc\u00b7bung", "ward", "ge\u00b7preist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Liegt auff der Todten Bahre.", "tokens": ["Liegt", "auff", "der", "Tod\u00b7ten", "Bah\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Was hurtig/ was gerad und starck", "tokens": ["Was", "hur\u00b7tig", "/", "was", "ge\u00b7rad", "und", "starck"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "ADJD", "$(", "PWS", "ADV", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist ietzt ein Aa\u00df und fault im Sarg.", "tokens": ["Ist", "ietzt", "ein", "Aa\u00df", "und", "fault", "im", "Sarg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "KON", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ihr/ die ihr St\u00e4rck' in Armen sp\u00fcrt;", "tokens": ["Ihr", "/", "die", "ihr", "St\u00e4rck", "in", "Ar\u00b7men", "sp\u00fcrt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "ART", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geschickligkeit in F\u00fcssen:", "tokens": ["Ge\u00b7schick\u00b7lig\u00b7keit", "in", "F\u00fcs\u00b7sen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "In F\u00e4usten gleiche Masse f\u00fchrt", "tokens": ["In", "F\u00e4us\u00b7ten", "glei\u00b7che", "Mas\u00b7se", "f\u00fchrt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu l\u00f6sen und zu schl\u00fcssen/", "tokens": ["Zu", "l\u00f6\u00b7sen", "und", "zu", "schl\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Vor Degen/ Ritterspiel und Pferd:", "tokens": ["Vor", "De\u00b7gen", "/", "Rit\u00b7ter\u00b7spiel", "und", "Pferd", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Schaut wie der Tod das Blath verkehrt.", "tokens": ["Schaut", "wie", "der", "Tod", "das", "Blath", "ver\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Was hilfft es/ da\u00df ihr das Rappir/", "tokens": ["Was", "hilfft", "es", "/", "da\u00df", "ihr", "das", "Rap\u00b7pir", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$(", "KOUS", "PPER", "ART", "NN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Dem Tibolt nachgetragen:", "tokens": ["Dem", "Ti\u00b7bolt", "nach\u00b7ge\u00b7tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df F\u00fcrsten nandten ihre Ziehr/", "tokens": ["Da\u00df", "F\u00fcrs\u00b7ten", "nand\u00b7ten", "ih\u00b7re", "Ziehr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nach dem sich viel geschlagen:", "tokens": ["Nach", "dem", "sich", "viel", "ge\u00b7schla\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Der Tod hat hier mit stracker Hand", "tokens": ["Der", "Tod", "hat", "hier", "mit", "stra\u00b7cker", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gef\u00fchl und Klinge mir entwand.", "tokens": ["Ge\u00b7f\u00fchl", "und", "Klin\u00b7ge", "mir", "ent\u00b7wand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Was nutzet es/ da\u00df ihr wohl schwingt", "tokens": ["Was", "nut\u00b7zet", "es", "/", "da\u00df", "ihr", "wohl", "schwingt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "$(", "KOUS", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Fahn und auch die Picke:", "tokens": ["Den", "Fahn", "und", "auch", "die", "Pi\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wol schieft/ wol schwimbt/ wol laufft und springt", "tokens": ["Wol", "schieft", "/", "wol", "schwimbt", "/", "wol", "laufft", "und", "springt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$(", "ADV", "VVFIN", "$(", "ADV", "VVFIN", "KON", "VVFIN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Vor sich und auch zu r\u00fccke:", "tokens": ["Vor", "sich", "und", "auch", "zu", "r\u00fc\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "KON", "ADV", "PTKZU", "VVFIN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.5": {"text": "Den Schenckeln bringt der Tod; Ach Pein!", "tokens": ["Den", "Schen\u00b7ckeln", "bringt", "der", "Tod", ";", "Ach", "Pein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$.", "ITJ", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hier das gelernte Zittern ein.", "tokens": ["Hier", "das", "ge\u00b7lern\u00b7te", "Zit\u00b7tern", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Was dien't es/ da\u00df ihr euer Pferd", "tokens": ["Was", "dien't", "es", "/", "da\u00df", "ihr", "eu\u00b7er", "Pferd"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "$(", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Umbwerfft zu beyden Seiten:", "tokens": ["Um\u00b7bwerfft", "zu", "bey\u00b7den", "Sei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df sich der Hengst/ wie ihr begehrt/", "tokens": ["Da\u00df", "sich", "der", "Hengst", "/", "wie", "ihr", "be\u00b7gehrt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "$(", "PWAV", "PPER", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Lest wol in Schulen reitten:", "tokens": ["Lest", "wol", "in", "Schu\u00b7len", "reit\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Das Schull- recht mach' ich hier gemach", "tokens": ["Das", "Schull", "recht", "mach'", "ich", "hier", "ge\u00b7mach"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dem Tod auff seiner Fahlen nach.", "tokens": ["Dem", "Tod", "auff", "sei\u00b7ner", "Fah\u00b7len", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Ihr/ die ihr viel auff Jugend traut/", "tokens": ["Ihr", "/", "die", "ihr", "viel", "auff", "Ju\u00b7gend", "traut", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "PRELS", "PPER", "ADV", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auff frische Mannes Kr\u00e4ffte:", "tokens": ["Auff", "fri\u00b7sche", "Man\u00b7nes", "Kr\u00e4ff\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Viel auff Gewerb und Wirtschafft baut/", "tokens": ["Viel", "auff", "Ge\u00b7werb", "und", "Wirt\u00b7schafft", "baut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auff allerhand Gesch\u00e4ffte:", "tokens": ["Auff", "al\u00b7ler\u00b7hand", "Ge\u00b7sch\u00e4ff\u00b7te", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ein Sarg wie der/ ist euer Lohn/", "tokens": ["Ein", "Sarg", "wie", "der", "/", "ist", "eu\u00b7er", "Lohn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "ART", "$(", "VAFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sonst kriegt ihr warlich nichts darvon.", "tokens": ["Sonst", "kriegt", "ihr", "war\u00b7lich", "nichts", "dar\u00b7von", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PIS", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Was ist die Jugend? Ein Gelach", "tokens": ["Was", "ist", "die", "Ju\u00b7gend", "?", "Ein", "Ge\u00b7lach"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "VAFIN", "ART", "NN", "$.", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Tausend Eitelkeiten:", "tokens": ["Von", "Tau\u00b7send", "Ei\u00b7tel\u00b7kei\u00b7ten", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein Spiel- ein Buhl- ein Lust-Gemach", "tokens": ["Ein", "Spiel", "ein", "Buhl", "ein", "Lust\u00b7Ge\u00b7mach"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "TRUNC", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Darinnen wir uns breiten.", "tokens": ["Da\u00b7rin\u00b7nen", "wir", "uns", "brei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Schaut wie mich Atropos ietzt hertzt/", "tokens": ["Schaut", "wie", "mich", "A\u00b7tro\u00b7pos", "ietzt", "hertzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "PPER", "NE", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df ich darinnen auch geschertzt.", "tokens": ["Da\u00df", "ich", "da\u00b7rin\u00b7nen", "auch", "ge\u00b7schertzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Was ist die Eh'? ein Sorgen Nest.", "tokens": ["Was", "ist", "die", "Eh'", "?", "ein", "Sor\u00b7gen", "Nest", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "$.", "ART", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie reich/ wie klug/ wie sch\u00f6ne", "tokens": ["Wie", "reich", "/", "wie", "klug", "/", "wie", "sch\u00f6\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "ADJD", "$(", "PWAV", "ADJD", "$(", "KOKOM", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dein Schatz/ dein liebes Weib gewest/", "tokens": ["Dein", "Schatz", "/", "dein", "lie\u00b7bes", "Weib", "ge\u00b7west", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PPOSAT", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie sitsam deine S\u00f6hne/", "tokens": ["Wie", "sit\u00b7sam", "dei\u00b7ne", "S\u00f6h\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPOSAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ein ander mu\u00df versorgen sie/", "tokens": ["Ein", "an\u00b7der", "mu\u00df", "ver\u00b7sor\u00b7gen", "sie", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VMFIN", "VVFIN", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Di\u00df hatt ich auch/ ietzt lieg ich hie.", "tokens": ["Di\u00df", "hatt", "ich", "auch", "/", "ietzt", "lieg", "ich", "hie", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "$(", "ADV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Was ist die Wirtschafft? eine Lust", "tokens": ["Was", "ist", "die", "Wirt\u00b7schafft", "?", "ei\u00b7ne", "Lust"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "VAFIN", "ART", "NN", "$.", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Unlust stets umbgeben/", "tokens": ["Mit", "Un\u00b7lust", "stets", "umb\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch wol dem/ der ihm wol bewust/", "tokens": ["Doch", "wol", "dem", "/", "der", "ihm", "wol", "be\u00b7wust", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "$(", "ART", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kan auff dem Felde leben:", "tokens": ["Kan", "auff", "dem", "Fel\u00b7de", "le\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Die Erde/ weil wir Erde sein/", "tokens": ["Die", "Er\u00b7de", "/", "weil", "wir", "Er\u00b7de", "sein", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "KOUS", "PPER", "NN", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Pfl\u00fcgt ich/ ietzt scharrt sie mich drauff ein!", "tokens": ["Pfl\u00fcgt", "ich", "/", "ietzt", "scharrt", "sie", "mich", "drauff", "ein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$(", "ADV", "VVFIN", "PPER", "PRF", "PAV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Was sind Gesch\u00e4fft? ein Licht da\u00df sich", "tokens": ["Was", "sind", "Ge\u00b7sch\u00e4fft", "?", "ein", "Licht", "da\u00df", "sich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "NN", "$.", "ART", "NN", "KOUS", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Begr\u00e4bet unterm brennen:", "tokens": ["Be\u00b7gr\u00e4\u00b7bet", "un\u00b7term", "bren\u00b7nen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir machen frey von H\u00e4ndeln dich/", "tokens": ["Wir", "ma\u00b7chen", "frey", "von", "H\u00e4n\u00b7deln", "dich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "NN", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Eh' als wir Unsre kennen.", "tokens": ["Eh'", "als", "wir", "Uns\u00b7re", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Der keinem Menschen was versagt:", "tokens": ["Der", "kei\u00b7nem", "Men\u00b7schen", "was", "ver\u00b7sagt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "PWS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sieht nicht/ wer nach den Seinen fragt.", "tokens": ["Sieht", "nicht", "/", "wer", "nach", "den", "Sei\u00b7nen", "fragt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$(", "PWS", "APPR", "ART", "PPOSS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Der Geist/ ein Wirth/ der durch das Haus/", "tokens": ["Der", "Geist", "/", "ein", "Wirth", "/", "der", "durch", "das", "Haus", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "$(", "ART", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Gasthoff geitzer W\u00fcrme/", "tokens": ["Den", "Gast\u00b7hoff", "geit\u00b7zer", "W\u00fcr\u00b7me", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hat seine Krafft gebreitet au\u00df/", "tokens": ["Hat", "sei\u00b7ne", "Krafft", "ge\u00b7brei\u00b7tet", "au\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "VVPP", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch so viel Jahr und St\u00fcrme/", "tokens": ["Durch", "so", "viel", "Jahr", "und", "St\u00fcr\u00b7me", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "NN", "KON", "NN", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.5": {"text": "Ist nunmehr Himmel auff gereist:", "tokens": ["Ist", "nun\u00b7mehr", "Him\u00b7mel", "auff", "ge\u00b7reist", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "APPR", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Kein Pfad das minste von ihm weist.", "tokens": ["Kein", "Pfad", "das", "mins\u00b7te", "von", "ihm", "weist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "ADJA", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Ihr/ die ihr Kunst und Wissenschafft", "tokens": ["Ihr", "/", "die", "ihr", "Kunst", "und", "Wis\u00b7sen\u00b7schafft"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "$(", "ART", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erfunden und beschrieben:", "tokens": ["Er\u00b7fun\u00b7den", "und", "be\u00b7schrie\u00b7ben", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Von deren Sinnen weisen Krafft", "tokens": ["Von", "de\u00b7ren", "Sin\u00b7nen", "wei\u00b7sen", "Krafft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PRELAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nichts unentdecket blieben.", "tokens": ["Nichts", "un\u00b7ent\u00b7de\u00b7cket", "blie\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sehr wenig hab ich nicht gewust", "tokens": ["Sehr", "we\u00b7nig", "hab", "ich", "nicht", "ge\u00b7wust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "VAFIN", "PPER", "PTKNEG", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und doch an diesen Orth gemust.", "tokens": ["Und", "doch", "an", "die\u00b7sen", "Orth", "ge\u00b7must", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Ich hab auf die gebundne Art/", "tokens": ["Ich", "hab", "auf", "die", "ge\u00b7bund\u00b7ne", "Art", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit mehr als Hundert B\u00fcchern:", "tokens": ["Mit", "mehr", "als", "Hun\u00b7dert", "B\u00fc\u00b7chern", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "KOKOM", "CARD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Zwar wollen mir/ vor meiner Farth/", "tokens": ["Zwar", "wol\u00b7len", "mir", "/", "vor", "mei\u00b7ner", "Farth", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "$(", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mein Andenckmahl versichern.", "tokens": ["Mein", "An\u00b7denck\u00b7mahl", "ver\u00b7si\u00b7chern", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Jedoch die B\u00fccher scharrt in sich", "tokens": ["Je\u00b7doch", "die", "B\u00fc\u00b7cher", "scharrt", "in", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VVFIN", "APPR", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die faule Mott'/ und Streck-Fu\u00df mich.", "tokens": ["Die", "fau\u00b7le", "Mott'", "/", "und", "Streck\u00b7Fu\u00df", "mich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "KON", "NN", "PPER", "$."], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}}, "stanza.21": {"line.1": {"text": "Gestalt/ und Eigenschafft und Grund/", "tokens": ["Ge\u00b7stalt", "/", "und", "Ei\u00b7gen\u00b7schafft", "und", "Grund", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KON", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der wunderbahrn Gesch\u00f6pffe:", "tokens": ["Der", "wun\u00b7der\u00b7bahrn", "Ge\u00b7sch\u00f6pf\u00b7fe", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ward mir durch weises suchen kund/", "tokens": ["Ward", "mir", "durch", "wei\u00b7ses", "su\u00b7chen", "kund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ADJA", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Werck vor kluge K\u00f6pffe/", "tokens": ["Ein", "Werck", "vor", "klu\u00b7ge", "K\u00f6pf\u00b7fe", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Der Dinge Glantz durch-ging mich offt/", "tokens": ["Der", "Din\u00b7ge", "Glantz", "durch\u00b7ging", "mich", "offt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PPER", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Jetzt lieg ich in der finstern Grufft.", "tokens": ["Jetzt", "lieg", "ich", "in", "der", "fins\u00b7tern", "Grufft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Die allgemeine Scheide Kunst/", "tokens": ["Die", "all\u00b7ge\u00b7mei\u00b7ne", "Schei\u00b7de", "Kunst", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wies mir das Saltz der Erden/", "tokens": ["Wies", "mir", "das", "Saltz", "der", "Er\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es solte drau\u00df/ durch Gottes Gunst/", "tokens": ["Es", "sol\u00b7te", "drau\u00df", "/", "durch", "Got\u00b7tes", "Gunst", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PAV", "$(", "APPR", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Weisen Artzney werden:", "tokens": ["Der", "Wei\u00b7sen", "Artz\u00b7ney", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Schaut wie der scheutzlich Alchimist/", "tokens": ["Schaut", "wie", "der", "scheutz\u00b7lich", "Al\u00b7chi\u00b7mist", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "ART", "ADJD", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Tod/ mich selber kocht und frist.", "tokens": ["Der", "Tod", "/", "mich", "sel\u00b7ber", "kocht", "und", "frist", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PPER", "ADV", "VVFIN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Das Recht/ da\u00df die Natur und Gott", "tokens": ["Das", "Recht", "/", "da\u00df", "die", "Na\u00b7tur", "und", "Gott"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "KOUS", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Uns gr\u00e4bt in das Gewissen:", "tokens": ["Uns", "gr\u00e4bt", "in", "das", "Ge\u00b7wis\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "War mir das rechte Grund Gebot/", "tokens": ["War", "mir", "das", "rech\u00b7te", "Grund", "Ge\u00b7bot", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Draus alle Rechts-Lehrn fliessen:", "tokens": ["Draus", "al\u00b7le", "Rechts\u00b7Lehrn", "flies\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Der Vieler/ liegt hier auff der Baar/", "tokens": ["Der", "Vie\u00b7ler", "/", "liegt", "hier", "auff", "der", "Baar", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "VVFIN", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein allgemeines Rath-Haus war.", "tokens": ["Ein", "all\u00b7ge\u00b7mei\u00b7nes", "Ra\u00b7th\u00b7Haus", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Was sie die Cabala auch kan/", "tokens": ["Was", "sie", "die", "Ca\u00b7ba\u00b7la", "auch", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "ADV", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Entbilden und enth\u00f6hlen", "tokens": ["Ent\u00b7bil\u00b7den", "und", "ent\u00b7h\u00f6h\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hoch \u00fcber de\u00df Gem\u00fcttes Bahn", "tokens": ["Hoch", "\u00fc\u00b7ber", "de\u00df", "Ge\u00b7m\u00fct\u00b7tes", "Bahn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In einer reinen Seelen/", "tokens": ["In", "ei\u00b7ner", "rei\u00b7nen", "See\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Hab ich geschaut/ erkand/ erfahrn/", "tokens": ["Hab", "ich", "ge\u00b7schaut", "/", "er\u00b7kand", "/", "er\u00b7fahrn", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "PPER", "VVPP", "$(", "VVFIN", "$(", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Jetzt lieg ich untern meisten Schaarn.", "tokens": ["Jetzt", "lieg", "ich", "un\u00b7tern", "meis\u00b7ten", "Schaarn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Und kurtz: die Werckzeug ingesambt/", "tokens": ["Und", "kurtz", ":", "die", "Wer\u00b7ck\u00b7zeug", "in\u00b7ge\u00b7sambt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$.", "ART", "NN", "ADJD", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Der h\u00f6chsten Wissenschafften:", "tokens": ["Der", "h\u00f6chs\u00b7ten", "Wis\u00b7sen\u00b7schaff\u00b7ten", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sind abgeschafft: hier endt ihr Ambt", "tokens": ["Sind", "ab\u00b7ge\u00b7schafft", ":", "hier", "endt", "ihr", "Ambt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "VVPP", "$.", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dran manche sich vergafften", "tokens": ["Dran", "man\u00b7che", "sich", "ver\u00b7gaff\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "PIAT", "PRF", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Nicht eines/ wann du es erkiest/", "tokens": ["Nicht", "ei\u00b7nes", "/", "wann", "du", "es", "er\u00b7kiest", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "$(", "PWAV", "PPER", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wei\u00df mehr/ was es gewesen ist.", "tokens": ["Wei\u00df", "mehr", "/", "was", "es", "ge\u00b7we\u00b7sen", "ist", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$(", "PWS", "PPER", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Die Lippen/ die es kund gethan/", "tokens": ["Die", "Lip\u00b7pen", "/", "die", "es", "kund", "ge\u00b7than", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "PTKVZ", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Hand/ in die es kommen:", "tokens": ["Die", "Hand", "/", "in", "die", "es", "kom\u00b7men", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "APPR", "PRELS", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Augen/ die es schauten an/", "tokens": ["Die", "Au\u00b7gen", "/", "die", "es", "schau\u00b7ten", "an", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Ohrn/ die es vernommen:", "tokens": ["Die", "Ohrn", "/", "die", "es", "ver\u00b7nom\u00b7men", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sind stumm/ sind lahm/ sind blind/ sind taub/", "tokens": ["Sind", "stumm", "/", "sind", "lahm", "/", "sind", "blind", "/", "sind", "taub", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$(", "VAFIN", "PTKVZ", "$(", "VAFIN", "ADJD", "$(", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und alles eine Handvoll Staub.", "tokens": ["Und", "al\u00b7les", "ei\u00b7ne", "Hand\u00b7voll", "Staub", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Drum der du diese Grabschriefft liest/", "tokens": ["Drum", "der", "du", "die\u00b7se", "Grab\u00b7schriefft", "liest", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "PPER", "PDAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und h\u00f6rst mich unterm Sande:", "tokens": ["Und", "h\u00f6rst", "mich", "un\u00b7term", "San\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Gedenck an Tod/ wie hoch du bist", "tokens": ["Ge\u00b7denck", "an", "Tod", "/", "wie", "hoch", "du", "bist"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NN", "$(", "PWAV", "ADJD", "PPER", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Am Stand und am Verstande:", "tokens": ["Am", "Stand", "und", "am", "Ver\u00b7stan\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Du hast nicht einen Schriet zu mir/", "tokens": ["Du", "hast", "nicht", "ei\u00b7nen", "Schriet", "zu", "mir", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ART", "NN", "APPR", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dein Grab steht untern F\u00fcssen dir.", "tokens": ["Dein", "Grab", "steht", "un\u00b7tern", "F\u00fcs\u00b7sen", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJA", "NN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Du wirst au\u00df deiner Felder Raum", "tokens": ["Du", "wirst", "au\u00df", "dei\u00b7ner", "Fel\u00b7der", "Raum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Grab allda zu liegen:", "tokens": ["Ein", "Grab", "all\u00b7da", "zu", "lie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Gewand/ au\u00df deinem Kasten kaum/", "tokens": ["Ge\u00b7wand", "/", "au\u00df", "dei\u00b7nem", "Kas\u00b7ten", "kaum", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "APPR", "PPOSAT", "NN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zum Sterbe-Kittel kriegen:", "tokens": ["Zum", "Ster\u00b7be\u00b7Kit\u00b7tel", "krie\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Von Dienern/ welche dich itzt ehrn", "tokens": ["Von", "Die\u00b7nern", "/", "wel\u00b7che", "dich", "itzt", "ehrn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$(", "PRELS", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wird man dich nicht mehr nennen h\u00f6rn.", "tokens": ["Wird", "man", "dich", "nicht", "mehr", "nen\u00b7nen", "h\u00f6rn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PRF", "PTKNEG", "ADV", "VVINF", "VVINF", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.29": {"line.1": {"text": "Nackt ein/ nackt zihn wir au\u00df der Zeit/", "tokens": ["Nackt", "ein", "/", "nackt", "zihn", "wir", "au\u00df", "der", "Zeit", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "$(", "ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nichts folgt uns/ wann wir sterben", "tokens": ["Nichts", "folgt", "uns", "/", "wann", "wir", "ster\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "$(", "PWAV", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als de\u00df Gewissens Reinigkeit", "tokens": ["Als", "de\u00df", "Ge\u00b7wis\u00b7sens", "Rei\u00b7nig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "NN"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das ander bleibt den Erben.", "tokens": ["Das", "an\u00b7der", "bleibt", "den", "Er\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Weib/ Kind/ Haus/ Ansehn/ Ambt und Gutt", "tokens": ["Weib", "/", "Kind", "/", "Haus", "/", "An\u00b7sehn", "/", "Ambt", "und", "Gutt"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$(", "NN", "$(", "NN", "$(", "VVINF", "$(", "NE", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nihmbstu nicht/ noch sie dich in Hutt.", "tokens": ["Nihmbs\u00b7tu", "nicht", "/", "noch", "sie", "dich", "in", "Hutt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "$(", "ADV", "PPER", "PRF", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Wann es am letzten Abdruck ist", "tokens": ["Wann", "es", "am", "letz\u00b7ten", "Ab\u00b7druck", "ist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPRART", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So hilfft dich nichts dein Wissen:", "tokens": ["So", "hilfft", "dich", "nichts", "dein", "Wis\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die K\u00fcnste/ so du vor erkiest/", "tokens": ["Die", "K\u00fcns\u00b7te", "/", "so", "du", "vor", "er\u00b7kiest", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "PPER", "APPR", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und dein Verstand verfliessen:", "tokens": ["Und", "dein", "Ver\u00b7stand", "ver\u00b7flies\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Gott sieht blo\u00df deinen Glauben an,", "tokens": ["Gott", "sieht", "blo\u00df", "dei\u00b7nen", "Glau\u00b7ben", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Fehlt dieser dir/ fehlst du der Bahn.", "tokens": ["Fehlt", "die\u00b7ser", "dir", "/", "fehlst", "du", "der", "Bahn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "PPER", "$(", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Der Glauben aber dehn Gott sieht/", "tokens": ["Der", "Glau\u00b7ben", "a\u00b7ber", "dehn", "Gott", "sieht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mu\u00df nichts/ als Christum wissen:", "tokens": ["Mu\u00df", "nichts", "/", "als", "Chris\u00b7tum", "wis\u00b7sen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "$(", "KOUS", "NE", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mu\u00df dich: drau\u00df ewig's Leben bl\u00fcht/", "tokens": ["Mu\u00df", "dich", ":", "drau\u00df", "e\u00b7wig's", "Le\u00b7ben", "bl\u00fcht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$.", "PAV", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In seine Wunden schl\u00fcssen:", "tokens": ["In", "sei\u00b7ne", "Wun\u00b7den", "schl\u00fcs\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Mu\u00df ihn und dich in eines ziehn/", "tokens": ["Mu\u00df", "ihn", "und", "dich", "in", "ei\u00b7nes", "ziehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "KON", "PRF", "APPR", "PIS", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Denn Gott nimbt sonst nichts an/ als ihn.", "tokens": ["Denn", "Gott", "nimbt", "sonst", "nichts", "an", "/", "als", "ihn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADV", "PIS", "PTKVZ", "$(", "KOUS", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Gott f\u00fcrchten/ dieses \u00fcbertriefft", "tokens": ["Gott", "f\u00fcrch\u00b7ten", "/", "die\u00b7ses", "\u00fc\u00b7bert\u00b7riefft"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "VVINF", "$(", "PDS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "All' andere Gesetze:", "tokens": ["All'", "an\u00b7de\u00b7re", "Ge\u00b7set\u00b7ze", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und Christum lieben: alle Schrifft/", "tokens": ["Und", "Chris\u00b7tum", "lie\u00b7ben", ":", "al\u00b7le", "Schrifft", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NE", "VVINF", "$.", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und aller Wei\u00dfheit Sch\u00e4tze.", "tokens": ["Und", "al\u00b7ler", "Wei\u00df\u00b7heit", "Sch\u00e4t\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Dem heiligen Geiste geben stat", "tokens": ["Dem", "hei\u00b7li\u00b7gen", "Geis\u00b7te", "ge\u00b7ben", "stat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVINF", "VVFIN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Der Menschen allerkl\u00fcgsten Rath.", "tokens": ["Der", "Men\u00b7schen", "al\u00b7ler\u00b7kl\u00fcgs\u00b7ten", "Rath", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Mein Pilgram/ eines das ist noth/", "tokens": ["Mein", "Pilg\u00b7ram", "/", "ei\u00b7nes", "das", "ist", "noth", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "ART", "PDS", "VAFIN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dasselbe heist: wol sterben:", "tokens": ["Das\u00b7sel\u00b7be", "heist", ":", "wol", "ster\u00b7ben", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$.", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Kanstu es: du siehst nicht den Tod/", "tokens": ["Kans\u00b7tu", "es", ":", "du", "siehst", "nicht", "den", "Tod", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$.", "PPER", "VVFIN", "PTKNEG", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wo nicht: du must verterben.", "tokens": ["Wo", "nicht", ":", "du", "must", "ver\u00b7ter\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$.", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wol sterben/ ist wol aufferstehn/", "tokens": ["Wol", "ster\u00b7ben", "/", "ist", "wol", "auf\u00b7fer\u00b7stehn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$(", "VAFIN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Drauff wart' ich/ du magst f\u00fcrder gehn.", "tokens": ["Drauff", "wart'", "ich", "/", "du", "magst", "f\u00fcr\u00b7der", "gehn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$(", "PPER", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}