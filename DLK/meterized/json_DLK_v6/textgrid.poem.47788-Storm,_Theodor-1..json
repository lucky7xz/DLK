{"textgrid.poem.47788": {"metadata": {"author": {"name": "Storm, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1853, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sie sa\u00dfen sich gen\u00fcber bang", "tokens": ["Sie", "sa\u00b7\u00dfen", "sich", "ge\u00b7n\u00fc\u00b7ber", "bang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und sahen sich an in Schmerzen;", "tokens": ["Und", "sa\u00b7hen", "sich", "an", "in", "Schmer\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "APPR", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Oh, l\u00e4gen sie in tiefster Gruft", "tokens": ["Oh", ",", "l\u00e4\u00b7gen", "sie", "in", "tiefs\u00b7ter", "Gruft"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und l\u00e4gen Herz an Herzen! \u2013", "tokens": ["Und", "l\u00e4\u00b7gen", "Herz", "an", "Her\u00b7zen", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJA", "NN", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Sie sprach: \u00bbDa\u00df wir beisammen sind,", "tokens": ["Sie", "sprach", ":", "\u00bb", "Da\u00df", "wir", "bei\u00b7sam\u00b7men", "sind", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "KOUS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Bruder, will nicht taugen!\u00ab", "tokens": ["Mein", "Bru\u00b7der", ",", "will", "nicht", "tau\u00b7gen", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "$,", "VMFIN", "PTKNEG", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Er sah ihr in die Augen tief:", "tokens": ["Er", "sah", "ihr", "in", "die", "Au\u00b7gen", "tief", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbo s\u00fc\u00dfe Schwesteraugen!\u00ab", "tokens": ["\u00bb", "o", "s\u00fc\u00b7\u00dfe", "Schwes\u00b7ter\u00b7au\u00b7gen", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Sie fa\u00dfte flehend seine Hand", "tokens": ["Sie", "fa\u00df\u00b7te", "fle\u00b7hend", "sei\u00b7ne", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und rief: \u00bbO denk der S\u00fcnde!\u00ab", "tokens": ["Und", "rief", ":", "\u00bb", "O", "denk", "der", "S\u00fcn\u00b7de", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "NE", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Er sprach: \u00bbO s\u00fc\u00dfes Schwesterblut,", "tokens": ["Er", "sprach", ":", "\u00bb", "O", "s\u00fc\u00b7\u00dfes", "Schwes\u00b7ter\u00b7blut", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was l\u00e4ufst du so geschwinde!\u00ab", "tokens": ["Was", "l\u00e4ufst", "du", "so", "ge\u00b7schwin\u00b7de", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ADJA", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Er zog die schmalen Fingerlein", "tokens": ["Er", "zog", "die", "schma\u00b7len", "Fin\u00b7ger\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An seinen Mund zur Stelle;", "tokens": ["An", "sei\u00b7nen", "Mund", "zur", "Stel\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie rief: \u00bbOh, hilf mir, Herre Christ,", "tokens": ["Sie", "rief", ":", "\u00bb", "Oh", ",", "hilf", "mir", ",", "Her\u00b7re", "Christ", ","], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "ITJ", "$,", "VVIMP", "PPER", "$,", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er zieht mich nach der H\u00f6lle!\u00ab", "tokens": ["Er", "zieht", "mich", "nach", "der", "H\u00f6l\u00b7le", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Der Bruder hielt ihr zu den Mund;", "tokens": ["Der", "Bru\u00b7der", "hielt", "ihr", "zu", "den", "Mund", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er rief nach seinen Knappen.", "tokens": ["Er", "rief", "nach", "sei\u00b7nen", "Knap\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nun r\u00fcsteten sie Reisezeug,", "tokens": ["Nun", "r\u00fcs\u00b7te\u00b7ten", "sie", "Rei\u00b7se\u00b7zeug", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun z\u00e4umten sie die Rappen.", "tokens": ["Nun", "z\u00e4um\u00b7ten", "sie", "die", "Rap\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Er sprach: \u00bbDa\u00df ich dein Bruder sei,", "tokens": ["Er", "sprach", ":", "\u00bb", "Da\u00df", "ich", "dein", "Bru\u00b7der", "sei", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht l\u00e4nger will ich's tragen;", "tokens": ["Nicht", "l\u00e4n\u00b7ger", "will", "ich's", "tra\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nicht l\u00e4nger will ich drum im Grab", "tokens": ["Nicht", "l\u00e4n\u00b7ger", "will", "ich", "drum", "im", "Grab"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "VMFIN", "PPER", "PAV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vater und Mutter verklagen.", "tokens": ["Va\u00b7ter", "und", "Mut\u00b7ter", "ver\u00b7kla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.7": {"line.1": {"text": "Zu l\u00f6sen vermag der Papst Urban,", "tokens": ["Zu", "l\u00f6\u00b7sen", "ver\u00b7mag", "der", "Papst", "Ur\u00b7ban", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVFIN", "ART", "NN", "NE", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er mag uns l\u00f6sen und binden!", "tokens": ["Er", "mag", "uns", "l\u00f6\u00b7sen", "und", "bin\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und s\u00e4\u00df er an Sankt Peters Hand,", "tokens": ["Und", "s\u00e4\u00df", "er", "an", "Sankt", "Pe\u00b7ters", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "VVFIN", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Brautring mu\u00df ich finden.\u00ab", "tokens": ["Den", "Brau\u00b7tring", "mu\u00df", "ich", "fin\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Er ritt dahin; die Tr\u00e4ne rann", "tokens": ["Er", "ritt", "da\u00b7hin", ";", "die", "Tr\u00e4\u00b7ne", "rann"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PAV", "$.", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von ihrem Angesichte;", "tokens": ["Von", "ih\u00b7rem", "An\u00b7ge\u00b7sich\u00b7te", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Stuhl, wo er gesessen, stand", "tokens": ["Der", "Stuhl", ",", "wo", "er", "ge\u00b7ses\u00b7sen", ",", "stand"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "VVPP", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im Abendsonnenlichte.", "tokens": ["Im", "A\u00b7bend\u00b7son\u00b7nen\u00b7lich\u00b7te", "."], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Sie stieg hinab durch Hof und Hall'", "tokens": ["Sie", "stieg", "hin\u00b7ab", "durch", "Hof", "und", "Hall'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu der Kapelle Stufen:", "tokens": ["Zu", "der", "Ka\u00b7pel\u00b7le", "Stu\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "---+-+-", "measure": "unknown.measure.di"}, "line.3": {"text": "\u00bbweh mir, ich h\u00f6r im Grabe tief", "tokens": ["\u00bb", "weh", "mir", ",", "ich", "h\u00f6r", "im", "Gra\u00b7be", "tief"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VVIMP", "PPER", "$,", "PPER", "VVFIN", "APPRART", "NN", "ADJD"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.4": {"text": "Vater und Mutter rufen!\u00ab", "tokens": ["Va\u00b7ter", "und", "Mut\u00b7ter", "ru\u00b7fen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "$.", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.10": {"line.1": {"text": "Sie stieg hinauf ins K\u00e4mmerlein;", "tokens": ["Sie", "stieg", "hin\u00b7auf", "ins", "K\u00e4m\u00b7mer\u00b7lein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das stand in D\u00e4mmernissen.", "tokens": ["Das", "stand", "in", "D\u00e4m\u00b7mer\u00b7nis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ach, n\u00e4chtens schlug die Nachtigall;", "tokens": ["Ach", ",", "n\u00e4ch\u00b7tens", "schlug", "die", "Nach\u00b7ti\u00b7gall", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da sa\u00df sie wach im Kissen.", "tokens": ["Da", "sa\u00df", "sie", "wach", "im", "Kis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Da fuhr ihr Herz dem Liebsten nach", "tokens": ["Da", "fuhr", "ihr", "Herz", "dem", "Liebs\u00b7ten", "nach"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ART", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "All\u00fcberall auf Erden;", "tokens": ["Al\u00b7l\u00fc\u00b7be\u00b7rall", "auf", "Er\u00b7den", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie streckte weit die Arme aus:", "tokens": ["Sie", "streck\u00b7te", "weit", "die", "Ar\u00b7me", "aus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbunselig mu\u00df ich werden!\u00ab", "tokens": ["\u00bb", "un\u00b7se\u00b7lig", "mu\u00df", "ich", "wer\u00b7den", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "VMFIN", "PPER", "VAINF", "$.", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}}}}