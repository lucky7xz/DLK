{"textgrid.poem.40004": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wie wunderbar, o Gott! sind Deine Wercke!", "genre": "verse", "period": "N.A.", "pub_year": 1713, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie wunderbar, o Gott! sind Deine Wercke!", "tokens": ["Wie", "wun\u00b7der\u00b7bar", ",", "o", "Gott", "!", "sind", "Dei\u00b7ne", "Wer\u00b7cke", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$,", "FM", "NN", "$.", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie unbegreiflich sind die Spuren Deiner St\u00e4rcke!", "tokens": ["Wie", "un\u00b7be\u00b7greif\u00b7lich", "sind", "die", "Spu\u00b7ren", "Dei\u00b7ner", "St\u00e4r\u00b7cke", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie gro\u00df ist alles das, so die Natur uns weis't!", "tokens": ["Wie", "gro\u00df", "ist", "al\u00b7les", "das", ",", "so", "die", "Na\u00b7tur", "uns", "weis't", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PIS", "PDS", "$,", "ADV", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie klein hingegen unser Geist!", "tokens": ["Wie", "klein", "hin\u00b7ge\u00b7gen", "un\u00b7ser", "Geist", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "So rief ich, als mein Freund, den die gelehrte Welt", "tokens": ["So", "rief", "ich", ",", "als", "mein", "Freund", ",", "den", "die", "ge\u00b7lehr\u00b7te", "Welt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPOSAT", "NN", "$,", "PRELS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Fast f\u00fcr ein Wunder h\u00e4lt,", "tokens": ["Fast", "f\u00fcr", "ein", "Wun\u00b7der", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mein Richey, der hieselbst mit solchem Ruhme lehret,", "tokens": ["Mein", "Ri\u00b7chey", ",", "der", "hie\u00b7selbst", "mit", "sol\u00b7chem", "Ruh\u00b7me", "leh\u00b7ret", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ADV", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mir etwas, so ich nie gesehn,", "tokens": ["Mir", "et\u00b7was", ",", "so", "ich", "nie", "ge\u00b7sehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "ADV", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und welches doch so rar, als sch\u00f6n,", "tokens": ["Und", "wel\u00b7ches", "doch", "so", "rar", ",", "als", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "ADV", "ADJD", "$,", "KOUS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "J\u00fcngst zugeschicket und verehret.", "tokens": ["J\u00fcngst", "zu\u00b7ge\u00b7schi\u00b7cket", "und", "ver\u00b7eh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ein angenehmes Fr\u00fchlings-Kind,", "tokens": ["Ein", "an\u00b7ge\u00b7neh\u00b7mes", "Fr\u00fch\u00b7lings\u00b7Kind", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das, ohne Mutter, war gebohren,", "tokens": ["Das", ",", "oh\u00b7ne", "Mut\u00b7ter", ",", "war", "ge\u00b7boh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "$,", "KOUI", "NN", "$,", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Zu einer Zeit, da alles noch gefroren,", "tokens": ["Zu", "ei\u00b7ner", "Zeit", ",", "da", "al\u00b7les", "noch", "ge\u00b7fro\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "KOUS", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Ein' Ambra-volle Hyacinth',", "tokens": ["Ein'", "Am\u00b7bra\u00b7vol\u00b7le", "Hya\u00b7cinth'", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Die unvergleichlich bl\u00fcht', auch unvergleichlich roch,", "tokens": ["Die", "un\u00b7ver\u00b7gleich\u00b7lich", "bl\u00fcht'", ",", "auch", "un\u00b7ver\u00b7gleich\u00b7lich", "roch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "$,", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und die, o Wunder! jedennoch", "tokens": ["Und", "die", ",", "o", "Wun\u00b7der", "!", "je\u00b7den\u00b7noch"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KON", "ART", "$,", "FM", "NN", "$.", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Die Erde nie in ihrem Schoo\u00df geheget,", "tokens": ["Die", "Er\u00b7de", "nie", "in", "ih\u00b7rem", "Schoo\u00df", "ge\u00b7he\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Noch sie, mit ihrem Nahrungs-Saft", "tokens": ["Noch", "sie", ",", "mit", "ih\u00b7rem", "Nah\u00b7rungs\u00b7Saft"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PPER", "$,", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Und der in ihr verborg'nen Kraft,", "tokens": ["Und", "der", "in", "ihr", "ver\u00b7bor\u00b7g'\u00b7nen", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "---+-+--+", "measure": "iambic.tri.chol"}, "line.16": {"text": "Ges\u00e4ugt, ern\u00e4hrt, verpfleget,", "tokens": ["Ge\u00b7s\u00e4ugt", ",", "er\u00b7n\u00e4hrt", ",", "ver\u00b7pfle\u00b7get", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["VVPP", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.17": {"text": "Sah ich vor meinen Augen stehn.", "tokens": ["Sah", "ich", "vor", "mei\u00b7nen", "Au\u00b7gen", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Die Zwiebel war, so wie die Bluhme, blo\u00df,", "tokens": ["Die", "Zwie\u00b7bel", "war", ",", "so", "wie", "die", "Bluh\u00b7me", ",", "blo\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "ADV", "KOKOM", "ART", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Ohn' Erd', in freyer Luft zu sehn.", "tokens": ["Ohn'", "Erd'", ",", "in", "frey\u00b7er", "Luft", "zu", "sehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Ein Glas, so nicht besonders gro\u00df,", "tokens": ["Ein", "Glas", ",", "so", "nicht", "be\u00b7son\u00b7ders", "gro\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Erf\u00fcllt mit klarer Feuchtigkeit,", "tokens": ["Er\u00b7f\u00fcllt", "mit", "kla\u00b7rer", "Feuch\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Lie\u00df mir, zu gleicher Zeit,", "tokens": ["Lie\u00df", "mir", ",", "zu", "glei\u00b7cher", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.23": {"text": "Die Wurtzeln, die so wei\u00df, wie Silber, schauen.", "tokens": ["Die", "Wurt\u00b7zeln", ",", "die", "so", "wei\u00df", ",", "wie", "Sil\u00b7ber", ",", "schau\u00b7en", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,", "PWAV", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "Sie sahen selbst fast wie ein Bluhmen-Straus,", "tokens": ["Sie", "sa\u00b7hen", "selbst", "fast", "wie", "ein", "Bluh\u00b7men\u00b7Straus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "In den so angenehm geschlung'nen Z\u00e4sern, aus.", "tokens": ["In", "den", "so", "an\u00b7ge\u00b7nehm", "ge\u00b7schlung'\u00b7nen", "Z\u00e4\u00b7sern", ",", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ADJD", "ADJA", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Kaum konnt' ich meinen Augen trauen.", "tokens": ["Kaum", "konnt'", "ich", "mei\u00b7nen", "Au\u00b7gen", "trau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Was die Natur uns bis daher versteckt,", "tokens": ["Was", "die", "Na\u00b7tur", "uns", "bis", "da\u00b7her", "ver\u00b7steckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "PPER", "ADV", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und was sie gleichsam recht mit Sorgen,", "tokens": ["Und", "was", "sie", "gleich\u00b7sam", "recht", "mit", "Sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADJD", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Im Schoo\u00df der Erden, uns verborgen.", "tokens": ["Im", "Schoo\u00df", "der", "Er\u00b7den", ",", "uns", "ver\u00b7bor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie sie die Wurtzeln zeugt, ern\u00e4hret, dehnt und streckt,", "tokens": ["Wie", "sie", "die", "Wurt\u00b7zeln", "zeugt", ",", "er\u00b7n\u00e4h\u00b7ret", ",", "dehnt", "und", "streckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wird unsern Augen nun entdeckt.", "tokens": ["Wird", "un\u00b7sern", "Au\u00b7gen", "nun", "ent\u00b7deckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie sehr bewundert' ich, da\u00df etwas wachsen k\u00f6nnte", "tokens": ["Wie", "sehr", "be\u00b7wun\u00b7dert'", "ich", ",", "da\u00df", "et\u00b7was", "wach\u00b7sen", "k\u00f6nn\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "$,", "KOUS", "PIS", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Gantz ausser seinem Elemente;", "tokens": ["Gantz", "aus\u00b7ser", "sei\u00b7nem", "E\u00b7le\u00b7men\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Ja was noch mehr, da\u00df menschlicher Verstand,", "tokens": ["Ja", "was", "noch", "mehr", ",", "da\u00df", "menschli\u00b7cher", "Ver\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "PWS", "ADV", "ADV", "$,", "KOUS", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.9": {"text": "In so viel tausend Jahren,", "tokens": ["In", "so", "viel", "tau\u00b7send", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Dergleichen niemahls noch erkannt,", "tokens": ["Derg\u00b7lei\u00b7chen", "nie\u00b7mahls", "noch", "er\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Und nichts davon erfahren,", "tokens": ["Und", "nichts", "da\u00b7von", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PAV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Da es jedoch so leicht, da\u00df jedermann,", "tokens": ["Da", "es", "je\u00b7doch", "so", "leicht", ",", "da\u00df", "je\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADJD", "$,", "KOUS", "PIS", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Der es nur einmahl sieht und h\u00f6rt, es machen kann!", "tokens": ["Der", "es", "nur", "ein\u00b7mahl", "sieht", "und", "h\u00f6rt", ",", "es", "ma\u00b7chen", "kann", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "VVFIN", "KON", "VVFIN", "$,", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Man setzet auf ein Glas,", "tokens": ["Man", "set\u00b7zet", "auf", "ein", "Glas", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Das voller Wasser ist,", "tokens": ["Das", "vol\u00b7ler", "Was\u00b7ser", "ist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Bluhmen-Zwiebel auf, so da\u00df sie kaum das Na\u00df,", "tokens": ["Die", "Bluh\u00b7men\u00b7Zwie\u00b7bel", "auf", ",", "so", "da\u00df", "sie", "kaum", "das", "Na\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "ADV", "KOUS", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit ihrem untern Theil, ber\u00fchret.", "tokens": ["Mit", "ih\u00b7rem", "un\u00b7tern", "Theil", ",", "be\u00b7r\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Das ist die gantze Kunst, worauf, in kurtzer Frist,", "tokens": ["Das", "ist", "die", "gant\u00b7ze", "Kunst", ",", "wo\u00b7rauf", ",", "in", "kurt\u00b7zer", "Frist", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,", "PWAV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das Glas voll Wurtzeln wird, der Stiel sich aufw\u00e4rts f\u00fchret;", "tokens": ["Das", "Glas", "voll", "Wurt\u00b7zeln", "wird", ",", "der", "Stiel", "sich", "auf\u00b7w\u00e4rts", "f\u00fch\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "VAFIN", "$,", "ART", "NN", "PRF", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und kommt sodann, in wenig Zeit,", "tokens": ["Und", "kommt", "so\u00b7dann", ",", "in", "we\u00b7nig", "Zeit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Bluhme zur Vollkommenheit.", "tokens": ["Die", "Bluh\u00b7me", "zur", "Voll\u00b7kom\u00b7men\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Derselben fehlet nichts an Farb', an Zierlichkeit,", "tokens": ["Der\u00b7sel\u00b7ben", "feh\u00b7let", "nichts", "an", "Fa\u00b7rb'", ",", "an", "Zier\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "APPR", "NN", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "An lieblichem Geruch, der kr\u00e4ftig, uns zu r\u00fchren.", "tokens": ["An", "lieb\u00b7li\u00b7chem", "Ge\u00b7ruch", ",", "der", "kr\u00e4f\u00b7tig", ",", "uns", "zu", "r\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "PRELS", "ADJD", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Mein G\u00e4rtner hat, hiedurch bewogen,", "tokens": ["Mein", "G\u00e4rt\u00b7ner", "hat", ",", "hie\u00b7durch", "be\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "$,", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Auf gleiche Weise, Lilien,", "tokens": ["Auf", "glei\u00b7che", "Wei\u00b7se", ",", "Li\u00b7li\u00b7en", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Narcissen, Kaiser-Kron- und Tulpen aufgezogen.", "tokens": ["Nar\u00b7cis\u00b7sen", ",", "Kai\u00b7ser\u00b7Kron", "und", "Tul\u00b7pen", "auf\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "TRUNC", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ich, um dieses Werck noch weiter zu probiren,", "tokens": ["Und", "ich", ",", "um", "die\u00b7ses", "Werck", "noch", "wei\u00b7ter", "zu", "pro\u00b7bi\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "KOUI", "PDAT", "NN", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hab' einst ein d\u00fcnnes Bley, an manchem Ort,", "tokens": ["Hab'", "einst", "ein", "d\u00fcn\u00b7nes", "Bley", ",", "an", "man\u00b7chem", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Mit kleinen L\u00f6cherchen durchbohrt,", "tokens": ["Mit", "klei\u00b7nen", "L\u00f6\u00b7cher\u00b7chen", "durch\u00b7bohrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und mit demselbigen ein solches Glas bedeckt,", "tokens": ["Und", "mit", "dem\u00b7sel\u00b7bi\u00b7gen", "ein", "sol\u00b7ches", "Glas", "be\u00b7deckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDAT", "ART", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dann Haber-K\u00f6rnerchen genommen,", "tokens": ["Dann", "Ha\u00b7ber\u00b7K\u00f6r\u00b7ner\u00b7chen", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Und in die L\u00f6cher eingesteckt;", "tokens": ["Und", "in", "die", "L\u00f6\u00b7cher", "ein\u00b7ge\u00b7steckt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wodurch ich denn, nach nicht gar langer Zeit,", "tokens": ["Wo\u00b7durch", "ich", "denn", ",", "nach", "nicht", "gar", "lan\u00b7ger", "Zeit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "$,", "APPR", "PTKNEG", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Auch reifen Haber \u00fcberkommen.", "tokens": ["Auch", "rei\u00b7fen", "Ha\u00b7ber", "\u00fc\u00b7ber\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Ja endlich hab' ich gar, hiedurch bewogen,", "tokens": ["Ja", "end\u00b7lich", "hab'", "ich", "gar", ",", "hie\u00b7durch", "be\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "VAFIN", "PPER", "ADV", "$,", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Noch weiter fortzugehn,", "tokens": ["Noch", "wei\u00b7ter", "fort\u00b7zu\u00b7gehn", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "Auf eben diese Art, schon einen Baum gezogen.", "tokens": ["Auf", "e\u00b7ben", "die\u00b7se", "Art", ",", "schon", "ei\u00b7nen", "Baum", "ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PDAT", "NN", "$,", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ich seh bereits, mit Bl\u00e4ttern und mit Zweigen,", "tokens": ["Ich", "seh", "be\u00b7reits", ",", "mit", "Bl\u00e4t\u00b7tern", "und", "mit", "Zwei\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Ein K\u00e4sten-B\u00e4umchen vor mir stehn,", "tokens": ["Ein", "K\u00e4s\u00b7ten\u00b7B\u00e4um\u00b7chen", "vor", "mir", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Und aus dem Glas, aus blossem Wasser, steigen,", "tokens": ["Und", "aus", "dem", "Glas", ",", "aus", "blos\u00b7sem", "Was\u00b7ser", ",", "stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "APPR", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Mit einer sch\u00f6nen Bl\u00e4tter-Kronen,", "tokens": ["Mit", "ei\u00b7ner", "sch\u00f6\u00b7nen", "Bl\u00e4t\u00b7ter\u00b7Kro\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Ja in dem Glase sich zugleich die Wurtzel zeigen.", "tokens": ["Ja", "in", "dem", "Gla\u00b7se", "sich", "zu\u00b7gleich", "die", "Wurt\u00b7zel", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "APPR", "ART", "NN", "PRF", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Noch mehr, es bl\u00fch'n und reifen albereit,", "tokens": ["Noch", "mehr", ",", "es", "bl\u00fch'n", "und", "rei\u00b7fen", "al\u00b7be\u00b7reit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PPER", "VVFIN", "KON", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Auf gleiche Weis' und Art gezog'ne Erbs- und Bohnen,", "tokens": ["Auf", "glei\u00b7che", "Weis'", "und", "Art", "ge\u00b7zo\u00b7g'\u00b7ne", "Erbs", "und", "Boh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "ADJA", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "In zierlicher Vollkommenheit.", "tokens": ["In", "zier\u00b7li\u00b7cher", "Voll\u00b7kom\u00b7men\u00b7heit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Mich deucht, du sprichts bey dieser Seltsamkeit:", "tokens": ["Mich", "deucht", ",", "du", "sprichts", "bey", "die\u00b7ser", "Selt\u00b7sam\u00b7keit", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wirckt denn die Erde nichts bey Bluhmen und bey Fr\u00fcchten,", "tokens": ["Wirckt", "denn", "die", "Er\u00b7de", "nichts", "bey", "Bluh\u00b7men", "und", "bey", "Fr\u00fcch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "PIS", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und kann das Wasser es allein verrichten;", "tokens": ["Und", "kann", "das", "Was\u00b7ser", "es", "al\u00b7lein", "ver\u00b7rich\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So hat man ja bisher", "tokens": ["So", "hat", "man", "ja", "bis\u00b7her"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Der Erde gr\u00f6sser' Ehr'", "tokens": ["Der", "Er\u00b7de", "gr\u00f6s\u00b7ser'", "Ehr'"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Erwiesen, als wie ihr mit Recht geb\u00fchret,", "tokens": ["Er\u00b7wie\u00b7sen", ",", "als", "wie", "ihr", "mit", "Recht", "ge\u00b7b\u00fch\u00b7ret", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "KOKOM", "PPER", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Indem sie alles das verlieret,", "tokens": ["In\u00b7dem", "sie", "al\u00b7les", "das", "ver\u00b7lie\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was man, aus Unverstand getrieben,", "tokens": ["Was", "man", ",", "aus", "Un\u00b7ver\u00b7stand", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Bisher ihr zugeschrieben.", "tokens": ["Bis\u00b7her", "ihr", "zu\u00b7ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Allein,", "tokens": ["Al\u00b7lein", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Geliebter Mensch, halt ein,", "tokens": ["Ge\u00b7lieb\u00b7ter", "Mensch", ",", "halt", "ein", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und \u00fcbereile dich in deinem Urtheil nicht!", "tokens": ["Und", "\u00fc\u00b7be\u00b7rei\u00b7le", "dich", "in", "dei\u00b7nem", "Ur\u00b7theil", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vielmehr nimm diesen Unterricht:", "tokens": ["Viel\u00b7mehr", "nimm", "die\u00b7sen", "Un\u00b7ter\u00b7richt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Die Erde, die von dem, dem ewig Preis geb\u00fchret,", "tokens": ["Die", "Er\u00b7de", ",", "die", "von", "dem", ",", "dem", "e\u00b7wig", "Preis", "ge\u00b7b\u00fch\u00b7ret", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "ART", "$,", "PRELS", "ADJD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Recht wunderbar erschaffen und formiret,", "tokens": ["Recht", "wun\u00b7der\u00b7bar", "er\u00b7schaf\u00b7fen", "und", "for\u00b7mi\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVPP", "KON", "VVFIN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Verliert, bey der Entdeckung, nichts. Sie bleibet", "tokens": ["Ver\u00b7liert", ",", "bey", "der", "Ent\u00b7de\u00b7ckung", ",", "nichts", ".", "Sie", "blei\u00b7bet"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["VVPP", "$,", "APPR", "ART", "NN", "$,", "PIS", "$.", "PPER", "VVFIN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Ein Wunder-Werck des H\u00f6chsten, wenn die Kraft", "tokens": ["Ein", "Wun\u00b7der\u00b7\u00b7Werck", "des", "H\u00f6chs\u00b7ten", ",", "wenn", "die", "Kraft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Auch gleich nicht anders w\u00e4r', als wie man's itzt beschreibet,", "tokens": ["Auch", "gleich", "nicht", "an\u00b7ders", "w\u00e4r'", ",", "als", "wie", "man's", "itzt", "be\u00b7schrei\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "ADV", "VAFIN", "$,", "KOUS", "KOKOM", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das sich jedoch nicht so verh\u00e4lt,", "tokens": ["Das", "sich", "je\u00b7doch", "nicht", "so", "ver\u00b7h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "ADV", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Wie einem jeglichen es in die Augen f\u00e4llt.", "tokens": ["Wie", "ei\u00b7nem", "jeg\u00b7li\u00b7chen", "es", "in", "die", "Au\u00b7gen", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "PIAT", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Denn wenn derselben Eigenschaft", "tokens": ["Denn", "wenn", "der\u00b7sel\u00b7ben", "Ei\u00b7gen\u00b7schaft"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "KOUS", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Nur blo\u00df darin, da\u00df sie aus Theilchen, die so klein,", "tokens": ["Nur", "blo\u00df", "da\u00b7rin", ",", "da\u00df", "sie", "aus", "Theil\u00b7chen", ",", "die", "so", "klein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PAV", "$,", "KOUS", "PPER", "APPR", "NN", "$,", "PRELS", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Bestehen sollt', allein best\u00fcnde;", "tokens": ["Be\u00b7ste\u00b7hen", "sollt'", ",", "al\u00b7lein", "be\u00b7st\u00fcn\u00b7de", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VMFIN", "$,", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "So ist es doch gewi\u00df, wenn man es recht ergr\u00fcndet,", "tokens": ["So", "ist", "es", "doch", "ge\u00b7wi\u00df", ",", "wenn", "man", "es", "recht", "er\u00b7gr\u00fcn\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "$,", "KOUS", "PIS", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Da\u00df man auch darin blo\u00df allein", "tokens": ["Da\u00df", "man", "auch", "da\u00b7rin", "blo\u00df", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ADV", "PAV", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Was unbegreifliches und n\u00fctzlichs finde.", "tokens": ["Was", "un\u00b7be\u00b7greif\u00b7li\u00b7ches", "und", "n\u00fctz\u00b7lichs", "fin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "KON", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Denn da\u00df solch eine Meng' von Theilchen in der Erde", "tokens": ["Denn", "da\u00df", "solch", "ei\u00b7ne", "Meng'", "von", "Theil\u00b7chen", "in", "der", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PIAT", "ART", "NN", "APPR", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Zu einem grossen C\u00f6rper werde,", "tokens": ["Zu", "ei\u00b7nem", "gros\u00b7sen", "C\u00f6r\u00b7per", "wer\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Und sich zwar wohl, jedoch nicht gantz, verbindet,", "tokens": ["Und", "sich", "zwar", "wohl", ",", "je\u00b7doch", "nicht", "gantz", ",", "ver\u00b7bin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PRF", "ADV", "ADV", "$,", "ADV", "PTKNEG", "ADV", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Wodurch denn Platz entsteht, da\u00df sich die Feuchtigkeiten", "tokens": ["Wo\u00b7durch", "denn", "Platz", "ent\u00b7steht", ",", "da\u00df", "sich", "die", "Feuch\u00b7tig\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "NN", "VVFIN", "$,", "KOUS", "PRF", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Darin versammlen, halten, sencken,", "tokens": ["Da\u00b7rin", "ver\u00b7samm\u00b7len", ",", "hal\u00b7ten", ",", "sen\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PAV", "VVINF", "$,", "VVFIN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Mit Maass', ohn' Ueberflu\u00df, die Wurtzeln tr\u00e4ncken,", "tokens": ["Mit", "Maass'", ",", "ohn'", "Ue\u00b7berf\u00b7lu\u00df", ",", "die", "Wurt\u00b7zeln", "tr\u00e4n\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "NN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Die eben dadurch auch, sich auszubreiten,", "tokens": ["Die", "e\u00b7ben", "da\u00b7durch", "auch", ",", "sich", "aus\u00b7zu\u00b7brei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADV", "PAV", "ADV", "$,", "PRF", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Gelegenheit und Platz gewinnen;", "tokens": ["Ge\u00b7le\u00b7gen\u00b7heit", "und", "Platz", "ge\u00b7win\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Ist ja wohl recht Bewunderns-werth.", "tokens": ["Ist", "ja", "wohl", "recht", "Be\u00b7wun\u00b7derns\u00b7werth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Wer aber kann nur eine Art,", "tokens": ["Wer", "a\u00b7ber", "kann", "nur", "ei\u00b7ne", "Art", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VMFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Die Pflantzen, die so klein, so zart,", "tokens": ["Die", "Pflant\u00b7zen", ",", "die", "so", "klein", ",", "so", "zart", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ADJD", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Gerade zu erhalten, wohl ersinnen,", "tokens": ["Ge\u00b7ra\u00b7de", "zu", "er\u00b7hal\u00b7ten", ",", "wohl", "er\u00b7sin\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "$,", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Und, ohne sie zu dr\u00fccken, zu verletzen,", "tokens": ["Und", ",", "oh\u00b7ne", "sie", "zu", "dr\u00fc\u00b7cken", ",", "zu", "ver\u00b7let\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "KOUI", "PPER", "PTKZU", "VVINF", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Dieselbigen so fest zu setzen,", "tokens": ["Die\u00b7sel\u00b7bi\u00b7gen", "so", "fest", "zu", "set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Da\u00df sie so gar vor Sturm und Wind", "tokens": ["Da\u00df", "sie", "so", "gar", "vor", "Sturm", "und", "Wind"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Genug gesichert sind?", "tokens": ["Ge\u00b7nug", "ge\u00b7si\u00b7chert", "sind", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.30": {"text": "Die\u00df alles scheinet uns zwar, leider! nur gemein,", "tokens": ["Die\u00df", "al\u00b7les", "schei\u00b7net", "uns", "zwar", ",", "lei\u00b7der", "!", "nur", "ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "PPER", "ADV", "$,", "ADV", "$.", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Und weder Weisheit, Macht, noch grosse Kunst zu seyn;", "tokens": ["Und", "we\u00b7der", "Weis\u00b7heit", ",", "Macht", ",", "noch", "gros\u00b7se", "Kunst", "zu", "seyn", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KON", "NN", "$,", "NN", "$,", "ADV", "ADJA", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Allein das eben ist die Unart uns'rer Sinnen,", "tokens": ["Al\u00b7lein", "das", "e\u00b7ben", "ist", "die", "Un\u00b7art", "un\u00b7s'\u00b7rer", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADV", "VAFIN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.33": {"text": "Da\u00df alles, was wir t\u00e4glich sehn,", "tokens": ["Da\u00df", "al\u00b7les", ",", "was", "wir", "t\u00e4g\u00b7lich", "sehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "PRELS", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Von aussen kaum, viel weniger von innen,", "tokens": ["Von", "aus\u00b7sen", "kaum", ",", "viel", "we\u00b7ni\u00b7ger", "von", "in\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ADV", "$,", "ADV", "ADV", "APPR", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.35": {"text": "Von uns betrachtet wird. Die Ursach zu verstehn,", "tokens": ["Von", "uns", "be\u00b7trach\u00b7tet", "wird", ".", "Die", "Ur\u00b7sach", "zu", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "VAFIN", "$.", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Wodurch, wozu und wie die Dinge hie geschehn,", "tokens": ["Wo\u00b7durch", ",", "wo\u00b7zu", "und", "wie", "die", "Din\u00b7ge", "hie", "ge\u00b7schehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PWAV", "KON", "PWAV", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Ist ja das eintzige, so uns vom Vieh", "tokens": ["Ist", "ja", "das", "eint\u00b7zi\u00b7ge", ",", "so", "uns", "vom", "Vieh"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "$,", "ADV", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.38": {"text": "Allein vermag zu unterscheiden;", "tokens": ["Al\u00b7lein", "ver\u00b7mag", "zu", "un\u00b7ter\u00b7schei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Doch nimmt man sich damit nicht die geringste M\u00fch.", "tokens": ["Doch", "nimmt", "man", "sich", "da\u00b7mit", "nicht", "die", "ge\u00b7rings\u00b7te", "M\u00fch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PRF", "PAV", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Die milde Mutter siehet man,", "tokens": ["Die", "mil\u00b7de", "Mut\u00b7ter", "sie\u00b7het", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als einen schwartz- und groben Klumpen, an.", "tokens": ["Als", "ei\u00b7nen", "schwartz", "und", "gro\u00b7ben", "Klum\u00b7pen", ",", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "ART", "TRUNC", "KON", "ADJA", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Je mehr ein Werck, das grossen Nutzen bringet,", "tokens": ["Je", "mehr", "ein", "Werck", ",", "das", "gros\u00b7sen", "Nut\u00b7zen", "brin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$,", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Uns etwas eintzelnes und einfachs weiset;", "tokens": ["Uns", "et\u00b7was", "eint\u00b7zel\u00b7nes", "und", "ein\u00b7fachs", "wei\u00b7set", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "ADJA", "KON", "PIS", "VVFIN", "$."], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Je mehr dem, der's gemacht, draus Ehr' und Lob entspringet,", "tokens": ["Je", "mehr", "dem", ",", "der's", "ge\u00b7macht", ",", "draus", "Ehr'", "und", "Lob", "ent\u00b7sprin\u00b7get", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "$,", "PRELS", "VVPP", "$,", "PAV", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Je mehr es seinen Meister preiset.", "tokens": ["Je", "mehr", "es", "sei\u00b7nen", "Meis\u00b7ter", "prei\u00b7set", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Denn da\u00df das Feuer hei\u00df und leicht,", "tokens": ["Denn", "da\u00df", "das", "Feu\u00b7er", "hei\u00df", "und", "leicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das Wasser fl\u00fc\u00dfig, schwer und feucht,", "tokens": ["Das", "Was\u00b7ser", "fl\u00fc\u00b7\u00dfig", ",", "schwer", "und", "feucht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die Erde fest, und doch nicht allzufest,", "tokens": ["Die", "Er\u00b7de", "fest", ",", "und", "doch", "nicht", "all\u00b7zu\u00b7fest", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "KON", "ADV", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Durchdringlich, k\u00f6rnig ist, und sich handthieren l\u00e4sst;", "tokens": ["Durch\u00b7dring\u00b7lich", ",", "k\u00f6r\u00b7nig", "ist", ",", "und", "sich", "handt\u00b7hie\u00b7ren", "l\u00e4sst", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "VAFIN", "$,", "KON", "PRF", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Sind Eigenschaften, die allein", "tokens": ["Sind", "Ei\u00b7gen\u00b7schaf\u00b7ten", ",", "die", "al\u00b7lein"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VAFIN", "NN", "$,", "PRELS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Von ", "tokens": ["Von"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.11": {"text": "Sind Wunder, welche wir bewundern sollen,", "tokens": ["Sind", "Wun\u00b7der", ",", "wel\u00b7che", "wir", "be\u00b7wun\u00b7dern", "sol\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "PRELS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Wofern wir Menschen heissen wollen.", "tokens": ["Wo\u00b7fern", "wir", "Men\u00b7schen", "heis\u00b7sen", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Ach ", "tokens": ["Ach"], "token_info": ["word"], "pos": ["ITJ"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Aus welchem alles Gute quillt,", "tokens": ["Aus", "wel\u00b7chem", "al\u00b7les", "Gu\u00b7te", "quillt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ach la\u00df uns doch, durch Deinen Geist erf\u00fcllt,", "tokens": ["Ach", "la\u00df", "uns", "doch", ",", "durch", "Dei\u00b7nen", "Geist", "er\u00b7f\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVIMP", "PPER", "ADV", "$,", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Von der Gewohnheit-Pest genesen!", "tokens": ["Von", "der", "Ge\u00b7wohn\u00b7heit\u00b7Pest", "ge\u00b7ne\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Damit von uns, zu aller Zeit,", "tokens": ["Da\u00b7mit", "von", "uns", ",", "zu", "al\u00b7ler", "Zeit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "APPR", "PPER", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So wohl des Wassers Fruchtbarkeit,", "tokens": ["So", "wohl", "des", "Was\u00b7sers", "Frucht\u00b7bar\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Als auch die k\u00fcnstliche Beschaffenheit", "tokens": ["Als", "auch", "die", "k\u00fcnst\u00b7li\u00b7che", "Be\u00b7schaf\u00b7fen\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Der wunderbar-formirten Erde,", "tokens": ["Der", "wun\u00b7der\u00b7ba\u00b7rfor\u00b7mir\u00b7ten", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.9": {"text": "Mit Ehrfurcht, Ernst und Lust, bewundert werde!", "tokens": ["Mit", "Ehr\u00b7furcht", ",", "Ernst", "und", "Lust", ",", "be\u00b7wun\u00b7dert", "wer\u00b7de", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NE", "KON", "NN", "$,", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}