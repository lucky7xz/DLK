{"dta.poem.23478": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "N.A.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1619", "urn": "urn:nbn:de:kobv:b4-20627-4", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "O Gro\u00dfer Printz/ in dessen schutz", "tokens": ["O", "Gro\u00b7\u00dfer", "Printz", "/", "in", "des\u00b7sen", "schutz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "$(", "APPR", "PRELAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sich alle Tugenten ergeben/", "tokens": ["Sich", "al\u00b7le", "Tu\u00b7gen\u00b7ten", "er\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das Sie der argen welt zu trutz", "tokens": ["Das", "Sie", "der", "ar\u00b7gen", "welt", "zu", "trutz"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "ART", "ADJA", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "M\u00f6gen auf erden sicher leben;", "tokens": ["M\u00f6\u00b7gen", "auf", "er\u00b7den", "si\u00b7cher", "le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "ADJD", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Verschm\u00e4het dises B\u00fcchlin nicht", "tokens": ["Ver\u00b7schm\u00e4\u00b7het", "di\u00b7ses", "B\u00fcch\u00b7lin", "nicht"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PDAT", "NN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So Euch auf der Musen begehren", "tokens": ["So", "Euch", "auf", "der", "Mu\u00b7sen", "be\u00b7geh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "APPR", "ART", "NN", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.7": {"text": "Ich dem\u00fctiglich thu verehren.", "tokens": ["Ich", "de\u00b7m\u00fc\u00b7tig\u00b7lich", "thu", "ver\u00b7eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVFIN", "VVFIN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Dan als ich newlich nachts allein", "tokens": ["Dan", "als", "ich", "new\u00b7lich", "nachts", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf dem feld hin vnd her spatzierte", "tokens": ["Auf", "dem", "feld", "hin", "vnd", "her", "spat\u00b7zier\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PTKVZ", "KON", "ADV", "VVFIN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Wahin Ph", "tokens": ["Wa\u00b7hin", "Ph"], "token_info": ["word", "word"], "pos": ["ADV", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Meine vnachtsame trit f\u00fchrte/", "tokens": ["Mei\u00b7ne", "vnacht\u00b7sa\u00b7me", "trit", "f\u00fchr\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Vnd verdrossen bey mir gedacht/", "tokens": ["Vnd", "ver\u00b7dros\u00b7sen", "bey", "mir", "ge\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "VVPP", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Wie \u00fcbel ich die zeit zubracht/", "tokens": ["Wie", "\u00fc\u00b7bel", "ich", "die", "zeit", "zu\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "In welcher mit der Musen lehren", "tokens": ["In", "wel\u00b7cher", "mit", "der", "Mu\u00b7sen", "leh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ich mich selbs thet vmbsunst beth\u00f6ren:", "tokens": ["Ich", "mich", "selbs", "thet", "vmbsunst", "be\u00b7th\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "ADV", "VVFIN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Da fand ich mich an einem Ort", "tokens": ["Da", "fand", "ich", "mich", "an", "ei\u00b7nem", "Ort"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bald von Jhnen allen vmbgeben/", "tokens": ["Bald", "von", "Jh\u00b7nen", "al\u00b7len", "vmb\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "PIS", "VVPP", "$("], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Vnd h\u00f6rt Sie durch manch s\u00fc\u00dfes wort", "tokens": ["Vnd", "h\u00f6rt", "Sie", "durch", "manch", "s\u00fc\u00b7\u00dfes", "wort"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Meinem verdru\u00df gern widerstreben:", "tokens": ["Mei\u00b7nem", "ver\u00b7dru\u00df", "gern", "wi\u00b7der\u00b7stre\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Insonderheit kam auch herf\u00fcr", "tokens": ["In\u00b7son\u00b7der\u00b7heit", "kam", "auch", "her\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Jhr F\u00fchrer Apollo/ der mir", "tokens": ["Ihr", "F\u00fch\u00b7rer", "A\u00b7pol\u00b7lo", "/", "der", "mir"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "NE", "$(", "PRELS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Gleich f\u00fcr Sie all auf meine klagen", "tokens": ["Gleich", "f\u00fcr", "Sie", "all", "auf", "mei\u00b7ne", "kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPER", "PIAT", "APPR", "PPOSAT", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Jhre meinung selbs f\u00fcrgetragen:", "tokens": ["Ih\u00b7re", "mei\u00b7nung", "selbs", "f\u00fcr\u00b7ge\u00b7tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Filodor (sprach Er) la\u00df numehr", "tokens": ["Fi\u00b7lo\u00b7dor", "(", "sprach", "Er", ")", "la\u00df", "nu\u00b7mehr"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NE", "$(", "VVFIN", "PPER", "$(", "VVIMP", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "All forcht/ sorgen vnd trawren fahren/", "tokens": ["All", "forcht", "/", "sor\u00b7gen", "vnd", "traw\u00b7ren", "fah\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$(", "NN", "KON", "VVINF", "VVINF", "$("], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Dan ein F\u00fcrst/ aller F\u00fcrsten ehr/", "tokens": ["Dan", "ein", "F\u00fcrst", "/", "al\u00b7ler", "F\u00fcrs\u00b7ten", "ehr", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$(", "PIAT", "NN", "NN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Vnd ist sein Nam (der wie sein gunst/", "tokens": ["Vnd", "ist", "sein", "Nam", "(", "der", "wie", "sein", "gunst", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "$(", "ART", "KOKOM", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein getrewer schirm vnsrer Kunst)", "tokens": ["Ein", "ge\u00b7tre\u00b7wer", "schirm", "vns\u00b7rer", "Kunst", ")"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJD", "ADJA", "NN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Georg-Friderich Marggraf zu Baden/", "tokens": ["Ge\u00b7or\u00b7gFri\u00b7de\u00b7rich", "Marg\u00b7graf", "zu", "Ba\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NN", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Bey welchem Wir vnd du in gnaden.", "tokens": ["Bey", "wel\u00b7chem", "Wir", "vnd", "du", "in", "gna\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "KON", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Jhm opfer du auf dein gesang/", "tokens": ["Jhm", "op\u00b7fer", "du", "auf", "dein", "ge\u00b7sang", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "PPER", "APPR", "PPOSAT", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd schew dich nicht vor seinen wafen/", "tokens": ["Vnd", "schew", "dich", "nicht", "vor", "sei\u00b7nen", "wa\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ab welchen seinen Feinden bang/", "tokens": ["Ab", "wel\u00b7chen", "sei\u00b7nen", "Fein\u00b7den", "bang", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "PPOSAT", "NN", "ADJD", "$("], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.4": {"text": "Welche der H\u00f6chst durch Jhn will strafen:", "tokens": ["Wel\u00b7che", "der", "H\u00f6chst", "durch", "Jhn", "will", "stra\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "APPR", "PPER", "VMFIN", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Dan die gro\u00dfe Helden allzeit", "tokens": ["Dan", "die", "gro\u00b7\u00dfe", "Hel\u00b7den", "all\u00b7zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "ADV"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Haben vor/ in vnd nach dem streit", "tokens": ["Ha\u00b7ben", "vor", "/", "in", "vnd", "nach", "dem", "streit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "$(", "APPR", "KON", "APPR", "ART", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Vns geliebet/ Ja vns geehret/", "tokens": ["Vns", "ge\u00b7lie\u00b7bet", "/", "Ja", "vns", "ge\u00b7eh\u00b7ret", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "$(", "PTKANT", "PPER", "VVPP", "$("], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Vnd Jhrer gegenwart gewehret.", "tokens": ["Vnd", "Ih\u00b7rer", "ge\u00b7gen\u00b7wart", "ge\u00b7weh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Auch ist Jhr lob noch billich kund/", "tokens": ["Auch", "ist", "Ihr", "lob", "noch", "bil\u00b7lich", "kund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ADV", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd kan ewiglich nicht vergehen/", "tokens": ["Vnd", "kan", "e\u00b7wig\u00b7lich", "nicht", "ver\u00b7ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "PTKNEG", "VVINF", "$("], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Welches eines Poeten mund", "tokens": ["Wel\u00b7ches", "ei\u00b7nes", "Po\u00b7et\u00b7en", "mund"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Der gantzen welt gab zuverstehen;", "tokens": ["Der", "gant\u00b7zen", "welt", "gab", "zu\u00b7ver\u00b7ste\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Darumb gib Jhm auch ehr vnd prei\u00df/", "tokens": ["Da\u00b7rumb", "gib", "Jhm", "auch", "ehr", "vnd", "prei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVIMP", "PPER", "ADV", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dan ja der menschen h\u00f6chster flei\u00df", "tokens": ["Dan", "ja", "der", "men\u00b7schen", "h\u00f6chs\u00b7ter", "flei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Kan den G\u00f6ttern mehr nicht erweisen", "tokens": ["Kan", "den", "G\u00f6t\u00b7tern", "mehr", "nicht", "er\u00b7wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "NN", "ADV", "PTKNEG", "VVINF"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Dan Sie loben/ ehren vnd preisen.", "tokens": ["Dan", "Sie", "lo\u00b7ben", "/", "eh\u00b7ren", "vnd", "prei\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "$(", "VVINF", "KON", "VVFIN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Als Jupiter durch seine strahl", "tokens": ["Als", "Ju\u00b7pi\u00b7ter", "durch", "sei\u00b7ne", "strahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Risen jhr leben verk\u00fcrtzet/", "tokens": ["Den", "Ri\u00b7sen", "jhr", "le\u00b7ben", "ver\u00b7k\u00fcrt\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie \u00fcber vnd \u00fcber gest\u00fcrtzet/", "tokens": ["Sie", "\u00fc\u00b7ber", "vnd", "\u00fc\u00b7ber", "ge\u00b7st\u00fcrt\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "KON", "APPR", "VVPP", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Begehrte Er (sigreich) mehr nicht/", "tokens": ["Be\u00b7gehr\u00b7te", "Er", "(", "sig\u00b7reich", ")", "mehr", "nicht", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$(", "ADJD", "$(", "ADV", "PTKNEG", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dan das wir ein sch\u00f6nes gedicht", "tokens": ["Dan", "das", "wir", "ein", "sch\u00f6\u00b7nes", "ge\u00b7dicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "PPER", "ART", "ADJA", "NN"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Vor seinen Ohren wol erklangen/", "tokens": ["Vor", "sei\u00b7nen", "Oh\u00b7ren", "wol", "er\u00b7klan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Vnd sein lob mit seinem sig sangen.", "tokens": ["Vnd", "sein", "lob", "mit", "sei\u00b7nem", "sig", "san\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "PPOSAT", "ADJD", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Wolan dan/ Castalischer Chor", "tokens": ["Wo\u00b7lan", "dan", "/", "Cas\u00b7ta\u00b7li\u00b7scher", "Chor"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADV", "ADV", "$(", "ADJA", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Lasst vns auch disen F\u00fcrsten ehren/", "tokens": ["Lasst", "vns", "auch", "di\u00b7sen", "F\u00fcrs\u00b7ten", "eh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PDAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd du sing mit Vns/ Filodor/", "tokens": ["Vnd", "du", "sing", "mit", "Vns", "/", "Fi\u00b7lo\u00b7dor", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPER", "$(", "NE", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Als wir deinen mund werden lehren:", "tokens": ["Als", "wir", "dei\u00b7nen", "mund", "wer\u00b7den", "leh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Vnd weil Er ja vnser Patron/", "tokens": ["Vnd", "weil", "Er", "ja", "vn\u00b7ser", "Pat\u00b7ron", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PPOSAT", "NN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "So lasst vns flechten eine Cron/", "tokens": ["So", "lasst", "vns", "flech\u00b7ten", "ei\u00b7ne", "Cron", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die du Jhm deem\u00fchtig solt bringen.", "tokens": ["Die", "du", "Jhm", "dee\u00b7m\u00fch\u00b7tig", "solt", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "ADJD", "VMFIN", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Fieng demnach also zusingen:", "tokens": ["Fi\u00b7eng", "dem\u00b7nach", "al\u00b7so", "zu\u00b7sin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PAV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}