{"textgrid.poem.34638": {"metadata": {"author": {"name": "Neukirch, Benjamin", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der geist der poesie hat manches schon erdacht/", "genre": "verse", "period": "N.A.", "pub_year": 1697, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der geist der poesie hat manches schon erdacht/", "tokens": ["Der", "geist", "der", "po\u00b7e\u00b7sie", "hat", "man\u00b7ches", "schon", "er\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "PIS", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn sie der todten grab mit farben angestrichen/", "tokens": ["Wenn", "sie", "der", "tod\u00b7ten", "grab", "mit", "far\u00b7ben", "an\u00b7ge\u00b7stri\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und bald aus ihrem thun granaten-frucht gemacht/", "tokens": ["Und", "bald", "aus", "ih\u00b7rem", "thun", "gra\u00b7na\u00b7ten\u00b7frucht", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "VVFIN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bald wieder ihren ruhm mit lorbeern hat verglichen;", "tokens": ["Bald", "wie\u00b7der", "ih\u00b7ren", "ruhm", "mit", "lor\u00b7beern", "hat", "ver\u00b7gli\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "APPR", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Heut aber f\u00e4ngt mein trieb was ungemeines an/", "tokens": ["Heut", "a\u00b7ber", "f\u00e4ngt", "mein", "trieb", "was", "un\u00b7ge\u00b7mei\u00b7nes", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPOSAT", "VVFIN", "PIS", "ADJA", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Indem ich einen mann/ der voller kern gewesen/", "tokens": ["In\u00b7dem", "ich", "ei\u00b7nen", "mann", "/", "der", "vol\u00b7ler", "kern", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "$(", "ART", "ADJA", "NN", "VAPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der uns mehr nutz und frucht als palmen lassen lesen/", "tokens": ["Der", "uns", "mehr", "nutz", "und", "frucht", "als", "pal\u00b7men", "las\u00b7sen", "le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PIAT", "NN", "KON", "ADJD", "KOKOM", "VVINF", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und wie ein balsam-baum sich allen auffgethan/", "tokens": ["Und", "wie", "ein", "bal\u00b7sam\u00b7baum", "sich", "al\u00b7len", "auff\u00b7ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "PRF", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Den edlen Gutsmuth nur mit einer blossen eichen/", "tokens": ["Den", "ed\u00b7len", "Guts\u00b7muth", "nur", "mit", "ei\u00b7ner", "blos\u00b7sen", "ei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Nach seinem tode will in dieser schrifft vergleichen.", "tokens": ["Nach", "sei\u00b7nem", "to\u00b7de", "will", "in", "die\u00b7ser", "schrifft", "ver\u00b7glei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Doch denckt nicht/ sterbliche/ da\u00df meiner feder hier", "tokens": ["Doch", "denckt", "nicht", "/", "sterb\u00b7li\u00b7che", "/", "da\u00df", "mei\u00b7ner", "fe\u00b7der", "hier"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "$(", "VVFIN", "$(", "KOUS", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So krafft als dinte wird zu beyder ruhme fehlen;", "tokens": ["So", "krafft", "als", "din\u00b7te", "wird", "zu", "bey\u00b7der", "ruh\u00b7me", "feh\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "VVFIN", "VAFIN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Athen zog eicheln schon dem besten zucker f\u00fcr/", "tokens": ["A\u00b7then", "zog", "ei\u00b7cheln", "schon", "dem", "bes\u00b7ten", "zu\u00b7cker", "f\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "VVFIN", "ADV", "ART", "ADJA", "NN", "APPR", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Und lie\u00df/ wie Spanien/ zu speisen sie erwehlen.", "tokens": ["Und", "lie\u00df", "/", "wie", "Spa\u00b7ni\u00b7en", "/", "zu", "spei\u00b7sen", "sie", "er\u00b7weh\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "KOKOM", "NE", "$(", "PTKZU", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die R\u00f6mer haben nur/ den helden ihrer stadt", "tokens": ["Die", "R\u00f6\u00b7mer", "ha\u00b7ben", "nur", "/", "den", "hel\u00b7den", "ih\u00b7rer", "stadt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "$(", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zu ehren/ einen krantz von eichen-laub erfunden/", "tokens": ["Zu", "eh\u00b7ren", "/", "ei\u00b7nen", "krantz", "von", "ei\u00b7chen\u00b7laub", "er\u00b7fun\u00b7den", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$(", "ART", "NN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und Deutschland war so sehr an dieses holtz gebunden/", "tokens": ["Und", "Deutschland", "war", "so", "sehr", "an", "die\u00b7ses", "holtz", "ge\u00b7bun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "ADV", "ADV", "APPR", "PDAT", "NN", "VVPP", "$("], "meter": "--+-+-+-+-+-", "measure": "anapaest.init"}, "line.8": {"text": "Da\u00df man mit anderm nichts vor dem geopffert hat.", "tokens": ["Da\u00df", "man", "mit", "an\u00b7derm", "nichts", "vor", "dem", "ge\u00b7opf\u00b7fert", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PIS", "PIS", "APPR", "ART", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was kan der selige nun besserm auff der erden/", "tokens": ["Was", "kan", "der", "se\u00b7li\u00b7ge", "nun", "bes\u00b7serm", "auff", "der", "er\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "ADJA", "ADV", "ADJD", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Als einer eichen noch zuletzt verglichen werden?", "tokens": ["Als", "ei\u00b7ner", "ei\u00b7chen", "noch", "zu\u00b7letzt", "ver\u00b7gli\u00b7chen", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Sein erster kinder-gang in der verwirrten welt/", "tokens": ["Sein", "ers\u00b7ter", "kin\u00b7der\u00b7gang", "in", "der", "ver\u00b7wirr\u00b7ten", "welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nahm witz und lehren schon von jungen eichen-zweigen;", "tokens": ["Nahm", "witz", "und", "leh\u00b7ren", "schon", "von", "jun\u00b7gen", "ei\u00b7chen\u00b7zwei\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "KON", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn wie ihr zartes holtz sich/ wie es uns gef\u00e4llt/", "tokens": ["Denn", "wie", "ihr", "zar\u00b7tes", "holtz", "sich", "/", "wie", "es", "uns", "ge\u00b7f\u00e4llt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPOSAT", "ADJA", "NN", "PRF", "$(", "PWAV", "PPER", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Von unsern h\u00e4nden l\u00e4st nach ieder forme beugen:", "tokens": ["Von", "un\u00b7sern", "h\u00e4n\u00b7den", "l\u00e4st", "nach", "ie\u00b7der", "for\u00b7me", "beu\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "VVFIN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So fiel sein hertze bald der eltern willen bey/", "tokens": ["So", "fiel", "sein", "hert\u00b7ze", "bald", "der", "el\u00b7tern", "wil\u00b7len", "bey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ADV", "ART", "ADJA", "NN", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und lie\u00df wie Cimon sich zur tugend auffw\u00e4rts richten/", "tokens": ["Und", "lie\u00df", "wie", "Ci\u00b7mon", "sich", "zur", "tu\u00b7gend", "auf\u00b7fw\u00e4rts", "rich\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOKOM", "NE", "PRF", "APPRART", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Zu zeigen: da\u00df ein baum nur reich an seinen fr\u00fcchten/", "tokens": ["Zu", "zei\u00b7gen", ":", "da\u00df", "ein", "baum", "nur", "reich", "an", "sei\u00b7nen", "fr\u00fcch\u00b7ten", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$.", "KOUS", "ART", "ADV", "ADV", "ADJD", "APPR", "PPOSAT", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und eine mutter erst vollkommen gl\u00fccklich sey/", "tokens": ["Und", "ei\u00b7ne", "mut\u00b7ter", "erst", "voll\u00b7kom\u00b7men", "gl\u00fcck\u00b7lich", "sey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "ADJD", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wenn sie um ihren schatz vor andern recht zu preisen/", "tokens": ["Wenn", "sie", "um", "ih\u00b7ren", "schatz", "vor", "an\u00b7dern", "recht", "zu", "prei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "APPR", "PIS", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Nur/ wie Cornelia/ darff auff die kinder weisen.", "tokens": ["Nur", "/", "wie", "Cor\u00b7ne\u00b7lia", "/", "darff", "auff", "die", "kin\u00b7der", "wei\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KOKOM", "NE", "$(", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.4": {"line.1": {"text": "Mit zeit und jahren wuchs auch die erfahrenheit/", "tokens": ["Mit", "zeit", "und", "jah\u00b7ren", "wuchs", "auch", "die", "er\u00b7fah\u00b7ren\u00b7heit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So wie ein eichen-baum von vielen sturm und winden;", "tokens": ["So", "wie", "ein", "ei\u00b7chen\u00b7baum", "von", "vie\u00b7len", "sturm", "und", "win\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "APPR", "PIAT", "NN", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn wer die stirne nicht mit staub und schwei\u00df bestreut/", "tokens": ["Denn", "wer", "die", "stir\u00b7ne", "nicht", "mit", "staub", "und", "schwei\u00df", "be\u00b7streut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "ADJA", "PTKNEG", "APPR", "ADJD", "KON", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wird auch das g\u00fcldne flie\u00df der ehre selten finden.", "tokens": ["Wird", "auch", "das", "g\u00fcld\u00b7ne", "flie\u00df", "der", "eh\u00b7re", "sel\u00b7ten", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "VVFIN", "ART", "VVFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der kl\u00fcgste Hannibal mu\u00df durch gefahr erh\u00f6ht/", "tokens": ["Der", "kl\u00fcgs\u00b7te", "Han\u00b7ni\u00b7bal", "mu\u00df", "durch", "ge\u00b7fahr", "er\u00b7h\u00f6ht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der grosse C\u00e4sar vor in wellen elend werden.", "tokens": ["Der", "gros\u00b7se", "C\u00e4\u00b7sar", "vor", "in", "wel\u00b7len", "e\u00b7lend", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "APPR", "PWAT", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Drum brach der selige durch sorgen und beschwerden/", "tokens": ["Drum", "brach", "der", "se\u00b7li\u00b7ge", "durch", "sor\u00b7gen", "und", "be\u00b7schwer\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "ADJA", "APPR", "NN", "KON", "ADJD", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und glaubte: da\u00df ein mensch nicht eher feste steht/", "tokens": ["Und", "glaub\u00b7te", ":", "da\u00df", "ein", "mensch", "nicht", "e\u00b7her", "fes\u00b7te", "steht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "KOUS", "ART", "NN", "PTKNEG", "ADV", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Bi\u00df m\u00fch und kummer ihm/ mit dem wir uns beladen/", "tokens": ["Bi\u00df", "m\u00fch", "und", "kum\u00b7mer", "ihm", "/", "mit", "dem", "wir", "uns", "be\u00b7la\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "KON", "NN", "PPER", "$(", "APPR", "PRELS", "PPER", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So wenig als das feur kan gr\u00fcnen eichen schaden.", "tokens": ["So", "we\u00b7nig", "als", "das", "feur", "kan", "gr\u00fc\u00b7nen", "ei\u00b7chen", "scha\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "KOKOM", "ART", "NN", "VMFIN", "VVINF", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Di\u00df alles \u00fcberwog der kern der s\u00fcssen frucht/", "tokens": ["Di\u00df", "al\u00b7les", "\u00fc\u00b7ber\u00b7wog", "der", "kern", "der", "s\u00fcs\u00b7sen", "frucht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die er bi\u00df in den tod vor keinem angebunden/", "tokens": ["Die", "er", "bi\u00df", "in", "den", "tod", "vor", "kei\u00b7nem", "an\u00b7ge\u00b7bun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "APPR", "ART", "NN", "APPR", "PIS", "VVPP", "$("], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Und mancher offtermahls noch eh' er sie gesucht/", "tokens": ["Und", "man\u00b7cher", "off\u00b7ter\u00b7mahls", "noch", "eh'", "er", "sie", "ge\u00b7sucht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADV", "ADV", "KOUS", "PPER", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie eicheln ohngefehr in w\u00e4ldern hat gefunden.", "tokens": ["Wie", "ei\u00b7cheln", "ohn\u00b7ge\u00b7fehr", "in", "w\u00e4l\u00b7dern", "hat", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADJD", "APPR", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der fromme Scipio hat alle fast beschenckt/", "tokens": ["Der", "from\u00b7me", "Sci\u00b7pio", "hat", "al\u00b7le", "fast", "be\u00b7schenckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "VAFIN", "PIS", "ADV", "VVPP", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Agesilaus nichts als schuldner hinterlassen;", "tokens": ["A\u00b7ge\u00b7si\u00b7laus", "nichts", "als", "schuld\u00b7ner", "hin\u00b7ter\u00b7las\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIS", "KOKOM", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Er suchte iederman mit liebe zu umfassen/", "tokens": ["Er", "such\u00b7te", "ie\u00b7der\u00b7man", "mit", "lie\u00b7be", "zu", "um\u00b7fas\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "ADJA", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und hat mit Phocion den gringsten nicht gekr\u00e4nckt/", "tokens": ["Und", "hat", "mit", "Pho\u00b7ci\u00b7on", "den", "grings\u00b7ten", "nicht", "ge\u00b7kr\u00e4nckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "ART", "ADJA", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wohl aber vielen so/ wie eichen-b\u00e4ume bienen/", "tokens": ["Wohl", "a\u00b7ber", "vie\u00b7len", "so", "/", "wie", "ei\u00b7chen\u00b7b\u00e4u\u00b7me", "bie\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "ADV", "$(", "KOKOM", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Zu ihrem auffenthalt und schutze m\u00fcssen dienen.", "tokens": ["Zu", "ih\u00b7rem", "auf\u00b7fent\u00b7halt", "und", "schut\u00b7ze", "m\u00fcs\u00b7sen", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "VVFIN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Nechst liebe soll ein mensch auch klug im rathe seyn/", "tokens": ["Nechst", "lie\u00b7be", "soll", "ein", "mensch", "auch", "klug", "im", "ra\u00b7the", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VMFIN", "ART", "NN", "ADV", "ADJD", "APPRART", "VVFIN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nach art der wider gifft bewehrten eichen-rinden.", "tokens": ["Nach", "art", "der", "wi\u00b7der", "gifft", "be\u00b7wehr\u00b7ten", "ei\u00b7chen\u00b7rin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn klugheit mu\u00df die noth mit zucker \u00fcberstreun;", "tokens": ["Denn", "klug\u00b7heit", "mu\u00df", "die", "noth", "mit", "zu\u00b7cker", "\u00fc\u00b7bers\u00b7treun", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VMFIN", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie \u00e4rtzte wund und schmertz mit eichen-laub verbinden.", "tokens": ["Wie", "\u00e4rtz\u00b7te", "wund", "und", "schmertz", "mit", "ei\u00b7chen\u00b7laub", "ver\u00b7bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADJD", "KON", "ADJD", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der ruhm des seligen ist allen offenbar/", "tokens": ["Der", "ruhm", "des", "se\u00b7li\u00b7gen", "ist", "al\u00b7len", "of\u00b7fen\u00b7bar", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "VAFIN", "PIAT", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und darff wie Cato sich durch s\u00e4ulen nicht vermehren/", "tokens": ["Und", "darff", "wie", "Ca\u00b7to", "sich", "durch", "s\u00e4u\u00b7len", "nicht", "ver\u00b7meh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "KOKOM", "NE", "PRF", "APPR", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Weil blo\u00df vernunfft und witz der marmel seiner ehren/", "tokens": ["Weil", "blo\u00df", "ver\u00b7nunfft", "und", "witz", "der", "mar\u00b7mel", "sei\u00b7ner", "eh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "KON", "NN", "ART", "NN", "PPOSAT", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So wie der eichen-safft des mistels wachsthum war;", "tokens": ["So", "wie", "der", "ei\u00b7chen\u00b7\u00b7safft", "des", "mis\u00b7tels", "wach\u00b7sthum", "war", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und unser Leopold ihn selber neu gebohren/", "tokens": ["Und", "un\u00b7ser", "Leo\u00b7pold", "ihn", "sel\u00b7ber", "neu", "ge\u00b7boh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NE", "PPER", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Indem er ihn zum rath und ritter au\u00dferkohren.", "tokens": ["In\u00b7dem", "er", "ihn", "zum", "rath", "und", "rit\u00b7ter", "au\u00b7\u00dfer\u00b7koh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPRART", "NN", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Je h\u00f6her aber er an stand und w\u00fcrde stieg/", "tokens": ["Je", "h\u00f6\u00b7her", "a\u00b7ber", "er", "an", "stand", "und", "w\u00fcr\u00b7de", "stieg", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "PPER", "APPR", "VVFIN", "KON", "VAFIN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Je tieffer warff sein hertz sich wieder zu der erden;", "tokens": ["Je", "tief\u00b7fer", "warff", "sein", "hertz", "sich", "wie\u00b7der", "zu", "der", "er\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPOSAT", "NN", "PRF", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn dieses bleibt auch sein/ wie Cyrus/ gr\u00f6ster sieg/", "tokens": ["Denn", "die\u00b7ses", "bleibt", "auch", "sein", "/", "wie", "Cy\u00b7rus", "/", "gr\u00f6s\u00b7ter", "sieg", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ADV", "VAINF", "$(", "KOKOM", "NE", "$(", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df er im gl\u00fccke nicht hat k\u00f6nnen st\u00f6ltzer werden/", "tokens": ["Da\u00df", "er", "im", "gl\u00fc\u00b7cke", "nicht", "hat", "k\u00f6n\u00b7nen", "st\u00b7\u00f6lt\u00b7zer", "wer\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "VVFIN", "PTKNEG", "VAFIN", "VMFIN", "ADJD", "VAINF", "$("], "meter": "-+-+--+---+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Und also di\u00dffalls auch wie eichen sich bezeigt;", "tokens": ["Und", "al\u00b7so", "di\u00df\u00b7falls", "auch", "wie", "ei\u00b7chen", "sich", "be\u00b7zeigt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADV", "KOKOM", "VVFIN", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die zwar ihr hohes haupt zum himmel auffw\u00e4rts strecken/", "tokens": ["Die", "zwar", "ihr", "ho\u00b7hes", "haupt", "zum", "him\u00b7mel", "auf\u00b7fw\u00e4rts", "stre\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPOSAT", "ADJA", "NN", "APPRART", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "An wurtzeln aber auch gleich tieff im grunde stecken/", "tokens": ["An", "wurt\u00b7zeln", "a\u00b7ber", "auch", "gleich", "tieff", "im", "grun\u00b7de", "ste\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "ADV", "ADV", "ADJD", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Zur lehre: da\u00df der ruhm schon von sich selber steigt/", "tokens": ["Zur", "leh\u00b7re", ":", "da\u00df", "der", "ruhm", "schon", "von", "sich", "sel\u00b7ber", "steigt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "KOUS", "ART", "NN", "ADV", "APPR", "PRF", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und ein bescheidner blo\u00df mit nutz-erf\u00fcllten schalen/", "tokens": ["Und", "ein", "be\u00b7scheid\u00b7ner", "blo\u00df", "mit", "nutz\u00b7er\u00b7f\u00fcll\u00b7ten", "scha\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "ADV", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Gleich wie ihr gipffel soll mit lauter fr\u00fcchten pralen.", "tokens": ["Gleich", "wie", "ihr", "gipf\u00b7fel", "soll", "mit", "lau\u00b7ter", "fr\u00fcch\u00b7ten", "pra\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PPOSAT", "NN", "VMFIN", "APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Die klugen zehlen sonst zu wundern der natur", "tokens": ["Die", "klu\u00b7gen", "zeh\u00b7len", "sonst", "zu", "wun\u00b7dern", "der", "na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "ADV", "PTKZU", "VVINF", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auch dieses: da\u00df ihr stamm kan keinen \u00f6lbaum leiden.", "tokens": ["Auch", "die\u00b7ses", ":", "da\u00df", "ihr", "stamm", "kan", "kei\u00b7nen", "\u00f6l\u00b7baum", "lei\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "$.", "KOUS", "PPER", "VVFIN", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer wei\u00df nicht/ wie sein geist auff der gesetzten spur/", "tokens": ["Wer", "wei\u00df", "nicht", "/", "wie", "sein", "geist", "auff", "der", "ge\u00b7setz\u00b7ten", "spur", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "$(", "KOKOM", "PPOSAT", "NN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Das \u00f6le falscher welt hat wissen zu vermeiden?", "tokens": ["Das", "\u00f6\u00b7le", "fal\u00b7scher", "welt", "hat", "wis\u00b7sen", "zu", "ver\u00b7mei\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "VAFIN", "VVINF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wenn er auff erden schon den grossen Gott beschaut/", "tokens": ["Wenn", "er", "auff", "er\u00b7den", "schon", "den", "gros\u00b7sen", "Gott", "be\u00b7schaut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ADV", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Und durch des glaubens krafft den s\u00fcnden obgelegen?", "tokens": ["Und", "durch", "des", "glau\u00b7bens", "krafft", "den", "s\u00fcn\u00b7den", "ob\u00b7ge\u00b7le\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Drum ward er lebenslang vom himmel auch mit segen/", "tokens": ["Drum", "ward", "er", "le\u00b7bens\u00b7lang", "vom", "him\u00b7mel", "auch", "mit", "se\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "VVFIN", "APPRART", "NN", "ADV", "APPR", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Als wie ein eichen-baum mit honig \u00fcberthaut/", "tokens": ["Als", "wie", "ein", "ei\u00b7chen\u00b7baum", "mit", "ho\u00b7nig", "\u00fc\u00b7bert\u00b7haut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "NN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und lie\u00df die bl\u00f6den offt aus seinen augen lesen:", "tokens": ["Und", "lie\u00df", "die", "bl\u00f6\u00b7den", "offt", "aus", "sei\u00b7nen", "au\u00b7gen", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da\u00df er bey sorgen auch stets gutes muths gewesen.", "tokens": ["Da\u00df", "er", "bey", "sor\u00b7gen", "auch", "stets", "gu\u00b7tes", "muths", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ADV", "ADV", "ADJA", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Itzt hat der blasse tod sein urthel abgefa\u00dft/", "tokens": ["Itzt", "hat", "der", "blas\u00b7se", "tod", "sein", "ur\u00b7thel", "ab\u00b7ge\u00b7fa\u00dft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und l\u00e4st das trauer-lied in unsern ohren schallen/", "tokens": ["Und", "l\u00e4st", "das", "trau\u00b7e\u00b7rlied", "in", "un\u00b7sern", "oh\u00b7ren", "schal\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was jener Spanier auff einen eichen-ast", "tokens": ["Was", "je\u00b7ner", "Spa\u00b7nier", "auff", "ei\u00b7nen", "ei\u00b7chen\u00b7ast"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PDAT", "NN", "APPR", "ART", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Zum sinnenbilde schrieb: Nun ist er auch gefallen.", "tokens": ["Zum", "sin\u00b7nen\u00b7bil\u00b7de", "schrieb", ":", "Nun", "ist", "er", "auch", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$.", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch nur der meynung nach; denn kunst und wissenschafft/", "tokens": ["Doch", "nur", "der", "mey\u00b7nung", "nach", ";", "denn", "kunst", "und", "wis\u00b7sen\u00b7schafft", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "PTKVZ", "$.", "KON", "PTKVZ", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Schnitzt form und bilder erst aus umgef\u00e4llten eichen;", "tokens": ["Schnitzt", "form", "und", "bil\u00b7der", "erst", "aus", "um\u00b7ge\u00b7f\u00e4ll\u00b7ten", "ei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "NN", "ADV", "APPR", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So kan auch unser geist erst Gottes bilde gleichen/", "tokens": ["So", "kan", "auch", "un\u00b7ser", "geist", "erst", "Got\u00b7tes", "bil\u00b7de", "glei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "PPOSAT", "NN", "ADV", "NN", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wenn er sich von der welt zum himmel auffgerafft;", "tokens": ["Wenn", "er", "sich", "von", "der", "welt", "zum", "him\u00b7mel", "auff\u00b7ge\u00b7rafft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der leib mu\u00df aber so/ wie eicheln in der erden", "tokens": ["Der", "leib", "mu\u00df", "a\u00b7ber", "so", "/", "wie", "ei\u00b7cheln", "in", "der", "er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "ADV", "ADV", "$(", "PWAV", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Zum stamme/ mit der zeit zum menschen wieder werden.", "tokens": ["Zum", "stam\u00b7me", "/", "mit", "der", "zeit", "zum", "men\u00b7schen", "wie\u00b7der", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "VVFIN", "$(", "APPR", "ART", "NN", "APPRART", "NN", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Was pre\u00dft/ betr\u00fcbteste/ denn eure seuffzer aus?", "tokens": ["Was", "pre\u00dft", "/", "be\u00b7tr\u00fcb\u00b7tes\u00b7te", "/", "denn", "eu\u00b7re", "seuff\u00b7zer", "aus", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$(", "VVFIN", "$(", "KON", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein baum/ der lange zeit mit ruhme frucht gegeben/", "tokens": ["Ein", "baum", "/", "der", "lan\u00b7ge", "zeit", "mit", "ruh\u00b7me", "frucht", "ge\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und schon/ dem wesen nach/ im himmel wie ein haus", "tokens": ["Und", "schon", "/", "dem", "we\u00b7sen", "nach", "/", "im", "him\u00b7mel", "wie", "ein", "haus"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$(", "ART", "NN", "APPR", "$(", "APPRART", "NN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Von eichen-holtze/ f\u00e4ngt von neuem an zu leben?", "tokens": ["Von", "ei\u00b7chen\u00b7holt\u00b7ze", "/", "f\u00e4ngt", "von", "neu\u00b7em", "an", "zu", "le\u00b7ben", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "VVFIN", "APPR", "ADJA", "APZR", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "F\u00fcrwar/ sein gl\u00fccke braucht itzt eure klagen nicht;", "tokens": ["F\u00fcr\u00b7war", "/", "sein", "gl\u00fc\u00b7cke", "braucht", "itzt", "eu\u00b7re", "kla\u00b7gen", "nicht", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PPOSAT", "NN", "VVFIN", "ADV", "PPOSAT", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Drum auff/ und streicht das saltz der thr\u00e4nen von den wangen!", "tokens": ["Drum", "auff", "/", "und", "streicht", "das", "saltz", "der", "thr\u00e4\u00b7nen", "von", "den", "wan\u00b7gen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "APPR", "$(", "KON", "VVFIN", "ART", "NN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Denn ist euch allen gleich ein vater untergangen/", "tokens": ["Denn", "ist", "euch", "al\u00b7len", "gleich", "ein", "va\u00b7ter", "un\u00b7ter\u00b7gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PIS", "ADV", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So glaubt/ da\u00df dennoch auch sein tod di\u00df urtheil spricht:", "tokens": ["So", "glaubt", "/", "da\u00df", "den\u00b7noch", "auch", "sein", "tod", "di\u00df", "ur\u00b7theil", "spricht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "KOUS", "ADV", "ADV", "PPOSAT", "NN", "PDS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Da\u00df/ wer hier trauren will/ mu\u00df eichen-b\u00e4umen gleichen/", "tokens": ["Da\u00df", "/", "wer", "hier", "trau\u00b7ren", "will", "/", "mu\u00df", "ei\u00b7chen\u00b7b\u00e4u\u00b7men", "glei\u00b7chen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "PWS", "ADV", "VVINF", "VMFIN", "$(", "VMFIN", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und mehr dem kummer nicht/ als diese blitzen weichen.", "tokens": ["Und", "mehr", "dem", "kum\u00b7mer", "nicht", "/", "als", "die\u00b7se", "blit\u00b7zen", "wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "PTKNEG", "$(", "KOUS", "PDS", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}