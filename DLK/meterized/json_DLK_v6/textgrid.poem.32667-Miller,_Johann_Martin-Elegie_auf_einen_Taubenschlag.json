{"textgrid.poem.32667": {"metadata": {"author": {"name": "Miller, Johann Martin", "birth": "N.A.", "death": "N.A."}, "title": "Elegie auf einen Taubenschlag", "genre": "verse", "period": "N.A.", "pub_year": 1772, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ah Verw\u00fcstung! \u00fcberall umher,", "tokens": ["Ah", "Ver\u00b7w\u00fcs\u00b7tung", "!", "\u00fc\u00b7be\u00b7rall", "um\u00b7her", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Liegen sie in Todesschlaf versunken,", "tokens": ["Lie\u00b7gen", "sie", "in", "To\u00b7des\u00b7schlaf", "ver\u00b7sun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Meine T\u00e4ubchen! keines atmet mehr,", "tokens": ["Mei\u00b7ne", "T\u00e4ub\u00b7chen", "!", "kei\u00b7nes", "at\u00b7met", "mehr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PIS", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Und der Marder hat ihr Blut getrunken.", "tokens": ["Und", "der", "Mar\u00b7der", "hat", "ihr", "Blut", "ge\u00b7trun\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Das geliebte Ringelt\u00e4ubchen hier", "tokens": ["Das", "ge\u00b7lieb\u00b7te", "Rin\u00b7gel\u00b7t\u00e4ub\u00b7chen", "hier"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Hatt' ich mit so vieler M\u00fch' erzogen,", "tokens": ["Hatt'", "ich", "mit", "so", "vie\u00b7ler", "M\u00fch'", "er\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Und wenn ich ihm winkte, kam es mir", "tokens": ["Und", "wenn", "ich", "ihm", "wink\u00b7te", ",", "kam", "es", "mir"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "PPER"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Freundlich auf die Schultern hergeflogen.", "tokens": ["Freund\u00b7lich", "auf", "die", "Schul\u00b7tern", "her\u00b7ge\u00b7flo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Ach, entfiedert und entstellt vom Tod,", "tokens": ["Ach", ",", "ent\u00b7fie\u00b7dert", "und", "ent\u00b7stellt", "vom", "Tod", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVPP", "KON", "VVFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Liegt mein liebes silberwei\u00dfes T\u00e4ubchen,", "tokens": ["Liegt", "mein", "lie\u00b7bes", "sil\u00b7ber\u00b7wei\u00b7\u00dfes", "T\u00e4ub\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "An den F\u00fc\u00dfchen trug es hohes Rot,", "tokens": ["An", "den", "F\u00fc\u00df\u00b7chen", "trug", "es", "ho\u00b7hes", "Rot", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Auf dem Kopf ein mondgeformtes H\u00e4ubchen;", "tokens": ["Auf", "dem", "Kopf", "ein", "mond\u00b7ge\u00b7form\u00b7tes", "H\u00e4ub\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Ihm zur Seiten liegt das M\u00e4nnchen da", "tokens": ["Ihm", "zur", "Sei\u00b7ten", "liegt", "das", "M\u00e4nn\u00b7chen", "da"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "APPRART", "NN", "VVFIN", "ART", "NN", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Mit dem glatten aschengrauen K\u00f6pfchen,", "tokens": ["Mit", "dem", "glat\u00b7ten", "asc\u00b7hen\u00b7grau\u00b7en", "K\u00f6pf\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Alle Regenbogenfarben sah", "tokens": ["Al\u00b7le", "Re\u00b7gen\u00b7bo\u00b7gen\u00b7far\u00b7ben", "sah"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Man im Sonnenstrahl an seinem Kr\u00f6pfchen.", "tokens": ["Man", "im", "Son\u00b7nen\u00b7strahl", "an", "sei\u00b7nem", "Kr\u00f6pf\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPRART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Ach, und Damons T\u00e4ubchen! \u2013 Gestern kam", "tokens": ["Ach", ",", "und", "Da\u00b7mons", "T\u00e4ub\u00b7chen", "!", "\u2013", "Ge\u00b7stern", "kam"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["ITJ", "$,", "KON", "NE", "NN", "$.", "$(", "NN", "VVFIN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Es so freundlich zu mir hergeflogen,", "tokens": ["Es", "so", "freund\u00b7lich", "zu", "mir", "her\u00b7ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Als die Eifersucht mit d\u00fcsterm Gram", "tokens": ["Als", "die", "Ei\u00b7fer\u00b7sucht", "mit", "d\u00fcs\u00b7term", "Gram"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Meine Stirn' und Wangen \u00fcberzogen! \u2013", "tokens": ["Mei\u00b7ne", "Stirn'", "und", "Wan\u00b7gen", "\u00fc\u00b7berz\u00b7o\u00b7gen", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Grausam jagt' ich es hinweg, weil ich", "tokens": ["Grau\u00b7sam", "jagt'", "ich", "es", "hin\u00b7weg", ",", "weil", "ich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "PPER", "ADV", "$,", "KOUS", "PPER"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Zornig war auf den, der es mir schenkte.", "tokens": ["Zor\u00b7nig", "war", "auf", "den", ",", "der", "es", "mir", "schenk\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "APPR", "ART", "$,", "PRELS", "PPER", "PPER", "VVFIN", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "O vergieb mir, T\u00e4ubchen, da\u00df ich dich,", "tokens": ["O", "ver\u00b7gieb", "mir", ",", "T\u00e4ub\u00b7chen", ",", "da\u00df", "ich", "dich", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "$,", "NN", "$,", "KOUS", "PPER", "PRF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "So wie meinen guten Sch\u00e4fer kr\u00e4nkte!", "tokens": ["So", "wie", "mei\u00b7nen", "gu\u00b7ten", "Sch\u00e4\u00b7fer", "kr\u00e4nk\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "Um Verzeihung flehen will ich ihn,", "tokens": ["Um", "Ver\u00b7zei\u00b7hung", "fle\u00b7hen", "will", "ich", "ihn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "VVINF", "VMFIN", "PPER", "PPER", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Alle meine Fehler ihm bekennen,", "tokens": ["Al\u00b7le", "mei\u00b7ne", "Feh\u00b7ler", "ihm", "be\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "NN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Seine Hand an meine Lippen ziehn,", "tokens": ["Sei\u00b7ne", "Hand", "an", "mei\u00b7ne", "Lip\u00b7pen", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Meinen lieben, trauten Freund ihn nennen!", "tokens": ["Mei\u00b7nen", "lie\u00b7ben", ",", "trau\u00b7ten", "Freund", "ihn", "nen\u00b7nen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "$,", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Wenn er dann noch grausam bleibt, will ich", "tokens": ["Wenn", "er", "dann", "noch", "grau\u00b7sam", "bleibt", ",", "will", "ich"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADJD", "VVFIN", "$,", "VMFIN", "PPER"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Ihm das liebe, tote T\u00e4ubchen zeigen;", "tokens": ["Ihm", "das", "lie\u00b7be", ",", "to\u00b7te", "T\u00e4ub\u00b7chen", "zei\u00b7gen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PDS", "VVFIN", "$,", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Weinen wird er, k\u00fcssen wird er mich,", "tokens": ["Wei\u00b7nen", "wird", "er", ",", "k\u00fcs\u00b7sen", "wird", "er", "mich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$,", "VVINF", "VAFIN", "PPER", "PRF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Und vor Bangigkeit und Wehmut schweigen.", "tokens": ["Und", "vor", "Ban\u00b7gig\u00b7keit", "und", "Weh\u00b7mut", "schwei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Dort im Hain begraben wir dich dann,", "tokens": ["Dort", "im", "Hain", "be\u00b7gra\u00b7ben", "wir", "dich", "dann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VVFIN", "PPER", "PRF", "ADV", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Mitleidsthr\u00e4nen sollen dich benetzen,", "tokens": ["Mit\u00b7leidst\u00b7hr\u00e4\u00b7nen", "sol\u00b7len", "dich", "be\u00b7net\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Ma\u00dflieb, Tausendsch\u00f6n und Thymian", "tokens": ["Ma\u00df\u00b7lieb", ",", "Tau\u00b7send\u00b7sch\u00f6n", "und", "Thy\u00b7mi\u00b7an"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NE", "KON", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Wollen wir um deinen H\u00fcgel setzen.", "tokens": ["Wol\u00b7len", "wir", "um", "dei\u00b7nen", "H\u00fc\u00b7gel", "set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Jeden stillen Sommertag, wenn wir", "tokens": ["Je\u00b7den", "stil\u00b7len", "Som\u00b7mer\u00b7tag", ",", "wenn", "wir"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "$,", "KOUS", "PPER"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "In der D\u00e4mmerung einander k\u00fcssen,", "tokens": ["In", "der", "D\u00e4m\u00b7me\u00b7rung", "ein\u00b7an\u00b7der", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Sollen, liebes, trautes T\u00e4ubchen, dir", "tokens": ["Sol\u00b7len", ",", "lie\u00b7bes", ",", "trau\u00b7tes", "T\u00e4ub\u00b7chen", ",", "dir"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word"], "pos": ["VMFIN", "$,", "ADJA", "$,", "ADJA", "NN", "$,", "PPER"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Hei\u00dfe Thr\u00e4nen uns vom Auge flie\u00dfen.", "tokens": ["Hei\u00b7\u00dfe", "Thr\u00e4\u00b7nen", "uns", "vom", "Au\u00b7ge", "flie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}}}}