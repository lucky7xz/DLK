{"textgrid.poem.54331": {"metadata": {"author": {"name": "Ziegler, Christiana Mariana von", "birth": "N.A.", "death": "N.A."}, "title": "13. Ode", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Kirche jauchzt; ihr Recht besteht,", "tokens": ["Die", "Kir\u00b7che", "jauchzt", ";", "ihr", "Recht", "be\u00b7steht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ruht auf fest gestellten Gr\u00fcnden;", "tokens": ["Und", "ruht", "auf", "fest", "ge\u00b7stell\u00b7ten", "Gr\u00fcn\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So weit die Macht der Deutschen geht", "tokens": ["So", "weit", "die", "Macht", "der", "Deut\u00b7schen", "geht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ART", "NN", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kann sie die Sicherheit durch Schutz im Frieden finden.", "tokens": ["Kann", "sie", "die", "Si\u00b7cher\u00b7heit", "durch", "Schutz", "im", "Frie\u00b7den", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "APPR", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Zwietracht weicht der Einigkeit,", "tokens": ["Die", "Zwiet\u00b7racht", "weicht", "der", "Ei\u00b7nig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es flieht der Ha\u00df der alten Zeit", "tokens": ["Es", "flieht", "der", "Ha\u00df", "der", "al\u00b7ten", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und darf sich weiter nicht in diese Grenzen wagen.", "tokens": ["Und", "darf", "sich", "wei\u00b7ter", "nicht", "in", "die\u00b7se", "Gren\u00b7zen", "wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "ADV", "PTKNEG", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der hohen St\u00e4nde Freundschaftsband", "tokens": ["Der", "ho\u00b7hen", "St\u00e4n\u00b7de", "Freund\u00b7schafts\u00b7band"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Vereinigt Herzen Mund und Hand,", "tokens": ["Ver\u00b7ei\u00b7nigt", "Her\u00b7zen", "Mund", "und", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ein solches Ungeheur ins Elend zu verjagen.", "tokens": ["Ein", "sol\u00b7ches", "Un\u00b7ge\u00b7heur", "ins", "E\u00b7lend", "zu", "ver\u00b7ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wie grausam hat ihr wilder Arm", "tokens": ["Wie", "grau\u00b7sam", "hat", "ihr", "wil\u00b7der", "Arm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des H\u00f6chsten Heiligthum zerst\u00f6ret!", "tokens": ["Des", "H\u00f6chs\u00b7ten", "Hei\u00b7lig\u00b7thum", "zer\u00b7st\u00f6\u00b7ret", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wie hat nicht Ungl\u00fcck, Gram und Harm", "tokens": ["Wie", "hat", "nicht", "Un\u00b7gl\u00fcck", ",", "Gram", "und", "Harm"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PTKNEG", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch sie der Unschuld Quaal erwecket und vermehret!", "tokens": ["Durch", "sie", "der", "Un\u00b7schuld", "Qua\u00b7al", "er\u00b7we\u00b7cket", "und", "ver\u00b7meh\u00b7ret", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-++-+-+-+-", "measure": "unknown.measure.septa"}, "line.5": {"text": "Sie suchte Blut, und nicht die Schuld,", "tokens": ["Sie", "such\u00b7te", "Blut", ",", "und", "nicht", "die", "Schuld", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "KON", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und hatte sonsten nicht Geduld", "tokens": ["Und", "hat\u00b7te", "sons\u00b7ten", "nicht", "Ge\u00b7duld"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "PTKNEG", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Als nur die Noth zu sehn so die Bedr\u00e4ngten dr\u00fcckte.", "tokens": ["Als", "nur", "die", "Noth", "zu", "sehn", "so", "die", "Be\u00b7dr\u00e4ng\u00b7ten", "dr\u00fcck\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PTKZU", "VVINF", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sie n\u00e4hrte Nattern in der Brust,", "tokens": ["Sie", "n\u00e4hr\u00b7te", "Nat\u00b7tern", "in", "der", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und brachte der verdammten Lust", "tokens": ["Und", "brach\u00b7te", "der", "ver\u00b7damm\u00b7ten", "Lust"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Das Opfer ihres Zorns, der sich zur Rache schickte.", "tokens": ["Das", "Op\u00b7fer", "ih\u00b7res", "Zorns", ",", "der", "sich", "zur", "Ra\u00b7che", "schick\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,", "PRELS", "PRF", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Je mehr die Wuth verderbt und schl\u00e4gt,", "tokens": ["Je", "mehr", "die", "Wuth", "ver\u00b7derbt", "und", "schl\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Je mehr gew\u00f6hnt sie sich zum W\u00fcrgen:", "tokens": ["Je", "mehr", "ge\u00b7w\u00f6hnt", "sie", "sich", "zum", "W\u00fcr\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "PPER", "PRF", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Je weiter sie die Waffen tr\u00e4gt,", "tokens": ["Je", "wei\u00b7ter", "sie", "die", "Waf\u00b7fen", "tr\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Je mehr verschm\u00e4het sie die sichern Friedensb\u00fcrgen.", "tokens": ["Je", "mehr", "ver\u00b7schm\u00e4\u00b7het", "sie", "die", "si\u00b7chern", "Frie\u00b7dens\u00b7b\u00fcr\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.5": {"text": "Sie w\u00fcnscht der Unschuld Untergang;", "tokens": ["Sie", "w\u00fcnscht", "der", "Un\u00b7schuld", "Un\u00b7ter\u00b7gang", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und ihr wird keine Zeit zu lang", "tokens": ["Und", "ihr", "wird", "kei\u00b7ne", "Zeit", "zu", "lang"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "PIAT", "NN", "PTKA", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das ausgezogne Schwerdt auf ihren Hals zu wetzen.", "tokens": ["Das", "aus\u00b7ge\u00b7zog\u00b7ne", "Schwerdt", "auf", "ih\u00b7ren", "Hals", "zu", "wet\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sie bl\u00e4st die matten Funken auf,", "tokens": ["Sie", "bl\u00e4st", "die", "mat\u00b7ten", "Fun\u00b7ken", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und denkt, und sinnet nur darauf,", "tokens": ["Und", "denkt", ",", "und", "sin\u00b7net", "nur", "da\u00b7rauf", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KON", "VVFIN", "ADV", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Den angefachten Brand in volle Gluth zu setzen.", "tokens": ["Den", "an\u00b7ge\u00b7fach\u00b7ten", "Brand", "in", "vol\u00b7le", "Gluth", "zu", "set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wie Sturm und Wind die Wolken treibt,", "tokens": ["Wie", "Sturm", "und", "Wind", "die", "Wol\u00b7ken", "treibt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein schweres Wetter aufzuth\u00fcrmen;", "tokens": ["Ein", "schwe\u00b7res", "Wet\u00b7ter", "auf\u00b7zut\u00b7h\u00fcr\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wobey die Welt in Sorgen bleibt", "tokens": ["Wo\u00b7bey", "die", "Welt", "in", "Sor\u00b7gen", "bleibt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich wieder seinen Strahl mit Vorsicht zu beschirmen:", "tokens": ["Sich", "wie\u00b7der", "sei\u00b7nen", "Strahl", "mit", "Vor\u00b7sicht", "zu", "be\u00b7schir\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "PPOSAT", "NN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der schnelle Blitz hernieder f\u00e4hrt;", "tokens": ["Der", "schnel\u00b7le", "Blitz", "her\u00b7nie\u00b7der", "f\u00e4hrt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und hier und dort ein Haus verzehrt,", "tokens": ["Und", "hier", "und", "dort", "ein", "Haus", "ver\u00b7zehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KON", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das sonst die Zeiten trotzt und die Gewalt verschm\u00e4het;", "tokens": ["Das", "sonst", "die", "Zei\u00b7ten", "trotzt", "und", "die", "Ge\u00b7walt", "ver\u00b7schm\u00e4\u00b7het", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "VVFIN", "KON", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und wenn dies kaum getilget ist,", "tokens": ["Und", "wenn", "dies", "kaum", "ge\u00b7til\u00b7get", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PDS", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Sein Schwefelflu\u00df ein neues fri\u00dft,", "tokens": ["Sein", "Schwe\u00b7fel\u00b7flu\u00df", "ein", "neu\u00b7es", "fri\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Da\u00df ein erschrocknes Volk bey Gott um Beystand flehet:", "tokens": ["Da\u00df", "ein", "er\u00b7schrock\u00b7nes", "Volk", "bey", "Gott", "um", "Beys\u00b7tand", "fle\u00b7het", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "APPR", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "So hat die Zwietracht auch gethan,", "tokens": ["So", "hat", "die", "Zwiet\u00b7racht", "auch", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und manches F\u00fcrsten Blut erhitzet;", "tokens": ["Und", "man\u00b7ches", "F\u00fcrs\u00b7ten", "Blut", "er\u00b7hit\u00b7zet", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und wie sie tapfer l\u00fcgen kann,", "tokens": ["Und", "wie", "sie", "tap\u00b7fer", "l\u00fc\u00b7gen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch dieses Schlangengift den Redlichsten beschmitzet.", "tokens": ["Durch", "die\u00b7ses", "Schlan\u00b7gen\u00b7gift", "den", "Red\u00b7lichs\u00b7ten", "be\u00b7schmit\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.5": {"text": "Man bricht mit ganzen Heeren ein,", "tokens": ["Man", "bricht", "mit", "gan\u00b7zen", "Hee\u00b7ren", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Wahrheit soll vertilget seyn:", "tokens": ["Die", "Wahr\u00b7heit", "soll", "ver\u00b7til\u00b7get", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Man soll durch Tod und Staub ihr frey Bek\u00e4nntni\u00df b\u00fcssen.", "tokens": ["Man", "soll", "durch", "Tod", "und", "Staub", "ihr", "frey", "Be\u00b7k\u00e4nnt\u00b7ni\u00df", "b\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "APPR", "NN", "KON", "NN", "PPOSAT", "ADJD", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Raserey bewaffnet sich,", "tokens": ["Die", "Ra\u00b7se\u00b7rey", "be\u00b7waff\u00b7net", "sich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und hilft der Bosheit ritterlich,", "tokens": ["Und", "hilft", "der", "Bos\u00b7heit", "rit\u00b7ter\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und will von Gnade nichts, nichts von Erbarmen wissen.", "tokens": ["Und", "will", "von", "Gna\u00b7de", "nichts", ",", "nichts", "von", "Er\u00b7bar\u00b7men", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "NN", "PIS", "$,", "PIS", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Was hat die Gluthen angeflammt?", "tokens": ["Was", "hat", "die", "Glu\u00b7then", "an\u00b7ge\u00b7flammt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was hat den frechen Zorn gereizet?", "tokens": ["Was", "hat", "den", "fre\u00b7chen", "Zorn", "ge\u00b7rei\u00b7zet", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wer sagt, woher dies Ungl\u00fcck stammt?", "tokens": ["Wer", "sagt", ",", "wo\u00b7her", "dies", "Un\u00b7gl\u00fcck", "stammt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "PWAV", "PDS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Warum man hier so sehr nach Menschenblute geizet?", "tokens": ["Wa\u00b7rum", "man", "hier", "so", "sehr", "nach", "Men\u00b7schen\u00b7blu\u00b7te", "gei\u00b7zet", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "ADV", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sind Reich und Freyheit denn in Noth?", "tokens": ["Sind", "Reich", "und", "Frey\u00b7heit", "denn", "in", "Noth", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wem wird ein schwerer Fall gedroht?", "tokens": ["Wem", "wird", "ein", "schwe\u00b7rer", "Fall", "ge\u00b7droht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wer will den Kayserthron zu Grund und Boden st\u00fcrzen?", "tokens": ["Wer", "will", "den", "Kay\u00b7ser\u00b7thron", "zu", "Grund", "und", "Bo\u00b7den", "st\u00fcr\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Beschimpft man Gottes Majestet,", "tokens": ["Be\u00b7schimpft", "man", "Got\u00b7tes", "Ma\u00b7jes\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "NN", "NE", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "Da\u00df man so scharf zu Werke geht;", "tokens": ["Da\u00df", "man", "so", "scharf", "zu", "Wer\u00b7ke", "geht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADJD", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und darin Ehre sucht, das Leben zu verk\u00fcrzen?", "tokens": ["Und", "da\u00b7rin", "Eh\u00b7re", "sucht", ",", "das", "Le\u00b7ben", "zu", "ver\u00b7k\u00fcr\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "NN", "VVFIN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Ein schwacher M\u00f6nch entdeckt ein Licht;", "tokens": ["Ein", "schwa\u00b7cher", "M\u00f6nch", "ent\u00b7deckt", "ein", "Licht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sein Geist wird dadurch aufgekl\u00e4ret;", "tokens": ["Sein", "Geist", "wird", "da\u00b7durch", "auf\u00b7ge\u00b7kl\u00e4\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Er folgt ihm und verschweigt es nicht,", "tokens": ["Er", "folgt", "ihm", "und", "ver\u00b7schweigt", "es", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und zeiget es der Welt, was er dadurch erf\u00e4hret.", "tokens": ["Und", "zei\u00b7get", "es", "der", "Welt", ",", "was", "er", "da\u00b7durch", "er\u00b7f\u00e4h\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "$,", "PWS", "PPER", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Salbe die sein Lehrstuhl gab,", "tokens": ["Die", "Sal\u00b7be", "die", "sein", "Lehr\u00b7stuhl", "gab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Treibt vieler Augen Schuppen ab,", "tokens": ["Treibt", "vie\u00b7ler", "Au\u00b7gen", "Schup\u00b7pen", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wodurch das arme Volk so lange blind gewesen.", "tokens": ["Wo\u00b7durch", "das", "ar\u00b7me", "Volk", "so", "lan\u00b7ge", "blind", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "ADV", "ADV", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Er weiset die Betr\u00fcgerey,", "tokens": ["Er", "wei\u00b7set", "die", "Be\u00b7tr\u00fc\u00b7ge\u00b7rey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und was das beste Mittel sey", "tokens": ["Und", "was", "das", "bes\u00b7te", "Mit\u00b7tel", "sey"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "ART", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Von seiner Seelen Noth vollkommen zu genesen.", "tokens": ["Von", "sei\u00b7ner", "See\u00b7len", "Noth", "voll\u00b7kom\u00b7men", "zu", "ge\u00b7ne\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}}, "stanza.8": {"line.1": {"text": "So sehr der Tag den Wandersmann", "tokens": ["So", "sehr", "der", "Tag", "den", "Wan\u00b7ders\u00b7mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der in der Irre fehl gegangen,", "tokens": ["Der", "in", "der", "Ir\u00b7re", "fehl", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ermuntern und vergn\u00fcgen kann,", "tokens": ["Er\u00b7mun\u00b7tern", "und", "ver\u00b7gn\u00fc\u00b7gen", "kann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn er sein neues Licht durch Titans Glanz empfangen;", "tokens": ["Wenn", "er", "sein", "neu\u00b7es", "Licht", "durch", "Ti\u00b7tans", "Glanz", "emp\u00b7fan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So sehr nahm dieser helle Schein", "tokens": ["So", "sehr", "nahm", "die\u00b7ser", "hel\u00b7le", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Des Volkes finstre Seelen ein,", "tokens": ["Des", "Vol\u00b7kes", "finst\u00b7re", "See\u00b7len", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und trieb sie kr\u00e4ftig an, den Irrthum zu verlassen.", "tokens": ["Und", "trieb", "sie", "kr\u00e4f\u00b7tig", "an", ",", "den", "Irr\u00b7thum", "zu", "ver\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ein jeder ward dadurch ger\u00fchrt,", "tokens": ["Ein", "je\u00b7der", "ward", "da\u00b7durch", "ge\u00b7r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VAFIN", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und von der Wahrheit \u00fcberf\u00fchrt,", "tokens": ["Und", "von", "der", "Wahr\u00b7heit", "\u00fc\u00b7berf\u00b7\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Da\u00df er verbunden sey die Finsterni\u00df zu hassen.", "tokens": ["Da\u00df", "er", "ver\u00b7bun\u00b7den", "sey", "die", "Fins\u00b7ter\u00b7ni\u00df", "zu", "has\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Wer macht sich auf? wen seh ich dort?", "tokens": ["Wer", "macht", "sich", "auf", "?", "wen", "seh", "ich", "dort", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "PTKVZ", "$.", "PWS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit wem, warum, wie will er k\u00e4mpfen?", "tokens": ["Mit", "wem", ",", "wa\u00b7rum", ",", "wie", "will", "er", "k\u00e4mp\u00b7fen", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PWAV", "$,", "PWAV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wer schickt den Held? der kalte Nord,", "tokens": ["Wer", "schickt", "den", "Held", "?", "der", "kal\u00b7te", "Nord", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "$.", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Hitze soll er hier in den Verfolgern d\u00e4mpfen.", "tokens": ["Die", "Hit\u00b7ze", "soll", "er", "hier", "in", "den", "Ver\u00b7fol\u00b7gern", "d\u00e4mp\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er kommt zum Streit, und f\u00e4llt er schon,", "tokens": ["Er", "kommt", "zum", "Streit", ",", "und", "f\u00e4llt", "er", "schon", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$,", "KON", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So bleibt ihm doch die Siegeskron", "tokens": ["So", "bleibt", "ihm", "doch", "die", "Sie\u00b7ges\u00b7kron"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und uns durch seinen Tod die Freyheit und das Leben.", "tokens": ["Und", "uns", "durch", "sei\u00b7nen", "Tod", "die", "Frey\u00b7heit", "und", "das", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PPOSAT", "NN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sein Sterben r\u00e4cht so mancher Held", "tokens": ["Sein", "Ster\u00b7ben", "r\u00e4cht", "so", "man\u00b7cher", "Held"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der sich auf seine Seite stellt,", "tokens": ["Der", "sich", "auf", "sei\u00b7ne", "Sei\u00b7te", "stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und vor der L\u00e4nder Wohl sich selber hingegeben.", "tokens": ["Und", "vor", "der", "L\u00e4n\u00b7der", "Wohl", "sich", "sel\u00b7ber", "hin\u00b7ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "PRF", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Doch wird man einst des Mordens satt,", "tokens": ["Doch", "wird", "man", "einst", "des", "Mor\u00b7dens", "satt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIS", "ADV", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und durch das lange Streiten m\u00fcde,", "tokens": ["Und", "durch", "das", "lan\u00b7ge", "Strei\u00b7ten", "m\u00fc\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und was man sonst verworfen hat,", "tokens": ["Und", "was", "man", "sonst", "ver\u00b7wor\u00b7fen", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Daran gedenkt man itzt; das Absehn ist der Friede.", "tokens": ["Da\u00b7ran", "ge\u00b7denkt", "man", "itzt", ";", "das", "Ab\u00b7sehn", "ist", "der", "Frie\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIS", "ADV", "$.", "ART", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man eilt von allen Orten zu,", "tokens": ["Man", "eilt", "von", "al\u00b7len", "Or\u00b7ten", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sinnt auf die gemeine Ruh,", "tokens": ["Und", "sinnt", "auf", "die", "ge\u00b7mei\u00b7ne", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und will der Streitigkeit gemessne Schranken setzen.", "tokens": ["Und", "will", "der", "Strei\u00b7tig\u00b7keit", "ge\u00b7mess\u00b7ne", "Schran\u00b7ken", "set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "In M\u00fcnster und in Osnabr\u00fcck,", "tokens": ["In", "M\u00fcns\u00b7ter", "und", "in", "Os\u00b7na\u00b7br\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Befestigt man des Reiches Gl\u00fcck,", "tokens": ["Be\u00b7fes\u00b7tigt", "man", "des", "Rei\u00b7ches", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und weis der Deutschen Ruh nach ihrem Werth zu sch\u00e4tzen.", "tokens": ["Und", "weis", "der", "Deut\u00b7schen", "Ruh", "nach", "ih\u00b7rem", "Werth", "zu", "sch\u00e4t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Die Weisheit nimmt den Vorsitz ein", "tokens": ["Die", "Weis\u00b7heit", "nimmt", "den", "Vor\u00b7sitz", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In diesem hohen Staatsgerichte,", "tokens": ["In", "die\u00b7sem", "ho\u00b7hen", "Staats\u00b7ge\u00b7rich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und macht der Arglist falschen Schein", "tokens": ["Und", "macht", "der", "Arg\u00b7list", "fal\u00b7schen", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch Einsicht und Verstand f\u00fcr aller Welt zunichte.", "tokens": ["Durch", "Ein\u00b7sicht", "und", "Ver\u00b7stand", "f\u00fcr", "al\u00b7ler", "Welt", "zu\u00b7nich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie setzet, ordnet, und bestimmt,", "tokens": ["Sie", "set\u00b7zet", ",", "ord\u00b7net", ",", "und", "be\u00b7stimmt", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "$,", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie l\u00f6scht das Feuer das noch glimmt,", "tokens": ["Sie", "l\u00f6scht", "das", "Feu\u00b7er", "das", "noch", "glimmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und \u00fcbergiebt die Schuld dem ewigen Vergessen.", "tokens": ["Und", "\u00fc\u00b7berg\u00b7iebt", "die", "Schuld", "dem", "e\u00b7wi\u00b7gen", "Ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Hier wird durch kluger M\u00e4nner Rath", "tokens": ["Hier", "wird", "durch", "klu\u00b7ger", "M\u00e4n\u00b7ner", "Rath"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Sicherheit vor jeden Staat,", "tokens": ["Die", "Si\u00b7cher\u00b7heit", "vor", "je\u00b7den", "Staat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und das erkannte Recht vern\u00fcnftig abgemessen.", "tokens": ["Und", "das", "er\u00b7kann\u00b7te", "Recht", "ver\u00b7n\u00fcnf\u00b7tig", "ab\u00b7ge\u00b7mes\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "O Deutschland f\u00fcrchte dich nicht mehr!", "tokens": ["O", "Deutschland", "f\u00fcrch\u00b7te", "dich", "nicht", "mehr", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die Zanksucht hat die Kraft verlohren,", "tokens": ["Die", "Zank\u00b7sucht", "hat", "die", "Kraft", "ver\u00b7loh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie bebt bereits und zittert sehr,", "tokens": ["Sie", "bebt", "be\u00b7reits", "und", "zit\u00b7tert", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und h\u00f6rt das Friedenswort, so ihr den Tod geschworen.", "tokens": ["Und", "h\u00f6rt", "das", "Frie\u00b7dens\u00b7wort", ",", "so", "ihr", "den", "Tod", "ge\u00b7schwo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "ADV", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Vorsicht reicht dir ihren Schild;", "tokens": ["Die", "Vor\u00b7sicht", "reicht", "dir", "ih\u00b7ren", "Schild", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die sch\u00fctzt dich mehr als jenes Bild", "tokens": ["Die", "sch\u00fctzt", "dich", "mehr", "als", "je\u00b7nes", "Bild"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "PIAT", "KOKOM", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das Rom so lange Zeit zum Wunder aufgehoben.", "tokens": ["Das", "Rom", "so", "lan\u00b7ge", "Zeit", "zum", "Wun\u00b7der", "auf\u00b7ge\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADV", "ADJA", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Kirche wird nicht mehr gedr\u00fcckt,", "tokens": ["Die", "Kir\u00b7che", "wird", "nicht", "mehr", "ge\u00b7dr\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Kein Grenzstein durch Gewalt verr\u00fcckt,", "tokens": ["Kein", "Grenz\u00b7stein", "durch", "Ge\u00b7walt", "ver\u00b7r\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und aller Neuerung ein Riegel vorgeschoben.", "tokens": ["Und", "al\u00b7ler", "Neu\u00b7e\u00b7rung", "ein", "Rie\u00b7gel", "vor\u00b7ge\u00b7scho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Was blendet mich denn f\u00fcr ein Strahl", "tokens": ["Was", "blen\u00b7det", "mich", "denn", "f\u00fcr", "ein", "Strahl"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Prachterf\u00fcllten Kostbarkeiten?", "tokens": ["Von", "Prach\u00b7ter\u00b7f\u00fcll\u00b7ten", "Kost\u00b7bar\u00b7kei\u00b7ten", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ist dieses nicht der G\u00f6ttersaal", "tokens": ["Ist", "die\u00b7ses", "nicht", "der", "G\u00f6t\u00b7ter\u00b7saal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PDS", "PTKNEG", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wo Recht und Billigkeit den Urtheilsspruch bereiten?", "tokens": ["Wo", "Recht", "und", "Bil\u00b7lig\u00b7keit", "den", "Ur\u00b7theils\u00b7spruch", "be\u00b7rei\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer ists, von dessen treuer Hand", "tokens": ["Wer", "ists", ",", "von", "des\u00b7sen", "treu\u00b7er", "Hand"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "$,", "APPR", "PRELAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Sch\u00e4tze die er vor sich fand", "tokens": ["Die", "Sch\u00e4t\u00b7ze", "die", "er", "vor", "sich", "fand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "PPER", "APPR", "PRF", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Gesammelt und der Welt itzt dargeleget werden?", "tokens": ["Ge\u00b7sam\u00b7melt", "und", "der", "Welt", "itzt", "dar\u00b7ge\u00b7le\u00b7get", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ART", "NN", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wer hat doch hier ans Licht gebracht", "tokens": ["Wer", "hat", "doch", "hier", "ans", "Licht", "ge\u00b7bracht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "ADV", "ADV", "APPRART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Was dort die Weisheit ausgedacht,", "tokens": ["Was", "dort", "die", "Weis\u00b7heit", "aus\u00b7ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Zur Ruhe vor das Land, zur Tilgung der Beschwerden?", "tokens": ["Zur", "Ru\u00b7he", "vor", "das", "Land", ",", "zur", "Til\u00b7gung", "der", "Be\u00b7schwer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "$,", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Ein Mann, den Herz, Verstand, und Kraft", "tokens": ["Ein", "Mann", ",", "den", "Herz", ",", "Ver\u00b7stand", ",", "und", "Kraft"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "NN", "$,", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Deutschen Kindern vorgezogen:", "tokens": ["Den", "Deut\u00b7schen", "Kin\u00b7dern", "vor\u00b7ge\u00b7zo\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Mann, dem Witz und Wissenschaft", "tokens": ["Ein", "Mann", ",", "dem", "Witz", "und", "Wis\u00b7sen\u00b7schaft"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit schwerer Ueberwucht sein Antheil zugewogen.", "tokens": ["Mit", "schwe\u00b7rer", "Ue\u00b7ber\u00b7wucht", "sein", "An\u00b7theil", "zu\u00b7ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Mann, der Deutschlands Ehre liebt,", "tokens": ["Ein", "Mann", ",", "der", "Deutschlands", "Eh\u00b7re", "liebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und wenn er sich auch M\u00fche giebt", "tokens": ["Und", "wenn", "er", "sich", "auch", "M\u00fc\u00b7he", "giebt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "PRF", "ADV", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sonst keinen Lohn verlangt, als den die Tugend bringet;", "tokens": ["Sonst", "kei\u00b7nen", "Lohn", "ver\u00b7langt", ",", "als", "den", "die", "Tu\u00b7gend", "brin\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVPP", "$,", "KOUS", "ART", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ein Mann, bey dem der strenge Flei\u00df", "tokens": ["Ein", "Mann", ",", "bey", "dem", "der", "stren\u00b7ge", "Flei\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "APPR", "ART", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Von keinen Ruhestunden weis,", "tokens": ["Von", "kei\u00b7nen", "Ru\u00b7hes\u00b7tun\u00b7den", "weis", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Der keiner Arbeit schont, durch die sein Werk gelinget.", "tokens": ["Der", "kei\u00b7ner", "Ar\u00b7beit", "schont", ",", "durch", "die", "sein", "Werk", "ge\u00b7lin\u00b7get", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$,", "APPR", "PRELS", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Nun kommt und seht was f\u00fcr ein Glanz", "tokens": ["Nun", "kommt", "und", "seht", "was", "f\u00fcr", "ein", "Glanz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das auserlesne Kleinod zieret", "tokens": ["Das", "au\u00b7ser\u00b7les\u00b7ne", "Klei\u00b7nod", "zie\u00b7ret"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sein sch\u00f6ner Schmuck entz\u00fcckt uns ganz,", "tokens": ["Sein", "sch\u00f6\u00b7ner", "Schmuck", "ent\u00b7z\u00fcckt", "uns", "ganz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und zeigt die Gro\u00dfmuth an, die Meierns Sinne r\u00fchret.", "tokens": ["Und", "zeigt", "die", "Gro\u00df\u00b7muth", "an", ",", "die", "Mei\u00b7erns", "Sin\u00b7ne", "r\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hier herrscht Geschmack, Vernunft und Kunst,", "tokens": ["Hier", "herrscht", "Ge\u00b7schmack", ",", "Ver\u00b7nunft", "und", "Kunst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nicht leerer W\u00f6rter eitler Dunst,", "tokens": ["Nicht", "lee\u00b7rer", "W\u00f6r\u00b7ter", "eit\u00b7ler", "Dunst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Nein. ", "tokens": ["Nein", "."], "token_info": ["word", "punct"], "pos": ["PTKANT", "$."], "meter": "+", "measure": "single.up"}, "line.8": {"text": "Denn weil er nie dem Neide weicht,", "tokens": ["Denn", "weil", "er", "nie", "dem", "Nei\u00b7de", "weicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Kann er ein Werk dem keines gleicht,", "tokens": ["Kann", "er", "ein", "Werk", "dem", "kei\u00b7nes", "gleicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "ART", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und sich dadurch zugleich ein ewig Denkmal stiften.", "tokens": ["Und", "sich", "da\u00b7durch", "zu\u00b7gleich", "ein", "e\u00b7wig", "Denk\u00b7mal", "stif\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "PAV", "ADV", "ART", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Ganz Deutschland siehts, und wird entz\u00fcckt,", "tokens": ["Ganz", "Deutschland", "siehts", ",", "und", "wird", "ent\u00b7z\u00fcckt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "$,", "KON", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bewundert des von Meiern Gaben;", "tokens": ["Be\u00b7wun\u00b7dert", "des", "von", "Mei\u00b7ern", "Ga\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und r\u00fchmet was es hier erblickt,", "tokens": ["Und", "r\u00fch\u00b7met", "was", "es", "hier", "er\u00b7blickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PWS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sucht sein wahres Lob in Erz und Stahl zu graben.", "tokens": ["Und", "sucht", "sein", "wah\u00b7res", "Lob", "in", "Erz", "und", "Stahl", "zu", "gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN", "APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wo lebt ein solcher Deutscher Sohn", "tokens": ["Wo", "lebt", "ein", "sol\u00b7cher", "Deut\u00b7scher", "Sohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "ART", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der seiner schweren Arbeit Lohn", "tokens": ["Der", "sei\u00b7ner", "schwe\u00b7ren", "Ar\u00b7beit", "Lohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Nur in der Nutzbarkeit vor viele L\u00e4nder findet?", "tokens": ["Nur", "in", "der", "Nutz\u00b7bar\u00b7keit", "vor", "vie\u00b7le", "L\u00e4n\u00b7der", "fin\u00b7det", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Vor einen solchen grossen Sinn", "tokens": ["Vor", "ei\u00b7nen", "sol\u00b7chen", "gros\u00b7sen", "Sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Geh\u00f6rt der trefflichste Gewinn,", "tokens": ["Ge\u00b7h\u00f6rt", "der", "treff\u00b7lichs\u00b7te", "Ge\u00b7winn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und da\u00df ein ganzes Volk ihm Ehrenkr\u00e4nze windet.", "tokens": ["Und", "da\u00df", "ein", "gan\u00b7zes", "Volk", "ihm", "Eh\u00b7ren\u00b7kr\u00e4n\u00b7ze", "win\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Wie wird mir? was bezaubert mich?", "tokens": ["Wie", "wird", "mir", "?", "was", "be\u00b7zau\u00b7bert", "mich", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "$.", "PWS", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wer \u00f6ffnet die verschlossnen Gr\u00fcfte?", "tokens": ["Wer", "\u00f6ff\u00b7net", "die", "ver\u00b7schloss\u00b7nen", "Gr\u00fcf\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Welch ein Gesicht beth\u00f6ret mich", "tokens": ["Welch", "ein", "Ge\u00b7sicht", "be\u00b7th\u00f6\u00b7ret", "mich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "ART", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vielleicht ist es ein Bild der dickgemachten L\u00fcfte?", "tokens": ["Viel\u00b7leicht", "ist", "es", "ein", "Bild", "der", "dick\u00b7ge\u00b7mach\u00b7ten", "L\u00fcf\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nein, nein, es ist der theure Mann,", "tokens": ["Nein", ",", "nein", ",", "es", "ist", "der", "theu\u00b7re", "Mann", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Adami, der so viel gethan,", "tokens": ["A\u00b7da\u00b7mi", ",", "der", "so", "viel", "ge\u00b7than", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df Kayser, F\u00fcrst und Reich nach Fried und Ruhe streben.", "tokens": ["Da\u00df", "Kay\u00b7ser", ",", "F\u00fcrst", "und", "Reich", "nach", "Fried", "und", "Ru\u00b7he", "stre\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "NN", "KON", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Er geht durch Meierns Kraft herf\u00fcr:", "tokens": ["Er", "geht", "durch", "Mei\u00b7erns", "Kraft", "her\u00b7f\u00fcr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Verl\u00e4\u00dft den Staub, und zeigt sich hier,", "tokens": ["Ver\u00b7l\u00e4\u00dft", "den", "Staub", ",", "und", "zeigt", "sich", "hier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "PRF", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und f\u00e4ngt nach langer Zeit nun wieder an zu leben.", "tokens": ["Und", "f\u00e4ngt", "nach", "lan\u00b7ger", "Zeit", "nun", "wie\u00b7der", "an", "zu", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "ADV", "ADV", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Willkommen Ehrenwehrtes Haupt,", "tokens": ["Will\u00b7kom\u00b7men", "Eh\u00b7ren\u00b7wehr\u00b7tes", "Haupt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du Schutzgott der bedr\u00e4ngten Sache.", "tokens": ["Du", "Schutz\u00b7gott", "der", "be\u00b7dr\u00e4ng\u00b7ten", "Sa\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Neid hat Deinen Ruhm geraubt", "tokens": ["Der", "Neid", "hat", "Dei\u00b7nen", "Ruhm", "ge\u00b7raubt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Damit die Nachwelt noch zu Deiner Ehre wache.", "tokens": ["Da\u00b7mit", "die", "Nach\u00b7welt", "noch", "zu", "Dei\u00b7ner", "Eh\u00b7re", "wa\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dein redliches und Deutsches Blut", "tokens": ["Dein", "red\u00b7li\u00b7ches", "und", "Deut\u00b7sches", "Blut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gilt mehr als wohl dein Bischofshut,", "tokens": ["Gilt", "mehr", "als", "wohl", "dein", "Bi\u00b7schof\u00b7shut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "KOKOM", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Den deine Fr\u00f6mmigkeit und Sorgenlast verdiente.", "tokens": ["Den", "dei\u00b7ne", "Fr\u00f6m\u00b7mig\u00b7keit", "und", "Sor\u00b7gen\u00b7last", "ver\u00b7dien\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Du wiederstandest der Gefahr", "tokens": ["Du", "wie\u00b7der\u00b7stan\u00b7dest", "der", "Ge\u00b7fahr"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Dir nur \u00fcberwindlich war,", "tokens": ["Die", "Dir", "nur", "\u00fc\u00b7berw\u00b7ind\u00b7lich", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Indem durch deine Kraft des Friedens Oelzweig gr\u00fcnte.", "tokens": ["In\u00b7dem", "durch", "dei\u00b7ne", "Kraft", "des", "Frie\u00b7dens", "O\u00b7el\u00b7zweig", "gr\u00fcn\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "ART", "NN", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.19": {"line.1": {"text": "Ein Held an Muth, ein Gott an Rath,", "tokens": ["Ein", "Held", "an", "Muth", ",", "ein", "Gott", "an", "Rath", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das bist Du grosser Mann gewesen,", "tokens": ["Das", "bist", "Du", "gros\u00b7ser", "Mann", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADJA", "NN", "VAPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Heyland vor so manchen Staat,", "tokens": ["Ein", "Hey\u00b7land", "vor", "so", "man\u00b7chen", "Staat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Weil dessen krankes Gl\u00fcck, durch Deine Kunst genesen.", "tokens": ["Weil", "des\u00b7sen", "kran\u00b7kes", "Gl\u00fcck", ",", "durch", "Dei\u00b7ne", "Kunst", "ge\u00b7ne\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ADJA", "NN", "$,", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was Du sonst sprachst, das galt sehr viel,", "tokens": ["Was", "Du", "sonst", "sprachst", ",", "das", "galt", "sehr", "viel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVFIN", "$,", "PDS", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der L\u00e4nder Wohlfahrt war das Ziel", "tokens": ["Der", "L\u00e4n\u00b7der", "Wohl\u00b7fahrt", "war", "das", "Ziel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der treu gesinneten und Weisheitsvollen Spr\u00fcche.", "tokens": ["Der", "treu", "ge\u00b7sin\u00b7ne\u00b7ten", "und", "Weis\u00b7heits\u00b7vol\u00b7len", "Spr\u00fc\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVPP", "KON", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So viel man Klugheit und Verstand", "tokens": ["So", "viel", "man", "Klug\u00b7heit", "und", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PIS", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Bey jenen grossen M\u00e4nnern fand,", "tokens": ["Bey", "je\u00b7nen", "gros\u00b7sen", "M\u00e4n\u00b7nern", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So wagt es keiner doch, da\u00df er sich Dir vergliche.", "tokens": ["So", "wagt", "es", "kei\u00b7ner", "doch", ",", "da\u00df", "er", "sich", "Dir", "ver\u00b7gli\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "ADV", "$,", "KOUS", "PPER", "PRF", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Wohin verschwindet das Gesicht?", "tokens": ["Wo\u00b7hin", "ver\u00b7schwin\u00b7det", "das", "Ge\u00b7sicht", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was hindert mich, ihn mehr zu preisen?", "tokens": ["Was", "hin\u00b7dert", "mich", ",", "ihn", "mehr", "zu", "prei\u00b7sen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mein schwacher Kiel vermag es nicht", "tokens": ["Mein", "schwa\u00b7cher", "Kiel", "ver\u00b7mag", "es", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NE", "VVFIN", "PPER", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So viel als er verdient, ihm Ehre zu erweisen.", "tokens": ["So", "viel", "als", "er", "ver\u00b7dient", ",", "ihm", "Eh\u00b7re", "zu", "er\u00b7wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KOUS", "PPER", "VVPP", "$,", "PPER", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er wird von seinen Banden los,", "tokens": ["Er", "wird", "von", "sei\u00b7nen", "Ban\u00b7den", "los", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durch den ber\u00fchmten Meiern gro\u00df,", "tokens": ["Durch", "den", "be\u00b7r\u00fchm\u00b7ten", "Mei\u00b7ern", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df die Vergessenheit von seinem Namen weichet.", "tokens": ["Da\u00df", "die", "Ver\u00b7ges\u00b7sen\u00b7heit", "von", "sei\u00b7nem", "Na\u00b7men", "wei\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Gro\u00dfmuth, beyder Eigenthum,", "tokens": ["Die", "Gro\u00df\u00b7muth", ",", "bey\u00b7der", "Ei\u00b7gen\u00b7thum", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Verewigt den erworbnen Ruhm", "tokens": ["Ve\u00b7re\u00b7wigt", "den", "er\u00b7worb\u00b7nen", "Ruhm"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.10": {"text": "Durch diese hat er auch den h\u00f6chsten Grad erreichet.", "tokens": ["Durch", "die\u00b7se", "hat", "er", "auch", "den", "h\u00f6chs\u00b7ten", "Grad", "er\u00b7rei\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}