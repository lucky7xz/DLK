{"textgrid.poem.48213": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "5. Kirchenumbau", "genre": "verse", "period": "N.A.", "pub_year": 1858, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Spricht der Polier: \u00bbNu blo\u00df noch das eine:", "tokens": ["Spricht", "der", "Po\u00b7lier", ":", "\u00bb", "Nu", "blo\u00df", "noch", "das", "ei\u00b7ne", ":"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$.", "$(", "ADV", "ADV", "ADV", "ART", "ART", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Herr Schultze, wohin mit die Leichensteine?", "tokens": ["Herr", "Schult\u00b7ze", ",", "wo\u00b7hin", "mit", "die", "Lei\u00b7chen\u00b7stei\u00b7ne", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "PWAV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die meisten, wenn recht ich gelesen habe,", "tokens": ["Die", "meis\u00b7ten", ",", "wenn", "recht", "ich", "ge\u00b7le\u00b7sen", "ha\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "$,", "KOUS", "ADJD", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Waren alte Nonnen aus \u203aHeiligen Grabe\u2039.\u00ab", "tokens": ["Wa\u00b7ren", "al\u00b7te", "Non\u00b7nen", "aus", "\u203a", "Hei\u00b7li\u00b7gen", "Gra\u00b7be", "\u2039", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["VAFIN", "ADJA", "NN", "APPR", "NE", "ADJA", "NN", "$(", "$.", "$("], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "\u00bbund Ritter?\u00ab", "tokens": ["\u00bb", "und", "Rit\u00b7ter", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "NN", "$.", "$("], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.3": {"line.1": {"text": "\u00bbnu Ritter, ein St\u00fccker sieben,", "tokens": ["\u00bb", "nu", "Rit\u00b7ter", ",", "ein", "St\u00fc\u00b7cker", "sie\u00b7ben", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "NN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ich hab ihre Namens aufgeschrieben,", "tokens": ["Ich", "hab", "ih\u00b7re", "Na\u00b7mens", "auf\u00b7ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Blo\u00df, wo sie gestanden, da sind ja nu L\u00f6cher:", "tokens": ["Blo\u00df", ",", "wo", "sie", "ge\u00b7stan\u00b7den", ",", "da", "sind", "ja", "nu", "L\u00f6\u00b7cher", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "VVPP", "$,", "ADV", "VAFIN", "ADV", "ADV", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "1 Bredow, 1 Ribbeck, 2 Rohr, 3 Kr\u00f6cher,", "tokens": ["Bre\u00b7dow", ",", "1", "Rib\u00b7beck", ",", "2", "Rohr", ",", "3", "Kr\u00f6\u00b7cher", ","], "token_info": ["word", "punct", "number", "word", "punct", "number", "word", "punct", "number", "word", "punct"], "pos": ["NE", "$,", "CARD", "NN", "$,", "CARD", "NN", "$,", "CARD", "NN", "$,"], "meter": "+-+-++-", "measure": "unknown.measure.tetra"}, "line.5": {"text": "Wo soll'n wir mit hin? wo soll ich sie stell'n? \u00ab", "tokens": ["Wo", "soll'n", "wir", "mit", "hin", "?", "wo", "soll", "ich", "sie", "stell'n", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "APPR", "PTKVZ", "$.", "PWAV", "VMFIN", "PPER", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "\u00bbstellen? Nu gar nich. Das gibt gute Schwelln,", "tokens": ["\u00bb", "stel\u00b7len", "?", "Nu", "gar", "nich", ".", "Das", "gibt", "gu\u00b7te", "Schwelln", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVINF", "$.", "ADV", "ADV", "PTKNEG", "$.", "PDS", "VVFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Schwellen f\u00fcr Stall und Stuterei,", "tokens": ["Schwel\u00b7len", "f\u00fcr", "Stall", "und", "Stu\u00b7te\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Da freun sich die Junkers noch dabei.\u00ab", "tokens": ["Da", "freun", "sich", "die", "Jun\u00b7kers", "noch", "da\u00b7bei", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "ADV", "PAV", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "\u00bbund denn, Herr Schultze, dicht \u00fcberm Altar", "tokens": ["\u00bb", "und", "denn", ",", "Herr", "Schult\u00b7ze", ",", "dicht", "\u00fc\u00b7berm", "Al\u00b7tar"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "KON", "ADV", "$,", "NN", "NN", "$,", "ADJD", "APPRART", "NN"], "meter": "-+-+-+---+", "measure": "zehnsilber"}, "line.2": {"text": "Noch so was vergoldigt Kattolsches war,", "tokens": ["Noch", "so", "was", "ver\u00b7gol\u00b7digt", "Kat\u00b7tol\u00b7sches", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PWS", "VVFIN", "NE", "VAFIN", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Maria mit Christkind ... Es war doch ein Jammer.\u00ab", "tokens": ["Ma\u00b7ria", "mit", "Christ\u00b7kind", "...", "Es", "war", "doch", "ein", "Jam\u00b7mer", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "APPR", "NN", "$(", "PPER", "VAFIN", "ADV", "ART", "NN", "$.", "$("], "meter": "-+-++-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "\u00bbversteht sich. In die Rumpelkammer!\u00ab", "tokens": ["\u00bb", "ver\u00b7steht", "sich", ".", "In", "die", "Rum\u00b7pel\u00b7kam\u00b7mer", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PRF", "$.", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}