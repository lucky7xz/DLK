{"textgrid.poem.53821": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Was brauchen wir \u2013?", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als falsche Extrabl\u00e4tter riefen,", "tokens": ["Als", "fal\u00b7sche", "Ext\u00b7ra\u00b7bl\u00e4t\u00b7ter", "rie\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "da traten wir in Reihen an;", "tokens": ["da", "tra\u00b7ten", "wir", "in", "Rei\u00b7hen", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und schrieben nur in Feldpostbriefen,", "tokens": ["und", "schrie\u00b7ben", "nur", "in", "Feld\u00b7post\u00b7brie\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "was man doch laut nicht sagen kann.", "tokens": ["was", "man", "doch", "laut", "nicht", "sa\u00b7gen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "ADV", "ADJD", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gewi\u00df, wir waren Sozialisten", "tokens": ["Ge\u00b7wi\u00df", ",", "wir", "wa\u00b7ren", "So\u00b7zi\u00b7a\u00b7lis\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "(nach innen); in den Kompanien", "tokens": ["(", "nach", "in\u00b7nen", ")", ";", "in", "den", "Kom\u00b7pa\u00b7ni\u00b7en"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "APPR", "ADV", "$(", "$.", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "gabs keine bessern Infanteristen \u2013", "tokens": ["gabs", "kei\u00b7ne", "bes\u00b7sern", "In\u00b7fan\u00b7te\u00b7ris\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "aus Disziplin.", "tokens": ["aus", "Dis\u00b7zip\u00b7lin", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Als Noskes L\u00fcmmel Blut vergossen,", "tokens": ["Als", "Nos\u00b7kes", "L\u00fcm\u00b7mel", "Blut", "ver\u00b7gos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NE", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "da schwenkten wir in Reihen ein;", "tokens": ["da", "schwenk\u00b7ten", "wir", "in", "Rei\u00b7hen", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "gewi\u00df: da lagen die Genossen \u2013", "tokens": ["ge\u00b7wi\u00df", ":", "da", "la\u00b7gen", "die", "Ge\u00b7nos\u00b7sen", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ADV", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "wir drohten tapfer \u00fcbern Rhein.", "tokens": ["wir", "droh\u00b7ten", "tap\u00b7fer", "\u00fc\u00b7bern", "Rhein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "VVFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn sie den Klassenkampf verpfuschten,", "tokens": ["Wenn", "sie", "den", "Klas\u00b7sen\u00b7kampf", "ver\u00b7pfuschten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "auf ihren Sesseln in Berlin \u2013:", "tokens": ["auf", "ih\u00b7ren", "Ses\u00b7seln", "in", "Ber\u00b7lin", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NE", "$(", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "dann hielten wir das Maul und kuschten", "tokens": ["dann", "hiel\u00b7ten", "wir", "das", "Maul", "und", "kuschten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "aus Disziplin.", "tokens": ["aus", "Dis\u00b7zip\u00b7lin", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Hat Hermann M\u00fcller uns verraten,", "tokens": ["Hat", "Her\u00b7mann", "M\u00fcl\u00b7ler", "uns", "ver\u00b7ra\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NE", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "hat Onkel H\u00f6rsing falschen Tritt,", "tokens": ["hat", "On\u00b7kel", "H\u00f6r\u00b7sing", "fal\u00b7schen", "Tritt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "sind wir von Richtern und Soldaten", "tokens": ["sind", "wir", "von", "Rich\u00b7tern", "und", "Sol\u00b7da\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "zerstampft \u2013", "tokens": ["zer\u00b7stampft", "\u2013"], "token_info": ["word", "punct"], "pos": ["VVPP", "$("], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "wir machen immer mit.", "tokens": ["wir", "ma\u00b7chen", "im\u00b7mer", "mit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "So werden wir nach drei\u00dfig Jahren,", "tokens": ["So", "wer\u00b7den", "wir", "nach", "drei\u00b7\u00dfig", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "besiegt, blamiert, verhaun, verschrien,", "tokens": ["be\u00b7siegt", ",", "bla\u00b7miert", ",", "ver\u00b7haun", ",", "ver\u00b7schri\u00b7en", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVPP", "$,", "VVFIN", "$,", "VVINF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "getreulich in die Grube fahren.", "tokens": ["ge\u00b7treu\u00b7lich", "in", "die", "Gru\u00b7be", "fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Aus Disziplin.", "tokens": ["Aus", "Dis\u00b7zip\u00b7lin", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Aus Disziplin.", "tokens": ["Aus", "Dis\u00b7zip\u00b7lin", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}