{"textgrid.poem.52850": {"metadata": {"author": {"name": "Eichrodt, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "1L: Nun h\u00f6ret, wie geschehen", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nun h\u00f6ret, wie geschehen", "tokens": ["Nun", "h\u00f6\u00b7ret", ",", "wie", "ge\u00b7sche\u00b7hen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "PWAV", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Tod des Ariovist,", "tokens": ["Der", "Tod", "des", "A\u00b7rio\u00b7vist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Den Niemand hat gesehen", "tokens": ["Den", "Nie\u00b7mand", "hat", "ge\u00b7se\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PIS", "VAFIN", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und doch passiret ist.", "tokens": ["Und", "doch", "pas\u00b7si\u00b7ret", "ist", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "VAFIN", "$."], "meter": "--+-+-", "measure": "anapaest.init"}}, "stanza.2": {"line.1": {"text": "Es ritt in stillem Zoren", "tokens": ["Es", "ritt", "in", "stil\u00b7lem", "Zo\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Held, gem\u00e4chlich faul,", "tokens": ["Der", "Held", ",", "ge\u00b7m\u00e4ch\u00b7lich", "faul", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ohn' Sattel, Zaum und Sporen", "tokens": ["Ohn'", "Sat\u00b7tel", ",", "Zaum", "und", "Spo\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auf seinem Schwabengaul.", "tokens": ["Auf", "sei\u00b7nem", "Schwa\u00b7ben\u00b7gaul", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Auf einer R\u00f6merheerstra\u00df,", "tokens": ["Auf", "ei\u00b7ner", "R\u00f6\u00b7mer\u00b7heer\u00b7stra\u00df", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die fest und bucklig war,", "tokens": ["Die", "fest", "und", "buck\u00b7lig", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Begegnet von der Querga\u00df", "tokens": ["Be\u00b7geg\u00b7net", "von", "der", "Quer\u00b7ga\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ihm ein verlaufnes Paar.", "tokens": ["Ihm", "ein", "ver\u00b7lauf\u00b7nes", "Paar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Es waren alte R\u00f6mer,", "tokens": ["Es", "wa\u00b7ren", "al\u00b7te", "R\u00f6\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ein J\u00fcngling und ein Mann,", "tokens": ["Ein", "J\u00fcng\u00b7ling", "und", "ein", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Denn ihnen war's bequemer,", "tokens": ["Denn", "ih\u00b7nen", "wa\u00b7r's", "be\u00b7que\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Zu lotteln hinten dran.", "tokens": ["Zu", "lot\u00b7teln", "hin\u00b7ten", "dran", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Vermuthlich Marodierer", "tokens": ["Ver\u00b7muth\u00b7lich", "Ma\u00b7ro\u00b7die\u00b7rer"], "token_info": ["word", "word"], "pos": ["ADJD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Von C\u00e4sars wildem Heer,", "tokens": ["Von", "C\u00e4\u00b7sars", "wil\u00b7dem", "Heer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Spaniolen oder Syrer,", "tokens": ["Spa\u00b7ni\u00b7o\u00b7len", "o\u00b7der", "Sy\u00b7rer", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Man wei\u00df es halt nicht mehr.", "tokens": ["Man", "wei\u00df", "es", "halt", "nicht", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Da wollte vor dem K\u00f6nig", "tokens": ["Da", "woll\u00b7te", "vor", "dem", "K\u00f6\u00b7nig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Das Paar den Hut nicht ziehn,", "tokens": ["Das", "Paar", "den", "Hut", "nicht", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das \u00e4rgert ihn nicht wenig,", "tokens": ["Das", "\u00e4r\u00b7gert", "ihn", "nicht", "we\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Macht ganz berserkert ihn.", "tokens": ["Macht", "ganz", "ber\u00b7ser\u00b7kert", "ihn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVFIN", "PPER", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.7": {"line.1": {"text": "Er ruft mit H\u00fcnenstimme", "tokens": ["Er", "ruft", "mit", "H\u00fc\u00b7nens\u00b7tim\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Das Kinzigthal entlang,", "tokens": ["Das", "Kin\u00b7zig\u00b7thal", "ent\u00b7lang", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Inde\u00df er hoch im Grimme", "tokens": ["In\u00b7de\u00df", "er", "hoch", "im", "Grim\u00b7me"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Kugelkeule schwang.", "tokens": ["Die", "Ku\u00b7gel\u00b7keu\u00b7le", "schwang", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Ich sag' Euch, machet linksum!", "tokens": ["Ich", "sag'", "Euch", ",", "ma\u00b7chet", "link\u00b7sum", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "VVFIN", "ADV", "$."], "meter": "-+-+---", "measure": "unknown.measure.di"}, "line.2": {"text": "Die Keul' ist spiegelglatt", "tokens": ["Die", "Keul'", "ist", "spie\u00b7gel\u00b7glatt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und rund, und dennoch ringsum", "tokens": ["Und", "rund", ",", "und", "den\u00b7noch", "ring\u00b7sum"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJD", "$,", "KON", "ADV", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Scharf, wie man Messer hat:", "tokens": ["Scharf", ",", "wie", "man", "Mes\u00b7ser", "hat", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PIS", "NN", "VAFIN", "$."], "meter": "++-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Wie Messer zum Rasiren!", "tokens": ["Wie", "Mes\u00b7ser", "zum", "Ra\u00b7si\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPRART", "NN", "$."], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.2": {"text": "Merkw\u00fcrdig! Wo man sucht", "tokens": ["Merk\u00b7w\u00fcr\u00b7dig", "!", "Wo", "man", "sucht"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADJD", "$.", "PWAV", "PIS", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Fl\u00e4che zu ber\u00fchren,", "tokens": ["Die", "Fl\u00e4\u00b7che", "zu", "be\u00b7r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da schneidet sie verflucht!", "tokens": ["Da", "schnei\u00b7det", "sie", "ver\u00b7flucht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Ich warne euch im Guten,", "tokens": ["Ich", "war\u00b7ne", "euch", "im", "Gu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Man siehts dem Ding nicht an,", "tokens": ["Man", "siehts", "dem", "Ding", "nicht", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ART", "NN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wollt Ihr euch nicht sputen,", "tokens": ["Und", "wollt", "Ihr", "euch", "nicht", "spu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So seid ihr \u00fcbel dran!", "tokens": ["So", "seid", "ihr", "\u00fc\u00b7bel", "dran", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Doch hatten f\u00fcr die Mahnung", "tokens": ["Doch", "hat\u00b7ten", "f\u00fcr", "die", "Mah\u00b7nung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Kerle kein Geh\u00f6r,", "tokens": ["Die", "Ker\u00b7le", "kein", "Ge\u00b7h\u00f6r", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und aus des Mauls Verzahnung", "tokens": ["Und", "aus", "des", "Mauls", "Ver\u00b7za\u00b7hnung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Verspotten sie ihn sehr.", "tokens": ["Ver\u00b7spot\u00b7ten", "sie", "ihn", "sehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Da holt er aus zum Hiebe", "tokens": ["Da", "holt", "er", "aus", "zum", "Hie\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und schl\u00e4gt den Ersten, fein", "tokens": ["Und", "schl\u00e4gt", "den", "Ers\u00b7ten", ",", "fein"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wie eine alte R\u00fcbe,", "tokens": ["Wie", "ei\u00b7ne", "al\u00b7te", "R\u00fc\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "In Erzgrundboden 'nein.", "tokens": ["In", "Erz\u00b7grund\u00b7bo\u00b7den", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.13": {"line.1": {"text": "Der Zweite gleich vor Schrecken", "tokens": ["Der", "Zwei\u00b7te", "gleich", "vor", "Schre\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Stirbt auf dem Platz und spricht:", "tokens": ["Stirbt", "auf", "dem", "Platz", "und", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Vom Ro\u00df und von dem Recken", "tokens": ["Vom", "Ro\u00df", "und", "von", "dem", "Re\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Seh' ich die Bohne nicht!", "tokens": ["Seh'", "ich", "die", "Boh\u00b7ne", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Ja, wie die Barden melden,", "tokens": ["Ja", ",", "wie", "die", "Bar\u00b7den", "mel\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PWAV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So fuhr die Keule noch", "tokens": ["So", "fuhr", "die", "Keu\u00b7le", "noch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mitsammt der Faust des Helden", "tokens": ["Mit\u00b7sammt", "der", "Faust", "des", "Hel\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hinunter in das Loch.", "tokens": ["Hin\u00b7un\u00b7ter", "in", "das", "Loch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Es war die Wucht zu grimmig,", "tokens": ["Es", "war", "die", "Wucht", "zu", "grim\u00b7mig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Aus Unvorsichtigkeit!", "tokens": ["Aus", "Un\u00b7vor\u00b7sich\u00b7tig\u00b7keit", "!"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "H\u00f6rt, h\u00f6ret, was einstimmig,", "tokens": ["H\u00f6rt", ",", "h\u00f6\u00b7ret", ",", "was", "ein\u00b7stim\u00b7mig", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "PRELS", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Berichteten die Leut!", "tokens": ["Be\u00b7rich\u00b7te\u00b7ten", "die", "Leut", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Es ri\u00df der Hieb hinabe", "tokens": ["Es", "ri\u00df", "der", "Hieb", "hi\u00b7na\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Den Reiter und sein Ro\u00df,", "tokens": ["Den", "Rei\u00b7ter", "und", "sein", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und lagen sie im Grabe,", "tokens": ["Und", "la\u00b7gen", "sie", "im", "Gra\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das wieder schnell sich schlo\u00df.", "tokens": ["Das", "wie\u00b7der", "schnell", "sich", "schlo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADJD", "PRF", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Der Held nicht konnt' es wehren,", "tokens": ["Der", "Held", "nicht", "konnt'", "es", "weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zu gro\u00df war seine Kraft,", "tokens": ["Zu", "gro\u00df", "war", "sei\u00b7ne", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit Besen konnte kehren", "tokens": ["Mit", "Be\u00b7sen", "konn\u00b7te", "keh\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Man auf der Schneelandschaft.", "tokens": ["Man", "auf", "der", "Schnee\u00b7land\u00b7schaft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Jedoch die scharfe Keule", "tokens": ["Je\u00b7doch", "die", "schar\u00b7fe", "Keu\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "---+-+-", "measure": "unknown.measure.di"}, "line.2": {"text": "Lag jetzt im Boden und", "tokens": ["Lag", "jetzt", "im", "Bo\u00b7den", "und"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "APPRART", "NN", "KON"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Schnitt in der langen Weile", "tokens": ["Schnitt", "in", "der", "lan\u00b7gen", "Wei\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bis heute durch den Grund.", "tokens": ["Bis", "heu\u00b7te", "durch", "den", "Grund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Man fand die mehrgenannte", "tokens": ["Man", "fand", "die", "mehr\u00b7ge\u00b7nann\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Am Strand Amerika's -", "tokens": ["Am", "Strand", "A\u00b7me\u00b7ri\u00b7ka's"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "NE", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Deutscher sie erkannte,", "tokens": ["Ein", "Deut\u00b7scher", "sie", "er\u00b7kann\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der j\u00fcngst im C\u00e4sar las.", "tokens": ["Der", "j\u00fcngst", "im", "C\u00e4\u00b7sar", "las", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPRART", "NE", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "So wollte ich euch singen,", "tokens": ["So", "woll\u00b7te", "ich", "euch", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und wollte sagen euch", "tokens": ["Und", "woll\u00b7te", "sa\u00b7gen", "euch"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VMFIN", "VVINF", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Vom ersten, nicht geringen", "tokens": ["Vom", "ers\u00b7ten", ",", "nicht", "ge\u00b7rin\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["APPRART", "ADJA", "$,", "PTKNEG", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Genie- und Schwabenstreich.", "tokens": ["Ge\u00b7ni\u00b7e", "und", "Schwa\u00b7ben\u00b7streich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}}}}