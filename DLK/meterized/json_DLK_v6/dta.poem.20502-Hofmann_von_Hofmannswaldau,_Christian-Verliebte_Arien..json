{"dta.poem.20502": {"metadata": {"author": {"name": "Hofmann von Hofmannswaldau, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Verliebte Arien.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1695", "urn": "urn:nbn:de:kobv:b4-200905197751", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Flora deine rosen-wangen/", "tokens": ["Flo\u00b7ra", "dei\u00b7ne", "ro\u00b7sen\u00b7wan\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der beseelten liljen-schaar/", "tokens": ["Der", "be\u00b7seel\u00b7ten", "lil\u00b7jen\u00b7schaar", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die auff allen gliedern prangen/", "tokens": ["Die", "auff", "al\u00b7len", "glie\u00b7dern", "pran\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PIAT", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und das gold-geflammte haar/", "tokens": ["Und", "das", "gold\u00b7ge\u00b7flamm\u00b7te", "haar", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sind die kr\u00e4fften-reiche sachen/", "tokens": ["Sind", "die", "kr\u00e4ff\u00b7ten\u00b7rei\u00b7che", "sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "So mich dir zum sclaven machen.", "tokens": ["So", "mich", "dir", "zum", "scla\u00b7ven", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PPER", "APPRART", "ADJA", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Was ein engel sch\u00f6nes heget/", "tokens": ["Was", "ein", "en\u00b7gel", "sch\u00f6\u00b7nes", "he\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ADJA", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat die g\u00fcnstige natur", "tokens": ["Hat", "die", "g\u00fcns\u00b7ti\u00b7ge", "na\u00b7tur"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dir fast zweyfach beygeleget/", "tokens": ["Dir", "fast", "zwey\u00b7fach", "bey\u00b7ge\u00b7le\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber di\u00df beseuffz\u2019 ich nur/", "tokens": ["A\u00b7ber", "di\u00df", "be\u00b7seuff\u00b7z'", "ich", "nur", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PPER", "ADV", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "Da\u00df so ungemeine gaben", "tokens": ["Da\u00df", "so", "un\u00b7ge\u00b7mei\u00b7ne", "ga\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADJA", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Grausamkeit zur schwester haben.", "tokens": ["Grau\u00b7sam\u00b7keit", "zur", "schwes\u00b7ter", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "ADJA", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Deiner augen reine kertzen", "tokens": ["Dei\u00b7ner", "au\u00b7gen", "rei\u00b7ne", "kert\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind umsonst nicht schwartz gemacht/", "tokens": ["Sind", "um\u00b7sonst", "nicht", "schwartz", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "ADJD", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sie betrauren tausend hertzen/", "tokens": ["Sie", "be\u00b7trau\u00b7ren", "tau\u00b7send", "hert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die ihr plitz hat umgebracht;", "tokens": ["Die", "ihr", "plitz", "hat", "um\u00b7ge\u00b7bracht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und wer wei\u00df wie lang es w\u00e4hret/", "tokens": ["Und", "wer", "wei\u00df", "wie", "lang", "es", "w\u00e4h\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "KOKOM", "ADJD", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df auch mich ihr strahl verzehret.", "tokens": ["Da\u00df", "auch", "mich", "ihr", "strahl", "ver\u00b7zeh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Darum/ angenehme seele/", "tokens": ["Da\u00b7rum", "/", "an\u00b7ge\u00b7neh\u00b7me", "see\u00b7le", "/"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PAV", "$(", "ADJA", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Spare doch der worte krafft/", "tokens": ["Spa\u00b7re", "doch", "der", "wor\u00b7te", "krafft", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach verschleu\u00df die purpur-h\u00f6le/", "tokens": ["Ach", "ver\u00b7schleu\u00df", "die", "pur\u00b7pur\u00b7h\u00f6le", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn ein blick hat gleiche macht/", "tokens": ["Denn", "ein", "blick", "hat", "glei\u00b7che", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJA", "VVFIN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und wo blicke k\u00f6nnen t\u00f6dten/", "tokens": ["Und", "wo", "bli\u00b7cke", "k\u00f6n\u00b7nen", "t\u00f6d\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da sind worte nicht von n\u00f6then.", "tokens": ["Da", "sind", "wor\u00b7te", "nicht", "von", "n\u00f6\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "PTKNEG", "APPR", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Doch ich la\u00df es mir gefallen/", "tokens": ["Doch", "ich", "la\u00df", "es", "mir", "ge\u00b7fal\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PPER", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ob mich deines mundes krafft/", "tokens": ["Ob", "mich", "dei\u00b7nes", "mun\u00b7des", "krafft", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Oder auch die feuer-ballen", "tokens": ["O\u00b7der", "auch", "die", "feu\u00b7er\u00b7bal\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Deiner augen hingerafft/", "tokens": ["Dei\u00b7ner", "au\u00b7gen", "hin\u00b7ge\u00b7rafft", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn mich nur vor allen dingen/", "tokens": ["Wenn", "mich", "nur", "vor", "al\u00b7len", "din\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PIAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Flora w\u00fcrdigt umzubringen.", "tokens": ["Flo\u00b7ra", "w\u00fcr\u00b7digt", "um\u00b7zu\u00b7brin\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}