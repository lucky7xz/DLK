{"textgrid.poem.25575": {"metadata": {"author": {"name": "Goeckingk, Leopold Friedrich G\u00fcnther von", "birth": "N.A.", "death": "N.A."}, "title": "1L: In einem Saal', wo Affen, Papageyn,", "genre": "verse", "period": "N.A.", "pub_year": 1788, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In einem Saal', wo Affen, Papageyn,", "tokens": ["In", "ei\u00b7nem", "Saal'", ",", "wo", "Af\u00b7fen", ",", "Pa\u00b7pa\u00b7geyn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PWAV", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und V\u00f6gel aller Art, zur Lust des F\u00fcrsten sa\u00dfen,", "tokens": ["Und", "V\u00f6\u00b7gel", "al\u00b7ler", "Art", ",", "zur", "Lust", "des", "F\u00fcrs\u00b7ten", "sa\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PIAT", "NN", "$,", "APPRART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sperrt man auch einen Sprosser ein.", "tokens": ["Sperrt", "man", "auch", "ei\u00b7nen", "Spros\u00b7ser", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die V\u00f6gel lachen, schwatzen, spa\u00dfen,", "tokens": ["Die", "V\u00f6\u00b7gel", "la\u00b7chen", ",", "schwat\u00b7zen", ",", "spa\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der Sprosser nur mischt nie sich mit hinein.", "tokens": ["Der", "Spros\u00b7ser", "nur", "mischt", "nie", "sich", "mit", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "ADV", "PRF", "APPR", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Drob wundert sich ein Cacadoux;", "tokens": ["Drob", "wun\u00b7dert", "sich", "ein", "Ca\u00b7ca\u00b7doux", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die Neugier plagt ihn, nachzufragen.", "tokens": ["Die", "Neu\u00b7gier", "plagt", "ihn", ",", "nach\u00b7zu\u00b7fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "\u00bbwas fehlt denn dir? du h\u00f6rst nur immer zu?", "tokens": ["\u00bb", "was", "fehlt", "denn", "dir", "?", "du", "h\u00f6rst", "nur", "im\u00b7mer", "zu", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "KON", "PPER", "$.", "PPER", "VVFIN", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Beliebt dir's nicht, einmal zu schlagen?", "tokens": ["Be\u00b7liebt", "dir's", "nicht", ",", "ein\u00b7mal", "zu", "schla\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PTKNEG", "$,", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Kurzweile gibt's doch hier genug,", "tokens": ["Kurz\u00b7wei\u00b7le", "gibt's", "doch", "hier", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Auch l\u00e4\u00dft es ja der F\u00fcrst an Futter uns nicht fehlen;", "tokens": ["Auch", "l\u00e4\u00dft", "es", "ja", "der", "F\u00fcrst", "an", "Fut\u00b7ter", "uns", "nicht", "feh\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "APPR", "NN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und doch mit Langerweil' am Hofe sich zu qu\u00e4len!", "tokens": ["Und", "doch", "mit", "Lan\u00b7ger\u00b7weil'", "am", "Ho\u00b7fe", "sich", "zu", "qu\u00e4\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "APPRART", "NN", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Sehr Sonderbar!\u00ab", "tokens": ["Sehr", "Son\u00b7der\u00b7bar", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct"], "pos": ["ADV", "NN", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.14": {"text": "Drum ist er auch nicht klug!", "tokens": ["Drum", "ist", "er", "auch", "nicht", "klug", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.15": {"text": "(lacht hier dem Cacadoux ein Aeffchen in die Ohren;)", "tokens": ["(", "lacht", "hier", "dem", "Ca\u00b7ca\u00b7doux", "ein", "A\u00b7ef\u00b7fchen", "in", "die", "Oh\u00b7ren", ";)"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "emoticon"], "pos": ["$(", "VVFIN", "ADV", "ART", "NN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}, "line.16": {"text": "Die Stimm' hat er dazu verloren,", "tokens": ["Die", "Stimm'", "hat", "er", "da\u00b7zu", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PAV", "VVPP", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.17": {"text": "Sonst pfiff' er uns gewi\u00df genug,", "tokens": ["Sonst", "pfiff'", "er", "uns", "ge\u00b7wi\u00df", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Man kennt ja sonst die Eitelkeit der Thoren.", "tokens": ["Man", "kennt", "ja", "sonst", "die", "Ei\u00b7tel\u00b7keit", "der", "Tho\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Nein, sprach der Sprosser, guter Cacadoux!", "tokens": ["Nein", ",", "sprach", "der", "Spros\u00b7ser", ",", "gu\u00b7ter", "Ca\u00b7ca\u00b7doux", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "ART", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Possierlichkeiten, und in einem Nu", "tokens": ["Pos\u00b7sier\u00b7lich\u00b7kei\u00b7ten", ",", "und", "in", "ei\u00b7nem", "Nu"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "KON", "APPR", "ART", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Von Tausend Dingen schwatzen, sind ein eigen", "tokens": ["Von", "Tau\u00b7send", "Din\u00b7gen", "schwat\u00b7zen", ",", "sind", "ein", "ei\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "CARD", "NN", "VVINF", "$,", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Talent! Der Affe springe, schimpfe du!", "tokens": ["Ta\u00b7lent", "!", "Der", "Af\u00b7fe", "sprin\u00b7ge", ",", "schimp\u00b7fe", "du", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "ART", "NN", "VVFIN", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Allein f\u00fcr mich geziemt sich's hier \u2013 zu schweigen.", "tokens": ["Al\u00b7lein", "f\u00fcr", "mich", "ge\u00b7ziemt", "sich's", "hier", "\u2013", "zu", "schwei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "VVFIN", "PIS", "ADV", "$(", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "Und die Moral, H\u00f6flinge, denkt hinzu.", "tokens": ["Und", "die", "Mo\u00b7ral", ",", "H\u00f6f\u00b7lin\u00b7ge", ",", "denkt", "hin\u00b7zu", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "NN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}