{"dta.poem.12798": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Auf einen, der zu Wittenberg  \n  Magister  wurde.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1710", "urn": "urn:nbn:de:kobv:b4-20284-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wjr wallen, Edler Freund! in gar betr\u00fcbten zeiten.", "tokens": ["Wjr", "wal\u00b7len", ",", "Ed\u00b7ler", "Freund", "!", "in", "gar", "be\u00b7tr\u00fcb\u00b7ten", "zei\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "$,", "ADJA", "NN", "$.", "APPR", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was haben wir nicht schon vor \u00fcppigkeit erlebt?", "tokens": ["Was", "ha\u00b7ben", "wir", "nicht", "schon", "vor", "\u00fcp\u00b7pig\u00b7keit", "er\u00b7lebt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PTKNEG", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dort will ein sonderling des H\u00f6chsten wort bestreiten,", "tokens": ["Dort", "will", "ein", "son\u00b7der\u00b7ling", "des", "H\u00f6chs\u00b7ten", "wort", "be\u00b7strei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dieweil es seinem stoltz und frevel widerstrebt:", "tokens": ["Die\u00b7weil", "es", "sei\u00b7nem", "stoltz", "und", "fre\u00b7vel", "wi\u00b7der\u00b7strebt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Hier will ein flatter-geist bis in den himmel fliegen,", "tokens": ["Hier", "will", "ein", "flat\u00b7ter\u00b7geist", "bis", "in", "den", "him\u00b7mel", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "APPR", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und sieht nicht, da\u00df er sich grad\u2019 in die h\u00f6lle st\u00fcrtzt.", "tokens": ["Und", "sieht", "nicht", ",", "da\u00df", "er", "sich", "grad'", "in", "die", "h\u00f6l\u00b7le", "st\u00fcrtzt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$,", "KOUS", "PPER", "PRF", "ADV", "APPR", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Insonderheit will itzt der schwarm der sp\u00f6tter siegen,", "tokens": ["In\u00b7son\u00b7der\u00b7heit", "will", "itzt", "der", "schwarm", "der", "sp\u00f6t\u00b7ter", "sie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADV", "ART", "ADJD", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der, was er redt und schreibt, mit gifft und galle w\u00fcrtzt.", "tokens": ["Der", ",", "was", "er", "redt", "und", "schreibt", ",", "mit", "gifft", "und", "gal\u00b7le", "w\u00fcrtzt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PWS", "PPER", "VVFIN", "KON", "VVFIN", "$,", "APPR", "NN", "KON", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Die klugheit, so ihn f\u00fchrt, durchst\u00f6ret alle h\u00e4user.", "tokens": ["Die", "klug\u00b7heit", ",", "so", "ihn", "f\u00fchrt", ",", "durchs\u00b7t\u00f6\u00b7ret", "al\u00b7le", "h\u00e4u\u00b7ser", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PPER", "VVFIN", "$,", "VVFIN", "PIS", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die tempel bleiben nicht von seiner wut verschont.", "tokens": ["Die", "tem\u00b7pel", "blei\u00b7ben", "nicht", "von", "sei\u00b7ner", "wut", "ver\u00b7schont", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hier gilt kein ansehn mehr, er macht sich selbst an K\u00e4yser,", "tokens": ["Hier", "gilt", "kein", "an\u00b7sehn", "mehr", ",", "er", "macht", "sich", "selbst", "an", "K\u00e4y\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "PRF", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und endlich gar an den, der in dem himmel wohnt.", "tokens": ["Und", "end\u00b7lich", "gar", "an", "den", ",", "der", "in", "dem", "him\u00b7mel", "wohnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPR", "ART", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Deswegen darff es uns mit nichten wunder nehmen,", "tokens": ["Des\u00b7we\u00b7gen", "darff", "es", "uns", "mit", "nich\u00b7ten", "wun\u00b7der", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "PRF", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn diese schlangen-zucht auch in dem Pindus w\u00fchlt:", "tokens": ["Wenn", "die\u00b7se", "schlan\u00b7gen\u00b7zucht", "auch", "in", "dem", "Pin\u00b7dus", "w\u00fchlt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "VVFIN", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn diese sp\u00f6tter sich nicht vor den Musen sch\u00e4men,", "tokens": ["Wenn", "die\u00b7se", "sp\u00f6t\u00b7ter", "sich", "nicht", "vor", "den", "Mu\u00b7sen", "sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "ADJA", "PRF", "PTKNEG", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ihr entbrannter grimm sich an den lorbeern k\u00fchlt.", "tokens": ["Und", "ihr", "ent\u00b7brann\u00b7ter", "grimm", "sich", "an", "den", "lor\u00b7beern", "k\u00fchlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PRF", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Du weist, Gelehrter Freund! wie man den crantz verh\u00f6net,", "tokens": ["Du", "weist", ",", "Ge\u00b7lehr\u00b7ter", "Freund", "!", "wie", "man", "den", "crantz", "ver\u00b7h\u00f6\u00b7net", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NN", "NN", "$.", "PWAV", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Womit der weisheit hand den klugen flei\u00df bedenckt.", "tokens": ["Wo\u00b7mit", "der", "weis\u00b7heit", "hand", "den", "klu\u00b7gen", "flei\u00df", "be\u00b7denckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Womit itzt Leucoris die werthen s\u00f6hne er\u00f6net,", "tokens": ["Wo\u00b7mit", "itzt", "Leu\u00b7co\u00b7ris", "die", "wert\u00b7hen", "s\u00f6h\u00b7ne", "e\u00b7r\u00f6\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NE", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "So ihre beste zeit der wissenschafft geschenckt.", "tokens": ["So", "ih\u00b7re", "bes\u00b7te", "zeit", "der", "wis\u00b7sen\u00b7schafft", "ge\u00b7schenckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Doch wie der sonnen licht wol ohne flecken bleibet,", "tokens": ["Doch", "wie", "der", "son\u00b7nen", "licht", "wol", "oh\u00b7ne", "fle\u00b7cken", "blei\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn ihr gleich jener thor mit tausend pfeilen dr\u00e4ut:", "tokens": ["Wenn", "ihr", "gleich", "je\u00b7ner", "thor", "mit", "tau\u00b7send", "pfei\u00b7len", "dr\u00e4ut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PDAT", "NN", "APPR", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein wohlgepflantztes reis auch gar erw\u00fcnscht bekleibet,", "tokens": ["Ein", "wohl\u00b7ge\u00b7pflantz\u00b7tes", "reis", "auch", "gar", "er\u00b7w\u00fcnscht", "be\u00b7klei\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADV", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn schon die spinn\u2019 ihr gifft an seine bl\u00e4tter speyt;", "tokens": ["Wenn", "schon", "die", "spinn'", "ihr", "gifft", "an", "sei\u00b7ne", "bl\u00e4t\u00b7ter", "speyt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "VVFIN", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "So wird der lorbeer-crantz wol unverwelcklich gr\u00fcnen,", "tokens": ["So", "wird", "der", "lor\u00b7beer\u00b7crantz", "wol", "un\u00b7ver\u00b7welck\u00b7lich", "gr\u00fc\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und vor der sp\u00f6tter blitz und donner sicher stehn,", "tokens": ["Und", "vor", "der", "sp\u00f6t\u00b7ter", "blitz", "und", "don\u00b7ner", "si\u00b7cher", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "KON", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die weisheit pfleget ihn auf ihren ehren-b\u00fchnen,", "tokens": ["Die", "weis\u00b7heit", "pfle\u00b7get", "ihn", "auf", "ih\u00b7ren", "eh\u00b7ren\u00b7b\u00fch\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "PPOSAT", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn Mom und Zoilus mit schimpff zu grunde gehn.", "tokens": ["Wenn", "Mom", "und", "Zoi\u00b7lus", "mit", "schimpff", "zu", "grun\u00b7de", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "KON", "NE", "APPR", "VVFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.8": {"line.1": {"text": "Gesetzt, da\u00df manchmal auch das volck der idioten", "tokens": ["Ge\u00b7setzt", ",", "da\u00df", "manch\u00b7mal", "auch", "das", "volck", "der", "i\u00b7dio\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "KOUS", "ADV", "ADV", "ART", "NN", "ART", "ADJA"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ein glied von ihrer zunfft auf den Parnassus bringt;", "tokens": ["Ein", "glied", "von", "ih\u00b7rer", "zunfft", "auf", "den", "Par\u00b7nas\u00b7sus", "bringt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.3": {"text": "Hat man doch kindern offt gar Cronen angeboten,", "tokens": ["Hat", "man", "doch", "kin\u00b7dern", "offt", "gar", "Cro\u00b7nen", "an\u00b7ge\u00b7bo\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "NN", "ADV", "ADV", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zu welchen sich nur sonst ein kluges alter schwingt.", "tokens": ["Zu", "wel\u00b7chen", "sich", "nur", "sonst", "ein", "klu\u00b7ges", "al\u00b7ter", "schwingt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "PRF", "ADV", "ADV", "ART", "ADJA", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Und dennoch bleibt der glantz der Maiest\u00e4t in ehren.", "tokens": ["Und", "den\u00b7noch", "bleibt", "der", "glantz", "der", "Mai\u00b7es\u00b7t\u00e4t", "in", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "ART", "NN", "APPR", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was kan in dieser welt ohn alle fehler seyn?", "tokens": ["Was", "kan", "in", "die\u00b7ser", "welt", "ohn", "al\u00b7le", "feh\u00b7ler", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "APPR", "PDAT", "NN", "APPR", "PIS", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die sp\u00f6tter, die das gras im felde wachsen h\u00f6ren,", "tokens": ["Die", "sp\u00f6t\u00b7ter", ",", "die", "das", "gras", "im", "fel\u00b7de", "wach\u00b7sen", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PRELS", "ART", "NN", "APPRART", "NN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wird die vollkommenheit wol schwehrlich ie erfreun.", "tokens": ["Wird", "die", "voll\u00b7kom\u00b7men\u00b7heit", "wol", "schwehr\u00b7lich", "ie", "er\u00b7freun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Genung, da\u00df Deutschland noch sehr viel Magister kennet,", "tokens": ["Ge\u00b7nung", ",", "da\u00df", "Deutschland", "noch", "sehr", "viel", "Ma\u00b7gis\u00b7ter", "ken\u00b7net", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "NE", "ADV", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Die ihren lorbeer-crantz durch ihren witz verdient.", "tokens": ["Die", "ih\u00b7ren", "lor\u00b7beer\u00b7crantz", "durch", "ih\u00b7ren", "witz", "ver\u00b7dient", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Genung, da\u00df Leucoris viel solche m\u00e4nner nennet,", "tokens": ["Ge\u00b7nung", ",", "da\u00df", "Leu\u00b7co\u00b7ris", "viel", "sol\u00b7che", "m\u00e4n\u00b7ner", "nen\u00b7net", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "NE", "ADV", "PIAT", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die keiner mit vernunfft zu tadeln sich erk\u00fchnt.", "tokens": ["Die", "kei\u00b7ner", "mit", "ver\u00b7nunfft", "zu", "ta\u00b7deln", "sich", "er\u00b7k\u00fchnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "NN", "PTKZU", "VVINF", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Genung, da\u00df wir an dir ein solches muster finden,", "tokens": ["Ge\u00b7nung", ",", "da\u00df", "wir", "an", "dir", "ein", "sol\u00b7ches", "mus\u00b7ter", "fin\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "APPR", "PPER", "ART", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gelehrt- und kluger R\u00fchr! das ieder loben mu\u00df.", "tokens": ["Ge\u00b7lehr\u00b7t", "und", "klu\u00b7ger", "R\u00fchr", "!", "das", "ie\u00b7der", "lo\u00b7ben", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "ADJA", "NN", "$.", "ART", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Wer seinen ehren-bau so fest, als du, kan gr\u00fcnden,", "tokens": ["Wer", "sei\u00b7nen", "eh\u00b7ren\u00b7bau", "so", "fest", ",", "als", "du", ",", "kan", "gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "ADV", "PTKVZ", "$,", "KOUS", "PPER", "$,", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Tr\u00e4gt den magister-hut den sp\u00f6ttern zum verdru\u00df.", "tokens": ["Tr\u00e4gt", "den", "ma\u00b7gis\u00b7ter\u00b7hut", "den", "sp\u00f6t\u00b7tern", "zum", "ver\u00b7dru\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "APPRART", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}}, "stanza.12": {"line.1": {"text": "Dein Vater hatte dich vern\u00fcnfftig auferzogen,", "tokens": ["Dein", "Va\u00b7ter", "hat\u00b7te", "dich", "ver\u00b7n\u00fcnff\u00b7tig", "auf\u00b7er\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und dir den ersten weg zur weisheit kund gethan.", "tokens": ["Und", "dir", "den", "ers\u00b7ten", "weg", "zur", "weis\u00b7heit", "kund", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "ADJA", "ADV", "APPRART", "NN", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du bist dem Vater auch bald r\u00fchmlich nachgeflogen,", "tokens": ["Du", "bist", "dem", "Va\u00b7ter", "auch", "bald", "r\u00fchm\u00b7lich", "nach\u00b7ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "ADV", "ADJD", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "An dem sich Dre\u00dfden itzt nach wunsch erbauen kan.", "tokens": ["An", "dem", "sich", "Dre\u00df\u00b7den", "itzt", "nach", "wunsch", "er\u00b7bau\u00b7en", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "NE", "ADV", "APPR", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Drum nahm dich Philuree nach hingelegten schulen,", "tokens": ["Drum", "nahm", "dich", "Phi\u00b7lu\u00b7ree", "nach", "hin\u00b7ge\u00b7leg\u00b7ten", "schu\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PRF", "NE", "APPR", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als einen muntern Sohn mit beyden armen auf.", "tokens": ["Als", "ei\u00b7nen", "mun\u00b7tern", "Sohn", "mit", "bey\u00b7den", "ar\u00b7men", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "APPR", "PIAT", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Verschlendert mancher thor allda die zeit mit buhlen.", "tokens": ["Ver\u00b7schlen\u00b7dert", "man\u00b7cher", "thor", "all\u00b7da", "die", "zeit", "mit", "buh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "ADV", "ART", "NN", "APPR", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So f\u00fchrte dich dein witz gantz einen andern lauf.", "tokens": ["So", "f\u00fchr\u00b7te", "dich", "dein", "witz", "gantz", "ei\u00b7nen", "an\u00b7dern", "lauf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Doch als die Musen hier aus furcht des krieges wichen,", "tokens": ["Doch", "als", "die", "Mu\u00b7sen", "hier", "aus", "furcht", "des", "krie\u00b7ges", "wi\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "APPR", "NN", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So muste Jena dir ein sichrer hafen seyn.", "tokens": ["So", "mus\u00b7te", "Je\u00b7na", "dir", "ein", "sich\u00b7rer", "ha\u00b7fen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NE", "PPER", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn andre durch die stadt nach einem dorffe strichen,", "tokens": ["Wenn", "and\u00b7re", "durch", "die", "stadt", "nach", "ei\u00b7nem", "dorf\u00b7fe", "stri\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So wuste sich dein geist mit lesen zu erfreun.", "tokens": ["So", "wus\u00b7te", "sich", "dein", "geist", "mit", "le\u00b7sen", "zu", "er\u00b7freun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PPOSAT", "NN", "APPR", "VVINF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Du hast, was F\u00f6rtsch gelehrt, Buddeus ausgeleget,", "tokens": ["Du", "hast", ",", "was", "F\u00f6rtsch", "ge\u00b7lehrt", ",", "Bud\u00b7deus", "aus\u00b7ge\u00b7le\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PWS", "NN", "VVPP", "$,", "NE", "VVFIN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und Lungershausens flei\u00df subtiles vorgebracht,", "tokens": ["Und", "Lun\u00b7gers\u00b7hau\u00b7sens", "flei\u00df", "sub\u00b7ti\u00b7les", "vor\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bed\u00e4chtig untersucht, wie ein gem\u00fcthe pfleget,", "tokens": ["Be\u00b7d\u00e4ch\u00b7tig", "un\u00b7ter\u00b7sucht", ",", "wie", "ein", "ge\u00b7m\u00fc\u00b7the", "pfle\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,", "PWAV", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das seine jahre nicht dem Schlendrian verpacht.", "tokens": ["Das", "sei\u00b7ne", "jah\u00b7re", "nicht", "dem", "Schlen\u00b7dri\u00b7an", "ver\u00b7pacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "PTKNEG", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Wie die begierde nun, was gr\u00fcndliches zu wissen,", "tokens": ["Wie", "die", "be\u00b7gier\u00b7de", "nun", ",", "was", "gr\u00fcnd\u00b7li\u00b7ches", "zu", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "$,", "PWS", "ADJA", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sich nicht so binden l\u00e4st, und offt noch weiter geht;", "tokens": ["Sich", "nicht", "so", "bin\u00b7den", "l\u00e4st", ",", "und", "offt", "noch", "wei\u00b7ter", "geht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKNEG", "ADV", "VVINF", "VVFIN", "$,", "KON", "ADV", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So eiltest du dahin, wo Elb und Elster flie\u00dfen,", "tokens": ["So", "eil\u00b7test", "du", "da\u00b7hin", ",", "wo", "Elb", "und", "Els\u00b7ter", "flie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PAV", "$,", "PWAV", "NE", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Luthers eifer noch auf der catheder steht.", "tokens": ["Und", "Lu\u00b7thers", "ei\u00b7fer", "noch", "auf", "der", "cat\u00b7he\u00b7der", "steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADJD", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}}, "stanza.17": {"line.1": {"text": "Hier hast du deinen slei\u00df noch ferner sp\u00fcren lassen:", "tokens": ["Hier", "hast", "du", "dei\u00b7nen", "slei\u00df", "noch", "fer\u00b7ner", "sp\u00fc\u00b7ren", "las\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "NN", "ADV", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hier hat die wissenschafft ihr rechtes ziel erlangt.", "tokens": ["Hier", "hat", "die", "wis\u00b7sen\u00b7schafft", "ihr", "rech\u00b7tes", "ziel", "er\u00b7langt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wir m\u00fchen uns umsonst dein lob hier abzufassen,", "tokens": ["Wir", "m\u00fc\u00b7hen", "uns", "um\u00b7sonst", "dein", "lob", "hier", "ab\u00b7zu\u00b7fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PPOSAT", "NN", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nachdem dein haupt bereits mit frischen lorbeern prangt.", "tokens": ["Nach\u00b7dem", "dein", "haupt", "be\u00b7reits", "mit", "fri\u00b7schen", "lor\u00b7beern", "prangt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Aus lorbeern, welche dir die weisheit aufgesetzet,", "tokens": ["Aus", "lor\u00b7beern", ",", "wel\u00b7che", "dir", "die", "weis\u00b7heit", "auf\u00b7ge\u00b7set\u00b7zet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVINF", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die weisheit, die den mund der sp\u00f6tter stopffen kan.", "tokens": ["Die", "weis\u00b7heit", ",", "die", "den", "mund", "der", "sp\u00f6t\u00b7ter", "stopf\u00b7fen", "kan", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "ART", "ADJA", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drum zeigen wir allein, wie uns die ehr ergetzet,", "tokens": ["Drum", "zei\u00b7gen", "wir", "al\u00b7lein", ",", "wie", "uns", "die", "ehr", "er\u00b7get\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "$,", "PWAV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die dein verdienst belohnt, in diesen zeilen an.", "tokens": ["Die", "dein", "ver\u00b7dienst", "be\u00b7lohnt", ",", "in", "die\u00b7sen", "zei\u00b7len", "an", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVPP", "$,", "APPR", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Doch w\u00fcnschen wir zugleich, da\u00df trotz den schlimmen zeiten,", "tokens": ["Doch", "w\u00fcn\u00b7schen", "wir", "zu\u00b7gleich", ",", "da\u00df", "trotz", "den", "schlim\u00b7men", "zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$,", "KOUS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dich GOttes segens-hand noch fernerweit erfreu,", "tokens": ["Dich", "Got\u00b7tes", "se\u00b7gens\u00b7hand", "noch", "fer\u00b7ner\u00b7weit", "er\u00b7freu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "NE", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und da\u00df der lorbeer-crantz, den Musen zubereiten,", "tokens": ["Und", "da\u00df", "der", "lor\u00b7beer\u00b7crantz", ",", "den", "Mu\u00b7sen", "zu\u00b7be\u00b7rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den sp\u00f6ttern zum verdru\u00df noch stets in ehren sey!", "tokens": ["Den", "sp\u00f6t\u00b7tern", "zum", "ver\u00b7dru\u00df", "noch", "stets", "in", "eh\u00b7ren", "sey", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "ADV", "ADV", "APPR", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}