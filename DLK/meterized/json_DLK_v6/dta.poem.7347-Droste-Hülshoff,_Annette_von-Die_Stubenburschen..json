{"dta.poem.7347": {"metadata": {"author": {"name": "Droste-H\u00fclshoff, Annette von", "birth": "N.A.", "death": "N.A."}, "title": "Die Stubenburschen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1844", "urn": "urn:nbn:de:kobv:b4-20090519994", "language": ["de:0.99"], "booktitle": "Droste-H\u00fclshoff, Annette von: Gedichte. Stuttgart u. a., 1844."}, "poem": {"stanza.1": {"line.1": {"text": "Sie waren Beide froh und gut,", "tokens": ["Sie", "wa\u00b7ren", "Bei\u00b7de", "froh", "und", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und mochten ungern scheiden;", "tokens": ["Und", "moch\u00b7ten", "un\u00b7gern", "schei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Jahre fliehn, es lischt der Muth,", "tokens": ["Die", "Jah\u00b7re", "fliehn", ",", "es", "lischt", "der", "Muth", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Tag bringt Freud' und Leiden,", "tokens": ["Der", "Tag", "bringt", "Freud'", "und", "Lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Gesch\u00e4ft will Zeit und Zeit ist schnell,", "tokens": ["Ge\u00b7sch\u00e4ft", "will", "Zeit", "und", "Zeit", "ist", "schnell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "NN", "KON", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So unterblieb das Schreiben,", "tokens": ["So", "un\u00b7ter\u00b7blieb", "das", "Schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Doch \u00f6fters sprach Emanuel:", "tokens": ["Doch", "\u00f6f\u00b7ters", "sprach", "E\u00b7ma\u00b7nu\u00b7el", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "\u201ewas mag der Franzel treiben!\u201c", "tokens": ["\u201e", "was", "mag", "der", "Fran\u00b7zel", "trei\u00b7ben", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "VMFIN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Da trat einst Wintermorgens fr\u00fch", "tokens": ["Da", "trat", "einst", "Win\u00b7ter\u00b7mor\u00b7gens", "fr\u00fch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Mann in seine Stube,", "tokens": ["Ein", "Mann", "in", "sei\u00b7ne", "Stu\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Seltsam verschabt wie ein Genie,", "tokens": ["Selt\u00b7sam", "ver\u00b7schabt", "wie", "ein", "Ge\u00b7nie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Und hager wie Coeur Bube,", "tokens": ["Und", "ha\u00b7ger", "wie", "Co\u00b7eur", "Bu\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KOKOM", "NN", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Sah ihn so glau und pfiffig an,", "tokens": ["Sah", "ihn", "so", "glau", "und", "pfif\u00b7fig", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "KON", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und blinzelt vor Behagen:", "tokens": ["Und", "blin\u00b7zelt", "vor", "Be\u00b7ha\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "\u201eemanuel, du Hampelmann!", "tokens": ["\u201e", "e\u00b7ma\u00b7nu\u00b7el", ",", "du", "Ham\u00b7pel\u00b7mann", "!"], "token_info": ["punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "PPER", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Willst du mir denn nichts sagen?\u201c", "tokens": ["Willst", "du", "mir", "denn", "nichts", "sa\u00b7gen", "?", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "PIS", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "\u201eer ist es!\u201c rief der Doktor aus,", "tokens": ["\u201e", "er", "ist", "es", "!", "\u201c", "rief", "der", "Dok\u00b7tor", "aus", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PPER", "$.", "$(", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und reicht ihm beide H\u00e4nde.", "tokens": ["Und", "reicht", "ihm", "bei\u00b7de", "H\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201ewillkomm, Willkomm! wie siehst du aus?", "tokens": ["\u201e", "will\u00b7komm", ",", "Will\u00b7komm", "!", "wie", "siehst", "du", "aus", "?"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "NE", "$.", "PWAV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ei, munter und behende.\u201c", "tokens": ["Ei", ",", "mun\u00b7ter", "und", "be\u00b7hen\u00b7de", ".", "\u201c"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "ADJD", "KON", "ADJA", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "\u201eha\u201c rief der Andre, \u201eSapperment,", "tokens": ["\u201e", "ha", "\u201c", "rief", "der", "And\u00b7re", ",", "\u201e", "Sap\u00b7per\u00b7ment", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["$(", "ITJ", "$(", "VVFIN", "ART", "ADJA", "$,", "$(", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Man sieht, du darfst nicht sorgen!", "tokens": ["Man", "sieht", ",", "du", "darfst", "nicht", "sor\u00b7gen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PPER", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Wie roth du bist, wie corpulent!", "tokens": ["Wie", "roth", "du", "bist", ",", "wie", "cor\u00b7pu\u00b7lent", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "VAFIN", "$,", "PWAV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Du hast dich wohl geborgen.\u201c", "tokens": ["Du", "hast", "dich", "wohl", "ge\u00b7bor\u00b7gen", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Drauf sa\u00df man zu Kamin und Wein,", "tokens": ["Drauf", "sa\u00df", "man", "zu", "Ka\u00b7min", "und", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIS", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lie\u00df von der Glut sich r\u00f6sten,", "tokens": ["Lie\u00df", "von", "der", "Glut", "sich", "r\u00f6s\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und \u00e4tzte sich mit Schmeichelein,", "tokens": ["Und", "\u00e4tz\u00b7te", "sich", "mit", "Schmei\u00b7che\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Alternden zu tr\u00f6sten.", "tokens": ["Den", "Al\u00b7tern\u00b7den", "zu", "tr\u00f6s\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ein Jeder warf den Hamen hin", "tokens": ["Ein", "Je\u00b7der", "warf", "den", "Ha\u00b7men", "hin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als wohlge\u00fcbter Fischer,", "tokens": ["Als", "wohl\u00b7ge\u00b7\u00fcb\u00b7ter", "Fi\u00b7scher", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und Jeder dachte still: \u201eich bin", "tokens": ["Und", "Je\u00b7der", "dach\u00b7te", "still", ":", "\u201e", "ich", "bin"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "PTKVZ", "$.", "$(", "PPER", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Gewi\u00df um zehn Jahr frischer.\u201c", "tokens": ["Ge\u00b7wi\u00df", "um", "zehn", "Jahr", "fri\u00b7scher", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "CARD", "NN", "ADJD", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Man sch\u00fcttelte die H\u00e4nde derb,", "tokens": ["Man", "sch\u00fct\u00b7tel\u00b7te", "die", "H\u00e4n\u00b7de", "derb", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dann gieng es an ein Fragen.", "tokens": ["Dann", "gieng", "es", "an", "ein", "Fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Reich war des Medikus Erwerb,", "tokens": ["Reich", "war", "des", "Me\u00b7di\u00b7kus", "Er\u00b7werb", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Und dennoch mocht' er klagen.", "tokens": ["Und", "den\u00b7noch", "mocht'", "er", "kla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Er sah den Franz bedenklich an,", "tokens": ["Er", "sah", "den", "Franz", "be\u00b7denk\u00b7lich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NE", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und dacht', er steck' in Schulden,", "tokens": ["Und", "dacht'", ",", "er", "steck'", "in", "Schul\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Doch dieser prahlt': er sey ein Mann", "tokens": ["Doch", "die\u00b7ser", "prahlt'", ":", "er", "sey", "ein", "Mann"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VVFIN", "$.", "PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Von \u201e", "tokens": ["Von", "\u201e"], "token_info": ["word", "punct"], "pos": ["APPR", "$("], "meter": "-", "measure": "single.down"}}, "stanza.6": {"line.1": {"text": "Und dann, ein kecker K\u00e4mpfer,", "tokens": ["Und", "dann", ",", "ein", "ke\u00b7cker", "K\u00e4mp\u00b7fer", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Gerasselt mit der Eisenfahrt,", "tokens": ["Ge\u00b7ras\u00b7selt", "mit", "der", "Ei\u00b7sen\u00b7fahrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gestrudelt mit dem D\u00e4mpfer!", "tokens": ["Ge\u00b7stru\u00b7delt", "mit", "dem", "D\u00e4mp\u00b7fer", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "O wie er die \u201eStadt Leyden\u201c pries,", "tokens": ["O", "wie", "er", "die", "\u201e", "Stadt", "Ley\u00b7den", "\u201c", "pries", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NE", "PWAV", "PPER", "ART", "$(", "NN", "NN", "$(", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und der Kaj\u00fcte Glei\u00dfen!", "tokens": ["Und", "der", "Ka\u00b7j\u00fc\u00b7te", "Glei\u00b7\u00dfen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Nach seiner Meinung d\u00fcrfte sie", "tokens": ["Nach", "sei\u00b7ner", "Mei\u00b7nung", "d\u00fcrf\u00b7te", "sie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u201eviktoria\u201c nur hei\u00dfen.", "tokens": ["\u201e", "vik\u00b7to\u00b7ria", "\u201c", "nur", "hei\u00b7\u00dfen", "."], "token_info": ["punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "FM", "$(", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Das hat den Medikus ger\u00fchrt,", "tokens": ["Das", "hat", "den", "Me\u00b7di\u00b7kus", "ge\u00b7r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihm den bescheidnen Schlucker", "tokens": ["Ihm", "den", "be\u00b7scheid\u00b7nen", "Schlu\u00b7cker"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Lebendig vor das Aug' gef\u00fchrt,", "tokens": ["Le\u00b7ben\u00b7dig", "vor", "das", "Aug'", "ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Der Kl\u00f6\u00dfe a\u00df wie Zucker.", "tokens": ["Der", "Kl\u00f6\u00b7\u00dfe", "a\u00df", "wie", "Zu\u00b7cker", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KOKOM", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und gar als jener sprach: \u201edenkst du", "tokens": ["Und", "gar", "als", "je\u00b7ner", "sprach", ":", "\u201e", "denkst", "du"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["KON", "ADV", "KOKOM", "PDS", "VVFIN", "$.", "$(", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Noch an die halbe Flasche?\u201c", "tokens": ["Noch", "an", "die", "hal\u00b7be", "Fla\u00b7sche", "?", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Der Doktor kniff die Augen zu,", "tokens": ["Der", "Dok\u00b7tor", "kniff", "die", "Au\u00b7gen", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und klimpert' in der Tasche.", "tokens": ["Und", "klim\u00b7pert'", "in", "der", "Ta\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Dann gieng es weiter: \u201edenkst du dort?", "tokens": ["Dann", "gieng", "es", "wei\u00b7ter", ":", "\u201e", "denkst", "du", "dort", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$.", "$(", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und denkst du dies? und Jenes?\u201c", "tokens": ["Und", "denkst", "du", "dies", "?", "und", "Je\u00b7nes", "?", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "PDS", "$.", "KON", "PDS", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Bilder wogten lustig fort,", "tokens": ["Die", "Bil\u00b7der", "wog\u00b7ten", "lus\u00b7tig", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Viel Herzliches und Sch\u00f6nes.", "tokens": ["Viel", "Herz\u00b7li\u00b7ches", "und", "Sch\u00f6\u00b7nes", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wie Abendroth zog in's Gemach", "tokens": ["Wie", "A\u00b7ben\u00b7droth", "zog", "in's", "Ge\u00b7mach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Ein frischer Jugendodem,", "tokens": ["Ein", "fri\u00b7scher", "Ju\u00b7gen\u00b7do\u00b7dem", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und \u00fcberhauchte nach und nach", "tokens": ["Und", "\u00fc\u00b7ber\u00b7hauch\u00b7te", "nach", "und", "nach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "KON", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der Pillenschachteln Brodem.", "tokens": ["Der", "Pil\u00b7len\u00b7schach\u00b7teln", "Bro\u00b7dem", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Am n\u00e4chsten Morgen hat man kaum", "tokens": ["Am", "n\u00e4chs\u00b7ten", "Mor\u00b7gen", "hat", "man", "kaum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "VAFIN", "PIS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Doktor m\u00f6gen kennen,", "tokens": ["Den", "Dok\u00b7tor", "m\u00f6\u00b7gen", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Man sah ihn l\u00e4cheln wie im Traum", "tokens": ["Man", "sah", "ihn", "l\u00e4\u00b7cheln", "wie", "im", "Traum"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "VVFIN", "KOKOM", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und seine Wangen brennen;", "tokens": ["Und", "sei\u00b7ne", "Wan\u00b7gen", "bren\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Im heiligen Studiercloset", "tokens": ["Im", "hei\u00b7li\u00b7gen", "Stu\u00b7dier\u00b7clo\u00b7set"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "H\u00f6rt' man die Gl\u00e4ser klingen,", "tokens": ["H\u00f6rt'", "man", "die", "Gl\u00e4\u00b7ser", "klin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und ein mist\u00f6niges Duett", "tokens": ["Und", "ein", "mis\u00b7t\u00f6\u00b7ni\u00b7ges", "Du\u00b7ett"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Aus Uhukehlen dringen.", "tokens": ["Aus", "U\u00b7hu\u00b7keh\u00b7len", "drin\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Nicht litt am Blute mehr der Mann,", "tokens": ["Nicht", "litt", "am", "Blu\u00b7te", "mehr", "der", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "APPRART", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Am Podagra und Grie\u00dfe;", "tokens": ["Am", "Po\u00b7da\u00b7gra", "und", "Grie\u00b7\u00dfe", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sah er den d\u00fcrren Franzel an,", "tokens": ["Sah", "er", "den", "d\u00fcr\u00b7ren", "Fran\u00b7zel", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So schien er sich ein Riese;", "tokens": ["So", "schien", "er", "sich", "ein", "Rie\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Hat er den Franzel angesehn", "tokens": ["Hat", "er", "den", "Fran\u00b7zel", "an\u00b7ge\u00b7sehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit seinem Gulden t\u00e4glich,", "tokens": ["Mit", "sei\u00b7nem", "Gul\u00b7den", "t\u00e4g\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "So mu\u00dft er selber sich gestehn,", "tokens": ["So", "mu\u00dft", "er", "sel\u00b7ber", "sich", "ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Es geh' ihm ganz ertr\u00e4glich.", "tokens": ["Es", "geh'", "ihm", "ganz", "er\u00b7tr\u00e4g\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Doch als der dritte Tag entschwand,", "tokens": ["Doch", "als", "der", "drit\u00b7te", "Tag", "ent\u00b7schwand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da sah man auch die Beiden", "tokens": ["Da", "sah", "man", "auch", "die", "Bei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Betr\u00fcbten Auges stehn am Strand,", "tokens": ["Be\u00b7tr\u00fcb\u00b7ten", "Au\u00b7ges", "stehn", "am", "Strand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und wieder hie\u00df es \u2014 Scheiden. \u2014", "tokens": ["Und", "wie\u00b7der", "hie\u00df", "es", "Schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$(", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "\u201eleb' wohl, Emanuel, leb' wohl!\u201c \u2014", "tokens": ["\u201e", "leb'", "wohl", ",", "E\u00b7ma\u00b7nu\u00b7el", ",", "leb'", "wohl", "!", "\u201c"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "VVIMP", "ADV", "$,", "NE", "$,", "VVFIN", "ADV", "$.", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u2014 \u201eLeb' wohl, du alte Seele!\u201c", "tokens": ["\u201e", "Leb'", "wohl", ",", "du", "al\u00b7te", "See\u00b7le", "!", "\u201c"], "token_info": ["punct", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "$(", "VVIMP", "ADV", "$,", "PPER", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und die \u201eStadt Leyden\u201c rauschte hohl", "tokens": ["Und", "die", "\u201e", "Stadt", "Ley\u00b7den", "\u201c", "rauschte", "hohl"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "$(", "NN", "NN", "$(", "VVFIN", "ADJD"], "meter": "---+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Durch Dunst und Wogenschwehle.", "tokens": ["Durch", "Dunst", "und", "Wo\u00b7gen\u00b7schweh\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Drei Monde hat das Jahr gebracht,", "tokens": ["Drei", "Mon\u00b7de", "hat", "das", "Jahr", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NE", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Seit Franzel ist geschieden,", "tokens": ["Seit", "Fran\u00b7zel", "ist", "ge\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mit ihm des Hypochonders Macht;", "tokens": ["Mit", "ihm", "des", "Hy\u00b7po\u00b7chon\u00b7ders", "Macht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Dokter lebt in Frieden.", "tokens": ["Der", "Dok\u00b7ter", "lebt", "in", "Frie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und will der D\u00e4mon hier und dort", "tokens": ["Und", "will", "der", "D\u00e4\u00b7mon", "hier", "und", "dort"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ART", "NN", "ADV", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sich schleichend offenbaren,", "tokens": ["Sich", "schlei\u00b7chend", "of\u00b7fen\u00b7ba\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "So geht er an des Rheines Bord", "tokens": ["So", "geht", "er", "an", "des", "Rhei\u00b7nes", "Bord"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und sieht \u201eStadt Leyden\u201c fahren.", "tokens": ["Und", "sieht", "\u201e", "Stadt", "Ley\u00b7den", "\u201c", "fah\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "NN", "NN", "$(", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}