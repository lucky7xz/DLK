{"textgrid.poem.54339": {"metadata": {"author": {"name": "Ziegler, Christiana Mariana von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Die Misgunst l\u00e4\u00dft je hier und dar", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Misgunst l\u00e4\u00dft je hier und dar", "tokens": ["Die", "Mis\u00b7gunst", "l\u00e4\u00dft", "je", "hier", "und", "dar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "KON", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und \u00fcberall die Klauen blicken,", "tokens": ["Und", "\u00fc\u00b7be\u00b7rall", "die", "Klau\u00b7en", "bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Man ist vor ihr stets in Gefahr,", "tokens": ["Man", "ist", "vor", "ihr", "stets", "in", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "PPER", "ADV", "APPR", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Denn sie sucht jeden zu bestricken.", "tokens": ["Denn", "sie", "sucht", "je\u00b7den", "zu", "be\u00b7stri\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So gar ein Kind sagt uns von ihr,", "tokens": ["So", "gar", "ein", "Kind", "sagt", "uns", "von", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVFIN", "PPER", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und kann uns ihre Spuren zeigen.", "tokens": ["Und", "kann", "uns", "ih\u00b7re", "Spu\u00b7ren", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Sie geht uns nach, und solten wir", "tokens": ["Sie", "geht", "uns", "nach", ",", "und", "sol\u00b7ten", "wir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "VMFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Auch auf die h\u00f6chsten Berge steigen.", "tokens": ["Auch", "auf", "die", "h\u00f6chs\u00b7ten", "Ber\u00b7ge", "stei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ja was? auch in der Thiere Reich", "tokens": ["Ja", "was", "?", "auch", "in", "der", "Thie\u00b7re", "Reich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "PWS", "$.", "ADV", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat man dies Unthier l\u00e4ngst entdecket,", "tokens": ["Hat", "man", "dies", "Un\u00b7thier", "l\u00e4ngst", "ent\u00b7de\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PDS", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das nach geschehnem Wurfe gleich", "tokens": ["Das", "nach", "ge\u00b7scheh\u00b7nem", "Wur\u00b7fe", "gleich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "APPR", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Jungen mit dem Gift beflecket.", "tokens": ["Die", "Jun\u00b7gen", "mit", "dem", "Gift", "be\u00b7fle\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Begiebt sichs da\u00df ein Hund ein Bein", "tokens": ["Be\u00b7giebt", "sichs", "da\u00df", "ein", "Hund", "ein", "Bein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "KOUS", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von ohngef\u00e4hr im Lauf ertappet:", "tokens": ["Von", "ohn\u00b7ge\u00b7f\u00e4hr", "im", "Lauf", "er\u00b7tap\u00b7pet", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.7": {"text": "So wird so gleich ein andrer seyn,", "tokens": ["So", "wird", "so", "gleich", "ein", "an\u00b7drer", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "ART", "ADJA", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der nach demselben neidisch schnappet.", "tokens": ["Der", "nach", "dem\u00b7sel\u00b7ben", "nei\u00b7disch", "schnap\u00b7pet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.3": {"line.1": {"text": "Pflegt sich nun dieses Natternkind", "tokens": ["Pflegt", "sich", "nun", "die\u00b7ses", "Nat\u00b7tern\u00b7kind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ADV", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auch zu den Thieren zu gesellen,", "tokens": ["Auch", "zu", "den", "Thie\u00b7ren", "zu", "ge\u00b7sel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ob sie gleich unvern\u00fcnftig sind,", "tokens": ["Ob", "sie", "gleich", "un\u00b7ver\u00b7n\u00fcnf\u00b7tig", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und gar kein Urtheil k\u00f6nnen f\u00e4llen;", "tokens": ["Und", "gar", "kein", "Ur\u00b7theil", "k\u00f6n\u00b7nen", "f\u00e4l\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie mu\u00df es vollends sich bem\u00fchn,", "tokens": ["Wie", "mu\u00df", "es", "vol\u00b7lends", "sich", "be\u00b7m\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ADV", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gesch\u00f6pfe, die wir weise nennen,", "tokens": ["Ge\u00b7sch\u00f6p\u00b7fe", ",", "die", "wir", "wei\u00b7se", "nen\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "In sein verstricktes Garn zu ziehn,", "tokens": ["In", "sein", "ver\u00b7strick\u00b7tes", "Garn", "zu", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df sie auch andre fangen k\u00f6nnen?", "tokens": ["Da\u00df", "sie", "auch", "and\u00b7re", "fan\u00b7gen", "k\u00f6n\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ja wohl; sie herscht nur gar zu sehr,", "tokens": ["Ja", "wohl", ";", "sie", "herscht", "nur", "gar", "zu", "sehr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "$.", "PPER", "VVFIN", "ADV", "ADV", "PTKA", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Besonders bey verliebten Seelen,", "tokens": ["Be\u00b7son\u00b7ders", "bey", "ver\u00b7lieb\u00b7ten", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die sich unstreitig noch weit mehr", "tokens": ["Die", "sich", "un\u00b7strei\u00b7tig", "noch", "weit", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "ADJD", "ADV", "ADJD", "ADV"], "meter": "-+-+-+++", "measure": "unknown.measure.penta"}, "line.4": {"text": "Mit Ha\u00df und Neid, als andre qu\u00e4len.", "tokens": ["Mit", "Ha\u00df", "und", "Neid", ",", "als", "and\u00b7re", "qu\u00e4\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "KOUS", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Fragt nur Berillen, die weis euch", "tokens": ["Fragt", "nur", "Be\u00b7ril\u00b7len", ",", "die", "weis", "euch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADV", "NN", "$,", "PRELS", "PTKVZ", "PPER"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.6": {"text": "Ein langes Lied davon zu singen;", "tokens": ["Ein", "lan\u00b7ges", "Lied", "da\u00b7von", "zu", "sin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wie manchen schlauen Fang und Streich", "tokens": ["Wie", "man\u00b7chen", "schlau\u00b7en", "Fang", "und", "Streich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Man ihr bem\u00fcht ist bey zu bringen.", "tokens": ["Man", "ihr", "be\u00b7m\u00fcht", "ist", "bey", "zu", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PPER", "VVPP", "VAFIN", "APPR", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Kaum, da\u00df sie mit dem Seladon", "tokens": ["Kaum", ",", "da\u00df", "sie", "mit", "dem", "Se\u00b7la\u00b7don"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hier in Bekantschaft ist gerathen,", "tokens": ["Hier", "in", "Be\u00b7kant\u00b7schaft", "ist", "ge\u00b7ra\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So riechen andre Nymphen schon", "tokens": ["So", "rie\u00b7chen", "and\u00b7re", "Nym\u00b7phen", "schon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Eifersucht gereizt, den Braten.", "tokens": ["Von", "Ei\u00b7fer\u00b7sucht", "ge\u00b7reizt", ",", "den", "Bra\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie dichten wahrlich Tag und Nacht,", "tokens": ["Sie", "dich\u00b7ten", "wahr\u00b7lich", "Tag", "und", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie sie dies Freundschaftsband zertrennen.", "tokens": ["Wie", "sie", "dies", "Freund\u00b7schafts\u00b7band", "zer\u00b7tren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PDS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Was haben sie nicht ausgedacht,", "tokens": ["Was", "ha\u00b7ben", "sie", "nicht", "aus\u00b7ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das sie ihr doch nicht zeigen k\u00f6nnen?", "tokens": ["Das", "sie", "ihr", "doch", "nicht", "zei\u00b7gen", "k\u00f6n\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PPER", "ADV", "PTKNEG", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Die eine, schaut die List nur an,", "tokens": ["Die", "ei\u00b7ne", ",", "schaut", "die", "List", "nur", "an", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "$,", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sucht ihn bey ihr so anzuschw\u00e4rzen,", "tokens": ["Sucht", "ihn", "bey", "ihr", "so", "an\u00b7zu\u00b7schw\u00e4r\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als meynt es dieser Spa\u00dfgalan", "tokens": ["Als", "meynt", "es", "die\u00b7ser", "Spa\u00df\u00b7ga\u00b7lan"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "VVFIN", "PPER", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit keiner einigen von Herzen.", "tokens": ["Mit", "kei\u00b7ner", "ei\u00b7ni\u00b7gen", "von", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVPP", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die andre zischt ihr in das Ohr:", "tokens": ["Die", "and\u00b7re", "zischt", "ihr", "in", "das", "Ohr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie soll sich nur zu tode h\u00e4rmen,", "tokens": ["Sie", "soll", "sich", "nur", "zu", "to\u00b7de", "h\u00e4r\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Man s\u00e4h ihn mit der Bienenchor", "tokens": ["Man", "s\u00e4h", "ihn", "mit", "der", "Bie\u00b7nen\u00b7chor"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Von einem Baum zum andern schw\u00e4rmen.", "tokens": ["Von", "ei\u00b7nem", "Baum", "zum", "an\u00b7dern", "schw\u00e4r\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPRART", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Die dritte warnet sie vor ihn,", "tokens": ["Die", "drit\u00b7te", "war\u00b7net", "sie", "vor", "ihn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und sucht durch frevelhaftes L\u00fcgen", "tokens": ["Und", "sucht", "durch", "fre\u00b7vel\u00b7haf\u00b7tes", "L\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Den Seladon von ihr zu ziehn,", "tokens": ["Den", "Se\u00b7la\u00b7don", "von", "ihr", "zu", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Um alle beyde zu betr\u00fcgen.", "tokens": ["Um", "al\u00b7le", "bey\u00b7de", "zu", "be\u00b7tr\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PIAT", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr falscher Vorwand legt ihm bey,", "tokens": ["Ihr", "fal\u00b7scher", "Vor\u00b7wand", "legt", "ihm", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als ob er, wenn er gleich nichts k\u00fc\u00dfte,", "tokens": ["Als", "ob", "er", ",", "wenn", "er", "gleich", "nichts", "k\u00fc\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "$,", "KOUS", "PPER", "ADV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ein W\u00e4scher und ein Prahler sey,", "tokens": ["Ein", "W\u00e4\u00b7scher", "und", "ein", "Prah\u00b7ler", "sey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der sich gar viel zu r\u00fchmen w\u00fc\u00dfte.", "tokens": ["Der", "sich", "gar", "viel", "zu", "r\u00fch\u00b7men", "w\u00fc\u00df\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADV", "PIS", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Berille, glaube keiner nicht,", "tokens": ["Be\u00b7ril\u00b7le", ",", "glau\u00b7be", "kei\u00b7ner", "nicht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "PIS", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie wollen dich nur hintergehen.", "tokens": ["Sie", "wol\u00b7len", "dich", "nur", "hin\u00b7ter\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr scheel und falsches Angesicht", "tokens": ["Ihr", "scheel", "und", "fal\u00b7sches", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Giebt dir es deutlich zu verstehen.", "tokens": ["Giebt", "dir", "es", "deut\u00b7lich", "zu", "ver\u00b7ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Man suchet dir durch Rank und List", "tokens": ["Man", "su\u00b7chet", "dir", "durch", "Rank", "und", "List"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dies Leckerbi\u00dfchen wegzufischen,", "tokens": ["Dies", "Le\u00b7cker\u00b7bi\u00df\u00b7chen", "weg\u00b7zu\u00b7fi\u00b7schen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und dich, so redlich er auch ist", "tokens": ["Und", "dich", ",", "so", "red\u00b7lich", "er", "auch", "ist"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "$,", "ADV", "ADJD", "PPER", "ADV", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Zu Zorn und Rachgier anzufrischen.", "tokens": ["Zu", "Zorn", "und", "Rach\u00b7gier", "an\u00b7zu\u00b7fri\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Weist du, warum sie Tag und Nacht", "tokens": ["Weist", "du", ",", "wa\u00b7rum", "sie", "Tag", "und", "Nacht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "$,", "PWAV", "PPER", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit ihrem Schm\u00e4hen auf dich st\u00fcrmen,", "tokens": ["Mit", "ih\u00b7rem", "Schm\u00e4\u00b7hen", "auf", "dich", "st\u00fcr\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und L\u00fcgen, so die Mi\u00dfgunst macht,", "tokens": ["Und", "L\u00fc\u00b7gen", ",", "so", "die", "Mi\u00df\u00b7gunst", "macht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So h\u00e4ufig auf einander th\u00fcrmen?", "tokens": ["So", "h\u00e4u\u00b7fig", "auf", "ein\u00b7an\u00b7der", "th\u00fcr\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Es will ein jegliches darvon", "tokens": ["Es", "will", "ein", "jeg\u00b7li\u00b7ches", "dar\u00b7von"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sich bey der Schnabelweide laben,", "tokens": ["Sich", "bey", "der", "Schna\u00b7bel\u00b7wei\u00b7de", "la\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und heimlich deinen Seladon", "tokens": ["Und", "heim\u00b7lich", "dei\u00b7nen", "Se\u00b7la\u00b7don"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJD", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Im Umgang ganz alleine haben.", "tokens": ["Im", "Um\u00b7gang", "ganz", "al\u00b7lei\u00b7ne", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}