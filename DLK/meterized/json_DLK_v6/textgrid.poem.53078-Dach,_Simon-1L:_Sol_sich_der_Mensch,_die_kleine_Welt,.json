{"textgrid.poem.53078": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Sol sich der Mensch, die kleine Welt,", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sol sich der Mensch, die kleine Welt,", "tokens": ["Sol", "sich", "der", "Mensch", ",", "die", "klei\u00b7ne", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Jetzt nicht auff s\u00fcsse Heyraht lencken?", "tokens": ["Jetzt", "nicht", "auff", "s\u00fcs\u00b7se", "Hey\u00b7raht", "len\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mu\u00df doch das pr\u00e4chtige Gezelt", "tokens": ["Mu\u00df", "doch", "das", "pr\u00e4ch\u00b7ti\u00b7ge", "Ge\u00b7zelt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der grossen nur an Liebe dencken.", "tokens": ["Der", "gros\u00b7sen", "nur", "an", "Lie\u00b7be", "den\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Die Erd' ist sauber vnd beleckt", "tokens": ["Die", "Erd'", "ist", "sau\u00b7ber", "vnd", "be\u00b7leckt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch den gew\u00fcnschten Schein der Sonnen,", "tokens": ["Durch", "den", "ge\u00b7w\u00fcnschten", "Schein", "der", "Son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ist ihres Winterfells entdeckt", "tokens": ["Ist", "ih\u00b7res", "Win\u00b7ter\u00b7fells", "ent\u00b7deckt"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd wird vom Himmel lieb gewonnen,", "tokens": ["Vnd", "wird", "vom", "Him\u00b7mel", "lieb", "ge\u00b7won\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPRART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Der sich herab in jhren Scho\u00df", "tokens": ["Der", "sich", "her\u00b7ab", "in", "jhren", "Scho\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Durch einen warmen Regen machet,", "tokens": ["Durch", "ei\u00b7nen", "war\u00b7men", "Re\u00b7gen", "ma\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd schw\u00e4ngert jhren d\u00fcrren Klo\u00df,", "tokens": ["Vnd", "schw\u00e4n\u00b7gert", "jhren", "d\u00fcr\u00b7ren", "Klo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da\u00df alles fr\u00f6lich sieht vnd lachet.", "tokens": ["Da\u00df", "al\u00b7les", "fr\u00f6\u00b7lich", "sieht", "vnd", "la\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJD", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Was au\u00df der Lufft den Ackersmann", "tokens": ["Was", "au\u00df", "der", "Lufft", "den", "A\u00b7ckers\u00b7mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit singen tr\u00f6stet vnd erfrewet,", "tokens": ["Mit", "sin\u00b7gen", "tr\u00f6s\u00b7tet", "vnd", "er\u00b7fre\u00b7wet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Spricht lieblich eins das andre an", "tokens": ["Spricht", "lieb\u00b7lich", "eins", "das", "and\u00b7re", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "PIS", "ART", "PIS", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd wird zu gleichem gleich getrewet.", "tokens": ["Vnd", "wird", "zu", "glei\u00b7chem", "gleich", "ge\u00b7tre\u00b7wet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "ADJA", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Die Heerde treibt den Hirten fort", "tokens": ["Die", "Heer\u00b7de", "treibt", "den", "Hir\u00b7ten", "fort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Galatheen nach zu lauffen,", "tokens": ["Der", "Ga\u00b7la\u00b7theen", "nach", "zu", "lauf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Pan braucht sich jetzt der besten Wort',", "tokens": ["Pan", "braucht", "sich", "jetzt", "der", "bes\u00b7ten", "Wort'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Ihr Nymphen, ewre Gunst zu kauffen.", "tokens": ["Ihr", "Nym\u00b7phen", ",", "ew\u00b7re", "Gunst", "zu", "kauf\u00b7fen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Das meiste, welches Auffenthalt", "tokens": ["Das", "meis\u00b7te", ",", "wel\u00b7ches", "Auf\u00b7fent\u00b7halt"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PDS", "VVFIN", "$,", "PWAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nur in den Wellen ist zu finden,", "tokens": ["Nur", "in", "den", "Wel\u00b7len", "ist", "zu", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VAFIN", "PTKZU", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Ja H\u00fcgel, Berge, Wild vnd Wald", "tokens": ["Ja", "H\u00fc\u00b7gel", ",", "Ber\u00b7ge", ",", "Wild", "vnd", "Wald"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "NN", "$,", "NN", "$,", "NE", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mu\u00df jetzt in Liebe sich verbinden.", "tokens": ["Mu\u00df", "jetzt", "in", "Lie\u00b7be", "sich", "ver\u00b7bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Der Mensch, ein Au\u00dfzug dieser Welt,", "tokens": ["Der", "Mensch", ",", "ein", "Au\u00df\u00b7zug", "die\u00b7ser", "Welt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wird vieler Schuld entledigt bleiben,", "tokens": ["Wird", "vie\u00b7ler", "Schuld", "ent\u00b7le\u00b7digt", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "VVPP", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn er sich dem geme\u00df verhelt,", "tokens": ["Wenn", "er", "sich", "dem", "ge\u00b7me\u00df", "ver\u00b7helt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ART", "NN", "VVPP", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.4": {"text": "Was Lufft, See, Erd vnd Himmel treiben.", "tokens": ["Was", "Lufft", ",", "See", ",", "Erd", "vnd", "Him\u00b7mel", "trei\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}