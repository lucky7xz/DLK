{"textgrid.poem.50496": {"metadata": {"author": {"name": "Wernicke, Christian", "birth": "N.A.", "death": "N.A."}, "title": "20. Reime dich, oder ich fresse dich", "genre": "verse", "period": "N.A.", "pub_year": 1693, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenig Kriegs-Volck, grosse W\u00e4lle,", "tokens": ["We\u00b7nig", "Kriegs\u00b7Volck", ",", "gros\u00b7se", "W\u00e4l\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenig Vieh', und grosse St\u00e4lle;", "tokens": ["We\u00b7nig", "Vieh'", ",", "und", "gros\u00b7se", "St\u00e4l\u00b7le", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "KON", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Grosse Teich', und keine Fisch,", "tokens": ["Gros\u00b7se", "Teich'", ",", "und", "kei\u00b7ne", "Fisch", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "KON", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Federn, und kein Flederwisch.", "tokens": ["Fe\u00b7dern", ",", "und", "kein", "Fle\u00b7der\u00b7wisch", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Viele Wort', und wenig Speise,", "tokens": ["Vie\u00b7le", "Wort'", ",", "und", "we\u00b7nig", "Spei\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "KON", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenig Geld auf langer Reise;", "tokens": ["We\u00b7nig", "Geld", "auf", "lan\u00b7ger", "Rei\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Sch\u00f6ne Beutel ohne Gold,", "tokens": ["Sch\u00f6\u00b7ne", "Beu\u00b7tel", "oh\u00b7ne", "Gold", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Grosse Titel ohne Sold.", "tokens": ["Gros\u00b7se", "Ti\u00b7tel", "oh\u00b7ne", "Sold", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Schlechte K\u00f6ch', und lange Messer,", "tokens": ["Schlech\u00b7te", "K\u00f6\u00b7ch'", ",", "und", "lan\u00b7ge", "Mes\u00b7ser", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "KON", "ADJA", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Schlechter Wein, und bunte F\u00e4sser;", "tokens": ["Schlech\u00b7ter", "Wein", ",", "und", "bun\u00b7te", "F\u00e4s\u00b7ser", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "KON", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Lange N\u00e4chte sonder Schlaff,", "tokens": ["Lan\u00b7ge", "N\u00e4ch\u00b7te", "son\u00b7der", "Schlaff", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "Viel Gesetze sonder Straff'.", "tokens": ["Viel", "Ge\u00b7set\u00b7ze", "son\u00b7der", "Straff'", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "Frantzsches Fussvolck ohne Schweitzer,", "tokens": ["Frantz\u00b7sches", "Fuss\u00b7volck", "oh\u00b7ne", "Schweit\u00b7zer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Ohne Pfeiff' ein Vogelbeitzer;", "tokens": ["Oh\u00b7ne", "Pfeiff'", "ein", "Vo\u00b7gel\u00b7beit\u00b7zer", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Ein Quacksalber ohne Narr,", "tokens": ["Ein", "Quack\u00b7sal\u00b7ber", "oh\u00b7ne", "Narr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.16": {"text": "Eine Quarr und keine Pfarr',", "tokens": ["Ei\u00b7ne", "Quarr", "und", "kei\u00b7ne", "Pfarr'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.17": {"text": "Viele Sch\u00e4tz', und kein Vergn\u00fcgen,", "tokens": ["Vie\u00b7le", "Sch\u00e4tz'", ",", "und", "kein", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "KON", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "Allchymisten sonder L\u00fcgen;", "tokens": ["All\u00b7chy\u00b7mis\u00b7ten", "son\u00b7der", "L\u00fc\u00b7gen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Eine Leuchte sonder Kertz',", "tokens": ["Ei\u00b7ne", "Leuch\u00b7te", "son\u00b7der", "Kertz'", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.20": {"text": "Und ein Stutzbahrt ohne Hertz,", "tokens": ["Und", "ein", "Stutz\u00b7bahrt", "oh\u00b7ne", "Hertz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.21": {"text": "Eine Sonn-Uhr' ohne Weiser,", "tokens": ["Ei\u00b7ne", "Sonn\u00b7Uhr'", "oh\u00b7ne", "Wei\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.22": {"text": "\u2013 \u2013 Singspiel' ohne Keiser:", "tokens": ["\u2013", "\u2013", "Sing\u00b7spiel'", "oh\u00b7ne", "Kei\u00b7ser", ":"], "token_info": ["punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "$(", "NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.23": {"text": "Eben so viel sind hier n\u00fctz", "tokens": ["E\u00b7ben", "so", "viel", "sind", "hier", "n\u00fctz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "VAFIN", "ADV", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}}}}}