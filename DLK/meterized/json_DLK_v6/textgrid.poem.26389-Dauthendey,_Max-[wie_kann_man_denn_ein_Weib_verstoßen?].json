{"textgrid.poem.26389": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "[wie kann man denn ein Weib versto\u00dfen?]", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie kann man denn ein Weib versto\u00dfen?", "tokens": ["Wie", "kann", "man", "denn", "ein", "Weib", "ver\u00b7sto\u00b7\u00dfen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PIS", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Weib ist doch kein Mann in Hosen.", "tokens": ["Ein", "Weib", "ist", "doch", "kein", "Mann", "in", "Ho\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PIAT", "NN", "APPR", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Verliebt ist jede Frau so sch\u00f6n,", "tokens": ["Ver\u00b7liebt", "ist", "je\u00b7de", "Frau", "so", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PIAT", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nur schw\u00fcl wird's \u00f6fters wie beim F\u00f6hn.", "tokens": ["Nur", "schw\u00fcl", "wird's", "\u00f6f\u00b7ters", "wie", "beim", "F\u00f6hn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ADV", "KOKOM", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Es stand vor mir Frau K\u00f6nigin", "tokens": ["Es", "stand", "vor", "mir", "Frau", "K\u00f6\u00b7ni\u00b7gin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und sprach: \u00bbIch habe dir verziehn.", "tokens": ["Und", "sprach", ":", "\u00bb", "Ich", "ha\u00b7be", "dir", "ver\u00b7ziehn", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PPER", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Es ist so einsam auf dem Land,", "tokens": ["Es", "ist", "so", "ein\u00b7sam", "auf", "dem", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fchl' ich dich nicht gleich bei der Hand.", "tokens": ["F\u00fchl'", "ich", "dich", "nicht", "gleich", "bei", "der", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PRF", "PTKNEG", "ADV", "APPR", "ART", "NN", "$."], "meter": "+---+--+", "measure": "iambic.tri.chol"}}, "stanza.5": {"line.1": {"text": "Drei Tag' ging ich im Schnee dahin,", "tokens": ["Drei", "Tag'", "ging", "ich", "im", "Schnee", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "APPRART", "NN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als ob ich nicht geboren bin.", "tokens": ["Als", "ob", "ich", "nicht", "ge\u00b7bo\u00b7ren", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "PTKNEG", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Froh bin ich, da\u00df ich wieder hier.", "tokens": ["Froh", "bin", "ich", ",", "da\u00df", "ich", "wie\u00b7der", "hier", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mach, was du willst, ich bleib' bei dir.\u00ab", "tokens": ["Mach", ",", "was", "du", "willst", ",", "ich", "bleib'", "bei", "dir", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "$,", "PWS", "PPER", "VMFIN", "$,", "PPER", "VVFIN", "APPR", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "\u00bbja,\u00ab sprach ich, \u00bbach, sieh es doch ein,", "tokens": ["\u00bb", "ja", ",", "\u00ab", "sprach", "ich", ",", "\u00bb", "ach", ",", "sieh", "es", "doch", "ein", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "ITJ", "$,", "VVIMP", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Schicksal kann uns je entzwein.", "tokens": ["Kein", "Schick\u00b7sal", "kann", "uns", "je", "ent\u00b7zwein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Ich f\u00fchl' mich wie im Honigtopf,", "tokens": ["Ich", "f\u00fchl'", "mich", "wie", "im", "Ho\u00b7nig\u00b7topf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KOKOM", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Seh' ich nur deinen goldnen Kopf;", "tokens": ["Seh'", "ich", "nur", "dei\u00b7nen", "gold\u00b7nen", "Kopf", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Doch Untreu ist auf mich versessen,", "tokens": ["Doch", "Un\u00b7treu", "ist", "auf", "mich", "ver\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie ist heut nacht bei mir gewesen.\u00ab", "tokens": ["Sie", "ist", "heut", "nacht", "bei", "mir", "ge\u00b7we\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "APPR", "PPER", "VAPP", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "\u2013 Auf einmal war es leer im Zimmer,", "tokens": ["\u2013", "Auf", "ein\u00b7mal", "war", "es", "leer", "im", "Zim\u00b7mer", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ADV", "VAFIN", "PPER", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es ging was fort, und ging f\u00fcr immer.", "tokens": ["Es", "ging", "was", "fort", ",", "und", "ging", "f\u00fcr", "im\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "PTKVZ", "$,", "KON", "VVFIN", "APPR", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Trotzdem die Lampe noch da war,", "tokens": ["Trotz\u00b7dem", "die", "Lam\u00b7pe", "noch", "da", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ADV", "ADV", "VAFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Verfinsterte 's sich sonderbar.", "tokens": ["Ver\u00b7fins\u00b7ter\u00b7te", "'s", "sich", "son\u00b7der\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Ich sprach: \u00bbO, rede doch ein Wort!", "tokens": ["Ich", "sprach", ":", "\u00bb", "O", ",", "re\u00b7de", "doch", "ein", "Wort", "!"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "ITJ", "$,", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich liebe dich doch immerfort.\u00ab", "tokens": ["Ich", "lie\u00b7be", "dich", "doch", "im\u00b7mer\u00b7fort", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Die Seele schien ihr ausgerissen,", "tokens": ["Die", "See\u00b7le", "schien", "ihr", "aus\u00b7ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie sah mich an ohne Gewissen.", "tokens": ["Sie", "sah", "mich", "an", "oh\u00b7ne", "Ge\u00b7wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "APPR", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.14": {"line.1": {"text": "Nie f\u00fchlt' ich vorher ein Unrecht,", "tokens": ["Nie", "f\u00fchlt'", "ich", "vor\u00b7her", "ein", "Un\u00b7recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Jetzt war mir's vor mir selber schlecht.", "tokens": ["Jetzt", "war", "mir's", "vor", "mir", "sel\u00b7ber", "schlecht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "APPR", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Die H\u00e4nde hingen ihr hernieder,", "tokens": ["Die", "H\u00e4n\u00b7de", "hin\u00b7gen", "ihr", "her\u00b7nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es waren nicht mehr ihre Glieder,", "tokens": ["Es", "wa\u00b7ren", "nicht", "mehr", "ih\u00b7re", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Der Schmerz hatte sie ganz zerdr\u00fcckt,", "tokens": ["Der", "Schmerz", "hat\u00b7te", "sie", "ganz", "zer\u00b7dr\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie lag in Scherben wie zerst\u00fcckt.", "tokens": ["Sie", "lag", "in", "Scher\u00b7ben", "wie", "zer\u00b7st\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KOKOM", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Wie was man nicht mehr leimen kann,", "tokens": ["Wie", "was", "man", "nicht", "mehr", "lei\u00b7men", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PWS", "PIS", "PTKNEG", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So sah sie mich zerbrochen an.", "tokens": ["So", "sah", "sie", "mich", "zer\u00b7bro\u00b7chen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "VVPP", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Sie sprach: \u00bbNun gibt es nichts mehr schlimmer,", "tokens": ["Sie", "sprach", ":", "\u00bb", "Nun", "gibt", "es", "nichts", "mehr", "schlim\u00b7mer", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "ADV", "VVFIN", "PPER", "PIS", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mein ganzer Mensch ist ein Gewimmer,", "tokens": ["Mein", "gan\u00b7zer", "Mensch", "ist", "ein", "Ge\u00b7wim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Ich hab' zum letztenmal gelacht,", "tokens": ["Ich", "hab'", "zum", "letz\u00b7ten\u00b7mal", "ge\u00b7lacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zur Mumie hast du mich gemacht.", "tokens": ["Zur", "Mu\u00b7mie", "hast", "du", "mich", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PPER", "PRF", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Mit Mumien ist nicht gut wandern,", "tokens": ["Mit", "Mu\u00b7mi\u00b7en", "ist", "nicht", "gut", "wan\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PTKNEG", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich geh', und du bleib' bei der andern.\u00ab \u2013", "tokens": ["Ich", "geh'", ",", "und", "du", "bleib'", "bei", "der", "an\u00b7dern", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "PPER", "VVFIN", "APPR", "ART", "ADJA", "$.", "$(", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Und eine Wolke tat entstehn,", "tokens": ["Und", "ei\u00b7ne", "Wol\u00b7ke", "tat", "ent\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit ihr tat etwas vor sich gehn.", "tokens": ["Mit", "ihr", "tat", "et\u00b7was", "vor", "sich", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PIS", "APPR", "PRF", "VVINF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.22": {"line.1": {"text": "Wie Heilige einst vor dem Volke", "tokens": ["Wie", "Hei\u00b7li\u00b7ge", "einst", "vor", "dem", "Vol\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJA", "ADV", "APPR", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Stieg K\u00f6nigin auf diese Wolke.", "tokens": ["Stieg", "K\u00f6\u00b7ni\u00b7gin", "auf", "die\u00b7se", "Wol\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Verj\u00fcngt erkannt ich sie kaum wieder,", "tokens": ["Ver\u00b7j\u00fcngt", "er\u00b7kannt", "ich", "sie", "kaum", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVFIN", "PPER", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Rosen f\u00fctterten ihre Glieder,", "tokens": ["Ro\u00b7sen", "f\u00fct\u00b7ter\u00b7ten", "ih\u00b7re", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.24": {"line.1": {"text": "Ihr Leib wie Daunen von der Eider", "tokens": ["Ihr", "Leib", "wie", "Dau\u00b7nen", "von", "der", "Ei\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KOKOM", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zeigt' rosa Blut wie Unterkleider,", "tokens": ["Zeigt'", "ro\u00b7sa", "Blut", "wie", "Un\u00b7ter\u00b7klei\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "NN", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Die goldnen Wimpern glitzern ihr,", "tokens": ["Die", "gold\u00b7nen", "Wim\u00b7pern", "glit\u00b7zern", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es lacht ihr Haar, sie redet irr.", "tokens": ["Es", "lacht", "ihr", "Haar", ",", "sie", "re\u00b7det", "irr", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Sie spricht: \u00bbIch habe jetzt gew\u00e4hlt,", "tokens": ["Sie", "spricht", ":", "\u00bb", "Ich", "ha\u00b7be", "jetzt", "ge\u00b7w\u00e4hlt", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PPER", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nehm einen, der mich nicht so qu\u00e4lt.\u00ab", "tokens": ["Nehm", "ei\u00b7nen", ",", "der", "mich", "nicht", "so", "qu\u00e4lt", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "$,", "PRELS", "PPER", "PTKNEG", "ADV", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Die Wolke ging mit ihr durchs Dach,", "tokens": ["Die", "Wol\u00b7ke", "ging", "mit", "ihr", "durchs", "Dach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich sah mit offnem Munde nach.", "tokens": ["Ich", "sah", "mit", "off\u00b7nem", "Mun\u00b7de", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Das Ganze ging im Handumdrehn,", "tokens": ["Das", "Gan\u00b7ze", "ging", "im", "Han\u00b7dum\u00b7drehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich habe nie so was gesehn.", "tokens": ["Ich", "ha\u00b7be", "nie", "so", "was", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Nun war auch ich ein Scherbenbrei,", "tokens": ["Nun", "war", "auch", "ich", "ein", "Scher\u00b7ben\u00b7brei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es schien mir durch und durch vorbei.", "tokens": ["Es", "schien", "mir", "durch", "und", "durch", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "KON", "APPR", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Mir war, als ob in langen T\u00f6nen", "tokens": ["Mir", "war", ",", "als", "ob", "in", "lan\u00b7gen", "T\u00f6\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "KOKOM", "KOUS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hunde in mir den Mond anst\u00f6hnen.", "tokens": ["Hun\u00b7de", "in", "mir", "den", "Mond", "an\u00b7st\u00f6h\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "ART", "NN", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.31": {"line.1": {"text": "Gestalten vor den T\u00fcren sa\u00dfen", "tokens": ["Ge\u00b7stal\u00b7ten", "vor", "den", "T\u00fc\u00b7ren", "sa\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In langen T\u00fcchern, kalten, nassen.", "tokens": ["In", "lan\u00b7gen", "T\u00fc\u00b7chern", ",", "kal\u00b7ten", ",", "nas\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJA", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Die Fenster tr\u00e4nten in dem Haus,", "tokens": ["Die", "Fens\u00b7ter", "tr\u00e4n\u00b7ten", "in", "dem", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als weinten sich die Zimmer aus.", "tokens": ["Als", "wein\u00b7ten", "sich", "die", "Zim\u00b7mer", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PRF", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Frau K\u00f6nigin ohn' Blutgergie\u00dfen", "tokens": ["Frau", "K\u00f6\u00b7ni\u00b7gin", "ohn'", "Blut\u00b7ger\u00b7gie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hat mich wie Z\u00e4hne ausgerissen.", "tokens": ["Hat", "mich", "wie", "Z\u00e4h\u00b7ne", "aus\u00b7ge\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "KOKOM", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Wu\u00dft nichts mehr mit mir anzufangen,", "tokens": ["Wu\u00dft", "nichts", "mehr", "mit", "mir", "an\u00b7zu\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "APPR", "PPER", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Legte mich hin und ist gegangen.", "tokens": ["Leg\u00b7te", "mich", "hin", "und", "ist", "ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "KON", "VAFIN", "VVPP", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.35": {"line.1": {"text": "Hat mich getrennt zur\u00fcckgelassen", "tokens": ["Hat", "mich", "ge\u00b7trennt", "zu\u00b7r\u00fcck\u00b7ge\u00b7las\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "VVPP", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie Unterteller ohne Tassen.", "tokens": ["Wie", "Un\u00b7ter\u00b7tel\u00b7ler", "oh\u00b7ne", "Tas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Unheimlich war mir meine Haut,", "tokens": ["Un\u00b7heim\u00b7lich", "war", "mir", "mei\u00b7ne", "Haut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die W\u00e4nde h\u00f6rt' ich sprechen laut.", "tokens": ["Die", "W\u00e4n\u00b7de", "h\u00f6rt'", "ich", "spre\u00b7chen", "laut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Wie Stimmer stimmen ein Klavier,", "tokens": ["Wie", "Stim\u00b7mer", "stim\u00b7men", "ein", "Kla\u00b7vier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "So sa\u00df ich horchend neben mir.", "tokens": ["So", "sa\u00df", "ich", "hor\u00b7chend", "ne\u00b7ben", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "Kam mir als Leichenwache vor,", "tokens": ["Kam", "mir", "als", "Lei\u00b7chen\u00b7wa\u00b7che", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "KOUS", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df ich in allen Pulsen fror.", "tokens": ["Da\u00df", "ich", "in", "al\u00b7len", "Pul\u00b7sen", "fror", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "An jedem Weg, den ich jetzt nahm,", "tokens": ["An", "je\u00b7dem", "Weg", ",", "den", "ich", "jetzt", "nahm", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mir eine tote Katz' vorkam.", "tokens": ["Mir", "ei\u00b7ne", "to\u00b7te", "Katz'", "vor\u00b7kam", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Und all die vielen Katzenleichen", "tokens": ["Und", "all", "die", "vie\u00b7len", "Kat\u00b7zen\u00b7lei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mu\u00dft' ich mit jenem Traum vergleichen,", "tokens": ["Mu\u00dft'", "ich", "mit", "je\u00b7nem", "Traum", "ver\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Wo ich K\u00f6nigin einst gesehn", "tokens": ["Wo", "ich", "K\u00f6\u00b7ni\u00b7gin", "einst", "ge\u00b7sehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "NN", "ADV", "VVPP"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Als Katz' mit Menschenkopf umgehn.", "tokens": ["Als", "Katz'", "mit", "Men\u00b7schen\u00b7kopf", "um\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Und st\u00fcndlich sa\u00df ich wie auf Steinen,", "tokens": ["Und", "st\u00fcnd\u00b7lich", "sa\u00df", "ich", "wie", "auf", "Stei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "KOKOM", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und tat mein K\u00e4tzlein hei\u00df beweinen.", "tokens": ["Und", "tat", "mein", "K\u00e4tz\u00b7lein", "hei\u00df", "be\u00b7wei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Ich tat mich st\u00fcndlich steinigen,", "tokens": ["Ich", "tat", "mich", "st\u00fcnd\u00b7lich", "stei\u00b7ni\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und konnt' mich nicht mehr reinigen.", "tokens": ["Und", "konnt'", "mich", "nicht", "mehr", "rei\u00b7ni\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "Und so wie kirchliche Ruinen", "tokens": ["Und", "so", "wie", "kirch\u00b7li\u00b7che", "Ru\u00b7i\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "KOKOM", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bin ruiniert ich mir erschienen;", "tokens": ["Bin", "ru\u00b7i\u00b7niert", "ich", "mir", "er\u00b7schie\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.45": {"line.1": {"text": "Ich sah am Meer einst hingefallen", "tokens": ["Ich", "sah", "am", "Meer", "einst", "hin\u00b7ge\u00b7fal\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Verschimmelt achtzehn Kathedralen;", "tokens": ["Ver\u00b7schim\u00b7melt", "acht\u00b7zehn", "Ka\u00b7thed\u00b7ra\u00b7len", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "CARD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Auf Gotland in der Wisbystadt", "tokens": ["Auf", "Got\u00b7land", "in", "der", "Wis\u00b7by\u00b7stadt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verbrannt man alle achtzehn hat.", "tokens": ["Ver\u00b7brannt", "man", "al\u00b7le", "acht\u00b7zehn", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PIAT", "CARD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.47": {"line.1": {"text": "Wo Ohrenbeicht' einst und Te Deum,", "tokens": ["Wo", "Oh\u00b7ren\u00b7beicht'", "einst", "und", "Te", "Deum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Strichen frivol die Seel\u00fcfte um,", "tokens": ["Stri\u00b7chen", "fri\u00b7vol", "die", "See\u00b7l\u00fcf\u00b7te", "um", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}}, "stanza.48": {"line.1": {"text": "Wo sonst der Heiligen Gedr\u00e4nge,", "tokens": ["Wo", "sonst", "der", "Hei\u00b7li\u00b7gen", "Ge\u00b7dr\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Gehn K\u00fche kauend durch Grasg\u00e4nge,", "tokens": ["Gehn", "K\u00fc\u00b7he", "kau\u00b7end", "durch", "Gras\u00b7g\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}}, "stanza.49": {"line.1": {"text": "Die Glocken rosten, tief begraben,", "tokens": ["Die", "Glo\u00b7cken", "ros\u00b7ten", ",", "tief", "be\u00b7gra\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Statt Priester predigen die Raben,", "tokens": ["Statt", "Pries\u00b7ter", "pre\u00b7di\u00b7gen", "die", "Ra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "Der Fensterrosen Blutrubinen,", "tokens": ["Der", "Fens\u00b7ter\u00b7ro\u00b7sen", "Blu\u00b7tru\u00b7bi\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die rot aufs Meer zur Nacht noch schienen,", "tokens": ["Die", "rot", "aufs", "Meer", "zur", "Nacht", "noch", "schie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPRART", "NN", "APPRART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "Sind L\u00f6cher, und wo sonst die Rose,", "tokens": ["Sind", "L\u00f6\u00b7cher", ",", "und", "wo", "sonst", "die", "Ro\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "KON", "PWAV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Schaut jetzt ein Loch ins Seelenlose.", "tokens": ["Schaut", "jetzt", "ein", "Loch", "ins", "See\u00b7len\u00b7lo\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.52": {"line.1": {"text": "Ein D\u00e4nenschiff mit Kirchensch\u00e4tzen", "tokens": ["Ein", "D\u00e4\u00b7nen\u00b7schiff", "mit", "Kir\u00b7chen\u00b7sch\u00e4t\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Tat damals sich zum Meergrund setzen.", "tokens": ["Tat", "da\u00b7mals", "sich", "zum", "Meer\u00b7grund", "set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PRF", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.53": {"line.1": {"text": "Die Heiligen waren zu schwer", "tokens": ["Die", "Hei\u00b7li\u00b7gen", "wa\u00b7ren", "zu", "schwer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PTKA", "ADJD"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Dem alten grauen Heidenmeer.", "tokens": ["Dem", "al\u00b7ten", "grau\u00b7en", "Hei\u00b7den\u00b7meer", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.54": {"line.1": {"text": "Die Heiligen verschwanden unten,", "tokens": ["Die", "Hei\u00b7li\u00b7gen", "ver\u00b7schwan\u00b7den", "un\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Haben nie mehr heraufgefunden.", "tokens": ["Ha\u00b7ben", "nie", "mehr", "her\u00b7auf\u00b7ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.55": {"line.1": {"text": "So krumm voll Unkraut unterm Himmel,", "tokens": ["So", "krumm", "voll", "Un\u00b7kraut", "un\u00b7term", "Him\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJD", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sch\u00f6n, einst voll Bilder, jetzt voll Schimmel,", "tokens": ["Sch\u00f6n", ",", "einst", "voll", "Bil\u00b7der", ",", "jetzt", "voll", "Schim\u00b7mel", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "ADJD", "NN", "$,", "ADV", "ADJD", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.56": {"line.1": {"text": "Belegt mit Meersalz und zerfallen,", "tokens": ["Be\u00b7legt", "mit", "Meer\u00b7salz", "und", "zer\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Glich ich den achtzehn Kathedralen.", "tokens": ["Glich", "ich", "den", "acht\u00b7zehn", "Ka\u00b7thed\u00b7ra\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "ART", "CARD", "NN", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}}}}}