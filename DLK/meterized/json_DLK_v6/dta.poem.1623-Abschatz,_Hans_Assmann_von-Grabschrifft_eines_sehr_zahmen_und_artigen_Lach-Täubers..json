{"dta.poem.1623": {"metadata": {"author": {"name": "Abschatz, Hans Assmann von", "birth": "N.A.", "death": "N.A."}, "title": "Grabschrifft eines sehr zahmen und artigen  \n Lach-T\u00e4ubers.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1704", "urn": "urn:nbn:de:kobv:b4-200905199889", "language": ["de:0.99"], "booktitle": "Abschatz, Hans Assmann von: Poetische Ubersetzungen und Gedichte. Leipzig, 1704."}, "poem": {"stanza.1": {"line.1": {"text": "Hier find ich Ruh und Grab/ ein Ph\u00f6nix meiner Art/ ", "tokens": ["Hier", "find", "ich", "Ruh", "und", "Grab", "/", "ein", "Ph\u00f6\u00b7nix", "mei\u00b7ner", "Art", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "KON", "NN", "$(", "ART", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Edlen T\u00e4uber Ruhm/ nach meiner Todes-Fahrt/", "tokens": ["Der", "Ed\u00b7len", "T\u00e4u\u00b7ber", "Ruhm", "/", "nach", "mei\u00b7ner", "To\u00b7des\u00b7Fahrt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$(", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nicht lache dieser Schrifft: Ich konte mich mit lachen", "tokens": ["Nicht", "la\u00b7che", "die\u00b7ser", "Schrifft", ":", "Ich", "kon\u00b7te", "mich", "mit", "la\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "VVFIN", "PDAT", "NN", "$.", "PPER", "VMFIN", "PRF", "APPR", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "(des Menschen Eigenthum) dir selber \u00e4hnlich machen.", "tokens": ["(", "des", "Men\u00b7schen", "Ei\u00b7gen\u00b7thum", ")", "dir", "sel\u00b7ber", "\u00e4hn\u00b7lich", "ma\u00b7chen", "."], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "NN", "$(", "PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Mein treues Artlich-seyn/ mein angenehmer Schertz/", "tokens": ["Mein", "treu\u00b7es", "Art\u00b7lich\u00b7seyn", "/", "mein", "an\u00b7ge\u00b7neh\u00b7mer", "Schertz", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$(", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Erwarb des Herren Gunst/ gewann der Frauen Hertz.", "tokens": ["Er\u00b7warb", "des", "Her\u00b7ren", "Gunst", "/", "ge\u00b7wann", "der", "Frau\u00b7en", "Hertz", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "$(", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wird Heucheley und List zu Hofe sonst getrieben/", "tokens": ["Wird", "Heu\u00b7che\u00b7ley", "und", "List", "zu", "Ho\u00b7fe", "sonst", "ge\u00b7trie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "APPR", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich bin stets ohne Fleck/ wie ohne Galle/ blieben.", "tokens": ["Ich", "bin", "stets", "oh\u00b7ne", "Fleck", "/", "wie", "oh\u00b7ne", "Gal\u00b7le", "/", "blie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "NN", "$(", "KOKOM", "APPR", "NN", "$(", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Es ehrt ", "tokens": ["Es", "ehrt"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Manch F\u00fcrst/ manch kluger Mann/ Hund/ Pferd und Ele-", "tokens": ["Manch", "F\u00fcrst", "/", "manch", "klu\u00b7ger", "Mann", "/", "Hund", "/", "Pferd", "und", "E\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "NN", "$(", "PIAT", "ADJA", "NN", "$(", "NN", "$(", "NN", "KON", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Tauben werden nicht von jenen \u00fcberwunden:", "tokens": ["Die", "Tau\u00b7ben", "wer\u00b7den", "nicht", "von", "je\u00b7nen", "\u00fc\u00b7berw\u00b7un\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "APPR", "PDAT", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein kluger ", "tokens": ["Ein", "klu\u00b7ger"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.4": {"line.1": {"text": "Ihr Boten in der Lufft bringts nach Aleppo hin/", "tokens": ["Ihr", "Bo\u00b7ten", "in", "der", "Lufft", "bringts", "nach", "A\u00b7lep\u00b7po", "hin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "VVFIN", "APPR", "NE", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Thut Post auff Babylon/ da\u00df ich gestorben bin/", "tokens": ["Thut", "Post", "auff", "Ba\u00b7by\u00b7lon", "/", "da\u00df", "ich", "ge\u00b7stor\u00b7ben", "bin", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "NE", "$(", "KOUS", "PPER", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nahnt alle Kr\u00f6pffer an/ da\u00df sie zu lezten Ehren", "tokens": ["Nahnt", "al\u00b7le", "Kr\u00f6pf\u00b7fer", "an", "/", "da\u00df", "sie", "zu", "lez\u00b7ten", "Eh\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIAT", "NN", "PTKVZ", "$(", "KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein trauriges Ragu und Drommeln lassen h\u00f6ren.", "tokens": ["Ein", "trau\u00b7ri\u00b7ges", "Ra\u00b7gu", "und", "Drom\u00b7meln", "las\u00b7sen", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Cythere spannt mich nun an ihren Wagen an/", "tokens": ["Cy\u00b7the\u00b7re", "spannt", "mich", "nun", "an", "ih\u00b7ren", "Wa\u00b7gen", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Am Himmel weichet mir der Leda weicher Schwan.", "tokens": ["Am", "Him\u00b7mel", "wei\u00b7chet", "mir", "der", "Le\u00b7da", "wei\u00b7cher", "Schwan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mein wohl-verdienter Ruhm mit Papogeyen-Schwingen", "tokens": ["Mein", "wohl\u00b7ver\u00b7dien\u00b7ter", "Ruhm", "mit", "Pa\u00b7po\u00b7geyen\u00b7Schwin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "NN"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Wird den gestirnten Pfau aus seinem Neste dringen.", "tokens": ["Wird", "den", "ge\u00b7stirn\u00b7ten", "Pfau", "aus", "sei\u00b7nem", "Nes\u00b7te", "drin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Sagt ein Pythagoras von unsern Geistern wahr/", "tokens": ["Sagt", "ein", "Py\u00b7tha\u00b7go\u00b7ras", "von", "un\u00b7sern", "Geis\u00b7tern", "wahr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NE", "APPR", "PPOSAT", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So erbt den meinigen ein wohlgeschickter Stahr:", "tokens": ["So", "erbt", "den", "mei\u00b7ni\u00b7gen", "ein", "wohl\u00b7ge\u00b7schick\u00b7ter", "Stahr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "PPOSS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch soll er hundert Jahr gleich einer Kr\u00e4he leben/", "tokens": ["Doch", "soll", "er", "hun\u00b7dert", "Jahr", "gleich", "ei\u00b7ner", "Kr\u00e4\u00b7he", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "CARD", "NN", "ADV", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und meiner Herrschafft/ an statt mein/ Vergn\u00fcgen geben.", "tokens": ["Und", "mei\u00b7ner", "Herr\u00b7schafft", "/", "an", "statt", "mein", "/", "Ver\u00b7gn\u00fc\u00b7gen", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$(", "APPR", "APPR", "PPOSAT", "$(", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}