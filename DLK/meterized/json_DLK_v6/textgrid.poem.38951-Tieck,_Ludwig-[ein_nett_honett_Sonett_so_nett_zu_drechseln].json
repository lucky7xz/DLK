{"textgrid.poem.38951": {"metadata": {"author": {"name": "Tieck, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "[ein nett honett Sonett so nett zu drechseln]", "genre": "verse", "period": "N.A.", "pub_year": 1813, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein nett honett Sonett so nett zu drechseln", "tokens": ["Ein", "nett", "ho\u00b7nett", "So\u00b7nett", "so", "nett", "zu", "drech\u00b7seln"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJD", "NN", "ADV", "ADJD", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ist nicht so leicht, ihr Kinderchen, das wett' ich,", "tokens": ["Ist", "nicht", "so", "leicht", ",", "ihr", "Kin\u00b7der\u00b7chen", ",", "das", "wett'", "ich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADV", "ADJD", "$,", "PPOSAT", "NN", "$,", "PDS", "VVFIN", "PPER", "$,"], "meter": "-+-+-+--++-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ihr nennt's Sonett, doch klingt es nicht sonettig,", "tokens": ["Ihr", "nennt's", "So\u00b7nett", ",", "doch", "klingt", "es", "nicht", "so\u00b7net\u00b7tig", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "ADV", "VVFIN", "PPER", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Statt Haber f\u00fcttert ihr den Gaul mit Hexeln.", "tokens": ["Statt", "Ha\u00b7ber", "f\u00fct\u00b7tert", "ihr", "den", "Gaul", "mit", "He\u00b7xeln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "PPER", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.2": {"line.1": {"text": "Dergleichen Dinge mu\u00df man nicht verwechseln;", "tokens": ["Derg\u00b7lei\u00b7chen", "Din\u00b7ge", "mu\u00df", "man", "nicht", "ver\u00b7wech\u00b7seln", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "NN", "VMFIN", "PIS", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein Unterschied ist zwischen einen Rettig,", "tokens": ["Ein", "Un\u00b7ter\u00b7schied", "ist", "zwi\u00b7schen", "ei\u00b7nen", "Ret\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "ART", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und ritt' ich, rutsch' ich, rumpl' ich, oder rett' ich,", "tokens": ["Und", "ritt'", "ich", ",", "rut\u00b7sch'", "ich", ",", "rum\u00b7pl'", "ich", ",", "o\u00b7der", "rett'", "ich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "$,", "KON", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auch Dichten, D\u00fcnnen, Singen, Kr\u00e4hen, Kr\u00e4chzeln.", "tokens": ["Auch", "Dich\u00b7ten", ",", "D\u00fcn\u00b7nen", ",", "Sin\u00b7gen", ",", "Kr\u00e4\u00b7hen", ",", "Kr\u00e4ch\u00b7zeln", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Drum liegt im Hafen stille doch ein Weilchen,", "tokens": ["Drum", "liegt", "im", "Ha\u00b7fen", "stil\u00b7le", "doch", "ein", "Weil\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "APPRART", "NN", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und lasset hier das kranke Schiff ausbessern,", "tokens": ["Und", "las\u00b7set", "hier", "das", "kran\u00b7ke", "Schiff", "aus\u00b7bes\u00b7sern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "ADJA", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Es zeigt mehr Leck' als Schiff in seiner Fl\u00e4che:", "tokens": ["Es", "zeigt", "mehr", "Leck'", "als", "Schiff", "in", "sei\u00b7ner", "Fl\u00e4\u00b7che", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "KOUS", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Noch lecker wird es, ihr bezahlt die Zeche,", "tokens": ["Noch", "le\u00b7cker", "wird", "es", ",", "ihr", "be\u00b7zahlt", "die", "Ze\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "PPER", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch d\u00fcnkt uns lecker nicht ein einzig Zeilchen;", "tokens": ["Doch", "d\u00fcnkt", "uns", "le\u00b7cker", "nicht", "ein", "ein\u00b7zig", "Zeil\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "PTKNEG", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Nach lauem Wasser kann kein Mund je w\u00e4ssern.", "tokens": ["Nach", "lau\u00b7em", "Was\u00b7ser", "kann", "kein", "Mund", "je", "w\u00e4s\u00b7sern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "PIAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}