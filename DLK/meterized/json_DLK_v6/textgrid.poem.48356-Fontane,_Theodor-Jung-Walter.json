{"textgrid.poem.48356": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Jung-Walter", "genre": "verse", "period": "N.A.", "pub_year": 1855, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Um Weihnachten war's, der Wind blies kalt", "tokens": ["Um", "Weih\u00b7nach\u00b7ten", "wa\u00b7r's", ",", "der", "Wind", "blies", "kalt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUI", "NN", "VAFIN", "$,", "ART", "NN", "VVFIN", "ADJD"], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.2": {"text": "Und die Tafelrunde begann,", "tokens": ["Und", "die", "Ta\u00b7fel\u00b7run\u00b7de", "be\u00b7gann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Da kam an den Hof des K\u00f6nigs", "tokens": ["Da", "kam", "an", "den", "Hof", "des", "K\u00f6\u00b7nigs"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Manch schottischer Rittersmann.", "tokens": ["Manch", "schot\u00b7ti\u00b7scher", "Rit\u00b7ters\u00b7mann", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Der K\u00f6nig und die K\u00f6nigin", "tokens": ["Der", "K\u00f6\u00b7nig", "und", "die", "K\u00f6\u00b7ni\u00b7gin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Schauten nieder von ihrem Schlo\u00df:", "tokens": ["Schau\u00b7ten", "nie\u00b7der", "von", "ih\u00b7rem", "Schlo\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Da sahen sie kommen Jung-Walter,", "tokens": ["Da", "sa\u00b7hen", "sie", "kom\u00b7men", "Jung\u00b7Wal\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Jung-Walter hoch zu Ro\u00df.", "tokens": ["Jung\u00b7Wal\u00b7ter", "hoch", "zu", "Ro\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Seine L\u00e4ufer liefen vor ihm her,", "tokens": ["Sei\u00b7ne", "L\u00e4u\u00b7fer", "lie\u00b7fen", "vor", "ihm", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Seine Reiter folgten ihm dicht,", "tokens": ["Sei\u00b7ne", "Rei\u00b7ter", "folg\u00b7ten", "ihm", "dicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Und sein Mantel wie von Golde", "tokens": ["Und", "sein", "Man\u00b7tel", "wie", "von", "Gol\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "KOKOM", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Blitzte im Sonnenlicht.", "tokens": ["Blitz\u00b7te", "im", "Son\u00b7nen\u00b7licht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.4": {"line.1": {"text": "Und von Golde waren die Decken,", "tokens": ["Und", "von", "Gol\u00b7de", "wa\u00b7ren", "die", "De\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "VAFIN", "ART", "NN", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und die Hufe von Silber hell,", "tokens": ["Und", "die", "Hu\u00b7fe", "von", "Sil\u00b7ber", "hell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "NN", "ADJD", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und das Ro\u00df, auf dem Jung-Walter ritt,", "tokens": ["Und", "das", "Ro\u00df", ",", "auf", "dem", "Jung\u00b7Wal\u00b7ter", "ritt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "War wie der Wind so schnell.", "tokens": ["War", "wie", "der", "Wind", "so", "schnell", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Da sprach ein t\u00fcckischer H\u00f6fling,", "tokens": ["Da", "sprach", "ein", "t\u00fc\u00b7cki\u00b7scher", "H\u00f6f\u00b7ling", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Der neben der K\u00f6nigin stand:", "tokens": ["Der", "ne\u00b7ben", "der", "K\u00f6\u00b7ni\u00b7gin", "stand", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+---+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "\u00bbwer ist der sch\u00f6nste Ritter", "tokens": ["\u00bb", "wer", "ist", "der", "sch\u00f6ns\u00b7te", "Rit\u00b7ter"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PWS", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "In Hoch- und Niederland?\u00ab", "tokens": ["In", "Hoch", "und", "Nie\u00b7der\u00b7land", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "TRUNC", "KON", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "\u00bbich habe gesehn viel Lords und Lairds,", "tokens": ["\u00bb", "ich", "ha\u00b7be", "ge\u00b7sehn", "viel", "Lords", "und", "Lairds", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "VVPP", "PIAT", "NN", "KON", "NE", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Manch sch\u00f6nen Ritters Gesicht,", "tokens": ["Manch", "sch\u00f6\u00b7nen", "Rit\u00b7ters", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Einen sch\u00f6neren als Jung-Walter", "tokens": ["Ei\u00b7nen", "sch\u00f6\u00b7ne\u00b7ren", "als", "Jung\u00b7Wal\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "KOUS", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Sah ich mein Lebtag nicht.\u00ab", "tokens": ["Sah", "ich", "mein", "Leb\u00b7tag", "nicht", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "PTKNEG", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Das h\u00f6rte der neidische K\u00f6nig,", "tokens": ["Das", "h\u00f6r\u00b7te", "der", "nei\u00b7di\u00b7sche", "K\u00f6\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Seine Wange verf\u00e4rbte sich:", "tokens": ["Sei\u00b7ne", "Wan\u00b7ge", "ver\u00b7f\u00e4rb\u00b7te", "sich", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "\u00bbund w\u00e4r' er zweimal sch\u00f6ner,", "tokens": ["\u00bb", "und", "w\u00e4r'", "er", "zwei\u00b7mal", "sch\u00f6\u00b7ner", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Erst nennen mu\u00dftest du mich.\u00ab", "tokens": ["Erst", "nen\u00b7nen", "mu\u00df\u00b7test", "du", "mich", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "PPER", "PRF", "$.", "$("], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.8": {"line.1": {"text": "\u00bbdu bist kein Lord und du bist kein Laird,", "tokens": ["\u00bb", "du", "bist", "kein", "Lord", "und", "du", "bist", "kein", "Laird", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PIAT", "NN", "KON", "PPER", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Du bist K\u00f6nig \u00fcber sie all',", "tokens": ["Du", "bist", "K\u00f6\u00b7nig", "\u00fc\u00b7ber", "sie", "all'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "APPR", "PPER", "PIS", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Da ist kein Ritter in Schottland,", "tokens": ["Da", "ist", "kein", "Rit\u00b7ter", "in", "Schott\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "APPR", "NE", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Der nicht w\u00e4re dein Vasall.\u00ab", "tokens": ["Der", "nicht", "w\u00e4\u00b7re", "dein", "Va\u00b7sall", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PTKNEG", "VAFIN", "PPOSAT", "NN", "$.", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.9": {"line.1": {"text": "Die K\u00f6nigin sprach es bang und bla\u00df,", "tokens": ["Die", "K\u00f6\u00b7ni\u00b7gin", "sprach", "es", "bang", "und", "bla\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der K\u00f6nig ward blutrot; \u2013", "tokens": ["Der", "K\u00f6\u00b7nig", "ward", "blut\u00b7rot", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Jung-Walter, da\u00df so sch\u00f6n du bist,", "tokens": ["Jung\u00b7Wal\u00b7ter", ",", "da\u00df", "so", "sch\u00f6n", "du", "bist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "ADV", "ADJD", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das bringt dir nun den Tod.", "tokens": ["Das", "bringt", "dir", "nun", "den", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Sie haben ihn flugs ergriffen,", "tokens": ["Sie", "ha\u00b7ben", "ihn", "flugs", "er\u00b7grif\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ihn sicher eingehegt,", "tokens": ["Ihn", "si\u00b7cher", "ein\u00b7ge\u00b7hegt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie haben Jung-Walter ergriffen", "tokens": ["Sie", "ha\u00b7ben", "Jung\u00b7Wal\u00b7ter", "er\u00b7grif\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "VVPP"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Und ihn in Ketten gelegt.", "tokens": ["Und", "ihn", "in", "Ket\u00b7ten", "ge\u00b7legt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.11": {"line.1": {"text": "\u00bboft bin ich geritten durch Stirling", "tokens": ["\u00bb", "oft", "bin", "ich", "ge\u00b7rit\u00b7ten", "durch", "Stir\u00b7ling"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VAFIN", "PPER", "VVPP", "APPR", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Bei Wetter und Regengu\u00df,", "tokens": ["Bei", "Wet\u00b7ter", "und", "Re\u00b7gen\u00b7gu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Nie bin ich geritten durch Stirling", "tokens": ["Nie", "bin", "ich", "ge\u00b7rit\u00b7ten", "durch", "Stir\u00b7ling"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "APPR", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Mit Ketten an Hand und Fu\u00df.", "tokens": ["Mit", "Ket\u00b7ten", "an", "Hand", "und", "Fu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "Oft bin ich geritten durch Stirling", "tokens": ["Oft", "bin", "ich", "ge\u00b7rit\u00b7ten", "durch", "Stir\u00b7ling"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "APPR", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Bei Regen und Windeswehn,", "tokens": ["Bei", "Re\u00b7gen", "und", "Win\u00b7des\u00b7wehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Nie bin ich geritten durch Stirling,", "tokens": ["Nie", "bin", "ich", "ge\u00b7rit\u00b7ten", "durch", "Stir\u00b7ling", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "APPR", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Um's nimmer wiederzusehn.\u00ab", "tokens": ["Um's", "nim\u00b7mer", "wie\u00b7der\u00b7zu\u00b7sehn", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NE", "ADV", "VVINF", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.13": {"line.1": {"text": "Am Fu\u00df des H\u00fcgels noch einmal", "tokens": ["Am", "Fu\u00df", "des", "H\u00fc\u00b7gels", "noch", "ein\u00b7mal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sah er Wappen und Helm und Schwert,", "tokens": ["Sah", "er", "Wap\u00b7pen", "und", "Helm", "und", "Schwert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Am Fu\u00df des H\u00fcgels noch einmal", "tokens": ["Am", "Fu\u00df", "des", "H\u00fc\u00b7gels", "noch", "ein\u00b7mal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sah er Sattel und Zaum und Pferd.", "tokens": ["Sah", "er", "Sat\u00b7tel", "und", "Zaum", "und", "Pferd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.14": {"line.1": {"text": "Am Fu\u00df des H\u00fcgels noch einmal", "tokens": ["Am", "Fu\u00df", "des", "H\u00fc\u00b7gels", "noch", "ein\u00b7mal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sah er seine Lady sch\u00f6n \u2013", "tokens": ["Sah", "er", "sei\u00b7ne", "La\u00b7dy", "sch\u00f6n", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Um das W\u00f6rtlein, das die K\u00f6nigin sprach,", "tokens": ["Um", "das", "W\u00f6rt\u00b7lein", ",", "das", "die", "K\u00f6\u00b7ni\u00b7gin", "sprach", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Mu\u00dft' sie ihn sterben sehn.", "tokens": ["Mu\u00dft'", "sie", "ihn", "ster\u00b7ben", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}