{"dta.poem.11360": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Auf den geburts-tag seiner Hoch-F\u00fcrstl.  \n Durchl. Hertzog Albrechts zu  \n Sachsen-Coburg, rc.  \n B. N.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1709", "urn": "urn:nbn:de:kobv:b4-20283-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Jhr m\u00fcden schafe! geht, geniesset eurer ruh!", "tokens": ["Ihr", "m\u00fc\u00b7den", "scha\u00b7fe", "!", "geht", ",", "ge\u00b7nies\u00b7set", "eu\u00b7rer", "ruh", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "VVFIN", "$.", "VVFIN", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und schlie\u00dft die augen dort an jenem berge zu,", "tokens": ["Und", "schlie\u00dft", "die", "au\u00b7gen", "dort", "an", "je\u00b7nem", "ber\u00b7ge", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "APPR", "PDAT", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wo Coburgs reicher Pan auf den begr\u00fcnten auen", "tokens": ["Wo", "Co\u00b7burgs", "rei\u00b7cher", "Pan", "auf", "den", "be\u00b7gr\u00fcn\u00b7ten", "au\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NE", "ADJD", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Uns neulich unverhofft lie\u00df seine l\u00e4mmer schauen!", "tokens": ["Uns", "neu\u00b7lich", "un\u00b7ver\u00b7hofft", "lie\u00df", "sei\u00b7ne", "l\u00e4m\u00b7mer", "schau\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "VVFIN", "PPOSAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du aber, grosser F\u00fcrst! nimm meine lieder an!", "tokens": ["Du", "a\u00b7ber", ",", "gros\u00b7ser", "F\u00fcrst", "!", "nimm", "mei\u00b7ne", "lie\u00b7der", "an", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "ADJA", "NN", "$.", "VVIMP", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Denn ob ich \u00e4rmster gleich nichts hohes singen kan,", "tokens": ["Denn", "ob", "ich", "\u00e4rms\u00b7ter", "gleich", "nichts", "ho\u00b7hes", "sin\u00b7gen", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "ADV", "PIS", "ADJA", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und etwan nicht mein rohr und meine weiden-fl\u00f6te", "tokens": ["Und", "et\u00b7wan", "nicht", "mein", "rohr", "und", "mei\u00b7ne", "wei\u00b7den\u00b7fl\u00f6\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PTKNEG", "PPOSAT", "NN", "KON", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So majest\u00e4tisch klingt, als deine feld-trompete;", "tokens": ["So", "ma\u00b7jes\u00b7t\u00e4\u00b7tisch", "klingt", ",", "als", "dei\u00b7ne", "feld\u00b7trom\u00b7pe\u00b7te", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So wei\u00df ich dennoch wohl, da\u00df dir die sch\u00e4ferey", "tokens": ["So", "wei\u00df", "ich", "den\u00b7noch", "wohl", ",", "da\u00df", "dir", "die", "sch\u00e4\u00b7fe\u00b7rey"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und unser hirten-spiel nicht gantz zuwider sey:", "tokens": ["Und", "un\u00b7ser", "hir\u00b7ten\u00b7spiel", "nicht", "gantz", "zu\u00b7wi\u00b7der", "sey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PTKNEG", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Sonst h\u00e4ttest du, o Mars! nicht noch vor wenig tagen", "tokens": ["Sonst", "h\u00e4t\u00b7test", "du", ",", "o", "Mars", "!", "nicht", "noch", "vor", "we\u00b7nig", "ta\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "$,", "FM", "NN", "$.", "PTKNEG", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Dein tapffer krieges-zelt bey h\u00fcrden aufgeschlagen.", "tokens": ["Dein", "tapf\u00b7fer", "krie\u00b7ge\u00b7szelt", "bey", "h\u00fcr\u00b7den", "auf\u00b7ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Es sind f\u00fcnff wochen um, da\u00df ich die k\u00fchnheit nahm,", "tokens": ["Es", "sind", "f\u00fcnff", "wo\u00b7chen", "um", ",", "da\u00df", "ich", "die", "k\u00fchn\u00b7heit", "nahm", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "CARD", "NN", "PTKVZ", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und aus der Brennen land in diese grentzen kam.", "tokens": ["Und", "aus", "der", "Bren\u00b7nen", "land", "in", "die\u00b7se", "grent\u00b7zen", "kam", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Das erste, was ich sah, und ewig will gedencken,", "tokens": ["Das", "ers\u00b7te", ",", "was", "ich", "sah", ",", "und", "e\u00b7wig", "will", "ge\u00b7den\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PWS", "PPER", "VVFIN", "$,", "KON", "ADJD", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "War, da\u00df du woll und vieh lie\u00dft deiner f\u00fcrstin schencken.", "tokens": ["War", ",", "da\u00df", "du", "woll", "und", "vieh", "lie\u00dft", "dei\u00b7ner", "f\u00fcrs\u00b7tin", "schen\u00b7cken", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "KOUS", "PPER", "VMFIN", "KON", "ADV", "VVFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ach! dacht ich bey mir selbst: Ist hier noch g\u00fcldne zeit,", "tokens": ["Ach", "!", "dacht", "ich", "bey", "mir", "selbst", ":", "Ist", "hier", "noch", "g\u00fcld\u00b7ne", "zeit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "APPR", "PPER", "ADV", "$.", "VAFIN", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Da Mars die halbe welt mit kugelu \u00fcberstreut?", "tokens": ["Da", "Mars", "die", "hal\u00b7be", "welt", "mit", "ku\u00b7ge\u00b7lu", "\u00fc\u00b7bers\u00b7treut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ART", "ADJA", "NN", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Da sich ein teutscher mann nicht mehr in Teutschland kennet:", "tokens": ["Da", "sich", "ein", "teut\u00b7scher", "mann", "nicht", "mehr", "in", "Teutschland", "ken\u00b7net", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "ADJA", "NN", "PTKNEG", "ADV", "APPR", "NE", "VVFIN", "$."], "meter": "---+--++-+--", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "Ein kind den vater nicht in seiner sprache nennet:", "tokens": ["Ein", "kind", "den", "va\u00b7ter", "nicht", "in", "sei\u00b7ner", "spra\u00b7che", "nen\u00b7net", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKNEG", "APPR", "PPOSAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Die speise nach Pari\u00df, der wein nach Welschland schmeckt:", "tokens": ["Die", "spei\u00b7se", "nach", "Pa\u00b7ri\u00df", ",", "der", "wein", "nach", "Wel\u00b7schland", "schmeckt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "NE", "$,", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und offt ein gantzer kram in einem kleide steckt?", "tokens": ["Und", "offt", "ein", "gant\u00b7zer", "kram", "in", "ei\u00b7nem", "klei\u00b7de", "steckt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "APPR", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Wei\u00df Coburg noch allein nicht von den fetten tagen,", "tokens": ["Wei\u00df", "Co\u00b7burg", "noch", "al\u00b7lein", "nicht", "von", "den", "fet\u00b7ten", "ta\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "ADV", "PTKNEG", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Die so viel reiche mehr, als pest und krieg, geschlagen?", "tokens": ["Die", "so", "viel", "rei\u00b7che", "mehr", ",", "als", "pest", "und", "krieg", ",", "ge\u00b7schla\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VVFIN", "ADV", "$,", "KOUS", "ADJD", "KON", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die dir, o Hannibal! den degen stumpff gemacht:", "tokens": ["Die", "dir", ",", "o", "Han\u00b7ni\u00b7bal", "!", "den", "de\u00b7gen", "stumpff", "ge\u00b7macht", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "FM", "NE", "$.", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Das aufgeblehte Rom durch Rom zu falle bracht:", "tokens": ["Das", "auf\u00b7ge\u00b7bleh\u00b7te", "Rom", "durch", "Rom", "zu", "fal\u00b7le", "bracht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NE", "APPR", "NE", "PTKZU", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Und unser vaterland bi\u00df auf das blut aussaugen?", "tokens": ["Und", "un\u00b7ser", "va\u00b7ter\u00b7land", "bi\u00df", "auf", "das", "blut", "aus\u00b7sau\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "So dacht ich, und belief die gegend mit den augen,", "tokens": ["So", "dacht", "ich", ",", "und", "be\u00b7lief", "die", "ge\u00b7gend", "mit", "den", "au\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KON", "VVFIN", "ART", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Ich sah bald feld und hof, bald kirch und schulen an;", "tokens": ["Ich", "sah", "bald", "feld", "und", "hof", ",", "bald", "kirch", "und", "schu\u00b7len", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "KON", "NN", "$,", "ADV", "ADJD", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Doch alles, was ich sah, war klug und wohl gethan.", "tokens": ["Doch", "al\u00b7les", ",", "was", "ich", "sah", ",", "war", "klug", "und", "wohl", "ge\u00b7than", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,", "VAFIN", "ADJD", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Denn Albrechts hoher witz erschien in allen st\u00e4nden,", "tokens": ["Denn", "Al\u00b7brechts", "ho\u00b7her", "witz", "er\u00b7schien", "in", "al\u00b7len", "st\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADJA", "NN", "VVFIN", "APPR", "PIAT", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "So artig, da\u00df ich nichts sah ohne noth verschwenden,", "tokens": ["So", "ar\u00b7tig", ",", "da\u00df", "ich", "nichts", "sah", "oh\u00b7ne", "noth", "ver\u00b7schwen\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "PPER", "PIS", "VVFIN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Und gleichwohl alles fand, was f\u00fcrsten zugeh\u00f6rt.", "tokens": ["Und", "gleich\u00b7wohl", "al\u00b7les", "fand", ",", "was", "f\u00fcrs\u00b7ten", "zu\u00b7ge\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIS", "VVFIN", "$,", "PWS", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Die mauren waren noch durch keinen feind versehrt:", "tokens": ["Die", "mau\u00b7ren", "wa\u00b7ren", "noch", "durch", "kei\u00b7nen", "feind", "ver\u00b7sehrt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Die b\u00fcrger wusten mir nichts widrigas zu sagen,", "tokens": ["Die", "b\u00fcr\u00b7ger", "wus\u00b7ten", "mir", "nichts", "wid\u00b7ri\u00b7gas", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "PIS", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Als was bey theurer zeit die gantze welt mu\u00df klagen.", "tokens": ["Als", "was", "bey", "theu\u00b7rer", "zeit", "die", "gant\u00b7ze", "welt", "mu\u00df", "kla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ADJA", "NN", "ART", "ADJA", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Mit kurtzem: Ich erfuhr, da\u00df gl\u00fcck und fr\u00f6lichkeit", "tokens": ["Mit", "kurt\u00b7zem", ":", "Ich", "er\u00b7fuhr", ",", "da\u00df", "gl\u00fcck", "und", "fr\u00f6\u00b7lich\u00b7keit"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "$.", "PPER", "VVFIN", "$,", "KOUS", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Die rosen nicht allein in feldern ausgestreut:", "tokens": ["Die", "ro\u00b7sen", "nicht", "al\u00b7lein", "in", "fel\u00b7dern", "aus\u00b7ge\u00b7streut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Und da\u00df man eben so, wie in den k\u00fchlen gr\u00fcnden,", "tokens": ["Und", "da\u00df", "man", "e\u00b7ben", "so", ",", "wie", "in", "den", "k\u00fch\u00b7len", "gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "ADV", "ADV", "$,", "PWAV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.40": {"text": "Bey hofe sch\u00e4fer kan und wahre tugend finden.", "tokens": ["Bey", "ho\u00b7fe", "sch\u00e4\u00b7fer", "kan", "und", "wah\u00b7re", "tu\u00b7gend", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ADJD", "VMFIN", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Und warlich, wo ein land nach wunsche soll gedeyn,", "tokens": ["Und", "war\u00b7lich", ",", "wo", "ein", "land", "nach", "wun\u00b7sche", "soll", "ge\u00b7deyn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "PWAV", "ART", "NN", "APPR", "ADJA", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "So mu\u00df sein ober-herr ein halber sch\u00e4fer seyn,", "tokens": ["So", "mu\u00df", "sein", "o\u00b7ber\u00b7herr", "ein", "hal\u00b7ber", "sch\u00e4\u00b7fer", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "ART", "ADJA", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Und ja so wohl, als wir, bey angebrochnem morgen,", "tokens": ["Und", "ja", "so", "wohl", ",", "als", "wir", ",", "bey", "an\u00b7ge\u00b7broch\u00b7nem", "mor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADV", "$,", "KOUS", "PPER", "$,", "APPR", "ADJA", "ADV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Nach seinem amte sehn, und f\u00fcr die heerde sorgen.", "tokens": ["Nach", "sei\u00b7nem", "am\u00b7te", "sehn", ",", "und", "f\u00fcr", "die", "heer\u00b7de", "sor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "VVINF", "$,", "KON", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Wir leben zwar f\u00fcr uns; doch mehr f\u00fcr unser vieh:", "tokens": ["Wir", "le\u00b7ben", "zwar", "f\u00fcr", "uns", ";", "doch", "mehr", "f\u00fcr", "un\u00b7ser", "vieh", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPER", "$.", "ADV", "ADV", "APPR", "PPOSAT", "FM", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Wir essen unser brod zwar freudig; doch mit m\u00fch:", "tokens": ["Wir", "es\u00b7sen", "un\u00b7ser", "brod", "zwar", "freu\u00b7dig", ";", "doch", "mit", "m\u00fch", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV", "ADJD", "$.", "ADV", "APPR", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Und wachen, wenn wir uns gleich halb zu bette legen:", "tokens": ["Und", "wa\u00b7chen", ",", "wenn", "wir", "uns", "gleich", "halb", "zu", "bet\u00b7te", "le\u00b7gen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$,", "KOUS", "PPER", "PRF", "ADV", "ADJD", "PTKZU", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "So mu\u00df ein kluger f\u00fcrst auch noch die fl\u00fcgel regen,", "tokens": ["So", "mu\u00df", "ein", "klu\u00b7ger", "f\u00fcrst", "auch", "noch", "die", "fl\u00fc\u00b7gel", "re\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "ADV", "ADV", "ADV", "ART", "NN", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Wenn sich die gantze welt in tieffen schlaf begr\u00e4bt.", "tokens": ["Wenn", "sich", "die", "gant\u00b7ze", "welt", "in", "tief\u00b7fen", "schlaf", "be\u00b7gr\u00e4bt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Wer ihm alleine nur, und nicht dem staate lebt,", "tokens": ["Wer", "ihm", "al\u00b7lei\u00b7ne", "nur", ",", "und", "nicht", "dem", "staa\u00b7te", "lebt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "$,", "KON", "PTKNEG", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Ist keiner crone werth. Denn sich wohl zu regieren,", "tokens": ["Ist", "kei\u00b7ner", "cro\u00b7ne", "werth", ".", "Denn", "sich", "wohl", "zu", "re\u00b7gie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "ADJD", "$.", "KON", "PRF", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Ist zwar sehr grosse kunst; Doch gr\u00f6\u00dfre, andre f\u00fchren:", "tokens": ["Ist", "zwar", "sehr", "gros\u00b7se", "kunst", ";", "Doch", "gr\u00f6\u00df\u00b7re", ",", "and\u00b7re", "f\u00fch\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJA", "NN", "$.", "KON", "VVFIN", "$,", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Die gr\u00f6ste, beydes thun. Und es ist gantz gemein,", "tokens": ["Die", "gr\u00f6s\u00b7te", ",", "bey\u00b7des", "thun", ".", "Und", "es", "ist", "gantz", "ge\u00b7mein", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PIS", "VVINF", "$.", "KON", "PPER", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Da\u00df der, dem jeder dient, mu\u00df vielen dienstbar seyn.", "tokens": ["Da\u00df", "der", ",", "dem", "je\u00b7der", "dient", ",", "mu\u00df", "vie\u00b7len", "dienst\u00b7bar", "seyn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$,", "PRELS", "PIS", "VVFIN", "$,", "VMFIN", "PIAT", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Der lohn f\u00fcr unsre m\u00fch ist s\u00fcsse milch und wolle:", "tokens": ["Der", "lohn", "f\u00fcr", "uns\u00b7re", "m\u00fch", "ist", "s\u00fcs\u00b7se", "milch", "und", "wol\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "ADJD", "VAFIN", "ADJA", "NN", "KON", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Wir wissen, da\u00df man nichts zu sehr beschweren solle,", "tokens": ["Wir", "wis\u00b7sen", ",", "da\u00df", "man", "nichts", "zu", "sehr", "be\u00b7schwe\u00b7ren", "sol\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PIS", "PIS", "APPR", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Und ziehn den schafen nicht gleich haut und leder ab:", "tokens": ["Und", "ziehn", "den", "scha\u00b7fen", "nicht", "gleich", "haut", "und", "le\u00b7der", "ab", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "VVFIN", "PTKNEG", "ADV", "VVFIN", "KON", "VVIMP", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Ein f\u00fcrst lebt freylich nicht durch seinen blossen stab,", "tokens": ["Ein", "f\u00fcrst", "lebt", "frey\u00b7lich", "nicht", "durch", "sei\u00b7nen", "blos\u00b7sen", "stab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "ADV", "PTKNEG", "APPR", "PPOSAT", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Und mu\u00df, wofern er soll die l\u00e4nder recht besch\u00fctzen,", "tokens": ["Und", "mu\u00df", ",", "wo\u00b7fern", "er", "soll", "die", "l\u00e4n\u00b7der", "recht", "be\u00b7sch\u00fct\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "$,", "KOUS", "PPER", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Nicht, wie der p\u00f6fel gehn, und in dem winckel sitzen;", "tokens": ["Nicht", ",", "wie", "der", "p\u00f6\u00b7fel", "gehn", ",", "und", "in", "dem", "win\u00b7ckel", "sit\u00b7zen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "$,", "PWAV", "ART", "NN", "VVINF", "$,", "KON", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Allein er mu\u00df auch nicht das recht in macht verdrehn,", "tokens": ["Al\u00b7lein", "er", "mu\u00df", "auch", "nicht", "das", "recht", "in", "macht", "ver\u00b7drehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VMFIN", "ADV", "PTKNEG", "ART", "ADJD", "APPR", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Und mehr auf falsche pracht, als wahre nothdurfft sehn:", "tokens": ["Und", "mehr", "auf", "fal\u00b7sche", "pracht", ",", "als", "wah\u00b7re", "noth\u00b7durfft", "sehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "$,", "KOUS", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Denn jeder bauer, der durch seine last verdirbet,", "tokens": ["Denn", "je\u00b7der", "bau\u00b7er", ",", "der", "durch", "sei\u00b7ne", "last", "ver\u00b7dir\u00b7bet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "PRELS", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Ist zeuge, da\u00df er schon an seinem gl\u00fccke stirbet.", "tokens": ["Ist", "zeu\u00b7ge", ",", "da\u00df", "er", "schon", "an", "sei\u00b7nem", "gl\u00fc\u00b7cke", "stir\u00b7bet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVFIN", "$,", "KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Wir armen sch\u00e4fer sind mit weid und vieh vergn\u00fcgt:", "tokens": ["Wir", "ar\u00b7men", "sch\u00e4\u00b7fer", "sind", "mit", "weid", "und", "vieh", "ver\u00b7gn\u00fcgt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "ADJD", "VAFIN", "APPR", "NN", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Wir forschen nicht, wie gro\u00df der nachbarn wiese liegt:", "tokens": ["Wir", "for\u00b7schen", "nicht", ",", "wie", "gro\u00df", "der", "nach\u00b7barn", "wie\u00b7se", "liegt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "ADJD", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Wie weit ihr acker grentzt: Wie viel sie l\u00e4mmer zehlen:", "tokens": ["Wie", "weit", "ihr", "ac\u00b7ker", "grentzt", ":", "Wie", "viel", "sie", "l\u00e4m\u00b7mer", "zeh\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPOSAT", "NN", "VVFIN", "$.", "PWAV", "PIS", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Und wie wir endlich gar uns m\u00f6chten reicher stehlen.", "tokens": ["Und", "wie", "wir", "end\u00b7lich", "gar", "uns", "m\u00f6ch\u00b7ten", "rei\u00b7cher", "steh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "ADV", "PPER", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Was ist doch sch\u00e4ndlicher, als wenn ein grosser f\u00fcrst,", "tokens": ["Was", "ist", "doch", "sch\u00e4nd\u00b7li\u00b7cher", ",", "als", "wenn", "ein", "gros\u00b7ser", "f\u00fcrst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "ADJD", "$,", "KOKOM", "KOUS", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Gleichwie ein tieger-thier, nach fremdem blute d\u00fcrst:", "tokens": ["Gleich\u00b7wie", "ein", "tie\u00b7ger\u00b7thier", ",", "nach", "frem\u00b7dem", "blu\u00b7te", "d\u00fcrst", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "$,", "APPR", "ADJA", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Sich durch betrug und list in fette l\u00e4nder spielet:", "tokens": ["Sich", "durch", "be\u00b7trug", "und", "list", "in", "fet\u00b7te", "l\u00e4n\u00b7der", "spie\u00b7let", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "VVFIN", "KON", "VVFIN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Mit Alexandern fast die halbe welt durchw\u00fchlet,", "tokens": ["Mit", "A\u00b7lex\u00b7an\u00b7dern", "fast", "die", "hal\u00b7be", "welt", "durch\u00b7w\u00fch\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Und hundert tausend mann vor eine Festung giebt?", "tokens": ["Und", "hun\u00b7dert", "tau\u00b7send", "mann", "vor", "ei\u00b7ne", "Fes\u00b7tung", "giebt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "CARD", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Wenn er die ehrsucht mehr, als sein gewissen, liebt:", "tokens": ["Wenn", "er", "die", "ehr\u00b7sucht", "mehr", ",", "als", "sein", "ge\u00b7wis\u00b7sen", ",", "liebt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "$,", "KOUS", "PPOSAT", "ADJA", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Mit eyd und schw\u00fcren schertzt: Das v\u00f6lcker-recht verlachet:", "tokens": ["Mit", "eyd", "und", "schw\u00fc\u00b7ren", "schertzt", ":", "Das", "v\u00f6lcker\u00b7recht", "ver\u00b7la\u00b7chet", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "VVINF", "VVFIN", "$.", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.76": {"text": "Schon wieder krieg anhebt, indem er friede machet:", "tokens": ["Schon", "wie\u00b7der", "krieg", "an\u00b7hebt", ",", "in\u00b7dem", "er", "frie\u00b7de", "ma\u00b7chet", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "VVFIN", "$,", "KOUS", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Und meint, er habe mehr als Scipio gethan,", "tokens": ["Und", "meint", ",", "er", "ha\u00b7be", "mehr", "als", "Sci\u00b7pio", "ge\u00b7than", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPER", "VAFIN", "PIAT", "KOKOM", "NE", "VVPP", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.78": {"text": "Wenn er zwey worte nur in titul flicken kan?", "tokens": ["Wenn", "er", "zwey", "wor\u00b7te", "nur", "in", "ti\u00b7tul", "fli\u00b7cken", "kan", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "CARD", "NN", "ADV", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "--++--+--+-+", "measure": "iambic.penta.relaxed"}, "line.79": {"text": "Die wahre herrschungs-kunst besteht in keinen meilen,", "tokens": ["Die", "wah\u00b7re", "herr\u00b7schungs\u00b7kunst", "be\u00b7steht", "in", "kei\u00b7nen", "mei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Man kan ein grosses land gar leicht ins kleine theilen;", "tokens": ["Man", "kan", "ein", "gros\u00b7ses", "land", "gar", "leicht", "ins", "klei\u00b7ne", "thei\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "ADJA", "NN", "ADV", "ADJD", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Der aber ist ein held, der durch vernunfft und flei\u00df", "tokens": ["Der", "a\u00b7ber", "ist", "ein", "held", ",", "der", "durch", "ver\u00b7nunfft", "und", "flei\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VAFIN", "ART", "VVFIN", "$,", "PRELS", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Das, was ihm GOtt geschenckt, wohl zu erhalten wei\u00df.", "tokens": ["Das", ",", "was", "ihm", "Gott", "ge\u00b7schenckt", ",", "wohl", "zu", "er\u00b7hal\u00b7ten", "wei\u00df", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PWS", "PPER", "NN", "VVPP", "$,", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "So artig findet man in sch\u00e4fern abgerissen,", "tokens": ["So", "ar\u00b7tig", "fin\u00b7det", "man", "in", "sch\u00e4\u00b7fern", "ab\u00b7ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PIS", "APPR", "ADJA", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Was ein gecr\u00f6ntes haurt soll auf dem throne wissen.", "tokens": ["Was", "ein", "ge\u00b7cr\u00f6n\u00b7tes", "haurt", "soll", "auf", "dem", "thro\u00b7ne", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Allein wer, grosser F\u00fcrst! wei\u00df, was durch dich geschehn,", "tokens": ["Al\u00b7lein", "wer", ",", "gros\u00b7ser", "F\u00fcrst", "!", "wei\u00df", ",", "was", "durch", "dich", "ge\u00b7schehn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "$,", "ADJA", "NN", "$.", "VVFIN", "$,", "PRELS", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Und was du t\u00e4glich thust, darff keinen sch\u00e4fer sehn;", "tokens": ["Und", "was", "du", "t\u00e4g\u00b7lich", "thust", ",", "darff", "kei\u00b7nen", "sch\u00e4\u00b7fer", "sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADJD", "VVFIN", "$,", "VMFIN", "PIAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Denn alles, was man w\u00fcnscht, da\u00df andre lernen m\u00f6chten,", "tokens": ["Denn", "al\u00b7les", ",", "was", "man", "w\u00fcnscht", ",", "da\u00df", "and\u00b7re", "ler\u00b7nen", "m\u00f6ch\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "PIS", "VVFIN", "$,", "KOUS", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Das hast du schon gethan. Du siehest nach den rechten:", "tokens": ["Das", "hast", "du", "schon", "ge\u00b7than", ".", "Du", "sie\u00b7hest", "nach", "den", "rech\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "VVPP", "$.", "PPER", "VVFIN", "APPR", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Du gehst die kammer durch, und wendest den verstand,", "tokens": ["Du", "gehst", "die", "kam\u00b7mer", "durch", ",", "und", "wen\u00b7dest", "den", "ver\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "KON", "VVFIN", "ART", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Wenn der und jener schl\u00e4ft, offt selber an das land:", "tokens": ["Wenn", "der", "und", "je\u00b7ner", "schl\u00e4ft", ",", "offt", "sel\u00b7ber", "an", "das", "land", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "KON", "PDS", "VVFIN", "$,", "ADV", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Du l\u00e4st eh etwas dir, als deinen b\u00fcrgern fehlen:", "tokens": ["Du", "l\u00e4st", "eh", "et\u00b7was", "dir", ",", "als", "dei\u00b7nen", "b\u00fcr\u00b7gern", "feh\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOUS", "PIS", "PPER", "$,", "KOUS", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Du streitest wider die, so fremde l\u00e4nder stehlen:", "tokens": ["Du", "strei\u00b7test", "wi\u00b7der", "die", ",", "so", "frem\u00b7de", "l\u00e4n\u00b7der", "steh\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "$,", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Und man begreiffet kaum, indem man dich betracht,", "tokens": ["Und", "man", "be\u00b7greif\u00b7fet", "kaum", ",", "in\u00b7dem", "man", "dich", "be\u00b7tracht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Was dich, erlauchter! hat, fried oder krieg? gemacht.", "tokens": ["Was", "dich", ",", "er\u00b7lauch\u00b7ter", "!", "hat", ",", "fried", "o\u00b7der", "krieg", "?", "ge\u00b7macht", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "PPER", "$,", "ADJD", "$.", "VAFIN", "$,", "NN", "KON", "NN", "$.", "VVPP", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.95": {"text": "Erlaube demnach mir, die seufftzer abzusingen,", "tokens": ["Er\u00b7lau\u00b7be", "dem\u00b7nach", "mir", ",", "die", "seufft\u00b7zer", "ab\u00b7zu\u00b7sin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PAV", "PPER", "$,", "PRELS", "ADJD", "VVIZU", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.96": {"text": "Die heute, kluger F\u00fcrst! dir deine sch\u00e4fer bringen:", "tokens": ["Die", "heu\u00b7te", ",", "klu\u00b7ger", "F\u00fcrst", "!", "dir", "dei\u00b7ne", "sch\u00e4\u00b7fer", "brin\u00b7gen", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "ADJA", "NN", "$.", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Jhr milden himmel! schauet,", "tokens": ["Ihr", "mil\u00b7den", "him\u00b7mel", "!", "schau\u00b7et", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$.", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.98": {"text": "Wie unser feld sich bauet", "tokens": ["Wie", "un\u00b7ser", "feld", "sich", "bau\u00b7et"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPOSAT", "NN", "PRF", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.99": {"text": "Und wieder fr\u00fcchte bringt!", "tokens": ["Und", "wie\u00b7der", "fr\u00fcch\u00b7te", "bringt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.100": {"text": "H\u00f6rt, wie die l\u00e4mmer schreyen,", "tokens": ["H\u00f6rt", ",", "wie", "die", "l\u00e4m\u00b7mer", "schre\u00b7yen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "ART", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.101": {"text": "Wie sich die schafe freuen,", "tokens": ["Wie", "sich", "die", "scha\u00b7fe", "freu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.102": {"text": "Wie unsre fl\u00f6te klingt!", "tokens": ["Wie", "uns\u00b7re", "fl\u00f6\u00b7te", "klingt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.103": {"text": "Di\u00df alles kan erweisen,", "tokens": ["Di\u00df", "al\u00b7les", "kan", "er\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.104": {"text": "Da\u00df uns das m\u00f6rder-eisen", "tokens": ["Da\u00df", "uns", "das", "m\u00f6r\u00b7der\u00b7ei\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.105": {"text": "Des krieges nicht ber\u00fchrt:", "tokens": ["Des", "krie\u00b7ges", "nicht", "be\u00b7r\u00fchrt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.106": {"text": "Und da\u00df, wenn andre w\u00fcten", "tokens": ["Und", "da\u00df", ",", "wenn", "and\u00b7re", "w\u00fc\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "KOUS", "$,", "KOUS", "PIS", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.107": {"text": "Man unter Albrechts h\u00fctten", "tokens": ["Man", "un\u00b7ter", "Al\u00b7brechts", "h\u00fct\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "APPR", "PIS", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.108": {"text": "Ein stilles leben f\u00fchrt.", "tokens": ["Ein", "stil\u00b7les", "le\u00b7ben", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVINF", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.109": {"text": "Jhr himmel! seyd gepriesen,", "tokens": ["Ihr", "him\u00b7mel", "!", "seyd", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.110": {"text": "Da\u00df ihr an uns erwiesen,", "tokens": ["Da\u00df", "ihr", "an", "uns", "er\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.111": {"text": "Was wir doch nicht verdient:", "tokens": ["Was", "wir", "doch", "nicht", "ver\u00b7dient", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.112": {"text": "Schaut aber auch zur\u00fccke,", "tokens": ["Schaut", "a\u00b7ber", "auch", "zu\u00b7r\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.113": {"text": "Und schafft, da\u00df Albrechts gl\u00fccke", "tokens": ["Und", "schafft", ",", "da\u00df", "Al\u00b7brechts", "gl\u00fc\u00b7cke"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PIS", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.114": {"text": "Wie unsre wiesen gr\u00fcnt!", "tokens": ["Wie", "uns\u00b7re", "wie\u00b7sen", "gr\u00fcnt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.115": {"text": "Sein witz und seine sorgen", "tokens": ["Sein", "witz", "und", "sei\u00b7ne", "sor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.116": {"text": "Geb\u00e4hren alle morgen", "tokens": ["Ge\u00b7b\u00e4h\u00b7ren", "al\u00b7le", "mor\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["NN", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.117": {"text": "Uns neuen fr\u00fchlings-schein:", "tokens": ["Uns", "neu\u00b7en", "fr\u00fch\u00b7lings\u00b7schein", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.118": {"text": "Drum last ihn ewig leben!", "tokens": ["Drum", "last", "ihn", "e\u00b7wig", "le\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.119": {"text": "Wo nicht, so schafft uns reben,", "tokens": ["Wo", "nicht", ",", "so", "schafft", "uns", "re\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$,", "ADV", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.120": {"text": "Die wie der vater seyn!", "tokens": ["Die", "wie", "der", "va\u00b7ter", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KOKOM", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}