{"dta.poem.11340": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Auf das absterben herrn Raymond  \n Faltzens, weit-ber\u00fchmten k\u00f6niglichen  \n Preu\u00dfischen  medailleurs.  \n  B. N.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1709", "urn": "urn:nbn:de:kobv:b4-20283-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Da Bonn durch Preussens starcken held", "tokens": ["Da", "Bonn", "durch", "Preus\u00b7sens", "star\u00b7cken", "held"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "APPR", "NN", "VVINF", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und C\u00f6horns donner niederf\u00e4llt:", "tokens": ["Und", "C\u00f6\u00b7horns", "don\u00b7ner", "nie\u00b7der\u00b7f\u00e4llt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da Wien die freuden-paucken r\u00fchret;", "tokens": ["Da", "Wi\u00b7en", "die", "freu\u00b7den\u00b7pau\u00b7cken", "r\u00fch\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "So leidt hingegen Ph\u00f6bus noth,", "tokens": ["So", "leidt", "hin\u00b7ge\u00b7gen", "Ph\u00f6\u00b7bus", "noth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und klagt, da\u00df er durch Faltzens tod", "tokens": ["Und", "klagt", ",", "da\u00df", "er", "durch", "Falt\u00b7zens", "tod"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "APPR", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mehr, als ein gantzes heer, verliehret.", "tokens": ["Mehr", ",", "als", "ein", "gant\u00b7zes", "heer", ",", "ver\u00b7lieh\u00b7ret", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PIS", "$,", "KOUS", "ART", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Z\u00f6rnt nicht, ihr helden! die ihr denckt,", "tokens": ["Z\u00f6rnt", "nicht", ",", "ihr", "hel\u00b7den", "!", "die", "ihr", "denckt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$,", "PPOSAT", "NN", "$.", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df alles an dem degen hengt:", "tokens": ["Da\u00df", "al\u00b7les", "an", "dem", "de\u00b7gen", "hengt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Jhr seyd der brust-schild unsers lebens;", "tokens": ["Ihr", "seyd", "der", "brust\u00b7schild", "un\u00b7sers", "le\u00b7bens", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Doch, soll euch einst die nach-welt sehn,", "tokens": ["Doch", ",", "soll", "euch", "einst", "die", "nach\u00b7welt", "sehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VMFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So mu\u00df es durch die kunst geschehn:", "tokens": ["So", "mu\u00df", "es", "durch", "die", "kunst", "ge\u00b7schehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sonft ist eur hoher ruhm vergebens.", "tokens": ["Sonft", "ist", "eur", "ho\u00b7her", "ruhm", "ver\u00b7ge\u00b7bens", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Jhr rennet wall und mauren an;", "tokens": ["Ihr", "ren\u00b7net", "wall", "und", "mau\u00b7ren", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir sagen, was ihr habt gethan:", "tokens": ["Wir", "sa\u00b7gen", ",", "was", "ihr", "habt", "ge\u00b7than", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWS", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Jhr sterbet; Unsre wercke bleiben.", "tokens": ["Ihr", "ster\u00b7bet", ";", "Uns\u00b7re", "wer\u00b7cke", "blei\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Camill! wer d\u00e4chte noch an dich,", "tokens": ["Ca\u00b7mill", "!", "wer", "d\u00e4ch\u00b7te", "noch", "an", "dich", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWS", "VVFIN", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gesch\u00e4h es nicht durch kupffer-stich,", "tokens": ["Ge\u00b7sch\u00e4h", "es", "nicht", "durch", "kupf\u00b7fer\u00b7stich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKNEG", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gesch\u00e4h es nicht durch kunst und sehreiben?", "tokens": ["Ge\u00b7sch\u00e4h", "es", "nicht", "durch", "kunst", "und", "seh\u00b7rei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKNEG", "APPR", "NN", "KON", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Ja, Friedrich! deine cr\u00f6nungs-that,", "tokens": ["Ja", ",", "Fried\u00b7rich", "!", "dei\u00b7ne", "cr\u00f6\u00b7nungs\u00b7that", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NE", "$.", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die keinen zusatz n\u00f6thig hat,", "tokens": ["Die", "kei\u00b7nen", "zu\u00b7satz", "n\u00f6\u00b7thig", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und gr\u00f6sser ist, als wir es meinen,", "tokens": ["Und", "gr\u00f6s\u00b7ser", "ist", ",", "als", "wir", "es", "mei\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die w\u00fcrde, k\u00f6nten stahl und stein", "tokens": ["Die", "w\u00fcr\u00b7de", ",", "k\u00f6n\u00b7ten", "stahl", "und", "stein"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "$,", "VMFIN", "ADV", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und b\u00fccher nicht die zeugen seyn,", "tokens": ["Und", "b\u00fc\u00b7cher", "nicht", "die", "zeu\u00b7gen", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKNEG", "ART", "VVFIN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Uns selbst als eine fabel scheinen.", "tokens": ["Uns", "selbst", "als", "ei\u00b7ne", "fa\u00b7bel", "schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Drum hast du bey der grossen macht", "tokens": ["Drum", "hast", "du", "bey", "der", "gros\u00b7sen", "macht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PPER", "APPR", "ART", "ADJA", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auch stets auf grossen ruhm gedacht,", "tokens": ["Auch", "stets", "auf", "gros\u00b7sen", "ruhm", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und so viel k\u00fcnstler aufgef\u00fchret,", "tokens": ["Und", "so", "viel", "k\u00fcnst\u00b7ler", "auf\u00b7ge\u00b7f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df man nicht wohl zu sagen wei\u00df,", "tokens": ["Da\u00df", "man", "nicht", "wohl", "zu", "sa\u00b7gen", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PTKNEG", "ADV", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ob dir mehr in dem felde prei\u00df,", "tokens": ["Ob", "dir", "mehr", "in", "dem", "fel\u00b7de", "prei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ob in der musen chor geb\u00fchret.", "tokens": ["Ob", "in", "der", "mu\u00b7sen", "chor", "ge\u00b7b\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Dein Faltz, den Ph\u00f6bus itzt beklagt,", "tokens": ["Dein", "Faltz", ",", "den", "Ph\u00f6\u00b7bus", "itzt", "be\u00b7klagt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War schon an Franckreich halb versagt;", "tokens": ["War", "schon", "an", "Fran\u00b7ck\u00b7reich", "halb", "ver\u00b7sagt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NE", "ADJD", "VVPP", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Jedoch dein glantz hat ihn bewogen,", "tokens": ["Je\u00b7doch", "dein", "glantz", "hat", "ihn", "be\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df er Pari\u00df f\u00fcr nichts gesch\u00e4tzt,", "tokens": ["Da\u00df", "er", "Pa\u00b7ri\u00df", "f\u00fcr", "nichts", "ge\u00b7sch\u00e4tzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "APPR", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den schein der wahrheit nachgesetzt,", "tokens": ["Den", "schein", "der", "wahr\u00b7heit", "nach\u00b7ge\u00b7setzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die tugend lastern vorgezogen.", "tokens": ["Die", "tu\u00b7gend", "las\u00b7tern", "vor\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Und dergestalt mu\u00df Ludewig", "tokens": ["Und", "der\u00b7ge\u00b7stalt", "mu\u00df", "Lu\u00b7de\u00b7wig"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "VMFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wohl freylich \u00fcber deinen sieg,", "tokens": ["Wohl", "frey\u00b7lich", "\u00fc\u00b7ber", "dei\u00b7nen", "sieg", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "O grosser held! f\u00fcr eyfer breunen:", "tokens": ["O", "gros\u00b7ser", "held", "!", "f\u00fcr", "ey\u00b7fer", "breu\u00b7nen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$.", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Schlag, spricht er, wie man schl\u00e4gt und ficht,", "tokens": ["Schlag", ",", "spricht", "er", ",", "wie", "man", "schl\u00e4gt", "und", "ficht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "$,", "PWAV", "PIS", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Beraub mich nur der k\u00fcnstler nicht,", "tokens": ["Be\u00b7raub", "mich", "nur", "der", "k\u00fcnst\u00b7ler", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ART", "ADJA", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die, was mir fehlt, ersetzen k\u00f6nnen.", "tokens": ["Die", ",", "was", "mir", "fehlt", ",", "er\u00b7set\u00b7zen", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "$,", "PWS", "PPER", "VVFIN", "$,", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Ach! k\u00f6ntest du doch auch zugleich", "tokens": ["Ach", "!", "k\u00f6n\u00b7test", "du", "doch", "auch", "zu\u00b7gleich"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "VMFIN", "PPER", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So, wie du dir ein k\u00f6nigreich,", "tokens": ["So", ",", "wie", "du", "dir", "ein", "k\u00f6\u00b7nig\u00b7reich", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "PPER", "ART", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So, wie du unser heyl gebauet,", "tokens": ["So", ",", "wie", "du", "un\u00b7ser", "heyl", "ge\u00b7bau\u00b7et", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Uns Faltzen aus dem grabe ziehn,", "tokens": ["Uns", "Falt\u00b7zen", "aus", "dem", "gra\u00b7be", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPR", "ART", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Durch dessen k\u00fcnstliches bem\u00fchn", "tokens": ["Durch", "des\u00b7sen", "k\u00fcnst\u00b7li\u00b7ches", "be\u00b7m\u00fchn"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PRELAT", "ADJA", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die gantze welt dein bildni\u00df schauet;", "tokens": ["Die", "gant\u00b7ze", "welt", "dein", "bild\u00b7ni\u00df", "schau\u00b7et", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Was wunder w\u00fcrden wir nicht sehn,", "tokens": ["Was", "wun\u00b7der", "w\u00fcr\u00b7den", "wir", "nicht", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die ja zum theile schon geschehn,", "tokens": ["Die", "ja", "zum", "thei\u00b7le", "schon", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPRART", "VVFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Theils aber bald geschehen werden!", "tokens": ["Theils", "a\u00b7ber", "bald", "ge\u00b7sche\u00b7hen", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Allein GOtt zieht den schau-platz zu:", "tokens": ["Al\u00b7lein", "Gott", "zieht", "den", "schau\u00b7platz", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Faltz geht zu seiner seelen-ruh,", "tokens": ["Faltz", "geht", "zu", "sei\u00b7ner", "see\u00b7len\u00b7ruh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und seine kunst mit ihm zur erden.", "tokens": ["Und", "sei\u00b7ne", "kunst", "mit", "ihm", "zur", "er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Jhr Musen! die ihr in der h\u00f6h\u2019,", "tokens": ["Ihr", "Mu\u00b7sen", "!", "die", "ihr", "in", "der", "h\u00f6h'", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PRELS", "PPER", "APPR", "ART", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Jhr Nymphen! die ihr an der Spree", "tokens": ["Ihr", "Nym\u00b7phen", "!", "die", "ihr", "an", "der", "Spree"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$.", "PRELS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und k\u00fchlen ufern pflegt zu wohnen,", "tokens": ["Und", "k\u00fch\u00b7len", "u\u00b7fern", "pflegt", "zu", "woh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "H\u00fcllt seinen leib in scharlach ein!", "tokens": ["H\u00fcllt", "sei\u00b7nen", "leib", "in", "schar\u00b7lach", "ein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Streut rosen auf den leichen-stein!", "tokens": ["Streut", "ro\u00b7sen", "auf", "den", "lei\u00b7chen\u00b7stein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Pflantzt in den umkreis anemonen!", "tokens": ["Pflantzt", "in", "den", "um\u00b7kreis", "a\u00b7ne\u00b7mo\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+---+--+-", "measure": "trochaic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Der viel unsterblich hat gemacht,", "tokens": ["Der", "viel", "uns\u00b7terb\u00b7lich", "hat", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Liegt nunmehr in des todes nacht;", "tokens": ["Liegt", "nun\u00b7mehr", "in", "des", "to\u00b7des", "nacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch, was er andern hat gegeben,", "tokens": ["Doch", ",", "was", "er", "an\u00b7dern", "hat", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWS", "PPER", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das bleibt ihm wieder zum gewinn?", "tokens": ["Das", "bleibt", "ihm", "wie\u00b7der", "zum", "ge\u00b7winn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie werden ewiglich durch ihn,", "tokens": ["Sie", "wer\u00b7den", "e\u00b7wig\u00b7lich", "durch", "ihn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Er wird in ihrem bilde leben.", "tokens": ["Er", "wird", "in", "ih\u00b7rem", "bil\u00b7de", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}