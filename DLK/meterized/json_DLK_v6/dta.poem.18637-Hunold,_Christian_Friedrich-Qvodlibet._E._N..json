{"dta.poem.18637": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Qvodlibet.  \n  E. N.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1702", "urn": "urn:nbn:de:kobv:b4-200905197766", "language": ["de:0.99"], "booktitle": "Hunold, Christian Friedrich: Die Edle Bem\u00fchung m\u00fcssiger Stunden. Hamburg, 1702."}, "poem": {"stanza.1": {"line.1": {"text": "Lerne viel. Sage wenig. H\u00f6re alles", "tokens": ["Ler\u00b7ne", "viel", ".", "Sa\u00b7ge", "we\u00b7nig", ".", "H\u00f6\u00b7re", "al\u00b7les"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ADV", "$.", "NN", "ADV", "$.", "VVFIN", "PIS"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Schreib doch den edlen Spruch mit g\u00fcldnen Littern an/", "tokens": ["Schreib", "doch", "den", "ed\u00b7len", "Spruch", "mit", "g\u00fcld\u00b7nen", "Lit\u00b7tern", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wer ihn practiciren kan", "tokens": ["Und", "wer", "ihn", "prac\u00b7ti\u00b7ci\u00b7ren", "kan"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den wil ich einen Weisen nennen.", "tokens": ["Den", "wil", "ich", "ei\u00b7nen", "Wei\u00b7sen", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn sich die Kinder einmahl brennen/", "tokens": ["Wenn", "sich", "die", "Kin\u00b7der", "ein\u00b7mahl", "bren\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So f\u00fcrchten sie das Feuer.", "tokens": ["So", "f\u00fcrch\u00b7ten", "sie", "das", "Feu\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Der Freunde sind sehr viel/", "tokens": ["Der", "Freun\u00b7de", "sind", "sehr", "viel", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Doch sind sie schrecklich theuer/", "tokens": ["Doch", "sind", "sie", "schreck\u00b7lich", "theu\u00b7er", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "ADJD", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Das macht/ der Eigennutz verderbet alles Spiel.", "tokens": ["Das", "macht", "/", "der", "Ei\u00b7gen\u00b7nutz", "ver\u00b7der\u00b7bet", "al\u00b7les", "Spiel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$(", "ART", "NN", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Von Freunden in der Noth", "tokens": ["Von", "Freun\u00b7den", "in", "der", "Noth"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Gehn funffzig auff ein Loth/", "tokens": ["Gehn", "funff\u00b7zig", "auff", "ein", "Loth", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "APPR", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Doch sol es hart und klemme stehn/", "tokens": ["Doch", "sol", "es", "hart", "und", "klem\u00b7me", "stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADJD", "KON", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "So werden hundert auff ein Qvintlein gehn.", "tokens": ["So", "wer\u00b7den", "hun\u00b7dert", "auff", "ein", "Qvint\u00b7lein", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "CARD", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Gemahlte Blumen riechen nicht/", "tokens": ["Ge\u00b7mahl\u00b7te", "Blu\u00b7men", "rie\u00b7chen", "nicht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PTKNEG", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Geschminckte Larven tauren selten", "tokens": ["Ge\u00b7schminck\u00b7te", "Lar\u00b7ven", "tau\u00b7ren", "sel\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "VVFIN", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Kein Freund wird einen Creutzer gelten/", "tokens": ["Kein", "Freund", "wird", "ei\u00b7nen", "Creut\u00b7zer", "gel\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Der anders denckt und anders spricht.", "tokens": ["Der", "an\u00b7ders", "denckt", "und", "an\u00b7ders", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "KON", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Gemahlte Blumen riechen nicht.", "tokens": ["Ge\u00b7mahl\u00b7te", "Blu\u00b7men", "rie\u00b7chen", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Wer nichts hat/ der ist nichts schuldig/", "tokens": ["Wer", "nichts", "hat", "/", "der", "ist", "nichts", "schul\u00b7dig", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VAFIN", "$(", "ART", "VAFIN", "PIS", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "In der Arbeit nur gedultig/", "tokens": ["In", "der", "Ar\u00b7beit", "nur", "ge\u00b7dul\u00b7tig", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Und da gehet treue Hand", "tokens": ["Und", "da", "ge\u00b7het", "treu\u00b7e", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ADJA", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.22": {"text": "Sicher durch das gantze Land", "tokens": ["Si\u00b7cher", "durch", "das", "gant\u00b7ze", "Land"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.23": {"text": "Weil das Sprichwort doch besteht/", "tokens": ["Weil", "das", "Sprich\u00b7wort", "doch", "be\u00b7steht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.24": {"text": "Besser betteln und bitten/", "tokens": ["Bes\u00b7ser", "bet\u00b7teln", "und", "bit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "KON", "VVINF", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.25": {"text": "Als zu sp\u00e4t", "tokens": ["Als", "zu", "sp\u00e4t"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PTKA", "ADJD"], "meter": "+-+", "measure": "trochaic.di"}, "line.26": {"text": "Capreolen an Galgen geschnitten.", "tokens": ["Cap\u00b7re\u00b7o\u00b7len", "an", "Gal\u00b7gen", "ge\u00b7schnit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVPP", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.27": {"text": "Ich bin Han\u00df ohne Sorgen/", "tokens": ["Ich", "bin", "Han\u00df", "oh\u00b7ne", "Sor\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "APPR", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.28": {"text": "Weil mir die Leute borgen/", "tokens": ["Weil", "mir", "die", "Leu\u00b7te", "bor\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.29": {"text": "Und weil ich noch kan stehlen/", "tokens": ["Und", "weil", "ich", "noch", "kan", "steh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.30": {"text": "So wird wir wenig fehlen/", "tokens": ["So", "wird", "wir", "we\u00b7nig", "feh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIS", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.31": {"text": "Allein von Hengelbeeren", "tokens": ["Al\u00b7lein", "von", "Hen\u00b7gel\u00b7bee\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.32": {"text": "Mag ich durchaus nichts h\u00f6ren.", "tokens": ["Mag", "ich", "durc\u00b7haus", "nichts", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.33": {"text": "Gute Nacht/ Fuchs!", "tokens": ["Gu\u00b7te", "Nacht", "/", "Fuchs", "!"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$(", "NE", "$."], "meter": "+-++", "measure": "unknown.measure.tri"}, "line.34": {"text": "Gold ist Gold und bleibet Gold/", "tokens": ["Gold", "ist", "Gold", "und", "blei\u00b7bet", "Gold", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "KON", "VVFIN", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.35": {"text": "Wenn es gleich im Kothe liegt:", "tokens": ["Wenn", "es", "gleich", "im", "Ko\u00b7the", "liegt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.36": {"text": "Ist dir auch kein M\u00e4dgen hold/", "tokens": ["Ist", "dir", "auch", "kein", "M\u00e4d\u00b7gen", "hold", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PIAT", "NN", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.37": {"text": "Sey dar\u00fcm nicht unvergn\u00fcgt.", "tokens": ["Sey", "da\u00b7r\u00fcm", "nicht", "un\u00b7ver\u00b7gn\u00fcgt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PAV", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.38": {"text": "Ein garstger Leib tr\u00e4gt einen sch\u00f6nen Rock/", "tokens": ["Ein", "garst\u00b7ger", "Leib", "tr\u00e4gt", "ei\u00b7nen", "sch\u00f6\u00b7nen", "Rock", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.39": {"text": "Ein armer Rittersmann verdient ein theuer Pferd", "tokens": ["Ein", "ar\u00b7mer", "Rit\u00b7ters\u00b7mann", "ver\u00b7dient", "ein", "theu\u00b7er", "Pferd"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Ein h\u00f6ltzerner Bock", "tokens": ["Ein", "h\u00f6lt\u00b7zer\u00b7ner", "Bock"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.41": {"text": "Ist einer guldnen Ziege werth.", "tokens": ["Ist", "ei\u00b7ner", "guld\u00b7nen", "Zie\u00b7ge", "werth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Ein Gl\u00e4\u00dfgen mit Weine vertreibet die Grillen/", "tokens": ["Ein", "Gl\u00e4\u00df\u00b7gen", "mit", "Wei\u00b7ne", "ver\u00b7trei\u00b7bet", "die", "Gril\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "ART", "NN", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.43": {"text": "Man suche nur Mittel/ den Kummer zu stillen/", "tokens": ["Man", "su\u00b7che", "nur", "Mit\u00b7tel", "/", "den", "Kum\u00b7mer", "zu", "stil\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "NN", "$(", "ART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.44": {"text": "Es wird mir versichert nichts kr\u00e4fftigers seyn/", "tokens": ["Es", "wird", "mir", "ver\u00b7si\u00b7chert", "nichts", "kr\u00e4ff\u00b7ti\u00b7gers", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVFIN", "PIS", "ADJA", "VAINF", "$("], "meter": "-+--++-+--+", "measure": "iambic.penta.relaxed"}, "line.45": {"text": "Dr\u00fcm lob' ich ein Gl\u00e4\u00dfgen/ und liebe den Wein.", "tokens": ["Dr\u00fcm", "lob'", "ich", "ein", "Gl\u00e4\u00df\u00b7gen", "/", "und", "lie\u00b7be", "den", "Wein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$(", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.46": {"text": "Verfolget dich der Neid", "tokens": ["Ver\u00b7fol\u00b7get", "dich", "der", "Neid"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.47": {"text": "Erwarte nur der Zeit/", "tokens": ["Er\u00b7war\u00b7te", "nur", "der", "Zeit", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.48": {"text": "Es wird sich alles schicken.", "tokens": ["Es", "wird", "sich", "al\u00b7les", "schi\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.49": {"text": "Man wird gedr\u00fcckt/ man wird auch wieder dr\u00fccken", "tokens": ["Man", "wird", "ge\u00b7dr\u00fcckt", "/", "man", "wird", "auch", "wie\u00b7der", "dr\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "VVPP", "$(", "PIS", "VAFIN", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.50": {"text": "Ob mich die Hunde neiden/", "tokens": ["Ob", "mich", "die", "Hun\u00b7de", "nei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.51": {"text": "Ihr Bellen f\u00e4hrt in Wind dahin/", "tokens": ["Ihr", "Bel\u00b7len", "f\u00e4hrt", "in", "Wind", "da\u00b7hin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "NN", "PAV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.52": {"text": "Wenn ich ein Ambo\u00df bin/", "tokens": ["Wenn", "ich", "ein", "Am\u00b7bo\u00df", "bin", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.53": {"text": "So mu\u00df ich als ein Ambo\u00df leiden/", "tokens": ["So", "mu\u00df", "ich", "als", "ein", "Am\u00b7bo\u00df", "lei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "KOUS", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.54": {"text": "Doch wenn das Gl\u00fccke mich zum Hammer macht/", "tokens": ["Doch", "wenn", "das", "Gl\u00fc\u00b7cke", "mich", "zum", "Ham\u00b7mer", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PPER", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.55": {"text": "So schlag' ich zu da\u00df alles kracht.", "tokens": ["So", "schlag'", "ich", "zu", "da\u00df", "al\u00b7les", "kracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "KOUS", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.56": {"text": "Verliebten wird ein Tag/ als wie ein Jahr so lang/", "tokens": ["Ver\u00b7lieb\u00b7ten", "wird", "ein", "Tag", "/", "als", "wie", "ein", "Jahr", "so", "lang", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$(", "KOUS", "KOKOM", "ART", "NN", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Kein Frauenzimmer ist so kranck/", "tokens": ["Kein", "Frau\u00b7en\u00b7zim\u00b7mer", "ist", "so", "kranck", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.58": {"text": "Da\u00df auf den R\u00fccken nicht noch k\u00f6ndte liegen.", "tokens": ["Da\u00df", "auf", "den", "R\u00fc\u00b7cken", "nicht", "noch", "k\u00f6nd\u00b7te", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "PTKNEG", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.59": {"text": "Sechs fette K\u00fch und vier gem\u00e4ste K\u00e4lber", "tokens": ["Sechs", "fet\u00b7te", "K\u00fch", "und", "vier", "ge\u00b7m\u00e4s\u00b7te", "K\u00e4l\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["CARD", "ADJA", "NN", "KON", "CARD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.60": {"text": "Sind zehnmahl noch so gut", "tokens": ["Sind", "zehn\u00b7mahl", "noch", "so", "gut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.61": {"text": "Als zehen d\u00fcrre Ziegen.", "tokens": ["Als", "ze\u00b7hen", "d\u00fcr\u00b7re", "Zie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "CARD", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.62": {"text": "Drey Dinge thun sich selber", "tokens": ["Drey", "Din\u00b7ge", "thun", "sich", "sel\u00b7ber"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "PRF", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.63": {"text": "Wer sie nicht selber thut:", "tokens": ["Wer", "sie", "nicht", "sel\u00b7ber", "thut", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.64": {"text": "Den Podex wischen/", "tokens": ["Den", "Po\u00b7dex", "wi\u00b7schen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.65": {"text": "Die H\u00e4nde trocknen/", "tokens": ["Die", "H\u00e4n\u00b7de", "trock\u00b7nen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.66": {"text": "Und endlich ein M\u00e4dgen von siebenzehn Jahren", "tokens": ["Und", "end\u00b7lich", "ein", "M\u00e4d\u00b7gen", "von", "sie\u00b7ben\u00b7zehn", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "APPR", "CARD", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.67": {"text": "Mit einem jungen Manne paaren.", "tokens": ["Mit", "ei\u00b7nem", "jun\u00b7gen", "Man\u00b7ne", "paa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.68": {"text": "Feuer Lieb und Hertzens-Pein", "tokens": ["Feu\u00b7er", "Lieb", "und", "Hert\u00b7zens\u00b7Pein"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.69": {"text": "K\u00f6nnen nicht verborgen seyn.", "tokens": ["K\u00f6n\u00b7nen", "nicht", "ver\u00b7bor\u00b7gen", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.70": {"text": "Wer nach der Tugend strebt/ des Ruhm wird ewig seyn/", "tokens": ["Wer", "nach", "der", "Tu\u00b7gend", "strebt", "/", "des", "Ruhm", "wird", "e\u00b7wig", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "VVFIN", "$(", "ART", "NN", "VAFIN", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Sie schliest die Ewigkeit in ihre Circul ein.", "tokens": ["Sie", "schliest", "die", "E\u00b7wig\u00b7keit", "in", "ih\u00b7re", "Cir\u00b7cul", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Nun weichet die nichtige Liebe der Jugend/", "tokens": ["Nun", "wei\u00b7chet", "die", "nich\u00b7ti\u00b7ge", "Lie\u00b7be", "der", "Ju\u00b7gend", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ART", "NN", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.73": {"text": "Ich Liebe die B\u00fccher und K\u00fcsse die Tugend/", "tokens": ["Ich", "Lie\u00b7be", "die", "B\u00fc\u00b7cher", "und", "K\u00fcs\u00b7se", "die", "Tu\u00b7gend", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ART", "NN", "KON", "NN", "ART", "NN", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.74": {"text": "Und wenn sich der Fr\u00fchling zur Arbeit gew\u00f6hnt/", "tokens": ["Und", "wenn", "sich", "der", "Fr\u00fch\u00b7ling", "zur", "Ar\u00b7beit", "ge\u00b7w\u00f6hnt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PRF", "ART", "NN", "APPRART", "NN", "VVPP", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.75": {"text": "So bleibet der Winter mit Seegen gekr\u00f6nt.", "tokens": ["So", "blei\u00b7bet", "der", "Win\u00b7ter", "mit", "See\u00b7gen", "ge\u00b7kr\u00f6nt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.76": {"text": "Immer an der Erden kleben/", "tokens": ["Im\u00b7mer", "an", "der", "Er\u00b7den", "kle\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.77": {"text": "Ist ein Bestialisch Leben.", "tokens": ["Ist", "ein", "Bes\u00b7ti\u00b7a\u00b7lisch", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.78": {"text": "Unser Leben thun und Tichten", "tokens": ["Un\u00b7ser", "Le\u00b7ben", "thun", "und", "Tich\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVINF", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.79": {"text": "Mu\u00df sich nach dem Himmel richten.", "tokens": ["Mu\u00df", "sich", "nach", "dem", "Him\u00b7mel", "rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.80": {"text": "Unverzagt!", "tokens": ["Un\u00b7ver\u00b7zagt", "!"], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.81": {"text": "Es sticht", "tokens": ["Es", "sticht"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.82": {"text": "Nicht alles Eisen/", "tokens": ["Nicht", "al\u00b7les", "Ei\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "PIAT", "NN", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.83": {"text": "Und alle beisen nicht/", "tokens": ["Und", "al\u00b7le", "bei\u00b7sen", "nicht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVIZU", "PTKNEG", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.84": {"text": "Die uns die Z\u00e4hne weisen", "tokens": ["Die", "uns", "die", "Z\u00e4h\u00b7ne", "wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.85": {"text": "Ein Pfennig in der B\u00fcchse", "tokens": ["Ein", "Pfen\u00b7nig", "in", "der", "B\u00fcch\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.86": {"text": "Turniret noch einmahl so sehr/", "tokens": ["Tur\u00b7ni\u00b7ret", "noch", "ein\u00b7mahl", "so", "sehr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ADV", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.87": {"text": "Als wenn er gantz voll Thaler w\u00e4r.", "tokens": ["Als", "wenn", "er", "gantz", "voll", "Tha\u00b7ler", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADV", "ADJD", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.88": {"text": "Wo keine Hasen sind/ da spicket man die F\u00fcchse.", "tokens": ["Wo", "kei\u00b7ne", "Ha\u00b7sen", "sind", "/", "da", "spi\u00b7cket", "man", "die", "F\u00fcch\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VAFIN", "$(", "ADV", "VVFIN", "PIS", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Man mu\u00df ein bi\u00dfgen k\u00fchne seyn/", "tokens": ["Man", "mu\u00df", "ein", "bi\u00df\u00b7gen", "k\u00fch\u00b7ne", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "NN", "VVFIN", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.90": {"text": "Gleich durch geht man am besten:", "tokens": ["Gleich", "durch", "geht", "man", "am", "bes\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "VVFIN", "PIS", "PTKA", "ADJD", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.91": {"text": "Ein reintlich Schwein", "tokens": ["Ein", "reint\u00b7lich", "Schwein"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJD", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.92": {"text": "Wird sich gar mager m\u00e4sten/", "tokens": ["Wird", "sich", "gar", "ma\u00b7ger", "m\u00e4s\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ADV", "ADJD", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.93": {"text": "Und eine saubre Hand", "tokens": ["Und", "ei\u00b7ne", "saub\u00b7re", "Hand"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.94": {"text": "F\u00e4hrt stets in einen leeren Beutel.", "tokens": ["F\u00e4hrt", "stets", "in", "ei\u00b7nen", "lee\u00b7ren", "Beu\u00b7tel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.95": {"text": "Es ist bekandt:", "tokens": ["Es", "ist", "be\u00b7kandt", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.96": {"text": "Die gantze Welt ist eitel/", "tokens": ["Die", "gant\u00b7ze", "Welt", "ist", "ei\u00b7tel", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.97": {"text": "Das macht/ weil sie voll eitel Narren ist/", "tokens": ["Das", "macht", "/", "weil", "sie", "voll", "ei\u00b7tel", "Nar\u00b7ren", "ist", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$(", "KOUS", "PPER", "ADJD", "ADJD", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.98": {"text": "Ach Pr\u00fcffe dich/ ob du nicht einer bist.", "tokens": ["Ach", "Pr\u00fcf\u00b7fe", "dich", "/", "ob", "du", "nicht", "ei\u00b7ner", "bist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "PPER", "$(", "KOUS", "PPER", "PTKNEG", "PIS", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.99": {"text": "Eine Rose machet keinen Crantz/", "tokens": ["Ei\u00b7ne", "Ro\u00b7se", "ma\u00b7chet", "kei\u00b7nen", "Crantz", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "NN", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.100": {"text": "Ein paar Bein e keinen Tantz/", "tokens": ["Ein", "paar", "Bein", "e", "kei\u00b7nen", "Tantz", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "NE", "PIAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.101": {"text": "Und wenn man nur ein eintzig M\u00e4dgen-K\u00fcst/", "tokens": ["Und", "wenn", "man", "nur", "ein", "eint\u00b7zig", "M\u00e4d\u00b7gen\u00b7K\u00fcst", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "ADV", "ART", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.102": {"text": "So wei\u00df man nicht/ was lieben ist.", "tokens": ["So", "wei\u00df", "man", "nicht", "/", "was", "lie\u00b7ben", "ist", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PTKNEG", "$(", "PWS", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.103": {"text": "Bed\u00e4chtig zum Beutel/ geschwinde zum Hute/", "tokens": ["Be\u00b7d\u00e4ch\u00b7tig", "zum", "Beu\u00b7tel", "/", "ge\u00b7schwin\u00b7de", "zum", "Hu\u00b7te", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "$(", "ADJA", "APPRART", "NN", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.104": {"text": "Belehnt mit einem Ritter-Guthe.", "tokens": ["Be\u00b7lehnt", "mit", "ei\u00b7nem", "Rit\u00b7ter\u00b7Gu\u00b7the", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.105": {"text": "Wer sparen und sich schmiegen kan/", "tokens": ["Wer", "spa\u00b7ren", "und", "sich", "schmie\u00b7gen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVINF", "KON", "PRF", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.106": {"text": "Dem f\u00fchret das Gl\u00fccke die g\u00fcldene Bahn.", "tokens": ["Dem", "f\u00fch\u00b7ret", "das", "Gl\u00fc\u00b7cke", "die", "g\u00fcl\u00b7de\u00b7ne", "Bahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.107": {"text": "Ein Schneider sa\u00df in guter Ruh/", "tokens": ["Ein", "Schnei\u00b7der", "sa\u00df", "in", "gu\u00b7ter", "Ruh", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.108": {"text": "Und da kroch eine Lau\u00df herzu/", "tokens": ["Und", "da", "kroch", "ei\u00b7ne", "Lau\u00df", "her\u00b7zu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.109": {"text": "Die drohet ihm den \u00e4rgsten Todt.", "tokens": ["Die", "dro\u00b7het", "ihm", "den", "\u00e4rgs\u00b7ten", "Todt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.110": {"text": "Der Schneider war in Angst und Noth/", "tokens": ["Der", "Schnei\u00b7der", "war", "in", "Angst", "und", "Noth", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VAFIN", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.111": {"text": "Doch fast er sich bald einen Muth/", "tokens": ["Doch", "fast", "er", "sich", "bald", "ei\u00b7nen", "Muth", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "PRF", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.112": {"text": "Er nahm sein Schild den Finger-Hut/", "tokens": ["Er", "nahm", "sein", "Schild", "den", "Fin\u00b7ger\u00b7Hut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.113": {"text": "Die Nadel war sein blancker Spie\u00df", "tokens": ["Die", "Na\u00b7del", "war", "sein", "blan\u00b7cker", "Spie\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.114": {"text": "Wormit er schrecklich um sich stie\u00df.", "tokens": ["Wor\u00b7mit", "er", "schreck\u00b7lich", "um", "sich", "stie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADJD", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.115": {"text": "Der Strit gieng an/ der war sehr scharff/", "tokens": ["Der", "Strit", "gieng", "an", "/", "der", "war", "sehr", "scharff", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$(", "ART", "VAFIN", "ADV", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.116": {"text": "Bi\u00df er die Lau\u00df zu Boden warff.", "tokens": ["Bi\u00df", "er", "die", "Lau\u00df", "zu", "Bo\u00b7den", "warff", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.117": {"text": "Er brachte sie erb\u00e4rmlich um/", "tokens": ["Er", "brach\u00b7te", "sie", "er\u00b7b\u00e4rm\u00b7lich", "um", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.118": {"text": "Das gab den Schneider grossen Ruhm.", "tokens": ["Das", "gab", "den", "Schnei\u00b7der", "gros\u00b7sen", "Ruhm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.119": {"text": "Wer hatt' ihm dieses zu getraut?", "tokens": ["Wer", "hatt'", "ihm", "die\u00b7ses", "zu", "ge\u00b7traut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PDS", "PTKZU", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.120": {"text": "Er zieht ihr endlich ab die Haut/", "tokens": ["Er", "zieht", "ihr", "end\u00b7lich", "ab", "die", "Haut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.121": {"text": "Und macht sich ein paar Hosen draus.", "tokens": ["Und", "macht", "sich", "ein", "paar", "Ho\u00b7sen", "draus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ART", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.122": {"text": "Ach! Schade vor die arme Lau\u00df.", "tokens": ["Ach", "!", "Scha\u00b7de", "vor", "die", "ar\u00b7me", "Lau\u00df", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "ADJD", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.123": {"text": "Noch eins: Das ", "tokens": ["Noch", "eins", ":", "Das"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADV", "PIS", "$.", "ART"], "meter": "+-+", "measure": "trochaic.di"}}}}}