{"textgrid.poem.44085": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Mein Gott, wo ist denn schon der Lenz von meinen Jahren", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mein Gott, wo ist denn schon der Lenz von meinen Jahren", "tokens": ["Mein", "Gott", ",", "wo", "ist", "denn", "schon", "der", "Lenz", "von", "mei\u00b7nen", "Jah\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PWAV", "VAFIN", "ADV", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So still, so unvermerckt, so zeitig hingefahren?", "tokens": ["So", "still", ",", "so", "un\u00b7ver\u00b7merckt", ",", "so", "zei\u00b7tig", "hin\u00b7ge\u00b7fah\u00b7ren", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "$,", "ADV", "ADJD", "$,", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So schnell fleucht nimmermehr ein Seegel durch das Meer,", "tokens": ["So", "schnell", "fleucht", "nim\u00b7mer\u00b7mehr", "ein", "See\u00b7gel", "durch", "das", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "ADV", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So fl\u00fcchtig dringt wohl kaum ein hei\u00dfes Bley zum Ziele,", "tokens": ["So", "fl\u00fcch\u00b7tig", "dringt", "wohl", "kaum", "ein", "hei\u00b7\u00dfes", "Bley", "zum", "Zie\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es d\u00fcnckt mich ja noch gut der ersten Kinderspiele;", "tokens": ["Es", "d\u00fcnckt", "mich", "ja", "noch", "gut", "der", "ers\u00b7ten", "Kin\u00b7der\u00b7spie\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wo kommt denn aber schon des C\u00f6rpers Schwachheit her?", "tokens": ["Wo", "kommt", "denn", "a\u00b7ber", "schon", "des", "C\u00f6r\u00b7pers", "Schwach\u00b7heit", "her", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "ADV", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Mein Alter ist ja erst der Anfang, recht zu leben,", "tokens": ["Mein", "Al\u00b7ter", "ist", "ja", "erst", "der", "An\u00b7fang", ",", "recht", "zu", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADV", "ART", "NN", "$,", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Indem mir Raum und Zeit noch manchen Scherz kan geben.", "tokens": ["In\u00b7dem", "mir", "Raum", "und", "Zeit", "noch", "man\u00b7chen", "Scherz", "kan", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "KON", "NN", "ADV", "PIAT", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie? \u00dcberspringt dies nun die Stafeln der Natur?", "tokens": ["Wie", "?", "\u00dc\u00b7bers\u00b7pringt", "dies", "nun", "die", "Sta\u00b7feln", "der", "Na\u00b7tur", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VVFIN", "PDS", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mein Geist, der wie die Glut in fetten Cedern brannte,", "tokens": ["Mein", "Geist", ",", "der", "wie", "die", "Glut", "in", "fet\u00b7ten", "Ce\u00b7dern", "brann\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "KOKOM", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Verdru\u00df und Traurigkeit aus allen Winckeln bannte", "tokens": ["Ver\u00b7dru\u00df", "und", "Trau\u00b7rig\u00b7keit", "aus", "al\u00b7len", "Win\u00b7ckeln", "bann\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "APPR", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und wie der Bliz bey Nacht aus Mund und Antliz fuhr.", "tokens": ["Und", "wie", "der", "Bliz", "bey", "Nacht", "aus", "Mund", "und", "Ant\u00b7liz", "fuhr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "APPR", "NN", "APPR", "NN", "KON", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ich hatte von Geburth viel Ansehn auf der Erden,", "tokens": ["Ich", "hat\u00b7te", "von", "Ge\u00b7burth", "viel", "An\u00b7sehn", "auf", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "PIAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nach meiner V\u00e4ter Art ein starcker Geist zu werden.", "tokens": ["Nach", "mei\u00b7ner", "V\u00e4\u00b7ter", "Art", "ein", "star\u00b7cker", "Geist", "zu", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "ART", "ADJA", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Eltern kluge Gunst erzog Gem\u00fcth und Leib", "tokens": ["Der", "El\u00b7tern", "klu\u00b7ge", "Gunst", "er\u00b7zog", "Ge\u00b7m\u00fcth", "und", "Leib"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Durch \u00dcbung, Schwei\u00df und Kunst zu wichtigen Gesch\u00e4ften;", "tokens": ["Durch", "\u00dc\u00b7bung", ",", "Schwei\u00df", "und", "Kunst", "zu", "wich\u00b7ti\u00b7gen", "Ge\u00b7sch\u00e4f\u00b7ten", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was andern sauer ward, das war schon meinen Kr\u00e4ften", "tokens": ["Was", "an\u00b7dern", "sau\u00b7er", "ward", ",", "das", "war", "schon", "mei\u00b7nen", "Kr\u00e4f\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "PIS", "ADJD", "VAFIN", "$,", "PDS", "VAFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein lustiges Bem\u00fchn und froher Zeitvertreib.", "tokens": ["Ein", "lus\u00b7ti\u00b7ges", "Be\u00b7m\u00fchn", "und", "fro\u00b7her", "Zeit\u00b7ver\u00b7treib", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Kein Eckel, keine Furcht, kein abergl\u00e4ubisch Schr\u00f6cken", "tokens": ["Kein", "E\u00b7ckel", ",", "kei\u00b7ne", "Furcht", ",", "kein", "a\u00b7berg\u00b7l\u00e4u\u00b7bisch", "Schr\u00f6\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "$,", "PIAT", "ADJD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vermochte mir das Herz mit Unruh anzustecken.", "tokens": ["Ver\u00b7moch\u00b7te", "mir", "das", "Herz", "mit", "Un\u00b7ruh", "an\u00b7zu\u00b7ste\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Glieder fluchten nicht auf Hize, Frost und Stein,", "tokens": ["Die", "Glie\u00b7der", "fluch\u00b7ten", "nicht", "auf", "Hi\u00b7ze", ",", "Frost", "und", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Verfolgung, Mangel, Ha\u00df, Neid, L\u00fcgen, Schimpf und Zancken", "tokens": ["Ver\u00b7fol\u00b7gung", ",", "Man\u00b7gel", ",", "Ha\u00df", ",", "Neid", ",", "L\u00fc\u00b7gen", ",", "Schimpf", "und", "Zan\u00b7cken"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Erstickten mir keinmahl den Ehrgeiz der Gedancken,", "tokens": ["Er\u00b7stick\u00b7ten", "mir", "kein\u00b7mahl", "den", "Ehr\u00b7geiz", "der", "Ge\u00b7dan\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Welt durch Wi\u00dfenschaft ein n\u00fczlich Glied zu seyn.", "tokens": ["Der", "Welt", "durch", "Wi\u00b7\u00dfen\u00b7schaft", "ein", "n\u00fcz\u00b7lich", "Glied", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "ART", "ADJD", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ich sah mich als ein Kind den Warheitstrieb schon leiten,", "tokens": ["Ich", "sah", "mich", "als", "ein", "Kind", "den", "War\u00b7heit\u00b7strieb", "schon", "lei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KOUS", "ART", "NN", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich schwazte durch die Nacht bey Schriften alter Zeiten,", "tokens": ["Ich", "schwaz\u00b7te", "durch", "die", "Nacht", "bey", "Schrif\u00b7ten", "al\u00b7ter", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "APPR", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Musen nahmen mich der Mutter von der Hand;", "tokens": ["Die", "Mu\u00b7sen", "nah\u00b7men", "mich", "der", "Mut\u00b7ter", "von", "der", "Hand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich lernte nach und nach den Werth des Maro sch\u00e4zen", "tokens": ["Ich", "lern\u00b7te", "nach", "und", "nach", "den", "Werth", "des", "Ma\u00b7ro", "sch\u00e4\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "KON", "APPR", "ART", "NN", "ART", "NE", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und fra\u00df fast vor Begier, was Wolf und Leibniz sezen,", "tokens": ["Und", "fra\u00df", "fast", "vor", "Be\u00b7gier", ",", "was", "Wolf", "und", "Leib\u00b7niz", "se\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "$,", "PRELS", "NE", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Bey welchen ich den Kern der frommen Wei\u00dfheit fand.", "tokens": ["Bey", "wel\u00b7chen", "ich", "den", "Kern", "der", "from\u00b7men", "Wei\u00df\u00b7heit", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "PPER", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Dabey verschm\u00e4ht ich auch kein eu\u00dferlich Vergn\u00fcgen,", "tokens": ["Da\u00b7bey", "ver\u00b7schm\u00e4ht", "ich", "auch", "kein", "eu\u00b7\u00dfer\u00b7lich", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "PIAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Liebe wuste mich recht k\u00fcnstlich zu besiegen,", "tokens": ["Die", "Lie\u00b7be", "wus\u00b7te", "mich", "recht", "k\u00fcnst\u00b7lich", "zu", "be\u00b7sie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sobald Anacreon in meinen Zunder blies;", "tokens": ["So\u00b7bald", "A\u00b7na\u00b7cre\u00b7on", "in", "mei\u00b7nen", "Zun\u00b7der", "blies", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich dacht, es z\u00f6ge mich nur blos ein nettes Singen,", "tokens": ["Ich", "dacht", ",", "es", "z\u00f6\u00b7ge", "mich", "nur", "blos", "ein", "net\u00b7tes", "Sin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und war doch in der That ein z\u00e4rtliches Bezwingen", "tokens": ["Und", "war", "doch", "in", "der", "That", "ein", "z\u00e4rt\u00b7li\u00b7ches", "Be\u00b7zwin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der s\u00fc\u00dfen Eitelkeit, die ihre Macht bewies.", "tokens": ["Der", "s\u00fc\u00b7\u00dfen", "Ei\u00b7tel\u00b7keit", ",", "die", "ih\u00b7re", "Macht", "be\u00b7wies", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Bey vielem \u00c4rgern\u00fc\u00df und unter allen Sorgen,", "tokens": ["Bey", "vie\u00b7lem", "\u00c4r\u00b7ger\u00b7n\u00fc\u00df", "und", "un\u00b7ter", "al\u00b7len", "Sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "KON", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die mir noch ziemlich jung den Abend wie den Morgen", "tokens": ["Die", "mir", "noch", "ziem\u00b7lich", "jung", "den", "A\u00b7bend", "wie", "den", "Mor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADV", "ADV", "ADJD", "ART", "NN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mit Drohung und Gefahr empfindlich zugesazt,", "tokens": ["Mit", "Dro\u00b7hung", "und", "Ge\u00b7fahr", "emp\u00b7find\u00b7lich", "zu\u00b7ge\u00b7sazt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Verdarb ich gleichwohl nicht Gesellschaft, Scherz und K\u00fc\u00dfen,", "tokens": ["Ver\u00b7darb", "ich", "gleich\u00b7wohl", "nicht", "Ge\u00b7sell\u00b7schaft", ",", "Scherz", "und", "K\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und manch vertrauter Freund wird oft noch sagen m\u00fc\u00dfen,", "tokens": ["Und", "manch", "ver\u00b7trau\u00b7ter", "Freund", "wird", "oft", "noch", "sa\u00b7gen", "m\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "VAFIN", "ADV", "ADV", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie freudig ihm mein Trost die Grillen ausgeschwazt.", "tokens": ["Wie", "freu\u00b7dig", "ihm", "mein", "Trost", "die", "Gril\u00b7len", "aus\u00b7ge\u00b7schwazt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "PPOSAT", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Allein es \u00e4ndert sich die Scene meines Lebens.", "tokens": ["Al\u00b7lein", "es", "\u00e4n\u00b7dert", "sich", "die", "Sce\u00b7ne", "mei\u00b7nes", "Le\u00b7bens", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PRF", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ach Gott, wie ist es jezt mit mir so gar vergebens!", "tokens": ["Ach", "Gott", ",", "wie", "ist", "es", "jezt", "mit", "mir", "so", "gar", "ver\u00b7ge\u00b7bens", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "PWAV", "VAFIN", "PPER", "ADV", "APPR", "PPER", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was seh ich zwischen mir und mir vor Unterscheid!", "tokens": ["Was", "seh", "ich", "zwi\u00b7schen", "mir", "und", "mir", "vor", "Un\u00b7ter\u00b7scheid", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "PPER", "KON", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mein junges Feldgeschrey bringt stumme Klagelieder,", "tokens": ["Mein", "jun\u00b7ges", "Feld\u00b7ge\u00b7schrey", "bringt", "stum\u00b7me", "Kla\u00b7ge\u00b7lie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es keimt, es g\u00e4hrt bereits durch alle meine Glieder", "tokens": ["Es", "keimt", ",", "es", "g\u00e4hrt", "be\u00b7reits", "durch", "al\u00b7le", "mei\u00b7ne", "Glie\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "APPR", "PIAT", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Saame und das Gift geerbter Sterbligkeit.", "tokens": ["Der", "Saa\u00b7me", "und", "das", "Gift", "ge\u00b7erb\u00b7ter", "Ster\u00b7blig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Die Geister sind verraucht, die Nerven leer und trocken,", "tokens": ["Die", "Geis\u00b7ter", "sind", "ver\u00b7raucht", ",", "die", "Ner\u00b7ven", "leer", "und", "tro\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "ART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Luft will in der Brust, das Blut in Adern stocken,", "tokens": ["Die", "Luft", "will", "in", "der", "Brust", ",", "das", "Blut", "in", "A\u00b7dern", "sto\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPR", "ART", "NN", "$,", "ART", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das Auge thr\u00e4nt und zieht die scharfen Strahlen ein;", "tokens": ["Das", "Au\u00b7ge", "thr\u00e4nt", "und", "zieht", "die", "schar\u00b7fen", "Strah\u00b7len", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das Ohr klingt fort und f\u00fcr und l\u00e4uthet mir zu Grabe,", "tokens": ["Das", "Ohr", "klingt", "fort", "und", "f\u00fcr", "und", "l\u00e4u\u00b7thet", "mir", "zu", "Gra\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "KON", "APPR", "KON", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und da ich \u00fcberall viel Todeszeichen habe,", "tokens": ["Und", "da", "ich", "\u00fc\u00b7be\u00b7rall", "viel", "To\u00b7des\u00b7zei\u00b7chen", "ha\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PIAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So zagt dabey mein Herz in ungemeiner Pein.", "tokens": ["So", "zagt", "da\u00b7bey", "mein", "Herz", "in", "un\u00b7ge\u00b7mei\u00b7ner", "Pein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PAV", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Nicht etwan, da\u00df mein Fleisch, die abgelegte B\u00fcrde,", "tokens": ["Nicht", "et\u00b7wan", ",", "da\u00df", "mein", "Fleisch", ",", "die", "ab\u00b7ge\u00b7leg\u00b7te", "B\u00fcr\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "$,", "KOUS", "PPOSAT", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Aus Abscheu vor der Gruft zulezt noch weibisch w\u00fcrde:", "tokens": ["Aus", "Ab\u00b7scheu", "vor", "der", "Gruft", "zu\u00b7lezt", "noch", "wei\u00b7bisch", "w\u00fcr\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "ADV", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dies hab ich mir vorl\u00e4ngst bekand und leicht gemacht;", "tokens": ["Dies", "hab", "ich", "mir", "vor\u00b7l\u00e4ngst", "be\u00b7kand", "und", "leicht", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "PPER", "ADV", "VVFIN", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nur darum, da\u00df mein Fleisch sich in der Bl\u00fcthe neiget", "tokens": ["Nur", "da\u00b7rum", ",", "da\u00df", "mein", "Fleisch", "sich", "in", "der", "Bl\u00fc\u00b7the", "nei\u00b7get"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PAV", "$,", "KOUS", "PPOSAT", "NN", "PRF", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und nicht der Welt vorher durch seine Fr\u00fcchte zeiget,", "tokens": ["Und", "nicht", "der", "Welt", "vor\u00b7her", "durch", "sei\u00b7ne", "Fr\u00fcch\u00b7te", "zei\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zu was mich die Natur an dieses Licht gebracht.", "tokens": ["Zu", "was", "mich", "die", "Na\u00b7tur", "an", "die\u00b7ses", "Licht", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "ART", "NN", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Allein wer hat hier Schuld? Ich leider wohl am meisten,", "tokens": ["Al\u00b7lein", "wer", "hat", "hier", "Schuld", "?", "Ich", "lei\u00b7der", "wohl", "am", "meis\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VAFIN", "ADV", "NN", "$.", "PPER", "ADV", "ADV", "PTKA", "PIS", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich, welchen Gl\u00fcck und Wahn mit s\u00fc\u00dfen Tr\u00e4umen speisten,", "tokens": ["Ich", ",", "wel\u00b7chen", "Gl\u00fcck", "und", "Wahn", "mit", "s\u00fc\u00b7\u00dfen", "Tr\u00e4u\u00b7men", "speis\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PWAT", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als w\u00fcrd es stets so seyn und niemahls anders gehn,", "tokens": ["Als", "w\u00fcrd", "es", "stets", "so", "seyn", "und", "nie\u00b7mahls", "an\u00b7ders", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ADV", "ADV", "VAINF", "KON", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich, der ich so viel Zeit nicht kl\u00fcger angewendet,", "tokens": ["Ich", ",", "der", "ich", "so", "viel", "Zeit", "nicht", "kl\u00fc\u00b7ger", "an\u00b7ge\u00b7wen\u00b7det", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPER", "ADV", "PIAT", "NN", "PTKNEG", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gesundheit, St\u00e4rck und Kraft so liederlich verschwendet \u2013", "tokens": ["Ge\u00b7sund\u00b7heit", ",", "St\u00e4rck", "und", "Kraft", "so", "lie\u00b7der\u00b7lich", "ver\u00b7schwen\u00b7det", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ach Gott, verzeih es doch dem redlichen Gestehn!", "tokens": ["Ach", "Gott", ",", "ver\u00b7zeih", "es", "doch", "dem", "red\u00b7li\u00b7chen", "Ge\u00b7stehn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "VVIMP", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Nun ist auch dies wohl wahr, der Himmel wird es zeugen,", "tokens": ["Nun", "ist", "auch", "dies", "wohl", "wahr", ",", "der", "Him\u00b7mel", "wird", "es", "zeu\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PDS", "ADV", "ADJD", "$,", "ART", "NN", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df Neid und Ungl\u00fcck oft die besten K\u00f6pfe beugen", "tokens": ["Da\u00df", "Neid", "und", "Un\u00b7gl\u00fcck", "oft", "die", "bes\u00b7ten", "K\u00f6p\u00b7fe", "beu\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN", "ADV", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und da\u00df ich wider mich gar viel aus Noth gethan.", "tokens": ["Und", "da\u00df", "ich", "wi\u00b7der", "mich", "gar", "viel", "aus", "Noth", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "PPER", "ADV", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "O h\u00e4tte mich die Pflicht des Nechsten oft gerettet", "tokens": ["O", "h\u00e4t\u00b7te", "mich", "die", "Pflicht", "des", "Nechs\u00b7ten", "oft", "ge\u00b7ret\u00b7tet"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "PPER", "ART", "NN", "ART", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und mancher Blutsfreund selbst mir nicht den Fall gebettet,", "tokens": ["Und", "man\u00b7cher", "Bluts\u00b7freund", "selbst", "mir", "nicht", "den", "Fall", "ge\u00b7bet\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADV", "PPER", "PTKNEG", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Vielleicht \u2013 \u2013 jedoch genug! Ich klage niemand an.", "tokens": ["Viel\u00b7leicht", "\u2013", "\u2013", "je\u00b7doch", "ge\u00b7nug", "!", "Ich", "kla\u00b7ge", "nie\u00b7mand", "an", "."], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "$(", "ADV", "ADV", "$.", "PPER", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Ich klage niemand an aus redlichem Gem\u00fcthe", "tokens": ["Ich", "kla\u00b7ge", "nie\u00b7mand", "an", "aus", "red\u00b7li\u00b7chem", "Ge\u00b7m\u00fc\u00b7the"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und w\u00fcntsche mir vielmehr nach angebohrner G\u00fcte", "tokens": ["Und", "w\u00fcnt\u00b7sche", "mir", "viel\u00b7mehr", "nach", "an\u00b7ge\u00b7bohr\u00b7ner", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Nur so viel Gl\u00fcck und Zeit, den Freunden Guts zu thun;", "tokens": ["Nur", "so", "viel", "Gl\u00fcck", "und", "Zeit", ",", "den", "Freun\u00b7den", "Guts", "zu", "thun", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "NN", "KON", "NN", "$,", "ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und da es in der Welt nicht weiter m\u00f6glich scheinet,", "tokens": ["Und", "da", "es", "in", "der", "Welt", "nicht", "wei\u00b7ter", "m\u00f6g\u00b7lich", "schei\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "PTKNEG", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So thu es der vor mich, vor dem mein Herze weinet,", "tokens": ["So", "thu", "es", "der", "vor", "mich", ",", "vor", "dem", "mein", "Her\u00b7ze", "wei\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "APPR", "PPER", "$,", "APPR", "ART", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und la\u00dfe Neid und Groll mit mir im Grabe ruhn.", "tokens": ["Und", "la\u00b7\u00dfe", "Neid", "und", "Groll", "mit", "mir", "im", "Gra\u00b7be", "ruhn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "KON", "NN", "APPR", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Nur mich verklag ich selbst vor dir, gerechter Richter.", "tokens": ["Nur", "mich", "ver\u00b7klag", "ich", "selbst", "vor", "dir", ",", "ge\u00b7rech\u00b7ter", "Rich\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$,", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So viel mein Scheitel Haar, so viel der Milchweg Lichter,", "tokens": ["So", "viel", "mein", "Schei\u00b7tel", "Haar", ",", "so", "viel", "der", "Milch\u00b7weg", "Lich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "NN", "$,", "ADV", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So viel die Erde Gra\u00df, das Weltmeer Schuppen tr\u00e4gt,", "tokens": ["So", "viel", "die", "Er\u00b7de", "Gra\u00df", ",", "das", "Welt\u00b7meer", "Schup\u00b7pen", "tr\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "NN", "$,", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So zahlreich und so gro\u00df ist auch der S\u00fcnden Menge,", "tokens": ["So", "zahl\u00b7reich", "und", "so", "gro\u00df", "ist", "auch", "der", "S\u00fcn\u00b7den", "Men\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "ADJD", "VAFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die mich durch mich erdr\u00fcckt und immer in die L\u00e4nge", "tokens": ["Die", "mich", "durch", "mich", "er\u00b7dr\u00fcckt", "und", "im\u00b7mer", "in", "die", "L\u00e4n\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "APPR", "PPER", "VVPP", "KON", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mehr Holz und Unterhalt zum lezten Feuer legt.", "tokens": ["Mehr", "Holz", "und", "Un\u00b7ter\u00b7halt", "zum", "lez\u00b7ten", "Feu\u00b7er", "legt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Das \u00c4rgste w\u00e4re noch, mich hier vor dir zu sch\u00e4men:", "tokens": ["Das", "\u00c4rgs\u00b7te", "w\u00e4\u00b7re", "noch", ",", "mich", "hier", "vor", "dir", "zu", "sch\u00e4\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "$,", "PPER", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hier steh ich, gro\u00dfer Gott, du magst die Rechnung nehmen.", "tokens": ["Hier", "steh", "ich", ",", "gro\u00b7\u00dfer", "Gott", ",", "du", "magst", "die", "Rech\u00b7nung", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADJA", "NN", "$,", "PPER", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich h\u00f6r, obgleich best\u00fcrzt, das Urthel mit Gedult.", "tokens": ["Ich", "h\u00f6r", ",", "ob\u00b7gleich", "be\u00b7st\u00fcrzt", ",", "das", "Ur\u00b7thel", "mit", "Ge\u00b7dult", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ADJD", "$,", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie hab ich nicht in mich so lang und grob gest\u00fcrmet", "tokens": ["Wie", "hab", "ich", "nicht", "in", "mich", "so", "lang", "und", "grob", "ge\u00b7st\u00fcr\u00b7met"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPER", "PTKNEG", "APPR", "PPER", "ADV", "ADJD", "KON", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und Fluch auf Fluch geh\u00e4uft und Last auf Last geth\u00fcrmet!", "tokens": ["Und", "Fluch", "auf", "Fluch", "ge\u00b7h\u00e4uft", "und", "Last", "auf", "Last", "ge\u00b7th\u00fcr\u00b7met", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NN", "VVPP", "KON", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Schlag, wirf mich, t\u00f6dte mich! Es ist verdiente Schuld.", "tokens": ["Schlag", ",", "wirf", "mich", ",", "t\u00f6d\u00b7te", "mich", "!", "Es", "ist", "ver\u00b7dien\u00b7te", "Schuld", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVIMP", "PPER", "$,", "VVFIN", "PPER", "$.", "PPER", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Dein Zorn brennt nicht so sehr die b\u00f6sen Sodomskinder,", "tokens": ["Dein", "Zorn", "brennt", "nicht", "so", "sehr", "die", "b\u00f6\u00b7sen", "So\u00b7doms\u00b7kin\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKNEG", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die H\u00f6lle scheint noch kalt und plaget viel gelinder", "tokens": ["Die", "H\u00f6l\u00b7le", "scheint", "noch", "kalt", "und", "pla\u00b7get", "viel", "ge\u00b7lin\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJD", "KON", "VVFIN", "PIAT", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als mich die Qual und Reu, die in der Seelen schmerzt.", "tokens": ["Als", "mich", "die", "Qual", "und", "Reu", ",", "die", "in", "der", "See\u00b7len", "schmerzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "KON", "NE", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ist's m\u00f6glich, ach, so gieb, du ewiges Geschicke,", "tokens": ["Ist's", "m\u00f6g\u00b7lich", ",", "ach", ",", "so", "gieb", ",", "du", "e\u00b7wi\u00b7ges", "Ge\u00b7schi\u00b7cke", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "$,", "ITJ", "$,", "ADV", "VVIMP", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mir auch jezund vor Blut ein Theil der Zeit zur\u00fccke,", "tokens": ["Mir", "auch", "je\u00b7zund", "vor", "Blut", "ein", "Theil", "der", "Zeit", "zu\u00b7r\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "APPR", "NN", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Mit der sein Selbstbetrug sein zeitlich Wohl verscherzt!", "tokens": ["Mit", "der", "sein", "Selbst\u00b7be\u00b7trug", "sein", "zeit\u00b7lich", "Wohl", "ver\u00b7scherzt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPOSAT", "NN", "PPOSAT", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Wie be\u00dfer wollt ich jezt das theure Kleinod sch\u00e4zen,", "tokens": ["Wie", "be\u00b7\u00dfer", "wollt", "ich", "jezt", "das", "theu\u00b7re", "Klei\u00b7nod", "sch\u00e4\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VMFIN", "PPER", "ADV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie ruhig sollte sich hernach mein Alter sezen", "tokens": ["Wie", "ru\u00b7hig", "soll\u00b7te", "sich", "her\u00b7nach", "mein", "Al\u00b7ter", "se\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VMFIN", "PRF", "ADV", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und, wenn denn meine Pflicht der Welt genug gedient,", "tokens": ["Und", ",", "wenn", "denn", "mei\u00b7ne", "Pflicht", "der", "Welt", "ge\u00b7nug", "ge\u00b7dient", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ADV", "PPOSAT", "NN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit Fried und Freudigkeit und als im Rosengarthen", "tokens": ["Mit", "Fried", "und", "Freu\u00b7dig\u00b7keit", "und", "als", "im", "Ro\u00b7sen\u00b7gar\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "KON", "KOUS", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Den Tod und auf den Tod den Nachruf still erwarthen,", "tokens": ["Den", "Tod", "und", "auf", "den", "Tod", "den", "Nach\u00b7ruf", "still", "er\u00b7wart\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "APPR", "ART", "NN", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich sey als wie ein Baum nach vieler Frucht vergr\u00fcnt.", "tokens": ["Ich", "sey", "als", "wie", "ein", "Baum", "nach", "vie\u00b7ler", "Frucht", "ver\u00b7gr\u00fcnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOUS", "KOKOM", "ART", "NN", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Mein Gott, es ist geschehn, mehr kan ich nun nicht sagen.", "tokens": ["Mein", "Gott", ",", "es", "ist", "ge\u00b7schehn", ",", "mehr", "kan", "ich", "nun", "nicht", "sa\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPER", "VAFIN", "VVPP", "$,", "ADV", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Stimmt deine Vorsicht bey, so seze meinen Tagen", "tokens": ["Stimmt", "dei\u00b7ne", "Vor\u00b7sicht", "bey", ",", "so", "se\u00b7ze", "mei\u00b7nen", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$,", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "(hiskias weint in mir) nur wenig Stufen zu.", "tokens": ["(", "his\u00b7ki\u00b7as", "weint", "in", "mir", ")", "nur", "we\u00b7nig", "Stu\u00b7fen", "zu", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "VVFIN", "APPR", "PPER", "$(", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Ich will den kurzen Rest in tausend Sorgen theilen,", "tokens": ["Ich", "will", "den", "kur\u00b7zen", "Rest", "in", "tau\u00b7send", "Sor\u00b7gen", "thei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "APPR", "CARD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Durch That und Be\u00dferung das Zeugn\u00fc\u00df zu ereilen,", "tokens": ["Durch", "That", "und", "Be\u00b7\u00dfe\u00b7rung", "das", "Zeug\u00b7n\u00fc\u00df", "zu", "er\u00b7ei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df ich anjezo nicht mit Heucheln Bu\u00dfe thu.", "tokens": ["Da\u00df", "ich", "an\u00b7je\u00b7zo", "nicht", "mit", "Heu\u00b7cheln", "Bu\u00b7\u00dfe", "thu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "APPR", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Der Ernst macht alles gut; was hin ist, sey verge\u00dfen.", "tokens": ["Der", "Ernst", "macht", "al\u00b7les", "gut", ";", "was", "hin", "ist", ",", "sey", "ver\u00b7ge\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "ADJD", "$.", "PWS", "ADV", "VAFIN", "$,", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kein Kraut ist ja so welck, man weis noch Saft zu pre\u00dfen,", "tokens": ["Kein", "Kraut", "ist", "ja", "so", "welck", ",", "man", "weis", "noch", "Saft", "zu", "pre\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADV", "PTKVZ", "$,", "PIS", "PTKVZ", "KON", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der, kommt gleich jenes um, den Krancken Heil gew\u00e4hrt", "tokens": ["Der", ",", "kommt", "gleich", "je\u00b7nes", "um", ",", "den", "Kran\u00b7cken", "Heil", "ge\u00b7w\u00e4hrt"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "$,", "VVFIN", "ADV", "PDS", "PTKVZ", "$,", "ART", "NN", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mana\u00dfes mehrt zulezt die Anzahl frommer F\u00fcrsten,", "tokens": ["Ma\u00b7na\u00b7\u00dfes", "mehrt", "zu\u00b7lezt", "die", "An\u00b7zahl", "from\u00b7mer", "F\u00fcrs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und Saul kan nicht so starck nach Blut und Unschuld d\u00fcrsten,", "tokens": ["Und", "Saul", "kan", "nicht", "so", "starck", "nach", "Blut", "und", "Un\u00b7schuld", "d\u00fcrs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VMFIN", "PTKNEG", "ADV", "ADJD", "APPR", "NN", "KON", "NN", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Als eifrig und geschickt hernach sein Geist bekehrt.", "tokens": ["Als", "eif\u00b7rig", "und", "ge\u00b7schickt", "her\u00b7nach", "sein", "Geist", "be\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "KON", "ADJD", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Ist deiner Ordnung ja mein l\u00e4ngres Ziel zuwider,", "tokens": ["Ist", "dei\u00b7ner", "Ord\u00b7nung", "ja", "mein", "l\u00e4ng\u00b7res", "Ziel", "zu\u00b7wi\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "PPOSAT", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So rette, treuer Gott, doch alle meine Br\u00fcder,", "tokens": ["So", "ret\u00b7te", ",", "treu\u00b7er", "Gott", ",", "doch", "al\u00b7le", "mei\u00b7ne", "Br\u00fc\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ADJA", "NN", "$,", "ADV", "PIS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die voller Irrthum sind und noch an Jahren bl\u00fchn,", "tokens": ["Die", "vol\u00b7ler", "Irr\u00b7thum", "sind", "und", "noch", "an", "Jah\u00b7ren", "bl\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "KON", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und las sich ihren Geist an meinen Thr\u00e4nen spiegeln,", "tokens": ["Und", "las", "sich", "ih\u00b7ren", "Geist", "an", "mei\u00b7nen", "Thr\u00e4\u00b7nen", "spie\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Eh Ohnmacht, Schw\u00e4ch und Zeit die Gnadenth\u00fcr verriegeln,", "tokens": ["Eh", "Ohn\u00b7macht", ",", "Schw\u00e4ch", "und", "Zeit", "die", "Gna\u00b7dent\u00b7h\u00fcr", "ver\u00b7rie\u00b7geln", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "NN", "KON", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Damit sie mehr Gewinn von ihrem Pfunde ziehn.", "tokens": ["Da\u00b7mit", "sie", "mehr", "Ge\u00b7winn", "von", "ih\u00b7rem", "Pfun\u00b7de", "ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Von nun an will ich mich dir g\u00e4nzlich \u00fcberla\u00dfen", "tokens": ["Von", "nun", "an", "will", "ich", "mich", "dir", "g\u00e4nz\u00b7lich", "\u00fc\u00b7berl\u00b7a\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "APZR", "VMFIN", "PPER", "PPER", "PPER", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und um den lezten Sturm den st\u00e4rcksten Ancker fa\u00dfen,", "tokens": ["Und", "um", "den", "lez\u00b7ten", "Sturm", "den", "st\u00e4rcks\u00b7ten", "An\u00b7cker", "fa\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den uns auf Golgatha der Christen Hofnung reicht.", "tokens": ["Den", "uns", "auf", "Gol\u00b7ga\u00b7tha", "der", "Chris\u00b7ten", "Hof\u00b7nung", "reicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NE", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dein Wort, dein Sohn, dein Geist befriedigt mein Gewi\u00dfen", "tokens": ["Dein", "Wort", ",", "dein", "Sohn", ",", "dein", "Geist", "be\u00b7frie\u00b7digt", "mein", "Ge\u00b7wi\u00b7\u00dfen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und lehrt mich hier getrost der Jugend Fehler b\u00fc\u00dfen,", "tokens": ["Und", "lehrt", "mich", "hier", "ge\u00b7trost", "der", "Ju\u00b7gend", "Feh\u00b7ler", "b\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "VVPP", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Bis ihrer Strafen Schmerz mit W\u00e4rm und Athem weicht.", "tokens": ["Bis", "ih\u00b7rer", "Stra\u00b7fen", "Schmerz", "mit", "W\u00e4rm", "und", "A\u00b7them", "weicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Komm nun und wie du wilst, die Erbschuld abzufodern;", "tokens": ["Komm", "nun", "und", "wie", "du", "wilst", ",", "die", "Erb\u00b7schuld", "ab\u00b7zu\u00b7fo\u00b7dern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "PWAV", "PPER", "VMFIN", "$,", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Leib, das schwere Kleid, mag rei\u00dfen und vermodern,", "tokens": ["Der", "Leib", ",", "das", "schwe\u00b7re", "Kleid", ",", "mag", "rei\u00b7\u00dfen", "und", "ver\u00b7mo\u00b7dern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "$,", "VMFIN", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Weil dies Verwesen ihn mit neuer Klarheit schm\u00fcckt.", "tokens": ["Weil", "dies", "Ver\u00b7we\u00b7sen", "ihn", "mit", "neu\u00b7er", "Klar\u00b7heit", "schm\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "NN", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich will ihm zum Voraus mit freudenreichem Sehnen", "tokens": ["Ich", "will", "ihm", "zum", "Vo\u00b7raus", "mit", "freu\u00b7den\u00b7rei\u00b7chem", "Seh\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "APPRART", "NN", "APPR", "ADJA", "NN"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Auf Gr\u00e4bern nach und nach den Schimmer angew\u00f6hnen,", "tokens": ["Auf", "Gr\u00e4\u00b7bern", "nach", "und", "nach", "den", "Schim\u00b7mer", "an\u00b7ge\u00b7w\u00f6h\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "KON", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "In welchem ihn hinfort kein eitler Traum mehr r\u00fcckt.", "tokens": ["In", "wel\u00b7chem", "ihn", "hin\u00b7fort", "kein", "eit\u00b7ler", "Traum", "mehr", "r\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "PIAT", "ADJA", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "O sanfte Lagerstatt, o seeliges Gefilde!", "tokens": ["O", "sanf\u00b7te", "La\u00b7ger\u00b7statt", ",", "o", "see\u00b7li\u00b7ges", "Ge\u00b7fil\u00b7de", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "FM", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du tr\u00e4gst, du zeigest mir das Paradies im Bilde;", "tokens": ["Du", "tr\u00e4gst", ",", "du", "zei\u00b7gest", "mir", "das", "Pa\u00b7ra\u00b7dies", "im", "Bil\u00b7de", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich steh, ich weis nicht wie, recht innerlich ger\u00fchrt.", "tokens": ["Ich", "steh", ",", "ich", "weis", "nicht", "wie", ",", "recht", "in\u00b7ner\u00b7lich", "ge\u00b7r\u00fchrt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "PTKVZ", "PTKNEG", "KOKOM", "$,", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie sanfte wird sich hier Neid, Gram und Angst verschlafen,", "tokens": ["Wie", "sanf\u00b7te", "wird", "sich", "hier", "Neid", ",", "Gram", "und", "Angst", "ver\u00b7schla\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "VAFIN", "PRF", "ADV", "NN", "$,", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bis einst der gro\u00dfe Tag die B\u00f6cke von den Schaafen,", "tokens": ["Bis", "einst", "der", "gro\u00b7\u00dfe", "Tag", "die", "B\u00f6\u00b7cke", "von", "den", "Schaa\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ART", "ADJA", "NN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die in die Marter jagt und die zur Freude f\u00fchrt.", "tokens": ["Die", "in", "die", "Mar\u00b7ter", "jagt", "und", "die", "zur", "Freu\u00b7de", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "KON", "ART", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Mein Schaz, Immanuel, mein Heiland, meine Liebe!", "tokens": ["Mein", "Schaz", ",", "Im\u00b7ma\u00b7nu\u00b7el", ",", "mein", "Hei\u00b7land", ",", "mei\u00b7ne", "Lie\u00b7be", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NE", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Verleih doch, da\u00df ich mich in deinem Wandel \u00fcbe,", "tokens": ["Ver\u00b7leih", "doch", ",", "da\u00df", "ich", "mich", "in", "dei\u00b7nem", "Wan\u00b7del", "\u00fc\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$,", "KOUS", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Verdirb mir alle Kost, die nach der Erde schmeckt,", "tokens": ["Ver\u00b7dirb", "mir", "al\u00b7le", "Kost", ",", "die", "nach", "der", "Er\u00b7de", "schmeckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PIAT", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Verbittre mir die Welt durch deines Creuzes Frieden,", "tokens": ["Ver\u00b7bitt\u00b7re", "mir", "die", "Welt", "durch", "dei\u00b7nes", "Creu\u00b7zes", "Frie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vertreib, was mich und dich durch mein Versehn geschieden,", "tokens": ["Ver\u00b7treib", ",", "was", "mich", "und", "dich", "durch", "mein", "Ver\u00b7sehn", "ge\u00b7schie\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "PPER", "KON", "PRF", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und h\u00fcll in dein Verdienst, was Zorn und Rache weckt.", "tokens": ["Und", "h\u00fcll", "in", "dein", "Ver\u00b7dienst", ",", "was", "Zorn", "und", "Ra\u00b7che", "weckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "PPOSAT", "NN", "$,", "PWS", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Soll ja mein j\u00e4her Fall den C\u00f6rper niederst\u00fcrzen,", "tokens": ["Soll", "ja", "mein", "j\u00e4\u00b7her", "Fall", "den", "C\u00f6r\u00b7per", "nie\u00b7ders\u00b7t\u00fcr\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPOSAT", "ADJA", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So las mir Zeit und Schmerz auf deiner Brust verk\u00fcrzen", "tokens": ["So", "las", "mir", "Zeit", "und", "Schmerz", "auf", "dei\u00b7ner", "Brust", "ver\u00b7k\u00fcr\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und nimm den freyen Geist mit Arm und Mitleid auf.", "tokens": ["Und", "nimm", "den", "frey\u00b7en", "Geist", "mit", "Arm", "und", "Mit\u00b7leid", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wem irgend noch von mir ein \u00c4rgern\u00fc\u00df geblieben,", "tokens": ["Wem", "ir\u00b7gend", "noch", "von", "mir", "ein", "\u00c4r\u00b7ger\u00b7n\u00fc\u00df", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "APPR", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dem sey der Spruch ans Herz wie mir an Sarg geschrieben:", "tokens": ["Dem", "sey", "der", "Spruch", "ans", "Herz", "wie", "mir", "an", "Sarg", "ge\u00b7schrie\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPRART", "NN", "KOKOM", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Oft ist ein guter Tod der beste Lebenslauf.", "tokens": ["Oft", "ist", "ein", "gu\u00b7ter", "Tod", "der", "bes\u00b7te", "Le\u00b7bens\u00b7lauf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}