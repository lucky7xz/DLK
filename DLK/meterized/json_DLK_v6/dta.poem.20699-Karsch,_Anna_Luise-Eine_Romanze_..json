{"dta.poem.20699": {"metadata": {"author": {"name": "Karsch, Anna Luise", "birth": "N.A.", "death": "N.A."}, "title": "Eine Romanze .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1792", "urn": "urn:nbn:de:kobv:b4-200905193016", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Bei Reichenberg, nach Friedrichs Sieg,                 ", "tokens": ["Bei", "Rei\u00b7chen\u00b7berg", ",", "nach", "Fried\u00b7richs", "Sieg", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Besah mein Freund mit Klagen", "tokens": ["Be\u00b7sah", "mein", "Freund", "mit", "Kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Menschen, die der b\u00f6se Krieg", "tokens": ["Die", "Men\u00b7schen", ",", "die", "der", "b\u00f6\u00b7se", "Krieg"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gottsj\u00e4mmerlich erschlagen.", "tokens": ["Gotts\u00b7j\u00e4m\u00b7mer\u00b7lich", "er\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Dort lag ein Kopf \u2014 hier Arm und Bein,", "tokens": ["Dort", "lag", "ein", "Kopf", "hier", "Arm", "und", "Bein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$(", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Erb\u00e4rmlich anzuschauen.", "tokens": ["Er\u00b7b\u00e4rm\u00b7lich", "an\u00b7zu\u00b7schau\u00b7en", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Ich bilde mir dies Schlachtfeld ein", "tokens": ["Ich", "bil\u00b7de", "mir", "dies", "Schlacht\u00b7feld", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PDS", "NN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und mir f\u00e4ngt an zu grauen.", "tokens": ["Und", "mir", "f\u00e4ngt", "an", "zu", "grau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ein Korporal aus Habspurgs Heer", "tokens": ["Ein", "Kor\u00b7po\u00b7ral", "aus", "Hab\u00b7spurgs", "Heer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lag unter tausend Leichen,", "tokens": ["Lag", "un\u00b7ter", "tau\u00b7send", "Lei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sein K\u00f6rper, gro\u00df und stark und schwer,", "tokens": ["Sein", "K\u00f6r\u00b7per", ",", "gro\u00df", "und", "stark", "und", "schwer", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADJD", "KON", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zerfezt von S\u00e4belstreichen,", "tokens": ["Zer\u00b7fezt", "von", "S\u00e4\u00b7bel\u00b7strei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "War hingefallen in der Schlacht.", "tokens": ["War", "hin\u00b7ge\u00b7fal\u00b7len", "in", "der", "Schlacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihm lag nach guter Beute,", "tokens": ["Ihm", "lag", "nach", "gu\u00b7ter", "Beu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Die irgend ein Husar gemacht,", "tokens": ["Die", "ir\u00b7gend", "ein", "Hu\u00b7sar", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.8": {"text": "Noch ein Papier zur Seite.", "tokens": ["Noch", "ein", "Pa\u00b7pier", "zur", "Sei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Mein Freund neugierig, was das sey,", "tokens": ["Mein", "Freund", "neu\u00b7gie\u00b7rig", ",", "was", "das", "sey", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "$,", "PWS", "PDS", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hubs auf mit seinem Degen,", "tokens": ["Hubs", "auf", "mit", "sei\u00b7nem", "De\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Zogs an der Spitze schnell herbei,", "tokens": ["Zogs", "an", "der", "Spit\u00b7ze", "schnell", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Und fings an zu zerlegen;", "tokens": ["Und", "fings", "an", "zu", "zer\u00b7le\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Da rasselte nun das Papier,", "tokens": ["Da", "ras\u00b7sel\u00b7te", "nun", "das", "Pa\u00b7pier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Und er ward Schrecken-voller,", "tokens": ["Und", "er", "ward", "Schre\u00b7cken\u00b7vol\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Als selbst im Treffen, denn das Thier,", "tokens": ["Als", "selbst", "im", "Tref\u00b7fen", ",", "denn", "das", "Thier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPRART", "NN", "$,", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sein Pferd, bekam den Koller.", "tokens": ["Sein", "Pferd", ",", "be\u00b7kam", "den", "Kol\u00b7ler", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Papier und Degen fiel im Sand,", "tokens": ["Pa\u00b7pier", "und", "De\u00b7gen", "fiel", "im", "Sand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er durfte nicht vers\u00e4umen,", "tokens": ["Er", "durf\u00b7te", "nicht", "ver\u00b7s\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dies wilde Pferd mit rascher Hand", "tokens": ["Dies", "wil\u00b7de", "Pferd", "mit", "ra\u00b7scher", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADJA", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu z\u00fcgeln und zu z\u00e4umen;", "tokens": ["Zu", "z\u00fc\u00b7geln", "und", "zu", "z\u00e4u\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Doch Zaum und Z\u00fcgel thatens nicht,", "tokens": ["Doch", "Zaum", "und", "Z\u00fc\u00b7gel", "tha\u00b7tens", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "H\u00e4tt er nicht sanft gesprochen,", "tokens": ["H\u00e4tt", "er", "nicht", "sanft", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Wie er mit mir zuweilen spricht,", "tokens": ["Wie", "er", "mit", "mir", "zu\u00b7wei\u00b7len", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "H\u00e4tts ihm den Hals gebrochen \u2014", "tokens": ["H\u00e4tts", "ihm", "den", "Hals", "ge\u00b7bro\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVPP", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.5": {"line.1": {"text": "Jezt lenkt ers wieder um, und nahm", "tokens": ["Jezt", "lenkt", "ers", "wie\u00b7der", "um", ",", "und", "nahm"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "PTKVZ", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ganz still Papier und Degen;", "tokens": ["Ganz", "still", "Pa\u00b7pier", "und", "De\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Las nicht, bis er ins Feldhaus kam,", "tokens": ["Las", "nicht", ",", "bis", "er", "ins", "Feld\u00b7haus", "kam", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "$,", "KOUS", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da wollt er wunderswegen", "tokens": ["Da", "wollt", "er", "wun\u00b7ders\u00b7we\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Erfahren, was geschrieben w\u00e4r,", "tokens": ["Er\u00b7fah\u00b7ren", ",", "was", "ge\u00b7schrie\u00b7ben", "w\u00e4r", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da fand sichs auf dem Blatte,", "tokens": ["Da", "fand", "sichs", "auf", "dem", "Blat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Da\u00df es ein M\u00e4dchen wehmuthsschwer", "tokens": ["Da\u00df", "es", "ein", "M\u00e4d\u00b7chen", "weh\u00b7muths\u00b7schwer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Aus Wien geschrieben hatte.", "tokens": ["Aus", "Wi\u00b7en", "ge\u00b7schrie\u00b7ben", "hat\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVPP", "VAFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Viel sch\u00f6ne Namen waren hier", "tokens": ["Viel", "sch\u00f6\u00b7ne", "Na\u00b7men", "wa\u00b7ren", "hier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In s\u00fc\u00dfem Liebsgeschw\u00e4tze;", "tokens": ["In", "s\u00fc\u00b7\u00dfem", "Liebs\u00b7ge\u00b7schw\u00e4t\u00b7ze", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es ward erz\u00e4hlt, wie vielmal ihr", "tokens": ["Es", "ward", "er\u00b7z\u00e4hlt", ",", "wie", "viel\u00b7mal", "ihr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "PWAV", "ADV", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Traum das Herz erg\u00f6tze,", "tokens": ["Ein", "Traum", "das", "Herz", "er\u00b7g\u00f6t\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wie vielmal sich auch Furcht und Pein", "tokens": ["Wie", "viel\u00b7mal", "sich", "auch", "Furcht", "und", "Pein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "PRF", "ADV", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In ihre Brust ergossen,", "tokens": ["In", "ih\u00b7re", "Brust", "er\u00b7gos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Es m\u00fcsten wol Gespenster seyn,", "tokens": ["Es", "m\u00fcs\u00b7ten", "wol", "Ge\u00b7spens\u00b7ter", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ward jeder Vers geschlossen.", "tokens": ["Ward", "je\u00b7der", "Vers", "ge\u00b7schlos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Nun l\u00f6\u00dfte sich das R\u00e4thsel auf,", "tokens": ["Nun", "l\u00f6\u00df\u00b7te", "sich", "das", "R\u00e4th\u00b7sel", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Warum der Fu\u00df des Thieres", "tokens": ["Wa\u00b7rum", "der", "Fu\u00df", "des", "Thie\u00b7res"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Davon gerannt, im Fl\u00fcgellauf,", "tokens": ["Da\u00b7von", "ge\u00b7rannt", ",", "im", "Fl\u00fc\u00b7gel\u00b7lauf", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "VVPP", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Beim Rasseln des Papieres;", "tokens": ["Beim", "Ras\u00b7seln", "des", "Pa\u00b7pie\u00b7res", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Der Geist vom armen Korporal", "tokens": ["Der", "Geist", "vom", "ar\u00b7men", "Kor\u00b7po\u00b7ral"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wird da gespucket haben,", "tokens": ["Wird", "da", "ge\u00b7spu\u00b7cket", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Weil er gewollt man sollt einmal", "tokens": ["Weil", "er", "ge\u00b7wollt", "man", "sollt", "ein\u00b7mal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VMPP", "PIS", "VMFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Dies Bl\u00e4ttchen mit begraben.", "tokens": ["Dies", "Bl\u00e4tt\u00b7chen", "mit", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "APPR", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}