{"textgrid.poem.40409": {"metadata": {"author": {"name": "Scheffel, Joseph Viktor von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Bestreuet die H\u00e4upter mit Asche,", "genre": "verse", "period": "N.A.", "pub_year": 1856, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Bestreuet die H\u00e4upter mit Asche,", "tokens": ["Be\u00b7streu\u00b7et", "die", "H\u00e4up\u00b7ter", "mit", "A\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Verhaltet die Nasen euch bang,", "tokens": ["Ver\u00b7hal\u00b7tet", "die", "Na\u00b7sen", "euch", "bang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Heut gibt's bei tr\u00fcbflie\u00dfender Flasche", "tokens": ["Heut", "gibt's", "bei", "tr\u00fcb\u00b7flie\u00b7\u00dfen\u00b7der", "Fla\u00b7sche"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Einen bitumin\u00f6sen Gesang.", "tokens": ["Ei\u00b7nen", "bi\u00b7tu\u00b7mi\u00b7n\u00f6\u00b7sen", "Ge\u00b7sang", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}}, "stanza.2": {"line.1": {"text": "\u2013 Schw\u00fcl strahlet die Sonne der W\u00fcste,", "tokens": ["\u2013", "Schw\u00fcl", "strah\u00b7let", "die", "Son\u00b7ne", "der", "W\u00fcs\u00b7te", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Am Toten Meere macht's warm;", "tokens": ["Am", "To\u00b7ten", "Mee\u00b7re", "macht's", "warm", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ein Derwisch spaziert an der K\u00fcste,", "tokens": ["Ein", "Der\u00b7wisch", "spa\u00b7ziert", "an", "der", "K\u00fcs\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Eine Maid aus Engeddi am Arm.", "tokens": ["Ei\u00b7ne", "Maid", "aus", "En\u00b7ged\u00b7di", "am", "Arm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "APPRART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Nicht Luftzug noch Wellenschlag kr\u00e4uselt", "tokens": ["Nicht", "Luft\u00b7zug", "noch", "Wel\u00b7len\u00b7schlag", "kr\u00e4u\u00b7selt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKNEG", "NN", "ADV", "NN", "VVFIN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Den z\u00e4hen, bleifarbigen See,", "tokens": ["Den", "z\u00e4\u00b7hen", ",", "blei\u00b7far\u00b7bi\u00b7gen", "See", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Nur Naphthageruch kommt ges\u00e4uselt", "tokens": ["Nur", "Naph\u00b7tha\u00b7ge\u00b7ruch", "kommt", "ge\u00b7s\u00e4u\u00b7selt"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "NN", "VVFIN", "VVPP"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Und dunstig umflort sich die H\u00f6h'.", "tokens": ["Und", "duns\u00b7tig", "um\u00b7flort", "sich", "die", "H\u00f6h'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.4": {"line.1": {"text": "'s ist eine versalzene Gegend", "tokens": ["'s", "ist", "ei\u00b7ne", "ver\u00b7sal\u00b7ze\u00b7ne", "Ge\u00b7gend"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Und niemand ringsum ist gerecht;", "tokens": ["Und", "nie\u00b7mand", "ring\u00b7sum", "ist", "ge\u00b7recht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADV", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu Lots Zeit hat's Schwefel geregnet", "tokens": ["Zu", "Lots", "Zeit", "hat's", "Schwe\u00b7fel", "ge\u00b7reg\u00b7net"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "NN", "VAFIN", "NN", "VVPP"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und heut noch ist alles verpecht.", "tokens": ["Und", "heut", "noch", "ist", "al\u00b7les", "ver\u00b7pecht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VAFIN", "PIS", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.5": {"line.1": {"text": "Keine W\u00e4scherin naht mit dem K\u00fcbel,", "tokens": ["Kei\u00b7ne", "W\u00e4\u00b7sche\u00b7rin", "naht", "mit", "dem", "K\u00fc\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Kein Durstiger naht mit dem Krug,", "tokens": ["Kein", "Durs\u00b7ti\u00b7ger", "naht", "mit", "dem", "Krug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Und dem Durstigsten selber wird \u00fcbel,", "tokens": ["Und", "dem", "Durs\u00b7tigs\u00b7ten", "sel\u00b7ber", "wird", "\u00fc\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "VAFIN", "ADJD", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Wagt er aus der Flut einen Zug.", "tokens": ["Wagt", "er", "aus", "der", "Flut", "ei\u00b7nen", "Zug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.6": {"line.1": {"text": "Zwei schwarzbraune Klumpen lagen", "tokens": ["Zwei", "schwarz\u00b7brau\u00b7ne", "Klum\u00b7pen", "la\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["CARD", "ADJA", "NN", "VVFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Am Ufer faulbrenzlig und schwer;", "tokens": ["Am", "U\u00b7fer", "faul\u00b7brenz\u00b7lig", "und", "schwer", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Drauf satzte mit stillem Behagen", "tokens": ["Drauf", "satz\u00b7te", "mit", "stil\u00b7lem", "Be\u00b7ha\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Das Paar sich und liebte sich sehr.", "tokens": ["Das", "Paar", "sich", "und", "lieb\u00b7te", "sich", "sehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "KON", "VVFIN", "PRF", "ADV", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.7": {"line.1": {"text": "Doch wehe! sie sa\u00dfen auf Naphtha,", "tokens": ["Doch", "we\u00b7he", "!", "sie", "sa\u00b7\u00dfen", "auf", "Naph\u00b7tha", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$.", "PPER", "VVFIN", "APPR", "NE", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Und das l\u00e4\u00dft keinen mehr weg,", "tokens": ["Und", "das", "l\u00e4\u00dft", "kei\u00b7nen", "mehr", "weg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PIAT", "PIS", "PTKVZ", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Wer harmlos sich dreinsetzt, der haft't da", "tokens": ["Wer", "harm\u00b7los", "sich", "drein\u00b7setzt", ",", "der", "haft't", "da"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "ADJD", "PRF", "VVFIN", "$,", "PRELS", "VVFIN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und steckt im gediegensten Pech.", "tokens": ["Und", "steckt", "im", "ge\u00b7die\u00b7gens\u00b7ten", "Pech", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Sie konnten sich nimmer erheben,", "tokens": ["Sie", "konn\u00b7ten", "sich", "nim\u00b7mer", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ADV", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Sie jammerten: \u00bbAllah ist gro\u00df!", "tokens": ["Sie", "jam\u00b7mer\u00b7ten", ":", "\u00bb", "Al\u00b7lah", "ist", "gro\u00df", "!"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir kleben \u2013 wir kleben \u2013 wir kleben!", "tokens": ["Wir", "kle\u00b7ben", "\u2013", "wir", "kle\u00b7ben", "\u2013", "wir", "kle\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VVINF", "$(", "PPER", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Wir kleben und kommen nicht los!\u00ab", "tokens": ["Wir", "kle\u00b7ben", "und", "kom\u00b7men", "nicht", "los", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PTKNEG", "PTKVZ", "$.", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.9": {"line.1": {"text": "Umsonst hat ihr Klagen und Weinen", "tokens": ["Um\u00b7sonst", "hat", "ihr", "Kla\u00b7gen", "und", "Wei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "KON", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Die schweigende W\u00fcste durchhallt,", "tokens": ["Die", "schwei\u00b7gen\u00b7de", "W\u00fcs\u00b7te", "durch\u00b7hallt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Sie mu\u00dften zu Mumien versteinen", "tokens": ["Sie", "mu\u00df\u00b7ten", "zu", "Mu\u00b7mi\u00b7en", "ver\u00b7stei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "NN", "VVINF"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und wurden, ach, selbst zu Asphalt.", "tokens": ["Und", "wur\u00b7den", ",", "ach", ",", "selbst", "zu", "As\u00b7phalt", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "ITJ", "$,", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Ein V\u00f6gelein wollte um Hilfe", "tokens": ["Ein", "V\u00f6\u00b7ge\u00b7lein", "woll\u00b7te", "um", "Hil\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "APPR", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Hin\u00fcber zum St\u00e4dtlein Zoar,", "tokens": ["Hin\u00b7\u00fc\u00b7ber", "zum", "St\u00e4dt\u00b7lein", "Zoar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Bet\u00e4ubt fiel's herab ins Geschilfe,", "tokens": ["Be\u00b7t\u00e4ubt", "fiel's", "her\u00b7ab", "ins", "Ge\u00b7schil\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "ADV", "APPRART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Es stank, da\u00df zu fliegen nicht war.", "tokens": ["Es", "stank", ",", "da\u00df", "zu", "flie\u00b7gen", "nicht", "war", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PTKZU", "VVINF", "PTKNEG", "VAFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.11": {"line.1": {"text": "Und bla\u00df, mit erschaudernden Seelen", "tokens": ["Und", "bla\u00df", ",", "mit", "er\u00b7schau\u00b7dern\u00b7den", "See\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJD", "$,", "APPR", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Sah man einen Wallfahrtzug fliehn \u2013", "tokens": ["Sah", "man", "ei\u00b7nen", "Wall\u00b7fahrt\u00b7zug", "fliehn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "VVINF", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Den Pilgern sowie den Kamelen", "tokens": ["Den", "Pil\u00b7gern", "so\u00b7wie", "den", "Ka\u00b7me\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "War's benzoesauer zu Sinn.", "tokens": ["Wa\u00b7r's", "ben\u00b7zoe\u00b7sau\u00b7er", "zu", "Sinn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "NN", "$."], "meter": "-+-+---+", "measure": "unknown.measure.tri"}}, "stanza.12": {"line.1": {"text": "So geht's, wenn ein Derwisch will minnen", "tokens": ["So", "geht's", ",", "wenn", "ein", "Der\u00b7wisch", "will", "min\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "ART", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und hat das Terrain nicht erkannt ...", "tokens": ["Und", "hat", "das", "Ter\u00b7rain", "nicht", "er\u00b7kannt", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "O J\u00fcngling, fleuch eiligst von hinnen,", "tokens": ["O", "J\u00fcng\u00b7ling", ",", "fleuch", "ei\u00b7ligst", "von", "hin\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "VVFIN", "ADV", "APPR", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wo Erdpech entquillet dem Land.", "tokens": ["Wo", "Erd\u00b7pech", "ent\u00b7quil\u00b7let", "dem", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}}}}