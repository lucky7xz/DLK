{"textgrid.poem.57366": {"metadata": {"author": {"name": "Klopstock, Friedrich Gottlieb", "birth": "N.A.", "death": "N.A."}, "title": "1L: Sey denn Krieg, weil Krieg seyn muss! doch er sch\u00fctze nur, r\u00f6the", "genre": "verse", "period": "N.A.", "pub_year": 1794, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sey denn Krieg, weil Krieg seyn muss! doch er sch\u00fctze nur, r\u00f6the", "tokens": ["Sey", "denn", "Krieg", ",", "weil", "Krieg", "seyn", "muss", "!", "doch", "er", "sch\u00fct\u00b7ze", "nur", ",", "r\u00f6\u00b7the"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "ADV", "NN", "$,", "KOUS", "NN", "VAINF", "VMFIN", "$.", "KON", "PPER", "VVFIN", "ADV", "$,", "VVFIN"], "meter": "+-+-+-+--+--+-", "measure": "hexameter"}, "line.2": {"text": "Nicht in des Franken Heimat das Schwert;", "tokens": ["Nicht", "in", "des", "Fran\u00b7ken", "Hei\u00b7mat", "das", "Schwert", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "NN", "ART", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Lehrerin ist der Sache Beschaffenheit Sehenden; Andern", "tokens": ["Leh\u00b7re\u00b7rin", "ist", "der", "Sa\u00b7che", "Be\u00b7schaf\u00b7fen\u00b7heit", "Se\u00b7hen\u00b7den", ";", "An\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["NN", "VAFIN", "ART", "NN", "NN", "NN", "$.", "ADJA"], "meter": "+-+--+--+--+--+-", "measure": "hexameter"}, "line.4": {"text": "Ist es Erfahrung allein.", "tokens": ["Ist", "es", "Er\u00b7fah\u00b7rung", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NN", "ADV", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.5": {"text": "St\u00fcrzen, \u00fcber die Steine, und wieder st\u00fcrzen, und wieder!", "tokens": ["St\u00fcr\u00b7zen", ",", "\u00fc\u00b7ber", "die", "Stei\u00b7ne", ",", "und", "wie\u00b7der", "st\u00fcr\u00b7zen", ",", "und", "wie\u00b7der", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "ART", "NN", "$,", "KON", "ADV", "VVINF", "$,", "KON", "ADV", "$."], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.6": {"text": "Dieses lehrt die Anderen erst,", "tokens": ["Die\u00b7ses", "lehrt", "die", "An\u00b7de\u00b7ren", "erst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "ADV", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Dass es da, wo umher sie wanderten, ebener Weg nicht,", "tokens": ["Dass", "es", "da", ",", "wo", "um\u00b7her", "sie", "wan\u00b7der\u00b7ten", ",", "e\u00b7be\u00b7ner", "Weg", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "$,", "PWAV", "PTKVZ", "PPER", "VVFIN", "$,", "ADJA", "NN", "PTKNEG", "$,"], "meter": "--+--+-+--+--+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Dass es steinichter war.", "tokens": ["Dass", "es", "stei\u00b7nich\u00b7ter", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.9": {"text": "Weil sie denn also ganz noch erfahren nicht ist die Erfahrung,", "tokens": ["Weil", "sie", "denn", "al\u00b7so", "ganz", "noch", "er\u00b7fah\u00b7ren", "nicht", "ist", "die", "Er\u00b7fah\u00b7rung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADV", "ADV", "VVINF", "PTKNEG", "VAFIN", "ART", "NN", "$,"], "meter": "--+--+--+-+-+-+-", "measure": "anapaest.tri.plus"}, "line.10": {"text": "Ganz ihr bitterer Kelch", "tokens": ["Ganz", "ihr", "bit\u00b7te\u00b7rer", "Kelch"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "ADJA", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.11": {"text": "Bis zu dem Hesen hinab noch nicht getrunken; so sollen", "tokens": ["Bis", "zu", "dem", "He\u00b7sen", "hin\u00b7ab", "noch", "nicht", "ge\u00b7trun\u00b7ken", ";", "so", "sol\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "APPR", "ART", "NN", "ADV", "ADV", "PTKNEG", "VVPP", "$.", "ADV", "VMFIN"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.12": {"text": "Tausende noch", "tokens": ["Tau\u00b7sen\u00b7de", "noch"], "token_info": ["word", "word"], "pos": ["NN", "ADV"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.13": {"text": "Bluten? und weinen der Tausende mehr? Es sollen die M\u00fctter", "tokens": ["Blu\u00b7ten", "?", "und", "wei\u00b7nen", "der", "Tau\u00b7sen\u00b7de", "mehr", "?", "Es", "sol\u00b7len", "die", "M\u00fct\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "KON", "VVINF", "ART", "NN", "ADV", "$.", "PPER", "VMFIN", "ART", "NN"], "meter": "+--+--+--+-+--+-", "measure": "hexameter"}, "line.14": {"text": "Sich die S\u00f6hne zur St\u00fctze, die Braut", "tokens": ["Sich", "die", "S\u00f6h\u00b7ne", "zur", "St\u00fct\u00b7ze", ",", "die", "Braut"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PRF", "ART", "NN", "APPRART", "NN", "$,", "ART", "NN"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.15": {"text": "Ihren Gew\u00e4hlten umsonst herrufen vom schweigenden Schlachtfeld", "tokens": ["Ih\u00b7ren", "Ge\u00b7w\u00e4hl\u00b7ten", "um\u00b7sonst", "her\u00b7ru\u00b7fen", "vom", "schwei\u00b7gen\u00b7den", "Schlacht\u00b7feld"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADV", "VVPP", "APPRART", "ADJA", "NN"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.16": {"text": "Zum hochzeitlichen Tanz?", "tokens": ["Zum", "hoch\u00b7zeit\u00b7li\u00b7chen", "Tanz", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+---+", "measure": "dactylic.init"}, "line.17": {"text": "Lenken den Pflug der wankende Greis? Er sinkt, und die G\u00e4ule", "tokens": ["Len\u00b7ken", "den", "Pflug", "der", "wan\u00b7ken\u00b7de", "Greis", "?", "Er", "sinkt", ",", "und", "die", "G\u00e4u\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "NN", "ART", "ADJA", "NN", "$.", "PPER", "VVFIN", "$,", "KON", "ART", "NN"], "meter": "+--+-+--+-+--+-", "measure": "hexameter"}, "line.18": {"text": "Weiden die Saaten ihm ab.", "tokens": ["Wei\u00b7den", "die", "Saa\u00b7ten", "ihm", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.19": {"text": "Krieg denn, Krieg! doch gewarnt, wie er wurde, meid' er die Th\u00e4ler", "tokens": ["Krieg", "denn", ",", "Krieg", "!", "doch", "ge\u00b7warnt", ",", "wie", "er", "wur\u00b7de", ",", "meid'", "er", "die", "Th\u00e4\u00b7ler"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ADV", "$,", "NN", "$.", "ADV", "VVPP", "$,", "PWAV", "PPER", "VAFIN", "$,", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.20": {"text": "Galliens, wolle zu Kr\u00f6nungen nicht,", "tokens": ["Gal\u00b7li\u00b7ens", ",", "wol\u00b7le", "zu", "Kr\u00f6\u00b7nun\u00b7gen", "nicht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VMFIN", "APPR", "NN", "PTKNEG", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.21": {"text": "Nicht, zu entsagen dem, was dort Gl\u00fcckseligkeit scheinet,", "tokens": ["Nicht", ",", "zu", "ent\u00b7sa\u00b7gen", "dem", ",", "was", "dort", "Gl\u00fcck\u00b7se\u00b7lig\u00b7keit", "schei\u00b7net", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "$,", "PTKZU", "VVFIN", "ART", "$,", "PRELS", "ADV", "NN", "VVFIN", "$,"], "meter": "+--+--+-+-+-+-", "measure": "elegiambus"}, "line.22": {"text": "(ach einst war sie nicht Schein!)", "tokens": ["(", "ach", "einst", "war", "sie", "nicht", "Schein", "!", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ITJ", "ADV", "VAFIN", "PPER", "PTKNEG", "NN", "$.", "$("], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.23": {"text": "Zwingen ein Volk, das lange schon kalt bey der Sterbenden Anblick,", "tokens": ["Zwin\u00b7gen", "ein", "Volk", ",", "das", "lan\u00b7ge", "schon", "kalt", "bey", "der", "Ster\u00b7ben\u00b7den", "An\u00b7blick", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ADV", "ADV", "ADJD", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+--+--+--+-", "measure": "hexameter"}, "line.24": {"text": "Lang schon entgl\u00fcht", "tokens": ["Lang", "schon", "ent\u00b7gl\u00fcht"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADV", "VVPP"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.25": {"text": "War zu der Rache: er sey des eigenen Heerdes Besch\u00fctzer,", "tokens": ["War", "zu", "der", "Ra\u00b7che", ":", "er", "sey", "des", "ei\u00b7ge\u00b7nen", "Heer\u00b7des", "Be\u00b7sch\u00fct\u00b7zer", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "$.", "PPER", "VAFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "---+--+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.26": {"text": "Samle nicht welkende Lorber sich da,", "tokens": ["Sam\u00b7le", "nicht", "wel\u00b7ken\u00b7de", "Lor\u00b7ber", "sich", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "ADJA", "NN", "PRF", "ADV", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.27": {"text": "Neue! Alles ist jetzo neu! drum muss auch die Kriegskunst,", "tokens": ["Neu\u00b7e", "!", "Al\u00b7les", "ist", "jet\u00b7zo", "neu", "!", "drum", "muss", "auch", "die", "Kriegs\u00b7kunst", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "$.", "PIS", "VAFIN", "ADV", "ADJD", "$.", "PAV", "VMFIN", "ADV", "ART", "NN", "$,"], "meter": "+----+-+-+-++-", "measure": "dactylic.init"}, "line.28": {"text": "Als Vertheidigerin,", "tokens": ["Als", "Ver\u00b7thei\u00b7di\u00b7ge\u00b7rin", ","], "token_info": ["word", "word", "punct"], "pos": ["KOUS", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.29": {"text": "Neu seyn! War sie nicht stets Erfinderin? und wenn die Weisheit", "tokens": ["Neu", "seyn", "!", "War", "sie", "nicht", "stets", "Er\u00b7fin\u00b7de\u00b7rin", "?", "und", "wenn", "die", "Weis\u00b7heit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "VAINF", "$.", "VAFIN", "PPER", "PTKNEG", "ADV", "NN", "$.", "KON", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.30": {"text": "Sie auffordert, w\u00e4r sie es nicht?", "tokens": ["Sie", "auf\u00b7for\u00b7dert", ",", "w\u00e4r", "sie", "es", "nicht", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VAFIN", "PPER", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Jetzo w\u00e4r' ihr das Feuer des Adlerblickes erloschen?", "tokens": ["Jet\u00b7zo", "w\u00e4r'", "ihr", "das", "Feu\u00b7er", "des", "Ad\u00b7ler\u00b7bli\u00b7ckes", "er\u00b7lo\u00b7schen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.32": {"text": "Schlief' ihr der sinnende Geist?", "tokens": ["Schlie\u00b7f'", "ihr", "der", "sin\u00b7nen\u00b7de", "Geist", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.33": {"text": "O ihr gelingt's, sie erfindet, den menschenschonenden, kalten,", "tokens": ["O", "ihr", "ge\u00b7lingt's", ",", "sie", "er\u00b7fin\u00b7det", ",", "den", "men\u00b7schen\u00b7scho\u00b7nen\u00b7den", ",", "kal\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NE", "PPOSAT", "ADJA", "$,", "PPER", "VVFIN", "$,", "ART", "NN", "$,", "ADJA", "$,"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.34": {"text": "Deutscheren Plan!", "tokens": ["Deut\u00b7sche\u00b7ren", "Plan", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.35": {"text": "Streiter! der erste Schritt, der \u00fcber die Gr\u00e4nze den Feind f\u00fchrt;", "tokens": ["Strei\u00b7ter", "!", "der", "ers\u00b7te", "Schritt", ",", "der", "\u00fc\u00b7ber", "die", "Gr\u00e4n\u00b7ze", "den", "Feind", "f\u00fchrt", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ART", "ADJA", "NN", "$,", "PRELS", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+--+--+-", "measure": "hexameter"}, "line.36": {"text": "Fuhrt ihn in's Grab!", "tokens": ["Fuhrt", "ihn", "in's", "Grab", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.37": {"text": "T\u00e4uschet er, fliegt er mit Heerchen her\u00fcber, so steigt in dem R\u00fccken,", "tokens": ["T\u00e4u\u00b7schet", "er", ",", "fliegt", "er", "mit", "Heer\u00b7chen", "her\u00b7\u00fc\u00b7ber", ",", "so", "steigt", "in", "dem", "R\u00fc\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VVFIN", "PPER", "APPR", "NN", "ADV", "$,", "ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.38": {"text": "Auch nicht s\u00e4umend, ein Wetter ihm auf.", "tokens": ["Auch", "nicht", "s\u00e4u\u00b7mend", ",", "ein", "Wet\u00b7ter", "ihm", "auf", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADJD", "$,", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.39": {"text": "Gegen den Anflug ist, durch Pfahl und Graben, das Strohdach,", "tokens": ["Ge\u00b7gen", "den", "An\u00b7flug", "ist", ",", "durch", "Pfahl", "und", "Gra\u00b7ben", ",", "das", "Stroh\u00b7dach", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "$,", "APPR", "NN", "KON", "NN", "$,", "ART", "NN", "$,"], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}, "line.40": {"text": "Und die B\u00fcrgerh\u00fctte gesch\u00fctzt.", "tokens": ["Und", "die", "B\u00fcr\u00b7ger\u00b7h\u00fct\u00b7te", "ge\u00b7sch\u00fctzt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVPP", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.41": {"text": "Wag' er sich denn, und eil' her\u00fcber; das st\u00fcrmende Wetter", "tokens": ["Wag'", "er", "sich", "denn", ",", "und", "eil'", "her\u00b7\u00fc\u00b7ber", ";", "das", "st\u00fcr\u00b7men\u00b7de", "Wet\u00b7ter"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PRF", "ADV", "$,", "KON", "VVFIN", "ADV", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.42": {"text": "St\u00e4ubet ihn schnell vom Gesch\u00fctzten ins Feld,", "tokens": ["St\u00e4u\u00b7bet", "ihn", "schnell", "vom", "Ge\u00b7sch\u00fctz\u00b7ten", "ins", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPRART", "NN", "APPRART", "NN", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.43": {"text": "Und dann kehrt kein Bothe zur\u00fcck! Doch ich schweige von dieser", "tokens": ["Und", "dann", "kehrt", "kein", "Bo\u00b7the", "zu\u00b7r\u00fcck", "!", "Doch", "ich", "schwei\u00b7ge", "von", "die\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PIAT", "NN", "PTKVZ", "$.", "KON", "PPER", "VVFIN", "APPR", "PDAT"], "meter": "--+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.44": {"text": "Tiefen Schande des Kampfs.", "tokens": ["Tie\u00b7fen", "Schan\u00b7de", "des", "Kampfs", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.45": {"text": "Kriegen, und rasen ist Eins; und es gl\u00fccken der heilenden Kriegskunst", "tokens": ["Krie\u00b7gen", ",", "und", "ra\u00b7sen", "ist", "Eins", ";", "und", "es", "gl\u00fc\u00b7cken", "der", "hei\u00b7len\u00b7den", "Kriegs\u00b7kunst"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KON", "VVPP", "VAFIN", "NN", "$.", "KON", "PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "+--+--+--+--+-+-+", "measure": "dactylic.tetra.plus"}, "line.46": {"text": "Nie der vern\u00fcnftigen Stunden genug.", "tokens": ["Nie", "der", "ver\u00b7n\u00fcnf\u00b7ti\u00b7gen", "Stun\u00b7den", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "ADV", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.47": {"text": "Hermann hab' ich schweben gesehn; er l\u00e4chelte, sagte:", "tokens": ["Her\u00b7mann", "hab'", "ich", "schwe\u00b7ben", "ge\u00b7sehn", ";", "er", "l\u00e4\u00b7chel\u00b7te", ",", "sag\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "VVFIN", "VVPP", "$.", "PPER", "VVFIN", "$,", "VVFIN", "$."], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.48": {"text": "Sie erfinden den deutscheren Plan!", "tokens": ["Sie", "er\u00b7fin\u00b7den", "den", "deut\u00b7sche\u00b7ren", "Plan", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.49": {"text": "Selten nicht will man den Knoten der Fehde zerhaun; und zerhaut nicht!", "tokens": ["Sel\u00b7ten", "nicht", "will", "man", "den", "Kno\u00b7ten", "der", "Feh\u00b7de", "zer\u00b7haun", ";", "und", "zer\u00b7haut", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "VMFIN", "PIS", "ART", "NN", "ART", "NN", "VVINF", "$.", "KON", "VVFIN", "PTKNEG", "$."], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.50": {"text": "Enkel! sicherer l\u00f6set ihr auf.", "tokens": ["En\u00b7kel", "!", "si\u00b7che\u00b7rer", "l\u00f6\u00b7set", "ihr", "auf", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ADJD", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.51": {"text": "Enkel, Krieg! ich beschw\u00f6r' euch bey Siegmars Schwert', und bey meinem,", "tokens": ["En\u00b7kel", ",", "Krieg", "!", "ich", "be\u00b7schw\u00f6r'", "euch", "bey", "Sieg\u00b7mars", "Schwert'", ",", "und", "bey", "mei\u00b7nem", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$.", "PPER", "VVFIN", "PPER", "APPR", "NE", "VVFIN", "$,", "KON", "APPR", "PPOSAT", "$,"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.52": {"text": "Aber cheruskischer Krieg!", "tokens": ["A\u00b7ber", "che\u00b7rus\u00b7ki\u00b7scher", "Krieg", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.53": {"text": "Dennoch ist Friede die sch\u00f6nste der L\u00f6sungen. Lasset von Hlyn euch", "tokens": ["Den\u00b7noch", "ist", "Frie\u00b7de", "die", "sch\u00f6ns\u00b7te", "der", "L\u00f6\u00b7sun\u00b7gen", ".", "Las\u00b7set", "von", "Hlyn", "euch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NN", "ART", "ADJA", "ART", "NN", "$.", "VVFIN", "APPR", "NE", "PPER"], "meter": "+--+--+---+--+-+-", "measure": "dactylic.tri.plus"}, "line.54": {"text": "F\u00fchren, von Freya zum Wagen im Hain!", "tokens": ["F\u00fch\u00b7ren", ",", "von", "Frey\u00b7a", "zum", "Wa\u00b7gen", "im", "Hain", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "NE", "APPRART", "NN", "APPRART", "NN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.55": {"text": "Nossa g\u00fcrte sich, f\u00fchre voran die blutigen Wodan,", "tokens": ["Nos\u00b7sa", "g\u00fcr\u00b7te", "sich", ",", "f\u00fch\u00b7re", "vo\u00b7ran", "die", "blu\u00b7ti\u00b7gen", "Wo\u00b7dan", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "$,", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.56": {"text": "Thorr, und Tyr in den Hain!\u00ab", "tokens": ["Thorr", ",", "und", "Tyr", "in", "den", "Hain", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "KON", "NE", "APPR", "ART", "NN", "$.", "$("], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.57": {"text": "Und der J\u00fcngling verschwand; mich aber tr\u00fcbte von neuem", "tokens": ["Und", "der", "J\u00fcng\u00b7ling", "ver\u00b7schwand", ";", "mich", "a\u00b7ber", "tr\u00fcb\u00b7te", "von", "neu\u00b7em"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "$.", "PPER", "ADV", "VVFIN", "APPR", "ADJA"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.58": {"text": "Meine Schwermuth: Dass Krieg", "tokens": ["Mei\u00b7ne", "Schwer\u00b7muth", ":", "Dass", "Krieg"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$.", "KOUS", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.59": {"text": "Seyn muss, ob ihm gleich, dem thierischen Scheusal, das ehmals", "tokens": ["Seyn", "muss", ",", "ob", "ihm", "gleich", ",", "dem", "thie\u00b7ri\u00b7schen", "Scheu\u00b7sal", ",", "das", "eh\u00b7mals"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "KOUS", "PPER", "ADV", "$,", "ART", "ADJA", "NN", "$,", "PRELS", "ADV"], "meter": "-+--+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.60": {"text": "Freye Frankreich Untergang schwur.", "tokens": ["Frey\u00b7e", "Fran\u00b7kreich", "Un\u00b7ter\u00b7gang", "schwur", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}