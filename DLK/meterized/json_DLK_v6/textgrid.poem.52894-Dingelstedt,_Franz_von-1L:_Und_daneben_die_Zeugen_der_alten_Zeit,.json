{"textgrid.poem.52894": {"metadata": {"author": {"name": "Dingelstedt, Franz von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Und daneben die Zeugen der alten Zeit,", "genre": "verse", "period": "N.A.", "pub_year": 1847, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und daneben die Zeugen der alten Zeit,", "tokens": ["Und", "da\u00b7ne\u00b7ben", "die", "Zeu\u00b7gen", "der", "al\u00b7ten", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der r\u00f6misch-deutschen Herrlichkeit,", "tokens": ["Der", "r\u00f6\u00b7mischdeut\u00b7schen", "Herr\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der R\u00f6mer mit seinen Kaiserbildern,", "tokens": ["Der", "R\u00f6\u00b7mer", "mit", "sei\u00b7nen", "Kai\u00b7ser\u00b7bil\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Goldenen Bullen und Wappenschildern!", "tokens": ["Gol\u00b7de\u00b7nen", "Bul\u00b7len", "und", "Wap\u00b7pen\u00b7schil\u00b7dern", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.2": {"line.1": {"text": "Der Platz, den einst mit schwerem Tritt", "tokens": ["Der", "Platz", ",", "den", "einst", "mit", "schwe\u00b7rem", "Tritt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der neugekr\u00f6nte Kaiser beschritt", "tokens": ["Der", "neu\u00b7ge\u00b7kr\u00f6n\u00b7te", "Kai\u00b7ser", "be\u00b7schritt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "\u00dcber scharlachene Decken von Samt,", "tokens": ["\u00dc\u00b7ber", "schar\u00b7la\u00b7che\u00b7ne", "De\u00b7cken", "von", "Samt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "+-+---+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Worauf in Gold der Adler geflammt!", "tokens": ["Wo\u00b7rauf", "in", "Gold", "der", "Ad\u00b7ler", "ge\u00b7flammt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "APPR", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.3": {"line.1": {"text": "Dort fiel der Stier, dort sprang der Wein,", "tokens": ["Dort", "fiel", "der", "Stier", ",", "dort", "sprang", "der", "Wein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dort ri\u00df das Volk die K\u00fcche ein,", "tokens": ["Dort", "ri\u00df", "das", "Volk", "die", "K\u00fc\u00b7che", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und rings ein Dr\u00e4ngen in engen R\u00e4umen", "tokens": ["Und", "rings", "ein", "Dr\u00e4n\u00b7gen", "in", "en\u00b7gen", "R\u00e4u\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Mit Glockengel\u00e4ut und Bechersch\u00e4umen!", "tokens": ["Mit", "Glo\u00b7cken\u00b7ge\u00b7l\u00e4ut", "und", "Be\u00b7cher\u00b7sch\u00e4u\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Beschleicht dich in heutiger N\u00fcchternheit", "tokens": ["Be\u00b7schleicht", "dich", "in", "heu\u00b7ti\u00b7ger", "N\u00fcch\u00b7tern\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Nimmer ein Traum von solcher Zeit?", "tokens": ["Nim\u00b7mer", "ein", "Traum", "von", "sol\u00b7cher", "Zeit", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "PIAT", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Hast du \u00fcber Herbst- und Ostermessen", "tokens": ["Hast", "du", "\u00fc\u00b7ber", "Herbs\u00b7t", "und", "Os\u00b7ter\u00b7mes\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "TRUNC", "KON", "NN"], "meter": "----+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Deiner alten Glorie ganz vergessen?", "tokens": ["Dei\u00b7ner", "al\u00b7ten", "Glo\u00b7rie", "ganz", "ver\u00b7ges\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Dein Strom wird breit, dein Quai wird weit,", "tokens": ["Dein", "Strom", "wird", "breit", ",", "dein", "Qua\u00b7i", "wird", "weit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Deine Stra\u00dfen versch\u00f6nen sich alle Zeit,", "tokens": ["Dei\u00b7ne", "Stra\u00b7\u00dfen", "ver\u00b7sch\u00f6\u00b7nen", "sich", "al\u00b7le", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "PIAT", "NN", "$,"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Und nur dein Herz, dein Volksbewu\u00dftsein", "tokens": ["Und", "nur", "dein", "Herz", ",", "dein", "Volks\u00b7be\u00b7wu\u00df\u00b7tsein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "PPOSAT", "NN", "$,", "PPOSAT", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Schrumpft ein und wird bald v\u00f6llig Verlust sein.", "tokens": ["Schrumpft", "ein", "und", "wird", "bald", "v\u00f6l\u00b7lig", "Ver\u00b7lust", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VAFIN", "ADV", "ADJD", "NN", "VAINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Ermanne dich, deutsche Stadt am Main!", "tokens": ["Er\u00b7man\u00b7ne", "dich", ",", "deut\u00b7sche", "Stadt", "am", "Main", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Du sollst mit unter den ersten sein,", "tokens": ["Du", "sollst", "mit", "un\u00b7ter", "den", "ers\u00b7ten", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "APPR", "ART", "ADJA", "VAINF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Nicht blo\u00df ein Tor, um durchzuwandeln,", "tokens": ["Nicht", "blo\u00df", "ein", "Tor", ",", "um", "durch\u00b7zu\u00b7wan\u00b7deln", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "$,", "KOUI", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht blo\u00df eine Halle zum Kaufen und Handeln.", "tokens": ["Nicht", "blo\u00df", "ei\u00b7ne", "Hal\u00b7le", "zum", "Kau\u00b7fen", "und", "Han\u00b7deln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "APPRART", "NN", "KON", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}, "stanza.7": {"line.1": {"text": "Prozent und Wechsel und Agio,", "tokens": ["Pro\u00b7zent", "und", "Wech\u00b7sel", "und", "A\u00b7gio", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NE", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Das macht ein deutsches Gem\u00fct nicht froh,", "tokens": ["Das", "macht", "ein", "deut\u00b7sches", "Ge\u00b7m\u00fct", "nicht", "froh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und die Juwelen und die Pal\u00e4ste", "tokens": ["Und", "die", "Ju\u00b7we\u00b7len", "und", "die", "Pa\u00b7l\u00e4s\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "KON", "ART", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Sind auch noch nicht von allem das Beste.", "tokens": ["Sind", "auch", "noch", "nicht", "von", "al\u00b7lem", "das", "Bes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PTKNEG", "APPR", "PIS", "ART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Roll hin in deiner Karossen Glanz;", "tokens": ["Roll", "hin", "in", "dei\u00b7ner", "Ka\u00b7ros\u00b7sen", "Glanz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "---+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Du verrollst, verrennst, verrechnest dich ganz;", "tokens": ["Du", "ver\u00b7rollst", ",", "ver\u00b7rennst", ",", "ver\u00b7rech\u00b7nest", "dich", "ganz", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Und bist und bleibst am Ende netto", "tokens": ["Und", "bist", "und", "bleibst", "am", "En\u00b7de", "net\u00b7to"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "KON", "VVFIN", "APPRART", "NN", "NE"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Doch nur unser erstes und letztes Ghetto!", "tokens": ["Doch", "nur", "un\u00b7ser", "ers\u00b7tes", "und", "letz\u00b7tes", "Ghet\u00b7to", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "ADJA", "KON", "ADJA", "NN", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}}}}}