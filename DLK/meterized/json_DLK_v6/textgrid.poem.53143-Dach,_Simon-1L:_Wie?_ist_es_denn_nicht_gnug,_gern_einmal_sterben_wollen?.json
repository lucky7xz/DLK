{"textgrid.poem.53143": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wie? ist es denn nicht gnug, gern einmal sterben wollen?", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie? ist es denn nicht gnug, gern einmal sterben wollen?", "tokens": ["Wie", "?", "ist", "es", "denn", "nicht", "gnug", ",", "gern", "ein\u00b7mal", "ster\u00b7ben", "wol\u00b7len", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VAFIN", "PPER", "ADV", "PTKNEG", "ADV", "$,", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Natur, Verh\u00e4ngn\u00fcs, Gott, wa\u00df haltet ihr mich auff?", "tokens": ["Na\u00b7tur", ",", "Ver\u00b7h\u00e4ng\u00b7n\u00fcs", ",", "Gott", ",", "wa\u00df", "hal\u00b7tet", "ihr", "mich", "auff", "?"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "PWAV", "VVFIN", "PPER", "PRF", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kein S\u00e4umn\u00fcs ist bey mir, vollendet ist mein Lauff,", "tokens": ["Kein", "S\u00e4um\u00b7n\u00fcs", "ist", "bey", "mir", ",", "voll\u00b7en\u00b7det", "ist", "mein", "Lauff", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "APPR", "PPER", "$,", "VVPP", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Soll ich die Durchfahrt euch denn tausentmahl verzollen?", "tokens": ["Soll", "ich", "die", "Durch\u00b7fahrt", "euch", "denn", "tau\u00b7sent\u00b7mahl", "ver\u00b7zol\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wa\u00df kr\u00e4nckt es, fertig seyn vnd sich verweilen sollen!", "tokens": ["Wa\u00df", "kr\u00e4nckt", "es", ",", "fer\u00b7tig", "seyn", "vnd", "sich", "ver\u00b7wei\u00b7len", "sol\u00b7len", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "$,", "ADJD", "VAINF", "KON", "PRF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist Sterben ein Gewinn? o mir ein thewrer Kauff,", "tokens": ["Ist", "Ster\u00b7ben", "ein", "Ge\u00b7winn", "?", "o", "mir", "ein", "thew\u00b7rer", "Kauff", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ART", "NN", "$.", "FM", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mich t\u00f6dten so viel Jahr vnd Kranckheiten zu hauff,", "tokens": ["Mich", "t\u00f6d\u00b7ten", "so", "viel", "Jahr", "vnd", "Kran\u00b7ck\u00b7hei\u00b7ten", "zu", "hauff", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN", "KON", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.4": {"text": "Ich lebe noch vnd bin wol zehnmahl tod erschollen.", "tokens": ["Ich", "le\u00b7be", "noch", "vnd", "bin", "wol", "zehn\u00b7mahl", "tod", "er\u00b7schol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "VAFIN", "ADV", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Weib, Kinder, macht es ihr? Verl\u00e4ngert ihr mein Licht?", "tokens": ["Weib", ",", "Kin\u00b7der", ",", "macht", "es", "ihr", "?", "Ver\u00b7l\u00e4n\u00b7gert", "ihr", "mein", "Licht", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "VVFIN", "PPER", "PPER", "$.", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Seht meinen Jammer an, ist dieses LiebesPflicht,", "tokens": ["Seht", "mei\u00b7nen", "Jam\u00b7mer", "an", ",", "ist", "die\u00b7ses", "Lie\u00b7bes", "Pflicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$,", "VAFIN", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zu schlechtem Vortheil euch mein Vortheil mir nicht g\u00f6nnen?", "tokens": ["Zu", "schlech\u00b7tem", "Vor\u00b7theil", "euch", "mein", "Vor\u00b7theil", "mir", "nicht", "g\u00f6n\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "PPOSAT", "NN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Ach kr\u00e4ncket mich nicht mehr durch ewer Angesicht!", "tokens": ["Ach", "kr\u00e4n\u00b7cket", "mich", "nicht", "mehr", "durch", "e\u00b7wer", "An\u00b7ge\u00b7sicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "PPER", "PTKNEG", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die allerletzte Pein ist, gl\u00e4ub ich, \u00e4rger nicht,", "tokens": ["Die", "al\u00b7ler\u00b7letz\u00b7te", "Pein", "ist", ",", "gl\u00e4ub", "ich", ",", "\u00e4r\u00b7ger", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$,", "VVFIN", "PPER", "$,", "ADJD", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Al\u00df leben m\u00fcssen, todt seyn wollen vnd nicht k\u00f6nnen.", "tokens": ["Al\u00df", "le\u00b7ben", "m\u00fcs\u00b7sen", ",", "todt", "seyn", "wol\u00b7len", "vnd", "nicht", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVINF", "VMINF", "$,", "ADJD", "VAINF", "VMFIN", "KON", "PTKNEG", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}