{"dta.poem.20536": {"metadata": {"author": {"name": "Scheyb, Franz Christoph von", "birth": "N.A.", "death": "N.A."}, "title": "Zweytes Buch.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1746", "urn": "urn:nbn:de:kobv:b4-20536-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ich h\u00f6rte dem Gespr\u00e4ch in stillem Eifer zu;", "tokens": ["Ich", "h\u00f6r\u00b7te", "dem", "Ge\u00b7spr\u00e4ch", "in", "stil\u00b7lem", "Ei\u00b7fer", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch ward mir kaum bekannt, auf was der", "tokens": ["Doch", "ward", "mir", "kaum", "be\u00b7kannt", ",", "auf", "was", "der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADJD", "$,", "APPR", "PRELS", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Grund beruh;", "tokens": ["Grund", "be\u00b7ruh", ";"], "token_info": ["word", "word", "punct"], "pos": ["NN", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "So wandt\u2019 ich mich dahin, wo meine F\u00fchrer waren,", "tokens": ["So", "wandt'", "ich", "mich", "da\u00b7hin", ",", "wo", "mei\u00b7ne", "F\u00fch\u00b7rer", "wa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "PAV", "$,", "PWAV", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Durch ihren Unterricht die Sache zu erfahren.", "tokens": ["Durch", "ih\u00b7ren", "Un\u00b7ter\u00b7richt", "die", "Sa\u00b7che", "zu", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Allein man \u00f6ffnete darzwischen Th\u00fcr und Thor,", "tokens": ["Al\u00b7lein", "man", "\u00f6ff\u00b7ne\u00b7te", "darz\u00b7wi\u00b7schen", "Th\u00fcr", "und", "Thor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "PAV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und jemand trat zugleich aus andern Zimmern vor,", "tokens": ["Und", "je\u00b7mand", "trat", "zu\u00b7gleich", "aus", "an\u00b7dern", "Zim\u00b7mern", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der mit Bezeigungen verschiedner H\u00f6flichkeiten", "tokens": ["Der", "mit", "Be\u00b7zei\u00b7gun\u00b7gen", "ver\u00b7schied\u00b7ner", "H\u00f6f\u00b7lich\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Zu wissen gab, da\u00df er uns soll hinein begleiten", "tokens": ["Zu", "wis\u00b7sen", "gab", ",", "da\u00df", "er", "uns", "soll", "hin\u00b7ein", "be\u00b7glei\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "VVFIN", "$,", "KOUS", "PPER", "PPER", "VMFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Welch\u2019 unverhoffte Pracht! ein hell bele\u00fcchter Saal!", "tokens": ["Welch'", "un\u00b7ver\u00b7hoff\u00b7te", "Pracht", "!", "ein", "hell", "be\u00b7le\u00fcch\u00b7ter", "Saal", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$.", "ART", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "10Ich gieng der Wahrheit nach, der ich mich anbefahl,", "tokens": ["gieng", "der", "Wahr\u00b7heit", "nach", ",", "der", "ich", "mich", "an\u00b7be\u00b7fahl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$,", "PRELS", "PPER", "PRF", "ADV", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.12": {"text": "Damit ich, was gesch\u00e4h, durch sie verstehen k\u00f6nnte,", "tokens": ["Da\u00b7mit", "ich", ",", "was", "ge\u00b7sch\u00e4h", ",", "durch", "sie", "ver\u00b7ste\u00b7hen", "k\u00f6nn\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PRELS", "ADJD", "$,", "APPR", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wann die Willf\u00e4hrigkeit derselben es verg\u00f6nnte.", "tokens": ["Wann", "die", "Will\u00b7f\u00e4h\u00b7rig\u00b7keit", "der\u00b7sel\u00b7ben", "es", "ver\u00b7g\u00f6nn\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PDAT", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Mein Auge war so sehr geblendet und bestrickt,", "tokens": ["Mein", "Au\u00b7ge", "war", "so", "sehr", "ge\u00b7blen\u00b7det", "und", "be\u00b7strickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADV", "VVPP", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Da\u00df es die Menge nur unachtsam \u00fcberblickt;", "tokens": ["Da\u00df", "es", "die", "Men\u00b7ge", "nur", "u\u00b7nacht\u00b7sam", "\u00fc\u00b7berb\u00b7lickt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "15Ich sah in dem Bezirck noch Anfang weder Ende,", "tokens": ["sah", "in", "dem", "Be\u00b7zirck", "noch", "An\u00b7fang", "we\u00b7der", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ADV", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.17": {"text": "Als h\u00e4tte das Geb\u00e4u noch Umkrei\u00df weder W\u00e4nde:", "tokens": ["Als", "h\u00e4t\u00b7te", "das", "Ge\u00b7b\u00e4u", "noch", "Um\u00b7krei\u00df", "we\u00b7der", "W\u00e4n\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ART", "NN", "ADV", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Es gl\u00e4ntzete die Luft von schimmerndem Crystall,", "tokens": ["Es", "gl\u00e4nt\u00b7ze\u00b7te", "die", "Luft", "von", "schim\u00b7mern\u00b7dem", "Crys\u00b7tall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Gold, Marmel, Farb\u2019 und Flamm erf\u00fcllten \u00fcberall", "tokens": ["Gold", ",", "Mar\u00b7mel", ",", "Fa\u00b7rb'", "und", "Flamm", "er\u00b7f\u00fcll\u00b7ten", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NE", "VVFIN", "ADV"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Den K\u00f6niglichen Saal; die unz\u00e4hlbaren Lichter", "tokens": ["Den", "K\u00f6\u00b7nig\u00b7li\u00b7chen", "Saal", ";", "die", "un\u00b7z\u00e4hl\u00b7ba\u00b7ren", "Lich\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "20Erhoben die Gestalt und Sch\u00f6nheit der Gesichter,", "tokens": ["die", "Ge\u00b7stalt", "und", "Sch\u00f6n\u00b7heit", "der", "Ge\u00b7sich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.22": {"text": "Die man in dem Gedr\u00e4ng\u2019 in dem Get\u00f6\u00df der Stadt", "tokens": ["Die", "man", "in", "dem", "Ge\u00b7dr\u00e4ng'", "in", "dem", "Ge\u00b7t\u00f6\u00df", "der", "Stadt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "APPR", "ART", "NN", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Bey der Vielf\u00e4ltigkeit nicht wahrgenommen hat:", "tokens": ["Bey", "der", "Viel\u00b7f\u00e4l\u00b7tig\u00b7keit", "nicht", "wahr\u00b7ge\u00b7nom\u00b7men", "hat", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKNEG", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Der Spiegel Gegen-Schein und unergr\u00fcndtes Spielen", "tokens": ["Der", "Spie\u00b7gel", "Ge\u00b7gen\u00b7Schein", "und", "un\u00b7er\u00b7gr\u00fcnd\u00b7tes", "Spie\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "War Ursach, da\u00df sie mir vermehrt ins Auge fielen;", "tokens": ["War", "Ur\u00b7sach", ",", "da\u00df", "sie", "mir", "ver\u00b7mehrt", "ins", "Au\u00b7ge", "fie\u00b7len", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "KOUS", "PPER", "PPER", "ADJD", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "25Der Hin- und Wieder-Schein der Tracht und der Gestalt,", "tokens": ["Hin", "und", "Wie\u00b7der\u00b7Schein", "der", "Tracht", "und", "der", "Ge\u00b7stalt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "NN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.27": {"text": "Der unermessne Glantz, die blendende Gewalt", "tokens": ["Der", "un\u00b7er\u00b7mess\u00b7ne", "Glantz", ",", "die", "blen\u00b7den\u00b7de", "Ge\u00b7walt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Bezauberte das Aug, entz\u00fcckte Geist und Sinnen,", "tokens": ["Be\u00b7zau\u00b7ber\u00b7te", "das", "Aug", ",", "ent\u00b7z\u00fcck\u00b7te", "Geist", "und", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Als s\u00e4he man ein Heer gekr\u00f6nter K\u00f6niginnen.", "tokens": ["Als", "s\u00e4\u00b7he", "man", "ein", "Heer", "ge\u00b7kr\u00f6n\u00b7ter", "K\u00f6\u00b7ni\u00b7gin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PIS", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Lust, Kummer, Fre\u00fcd und Sorg, Angst, Ehrforcht und Begier", "tokens": ["Lust", ",", "Kum\u00b7mer", ",", "Fre\u00fcd", "und", "Sorg", ",", "Angst", ",", "Ehr\u00b7forcht", "und", "Be\u00b7gier"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.31": {"text": "30Beklemmten meine Brust und rissen mich von mir.", "tokens": ["mei\u00b7ne", "Brust", "und", "ris\u00b7sen", "mich", "von", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "VVFIN", "PRF", "APPR", "PPER", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Hilff Fre\u00fcndinn! fuhr ich auf: hilff alles di\u00df zu mercken!", "tokens": ["Hilff", "Fre\u00fcn\u00b7dinn", "!", "fuhr", "ich", "auf", ":", "hilff", "al\u00b7les", "di\u00df", "zu", "mer\u00b7cken", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "VVFIN", "PPER", "PTKVZ", "$.", "VVFIN", "PIS", "PDS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mein Sinn verliehret sich in diesen Wunderwercken;", "tokens": ["Mein", "Sinn", "ver\u00b7lieh\u00b7ret", "sich", "in", "die\u00b7sen", "Wun\u00b7der\u00b7wer\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Menge war zu gro\u00df: Was aller K\u00fcnste Macht,", "tokens": ["Die", "Men\u00b7ge", "war", "zu", "gro\u00df", ":", "Was", "al\u00b7ler", "K\u00fcns\u00b7te", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKA", "ADJD", "$.", "PWS", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Geist, Feuer, Wohlgeschmack bi\u00df jetzt hervor gebracht,", "tokens": ["Geist", ",", "Feu\u00b7er", ",", "Wohl\u00b7ge\u00b7schmack", "bi\u00df", "jetzt", "her\u00b7vor", "ge\u00b7bracht", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "APPR", "ADV", "PTKVZ", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "35Das stund um uns herum; was je die Pracht verschwendet,", "tokens": ["stund", "um", "uns", "he\u00b7rum", ";", "was", "je", "die", "Pracht", "ver\u00b7schwen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "PTKVZ", "$.", "PWS", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "War zur Verwunderung der Kunst hier angewendet:", "tokens": ["War", "zur", "Ver\u00b7wun\u00b7de\u00b7rung", "der", "Kunst", "hier", "an\u00b7ge\u00b7wen\u00b7det", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Des Haupt-Orts Majest\u00e4t war ein erhobner Thron,", "tokens": ["Des", "Haup\u00b7tOrts", "Ma\u00b7jes\u00b7t\u00e4t", "war", "ein", "er\u00b7hob\u00b7ner", "Thron", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den Palmen, Lorber-Zweig, Oehl-Reiser, Zepter, Kron,", "tokens": ["Den", "Pal\u00b7men", ",", "Lor\u00b7ber\u00b7Zweig", ",", "O\u00b7ehl\u00b7Rei\u00b7ser", ",", "Zep\u00b7ter", ",", "Kron", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "NE", "$,", "NE", "$,", "NN", "$,", "NE", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Reichs-Aepfel, Kriegs-Ger\u00e4th und Friedens-Sch\u00e4tz\u2019 umrungen,", "tokens": ["Reichs\u00b7Ae\u00b7pfel", ",", "Kriegs\u00b7Ge\u00b7r\u00e4th", "und", "Frie\u00b7dens\u00b7Sch\u00e4tz'", "um\u00b7run\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "40Die auf das herrlichste sich in einander schlungen.", "tokens": ["auf", "das", "herr\u00b7lichs\u00b7te", "sich", "in", "ein\u00b7an\u00b7der", "schlun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "PRF", "APPR", "PRF", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.3": {"line.1": {"text": "Die meisten von der Schaar erw\u00e4hlten nach und nach", "tokens": ["Die", "meis\u00b7ten", "von", "der", "Schaar", "er\u00b7w\u00e4hl\u00b7ten", "nach", "und", "nach"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "APPR", "ART", "NN", "VVFIN", "APPR", "KON", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In Ordnung einen Platz, und setzten sich gemach", "tokens": ["In", "Ord\u00b7nung", "ei\u00b7nen", "Platz", ",", "und", "setz\u00b7ten", "sich", "ge\u00b7mach"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ART", "NN", "$,", "KON", "VVFIN", "PRF", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "In einen Krei\u00df herum, dem alle die Matronen,", "tokens": ["In", "ei\u00b7nen", "Krei\u00df", "he\u00b7rum", ",", "dem", "al\u00b7le", "die", "Mat\u00b7ro\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$,", "PRELS", "PIS", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die wir vorher gekannt, begunnten beyzuwohnen;", "tokens": ["Die", "wir", "vor\u00b7her", "ge\u00b7kannt", ",", "be\u00b7gunn\u00b7ten", "bey\u00b7zu\u00b7woh\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVPP", "$,", "VVFIN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "45Als w\u00e4r ein hoher Rath von gr\u00f6ster Wichtigkeit,", "tokens": ["w\u00e4r", "ein", "ho\u00b7her", "Rath", "von", "gr\u00f6s\u00b7ter", "Wich\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.6": {"text": "Und die Zusammenkunft zu solchem Ziel bereit.", "tokens": ["Und", "die", "Zu\u00b7sam\u00b7men\u00b7kunft", "zu", "sol\u00b7chem", "Ziel", "be\u00b7reit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PIAT", "NN", "ADJD", "$."], "meter": "-----+-+-+-+", "measure": "unknown.measure.tetra"}}, "stanza.4": {"line.1": {"text": "Was unbeschreiblicher rund eingetheilter Schimmer", "tokens": ["Was", "un\u00b7be\u00b7schreib\u00b7li\u00b7cher", "rund", "ein\u00b7ge\u00b7theil\u00b7ter", "Schim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADJD", "ADJD", "ADJA", "NN"], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Entsprung in diesem Platz von diesem Frauen-Zimmer!", "tokens": ["Ent\u00b7sprung", "in", "die\u00b7sem", "Platz", "von", "die\u00b7sem", "Frau\u00b7en\u00b7Zim\u00b7mer", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDAT", "NN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Trachten hell Gepr\u00e4ng, des Schmucks befe\u00fcrter Schein", "tokens": ["Der", "Trach\u00b7ten", "hell", "Ge\u00b7pr\u00e4ng", ",", "des", "Schmucks", "be\u00b7fe\u00b7\u00fcr\u00b7ter", "Schein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "NN", "$,", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "50Pr\u00e4gt' jedem Auge Lust, Verwundrung, Ehrfurcht ein;", "tokens": ["'", "je\u00b7dem", "Au\u00b7ge", "Lust", ",", "Ver\u00b7wund\u00b7rung", ",", "Ehr\u00b7furcht", "ein", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PIAT", "NN", "NN", "$,", "NN", "$,", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mit gr\u00f6ssrer Klarheit kann der sch\u00f6nste Tag nicht prangen,", "tokens": ["Mit", "gr\u00f6ss\u00b7rer", "Klar\u00b7heit", "kann", "der", "sch\u00f6ns\u00b7te", "Tag", "nicht", "pran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "ART", "ADJA", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Als jene, welche da den edlen Krei\u00df umfangen.", "tokens": ["Als", "je\u00b7ne", ",", "wel\u00b7che", "da", "den", "ed\u00b7len", "Krei\u00df", "um\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "$,", "PRELS", "ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dem reichen Kleider-Stoff, der sich je mehr geziert,", "tokens": ["Dem", "rei\u00b7chen", "Klei\u00b7der\u00b7Stoff", ",", "der", "sich", "je", "mehr", "ge\u00b7ziert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PRF", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Je mehr der Falten-Wall sich hin und her ger\u00fchrt;", "tokens": ["Je", "mehr", "der", "Fal\u00b7ten\u00b7Wall", "sich", "hin", "und", "her", "ge\u00b7r\u00fchrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "PRF", "PTKVZ", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "55Der Edelsteine Blitz, der in den Haaren steckte;", "tokens": ["E\u00b7del\u00b7stei\u00b7ne", "Blitz", ",", "der", "in", "den", "Haa\u00b7ren", "steck\u00b7te", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.10": {"text": "Der Farben Lieblichkeit, womit man sich bedeckte;", "tokens": ["Der", "Far\u00b7ben", "Lieb\u00b7lich\u00b7keit", ",", "wo\u00b7mit", "man", "sich", "be\u00b7deck\u00b7te", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PWAV", "PIS", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Dem Himmel-blauen Ze\u00fcg, der durch das Silber brach,", "tokens": ["Dem", "Him\u00b7mel\u00b7blau\u00b7en", "Ze\u00fcg", ",", "der", "durch", "das", "Sil\u00b7ber", "brach", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und sich in Gold verbarg, gieng zwar mein Vorwitz nach;", "tokens": ["Und", "sich", "in", "Gold", "ver\u00b7barg", ",", "gieng", "zwar", "mein", "Vor\u00b7witz", "nach", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "NN", "VVFIN", "$,", "VVFIN", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "60Doch weder di\u00df, noch was ich sonst erhobnes sp\u00fchrte,", "tokens": ["we\u00b7der", "di\u00df", ",", "noch", "was", "ich", "sonst", "er\u00b7hob\u00b7nes", "sp\u00fchr\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "$,", "KON", "PWS", "PPER", "ADV", "ADJA", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.14": {"text": "War jenes so das Hertz am allermeisten r\u00fchrte:", "tokens": ["War", "je\u00b7nes", "so", "das", "Hertz", "am", "al\u00b7ler\u00b7meis\u00b7ten", "r\u00fchr\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ADV", "ART", "NN", "APPRART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Das Ansehn der Gestalt; die Sch\u00f6nheit des Gesichts,", "tokens": ["Das", "An\u00b7sehn", "der", "Ge\u00b7stalt", ";", "die", "Sch\u00f6n\u00b7heit", "des", "Ge\u00b7sichts", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$.", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Der Fe\u00fcerreiche Blick war reitzend, sonsten nichts.", "tokens": ["Der", "Fe\u00b7\u00fcer\u00b7rei\u00b7che", "Blick", "war", "reit\u00b7zend", ",", "sons\u00b7ten", "nichts", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "VVPP", "$,", "VVFIN", "PIS", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Der Mienen Zauber-Art; das Prangen der Geb\u00e4rden", "tokens": ["Der", "Mie\u00b7nen", "Zau\u00b7ber\u00b7Art", ";", "das", "Pran\u00b7gen", "der", "Ge\u00b7b\u00e4r\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$.", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "65War was mit h\u00f6chster Lust must' angesehen werden:", "tokens": ["was", "mit", "h\u00f6chs\u00b7ter", "Lust", "must'", "an\u00b7ge\u00b7se\u00b7hen", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ADJA", "NN", "VMFIN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.19": {"text": "Der Augen Freundlichkeit; der Wangen Farben Reitz;", "tokens": ["Der", "Au\u00b7gen", "Freund\u00b7lich\u00b7keit", ";", "der", "Wan\u00b7gen", "Far\u00b7ben", "Reitz", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$.", "ART", "NN", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Der l\u00e4chlend-holde Mund, der sich hier allerseits", "tokens": ["Der", "l\u00e4chlen\u00b7dhol\u00b7de", "Mund", ",", "der", "sich", "hier", "al\u00b7ler\u00b7seits"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PRF", "ADV", "ADV"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.21": {"text": "Mit schmeichelhaftem Ernst und muntrer Anmuth zierte,", "tokens": ["Mit", "schmei\u00b7chel\u00b7haf\u00b7tem", "Ernst", "und", "mun\u00b7trer", "An\u00b7muth", "zier\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "War, was das Aug in Freud\u2019 und in Erstaunung f\u00fchrte.", "tokens": ["War", ",", "was", "das", "Aug", "in", "Freud'", "und", "in", "Er\u00b7stau\u00b7nung", "f\u00fchr\u00b7te", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PRELS", "ART", "NN", "APPR", "NN", "KON", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Je mehr sich nach und nach die Sch\u00e4tze vorgebracht,", "tokens": ["Je", "mehr", "sich", "nach", "und", "nach", "die", "Sch\u00e4t\u00b7ze", "vor\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PRF", "APPR", "KON", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Je weniger war ich in Sonderheit bedacht", "tokens": ["Je", "we\u00b7ni\u00b7ger", "war", "ich", "in", "Son\u00b7der\u00b7heit", "be\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "APPR", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Di\u00df oder das zu sehen; Die Menge dieser Frauen", "tokens": ["Di\u00df", "o\u00b7der", "das", "zu", "se\u00b7hen", ";", "Die", "Men\u00b7ge", "die\u00b7ser", "Frau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "KON", "PDS", "PTKZU", "VVINF", "$.", "ART", "NN", "PDAT", "NN"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Lie\u00df meiner Seh-Begier nichts nach der Ordnung schauen.", "tokens": ["Lie\u00df", "mei\u00b7ner", "Seh\u00b7Be\u00b7gier", "nichts", "nach", "der", "Ord\u00b7nung", "schau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PIS", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wahr ist es, da\u00df ich oft um Unterricht gefragt,", "tokens": ["Wahr", "ist", "es", ",", "da\u00df", "ich", "oft", "um", "Un\u00b7ter\u00b7richt", "ge\u00b7fragt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "75Da\u00df mir die Wahrheit auch oft was ins Ohr gesagt;", "tokens": ["mir", "die", "Wahr\u00b7heit", "auch", "oft", "was", "ins", "Ohr", "ge\u00b7sagt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "ADV", "ADV", "PWS", "APPRART", "NN", "VVPP", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.7": {"text": "Allein was halff es mich, die Antwort aus zu warten,", "tokens": ["Al\u00b7lein", "was", "halff", "es", "mich", ",", "die", "Ant\u00b7wort", "aus", "zu", "war\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VVFIN", "PPER", "PRF", "$,", "ART", "NN", "APZR", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da Witz und Aug\u2019 und Ohr erstaunt, entz\u00fcckt, erstarrten?", "tokens": ["Da", "Witz", "und", "Aug'", "und", "Ohr", "er\u00b7staunt", ",", "ent\u00b7z\u00fcckt", ",", "er\u00b7starr\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "KON", "NN", "VVPP", "$,", "VVPP", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Di\u00df war mir endlich ne\u00fc: es stund ein J\u00fcngling da,", "tokens": ["Di\u00df", "war", "mir", "end\u00b7lich", "ne\u00fc", ":", "es", "stund", "ein", "J\u00fcng\u00b7ling", "da", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "NE", "$.", "PPER", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der, gleich als such\u2019 er was, nach allen Seiten sah,", "tokens": ["Der", ",", "gleich", "als", "such'", "er", "was", ",", "nach", "al\u00b7len", "Sei\u00b7ten", "sah", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADV", "KOKOM", "VVFIN", "PPER", "PIS", "$,", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "80Und der Matronen Blick vorz\u00fcglich an sich risse,", "tokens": ["der", "Mat\u00b7ro\u00b7nen", "Blick", "vor\u00b7z\u00fcg\u00b7lich", "an", "sich", "ris\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "APPR", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Wie wann er zu dem Rath den Anfang machen m\u00fcsse.", "tokens": ["Wie", "wann", "er", "zu", "dem", "Rath", "den", "An\u00b7fang", "ma\u00b7chen", "m\u00fcs\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PWAV", "PPER", "APPR", "ART", "NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nachdem auch jedes Aug im Saal und in dem Krei\u00df,", "tokens": ["Nach\u00b7dem", "auch", "je\u00b7des", "Aug", "im", "Saal", "und", "in", "dem", "Krei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIAT", "NN", "APPRART", "NN", "KON", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Auf ihn gerichtet war, sprach er auf diese Wei\u00df:", "tokens": ["Auf", "ihn", "ge\u00b7rich\u00b7tet", "war", ",", "sprach", "er", "auf", "die\u00b7se", "Wei\u00df", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "VAFIN", "$,", "VVFIN", "PPER", "APPR", "PDAT", "NN", "$."], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.7": {"text": "\u201efreundinnen! euch ist ja der Vorsatz unverborgen,", "tokens": ["\u201e", "freun\u00b7din\u00b7nen", "!", "euch", "ist", "ja", "der", "Vor\u00b7satz", "un\u00b7ver\u00b7bor\u00b7gen", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVINF", "$.", "PPER", "VAFIN", "ADV", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "85\u201dMit dem wir diese Nacht zur Absicht unsrer Sorgen", "tokens": ["\"", "Mit", "dem", "wir", "die\u00b7se", "Nacht", "zur", "Ab\u00b7sicht", "uns\u00b7rer", "Sor\u00b7gen"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "APPR", "PRELS", "PPER", "PDAT", "NN", "APPRART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201egemeinsam auserw\u00e4hlt? Indem er also sprach,", "tokens": ["\u201e", "ge\u00b7mein\u00b7sam", "au\u00b7ser\u00b7w\u00e4hlt", "?", "In\u00b7dem", "er", "al\u00b7so", "sprach", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VVPP", "$.", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Warf er den Augenwinck fast allen Reihen nach,", "tokens": ["Warf", "er", "den", "Au\u00b7gen\u00b7winck", "fast", "al\u00b7len", "Rei\u00b7hen", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "PIAT", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.11": {"text": "Blieb still, wie wann er sich erst noch besinnen wollte,", "tokens": ["Blieb", "still", ",", "wie", "wann", "er", "sich", "erst", "noch", "be\u00b7sin\u00b7nen", "woll\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "PWAV", "PWAV", "PPER", "PRF", "ADV", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Was ihm zu reden w\u00e4r; ob er nicht schweigen sollte:", "tokens": ["Was", "ihm", "zu", "re\u00b7den", "w\u00e4r", ";", "ob", "er", "nicht", "schwei\u00b7gen", "soll\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKZU", "VVINF", "VAFIN", "$.", "KOUS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "90Doch fuhr er endlich fort: \u201dJa schreiten wir zum Werck!", "tokens": ["fuhr", "er", "end\u00b7lich", "fort", ":", "\"", "Ja", "schrei\u00b7ten", "wir", "zum", "Werck", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKVZ", "$.", "$(", "PTKANT", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.14": {"text": "\u201edie grosse K\u00f6niginn ist unser Augenmerck;", "tokens": ["\u201e", "die", "gros\u00b7se", "K\u00f6\u00b7ni\u00b7ginn", "ist", "un\u00b7ser", "Au\u00b7gen\u00b7merck", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "\u201ejhr Wort ist unser Schlu\u00df und unser Spruch ihr Wollen,", "tokens": ["\u201e", "jhr", "Wort", "ist", "un\u00b7ser", "Schlu\u00df", "und", "un\u00b7ser", "Spruch", "ihr", "Wol\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "\u201ewas sie befielt, das ist, was wir ihr rathen sollen:", "tokens": ["\u201e", "was", "sie", "be\u00b7fielt", ",", "das", "ist", ",", "was", "wir", "ihr", "ra\u00b7then", "sol\u00b7len", ":"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "PPER", "VVFIN", "$,", "PDS", "VAFIN", "$,", "PRELS", "PPER", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "\u201ewir folgen ihr, sie uns; sie stimmt in allem ein,", "tokens": ["\u201e", "wir", "fol\u00b7gen", "ihr", ",", "sie", "uns", ";", "sie", "stimmt", "in", "al\u00b7lem", "ein", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "$,", "PPER", "PPER", "$.", "PPER", "VVFIN", "APPR", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "95\u201dWas je von uns f\u00fcr sie mag ausgesonnen seyn.", "tokens": ["\"", "Was", "je", "von", "uns", "f\u00fcr", "sie", "mag", "aus\u00b7ge\u00b7son\u00b7nen", "seyn", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "ADV", "APPR", "PPER", "APPR", "PPER", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "\u201eman wei\u00df, was sie durch uns, und wir durch sie vollzogen;", "tokens": ["\u201e", "man", "wei\u00df", ",", "was", "sie", "durch", "uns", ",", "und", "wir", "durch", "sie", "voll\u00b7zo\u00b7gen", ";"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VVFIN", "$,", "PRELS", "PPER", "APPR", "PPER", "$,", "KON", "PPER", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "\u201ees ist mit ihrem Ruhm die Welt schon durchgeflogen.", "tokens": ["\u201e", "es", "ist", "mit", "ih\u00b7rem", "Ruhm", "die", "Welt", "schon", "durch\u00b7ge\u00b7flo\u00b7gen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "APPR", "PPOSAT", "NN", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Hier regte sich die Frau, so dort mit uns geschwebt,", "tokens": ["Hier", "reg\u00b7te", "sich", "die", "Frau", ",", "so", "dort", "mit", "uns", "ge\u00b7schwebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "$,", "ADV", "ADV", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und sprach: \u201eJa zweifelt nicht! Was auf der Erde lebt", "tokens": ["Und", "sprach", ":", "\u201e", "Ja", "zwei\u00b7felt", "nicht", "!", "Was", "auf", "der", "Er\u00b7de", "lebt"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$.", "$(", "PTKANT", "VVFIN", "PTKNEG", "$.", "PWS", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "100\u201dIst von derselben Ruhm und Gr\u00f6sse so belehret,", "tokens": ["\"", "Ist", "von", "der\u00b7sel\u00b7ben", "Ruhm", "und", "Gr\u00f6s\u00b7se", "so", "be\u00b7leh\u00b7ret", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "APPR", "PDAT", "NN", "KON", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201eda\u00df auch die Mi\u00dfgunst sie, doch heimlich z\u00fcrnend, ehret.", "tokens": ["\u201e", "da\u00df", "auch", "die", "Mi\u00df\u00b7gunst", "sie", ",", "doch", "heim\u00b7lich", "z\u00fcr\u00b7nend", ",", "eh\u00b7ret", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "KOUS", "ADV", "ART", "NN", "PPER", "$,", "ADV", "ADJD", "VVPP", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201eso lang ich flieg\u2019 hab ich die M\u00fche nicht gehabt", "tokens": ["\u201e", "so", "lang", "ich", "flieg'", "hab", "ich", "die", "M\u00fc\u00b7he", "nicht", "ge\u00b7habt"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "ADJD", "PPER", "VVFIN", "VAFIN", "PPER", "ART", "NN", "PTKNEG", "VAPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201eals seit der Himmel sie mit Kronen hat begabt.", "tokens": ["\u201e", "als", "seit", "der", "Him\u00b7mel", "sie", "mit", "Kro\u00b7nen", "hat", "be\u00b7gabt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "APPR", "ART", "NN", "PPER", "APPR", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201eso\u201e, fuhr der J\u00fcngling fort, So wirst du mir gestehen,", "tokens": ["\u201e", "so", "\u201e", ",", "fuhr", "der", "J\u00fcng\u00b7ling", "fort", ",", "So", "wirst", "du", "mir", "ge\u00b7ste\u00b7hen", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$(", "$,", "VVFIN", "ART", "NN", "PTKVZ", "$,", "ADV", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "105\u201dDa\u00df es die gantze Welt geh\u00f6ret und gesehen?", "tokens": ["\"", "Da\u00df", "es", "die", "gant\u00b7ze", "Welt", "ge\u00b7h\u00f6\u00b7ret", "und", "ge\u00b7se\u00b7hen", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "110\u201dMan frage Sud und Ost, man h\u00f6re Nord und West,", "tokens": ["\"", "Man", "fra\u00b7ge", "Sud", "und", "Ost", ",", "man", "h\u00f6\u00b7re", "Nord", "und", "West", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VVFIN", "NE", "KON", "NN", "$,", "PIS", "VVFIN", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u201eob man nicht dort so gar ihr Sa\u00fclen bauen l\u00e4\u00dft.", "tokens": ["\u201e", "ob", "man", "nicht", "dort", "so", "gar", "ihr", "Sa\u00fc\u00b7len", "bau\u00b7en", "l\u00e4\u00dft", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PIS", "PTKNEG", "ADV", "ADV", "ADV", "PPOSAT", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u201eich wundere mich nicht: dann wann ich es erwege,", "tokens": ["\u201e", "ich", "wun\u00b7de\u00b7re", "mich", "nicht", ":", "dann", "wann", "ich", "es", "er\u00b7we\u00b7ge", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "PTKNEG", "$.", "ADV", "PWAV", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u201eder Menschen Wanderschaft und Reisen \u00fcberlege,", "tokens": ["\u201e", "der", "Men\u00b7schen", "Wan\u00b7der\u00b7schaft", "und", "Rei\u00b7sen", "\u00fc\u00b7berl\u00b7e\u00b7ge", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "\u201eauf welchen sie dem Meer, der ungest\u00fcmen See,", "tokens": ["\u201e", "auf", "wel\u00b7chen", "sie", "dem", "Meer", ",", "der", "un\u00b7ge\u00b7st\u00fc\u00b7men", "See", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PWAT", "PPER", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "115\u201dDes Winters Wuth und Frost, dem Regen, Reif und Schnee", "tokens": ["\"", "Des", "Win\u00b7ters", "Wuth", "und", "Frost", ",", "dem", "Re\u00b7gen", ",", "Reif", "und", "Schnee"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ART", "NN", "NN", "KON", "NN", "$,", "ART", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "\u201ein dem ergrimmten Schaum der ungetreuen Wellen", "tokens": ["\u201e", "in", "dem", "er\u00b7grimm\u00b7ten", "Schaum", "der", "un\u00b7ge\u00b7treu\u00b7en", "Wel\u00b7len"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "\u201eder Winde Raserey sich pflegen blo\u00df zu stellen;", "tokens": ["\u201e", "der", "Win\u00b7de", "Ra\u00b7se\u00b7rey", "sich", "pfle\u00b7gen", "blo\u00df", "zu", "stel\u00b7len", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "NN", "PRF", "VVFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "\u201eda\u00df sie den goldnen Saft, den die Natur erzeugt,", "tokens": ["\u201e", "da\u00df", "sie", "den", "gold\u00b7nen", "Saft", ",", "den", "die", "Na\u00b7tur", "er\u00b7zeugt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ART", "ADJA", "NN", "$,", "PRELS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "\u201eund meistentheils damit den tapfern Krieger seugt;", "tokens": ["\u201e", "und", "meis\u00b7ten\u00b7theils", "da\u00b7mit", "den", "tap\u00b7fern", "Krie\u00b7ger", "seugt", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ADV", "PAV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "120\u201dDurch Schwei\u00df, den sie dadurch aus allen Gliedern pressen,", "tokens": ["\"", "Durch", "Schwei\u00df", ",", "den", "sie", "da\u00b7durch", "aus", "al\u00b7len", "Glie\u00b7dern", "pres\u00b7sen", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "$,", "PRELS", "PPER", "PAV", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "\u201ein unser Schatz-Gemach, in unsre Kasten fl\u00f6ssen:", "tokens": ["\u201e", "in", "un\u00b7ser", "Schatz\u00b7Ge\u00b7mach", ",", "in", "uns\u00b7re", "Kas\u00b7ten", "fl\u00f6s\u00b7sen", ":"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPOSAT", "NN", "$,", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "\u201edamit sie nur, sag\u2019 ich, von dem entlegnen Land", "tokens": ["\u201e", "da\u00b7mit", "sie", "nur", ",", "sag'", "ich", ",", "von", "dem", "ent\u00b7leg\u00b7nen", "Land"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "KOUS", "PPER", "ADV", "$,", "VVFIN", "PPER", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.22": {"text": "\u201eder Erden the\u00fcrstes Marck in Stuffen oder Sand", "tokens": ["\u201e", "der", "Er\u00b7den", "the\u00fcrs\u00b7tes", "Marck", "in", "Stuf\u00b7fen", "o\u00b7der", "Sand"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "ADJA", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "\u201eaus der vertiefften Nacht derselben Schachten zwingen,", "tokens": ["\u201e", "aus", "der", "ver\u00b7tieff\u00b7ten", "Nacht", "der\u00b7sel\u00b7ben", "Schach\u00b7ten", "zwin\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "ADJA", "NN", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "125\u201dUnd zum Behuf des Amts, so wir begleiten, bringen;", "tokens": ["\"", "Und", "zum", "Be\u00b7huf", "des", "Amts", ",", "so", "wir", "be\u00b7glei\u00b7ten", ",", "brin\u00b7gen", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "KON", "APPRART", "NN", "ART", "NN", "$,", "ADV", "PPER", "VVFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "\u201eso zeiget sich von selbst, da\u00df unsre K\u00f6niginn", "tokens": ["\u201e", "so", "zei\u00b7get", "sich", "von", "selbst", ",", "da\u00df", "uns\u00b7re", "K\u00f6\u00b7ni\u00b7ginn"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ADV", "VVFIN", "PRF", "APPR", "ADV", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "\u201eauch dort ger\u00fchmet sey, wohin die V\u00f6lcker ziehn.", "tokens": ["\u201e", "auch", "dort", "ge\u00b7r\u00fch\u00b7met", "sey", ",", "wo\u00b7hin", "die", "V\u00f6l\u00b7cker", "ziehn", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "VVPP", "VAFIN", "$,", "PWAV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "\u201ewer wird dahero nicht mit Fug und Recht bekennen,", "tokens": ["\u201e", "wer", "wird", "da\u00b7he\u00b7ro", "nicht", "mit", "Fug", "und", "Recht", "be\u00b7ken\u00b7nen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "PAV", "PTKNEG", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "\u201eda\u00df ich in diesem Fall die gantze Welt mu\u00df nennen,", "tokens": ["\u201e", "da\u00df", "ich", "in", "die\u00b7sem", "Fall", "die", "gant\u00b7ze", "Welt", "mu\u00df", "nen\u00b7nen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "APPR", "PDAT", "NN", "ART", "ADJA", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "130'\u201dSo mehr, als jeder Theil an ihr die Tugend liebt", "tokens": ["'", "\"", "So", "mehr", ",", "als", "je\u00b7der", "Theil", "an", "ihr", "die", "Tu\u00b7gend", "liebt"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "$(", "ADV", "ADV", "$,", "KOUS", "PIAT", "NN", "APPR", "PPER", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.30": {"text": "\u201eund dessentwegen ihr zum Kampf die Kr\u00e4ffte gibt,", "tokens": ["\u201e", "und", "des\u00b7sent\u00b7we\u00b7gen", "ihr", "zum", "Kampf", "die", "Kr\u00e4ff\u00b7te", "gibt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PAV", "PPER", "APPRART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "\u201eweil aus den Tugenden nicht alles hergeflossen,", "tokens": ["\u201e", "weil", "aus", "den", "Tu\u00b7gen\u00b7den", "nicht", "al\u00b7les", "her\u00b7ge\u00b7flos\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "APPR", "ART", "NN", "PTKNEG", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "\u201ewas GOtt durch sie der Welt zu zeigen hat beschlossen.", "tokens": ["\u201e", "was", "Gott", "durch", "sie", "der", "Welt", "zu", "zei\u00b7gen", "hat", "be\u00b7schlos\u00b7sen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "NN", "APPR", "PPER", "ART", "NN", "PTKZU", "VVINF", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "\u201enun haben wir die Nacht, die Freuden-Nacht gesehn,", "tokens": ["\u201e", "nun", "ha\u00b7ben", "wir", "die", "Nacht", ",", "die", "Freu\u00b7den\u00b7Nacht", "ge\u00b7sehn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "ART", "NN", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "135\u201dEs wird auch jedes Hertz aus unsrer Zahl gestehn:", "tokens": ["\"", "Es", "wird", "auch", "je\u00b7des", "Hertz", "aus", "uns\u00b7rer", "Zahl", "ge\u00b7stehn", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "PIAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201eda\u00df niemahls solche Lust in dieser Stadt gewesen,", "tokens": ["\u201e", "da\u00df", "nie\u00b7mahls", "sol\u00b7che", "Lust", "in", "die\u00b7ser", "Stadt", "ge\u00b7we\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "ADV", "PIAT", "NN", "APPR", "PDAT", "NN", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201eda\u00df von dergleichen Fest in keinem Buch zu lesen.", "tokens": ["\u201e", "da\u00df", "von", "derg\u00b7lei\u00b7chen", "Fest", "in", "kei\u00b7nem", "Buch", "zu", "le\u00b7sen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "APPR", "PIS", "NN", "APPR", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201eich finde weder Arm noch Reich, ja kein Geschlecht,", "tokens": ["\u201e", "ich", "fin\u00b7de", "we\u00b7der", "Arm", "noch", "Reich", ",", "ja", "kein", "Ge\u00b7schlecht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "KON", "NN", "ADV", "NN", "$,", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201ees sey die Frau, die Magd, es sey der Herr, der Knecht,", "tokens": ["\u201e", "es", "sey", "die", "Frau", ",", "die", "Magd", ",", "es", "sey", "der", "Herr", ",", "der", "Knecht", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "$,", "ART", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "140\u201dWas lebet spannte Kunst, Bem\u00fchung und Verm\u00f6gen", "tokens": ["\"", "Was", "le\u00b7bet", "spann\u00b7te", "Kunst", ",", "Be\u00b7m\u00fc\u00b7hung", "und", "Ver\u00b7m\u00f6\u00b7gen"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PWS", "VVFIN", "ADJA", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u201emit allen Kr\u00e4fften an, die Nacht an Tag zu legen,", "tokens": ["\u201e", "mit", "al\u00b7len", "Kr\u00e4ff\u00b7ten", "an", ",", "die", "Nacht", "an", "Tag", "zu", "le\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PIAT", "NN", "PTKVZ", "$,", "ART", "NN", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201eund durch die Freuden-Glut, durch dieses Ampel-Feur", "tokens": ["\u201e", "und", "durch", "die", "Freu\u00b7den\u00b7Glut", ",", "durch", "die\u00b7ses", "Am\u00b7pel\u00b7Feur"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "KON", "APPR", "ART", "NN", "$,", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u201ezu zeigen, wie das Hertz den Ehrfurchts-Schlu\u00df betheur:", "tokens": ["\u201e", "zu", "zei\u00b7gen", ",", "wie", "das", "Hertz", "den", "Ehr\u00b7furchts\u00b7Schlu\u00df", "be\u00b7theur", ":"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKZU", "VVINF", "$,", "PWAV", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u201eda\u00df es die K\u00f6niginn den allergr\u00f6sten Sch\u00e4tzen", "tokens": ["\u201e", "da\u00df", "es", "die", "K\u00f6\u00b7ni\u00b7ginn", "den", "al\u00b7ler\u00b7gr\u00f6s\u00b7ten", "Sch\u00e4t\u00b7zen"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KOUS", "PPER", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "145\u201dAus Liebe gegen sie verlange vorzusetzen;", "tokens": ["\"", "Aus", "Lie\u00b7be", "ge\u00b7gen", "sie", "ver\u00b7lan\u00b7ge", "vor\u00b7zu\u00b7set\u00b7zen", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "APPR", "PPER", "VVFIN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "\u201eweil sie mehr f\u00fcr ihr Volck, als f\u00fcr sich selber lebt,", "tokens": ["\u201e", "weil", "sie", "mehr", "f\u00fcr", "ihr", "Volck", ",", "als", "f\u00fcr", "sich", "sel\u00b7ber", "lebt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$,", "KOUS", "APPR", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "\u201emehr nach desselben Heil als nach dem eignen strebt;", "tokens": ["\u201e", "mehr", "nach", "des\u00b7sel\u00b7ben", "Heil", "als", "nach", "dem", "eig\u00b7nen", "strebt", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "APPR", "PDAT", "NN", "KOKOM", "APPR", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "\u201edes frohen Vaterlands geliebte", "tokens": ["\u201e", "des", "fro\u00b7hen", "Va\u00b7ter\u00b7lands", "ge\u00b7lieb\u00b7te"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "ART", "ADJA", "NN", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "\u201eder Feinde Bund und Macht, Gewalt und Muth zerreisset;", "tokens": ["\u201e", "der", "Fein\u00b7de", "Bund", "und", "Macht", ",", "Ge\u00b7walt", "und", "Muth", "zer\u00b7reis\u00b7set", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "NN", "KON", "NN", "$,", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "150\u201dDen angefochtnen Thron so tapffer unterst\u00fctzt,", "tokens": ["\"", "Den", "an\u00b7ge\u00b7focht\u00b7nen", "Thron", "so", "tapf\u00b7fer", "un\u00b7ter\u00b7st\u00fctzt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "\u201eda\u00df er nun selber auch auf seine Feinde blitzt;", "tokens": ["\u201e", "da\u00df", "er", "nun", "sel\u00b7ber", "auch", "auf", "sei\u00b7ne", "Fein\u00b7de", "blitzt", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ADV", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "\u201eindem er mehr und mehr durch l\u00e4ngst gew\u00fcnschte Sprossen,", "tokens": ["\u201e", "in\u00b7dem", "er", "mehr", "und", "mehr", "durch", "l\u00e4ngst", "ge\u00b7w\u00fcnschte", "Spros\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ADV", "KON", "ADV", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "\u201evon welchen neulich erst der Zweyte vorgeschossen,", "tokens": ["\u201e", "von", "wel\u00b7chen", "neu\u00b7lich", "erst", "der", "Zwey\u00b7te", "vor\u00b7ge\u00b7schos\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PWAT", "ADV", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Der Ertzhertzog Joseph ist/ den\n13. Mertz 1741. Der Ertzhertzog Carl\n\nden 1. Febr. 1745. gebohren; diese Re-\nde aber geschiehet den 14. Mertz 1745.", "tokens": ["Der", "Ertz\u00b7hert\u00b7zog", "Jo\u00b7se\u00b7ph", "ist", "/", "den", "13.", "Mertz", "17\u00b741", ".", "Der", "Ertz\u00b7hert\u00b7zog", "Carl", "den", "1.", "Febr", ".", "1745", ".", "ge\u00b7boh\u00b7ren", ";", "die\u00b7se", "Re", "de", "a\u00b7ber", "ge\u00b7schie\u00b7het", "den", "14.", "Mertz", "1745", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "ordinal", "word", "number", "punct", "word", "word", "word", "word", "ordinal", "word", "punct", "number", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "ordinal", "word", "number", "punct"], "pos": ["ART", "NN", "NE", "VAFIN", "$(", "ART", "ADJA", "NN", "CARD", "$.", "ART", "NN", "NE", "ART", "ADJA", "NN", "$.", "CARD", "$.", "VVPP", "$.", "PDAT", "NN", "NE", "ADV", "VVFIN", "ART", "ADJA", "NN", "CARD", "$."], "meter": "-+--+--+-+--+-+-+-+-+-+-+--+--+", "measure": "amphibrach.tri.plus"}, "line.22": {"text": "\u201ein solchen Stand gesetzt, da\u00df ihm kein Donner-Knall", "tokens": ["\u201e", "in", "sol\u00b7chen", "Stand", "ge\u00b7setzt", ",", "da\u00df", "ihm", "kein", "Don\u00b7ner\u00b7Knall"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "APPR", "PIAT", "NN", "VVPP", "$,", "KOUS", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "155\u201dIn Zukunft schrecken kann; kein schwerer Wetter-Schwall", "tokens": ["\"", "In", "Zu\u00b7kunft", "schre\u00b7cken", "kann", ";", "kein", "schwe\u00b7rer", "Wet\u00b7ter\u00b7Schwall"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "APPR", "NN", "VVINF", "VMFIN", "$.", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "\u201edesselben Grund verletzt; er trotzet auch die Wellen,", "tokens": ["\u201e", "des\u00b7sel\u00b7ben", "Grund", "ver\u00b7letzt", ";", "er", "trot\u00b7zet", "auch", "die", "Wel\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDAT", "NN", "VVPP", "$.", "PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "\u201edie noch an dessen Fu\u00df mit Sturm und Brausen prellen.", "tokens": ["\u201e", "die", "noch", "an", "des\u00b7sen", "Fu\u00df", "mit", "Sturm", "und", "Brau\u00b7sen", "prel\u00b7len", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADV", "APPR", "PRELAT", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "\u201emit einem Wort: es strebt und trachtet jedermann", "tokens": ["\u201e", "mit", "ei\u00b7nem", "Wort", ":", "es", "strebt", "und", "trach\u00b7tet", "je\u00b7der\u00b7mann"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "APPR", "ART", "NN", "$.", "PPER", "VVFIN", "KON", "VVFIN", "PIS"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "\u201enach dem was diese Frau zu loben taugen kann.", "tokens": ["\u201e", "nach", "dem", "was", "die\u00b7se", "Frau", "zu", "lo\u00b7ben", "tau\u00b7gen", "kann", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "PWS", "PDAT", "NN", "PTKZU", "VVINF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "160\u201dEs stimmen Freud und Feur in dieser Nacht zusammen,", "tokens": ["\"", "Es", "stim\u00b7men", "Freud", "und", "Feur", "in", "die\u00b7ser", "Nacht", "zu\u00b7sam\u00b7men", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "NN", "KON", "NN", "APPR", "PDAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "\u201eweil Trost und Lieb und Treu das gantze Volck entflammen.", "tokens": ["\u201e", "weil", "Trost", "und", "Lieb", "und", "Treu", "das", "gant\u00b7ze", "Volck", "ent\u00b7flam\u00b7men", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "NN", "KON", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "\u201enur unsre Regung scheint noch nicht genug erweckt;", "tokens": ["\u201e", "nur", "uns\u00b7re", "Re\u00b7gung", "scheint", "noch", "nicht", "ge\u00b7nug", "er\u00b7weckt", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PPOSAT", "NN", "VVFIN", "ADV", "PTKNEG", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "\u201eman kennt die Freude nicht, die sich in uns versteckt;", "tokens": ["\u201e", "man", "kennt", "die", "Freu\u00b7de", "nicht", ",", "die", "sich", "in", "uns", "ver\u00b7steckt", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VVFIN", "ART", "NN", "PTKNEG", "$,", "PRELS", "PRF", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "\u201ewohlan! so binden wir Sinn, Willen, Hertz zusammen,", "tokens": ["\u201e", "wo\u00b7hlan", "!", "so", "bin\u00b7den", "wir", "Sinn", ",", "Wil\u00b7len", ",", "Hertz", "zu\u00b7sam\u00b7men", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "$.", "ADV", "VAFIN", "PPER", "NN", "$,", "NN", "$,", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "165\u201dDem Volck, dem frohen Volck in allem nachzuahmen!", "tokens": ["\"", "Dem", "Volck", ",", "dem", "fro\u00b7hen", "Volck", "in", "al\u00b7lem", "nach\u00b7zu\u00b7ah\u00b7men", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "ART", "ADJA", "NN", "APPR", "PIS", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Hier schwieg er, und es schien, als ob er sich besann:", "tokens": ["Hier", "schwieg", "er", ",", "und", "es", "schien", ",", "als", "ob", "er", "sich", "be\u00b7sann", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KON", "PPER", "VVFIN", "$,", "KOKOM", "KOUS", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bald h\u00f6rt ich: \u201eJa; bald: \u201eNein. Drauf sieng er wieder an", "tokens": ["Bald", "h\u00f6rt", "ich", ":", "\u201e", "Ja", ";", "bald", ":", "\u201e", "Nein", ".", "Drauf", "sieng", "er", "wie\u00b7der", "an"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$.", "$(", "PTKANT", "$.", "ADV", "$.", "$(", "PTKANT", "$.", "PAV", "VVFIN", "PPER", "ADV", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und sprach: \u201eNein! besser ists, ein solches Werck zu finden,", "tokens": ["Und", "sprach", ":", "\u201e", "Nein", "!", "bes\u00b7ser", "ists", ",", "ein", "sol\u00b7ches", "Werck", "zu", "fin\u00b7den", ","], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PTKANT", "$.", "ADJD", "VAFIN", "$,", "ART", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201eda\u00df wir dadurch des Volcks Frolocken \u00fcberwinden.", "tokens": ["\u201e", "da\u00df", "wir", "da\u00b7durch", "des", "Volcks", "Fro\u00b7lo\u00b7cken", "\u00fc\u00b7berw\u00b7in\u00b7den", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PAV", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "170\u201dDie K\u00f6niginn ist schon der gantzen Welt bekannt;", "tokens": ["\"", "Die", "K\u00f6\u00b7ni\u00b7ginn", "ist", "schon", "der", "gant\u00b7zen", "Welt", "be\u00b7kannt", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201eder Ursprung ihres Ruhms wird aber nicht genannt.", "tokens": ["\u201e", "der", "Ur\u00b7sprung", "ih\u00b7res", "Ruhms", "wird", "a\u00b7ber", "nicht", "ge\u00b7nannt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "PPOSAT", "NN", "VAFIN", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201eman rufft: sie rettet sich! sie kriegt! sie wei\u00df zu siegen!", "tokens": ["\u201e", "man", "rufft", ":", "sie", "ret\u00b7tet", "sich", "!", "sie", "kriegt", "!", "sie", "wei\u00df", "zu", "sie\u00b7gen", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VVFIN", "$.", "PPER", "VVFIN", "PRF", "$.", "PPER", "VVFIN", "$.", "PPER", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u201edie Feinde werden sich vor ihrem Antlitz schmiegen!", "tokens": ["\u201e", "die", "Fein\u00b7de", "wer\u00b7den", "sich", "vor", "ih\u00b7rem", "Ant\u00b7litz", "schmie\u00b7gen", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201einzwischen sagt man nichts von der geheimen Macht,", "tokens": ["\u201e", "in\u00b7zwi\u00b7schen", "sagt", "man", "nichts", "von", "der", "ge\u00b7hei\u00b7men", "Macht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PIS", "PIS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "175\u201dDie bi\u00df auf diese Stund zu ihrem Schutz gewacht.", "tokens": ["\"", "Die", "bi\u00df", "auf", "die\u00b7se", "Stund", "zu", "ih\u00b7rem", "Schutz", "ge\u00b7wacht", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADV", "APPR", "PDAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u201eman wei\u00df, da\u00df Helm und Schild und Lantze viel gen\u00fctzet;", "tokens": ["\u201e", "man", "wei\u00df", ",", "da\u00df", "Helm", "und", "Schild", "und", "Lant\u00b7ze", "viel", "ge\u00b7n\u00fct\u00b7zet", ";"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VVFIN", "$,", "KOUS", "NN", "KON", "NN", "KON", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u201eda\u00df aber die\u00df Ger\u00e4th allein sie nicht besch\u00fctzet.", "tokens": ["\u201e", "da\u00df", "a\u00b7ber", "die\u00df", "Ge\u00b7r\u00e4\u00b7th", "al\u00b7lein", "sie", "nicht", "be\u00b7sch\u00fct\u00b7zet", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "ADV", "PDS", "NN", "ADV", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "\u201eder V\u00f6lcker Stimme schreyt nur Heer, und Feur, und Stahl,", "tokens": ["\u201e", "der", "V\u00f6l\u00b7cker", "Stim\u00b7me", "schreyt", "nur", "Heer", ",", "und", "Feur", ",", "und", "Stahl", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "NN", "VVFIN", "ADV", "NN", "$,", "KON", "NN", "$,", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "\u201eund Schwert, und Rach, und Wuth, und tapfrer Krieger Zahl!", "tokens": ["\u201e", "und", "Schwert", ",", "und", "Rach", ",", "und", "Wuth", ",", "und", "tapf\u00b7rer", "Krie\u00b7ger", "Zahl", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "NN", "$,", "KON", "NN", "$,", "KON", "NN", "$,", "KON", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "180\u201dKaum denckt man auf das Amt, so dieser Krei\u00df verrichtet,", "tokens": ["\"", "Kaum", "denckt", "man", "auf", "das", "Amt", ",", "so", "die\u00b7ser", "Krei\u00df", "ver\u00b7rich\u00b7tet", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PIS", "APPR", "ART", "NN", "$,", "ADV", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "\u201eder den Entwurff des Feinds allein verwirrt, zernichtet.", "tokens": ["\u201e", "der", "den", "Ent\u00b7wurff", "des", "Feinds", "al\u00b7lein", "ver\u00b7wirrt", ",", "zer\u00b7nich\u00b7tet", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ART", "ART", "NN", "ART", "NN", "ADV", "ADJD", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "\u201eso wend\u2019 ich mich zu euch: wir seynd die Gegenwehr,", "tokens": ["\u201e", "so", "wend'", "ich", "mich", "zu", "euch", ":", "wir", "seynd", "die", "Ge\u00b7gen\u00b7wehr", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "KOUS", "PPER", "PRF", "APPR", "PPER", "$.", "PPER", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201evon uns kommt Sieg und Ruhm, und Heil und Rettung her;", "tokens": ["\u201e", "von", "uns", "kommt", "Sieg", "und", "Ruhm", ",", "und", "Heil", "und", "Ret\u00b7tung", "her", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPER", "VVFIN", "NN", "KON", "NN", "$,", "KON", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201eso ehren wir uns selbst: Den Tugend-Chor verehren", "tokens": ["\u201e", "so", "eh\u00b7ren", "wir", "uns", "selbst", ":", "Den", "Tu\u00b7gen\u00b7dChor", "ver\u00b7eh\u00b7ren"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PRF", "ADV", "$.", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "185\u201dIst dieser K\u00f6niginn Vortreflichkeit vermehren;", "tokens": ["\"", "Ist", "die\u00b7ser", "K\u00f6\u00b7ni\u00b7ginn", "Vor\u00b7tre\u00b7flich\u00b7keit", "ver\u00b7meh\u00b7ren", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PDAT", "NN", "NN", "VVINF", "$."], "meter": "-+-+--+-++-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "\u201ewer dieses Krei\u00dfes Ruhm, Verdienst und Amt erh\u00f6ht,", "tokens": ["\u201e", "wer", "die\u00b7ses", "Krei\u00b7\u00dfes", "Ruhm", ",", "Ver\u00b7dienst", "und", "Amt", "er\u00b7h\u00f6ht", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "PDAT", "NN", "NN", "$,", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201eder preiset und erhebt auch ihre Majest\u00e4t.", "tokens": ["\u201e", "der", "prei\u00b7set", "und", "er\u00b7hebt", "auch", "ih\u00b7re", "Ma\u00b7jes\u00b7t\u00e4t", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "KON", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201eob demnach wir f\u00fcr uns, ob wir f\u00fcr sie was bauen,", "tokens": ["\u201e", "ob", "dem\u00b7nach", "wir", "f\u00fcr", "uns", ",", "ob", "wir", "f\u00fcr", "sie", "was", "bau\u00b7en", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PAV", "PPER", "APPR", "PPER", "$,", "KOUS", "PPER", "APPR", "PPER", "PIS", "VVINF", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "\u201eso wird man Sie sowohl, als uns geehret schauen.", "tokens": ["\u201e", "so", "wird", "man", "Sie", "so\u00b7wohl", ",", "als", "uns", "ge\u00b7eh\u00b7ret", "schau\u00b7en", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PIS", "PPER", "ADV", "$,", "KOUS", "PPER", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "190\u201dGewi\u00df ist es, da\u00df uns so viel Triumpf geb\u00fchrt,", "tokens": ["\"", "Ge\u00b7wi\u00df", "ist", "es", ",", "da\u00df", "uns", "so", "viel", "Tri\u00b7umpf", "ge\u00b7b\u00fchrt", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u201eals einst das Alterthum den Helden aufgef\u00fchrt:", "tokens": ["\u201e", "als", "einst", "das", "Al\u00b7ter\u00b7thum", "den", "Hel\u00b7den", "auf\u00b7ge\u00b7f\u00fchrt", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "ADV", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u201eweil wir der K\u00f6niginn das alles beygetragen,", "tokens": ["\u201e", "weil", "wir", "der", "K\u00f6\u00b7ni\u00b7ginn", "das", "al\u00b7les", "bey\u00b7ge\u00b7tra\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ART", "NN", "ART", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u201ewas zu derselben Ruhm fast alle V\u00f6lcker sagen.", "tokens": ["\u201e", "was", "zu", "der\u00b7sel\u00b7ben", "Ruhm", "fast", "al\u00b7le", "V\u00f6l\u00b7cker", "sa\u00b7gen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "APPR", "PDAT", "NN", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Hier merckte man, da\u00df er sich selber innerlich", "tokens": ["Hier", "merck\u00b7te", "man", ",", "da\u00df", "er", "sich", "sel\u00b7ber", "in\u00b7ner\u00b7lich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "$,", "KOUS", "PPER", "PRF", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "195Mit dem, was er dem Rath vortr\u00fcge, nicht verglich.", "tokens": ["dem", ",", "was", "er", "dem", "Rath", "vor\u00b7tr\u00fc\u00b7ge", ",", "nicht", "ver\u00b7glich", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "$,", "PWS", "PPER", "ART", "NN", "VVFIN", "$,", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Man konnt aus seinem Aug, und Thun und Lassen schliessen,", "tokens": ["Man", "konnt", "aus", "sei\u00b7nem", "Aug", ",", "und", "Thun", "und", "Las\u00b7sen", "schlies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "APPR", "PPOSAT", "NN", "$,", "KON", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df Satz und Gegensatz ihn noch im Zweifel liessen.", "tokens": ["Da\u00df", "Satz", "und", "Ge\u00b7gen\u00b7satz", "ihn", "noch", "im", "Zwei\u00b7fel", "lies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "\u201eallein\u201e, so fuhr er fort: Wer ist, wer sagt mir nun,", "tokens": ["\u201e", "al\u00b7lein", "\u201e", ",", "so", "fuhr", "er", "fort", ":", "Wer", "ist", ",", "wer", "sagt", "mir", "nun", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$(", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$.", "PWS", "VAFIN", "$,", "PWS", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201eworinnen dieses Werck, die\u00df Ehren-Werck soll ruhn?", "tokens": ["\u201e", "wo\u00b7rin\u00b7nen", "die\u00b7ses", "Werck", ",", "die\u00df", "Eh\u00b7ren\u00b7\u00b7Werck", "soll", "ruhn", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PDAT", "NN", "$,", "PDS", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "200\u201dWann Jede von dem Chor besonders prangen wollte;", "tokens": ["\"", "Wann", "Je\u00b7de", "von", "dem", "Chor", "be\u00b7son\u00b7ders", "pran\u00b7gen", "woll\u00b7te", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PIS", "APPR", "ART", "NN", "ADV", "VVFIN", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201ewann man f\u00fcr Jede was zu baun, entschliessen sollte;", "tokens": ["\u201e", "wann", "man", "f\u00fcr", "Je\u00b7de", "was", "zu", "baun", ",", "ent\u00b7schlies\u00b7sen", "soll\u00b7te", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PWAV", "PIS", "APPR", "PIAT", "PIS", "PTKZU", "VVINF", "$,", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201eso schw\u00fcng der Vorschlag sich weit \u00fcber unsre Macht,", "tokens": ["\u201e", "so", "schw\u00fcng", "der", "Vor\u00b7schlag", "sich", "weit", "\u00fc\u00b7ber", "uns\u00b7re", "Macht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ART", "NN", "PRF", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201eman f\u00e4ng zwar an, jedoch es w\u00fcrde nichts vollbracht:", "tokens": ["\u201e", "man", "f\u00e4ng", "zwar", "an", ",", "je\u00b7doch", "es", "w\u00fcr\u00b7de", "nichts", "voll\u00b7bracht", ":"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VVFIN", "ADV", "PTKVZ", "$,", "ADV", "PPER", "VAFIN", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201eso viele Tugenden! so viele Pracht-Colossen!", "tokens": ["\u201e", "so", "vie\u00b7le", "Tu\u00b7gen\u00b7den", "!", "so", "vie\u00b7le", "Pracht\u00b7Co\u00b7los\u00b7sen", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PIAT", "NN", "$.", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "205\u201dEs w\u00fcrd ein Wunder-Wald, doch blieb er unentsprossen.", "tokens": ["\"", "Es", "w\u00fcrd", "ein", "Wun\u00b7der\u00b7Wald", ",", "doch", "blieb", "er", "un\u00b7ent\u00b7spros\u00b7sen", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "\u201eso fassen wir den Schlu\u00df: Ein eintziges Geb\u00e4u,", "tokens": ["\u201e", "so", "fas\u00b7sen", "wir", "den", "Schlu\u00df", ":", "Ein", "eint\u00b7zi\u00b7ges", "Ge\u00b7b\u00e4u", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ART", "NN", "$.", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201edas man dem Amts-Verdienst der ersten Tugend weih,", "tokens": ["\u201e", "das", "man", "dem", "Amts\u00b7Ver\u00b7dienst", "der", "ers\u00b7ten", "Tu\u00b7gend", "weih", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PRELS", "PIS", "ART", "NN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201e(Stim\u0303t ihr mit mir nicht ein?) k\u00f6nnt unsern Wunsch und Willen", "tokens": ["\u201e", "(", "Stim\u0303t", "ihr", "mit", "mir", "nicht", "ein", "?", ")", "k\u00f6nnt", "un\u00b7sern", "Wunsch", "und", "Wil\u00b7len"], "token_info": ["punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "$(", "VVFIN", "PPER", "APPR", "PPER", "PTKNEG", "PTKVZ", "$.", "$(", "VVFIN", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201eso wohl, als jener Wald, durch seine Pracht erf\u00fcllen.", "tokens": ["\u201e", "so", "wohl", ",", "als", "je\u00b7ner", "Wald", ",", "durch", "sei\u00b7ne", "Pracht", "er\u00b7f\u00fcl\u00b7len", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "$,", "KOUS", "PDAT", "NN", "$,", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "210\u201dWer aber ist von uns, dem dieser Rang geb\u00fchrt?", "tokens": ["\"", "Wer", "a\u00b7ber", "ist", "von", "uns", ",", "dem", "die\u00b7ser", "Rang", "ge\u00b7b\u00fchrt", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "ADV", "VAFIN", "APPR", "PPER", "$,", "PRELS", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201ewer hat was ohne mich erfunden, ausgef\u00fchrt?", "tokens": ["\u201e", "wer", "hat", "was", "oh\u00b7ne", "mich", "er\u00b7fun\u00b7den", ",", "aus\u00b7ge\u00b7f\u00fchrt", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "PIS", "APPR", "PPER", "VVPP", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "\u201eso will das Recht, da\u00df man mir dieses Denckmal baue,", "tokens": ["\u201e", "so", "will", "das", "Recht", ",", "da\u00df", "man", "mir", "die\u00b7ses", "Denck\u00b7mal", "bau\u00b7e", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "ART", "NN", "$,", "KOUS", "PIS", "PPER", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u201eauf dessen ", "tokens": ["\u201e", "auf", "des\u00b7sen"], "token_info": ["punct", "word", "word"], "pos": ["$(", "APPR", "PRELAT"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.14": {"line.1": {"text": "Ich wurde nicht allein durch diesen Satz bewegt;", "tokens": ["Ich", "wur\u00b7de", "nicht", "al\u00b7lein", "durch", "die\u00b7sen", "Satz", "be\u00b7wegt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "215Die gantze Gegenwart des Saales ward erregt,", "tokens": ["gant\u00b7ze", "Ge\u00b7gen\u00b7wart", "des", "Saa\u00b7les", "ward", "er\u00b7regt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Nichts weniger als ihm geneiget beyzustimmen;", "tokens": ["Nichts", "we\u00b7ni\u00b7ger", "als", "ihm", "ge\u00b7nei\u00b7get", "bey\u00b7zu\u00b7stim\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "KOUS", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Man sah fast allerseits ein Mi\u00dfvergn\u00fcgen glimmen.", "tokens": ["Man", "sah", "fast", "al\u00b7ler\u00b7seits", "ein", "Mi\u00df\u00b7ver\u00b7gn\u00fc\u00b7gen", "glim\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Thalia selbst erwies Befremdung, ja Verdru\u00df:", "tokens": ["Tha\u00b7lia", "selbst", "er\u00b7wies", "Be\u00b7frem\u00b7dung", ",", "ja", "Ver\u00b7dru\u00df", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "NN", "$,", "ADV", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.6": {"text": "\u201ewas\u201e, sagte sie: Der ist beym Anfang schon am Schlu\u00df?", "tokens": ["\u201e", "was", "\u201e", ",", "sag\u00b7te", "sie", ":", "Der", "ist", "beym", "An\u00b7fang", "schon", "am", "Schlu\u00df", "?"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "$(", "$,", "VVFIN", "PPER", "$.", "PDS", "VAFIN", "APPRART", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "220Ich fragte, wer er sey; Ob sie den J\u00fcngling kenne?", "tokens": ["frag\u00b7te", ",", "wer", "er", "sey", ";", "Ob", "sie", "den", "J\u00fcng\u00b7ling", "ken\u00b7ne", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWS", "PPER", "VAFIN", "$.", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "\u201esein Reden zeigt\u201e, sprach sie, da\u00df er sich ", "tokens": ["\u201e", "sein", "Re\u00b7den", "zeigt", "\u201e", ",", "sprach", "sie", ",", "da\u00df", "er", "sich"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PPOSAT", "NN", "VVFIN", "$(", "$,", "VVFIN", "PPER", "$,", "KOUS", "PPER", "PRF"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.15": {"line.1": {"text": "Jhn aber hinderten die finstern Augen nicht.", "tokens": ["Jhn", "a\u00b7ber", "hin\u00b7der\u00b7ten", "die", "fins\u00b7tern", "Au\u00b7gen", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ART", "ADJA", "NN", "PTKNEG", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "\u201ejhr \u00fcbereilet euch! vernehmt nur den Bericht!", "tokens": ["\u201e", "jhr", "\u00fc\u00b7be\u00b7rei\u00b7let", "euch", "!", "ver\u00b7nehmt", "nur", "den", "Be\u00b7richt", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "$.", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201e", "tokens": ["\u201e"], "token_info": ["punct"], "pos": ["$("]}, "line.4": {"text": "225\u201dH\u00e4tt manches Helden-Werck durch allerkl\u00fcgste Streiter", "tokens": ["\"", "H\u00e4tt", "man\u00b7ches", "Hel\u00b7den\u00b7\u00b7Werck", "durch", "al\u00b7ler\u00b7kl\u00fcgs\u00b7te", "Strei\u00b7ter"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "PIAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201enicht gl\u00fccklicher vollbracht, als es mein Witz gethan;", "tokens": ["\u201e", "nicht", "gl\u00fcck\u00b7li\u00b7cher", "voll\u00b7bracht", ",", "als", "es", "mein", "Witz", "ge\u00b7than", ";"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKNEG", "ADJD", "VVPP", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.6": {"text": "\u201eich weise klar, da\u00df ich mich dessen r\u00fchmen kann.", "tokens": ["\u201e", "ich", "wei\u00b7se", "klar", ",", "da\u00df", "ich", "mich", "des\u00b7sen", "r\u00fch\u00b7men", "kann", "."], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADJD", "$,", "KOUS", "PPER", "PRF", "PDS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "\u201eich zweifle; dieses hei\u00dft: den Sachen nachzusinnen:", "tokens": ["\u201e", "ich", "zweif\u00b7le", ";", "die\u00b7ses", "hei\u00dft", ":", "den", "Sa\u00b7chen", "nach\u00b7zu\u00b7sin\u00b7nen", ":"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$.", "PDS", "VVFIN", "$.", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201edurch dieses werden wir derselben Zustand innen:", "tokens": ["\u201e", "durch", "die\u00b7ses", "wer\u00b7den", "wir", "der\u00b7sel\u00b7ben", "Zu\u00b7stand", "in\u00b7nen", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PDS", "VAFIN", "PPER", "PDAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "230\u201dDer Zustand zeigt den Weeg, der Weeg f\u00fchrt uns zum Ziel", "tokens": ["\"", "Der", "Zu\u00b7stand", "zeigt", "den", "Weeg", ",", "der", "Weeg", "f\u00fchrt", "uns", "zum", "Ziel"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "VVFIN", "ART", "NN", "$,", "ART", "NN", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201eso man nach Art und Maa\u00df der Sach erreichen will.", "tokens": ["\u201e", "so", "man", "nach", "Art", "und", "Maa\u00df", "der", "Sach", "er\u00b7rei\u00b7chen", "will", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PIS", "APPR", "NN", "KON", "NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201emit dieser Eigenschaft hab ich den Weeg gefunden;", "tokens": ["\u201e", "mit", "die\u00b7ser", "Ei\u00b7gen\u00b7schaft", "hab", "ich", "den", "Weeg", "ge\u00b7fun\u00b7den", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PDAT", "NN", "VAFIN", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201edurch diesen haben wir uns gl\u00fccklich durchgewunden:", "tokens": ["\u201e", "durch", "die\u00b7sen", "ha\u00b7ben", "wir", "uns", "gl\u00fcck\u00b7lich", "durch\u00b7ge\u00b7wun\u00b7den", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PDS", "VAFIN", "PPER", "PRF", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "\u201ewer ist, dem nicht die Furcht durch Hertz und Adern drang?", "tokens": ["\u201e", "wer", "ist", ",", "dem", "nicht", "die", "Furcht", "durch", "Hertz", "und", "A\u00b7dern", "drang", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "$,", "PRELS", "PTKNEG", "ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "235\u201dWer ist, der nicht mit Angst und Ungewi\u00dfheit rang?", "tokens": ["\"", "Wer", "ist", ",", "der", "nicht", "mit", "Angst", "und", "Un\u00b7ge\u00b7wi\u00df\u00b7heit", "rang", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "$,", "PRELS", "PTKNEG", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201ewer sa\u00df nicht manchesmal in traurigen Gedancken?", "tokens": ["\u201e", "wer", "sa\u00df", "nicht", "man\u00b7ches\u00b7mal", "in", "trau\u00b7ri\u00b7gen", "Ge\u00b7dan\u00b7cken", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PTKNEG", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201ewie oft begunnt man nicht mit eignem Sinn zu zancken;", "tokens": ["\u201e", "wie", "oft", "be\u00b7gunnt", "man", "nicht", "mit", "eig\u00b7nem", "Sinn", "zu", "zan\u00b7cken", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "ADV", "VVFIN", "PIS", "PTKNEG", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201ewart ihr nicht selber oft in Wanckelmuth versenckt?", "tokens": ["\u201e", "wart", "ihr", "nicht", "sel\u00b7ber", "oft", "in", "Wan\u00b7ckel\u00b7muth", "ver\u00b7senckt", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "PTKNEG", "ADV", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.6": {"text": "\u201ewer hat euch wiederum von dorten abgelenckt?", "tokens": ["\u201e", "wer", "hat", "euch", "wie\u00b7de\u00b7rum", "von", "dor\u00b7ten", "ab\u00b7ge\u00b7lenckt", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "PPER", "ADV", "APPR", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "240\u201dDie K\u00f6niginn und ich: wir haben uns beflissen,", "tokens": ["\"", "Die", "K\u00f6\u00b7ni\u00b7ginn", "und", "ich", ":", "wir", "ha\u00b7ben", "uns", "be\u00b7flis\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "KON", "PPER", "$.", "PPER", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u201edurch meine Zweifels-Kunst der Sachen Grund zu wissen.", "tokens": ["\u201e", "durch", "mei\u00b7ne", "Zwei\u00b7fels\u00b7Kunst", "der", "Sa\u00b7chen", "Grund", "zu", "wis\u00b7sen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPOSAT", "NN", "ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201efreund, Hoffnung, GOtt und Sieg, Feind, Waffen und Gefahr,", "tokens": ["\u201e", "freund", ",", "Hoff\u00b7nung", ",", "Gott", "und", "Sieg", ",", "Feind", ",", "Waf\u00b7fen", "und", "Ge\u00b7fahr", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "NN", "$,", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u201edie\u00df alles stellten wir uns so bedeutlich dar,", "tokens": ["\u201e", "die\u00df", "al\u00b7les", "stell\u00b7ten", "wir", "uns", "so", "be\u00b7deut\u00b7lich", "dar", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "PIS", "VVFIN", "PPER", "PRF", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u201eda\u00df kein Verdacht, kein Fall, kein Umstand ward vergessen,", "tokens": ["\u201e", "da\u00df", "kein", "Ver\u00b7dacht", ",", "kein", "Fall", ",", "kein", "Um\u00b7stand", "ward", "ver\u00b7ges\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PIAT", "NN", "$,", "PIAT", "NN", "$,", "PIAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "245\u201dWir hatten Tag und Nacht bald die\u00df, bald das ermessen.", "tokens": ["\"", "Wir", "hat\u00b7ten", "Tag", "und", "Nacht", "bald", "die\u00df", ",", "bald", "das", "er\u00b7mes\u00b7sen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "NN", "KON", "NN", "ADV", "PDS", "$,", "ADV", "PDS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "\u201ewann man sich anderwerts dem Kummer \u00fcberlie\u00df,", "tokens": ["\u201e", "wann", "man", "sich", "an\u00b7der\u00b7werts", "dem", "Kum\u00b7mer", "\u00fc\u00b7ber\u00b7lie\u00df", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PIS", "PRF", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "\u201eda sucht\u2019 ich, da\u00df ich uns aus dessen Banden ri\u00df.", "tokens": ["\u201e", "da", "sucht'", "ich", ",", "da\u00df", "ich", "uns", "aus", "des\u00b7sen", "Ban\u00b7den", "ri\u00df", "."], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "PRF", "APPR", "PRELAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wir hatten Ja und Nein, sonst nichts, zu Raths-Genossen,", "tokens": ["Wir", "hat\u00b7ten", "Ja", "und", "Nein", ",", "sonst", "nichts", ",", "zu", "Raths\u00b7Ge\u00b7nos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKANT", "KON", "PTKANT", "$,", "ADV", "PIS", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Durch diese ward von uns, was allen halff, entschlossen.", "tokens": ["Durch", "die\u00b7se", "ward", "von", "uns", ",", "was", "al\u00b7len", "halff", ",", "ent\u00b7schlos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PDS", "VAFIN", "APPR", "PPER", "$,", "PRELS", "PIAT", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}