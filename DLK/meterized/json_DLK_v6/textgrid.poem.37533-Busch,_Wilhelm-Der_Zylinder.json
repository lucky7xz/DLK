{"textgrid.poem.37533": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Der Zylinder", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Josephitag ist, wie du wei\u00dft,", "tokens": ["Jo\u00b7se\u00b7phi\u00b7tag", "ist", ",", "wie", "du", "wei\u00dft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Ein Fest f\u00fcr den, der Joseph hei\u00dft.", "tokens": ["Ein", "Fest", "f\u00fcr", "den", ",", "der", "Jo\u00b7se\u00b7ph", "hei\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "$,", "ART", "NE", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Drum b\u00fcrstet, weil er fromm und gut,", "tokens": ["Drum", "b\u00fcrs\u00b7tet", ",", "weil", "er", "fromm", "und", "gut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "$,", "KOUS", "PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch dieser Joseph seinen Hut", "tokens": ["Auch", "die\u00b7ser", "Jo\u00b7se\u00b7ph", "sei\u00b7nen", "Hut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PDAT", "NE", "PPOSAT", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und macht sich \u00fcberhaupt recht sch\u00f6n,", "tokens": ["Und", "macht", "sich", "\u00fc\u00b7ber\u00b7haupt", "recht", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie alle, die zur Metten gehn.", "tokens": ["Wie", "al\u00b7le", ",", "die", "zur", "Met\u00b7ten", "gehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "$,", "PRELS", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Hier geht er aus der T\u00fcre schon", "tokens": ["Hier", "geht", "er", "aus", "der", "T\u00fc\u00b7re", "schon"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und denkt an seinen Schutzpatron. \u2013", "tokens": ["Und", "denkt", "an", "sei\u00b7nen", "Schutz\u00b7pat\u00b7ron", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Herau\u00dfen weht nicht sehr gelind", "tokens": ["Her\u00b7au\u00b7\u00dfen", "weht", "nicht", "sehr", "ge\u00b7lind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PTKNEG", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Osten her ein k\u00fchler Wind,", "tokens": ["Von", "Os\u00b7ten", "her", "ein", "k\u00fch\u00b7ler", "Wind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APZR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So da\u00df die beiden langen Spitzen,", "tokens": ["So", "da\u00df", "die", "bei\u00b7den", "lan\u00b7gen", "Spit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die hinten an dem Fracke sitzen,", "tokens": ["Die", "hin\u00b7ten", "an", "dem", "Fra\u00b7cke", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mit leichtem Schwunge sich erheben", "tokens": ["Mit", "leich\u00b7tem", "Schwun\u00b7ge", "sich", "er\u00b7he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "PRF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und br\u00fcderlich nach Westen streben. \u2013", "tokens": ["Und", "br\u00fc\u00b7der\u00b7lich", "nach", "Wes\u00b7ten", "stre\u00b7ben", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJD", "APPR", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Jetzt kommt die Ecke. Immer schlimmer", "tokens": ["Jetzt", "kommt", "die", "E\u00b7cke", ".", "Im\u00b7mer", "schlim\u00b7mer"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "ADV", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Weht hier der Wind. \u2013 Ein Frauenzimmer,", "tokens": ["Weht", "hier", "der", "Wind", ".", "\u2013", "Ein", "Frau\u00b7en\u00b7zim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$.", "$(", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Obschon von W\u00fcchse sch\u00f6n und kr\u00e4ftig,", "tokens": ["Ob\u00b7schon", "von", "W\u00fcch\u00b7se", "sch\u00f6n", "und", "kr\u00e4f\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ist sehr bewegt und flattert heftig,", "tokens": ["Ist", "sehr", "be\u00b7wegt", "und", "flat\u00b7tert", "hef\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "KON", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So da\u00df man wohl bemerken kann \u2013 \u2013 \u2013", "tokens": ["So", "da\u00df", "man", "wohl", "be\u00b7mer\u00b7ken", "kann", "\u2013", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "KOUS", "PIS", "ADV", "VVINF", "VMFIN", "$(", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "O Joseph, was geht dich das an?", "tokens": ["O", "Jo\u00b7se\u00b7ph", ",", "was", "geht", "dich", "das", "an", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PWS", "VVFIN", "PPER", "PDS", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Ja, siehst du wohl, das war nicht gut!", "tokens": ["Ja", ",", "siehst", "du", "wohl", ",", "das", "war", "nicht", "gut", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "ADV", "$,", "PDS", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Jetzt nimmt der Wind dir deinen Hut! \u2013", "tokens": ["Jetzt", "nimmt", "der", "Wind", "dir", "dei\u00b7nen", "Hut", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Schnell legt der Joseph sein Brevier", "tokens": ["Schnell", "legt", "der", "Jo\u00b7se\u00b7ph", "sein", "Bre\u00b7vier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ART", "NE", "PPOSAT", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Auf einen Stein vor einer T\u00fcr,", "tokens": ["Auf", "ei\u00b7nen", "Stein", "vor", "ei\u00b7ner", "T\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Um so erleichtert ohne Weilen", "tokens": ["Um", "so", "er\u00b7leich\u00b7tert", "oh\u00b7ne", "Wei\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUI", "ADV", "VVPP", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dem sch\u00f6nen Fl\u00fcchtling nachzueilen. \u2013", "tokens": ["Dem", "sch\u00f6\u00b7nen", "Fl\u00fccht\u00b7ling", "nach\u00b7zu\u00b7ei\u00b7len", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VVIZU", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "O weh, da trifft und fa\u00dft ihn grad,", "tokens": ["O", "weh", ",", "da", "trifft", "und", "fa\u00dft", "ihn", "grad", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$,", "ADV", "VVFIN", "KON", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch nur am Rand, ein Droschkenrad.", "tokens": ["Doch", "nur", "am", "Rand", ",", "ein", "Droschken\u00b7rad", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Jetzt eilt er wieder schnell und heiter", "tokens": ["Jetzt", "eilt", "er", "wie\u00b7der", "schnell", "und", "hei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In sch\u00f6nen Kreisen emsig weiter,", "tokens": ["In", "sch\u00f6\u00b7nen", "Krei\u00b7sen", "em\u00b7sig", "wei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und Joseph eilet hinterdrein.", "tokens": ["Und", "Jo\u00b7se\u00b7ph", "ei\u00b7let", "hin\u00b7ter\u00b7drein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hopsa! Da liegt ja wohl ein Stein.", "tokens": ["Hop\u00b7sa", "!", "Da", "liegt", "ja", "wohl", "ein", "Stein", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ADV", "VVFIN", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Wutschi \u2013 der Joseph liegt im Saft.", "tokens": ["Wut\u00b7schi", "\u2013", "der", "Jo\u00b7se\u00b7ph", "liegt", "im", "Saft", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "ART", "NE", "VVFIN", "APPRART", "NN", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}}, "stanza.11": {"line.1": {"text": "Der Hut entfernt sich wirbelhaft. \u2013", "tokens": ["Der", "Hut", "ent\u00b7fernt", "sich", "wir\u00b7bel\u00b7haft", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADJD", "PRF", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Dies sieht aus frohem Hintergrund", "tokens": ["Dies", "sieht", "aus", "fro\u00b7hem", "Hin\u00b7ter\u00b7grund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein alter Herr mit seinem Hund,", "tokens": ["Ein", "al\u00b7ter", "Herr", "mit", "sei\u00b7nem", "Hund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und grade kommen auch daher", "tokens": ["Und", "gra\u00b7de", "kom\u00b7men", "auch", "da\u00b7her"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ADV", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die andern frommen Josepher", "tokens": ["Die", "an\u00b7dern", "from\u00b7men", "Jo\u00b7se\u00b7pher"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und denken sich mit frohem Graus:", "tokens": ["Und", "den\u00b7ken", "sich", "mit", "fro\u00b7hem", "Graus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie schauderhaft sieht Joseph aus!", "tokens": ["Wie", "schau\u00b7der\u00b7haft", "sieht", "Jo\u00b7se\u00b7ph", "aus", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "NE", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.13": {"line.1": {"text": "Und Josephs Hut, wo w\u00e4re der,", "tokens": ["Und", "Jo\u00b7se\u00b7phs", "Hut", ",", "wo", "w\u00e4\u00b7re", "der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NN", "$,", "PWAV", "VAFIN", "ART", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Wenn der Soldat allhier nicht w\u00e4r", "tokens": ["Wenn", "der", "Sol\u00b7dat", "all\u00b7hier", "nicht", "w\u00e4r"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADV", "PTKNEG", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und nicht mit seinem Bajonett", "tokens": ["Und", "nicht", "mit", "sei\u00b7nem", "Ba\u00b7jo\u00b7nett"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihn mutig aufgehalten h\u00e4tt. \u2013", "tokens": ["Ihn", "mu\u00b7tig", "auf\u00b7ge\u00b7hal\u00b7ten", "h\u00e4tt", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "ADJD", "VVPP", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Nun hat ihn doch der Joseph wieder. \u2013", "tokens": ["Nun", "hat", "ihn", "doch", "der", "Jo\u00b7se\u00b7ph", "wie\u00b7der", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NE", "ADV", "$.", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Stolz geht der Krieger auf und nieder. \u2013", "tokens": ["Stolz", "geht", "der", "Krie\u00b7ger", "auf", "und", "nie\u00b7der", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "PTKVZ", "KON", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Joseph aber schaut geschwind,", "tokens": ["Der", "Jo\u00b7se\u00b7ph", "a\u00b7ber", "schaut", "ge\u00b7schwind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADV", "VVFIN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wo seine andern Sachen sind.", "tokens": ["Wo", "sei\u00b7ne", "an\u00b7dern", "Sa\u00b7chen", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Gottlob, sie sind noch alle dort. \u2013", "tokens": ["Gott\u00b7lob", ",", "sie", "sind", "noch", "al\u00b7le", "dort", ".", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "ADV", "PIS", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Herr mit seinem Hund geht fort,", "tokens": ["Der", "Herr", "mit", "sei\u00b7nem", "Hund", "geht", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Und Joseph schreitet auch nach Haus. \u2013", "tokens": ["Und", "Jo\u00b7se\u00b7ph", "schrei\u00b7tet", "auch", "nach", "Haus", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NE", "VVFIN", "ADV", "APPR", "NN", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er sieht nicht mehr so stattlich aus", "tokens": ["Er", "sieht", "nicht", "mehr", "so", "statt\u00b7lich", "aus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "ADV", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Und mu\u00df nun leider dessentwegen", "tokens": ["Und", "mu\u00df", "nun", "lei\u00b7der", "des\u00b7sent\u00b7we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADV", "ADV", "PAV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Privatim seiner Andacht pflegen.", "tokens": ["Pri\u00b7va\u00b7tim", "sei\u00b7ner", "An\u00b7dacht", "pfle\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Drum soll man nie bei Windeswehen", "tokens": ["Drum", "soll", "man", "nie", "bei", "Win\u00b7des\u00b7we\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VMFIN", "PIS", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auf weibliche Gestalten sehen.", "tokens": ["Auf", "weib\u00b7li\u00b7che", "Ge\u00b7stal\u00b7ten", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}