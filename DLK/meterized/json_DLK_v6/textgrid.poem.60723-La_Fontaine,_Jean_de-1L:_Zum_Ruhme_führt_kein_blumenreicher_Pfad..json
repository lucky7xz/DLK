{"textgrid.poem.60723": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Zum Ruhme f\u00fchrt kein blumenreicher Pfad.", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zum Ruhme f\u00fchrt kein blumenreicher Pfad.", "tokens": ["Zum", "Ruh\u00b7me", "f\u00fchrt", "kein", "blu\u00b7men\u00b7rei\u00b7cher", "Pfad", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Als Zeuge nenn ich Herkules und seine Tat.", "tokens": ["Als", "Zeu\u00b7ge", "nenn", "ich", "Her\u00b7ku\u00b7les", "und", "sei\u00b7ne", "Tat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "PPER", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Gott hat kaum wohl einen seinesgleichen,", "tokens": ["Der", "Gott", "hat", "kaum", "wohl", "ei\u00b7nen", "sei\u00b7nes\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sei's in der Poesie, sei's in historischen Reichen.", "tokens": ["Sei's", "in", "der", "Poe\u00b7sie", ",", "sei's", "in", "his\u00b7to\u00b7ri\u00b7schen", "Rei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,", "VAFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch soll von einem hier berichtet sein,", "tokens": ["Doch", "soll", "von", "ei\u00b7nem", "hier", "be\u00b7rich\u00b7tet", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "ART", "ADV", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der angetrieben war von alten Talismanen,", "tokens": ["Der", "an\u00b7ge\u00b7trie\u00b7ben", "war", "von", "al\u00b7ten", "Ta\u00b7lis\u00b7ma\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVPP", "VAFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dem Gl\u00fccke nachzugehn im Lande der Romanen.", "tokens": ["Dem", "Gl\u00fc\u00b7cke", "nach\u00b7zu\u00b7gehn", "im", "Lan\u00b7de", "der", "Ro\u00b7ma\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Er reiste nicht allein.", "tokens": ["Er", "reis\u00b7te", "nicht", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Sein Freund und er gewahrten einen Pfahl,", "tokens": ["Sein", "Freund", "und", "er", "ge\u00b7wahr\u00b7ten", "ei\u00b7nen", "Pfahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Der eine Tafel trug, auf der zu lesen:", "tokens": ["Der", "ei\u00b7ne", "Ta\u00b7fel", "trug", ",", "auf", "der", "zu", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "$,", "APPR", "ART", "PTKZU", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "\u00bbherr Abenteurer, l\u00fcstet's dich einmal,", "tokens": ["\u00bb", "herr", "A\u00b7bent\u00b7eu\u00b7rer", ",", "l\u00fcs\u00b7tet's", "dich", "ein\u00b7mal", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NN", "NN", "$,", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Zu sehn, was keinem sichtbar noch gewesen", "tokens": ["Zu", "sehn", ",", "was", "kei\u00b7nem", "sicht\u00b7bar", "noch", "ge\u00b7we\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$,", "PRELS", "PIS", "ADJD", "ADV", "VAPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Von Rittern oder fahrenden Gesellen,", "tokens": ["Von", "Rit\u00b7tern", "o\u00b7der", "fah\u00b7ren\u00b7den", "Ge\u00b7sel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "So teile dieses Stromes Wellen.", "tokens": ["So", "tei\u00b7le", "die\u00b7ses", "Stro\u00b7mes", "Wel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PDAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Den Elefanten, der am andern Ufer liegt,", "tokens": ["Den", "E\u00b7lef\u00b7an\u00b7ten", ",", "der", "am", "an\u00b7dern", "U\u00b7fer", "liegt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Den steinernen, heb auf", "tokens": ["Den", "stei\u00b7ner\u00b7nen", ",", "heb", "auf"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "$,", "VVFIN", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.17": {"text": "Und trage ihn den Berg hinauf,", "tokens": ["Und", "tra\u00b7ge", "ihn", "den", "Berg", "hin\u00b7auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Der dort in Wolken seine Stirne wiegt;", "tokens": ["Der", "dort", "in", "Wol\u00b7ken", "sei\u00b7ne", "Stir\u00b7ne", "wiegt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Doch trage diese Last", "tokens": ["Doch", "tra\u00b7ge", "die\u00b7se", "Last"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PDAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.20": {"text": "Bis auf den Gipfel ohne Rast.\u00ab", "tokens": ["Bis", "auf", "den", "Gip\u00b7fel", "oh\u00b7ne", "Rast", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Da sprach der Freund: \u00bbNein, das f\u00e4llt mir nicht ein!", "tokens": ["Da", "sprach", "der", "Freund", ":", "\u00bb", "Nein", ",", "das", "f\u00e4llt", "mir", "nicht", "ein", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "$(", "PTKANT", "$,", "PDS", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Der Strom ist tief und wird gef\u00e4hrlich sein.", "tokens": ["Der", "Strom", "ist", "tief", "und", "wird", "ge\u00b7f\u00e4hr\u00b7lich", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KON", "VAFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Doch angenommen, da\u00df ich ihn durchquere,", "tokens": ["Doch", "an\u00b7ge\u00b7nom\u00b7men", ",", "da\u00df", "ich", "ihn", "durch\u00b7que\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "Was soll's, da\u00df ich mich mit dem Vieh beschwere?", "tokens": ["Was", "soll's", ",", "da\u00df", "ich", "mich", "mit", "dem", "Vieh", "be\u00b7schwe\u00b7re", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "$,", "KOUS", "PPER", "PRF", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Welch l\u00e4cherliches Unterfangen!", "tokens": ["Welch", "l\u00e4\u00b7cher\u00b7li\u00b7ches", "Un\u00b7ter\u00b7fan\u00b7gen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Ein Elefant aus Stein", "tokens": ["Ein", "E\u00b7le\u00b7fant", "aus", "Stein"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Kann h\u00f6chstens ein paar Schritt von uns zu tragen sein;", "tokens": ["Kann", "h\u00f6chs\u00b7tens", "ein", "paar", "Schritt", "von", "uns", "zu", "tra\u00b7gen", "sein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "PIAT", "NN", "APPR", "PPER", "PTKZU", "VVINF", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Doch auf den Gipfel zu gelangen", "tokens": ["Doch", "auf", "den", "Gip\u00b7fel", "zu", "ge\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ganz ohne Rast", "tokens": ["Ganz", "oh\u00b7ne", "Rast"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPR", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Mit solcher Last,", "tokens": ["Mit", "sol\u00b7cher", "Last", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Kann dann nur m\u00f6glich sein,", "tokens": ["Kann", "dann", "nur", "m\u00f6g\u00b7lich", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "ADJD", "VAINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Wenn jener Elefant aus Stein", "tokens": ["Wenn", "je\u00b7ner", "E\u00b7le\u00b7fant", "aus", "Stein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PDAT", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Zwerg ist, ein Spazierstockgriff.", "tokens": ["Ein", "Zwerg", "ist", ",", "ein", "Spa\u00b7zier\u00b7stock\u00b7griff", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wo ist der Sinn, die Ehre bei dem Spiel?", "tokens": ["Wo", "ist", "der", "Sinn", ",", "die", "Eh\u00b7re", "bei", "dem", "Spiel", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Die Inschrift ist nichts andres als ein Kniff,", "tokens": ["Die", "In\u00b7schrift", "ist", "nichts", "and\u00b7res", "als", "ein", "Kniff", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIS", "PIS", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Ein R\u00e4tsel f\u00fcr ein Kind, ganz ohne Zweck und Ziel.", "tokens": ["Ein", "R\u00e4t\u00b7sel", "f\u00fcr", "ein", "Kind", ",", "ganz", "oh\u00b7ne", "Zweck", "und", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Drum la\u00df ich Euch allein mit Eurem Elefant.\u00ab", "tokens": ["Drum", "la\u00df", "ich", "Euch", "al\u00b7lein", "mit", "Eu\u00b7rem", "E\u00b7le\u00b7fant", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der Sprecher ging. Der Abenteurer springt", "tokens": ["Der", "Spre\u00b7cher", "ging", ".", "Der", "A\u00b7bent\u00b7eu\u00b7rer", "springt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Geschlo\u00dfnen Auges in die Flut", "tokens": ["Ge\u00b7schlo\u00df\u00b7nen", "Au\u00b7ges", "in", "die", "Flut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Und schwimmt hin\u00fcber an den Strand.", "tokens": ["Und", "schwimmt", "hin\u00b7\u00fc\u00b7ber", "an", "den", "Strand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Und als er dort sich auf das Ufer schwingt,", "tokens": ["Und", "als", "er", "dort", "sich", "auf", "das", "U\u00b7fer", "schwingt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Erblickt er alsobald den Elefant,", "tokens": ["Er\u00b7blickt", "er", "al\u00b7so\u00b7bald", "den", "E\u00b7le\u00b7fant", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Der schwer im Sande ruht.", "tokens": ["Der", "schwer", "im", "San\u00b7de", "ruht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.17": {"text": "Er nimmt ihn, tr\u00e4gt ihn fort, kommt auf der H\u00f6he an,", "tokens": ["Er", "nimmt", "ihn", ",", "tr\u00e4gt", "ihn", "fort", ",", "kommt", "auf", "der", "H\u00f6\u00b7he", "an", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "PTKVZ", "$,", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Sieht einen Park und eine Stadt sodann.", "tokens": ["Sieht", "ei\u00b7nen", "Park", "und", "ei\u00b7ne", "Stadt", "so\u00b7dann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KON", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Der Elefant trompetet ein Signal,", "tokens": ["Der", "E\u00b7le\u00b7fant", "trom\u00b7pe\u00b7tet", "ein", "Sig\u00b7nal", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Da kommt bewaffnet Volk herbei mit einemmal.", "tokens": ["Da", "kommt", "be\u00b7waff\u00b7net", "Volk", "her\u00b7bei", "mit", "ei\u00b7nem\u00b7mal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "NN", "ADV", "APPR", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ein andrer w\u00e4re wohl bei dem Alarm", "tokens": ["Ein", "an\u00b7drer", "w\u00e4\u00b7re", "wohl", "bei", "dem", "A\u00b7larm"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VAFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Entflohn, doch dieser, statt zu weichen,", "tokens": ["Ent\u00b7flohn", ",", "doch", "die\u00b7ser", ",", "statt", "zu", "wei\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "PDAT", "$,", "KOUI", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Beschlie\u00dft, mit k\u00fchnem Arm", "tokens": ["Be\u00b7schlie\u00dft", ",", "mit", "k\u00fch\u00b7nem", "Arm"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.24": {"text": "Zu trotzen allen Streichen", "tokens": ["Zu", "trot\u00b7zen", "al\u00b7len", "Strei\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.25": {"text": "Und als ein Held zu sterben.", "tokens": ["Und", "als", "ein", "Held", "zu", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.26": {"text": "Wie staunte er, als er vernahm,", "tokens": ["Wie", "staun\u00b7te", "er", ",", "als", "er", "ver\u00b7nahm", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.27": {"text": "Da\u00df die Kohorte ihm zu huldigen kam", "tokens": ["Da\u00df", "die", "Ko\u00b7hor\u00b7te", "ihm", "zu", "hul\u00b7di\u00b7gen", "kam"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPER", "PTKZU", "VVINF", "VVFIN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.28": {"text": "Und ihn zum K\u00f6nige zu werben.", "tokens": ["Und", "ihn", "zum", "K\u00f6\u00b7ni\u00b7ge", "zu", "wer\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Er lie\u00df sich erst ein wenig bitten", "tokens": ["Er", "lie\u00df", "sich", "erst", "ein", "we\u00b7nig", "bit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ART", "PIS", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Und sprach, es sei nicht eben leichte B\u00fcrde;", "tokens": ["Und", "sprach", ",", "es", "sei", "nicht", "e\u00b7ben", "leich\u00b7te", "B\u00fcr\u00b7de", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPER", "VAFIN", "PTKNEG", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.31": {"text": "Mit gleichem Wort hat Sixtus es gelitten,", "tokens": ["Mit", "glei\u00b7chem", "Wort", "hat", "Six\u00b7tus", "es", "ge\u00b7lit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "NE", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.32": {"text": "Da\u00df man ihm antrug Papstesw\u00fcrde.", "tokens": ["Da\u00df", "man", "ihm", "an\u00b7trug", "Paps\u00b7tes\u00b7w\u00fcr\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.33": {"text": "(wenn man mir b\u00f6te, hier auf Erden", "tokens": ["(", "wenn", "man", "mir", "b\u00f6\u00b7te", ",", "hier", "auf", "Er\u00b7den"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "KOUS", "PIS", "PPER", "VVFIN", "$,", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "Ein K\u00f6nig oder Papst zu werden,", "tokens": ["Ein", "K\u00f6\u00b7nig", "o\u00b7der", "Papst", "zu", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.35": {"text": "Ich h\u00e4tte solche Frage nicht verneint.)", "tokens": ["Ich", "h\u00e4t\u00b7te", "sol\u00b7che", "Fra\u00b7ge", "nicht", "ver\u00b7neint", ".", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "PTKNEG", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.36": {"text": "Auch jener hat sein Str\u00e4uben nicht so ernst gemeint.", "tokens": ["Auch", "je\u00b7ner", "hat", "sein", "Str\u00e4u\u00b7ben", "nicht", "so", "ernst", "ge\u00b7meint", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VAFIN", "PPOSAT", "NN", "PTKNEG", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Den Schnellbereiten nimmt das Gl\u00fcck zum Herrn!", "tokens": ["Den", "Schnell\u00b7be\u00b7rei\u00b7ten", "nimmt", "das", "Gl\u00fcck", "zum", "Herrn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.38": {"text": "Der Kluge schreite drum zur Tat,", "tokens": ["Der", "Klu\u00b7ge", "schrei\u00b7te", "drum", "zur", "Tat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PAV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.39": {"text": "Bevor die weise \u00dcberlegung naht", "tokens": ["Be\u00b7vor", "die", "wei\u00b7se", "\u00dc\u00b7ber\u00b7le\u00b7gung", "naht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.40": {"text": "Mit \u203aWenn\u2039 und \u203aAber\u2039 und mit gutem Rat \u2013", "tokens": ["Mit", "\u203a", "Wenn", "\u2039", "und", "\u203a", "A\u00b7ber", "\u2039", "und", "mit", "gu\u00b7tem", "Rat", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$(", "KOUS", "$(", "KON", "$(", "KON", "$(", "KON", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.41": {"text": "Das blinde Gl\u00fcck folgt blinder K\u00fchnheit gern.", "tokens": ["Das", "blin\u00b7de", "Gl\u00fcck", "folgt", "blin\u00b7der", "K\u00fchn\u00b7heit", "gern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}