{"dta.poem.10629": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "Sonnet vber den Thurn zu Stra\u00dfburg.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1624", "urn": "urn:nbn:de:kobv:b4-200905197859", "language": ["de:0.99"], "booktitle": "Opitz, Martin: Teutsche P\u00f6emata und: Aristarchvs Wieder die verachtung Teutscher Sprach. Stra\u00dfburg, 1624."}, "poem": {"stanza.1": {"line.1": {"text": "Printz aller hohen Th\u00fcrn/ so jemals wirdt beschawen", "tokens": ["Printz", "al\u00b7ler", "ho\u00b7hen", "Th\u00fcrn", "/", "so", "je\u00b7mals", "wirdt", "be\u00b7scha\u00b7wen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PIAT", "ADJA", "NN", "$(", "ADV", "ADV", "VAFIN", "VVINF"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Der Sonnen klarer Glantz/ vnd auch beschawet hat:", "tokens": ["Der", "Son\u00b7nen", "kla\u00b7rer", "Glantz", "/", "vnd", "auch", "be\u00b7scha\u00b7wet", "hat", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$(", "KON", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie recht/ weil Stra\u00dfburg ist dergleichen sch\u00f6ne Statt/", "tokens": ["Wie", "recht", "/", "weil", "Stra\u00df\u00b7burg", "ist", "derg\u00b7lei\u00b7chen", "sch\u00f6\u00b7ne", "Statt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$(", "KOUS", "NE", "VAFIN", "PIS", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hat man dich nur in sie alleine m\u00fcssen bawen/", "tokens": ["Hat", "man", "dich", "nur", "in", "sie", "al\u00b7lei\u00b7ne", "m\u00fcs\u00b7sen", "ba\u00b7wen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PRF", "ADV", "APPR", "PPER", "ADV", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.5": {"text": "Du rechtes Wunderwerck bist zierlich zwar gehawen/", "tokens": ["Du", "rech\u00b7tes", "Wun\u00b7der\u00b7werck", "bist", "zier\u00b7lich", "zwar", "ge\u00b7ha\u00b7wen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VAFIN", "ADJD", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.6": {"text": "Doch noch bey weitem nicht zugleichen in der That", "tokens": ["Doch", "noch", "bey", "wei\u00b7tem", "nicht", "zu\u00b7glei\u00b7chen", "in", "der", "That"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "PIS", "PTKNEG", "VVPP", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der feinen Policey/ dem weisen Recht vnd Rhat/", "tokens": ["Der", "fei\u00b7nen", "Po\u00b7li\u00b7cey", "/", "dem", "wei\u00b7sen", "Recht", "vnd", "Rhat", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "ADJA", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der grossen H\u00f6fligkeit der M\u00e4nner vnd der Frawen/", "tokens": ["Der", "gros\u00b7sen", "H\u00f6f\u00b7lig\u00b7keit", "der", "M\u00e4n\u00b7ner", "vnd", "der", "Fra\u00b7wen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "KON", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Welch\u2019 vber deine Spitz an Lobe zuerh\u00f6hen;", "tokens": ["Welch'", "vber", "dei\u00b7ne", "Spitz", "an", "Lo\u00b7be", "zu\u00b7er\u00b7h\u00f6\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "APPR", "PPOSAT", "NN", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.10": {"text": "Kein orth wirdt jrgendt je gefunden weit vnd breit/", "tokens": ["Kein", "orth", "wirdt", "jr\u00b7gendt", "je", "ge\u00b7fun\u00b7den", "weit", "vnd", "breit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADV", "VVPP", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der jhnen gleichen mag an G\u00fct\u2019 vnd Freundligkeit.", "tokens": ["Der", "jh\u00b7nen", "glei\u00b7chen", "mag", "an", "G\u00fct'", "vnd", "Freund\u00b7lig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "VMFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wie wohl gibt die Natur hiemit vns zuverstehen/", "tokens": ["Wie", "wohl", "gibt", "die", "Na\u00b7tur", "hie\u00b7mit", "vns", "zu\u00b7ver\u00b7ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "ART", "NN", "PAV", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Da\u00df/ ob gleich die Gebew mehr steinern sind/ als Stein/", "tokens": ["Da\u00df", "/", "ob", "gleich", "die", "Ge\u00b7bew", "mehr", "stei\u00b7nern", "sind", "/", "als", "Stein", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "$(", "KOUS", "ADV", "ART", "NN", "ADV", "VVINF", "VAFIN", "$(", "KOUS", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Der Menschen Hertzen doch nicht sollen steinern sein.", "tokens": ["Der", "Men\u00b7schen", "Hert\u00b7zen", "doch", "nicht", "sol\u00b7len", "stei\u00b7nern", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "PTKNEG", "VMFIN", "VVINF", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}