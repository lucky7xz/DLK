{"dta.poem.12417": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Lied beym Heuen .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1806", "urn": "urn:nbn:de:kobv:b4-20090519157", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Es hatte ein Bauer ein sch\u00f6nes Weib,               ", "tokens": ["Es", "hat\u00b7te", "ein", "Bau\u00b7er", "ein", "sch\u00f6\u00b7nes", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Die blieb so gerne zu Haus,", "tokens": ["Die", "blieb", "so", "ger\u00b7ne", "zu", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "APPR", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Sie bat oft ihren lieben Mann,", "tokens": ["Sie", "bat", "oft", "ih\u00b7ren", "lie\u00b7ben", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er sollte doch fahren hinaus,", "tokens": ["Er", "soll\u00b7te", "doch", "fah\u00b7ren", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVFIN", "PTKVZ", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Er sollte doch fahren ins Heu,", "tokens": ["Er", "soll\u00b7te", "doch", "fah\u00b7ren", "ins", "Heu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Er sollte doch fahren ins", "tokens": ["Er", "soll\u00b7te", "doch", "fah\u00b7ren", "ins"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "VVFIN", "APPRART"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Ha ha, ha; ha, ha, ha, Heidildey,", "tokens": ["Ha", "ha", ",", "ha", ";", "ha", ",", "ha", ",", "ha", ",", "Hei\u00b7dil\u00b7dey", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ITJ", "ITJ", "$,", "ITJ", "$.", "ITJ", "$,", "ITJ", "$,", "ITJ", "$,", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Juch heysasa,", "tokens": ["Juch", "hey\u00b7sa\u00b7sa", ","], "token_info": ["word", "word", "punct"], "pos": ["FM.la", "FM.la", "$,"], "meter": "OOOO", "measure": "unknown.measure.zero"}, "line.9": {"text": "Er sollte doch fahren ins Heu.", "tokens": ["Er", "soll\u00b7te", "doch", "fah\u00b7ren", "ins", "Heu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVFIN", "APPRART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.2": {"line.1": {"text": "Der Mann der dachte in seinem Sinn:", "tokens": ["Der", "Mann", "der", "dach\u00b7te", "in", "sei\u00b7nem", "Sinn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u201edie Reden die sind gut!", "tokens": ["\u201e", "die", "Re\u00b7den", "die", "sind", "gut", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "ART", "VAFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201eich will mich hinter die Hausth\u00fcr stelln,", "tokens": ["\u201e", "ich", "will", "mich", "hin\u00b7ter", "die", "Hau\u00b7sth\u00fcr", "stelln", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "PRF", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "\u201ewill sehn, was meine Frau thut,", "tokens": ["\u201e", "will", "sehn", ",", "was", "mei\u00b7ne", "Frau", "thut", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "VVINF", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "\u201ewill sagen, ich fahre ins Heu, u. s. w.", "tokens": ["\u201e", "will", "sa\u00b7gen", ",", "ich", "fah\u00b7re", "ins", "Heu", ",", "u.", "s.", "w."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "abbreviation", "abbreviation", "abbreviation"], "pos": ["$(", "VMFIN", "VVINF", "$,", "PPER", "VVFIN", "APPRART", "NN", "$,", "KON", "VVIMP", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.3": {"line.1": {"text": "Da kommt geschlichen ein Reitersknecht", "tokens": ["Da", "kommt", "ge\u00b7schli\u00b7chen", "ein", "Rei\u00b7ters\u00b7knecht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "VVPP", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zum jungen Weibe hinein,", "tokens": ["Zum", "jun\u00b7gen", "Wei\u00b7be", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Und sie umpfanget gar freundlich ihn,", "tokens": ["Und", "sie", "um\u00b7pfan\u00b7get", "gar", "freund\u00b7lich", "ihn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ADJD", "PPER", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Gab straks ihren Willen darein.", "tokens": ["Gab", "straks", "ih\u00b7ren", "Wil\u00b7len", "da\u00b7rein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "PAV", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "\u201emein Mann ist gefahren ists Heu, u. s. w.", "tokens": ["\u201e", "mein", "Mann", "ist", "ge\u00b7fah\u00b7ren", "ists", "Heu", ",", "u.", "s.", "w."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "abbreviation", "abbreviation", "abbreviation"], "pos": ["$(", "PPOSAT", "NN", "VAFIN", "VVPP", "VAFIN", "NN", "$,", "KON", "VVIMP", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.4": {"line.1": {"text": "Er fa\u00dfte sie um ihr G\u00fcrtelband,", "tokens": ["Er", "fa\u00df\u00b7te", "sie", "um", "ihr", "G\u00fcr\u00b7tel\u00b7band", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und schwang sie wohl hin und her,", "tokens": ["Und", "schwang", "sie", "wohl", "hin", "und", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der Mann, der hinter der Hausth\u00fcr stand,", "tokens": ["Der", "Mann", ",", "der", "hin\u00b7ter", "der", "Hau\u00b7sth\u00fcr", "stand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ganz zornig da trat herf\u00fcr:", "tokens": ["Ganz", "zor\u00b7nig", "da", "trat", "her\u00b7f\u00fcr", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "\u201eich bin noch nicht fahren ins Heu, u. s. w.", "tokens": ["\u201e", "ich", "bin", "noch", "nicht", "fah\u00b7ren", "ins", "Heu", ",", "u.", "s.", "w."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "abbreviation", "abbreviation", "abbreviation"], "pos": ["$(", "PPER", "VAFIN", "ADV", "PTKNEG", "VVINF", "APPRART", "NN", "$,", "KON", "VVIMP", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.5": {"line.1": {"text": "\u201each trauter herzallerliebster Mann,", "tokens": ["\u201e", "ach", "trau\u00b7ter", "her\u00b7zal\u00b7ler\u00b7liebs\u00b7ter", "Mann", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJD", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u201evergieb mir nur diesen Fehl,", "tokens": ["\u201e", "ver\u00b7gieb", "mir", "nur", "die\u00b7sen", "Fehl", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "ADV", "PDAT", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u201ewill lieben f\u00fcrbas und herzen dich,", "tokens": ["\u201e", "will", "lie\u00b7ben", "f\u00fcr\u00b7bas", "und", "her\u00b7zen", "dich", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "VVINF", "VVFIN", "KON", "VVFIN", "PPER", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u201ewill kochen s\u00fc\u00df Muhs und Mehl;", "tokens": ["\u201e", "will", "ko\u00b7chen", "s\u00fc\u00df", "Muhs", "und", "Mehl", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "VVINF", "VVFIN", "NE", "KON", "NN", "$."], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}, "line.5": {"text": "\u201eich dachte du w\u00e4rest ins Heu, u. s. w.", "tokens": ["\u201e", "ich", "dach\u00b7te", "du", "w\u00e4\u00b7rest", "ins", "Heu", ",", "u.", "s.", "w."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "abbreviation", "abbreviation", "abbreviation"], "pos": ["$(", "PPER", "VVFIN", "PPER", "VAFIN", "APPRART", "NN", "$,", "KON", "VVIMP", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.6": {"line.1": {"text": "\u201eund wenn ich gleich gefahren w\u00e4r", "tokens": ["\u201e", "und", "wenn", "ich", "gleich", "ge\u00b7fah\u00b7ren", "w\u00e4r"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KON", "KOUS", "PPER", "ADV", "VVPP", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eins Heu und Haberstroh,", "tokens": ["\u201e", "ins", "Heu", "und", "Ha\u00b7bers\u00b7troh", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPRART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201eso sollt du nun und nimmermehr", "tokens": ["\u201e", "so", "sollt", "du", "nun", "und", "nim\u00b7mer\u00b7mehr"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VMFIN", "PPER", "ADV", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eeinen andern lieben also,", "tokens": ["\u201e", "ei\u00b7nen", "an\u00b7dern", "lie\u00b7ben", "al\u00b7so", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "\u201eder Teufel mag fahren ins Heu, u. s. w.", "tokens": ["\u201e", "der", "Teu\u00b7fel", "mag", "fah\u00b7ren", "ins", "Heu", ",", "u.", "s.", "w."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "abbreviation", "abbreviation", "abbreviation"], "pos": ["$(", "ART", "NN", "VMFIN", "VVINF", "APPRART", "NN", "$,", "KON", "VVIMP", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.7": {"line.1": {"text": "Und wer euch dies neue Liedlein pfif,", "tokens": ["Und", "wer", "euch", "dies", "neu\u00b7e", "Lied\u00b7lein", "pfif", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "PDS", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Der mu\u00df es singen gar oft,", "tokens": ["Der", "mu\u00df", "es", "sin\u00b7gen", "gar", "oft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Es war der junge Reitersknecht,", "tokens": ["Es", "war", "der", "jun\u00b7ge", "Rei\u00b7ters\u00b7knecht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er liegt auf Grasung im Hof,", "tokens": ["Er", "liegt", "auf", "Gra\u00b7sung", "im", "Hof", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "APPRART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Er fuhr auch manchmal ins Heu, u. s. w.", "tokens": ["Er", "fuhr", "auch", "manch\u00b7mal", "ins", "Heu", ",", "u.", "s.", "w."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "abbreviation", "abbreviation", "abbreviation"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPRART", "NN", "$,", "KON", "VVIMP", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}}}}