{"textgrid.poem.32992": {"metadata": {"author": {"name": "Flaischlen, C\u00e4sar", "birth": "N.A.", "death": "N.A."}, "title": "1L: O ja, wir ", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O ja, wir ", "tokens": ["O", "ja", ",", "wir"], "token_info": ["word", "word", "punct", "word"], "pos": ["ITJ", "ITJ", "$,", "PPER"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Narren und Schw\u00e4rmer", "tokens": ["Nar\u00b7ren", "und", "Schw\u00e4r\u00b7mer"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "und kindert\u00f6richte Toren ...", "tokens": ["und", "kin\u00b7der\u00b7t\u00f6\u00b7rich\u00b7te", "To\u00b7ren", "..."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "ihr habt recht!", "tokens": ["ihr", "habt", "recht", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "wir sind es! ...", "tokens": ["wir", "sind", "es", "!", "..."], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "PPER", "$.", "$("], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "unsern Tr\u00e4umen nachzuh\u00e4ngen", "tokens": ["un\u00b7sern", "Tr\u00e4u\u00b7men", "nach\u00b7zu\u00b7h\u00e4n\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "und unsere Kraft an Dinge zu vertr\u00f6deln,", "tokens": ["und", "un\u00b7se\u00b7re", "Kraft", "an", "Din\u00b7ge", "zu", "ver\u00b7tr\u00f6\u00b7deln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "so wert- und zwecklos!", "tokens": ["so", "wer\u00b7t", "und", "zweck\u00b7los", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "TRUNC", "KON", "ADJD", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.9": {"text": "ihr habt recht! ...", "tokens": ["ihr", "habt", "recht", "!", "..."], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$.", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "anstatt praktisch zu sein", "tokens": ["an\u00b7statt", "prak\u00b7tisch", "zu", "sein"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "ADJD", "PTKZU", "VAINF"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.11": {"text": "und Geld zu verdienen!", "tokens": ["und", "Geld", "zu", "ver\u00b7die\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.12": {"text": "oder ... wenn schon:", "tokens": ["o\u00b7der", "...", "wenn", "schon", ":"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["KON", "$(", "KOUS", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.13": {"text": "B\u00fccher zu schreiben,", "tokens": ["B\u00fc\u00b7cher", "zu", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.14": {"text": "wie der Verleger will,", "tokens": ["wie", "der", "Ver\u00b7le\u00b7ger", "will", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VMFIN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.15": {"text": "und wie sie gekauft werden ...", "tokens": ["und", "wie", "sie", "ge\u00b7kauft", "wer\u00b7den", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VVPP", "VAINF", "$."], "meter": "-+--++-", "measure": "iambic.tri.relaxed"}, "line.16": {"text": "ihr habt recht:", "tokens": ["ihr", "habt", "recht", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.17": {"text": "es ist Narrheit,", "tokens": ["es", "ist", "Nar\u00b7rheit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.18": {"text": "sich seine Jugend derart zu verqu\u00e4len", "tokens": ["sich", "sei\u00b7ne", "Ju\u00b7gend", "der\u00b7art", "zu", "ver\u00b7qu\u00e4\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PRF", "PPOSAT", "NN", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "und freiwillig", "tokens": ["und", "frei\u00b7wil\u00b7lig"], "token_info": ["word", "word"], "pos": ["KON", "ADJD"], "meter": "-++-", "measure": "unknown.measure.di"}, "line.20": {"text": "als Bettler sich durch's Leben zu schlagen,", "tokens": ["als", "Bett\u00b7ler", "sich", "durch's", "Le\u00b7ben", "zu", "schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PRF", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "und in den besten Jahren dann", "tokens": ["und", "in", "den", "bes\u00b7ten", "Jah\u00b7ren", "dann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "gebrochen und m\u00fcde zu sein,", "tokens": ["ge\u00b7bro\u00b7chen", "und", "m\u00fc\u00b7de", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.23": {"text": "ersch\u00f6pft und leer!", "tokens": ["er\u00b7sch\u00f6pft", "und", "leer", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.24": {"text": "und ... gebrochen ... wodurch?", "tokens": ["und", "...", "ge\u00b7bro\u00b7chen", "...", "wo\u00b7durch", "?"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "$(", "VVPP", "$(", "PWAV", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.25": {"text": "und ... m\u00fcde ... wovon? ...", "tokens": ["und", "...", "m\u00fc\u00b7de", "...", "wo\u00b7von", "?", "..."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["KON", "$(", "ADJD", "$(", "PWAV", "$.", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.26": {"text": "von nichts!! ...", "tokens": ["von", "nichts", "!!", "..."], "token_info": ["word", "word", "punct", "punct"], "pos": ["APPR", "PIS", "$.", "$("], "meter": "-+", "measure": "iambic.single"}, "line.27": {"text": "und mit verflackerndem Auge", "tokens": ["und", "mit", "ver\u00b7fla\u00b7ckern\u00b7dem", "Au\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.28": {"text": "zur\u00fcckzusehn", "tokens": ["zu\u00b7r\u00fcck\u00b7zu\u00b7sehn"], "token_info": ["word"], "pos": ["VVINF"], "meter": "-+-+", "measure": "iambic.di"}, "line.29": {"text": "und sich sagen zu m\u00fcssen,", "tokens": ["und", "sich", "sa\u00b7gen", "zu", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "VVINF", "PTKZU", "VMINF", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.30": {"text": "da\u00df alles M\u00fchn und alles Ringen,", "tokens": ["da\u00df", "al\u00b7les", "M\u00fchn", "und", "al\u00b7les", "Rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "KON", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "da\u00df aller Kampf ... umsonst war!", "tokens": ["da\u00df", "al\u00b7ler", "Kampf", "...", "um\u00b7sonst", "war", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "$(", "ADV", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.32": {"text": "und nicht blo\u00df umsonst,", "tokens": ["und", "nicht", "blo\u00df", "um\u00b7sonst", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "ADV", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.33": {"text": "da\u00df es l\u00e4cherlich war:", "tokens": ["da\u00df", "es", "l\u00e4\u00b7cher\u00b7lich", "war", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.34": {"text": "t\u00f6richter Tr\u00e4ume wegen", "tokens": ["t\u00f6\u00b7rich\u00b7ter", "Tr\u00e4u\u00b7me", "we\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "APPR"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.35": {"text": "sein bestes Leben lang sich", "tokens": ["sein", "bes\u00b7tes", "Le\u00b7ben", "lang", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "ADJD", "PRF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.36": {"text": "von der Gnade anderer abh\u00e4ngig zu machen", "tokens": ["von", "der", "Gna\u00b7de", "an\u00b7de\u00b7rer", "ab\u00b7h\u00e4n\u00b7gig", "zu", "ma\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "ADJD", "PTKZU", "VVINF"], "meter": "--+-+--+---+-", "measure": "iambic.tetra.relaxed"}, "line.37": {"text": "anstatt ... anstatt ...", "tokens": ["an\u00b7statt", "...", "an\u00b7statt", "..."], "token_info": ["word", "punct", "word", "punct"], "pos": ["KOUI", "$(", "KOUI", "$("], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.2": {"line.1": {"text": "anstatt ...", "tokens": ["an\u00b7statt", "..."], "token_info": ["word", "punct"], "pos": ["KOUI", "$("], "meter": "+-", "measure": "trochaic.single"}}, "stanza.3": {"line.1": {"text": "und doch ... und doch:", "tokens": ["und", "doch", "...", "und", "doch", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "KON", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "nur Starke k\u00f6nnen solche Narren sein!", "tokens": ["nur", "Star\u00b7ke", "k\u00f6n\u00b7nen", "sol\u00b7che", "Nar\u00b7ren", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VMFIN", "PIAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}