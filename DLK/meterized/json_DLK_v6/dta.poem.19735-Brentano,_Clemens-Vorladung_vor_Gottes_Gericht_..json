{"dta.poem.19735": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Vorladung vor Gottes Gericht .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1808", "urn": "urn:nbn:de:kobv:b4-20090519168", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Es sprach eine Mutter zu ihrem Sohn:               ", "tokens": ["Es", "sprach", "ei\u00b7ne", "Mut\u00b7ter", "zu", "ih\u00b7rem", "Sohn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "\u201emust heirathen, was sagst du dazu,", "tokens": ["\u201e", "must", "hei\u00b7ra\u00b7then", ",", "was", "sagst", "du", "da\u00b7zu", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "VVINF", "$,", "PWS", "VVFIN", "PPER", "PAV", "$,"], "meter": "+----+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "\u201edu must eine andre heirathen,", "tokens": ["\u201e", "du", "must", "ei\u00b7ne", "and\u00b7re", "hei\u00b7ra\u00b7then", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "ART", "ADJA", "VVINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "\u201edein feines Lieb must du nun lassen.\u201c", "tokens": ["\u201e", "dein", "fei\u00b7nes", "Lieb", "must", "du", "nun", "las\u00b7sen", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "ADJA", "NN", "VMFIN", "PPER", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "\u201each nein, ach nein, das kann nicht seyn,", "tokens": ["\u201e", "ach", "nein", ",", "ach", "nein", ",", "das", "kann", "nicht", "seyn", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PTKANT", "$,", "XY", "PTKANT", "$,", "PDS", "VMFIN", "PTKNEG", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eda\u00df ich mu\u00df scheiden von meinem Sch\u00e4tzelein,", "tokens": ["\u201e", "da\u00df", "ich", "mu\u00df", "schei\u00b7den", "von", "mei\u00b7nem", "Sch\u00e4t\u00b7zel\u00b7ein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "VMFIN", "VVINF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "\u201ewir haben einander genommen,", "tokens": ["\u201e", "wir", "ha\u00b7ben", "ein\u00b7an\u00b7der", "ge\u00b7nom\u00b7men", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "\u201ek\u00f6nnen nicht mehr von einander kommen.\u201c", "tokens": ["\u201e", "k\u00f6n\u00b7nen", "nicht", "mehr", "von", "ein\u00b7an\u00b7der", "kom\u00b7men", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VMFIN", "PTKNEG", "ADV", "APPR", "PRF", "VVINF", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "\u201ehabest du genommen, wen du willt,", "tokens": ["\u201e", "ha\u00b7best", "du", "ge\u00b7nom\u00b7men", ",", "wen", "du", "willt", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "VVPP", "$,", "PWS", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "\u201edu bist mein Kind und folgest mir nit?\u201c", "tokens": ["\u201e", "du", "bist", "mein", "Kind", "und", "fol\u00b7gest", "mir", "nit", "?", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "PPOSAT", "NN", "KON", "VVFIN", "PPER", "PTKNEG", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Ey Mutter, jezt will ich dir folgen,", "tokens": ["Ey", "Mut\u00b7ter", ",", "jezt", "will", "ich", "dir", "fol\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "ADV", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ey geh es mir, wie es auch wolle.", "tokens": ["Ey", "geh", "es", "mir", ",", "wie", "es", "auch", "wol\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PPER", "$,", "PWAV", "PPER", "ADV", "VMFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.4": {"line.1": {"text": "Und da es war am Hochzeittag,", "tokens": ["Und", "da", "es", "war", "am", "Hoch\u00b7zeit\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VAFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und alle Leut so lustig warn,", "tokens": ["Und", "al\u00b7le", "Leut", "so", "lus\u00b7tig", "warn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der gute Gesell war so betr\u00fcbet", "tokens": ["Der", "gu\u00b7te", "Ge\u00b7sell", "war", "so", "be\u00b7tr\u00fc\u00b7bet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "VVFIN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von wegen seiner andern Herzliebsten.", "tokens": ["Von", "we\u00b7gen", "sei\u00b7ner", "an\u00b7dern", "Herz\u00b7liebs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Es stand nicht l\u00e4nger als drey Tage an,", "tokens": ["Es", "stand", "nicht", "l\u00e4n\u00b7ger", "als", "drey", "Ta\u00b7ge", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADJD", "KOKOM", "CARD", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der gute Gesell so t\u00f6dtlich krank war,", "tokens": ["Der", "gu\u00b7te", "Ge\u00b7sell", "so", "t\u00f6dt\u00b7lich", "krank", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADJD", "ADJD", "VAFIN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er k\u00e4m seiner Liebsten vor den Laden,", "tokens": ["Er", "k\u00e4m", "sei\u00b7ner", "Liebs\u00b7ten", "vor", "den", "La\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ein Gott beh\u00fct will er von ihr haben.", "tokens": ["Ein", "Gott", "be\u00b7h\u00fct", "will", "er", "von", "ihr", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VMFIN", "PPER", "APPR", "PPER", "VAFIN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Sie aber gab einen harten Fluch,", "tokens": ["Sie", "a\u00b7ber", "gab", "ei\u00b7nen", "har\u00b7ten", "Fluch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Davon er schon hatte zu viel und genug;", "tokens": ["Da\u00b7von", "er", "schon", "hat\u00b7te", "zu", "viel", "und", "ge\u00b7nug", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADV", "VAFIN", "PTKA", "PIS", "KON", "ADV", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Ich will ihn meinen Aeltern aufladen,", "tokens": ["Ich", "will", "ihn", "mei\u00b7nen", "A\u00b7el\u00b7tern", "auf\u00b7la\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ich will beyde aufs j\u00fcngste Gericht laden.", "tokens": ["Ich", "will", "bey\u00b7de", "aufs", "j\u00fcngs\u00b7te", "Ge\u00b7richt", "la\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+---+-+-+-", "measure": "dactylic.init"}}, "stanza.7": {"line.1": {"text": "In zweyen Monden und das werd wahr,", "tokens": ["In", "zwe\u00b7yen", "Mon\u00b7den", "und", "das", "werd", "wahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "NN", "KON", "PDS", "VAFIN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ich lad sie vor Gottes Gericht so gar.", "tokens": ["Ich", "lad", "sie", "vor", "Got\u00b7tes", "Ge\u00b7richt", "so", "gar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "NN", "ADV", "ADV", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "In zweyen Monden sie starben znsammen,", "tokens": ["In", "zwe\u00b7yen", "Mon\u00b7den", "sie", "star\u00b7ben", "zn\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "NN", "PPER", "VVFIN", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ihr Weinen th\u00e4t l\u00f6schen die h\u00f6llischen Flammen.", "tokens": ["Ihr", "Wei\u00b7nen", "th\u00e4t", "l\u00f6\u00b7schen", "die", "h\u00f6l\u00b7li\u00b7schen", "Flam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}}}}