{"dta.poem.10044": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Betrachtung der V\u00f6gel.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20086-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Nach dem ich mancherley Gesch\u00f6pfe schon beschrieben,", "tokens": ["Nach", "dem", "ich", "man\u00b7cher\u00b7ley", "Ge\u00b7sch\u00f6p\u00b7fe", "schon", "be\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PIAT", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kann ich nicht l\u00e4nger widerstehn", "tokens": ["Kann", "ich", "nicht", "l\u00e4n\u00b7ger", "wi\u00b7der\u00b7stehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PTKNEG", "ADJD", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Neigung, die mich l\u00e4ngst getrieben,", "tokens": ["Der", "Nei\u00b7gung", ",", "die", "mich", "l\u00e4ngst", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Von allen Thieren, die so sch\u00f6n,", "tokens": ["Von", "al\u00b7len", "Thie\u00b7ren", ",", "die", "so", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PRELS", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die sch\u00f6nst- und zierlichsten, ", "tokens": ["Die", "sch\u00f6nst", "und", "zier\u00b7lichs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "VVFIN", "$,"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.6": {"text": "Um in derselben Bau, Geschwindigkeit und Pracht,", "tokens": ["Um", "in", "der\u00b7sel\u00b7ben", "Bau", ",", "Ge\u00b7schwin\u00b7dig\u00b7keit", "und", "Pracht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "PDAT", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die Wunder Des, der sie gemacht,", "tokens": ["Die", "Wun\u00b7der", "Des", ",", "der", "sie", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mit tausend Freuden zu besingen.", "tokens": ["Mit", "tau\u00b7send", "Freu\u00b7den", "zu", "be\u00b7sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ach! la\u00df, was ich von ihrem Heer,", "tokens": ["Ach", "!", "la\u00df", ",", "was", "ich", "von", "ih\u00b7rem", "Heer", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVIMP", "$,", "PWS", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu Deines Nahmens Preis\u2019 und Ehr,", "tokens": ["Zu", "Dei\u00b7nes", "Nah\u00b7mens", "Preis'", "und", "Ehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "O Sch\u00f6pffer, schreibe, wol gelingen!", "tokens": ["O", "Sch\u00f6pf\u00b7fer", ",", "schrei\u00b7be", ",", "wol", "ge\u00b7lin\u00b7gen", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "VVFIN", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Befiedertes Gesch\u00f6pff, das mit geschwinden Schwingen", "tokens": ["Be\u00b7fie\u00b7der\u00b7tes", "Ge\u00b7sch\u00f6pff", ",", "das", "mit", "ge\u00b7schwin\u00b7den", "Schwin\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "PRELS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bald in der d\u00fcnnen Lufft, und bald in dicken W\u00e4ldern,", "tokens": ["Bald", "in", "der", "d\u00fcn\u00b7nen", "Lufft", ",", "und", "bald", "in", "di\u00b7cken", "W\u00e4l\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,", "KON", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auf hohen Zweigen bald, und bald in flachen Feldern,", "tokens": ["Auf", "ho\u00b7hen", "Zwei\u00b7gen", "bald", ",", "und", "bald", "in", "fla\u00b7chen", "Fel\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "$,", "KON", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bald schwebt, bald h\u00fcpfft, bald springt, bald fliegt,", "tokens": ["Bald", "schwebt", ",", "bald", "h\u00fcpfft", ",", "bald", "springt", ",", "bald", "fliegt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ADV", "VVFIN", "$,", "ADV", "VVFIN", "$,", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und das mit schweben, h\u00fcpffen, springen,", "tokens": ["Und", "das", "mit", "schwe\u00b7ben", ",", "h\u00fcpf\u00b7fen", ",", "sprin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "PDS", "APPR", "VVINF", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Mit raschem fliegen, hellem singen,", "tokens": ["Mit", "ra\u00b7schem", "flie\u00b7gen", ",", "hel\u00b7lem", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VVINF", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Sowol sich selbst, als uns vergn\u00fcgt;", "tokens": ["So\u00b7wol", "sich", "selbst", ",", "als", "uns", "ver\u00b7gn\u00fcgt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ADV", "$,", "KOUS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Du zeigest der Vernunft, die dich betrachtet,", "tokens": ["Du", "zei\u00b7gest", "der", "Ver\u00b7nunft", ",", "die", "dich", "be\u00b7trach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Und auf dein sonderlich gebildet Wesen achtet,", "tokens": ["Und", "auf", "dein", "son\u00b7der\u00b7lich", "ge\u00b7bil\u00b7det", "We\u00b7sen", "ach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "ADJD", "VVPP", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ein neues Feld voll Wunder, voller Macht,", "tokens": ["Ein", "neu\u00b7es", "Feld", "voll", "Wun\u00b7der", ",", "vol\u00b7ler", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Und voller Weisheit Des, der dich hervor gebracht.", "tokens": ["Und", "vol\u00b7ler", "Weis\u00b7heit", "Des", ",", "der", "dich", "her\u00b7vor", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ART", "$,", "PRELS", "PPER", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wie Bluhmen f\u00fcr die Nas\u2019, und gleichfalls f\u00fcrs Gesicht,", "tokens": ["Wie", "Bluh\u00b7men", "f\u00fcr", "die", "Nas'", ",", "und", "gleich\u00b7falls", "f\u00fcrs", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "ART", "NN", "$,", "KON", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bewunderns-w\u00fcrdig zugericht\u2019t;", "tokens": ["Be\u00b7wun\u00b7derns\u00b7w\u00fcr\u00b7dig", "zu\u00b7ge\u00b7richt't", ";"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So scheint der V\u00f6gel Schaar f\u00fcr Augen und f\u00fcr Ohren", "tokens": ["So", "scheint", "der", "V\u00f6\u00b7gel", "Schaar", "f\u00fcr", "Au\u00b7gen", "und", "f\u00fcr", "Oh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Recht eigentlich erschaffen und erkohren.", "tokens": ["Recht", "ei\u00b7gent\u00b7lich", "er\u00b7schaf\u00b7fen", "und", "er\u00b7koh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVPP", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Wer kann die zierliche Figur,", "tokens": ["Wer", "kann", "die", "zier\u00b7li\u00b7che", "Fi\u00b7gur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Farben Glantz, dein schnell Gefieder,", "tokens": ["Der", "Far\u00b7ben", "Glantz", ",", "dein", "schnell", "Ge\u00b7fie\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Hurtigkeit der leichten Glieder,", "tokens": ["Die", "Hur\u00b7tig\u00b7keit", "der", "leich\u00b7ten", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bewunderns-wehrte Creatur,", "tokens": ["Be\u00b7wun\u00b7derns\u00b7wehr\u00b7te", "Crea\u00b7tur", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Ohn\u2019 Anmuth, ohne Freude sehn?", "tokens": ["Ohn'", "An\u00b7muth", ",", "oh\u00b7ne", "Freu\u00b7de", "sehn", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "KOUI", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Wann sie sich schnell durch d\u00fcnne L\u00fcffte schwingen,", "tokens": ["Wann", "sie", "sich", "schnell", "durch", "d\u00fcn\u00b7ne", "L\u00fcff\u00b7te", "schwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADJD", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Recht wie ein Pfeil durch dichte Bl\u00e4tter dringen;", "tokens": ["Recht", "wie", "ein", "Pfeil", "durch", "dich\u00b7te", "Bl\u00e4t\u00b7ter", "drin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wann sie behend und rasch von Zweig zu Zweigen springen,", "tokens": ["Wann", "sie", "be\u00b7hend", "und", "rasch", "von", "Zweig", "zu", "Zwei\u00b7gen", "sprin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADJD", "KON", "ADJD", "APPR", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Mit schlanckem Hals\u2019 ihr kleines K\u00f6pffchen drehn,", "tokens": ["Mit", "schlan\u00b7ckem", "Hals'", "ihr", "klei\u00b7nes", "K\u00f6pffc\u00b7hen", "drehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Durch Str\u00e4ucher schlupffen, schweben, fliegen,", "tokens": ["Durch", "Str\u00e4u\u00b7cher", "schlupf\u00b7fen", ",", "schwe\u00b7ben", ",", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$,", "VVFIN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Mit schwancken Zweigen sich bald auf-bald abw\u00e4rts wiegen;", "tokens": ["Mit", "schwan\u00b7cken", "Zwei\u00b7gen", "sich", "bald", "auf\u00b7bald", "ab\u00b7w\u00e4rts", "wie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PRF", "ADV", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Bald auf ein steiffer Aestchen setzen,", "tokens": ["Bald", "auf", "ein", "steif\u00b7fer", "A\u00b7est\u00b7chen", "set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Jhr Schn\u00e4belchen von beiden Seiten wetzen,", "tokens": ["Ihr", "Schn\u00e4\u00b7bel\u00b7chen", "von", "bei\u00b7den", "Sei\u00b7ten", "wet\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Bald vor-bald hinterw\u00e4rts bald h\u00fcpffen, und bald stehn,", "tokens": ["Bald", "vor\u00b7bald", "hin\u00b7ter\u00b7w\u00e4rts", "bald", "h\u00fcpf\u00b7fen", ",", "und", "bald", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADV", "VVINF", "$,", "KON", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Bald an ein kleines Zweiglein hangen,", "tokens": ["Bald", "an", "ein", "klei\u00b7nes", "Zwei\u00b7glein", "han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Bald eine Flieg\u2019 im Fluge fangen;", "tokens": ["Bald", "ei\u00b7ne", "Flieg'", "im", "Flu\u00b7ge", "fan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Sich ietzt in dick verwachsne Hecken,", "tokens": ["Sich", "ietzt", "in", "dick", "ver\u00b7wachs\u00b7ne", "He\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Mit schwirrendem Gepfeiff, verstecken;", "tokens": ["Mit", "schwir\u00b7ren\u00b7dem", "Ge\u00b7pfeiff", ",", "ver\u00b7ste\u00b7cken", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Behende wieder\u00fcm erscheinen, und von neuen", "tokens": ["Be\u00b7hen\u00b7de", "wie\u00b7de\u00b7r\u00fcm", "er\u00b7schei\u00b7nen", ",", "und", "von", "neu\u00b7en"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "VVINF", "$,", "KON", "APPR", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Mit tzwitscherndem Ger\u00e4usch und tausend Gauckeleyen", "tokens": ["Mit", "tzwit\u00b7schern\u00b7dem", "Ge\u00b7r\u00e4usch", "und", "tau\u00b7send", "Gau\u00b7cke\u00b7le\u00b7yen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "CARD", "NN"], "meter": "--+--+-+-+--+", "measure": "anapaest.di.plus"}, "line.16": {"text": "So Aug\u2019 als Ohr erfreuen.", "tokens": ["So", "Aug'", "als", "Ohr", "er\u00b7freu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KOUS", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.17": {"text": "Wann, sag\u2019 ich, die\u00df ihr fl\u00fcchtig Wesen", "tokens": ["Wann", ",", "sag'", "ich", ",", "die\u00df", "ihr", "fl\u00fcch\u00b7tig", "We\u00b7sen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "VVFIN", "PPER", "$,", "PDS", "PPOSAT", "ADJD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Ein auch nicht aufger\u00e4umt Gem\u00fcth,", "tokens": ["Ein", "auch", "nicht", "auf\u00b7ge\u00b7r\u00e4umt", "Ge\u00b7m\u00fcth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PTKNEG", "VVPP", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Mit aufmercksamen Ohr- und Blicken, h\u00f6rt und sieht,", "tokens": ["Mit", "auf\u00b7merck\u00b7sa\u00b7men", "Ohr", "und", "Bli\u00b7cken", ",", "h\u00f6rt", "und", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "TRUNC", "KON", "NN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Wird es von seinem Gram genesen.", "tokens": ["Wird", "es", "von", "sei\u00b7nem", "Gram", "ge\u00b7ne\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Es wird der V\u00f6gel Munterkeit.", "tokens": ["Es", "wird", "der", "V\u00f6\u00b7gel", "Mun\u00b7ter\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Jhr frohes h\u00fcpffen, schertzen, springen,", "tokens": ["Ihr", "fro\u00b7hes", "h\u00fcpf\u00b7fen", ",", "schert\u00b7zen", ",", "sprin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJA", "VVINF", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Jhr helles, Sorgen-freyes singen,", "tokens": ["Ihr", "hel\u00b7les", ",", "Sor\u00b7gen\u00b7freyes", "sin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "$,", "NN", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.24": {"text": "Fast wider seinen Willen, ihn", "tokens": ["Fast", "wi\u00b7der", "sei\u00b7nen", "Wil\u00b7len", ",", "ihn"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$,", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Aus seiner tieffen Schwehrmuth ziehn.", "tokens": ["Aus", "sei\u00b7ner", "tief\u00b7fen", "Schwehr\u00b7muth", "ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Zumahl wann er dabey gedencket,", "tokens": ["Zu\u00b7mahl", "wann", "er", "da\u00b7bey", "ge\u00b7den\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWAV", "PPER", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Da\u00df, Der den V\u00f6geln Nahrung schencket,", "tokens": ["Da\u00df", ",", "Der", "den", "V\u00f6\u00b7geln", "Nah\u00b7rung", "schen\u00b7cket", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "ART", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "F\u00fcr ihn auch, hier auf dieser Erde,", "tokens": ["F\u00fcr", "ihn", "auch", ",", "hier", "auf", "die\u00b7ser", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "$,", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Schon f\u00fcr die Nothdurft sorgen werde.", "tokens": ["Schon", "f\u00fcr", "die", "Noth\u00b7durft", "sor\u00b7gen", "wer\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Ach m\u00f6gt\u2019 auf diese Weis\u2019 ein iedes V\u00f6gelein,", "tokens": ["Ach", "m\u00f6gt'", "auf", "die\u00b7se", "Weis'", "ein", "ie\u00b7des", "V\u00f6\u00b7ge\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "APPR", "PDAT", "NN", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Mein Leser, dir und mir ein lehrend Beyspiel seyn!", "tokens": ["Mein", "Le\u00b7ser", ",", "dir", "und", "mir", "ein", "leh\u00b7rend", "Bey\u00b7spiel", "seyn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPER", "KON", "PPER", "ART", "ADJD", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Erweget ferner noch, geliebte Menschen, hier", "tokens": ["Er\u00b7we\u00b7get", "fer\u00b7ner", "noch", ",", "ge\u00b7lieb\u00b7te", "Men\u00b7schen", ",", "hier"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["VVFIN", "ADV", "ADV", "$,", "ADJA", "NN", "$,", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der V\u00f6gel Form und Flug mit mir.", "tokens": ["Der", "V\u00f6\u00b7gel", "Form", "und", "Flug", "mit", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der kleine C\u00f6rper ist fast einem Schiffchen gleich,", "tokens": ["Der", "klei\u00b7ne", "C\u00f6r\u00b7per", "ist", "fast", "ei\u00b7nem", "Schiff\u00b7chen", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Woran der Schwantz das Steur, die Fl\u00fcgel Ruder sind.", "tokens": ["Wo\u00b7ran", "der", "Schwantz", "das", "Steur", ",", "die", "Fl\u00fc\u00b7gel", "Ru\u00b7der", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "$,", "ART", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mit diesen theilen sie den Wind,", "tokens": ["Mit", "die\u00b7sen", "thei\u00b7len", "sie", "den", "Wind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und schwimmen durch der L\u00fcffte Reich.", "tokens": ["Und", "schwim\u00b7men", "durch", "der", "L\u00fcff\u00b7te", "Reich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die\u00df Flug-Werck zeiget uns so viele Wunder an,", "tokens": ["Die\u00df", "Flug\u00b7\u00b7Werck", "zei\u00b7get", "uns", "so", "vie\u00b7le", "Wun\u00b7der", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVFIN", "PPER", "ADV", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df man das Werck-Zeug nie genug bewundern kann.", "tokens": ["Da\u00df", "man", "das", "Wer\u00b7ck\u00b7Zeug", "nie", "ge\u00b7nug", "be\u00b7wun\u00b7dern", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.8": {"line.1": {"text": "Da\u00df sie die Fl\u00fcgel nicht von forn-nach hinten biegen,", "tokens": ["Da\u00df", "sie", "die", "Fl\u00fc\u00b7gel", "nicht", "von", "forn\u00b7nach", "hin\u00b7ten", "bie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "APPR", "NE", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie man die Ruder braucht; wol aber, wann sie fliegen,", "tokens": ["Wie", "man", "die", "Ru\u00b7der", "braucht", ";", "wol", "a\u00b7ber", ",", "wann", "sie", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "VVFIN", "$.", "ADV", "ADV", "$,", "PWAV", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Von oben unterw\u00e4rts, ist zu bewundern wehrt:", "tokens": ["Von", "o\u00b7ben", "un\u00b7ter\u00b7w\u00e4rts", ",", "ist", "zu", "be\u00b7wun\u00b7dern", "wehrt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "$,", "VAFIN", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weil sie dadurch nicht nur die d\u00fcnnen L\u00fcffte spalten,", "tokens": ["Weil", "sie", "da\u00b7durch", "nicht", "nur", "die", "d\u00fcn\u00b7nen", "L\u00fcff\u00b7te", "spal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PAV", "PTKNEG", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nein, auch zugleich dadurch sich in der H\u00f6he halten.", "tokens": ["Nein", ",", "auch", "zu\u00b7gleich", "da\u00b7durch", "sich", "in", "der", "H\u00f6\u00b7he", "hal\u00b7ten", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "ADV", "PAV", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Damit sie weniger in ihrer Fahrt beschwehrt,", "tokens": ["Da\u00b7mit", "sie", "we\u00b7ni\u00b7ger", "in", "ih\u00b7rer", "Fahrt", "be\u00b7schwehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hat ihnen die Natur, \u00fcm fertiger zu schweben,", "tokens": ["Hat", "ih\u00b7nen", "die", "Na\u00b7tur", ",", "\u00fcm", "fer\u00b7ti\u00b7ger", "zu", "schwe\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$,", "APPRART", "ADJA", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Fl\u00fcgel untern Theil recht ausgeh\u00f6hlt gegeben,", "tokens": ["Der", "Fl\u00fc\u00b7gel", "un\u00b7tern", "Theil", "recht", "aus\u00b7ge\u00b7h\u00f6hlt", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "ADJD", "VVPP", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den obern aber rund, und halb gew\u00f6lbt, formirt;", "tokens": ["Den", "o\u00b7bern", "a\u00b7ber", "rund", ",", "und", "halb", "ge\u00b7w\u00f6lbt", ",", "for\u00b7mirt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "ADJD", "$,", "KON", "ADJD", "VVPP", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Damit sie oberw\u00e4rts leicht durch die Lufft gef\u00fchrt,", "tokens": ["Da\u00b7mit", "sie", "o\u00b7berw\u00b7\u00e4rts", "leicht", "durch", "die", "Lufft", "ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und ohne Wiederstand sich fertig aufw\u00e4rts ziehn,", "tokens": ["Und", "oh\u00b7ne", "Wie\u00b7der\u00b7stand", "sich", "fer\u00b7tig", "auf\u00b7w\u00e4rts", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "PRF", "ADJD", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Hingegen unterw\u00e4rts viel Lufft zusammen fassen,", "tokens": ["Hin\u00b7ge\u00b7gen", "un\u00b7ter\u00b7w\u00e4rts", "viel", "Lufft", "zu\u00b7sam\u00b7men", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "NN", "ADV", "VVINF", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.8": {"text": "Und dadurch von der Lufft sich k\u00f6nnten tragen lassen.", "tokens": ["Und", "da\u00b7durch", "von", "der", "Lufft", "sich", "k\u00f6nn\u00b7ten", "tra\u00b7gen", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "APPR", "ART", "NN", "PRF", "VMFIN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Das kleinste Theil ist nur am C\u00f6rper fest,", "tokens": ["Das", "kleins\u00b7te", "Theil", "ist", "nur", "am", "C\u00f6r\u00b7per", "fest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Wodurch er sich noch st\u00e4rcker schwingen l\u00e4sst.", "tokens": ["Wo\u00b7durch", "er", "sich", "noch", "st\u00e4r\u00b7cker", "schwin\u00b7gen", "l\u00e4sst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADV", "ADJD", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Betrachten wir der Fittigen Figur,", "tokens": ["Be\u00b7trach\u00b7ten", "wir", "der", "Fit\u00b7ti\u00b7gen", "Fi\u00b7gur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Krafft, Wesen und Gebrauch, mein GOtt! wie zeiget sich", "tokens": ["Krafft", ",", "We\u00b7sen", "und", "Ge\u00b7brauch", ",", "mein", "Gott", "!", "wie", "zei\u00b7get", "sich"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,", "PPOSAT", "NN", "$.", "PWAV", "VVFIN", "PRF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "In diesem Werck-Zeug die Natur", "tokens": ["In", "die\u00b7sem", "Wer\u00b7ck\u00b7Zeug", "die", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "So k\u00fcnst- und so verwunderlich!", "tokens": ["So", "k\u00fcnst", "und", "so", "ver\u00b7wun\u00b7der\u00b7lich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "TRUNC", "KON", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie m\u00fcssen ", "tokens": ["Sie", "m\u00fcs\u00b7sen"], "token_info": ["word", "word"], "pos": ["PPER", "VMFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Damit der Vogel k\u00f6nnte fliegen;", "tokens": ["Da\u00b7mit", "der", "Vo\u00b7gel", "k\u00f6nn\u00b7te", "flie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NE", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und sie sind ", "tokens": ["Und", "sie", "sind"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPER", "VAFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "Das recht mit grossem Flei\u00df zu diesem Werck erlesen;", "tokens": ["Das", "recht", "mit", "gros\u00b7sem", "Flei\u00df", "zu", "die\u00b7sem", "Werck", "er\u00b7le\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "ADJA", "NN", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Weil dessen Dehnungs-Krafft die Eigenschafft ihr bringt,", "tokens": ["Weil", "des\u00b7sen", "Deh\u00b7nungs\u00b7Krafft", "die", "Ei\u00b7gen\u00b7schafft", "ihr", "bringt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRELAT", "NN", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da\u00df sie von selbst gerade wieder springt.", "tokens": ["Da\u00df", "sie", "von", "selbst", "ge\u00b7ra\u00b7de", "wie\u00b7der", "springt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADV", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Damit sie auch im Flug den Vogel nicht beschweren,", "tokens": ["Da\u00b7mit", "sie", "auch", "im", "Flug", "den", "Vo\u00b7gel", "nicht", "be\u00b7schwe\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "NN", "ART", "NE", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "So sind sie ", "tokens": ["So", "sind", "sie"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.11": {"line.1": {"text": "An einem ieden Feder-Kiel", "tokens": ["An", "ei\u00b7nem", "ie\u00b7den", "Fe\u00b7der\u00b7Kiel"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erblicket man unzehlig viel", "tokens": ["Er\u00b7bli\u00b7cket", "man", "un\u00b7zeh\u00b7lig", "viel"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ADJD", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Noch immer mehr verkleinter Federn Spitzen,", "tokens": ["Noch", "im\u00b7mer", "mehr", "ver\u00b7klein\u00b7ter", "Fe\u00b7dern", "Spit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Schuppen-weis\u2019 in sich vereinet sitzen;", "tokens": ["Die", "Schup\u00b7pen\u00b7weis'", "in", "sich", "ver\u00b7ei\u00b7net", "sit\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PRF", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wodurch die Lufft sich nicht vermag zu drengen,", "tokens": ["Wo\u00b7durch", "die", "Lufft", "sich", "nicht", "ver\u00b7mag", "zu", "dren\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PRF", "PTKNEG", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So da\u00df sie in der Lufft dadurch bequemer h\u00e4ngen.", "tokens": ["So", "da\u00df", "sie", "in", "der", "Lufft", "da\u00b7durch", "be\u00b7que\u00b7mer", "h\u00e4n\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "APPR", "ART", "NN", "PAV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "In iedem Z\u00e4serchen, wenn man es wol beachtet,", "tokens": ["In", "ie\u00b7dem", "Z\u00e4\u00b7ser\u00b7chen", ",", "wenn", "man", "es", "wol", "be\u00b7ach\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "KOUS", "PIS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und durch ein Gr\u00f6\u00dfrungs-Glas dasselbige betrachtet,", "tokens": ["Und", "durch", "ein", "Gr\u00f6\u00df\u00b7rungs\u00b7Glas", "das\u00b7sel\u00b7bi\u00b7ge", "be\u00b7trach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Trifft man,", "tokens": ["Trifft", "man", ","], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.10": {"text": "Mit fast erstauntem Aug\u2019, ein\u2019 eigne Feder an,", "tokens": ["Mit", "fast", "er\u00b7staun\u00b7tem", "Aug'", ",", "ein'", "eig\u00b7ne", "Fe\u00b7der", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die ja so sch\u00f6n gebildet und formirt.", "tokens": ["Die", "ja", "so", "sch\u00f6n", "ge\u00b7bil\u00b7det", "und", "for\u00b7mirt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADJD", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Sie ist mit ja so vielen Ecken,", "tokens": ["Sie", "ist", "mit", "ja", "so", "vie\u00b7len", "E\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADV", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Als ihre Mutter selbst, geziert.", "tokens": ["Als", "ih\u00b7re", "Mut\u00b7ter", "selbst", ",", "ge\u00b7ziert", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "$,", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Was k\u00f6nnen wir f\u00fcr Wunder mehr entdecken,", "tokens": ["Was", "k\u00f6n\u00b7nen", "wir", "f\u00fcr", "Wun\u00b7der", "mehr", "ent\u00b7de\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "APPR", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wann wir, auf welche Art die V\u00f6gel gehen, stehn,", "tokens": ["Wann", "wir", ",", "auf", "wel\u00b7che", "Art", "die", "V\u00f6\u00b7gel", "ge\u00b7hen", ",", "stehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "APPR", "PWAT", "NN", "ART", "NN", "VVINF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und auf den Zweigen sitzen, sehn.", "tokens": ["Und", "auf", "den", "Zwei\u00b7gen", "sit\u00b7zen", ",", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVINF", "$,", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es sind drey Biegungen an iedem Bein zu finden,", "tokens": ["Es", "sind", "drey", "Bie\u00b7gun\u00b7gen", "an", "ie\u00b7dem", "Bein", "zu", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "CARD", "NN", "APPR", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die sich mit einer Nerv\u2019 auf solche Art verbinden,", "tokens": ["Die", "sich", "mit", "ei\u00b7ner", "Ner\u00b7v'", "auf", "sol\u00b7che", "Art", "ver\u00b7bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "ART", "NN", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Da\u00df, da gedachte Nerv\u2019 \u00fcm alle die drey Glieder,", "tokens": ["Da\u00df", ",", "da", "ge\u00b7dach\u00b7te", "Ner\u00b7v'", "\u00fcm", "al\u00b7le", "die", "drey", "Glie\u00b7der", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUS", "ADJA", "NN", "APPRART", "PIS", "ART", "CARD", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Von oben ab hernieder", "tokens": ["Von", "o\u00b7ben", "ab", "her\u00b7nie\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADV", "PTKVZ", "PTKVZ"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Bis \u00fcm und in die Zehe geht,", "tokens": ["Bis", "\u00fcm", "und", "in", "die", "Ze\u00b7he", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Sobald ein Vogel-Fu\u00df gerade steht,", "tokens": ["So\u00b7bald", "ein", "Vo\u00b7gel\u00b7Fu\u00df", "ge\u00b7ra\u00b7de", "steht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Die Zehe sich bequem verbreiten,", "tokens": ["Die", "Ze\u00b7he", "sich", "be\u00b7quem", "ver\u00b7brei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Und aus einander spreiten.", "tokens": ["Und", "aus", "ein\u00b7an\u00b7der", "sprei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Wann aber sich das Bein mit seinen Gliedern kr\u00fcmmt,", "tokens": ["Wann", "a\u00b7ber", "sich", "das", "Bein", "mit", "sei\u00b7nen", "Glie\u00b7dern", "kr\u00fcmmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PRF", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die Nerve sich einfolglich dehnen mu\u00df;", "tokens": ["Die", "Ner\u00b7ve", "sich", "ein\u00b7folg\u00b7lich", "deh\u00b7nen", "mu\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADJD", "PDS", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "So ziehet er den gantzen Fu\u00df,", "tokens": ["So", "zie\u00b7het", "er", "den", "gant\u00b7zen", "Fu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Nebst allen Zehen, fest zusammen:", "tokens": ["Nebst", "al\u00b7len", "Ze\u00b7hen", ",", "fest", "zu\u00b7sam\u00b7men", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Wodurch der Vogel denn verschiedne Vortheil nimmt,", "tokens": ["Wo\u00b7durch", "der", "Vo\u00b7gel", "denn", "ver\u00b7schied\u00b7ne", "Vor\u00b7theil", "nimmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NE", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die all\u2019 aus diesem Grunde stammen.", "tokens": ["Die", "all'", "aus", "die\u00b7sem", "Grun\u00b7de", "stam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Da nicht allein ein Vogel, welcher schwimmt,", "tokens": ["Da", "nicht", "al\u00b7lein", "ein", "Vo\u00b7gel", ",", "wel\u00b7cher", "schwimmt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADV", "ART", "NE", "$,", "PRELS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Ohn ein so k\u00fcnstliches Zusammenziehn,", "tokens": ["Ohn", "ein", "so", "k\u00fcnst\u00b7li\u00b7ches", "Zu\u00b7sam\u00b7men\u00b7ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Indem das Wasser forn ihm widerstehen w\u00fcrde,", "tokens": ["In\u00b7dem", "das", "Was\u00b7ser", "forn", "ihm", "wi\u00b7der\u00b7ste\u00b7hen", "w\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "PPER", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Um fort zu gehn sich w\u00fcrd\u2019 \u00fcmsonst bem\u00fchn;", "tokens": ["Um", "fort", "zu", "gehn", "sich", "w\u00fcrd'", "\u00fcm\u00b7sonst", "be\u00b7m\u00fchn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PTKVZ", "PTKZU", "VVINF", "PRF", "VAFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Nein, sondern auch an V\u00f6geln, so auf Spitzen,", "tokens": ["Nein", ",", "son\u00b7dern", "auch", "an", "V\u00f6\u00b7geln", ",", "so", "auf", "Spit\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KON", "ADV", "APPR", "NN", "$,", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Und auf der B\u00e4ume Zweigen sitzen,", "tokens": ["Und", "auf", "der", "B\u00e4u\u00b7me", "Zwei\u00b7gen", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Sind eben, weil die Beine krumm gebogen,", "tokens": ["Sind", "e\u00b7ben", ",", "weil", "die", "Bei\u00b7ne", "krumm", "ge\u00b7bo\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "KOUS", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Durch die gedehnte Nerv, die Zehe krumm gezogen;", "tokens": ["Durch", "die", "ge\u00b7dehn\u00b7te", "Nerv", ",", "die", "Ze\u00b7he", "krumm", "ge\u00b7zo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "So da\u00df dadurch der Ast,", "tokens": ["So", "da\u00df", "da\u00b7durch", "der", "Ast", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PAV", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.27": {"text": "Durch ihres C\u00f6rpers eigne Last,", "tokens": ["Durch", "ih\u00b7res", "C\u00f6r\u00b7pers", "eig\u00b7ne", "Last", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "So fest beklemmt wird, und \u00fcmfasst,", "tokens": ["So", "fest", "be\u00b7klemmt", "wird", ",", "und", "\u00fcm\u00b7fasst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "VAFIN", "$,", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Da\u00df, auch so gar im Schlaff, und gegen Sturm und Wind,", "tokens": ["Da\u00df", ",", "auch", "so", "gar", "im", "Schlaff", ",", "und", "ge\u00b7gen", "Sturm", "und", "Wind", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "ADV", "ADV", "ADV", "APPRART", "NN", "$,", "KON", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "F\u00fcr Sturtz und Fall sie sicher sind.", "tokens": ["F\u00fcr", "Sturtz", "und", "Fall", "sie", "si\u00b7cher", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "La\u00df solche Wunder doch, o Mensch, nicht aus der Acht,", "tokens": ["La\u00df", "sol\u00b7che", "Wun\u00b7der", "doch", ",", "o", "Mensch", ",", "nicht", "aus", "der", "Acht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PIAT", "NN", "ADV", "$,", "FM", "NN", "$,", "PTKNEG", "APPR", "ART", "CARD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Betrachte sie, und r\u00fchm\u2019 in ihnen Dessen Macht,", "tokens": ["Be\u00b7trach\u00b7te", "sie", ",", "und", "r\u00fchm'", "in", "ih\u00b7nen", "Des\u00b7sen", "Macht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KON", "VVFIN", "APPR", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der alle Ding\u2019 hervor gebracht.", "tokens": ["Der", "al\u00b7le", "Ding'", "her\u00b7vor", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Wann wir nun ferner \u00fcberlegen,", "tokens": ["Wann", "wir", "nun", "fer\u00b7ner", "\u00fc\u00b7berl\u00b7e\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und, in der V\u00f6gel Reich\u2019, erwegen", "tokens": ["Und", ",", "in", "der", "V\u00f6\u00b7gel", "Reich'", ",", "er\u00b7we\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "$,", "APPR", "ART", "NN", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Den wunderbaren Unterscheid", "tokens": ["Den", "wun\u00b7der\u00b7ba\u00b7ren", "Un\u00b7ter\u00b7scheid"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An Gr\u00f6sse, Zier, Beschaffenheit,", "tokens": ["An", "Gr\u00f6s\u00b7se", ",", "Zier", ",", "Be\u00b7schaf\u00b7fen\u00b7heit", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ver\u00e4ndrung, Farben, und Figur,", "tokens": ["Ver\u00b7\u00e4n\u00b7drung", ",", "Far\u00b7ben", ",", "und", "Fi\u00b7gur", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Flug, Nahrung, Wohnung und Natur;", "tokens": ["Flug", ",", "Nah\u00b7rung", ",", "Woh\u00b7nung", "und", "Na\u00b7tur", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Erstaunen wir mit Recht, weil sie fast nicht zu zehlen.", "tokens": ["Er\u00b7stau\u00b7nen", "wir", "mit", "Recht", ",", "weil", "sie", "fast", "nicht", "zu", "zeh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "$,", "KOUS", "PPER", "ADV", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Doch theilet man sie insgemein", "tokens": ["Doch", "thei\u00b7let", "man", "sie", "ins\u00b7ge\u00b7mein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIS", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "In Wasser-Feld-Haus-Raub- und Singe-V\u00f6gel ein,", "tokens": ["In", "Was\u00b7ser\u00b7Feld\u00b7Haus\u00b7Raub", "und", "Sin\u00b7ge\u00b7V\u00f6\u00b7gel", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "TRUNC", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wovon wir denn f\u00fcr ietzt nur blo\u00df die letzten wehlen.", "tokens": ["Wo\u00b7von", "wir", "denn", "f\u00fcr", "ietzt", "nur", "blo\u00df", "die", "letz\u00b7ten", "weh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "APPR", "ADV", "ADV", "ADV", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Wann uns in holder Fr\u00fchlings-Zeit,", "tokens": ["Wann", "uns", "in", "hol\u00b7der", "Fr\u00fch\u00b7lings\u00b7Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bey reiner Lufft und heiterm Wetter,", "tokens": ["Bey", "rei\u00b7ner", "Lufft", "und", "hei\u00b7term", "Wet\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein j\u00fcngst begr\u00fcnter Wald zwar Millionen Bl\u00e4tter,", "tokens": ["Ein", "j\u00fcngst", "be\u00b7gr\u00fcn\u00b7ter", "Wald", "zwar", "Mil\u00b7lion\u00b7en", "Bl\u00e4t\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "ADV", "NN", "NN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Doch noch mehr Lust und Lieblichkeit", "tokens": ["Doch", "noch", "mehr", "Lust", "und", "Lieb\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PIAT", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "In seinem gr\u00fcnen Schatten zeiget;", "tokens": ["In", "sei\u00b7nem", "gr\u00fc\u00b7nen", "Schat\u00b7ten", "zei\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wann von der kleinen S\u00e4nger Schaar", "tokens": ["Wann", "von", "der", "klei\u00b7nen", "S\u00e4n\u00b7ger", "Schaar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So mancher Zweig, bald hier bald dar,", "tokens": ["So", "man\u00b7cher", "Zweig", ",", "bald", "hier", "bald", "dar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$,", "ADV", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sich durch den schnellen Flug, und frohes H\u00fcpffen, beuget,", "tokens": ["Sich", "durch", "den", "schnel\u00b7len", "Flug", ",", "und", "fro\u00b7hes", "H\u00fcpf\u00b7fen", ",", "beu\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PRF", "APPR", "ART", "ADJA", "NN", "$,", "KON", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Erf\u00fcllt ihr Lieder-reicher Chor", "tokens": ["Er\u00b7f\u00fcllt", "ihr", "Lie\u00b7der\u00b7rei\u00b7cher", "Chor"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und helles Gurgeln Luft und Ohr,", "tokens": ["Und", "hel\u00b7les", "Gur\u00b7geln", "Luft", "und", "Ohr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "So da\u00df vom locken, schlagen, singen", "tokens": ["So", "da\u00df", "vom", "lo\u00b7cken", ",", "schla\u00b7gen", ",", "sin\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["ADV", "KOUS", "APPRART", "VVINF", "$,", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Und zwitscherndem Ger\u00e4usch, so Berg als Thal erklingen.", "tokens": ["Und", "zwit\u00b7schern\u00b7dem", "Ge\u00b7r\u00e4usch", ",", "so", "Berg", "als", "Thal", "er\u00b7klin\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "ADV", "NN", "KOUS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Wie lieblich musicirt, und singet, GOtt zum Preise,", "tokens": ["Wie", "lieb\u00b7lich", "mu\u00b7si\u00b7cirt", ",", "und", "sin\u00b7get", ",", "Gott", "zum", "Prei\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVPP", "$,", "KON", "VVFIN", "$,", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Stieglitz, Emmerling, der H\u00e4nfling und die Meise,", "tokens": ["Der", "Stieg\u00b7litz", ",", "Em\u00b7mer\u00b7ling", ",", "der", "H\u00e4nf\u00b7ling", "und", "die", "Mei\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NE", "$,", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das Zeischen und der Finck, zumahl die Nachtigall,", "tokens": ["Das", "Zei\u00b7schen", "und", "der", "Finck", ",", "zu\u00b7mahl", "die", "Nach\u00b7ti\u00b7gall", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wann sie, mit hellerm Thon, und weit gesch\u00e4rfftern Schall,", "tokens": ["Wann", "sie", ",", "mit", "hel\u00b7lerm", "Thon", ",", "und", "weit", "ge\u00b7sch\u00e4rff\u00b7tern", "Schall", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "APPR", "ADJA", "NN", "$,", "KON", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Durchs zwitschernde Ger\u00e4usch so vieler S\u00e4nger dringet,", "tokens": ["Durchs", "zwit\u00b7schern\u00b7de", "Ge\u00b7r\u00e4usch", "so", "vie\u00b7ler", "S\u00e4n\u00b7ger", "drin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.6": {"text": "Und k\u00fcnstlicher, als alle, singet!", "tokens": ["Und", "k\u00fcnst\u00b7li\u00b7cher", ",", "als", "al\u00b7le", ",", "sin\u00b7get", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADJD", "$,", "KOUS", "PIS", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "War\u00fcm nun gl\u00e4uben wir, da\u00df sich das kleine Heer,", "tokens": ["Wa\u00b7r\u00fcm", "nun", "gl\u00e4u\u00b7ben", "wir", ",", "da\u00df", "sich", "das", "klei\u00b7ne", "Heer", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "$,", "KOUS", "PRF", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit solch unzehligen Ver\u00e4ndrung- und Manieren,", "tokens": ["Mit", "solch", "un\u00b7zeh\u00b7li\u00b7gen", "Ver\u00b7\u00e4n\u00b7drung", "und", "Ma\u00b7nie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "TRUNC", "KON", "NN", "$,"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "So lieblich, angenehm und f\u00fc\u00df zu musiciren,", "tokens": ["So", "lieb\u00b7lich", ",", "an\u00b7ge\u00b7nehm", "und", "f\u00fc\u00df", "zu", "mu\u00b7si\u00b7ci\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADJD", "KON", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit solchem Flei\u00df bestreb\u2019? Ist es ein Ungefehr,", "tokens": ["Mit", "sol\u00b7chem", "Flei\u00df", "be\u00b7streb'", "?", "Ist", "es", "ein", "Un\u00b7ge\u00b7fehr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PTKVZ", "$.", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.5": {"text": "Da\u00df sie so singen heisst? Ach nein!", "tokens": ["Da\u00df", "sie", "so", "sin\u00b7gen", "heisst", "?", "Ach", "nein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VVFIN", "$.", "NN", "PTKANT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wo wir vern\u00fcnftig seyn,", "tokens": ["Wo", "wir", "ver\u00b7n\u00fcnf\u00b7tig", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADJD", "VAINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "So kann man ja wol anders nicht gedencken,", "tokens": ["So", "kann", "man", "ja", "wol", "an\u00b7ders", "nicht", "ge\u00b7den\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "ADV", "ADV", "PTKNEG", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Als da\u00df der grosse Sch\u00f6pfer ihnen,", "tokens": ["Als", "da\u00df", "der", "gros\u00b7se", "Sch\u00f6p\u00b7fer", "ih\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "ADJA", "NN", "PPER", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Um Jhm, auf ihre Art, zu Seiner Ehr zu dienen,", "tokens": ["Um", "Jhm", ",", "auf", "ih\u00b7re", "Art", ",", "zu", "Sei\u00b7ner", "Ehr", "zu", "die\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und auch zugleich uns mit dahin zu lencken,", "tokens": ["Und", "auch", "zu\u00b7gleich", "uns", "mit", "da\u00b7hin", "zu", "len\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "PPER", "APPR", "PAV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Die Werck-Zeug, F\u00e4higkeit, und Lust dazu zu schencken,", "tokens": ["Die", "Wer\u00b7ck\u00b7Zeug", ",", "F\u00e4\u00b7hig\u00b7keit", ",", "und", "Lust", "da\u00b7zu", "zu", "schen\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,", "KON", "NN", "PAV", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Sie wehrt gehalten hat. Es kommt mir vor,", "tokens": ["Sie", "wehrt", "ge\u00b7hal\u00b7ten", "hat", ".", "Es", "kommt", "mir", "vor", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVPP", "VAFIN", "$.", "PPER", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Als ob der kleinen S\u00e4nger Chor,", "tokens": ["Als", "ob", "der", "klei\u00b7nen", "S\u00e4n\u00b7ger", "Chor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Damit er Dem Lob, Preis und Ehre gebe,", "tokens": ["Da\u00b7mit", "er", "Dem", "Lob", ",", "Preis", "und", "Eh\u00b7re", "ge\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "$,", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Durch den allein die W\u00e4lder gr\u00fcnen,", "tokens": ["Durch", "den", "al\u00b7lein", "die", "W\u00e4l\u00b7der", "gr\u00fc\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.16": {"text": "Dem alle Creaturen dienen,", "tokens": ["Dem", "al\u00b7le", "Crea\u00b7tu\u00b7ren", "die\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.17": {"text": "So s\u00fc\u00df zu singen sich bestrebe.", "tokens": ["So", "s\u00fc\u00df", "zu", "sin\u00b7gen", "sich", "be\u00b7stre\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKZU", "VVFIN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Mich deucht, kann ich gleich nicht der V\u00f6gel Sprach\u2019 er-", "tokens": ["Mich", "deucht", ",", "kann", "ich", "gleich", "nicht", "der", "V\u00f6\u00b7gel", "Sprach'", "er"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "VMFIN", "PPER", "ADV", "PTKNEG", "ART", "NN", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "In ihrem singen die\u00df zu finden:", "tokens": ["In", "ih\u00b7rem", "sin\u00b7gen", "die\u00df", "zu", "fin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "VVFIN", "PDS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "\u201ees ist blo\u00df Deine Gnad\u2019 allein,", "tokens": ["\u201e", "es", "ist", "blo\u00df", "Dei\u00b7ne", "Gnad'", "al\u00b7lein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eo HERR, da\u00df wir erschaffen seyn.", "tokens": ["\u201e", "o", "HeRR", ",", "da\u00df", "wir", "er\u00b7schaf\u00b7fen", "seyn", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "$,", "KOUS", "PPER", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201ewir k\u00f6nnen an des Fr\u00fchlings Sch\u00e4tzen", "tokens": ["\u201e", "wir", "k\u00f6n\u00b7nen", "an", "des", "Fr\u00fch\u00b7lings", "Sch\u00e4t\u00b7zen"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VMFIN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eund Lieblichkeiten uns ergetzen.", "tokens": ["\u201e", "und", "Lieb\u00b7lich\u00b7kei\u00b7ten", "uns", "er\u00b7get\u00b7zen", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "\u201eunzehlig sind die Wunder, die die Welt,", "tokens": ["\u201e", "un\u00b7zeh\u00b7lig", "sind", "die", "Wun\u00b7der", ",", "die", "die", "Welt", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "ART", "NN", "$,", "PRELS", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "\u201ezu unsrer Aumuth, in sich h\u00e4lt.", "tokens": ["\u201e", "zu", "uns\u00b7rer", "Au\u00b7muth", ",", "in", "sich", "h\u00e4lt", "."], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPOSAT", "NN", "$,", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u201emit wie so mancher Freud\u2019 und Wonne,", "tokens": ["\u201e", "mit", "wie", "so", "man\u00b7cher", "Freud'", "und", "Won\u00b7ne", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "KOKOM", "ADV", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "\u201emit wie viel Lieblichkeit und Lust", "tokens": ["\u201e", "mit", "wie", "viel", "Lieb\u00b7lich\u00b7keit", "und", "Lust"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "APPR", "KOKOM", "PIAT", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "\u201eerf\u00fcllet unsre kleine Brust", "tokens": ["\u201e", "er\u00b7f\u00fcl\u00b7let", "uns\u00b7re", "klei\u00b7ne", "Brust"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "\u201eder W\u00e4rm- und Strahlen Quell, die Sonne!", "tokens": ["\u201e", "der", "W\u00e4r\u00b7m", "und", "Strah\u00b7len", "Quell", ",", "die", "Son\u00b7ne", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "TRUNC", "KON", "NN", "NN", "$,", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.11": {"text": "\u201ewie sch\u00f6n, wie Wunder-sch\u00f6n", "tokens": ["\u201e", "wie", "sch\u00f6n", ",", "wie", "Wun\u00b7der\u00b7sch\u00f6n"], "token_info": ["punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "PWAV", "ADJD", "$,", "PWAV", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "\u201esind Erd und Himmel anzusehn!", "tokens": ["\u201e", "sind", "Erd", "und", "Him\u00b7mel", "an\u00b7zu\u00b7sehn", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "NN", "KON", "NN", "VVIZU", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "\u201eda\u00df wir so schnell die Schwingen regen,", "tokens": ["\u201e", "da\u00df", "wir", "so", "schnell", "die", "Schwin\u00b7gen", "re\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ADV", "ADJD", "ART", "NN", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eso fert- und hurtig uns bewegen,", "tokens": ["\u201e", "so", "fer\u00b7t", "und", "hur\u00b7tig", "uns", "be\u00b7we\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "TRUNC", "KON", "ADJD", "PPER", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "\u201eist einzig uns von Dir verliehn.", "tokens": ["\u201e", "ist", "ein\u00b7zig", "uns", "von", "Dir", "ver\u00b7liehn", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "ADJD", "PPER", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eso wollen wir auch, Dich zu Ehren,", "tokens": ["\u201e", "so", "wol\u00b7len", "wir", "auch", ",", "Dich", "zu", "Eh\u00b7ren", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "ADV", "$,", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "\u201eund Preis, und Ruhm, und Danck Dir zu gew\u00e4hren,", "tokens": ["\u201e", "und", "Preis", ",", "und", "Ruhm", ",", "und", "Danck", "Dir", "zu", "ge\u00b7w\u00e4h\u00b7ren", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "NN", "$,", "KON", "NN", "$,", "KON", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "\u201emit allen Kr\u00e4fften uns bem\u00fchn.", "tokens": ["\u201e", "mit", "al\u00b7len", "Kr\u00e4ff\u00b7ten", "uns", "be\u00b7m\u00fchn", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PIAT", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u201eund weil wir denn von allen Gaben", "tokens": ["\u201e", "und", "weil", "wir", "denn", "von", "al\u00b7len", "Ga\u00b7ben"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KON", "KOUS", "PPER", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "\u201enichts edlers, als die Stimmen, haben,", "tokens": ["\u201e", "nichts", "ed\u00b7lers", ",", "als", "die", "Stim\u00b7men", ",", "ha\u00b7ben", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PIS", "ADJA", "$,", "KOUS", "ART", "NN", "$,", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "\u201eso lassen wir sie denn ohn Unterla\u00df erklingen.", "tokens": ["\u201e", "so", "las\u00b7sen", "wir", "sie", "denn", "ohn", "Un\u00b7ter\u00b7la\u00df", "er\u00b7klin\u00b7gen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PPER", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u201ewir k\u00f6nnen zwar, o Sch\u00f6pfer, Deine Macht", "tokens": ["\u201e", "wir", "k\u00f6n\u00b7nen", "zwar", ",", "o", "Sch\u00f6p\u00b7fer", ",", "Dei\u00b7ne", "Macht"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "PPER", "VMFIN", "ADV", "$,", "FM", "NN", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "\u201eund Majest\u00e4t in Deiner Wercke Pracht", "tokens": ["\u201e", "und", "Ma\u00b7jes\u00b7t\u00e4t", "in", "Dei\u00b7ner", "Wer\u00b7cke", "Pracht"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KON", "NN", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "\u201enicht nach Verdienst erh\u00f6hen und besingen,", "tokens": ["\u201e", "nicht", "nach", "Ver\u00b7dienst", "er\u00b7h\u00f6\u00b7hen", "und", "be\u00b7sin\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKNEG", "APPR", "NN", "VVINF", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "\u201enoch Deiner Wunder Meng\u2019 erzehlen:", "tokens": ["\u201e", "noch", "Dei\u00b7ner", "Wun\u00b7der", "Meng'", "er\u00b7zeh\u00b7len", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PPOSAT", "NN", "NE", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "\u201edoch k\u00f6nnen wir vielleicht mit unsrer kleinen Kehlen", "tokens": ["\u201e", "doch", "k\u00f6n\u00b7nen", "wir", "viel\u00b7leicht", "mit", "uns\u00b7rer", "klei\u00b7nen", "Keh\u00b7len"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VMFIN", "PPER", "ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "\u201ebewunderns-wehrten Lieblichkeiten,", "tokens": ["\u201e", "be\u00b7wun\u00b7derns\u00b7wehr\u00b7ten", "Lieb\u00b7lich\u00b7kei\u00b7ten", ","], "token_info": ["punct", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "\u201evollkommnere Gesch\u00f6pf\u2019 als wir,", "tokens": ["\u201e", "voll\u00b7komm\u00b7ne\u00b7re", "Ge\u00b7sch\u00f6pf'", "als", "wir", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "KOUS", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "\u201enebst uns, zur Lust und Andacht leiten.", "tokens": ["\u201e", "nebst", "uns", ",", "zur", "Lust", "und", "An\u00b7dacht", "lei\u00b7ten", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPER", "$,", "APPRART", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Ja, ja! so singen sie, ob wirs gleich nicht verstehn,", "tokens": ["Ja", ",", "ja", "!", "so", "sin\u00b7gen", "sie", ",", "ob", "wirs", "gleich", "nicht", "ver\u00b7stehn", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "$.", "ADV", "VVFIN", "PPER", "$,", "KOUS", "PIS", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wenn sie den Gesang auch selber nicht verst\u00fcnden;", "tokens": ["Und", "wenn", "sie", "den", "Ge\u00b7sang", "auch", "sel\u00b7ber", "nicht", "ver\u00b7st\u00fcn\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "ADV", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So sollten wir dennoch, die wir viel weiter sehn,", "tokens": ["So", "soll\u00b7ten", "wir", "den\u00b7noch", ",", "die", "wir", "viel", "wei\u00b7ter", "sehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "$,", "PRELS", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Inhalt ihrer Lieder finden,", "tokens": ["Den", "In\u00b7halt", "ih\u00b7rer", "Lie\u00b7der", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Uns, durch empfundne Lust, zu ihrem Sch\u00f6pfer lencken,", "tokens": ["Uns", ",", "durch", "emp\u00b7fund\u00b7ne", "Lust", ",", "zu", "ih\u00b7rem", "Sch\u00f6p\u00b7fer", "len\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "APPR", "ADJA", "NN", "$,", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und Seinen Ruhm stets zu vermehren dencken:", "tokens": ["Und", "Sei\u00b7nen", "Ruhm", "stets", "zu", "ver\u00b7meh\u00b7ren", "den\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Da uns die Lieblichkeit der s\u00fcssen Stimmen r\u00fchrt,", "tokens": ["Da", "uns", "die", "Lieb\u00b7lich\u00b7keit", "der", "s\u00fcs\u00b7sen", "Stim\u00b7men", "r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und uns recht in die Seele dringet;", "tokens": ["Und", "uns", "recht", "in", "die", "See\u00b7le", "drin\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wodurch, indem sie uns mit Recht zum Sch\u00f6pfer f\u00fchrt,", "tokens": ["Wo\u00b7durch", ",", "in\u00b7dem", "sie", "uns", "mit", "Recht", "zum", "Sch\u00f6p\u00b7fer", "f\u00fchrt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "KOUS", "PPER", "PRF", "APPR", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Danck, Ehr-Furcht, Lieb\u2019 und Lob aus unsrer Lust ent-", "tokens": ["Danck", ",", "Ehr\u00b7Furcht", ",", "Lieb'", "und", "Lob", "aus", "uns\u00b7rer", "Lust", "ent"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "So lasst uns doch nicht minder uns bem\u00fchn,", "tokens": ["So", "lasst", "uns", "doch", "nicht", "min\u00b7der", "uns", "be\u00b7m\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Durch unsre Lust an unsers Sch\u00f6pfers Wercken,", "tokens": ["Durch", "uns\u00b7re", "Lust", "an", "un\u00b7sers", "Sch\u00f6p\u00b7fers", "Wer\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Auch edlere Gesch\u00f6pf zu Seinem Ruhm zu ziehn,", "tokens": ["Auch", "ed\u00b7le\u00b7re", "Ge\u00b7sch\u00f6pf", "zu", "Sei\u00b7nem", "Ruhm", "zu", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und Engeln, oder seelgen Seelen,", "tokens": ["Und", "En\u00b7geln", ",", "o\u00b7der", "seel\u00b7gen", "See\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Auch unsre Freude nicht verhehlen:", "tokens": ["Auch", "uns\u00b7re", "Freu\u00b7de", "nicht", "ver\u00b7heh\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Wann sie in unserm Lob-Geth\u00f6n,", "tokens": ["Wann", "sie", "in", "un\u00b7serm", "Lob\u00b7Get\u00b7h\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Ein durch die Creatur ger\u00fchrtes Hertze mercken;", "tokens": ["Ein", "durch", "die", "Crea\u00b7tur", "ge\u00b7r\u00fchr\u00b7tes", "Hert\u00b7ze", "mer\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADJA", "VVFIN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.12": {"text": "Wann sie, bey unserer Betrachtung, sehn", "tokens": ["Wann", "sie", ",", "bey", "un\u00b7se\u00b7rer", "Be\u00b7trach\u00b7tung", ",", "sehn"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PWAV", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Ein sehnend Aug\u2019 und fr\u00f6hliche Geberden,", "tokens": ["Ein", "seh\u00b7nend", "Aug'", "und", "fr\u00f6h\u00b7li\u00b7che", "Ge\u00b7ber\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Und durch dieselbigen von der in unsrer Brust", "tokens": ["Und", "durch", "die\u00b7sel\u00b7bi\u00b7gen", "von", "der", "in", "uns\u00b7rer", "Brust"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PDAT", "APPR", "ART", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Gef\u00fchlten innern Lust", "tokens": ["Ge\u00b7f\u00fchl\u00b7ten", "in\u00b7nern", "Lust"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "Ger\u00fchrt und \u00fcberf\u00fchret werden;", "tokens": ["Ge\u00b7r\u00fchrt", "und", "\u00fc\u00b7berf\u00b7\u00fch\u00b7ret", "wer\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "So kann gewi\u00df das helle schallen", "tokens": ["So", "kann", "ge\u00b7wi\u00df", "das", "hel\u00b7le", "schal\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADV", "ART", "ADJA", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Der Lieder-reichen Nachtigallen", "tokens": ["Der", "Lie\u00b7der\u00b7rei\u00b7chen", "Nach\u00b7ti\u00b7gal\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Der Menschen Ohr so sehr nicht r\u00fchren, und gefallen,", "tokens": ["Der", "Men\u00b7schen", "Ohr", "so", "sehr", "nicht", "r\u00fch\u00b7ren", ",", "und", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "ADV", "PTKNEG", "VVINF", "$,", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Als stille Seufzer, frohe Minen,", "tokens": ["Als", "stil\u00b7le", "Seuf\u00b7zer", ",", "fro\u00b7he", "Mi\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Die ein betrachtetes Gesch\u00f6pf", "tokens": ["Die", "ein", "be\u00b7trach\u00b7te\u00b7tes", "Ge\u00b7sch\u00f6pf"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "In uns erreget, ihnen", "tokens": ["In", "uns", "er\u00b7re\u00b7get", ",", "ih\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["APPR", "PPER", "VVFIN", "$,", "PPER"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.23": {"text": "Vergn\u00fcgen, Anmuth und Ergetzen", "tokens": ["Ver\u00b7gn\u00fc\u00b7gen", ",", "An\u00b7muth", "und", "Er\u00b7get\u00b7zen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN"], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}, "line.24": {"text": "Erregen mu\u00df, und sie noch mehr und mehr", "tokens": ["Er\u00b7re\u00b7gen", "mu\u00df", ",", "und", "sie", "noch", "mehr", "und", "mehr"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "$,", "KON", "PPER", "ADV", "ADV", "KON", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Zu ihres Sch\u00f6pfers Preis und Ehr,", "tokens": ["Zu", "ih\u00b7res", "Sch\u00f6p\u00b7fers", "Preis", "und", "Ehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "In eine seelge Freude setzen.", "tokens": ["In", "ei\u00b7ne", "seel\u00b7ge", "Freu\u00b7de", "set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Wer wollte denn nicht gern,", "tokens": ["Wer", "woll\u00b7te", "denn", "nicht", "gern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Bey so viel selbst gef\u00fchlter Lust,", "tokens": ["Bey", "so", "viel", "selbst", "ge\u00b7f\u00fchl\u00b7ter", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.3": {"text": "So gar der Engel Lust, und aller Engel HErrn", "tokens": ["So", "gar", "der", "En\u00b7gel", "Lust", ",", "und", "al\u00b7ler", "En\u00b7gel", "Herrn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "NN", "$,", "KON", "PIAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Lob, Ehr und Preis, zu mehren, zu erheben,", "tokens": ["Lob", ",", "Ehr", "und", "Preis", ",", "zu", "meh\u00b7ren", ",", "zu", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,", "PTKZU", "VVINF", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Lobsingend sich beftreben?", "tokens": ["Lob\u00b7sin\u00b7gend", "sich", "be\u00b7ft\u00b7re\u00b7ben", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PRF", "VVINF", "$."], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.6": {"text": "Wer wollte nicht, wie uns die V\u00f6gel hier auf Erden,", "tokens": ["Wer", "woll\u00b7te", "nicht", ",", "wie", "uns", "die", "V\u00f6\u00b7gel", "hier", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PTKNEG", "$,", "PWAV", "PPER", "ART", "NN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So ihnen dazu gern ein klingend Werck-Zeug werden?", "tokens": ["So", "ih\u00b7nen", "da\u00b7zu", "gern", "ein", "klin\u00b7gend", "Wer\u00b7ck\u00b7Zeug", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PAV", "ADV", "ART", "ADJD", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}}}}}