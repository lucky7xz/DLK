{"textgrid.poem.49204": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "1L: Vier mal ist der Fr\u00fchling kommen;", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Vier mal ist der Fr\u00fchling kommen;", "tokens": ["Vier", "mal", "ist", "der", "Fr\u00fch\u00b7ling", "kom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ADV", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vier mal hat die Winterszeit", "tokens": ["Vier", "mal", "hat", "die", "Win\u00b7ter\u00b7szeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "ADV", "VAFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Von den W\u00e4ldern abgenommen", "tokens": ["Von", "den", "W\u00e4l\u00b7dern", "ab\u00b7ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihr begr\u00fcntes Sommerkleid,", "tokens": ["Ihr", "be\u00b7gr\u00fcn\u00b7tes", "Som\u00b7mer\u00b7kleid", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Seit da\u00df wir gebracht sind worden", "tokens": ["Seit", "da\u00df", "wir", "ge\u00b7bracht", "sind", "wor\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "PPER", "VVPP", "VAFIN", "VAPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "In der treuen Freundschaft Orden.", "tokens": ["In", "der", "treu\u00b7en", "Freund\u00b7schaft", "Or\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Wie viel Tage sind verflossen", "tokens": ["Wie", "viel", "Ta\u00b7ge", "sind", "ver\u00b7flos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Inner Freud' und guter Lust,", "tokens": ["In\u00b7ner", "Freud'", "und", "gu\u00b7ter", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wann wir uns den Sinn begossen", "tokens": ["Wann", "wir", "uns", "den", "Sinn", "be\u00b7gos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PRF", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit Ly\u00e4us seiner Kost;", "tokens": ["Mit", "Ly\u00b7\u00e4us", "sei\u00b7ner", "Kost", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Doch nicht wie die rauhen Scythen,", "tokens": ["Doch", "nicht", "wie", "die", "rau\u00b7hen", "Scyt\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die den ganzen Wanst voll sch\u00fctten.", "tokens": ["Die", "den", "gan\u00b7zen", "Wanst", "voll", "sch\u00fct\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Wie ein Schiffer an dem Rande", "tokens": ["Wie", "ein", "Schif\u00b7fer", "an", "dem", "Ran\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Seinen krummen Nachen f\u00fchrt", "tokens": ["Sei\u00b7nen", "krum\u00b7men", "Na\u00b7chen", "f\u00fchrt"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und sich nicht weit helt vom Lande,", "tokens": ["Und", "sich", "nicht", "weit", "helt", "vom", "Lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "PTKNEG", "ADJD", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wann er starke Wellen sp\u00fcrt,", "tokens": ["Wann", "er", "star\u00b7ke", "Wel\u00b7len", "sp\u00fcrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "So auch mu\u00df es sein im Trinken,", "tokens": ["So", "auch", "mu\u00df", "es", "sein", "im", "Trin\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "PPOSAT", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wollen wir nicht untersinken.", "tokens": ["Wol\u00b7len", "wir", "nicht", "un\u00b7ter\u00b7sin\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Sehn wir in der Schale springen,", "tokens": ["Sehn", "wir", "in", "der", "Scha\u00b7le", "sprin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ungern, deinen klaren Wein,", "tokens": ["Un\u00b7gern", ",", "dei\u00b7nen", "kla\u00b7ren", "Wein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "K\u00f6nnen wir uns auch bezwingen,", "tokens": ["K\u00f6n\u00b7nen", "wir", "uns", "auch", "be\u00b7zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df wir lange n\u00fcchtern sein?", "tokens": ["Da\u00df", "wir", "lan\u00b7ge", "n\u00fcch\u00b7tern", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Es mu\u00df alles, was uns kr\u00e4nket,", "tokens": ["Es", "mu\u00df", "al\u00b7les", ",", "was", "uns", "kr\u00e4n\u00b7ket", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "In das Weinfa\u00df sein versenket.", "tokens": ["In", "das", "Wein\u00b7fa\u00df", "sein", "ver\u00b7sen\u00b7ket", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAINF", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Wann wir dann so viel genommen,", "tokens": ["Wann", "wir", "dann", "so", "viel", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df der angenehme Saft", "tokens": ["Da\u00df", "der", "an\u00b7ge\u00b7neh\u00b7me", "Saft"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Etwas in die Stirn' ist kommen,", "tokens": ["Et\u00b7was", "in", "die", "Stirn'", "ist", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da kriegt Herz und Zunge Kraft,", "tokens": ["Da", "kriegt", "Herz", "und", "Zun\u00b7ge", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "KON", "NN", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.5": {"text": "Da wird alles ausgelassen,", "tokens": ["Da", "wird", "al\u00b7les", "aus\u00b7ge\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Was uns taug und was wir hassen.", "tokens": ["Was", "uns", "taug", "und", "was", "wir", "has\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "KON", "PWS", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Warum dieses sei zu meiden,", "tokens": ["Wa\u00b7rum", "die\u00b7ses", "sei", "zu", "mei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDS", "VAFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Warum das nicht k\u00f6nne sein,", "tokens": ["Wa\u00b7rum", "das", "nicht", "k\u00f6n\u00b7ne", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDS", "PTKNEG", "VMFIN", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Warum der und der uns neiden,", "tokens": ["Wa\u00b7rum", "der", "und", "der", "uns", "nei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "KON", "ART", "PPER", "VVFIN", "$,"], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Jener auch nur falschen Schein", "tokens": ["Je\u00b7ner", "auch", "nur", "fal\u00b7schen", "Schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDAT", "ADV", "ADV", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Des Gem\u00fcthes von sich gibet,", "tokens": ["Des", "Ge\u00b7m\u00fc\u00b7thes", "von", "sich", "gi\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Herzlich ha\u00dft und m\u00fcndlich liebet.", "tokens": ["Herz\u00b7lich", "ha\u00dft", "und", "m\u00fcnd\u00b7lich", "lie\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "KON", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "O ihr Matten, o ihr Wiesen,", "tokens": ["O", "ihr", "Mat\u00b7ten", ",", "o", "ihr", "Wie\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$,", "FM", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Du Gebirge, welches wir", "tokens": ["Du", "Ge\u00b7bir\u00b7ge", ",", "wel\u00b7ches", "wir"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPER", "NN", "$,", "PRELS", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nennen von den alten Riesen,", "tokens": ["Nen\u00b7nen", "von", "den", "al\u00b7ten", "Rie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "O ihr warmen B\u00e4der ihr,", "tokens": ["O", "ihr", "war\u00b7men", "B\u00e4\u00b7der", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "ADJA", "NN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ihr Nap\u00e4en habt vernommen,", "tokens": ["Ihr", "Na\u00b7p\u00e4en", "habt", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Was uns oftmals ein ist kommen.", "tokens": ["Was", "uns", "oft\u00b7mals", "ein", "ist", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ART", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "So ergetzt uns hier auf Erden", "tokens": ["So", "er\u00b7getzt", "uns", "hier", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ein sch\u00f6n Glas und ein sch\u00f6n Buch,", "tokens": ["Ein", "sch\u00f6n", "Glas", "und", "ein", "sch\u00f6n", "Buch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "KON", "ART", "ADJD", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bi\u00df wir eingeh\u00fcllet werden", "tokens": ["Bi\u00df", "wir", "ein\u00b7ge\u00b7h\u00fcl\u00b7let", "wer\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVPP", "VAINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In ein St\u00fccke leinen Tuch.", "tokens": ["In", "ein", "St\u00fc\u00b7cke", "lei\u00b7nen", "Tuch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Weil wir mehr nicht mit uns nehmen,", "tokens": ["Weil", "wir", "mehr", "nicht", "mit", "uns", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sollen wir uns dann viel gr\u00e4men?", "tokens": ["Sol\u00b7len", "wir", "uns", "dann", "viel", "gr\u00e4\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Werden wir auch sonst nichts lassen,", "tokens": ["Wer\u00b7den", "wir", "auch", "sonst", "nichts", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "PIS", "VVINF", "$,"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.2": {"text": "(dann sich um das Eigenthum", "tokens": ["(", "dann", "sich", "um", "das", "Ei\u00b7gen\u00b7thum"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "PRF", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Niemand schlagen wird und hassen)", "tokens": ["Nie\u00b7mand", "schla\u00b7gen", "wird", "und", "has\u00b7sen", ")"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVINF", "VAFIN", "KON", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "So bleibt doch ein guter Ruhm,", "tokens": ["So", "bleibt", "doch", "ein", "gu\u00b7ter", "Ruhm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Den der Tod uns nicht kan sterben", "tokens": ["Den", "der", "Tod", "uns", "nicht", "kan", "ster\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "PPER", "PTKNEG", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und kein Mensch mit Geld erwerben.", "tokens": ["Und", "kein", "Mensch", "mit", "Geld", "er\u00b7wer\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Du durchrennst mit freiem Z\u00fcgel", "tokens": ["Du", "durch\u00b7rennst", "mit", "frei\u00b7em", "Z\u00fc\u00b7gel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Des geehrten Lobes Pfad", "tokens": ["Des", "ge\u00b7ehr\u00b7ten", "Lo\u00b7bes", "Pfad"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch des hohen Adlers Fl\u00fcgel,", "tokens": ["Durch", "des", "ho\u00b7hen", "Ad\u00b7lers", "Fl\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Welcher dich zu Diensten hat", "tokens": ["Wel\u00b7cher", "dich", "zu", "Diens\u00b7ten", "hat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "APPR", "NN", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und auch mich wil h\u00f6her heben,", "tokens": ["Und", "auch", "mich", "wil", "h\u00f6\u00b7her", "he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VMFIN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mir Helm, Schild und Adel geben.", "tokens": ["Mir", "Helm", ",", "Schild", "und", "A\u00b7del", "ge\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "NN", "KON", "NN", "VVINF", "$."], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}}, "stanza.11": {"line.1": {"text": "Dieses sind die Gift und Gaben,", "tokens": ["Die\u00b7ses", "sind", "die", "Gift", "und", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Die uns \u00fcber allen Neid,", "tokens": ["Die", "uns", "\u00fc\u00b7ber", "al\u00b7len", "Neid", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wann wir lange sind vergraben,", "tokens": ["Wann", "wir", "lan\u00b7ge", "sind", "ver\u00b7gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Heben sollen jederzeit;", "tokens": ["He\u00b7ben", "sol\u00b7len", "je\u00b7der\u00b7zeit", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Diese Sch\u00e4tz' und G\u00fcter machen,", "tokens": ["Die\u00b7se", "Sch\u00e4tz'", "und", "G\u00fc\u00b7ter", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df wir Hohn und Ha\u00df verlachen.", "tokens": ["Da\u00df", "wir", "Hohn", "und", "Ha\u00df", "ver\u00b7la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "KON", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Wann die Mi\u00dfgunst tausend Zungen", "tokens": ["Wann", "die", "Mi\u00df\u00b7gunst", "tau\u00b7send", "Zun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hette feindlich ausgestreckt", "tokens": ["Het\u00b7te", "feind\u00b7lich", "aus\u00b7ge\u00b7streckt"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "ADJD", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und k\u00e4m' auf uns zu gedrungen,", "tokens": ["Und", "k\u00e4m'", "auf", "uns", "zu", "ge\u00b7drun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Doch so bleiben wir verdeckt", "tokens": ["Doch", "so", "blei\u00b7ben", "wir", "ver\u00b7deckt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "In der Treu und Tugend Schatten,", "tokens": ["In", "der", "Treu", "und", "Tu\u00b7gend", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da kein Neid kan hingerathen.", "tokens": ["Da", "kein", "Neid", "kan", "hin\u00b7ge\u00b7ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Nun wolan, mit dem Bedinge", "tokens": ["Nun", "wo\u00b7lan", ",", "mit", "dem", "Be\u00b7din\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "La\u00df uns bleiben, wie wir sein!", "tokens": ["La\u00df", "uns", "blei\u00b7ben", ",", "wie", "wir", "sein", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVINF", "$,", "PWAV", "PPER", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da ich dann darauf dir bringe", "tokens": ["Da", "ich", "dann", "da\u00b7rauf", "dir", "brin\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PAV", "PPER", "VVFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Dieses gro\u00dfe Schiff voll Wein,", "tokens": ["Die\u00b7ses", "gro\u00b7\u00dfe", "Schiff", "voll", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "ADJD", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df dich wol nicht mehr sol d\u00fcrsten,", "tokens": ["Da\u00df", "dich", "wol", "nicht", "mehr", "sol", "d\u00fcrs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "ADV", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Auf Gesundheit unsers F\u00fcrsten.", "tokens": ["Auf", "Ge\u00b7sund\u00b7heit", "un\u00b7sers", "F\u00fcrs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}