{"dta.poem.9236": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "X.  \n Es hungert ihn nach Fleische.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Ach weh! wie hungert mich/ wo krieg ich neue krafft", "tokens": ["Ach", "weh", "!", "wie", "hun\u00b7gert", "mich", "/", "wo", "krieg", "ich", "neu\u00b7e", "krafft"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "ADV", "$.", "PWAV", "VVFIN", "PPER", "$(", "PWAV", "VVFIN", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wo find ich einen koch/ der mir zu essen schafft?", "tokens": ["Wo", "find", "ich", "ei\u00b7nen", "koch", "/", "der", "mir", "zu", "es\u00b7sen", "schafft", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ART", "NE", "$(", "PRELS", "PPER", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der fleisch kram ist zwar offen/", "tokens": ["Der", "fleisch", "kram", "ist", "zwar", "of\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VAFIN", "ADV", "ADJD", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ich aber wei\u00df nicht wohl/", "tokens": ["Ich", "a\u00b7ber", "wei\u00df", "nicht", "wohl", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PTKNEG", "ADV", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Wo ich was gutes hoffen", "tokens": ["Wo", "ich", "was", "gu\u00b7tes", "hof\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PIS", "ADJA", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und mich vergn\u00fcgen soll.", "tokens": ["Und", "mich", "ver\u00b7gn\u00fc\u00b7gen", "soll", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "2. Putt-h\u00fcngen fleisch ist weich/ und gehet niedlich ein/", "tokens": ["Put\u00b7th\u00fcn\u00b7gen", "fleisch", "ist", "weich", "/", "und", "ge\u00b7het", "nied\u00b7lich", "ein", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VAFIN", "ADJD", "$(", "KON", "VVFIN", "ADV", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es mag auch gut genung vor schwache m\u00e4dgen seyn/", "tokens": ["Es", "mag", "auch", "gut", "ge\u00b7nung", "vor", "schwa\u00b7che", "m\u00e4d\u00b7gen", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADJD", "ADV", "APPR", "ADJA", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch wann die liebe speise", "tokens": ["Doch", "wann", "die", "lie\u00b7be", "spei\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So zart und schlappricht sieht/", "tokens": ["So", "zart", "und", "schlap\u00b7pricht", "sieht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Verliert man auf die weise", "tokens": ["Ver\u00b7liert", "man", "auf", "die", "wei\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "APPR", "ART", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Gar leicht den appetit.", "tokens": ["Gar", "leicht", "den", "ap\u00b7pe\u00b7tit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "3. Das kalb-fleisch ist noch jung/ u. beist sich lieblich an", "tokens": ["Das", "kalb\u00b7fleisch", "ist", "noch", "jung", "/", "u.", "beist", "sich", "lieb\u00b7lich", "an"], "token_info": ["word", "word", "word", "word", "word", "punct", "abbreviation", "word", "word", "word", "word"], "pos": ["PDS", "ADJD", "VAFIN", "ADV", "ADJD", "$(", "KON", "VVFIN", "PRF", "ADJD", "PTKVZ"], "meter": "--+-+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Wenn man die eutergen mit unterschneiden kan/", "tokens": ["Wenn", "man", "die", "eu\u00b7ter\u00b7gen", "mit", "un\u00b7ter\u00b7schnei\u00b7den", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "PPOSS", "APPR", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch wen es an der mutter", "tokens": ["Doch", "wen", "es", "an", "der", "mut\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nicht lang gewesen ist/", "tokens": ["Nicht", "lang", "ge\u00b7we\u00b7sen", "ist", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VAPP", "VAFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "So ist es auch ein futter/", "tokens": ["So", "ist", "es", "auch", "ein", "fut\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Darnach mich nicht gel\u00fcst.", "tokens": ["Dar\u00b7nach", "mich", "nicht", "ge\u00b7l\u00fcst", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "4. Das rind-fleisch ist gemein/ und wird sehr hoch beliebt/", "tokens": ["Das", "rin\u00b7dfleisch", "ist", "ge\u00b7mein", "/", "und", "wird", "sehr", "hoch", "be\u00b7liebt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "VAFIN", "ADJD", "$(", "KON", "VAFIN", "ADV", "ADJD", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dieweil es guten Safft/ und volle nahrung giebt:", "tokens": ["Die\u00b7weil", "es", "gu\u00b7ten", "Safft", "/", "und", "vol\u00b7le", "nah\u00b7rung", "giebt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJA", "NN", "$(", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es h\u00e4lt vortreflich wieder/", "tokens": ["Es", "h\u00e4lt", "vor\u00b7tre\u00b7flich", "wie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch dieses gute lob", "tokens": ["Doch", "die\u00b7ses", "gu\u00b7te", "lob"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PDAT", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ist nicht vor schwache glieder/", "tokens": ["Ist", "nicht", "vor", "schwa\u00b7che", "glie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Was starck ist/ das ist grob.", "tokens": ["Was", "starck", "ist", "/", "das", "ist", "grob", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$(", "PDS", "VAFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "5. ", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "So machts im leibe nicht die geister gar subtil/", "tokens": ["So", "machts", "im", "lei\u00b7be", "nicht", "die", "geis\u00b7ter", "gar", "sub\u00b7til", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "VVFIN", "PTKNEG", "ART", "ADJA", "ADV", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der schmack ist auserlesen/", "tokens": ["Der", "schmack", "ist", "au\u00b7ser\u00b7le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Indessen ist es doch/", "tokens": ["In\u00b7des\u00b7sen", "ist", "es", "doch", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ein tummes schaaf gewesen/", "tokens": ["Ein", "tum\u00b7mes", "schaaf", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und hat den schaafs-kopff noch.", "tokens": ["Und", "hat", "den", "schaafs\u00b7kopff", "noch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "6. ", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Es ist um eine sau gar zu ein garstig thier/", "tokens": ["Es", "ist", "um", "ei\u00b7ne", "sau", "gar", "zu", "ein", "gars\u00b7tig", "thier", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "ADJD", "ADV", "APPR", "ART", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drum will mirs nicht zu sinne/", "tokens": ["Drum", "will", "mirs", "nicht", "zu", "sin\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "NE", "PTKNEG", "PTKZU", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da klebt ein bi\u00dfgen koth/", "tokens": ["Da", "klebt", "ein", "bi\u00df\u00b7gen", "koth", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da sitzet eine finne.", "tokens": ["Da", "sit\u00b7zet", "ei\u00b7ne", "fin\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Da ist es sonsten roth.", "tokens": ["Da", "ist", "es", "sons\u00b7ten", "roth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "7. ", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Doch es bedarff viel speck und kost ein haufen geld/", "tokens": ["Doch", "es", "be\u00b7darff", "viel", "speck", "und", "kost", "ein", "hau\u00b7fen", "geld", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ADJD", "KON", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das ist mein gr\u00f6ster tadel/", "tokens": ["Das", "ist", "mein", "gr\u00f6s\u00b7ter", "ta\u00b7del", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Drum denck ich nicht dahin/", "tokens": ["Drum", "denck", "ich", "nicht", "da\u00b7hin", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PTKNEG", "PAV", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Dieweil ich nicht von adel", "tokens": ["Die\u00b7weil", "ich", "nicht", "von", "a\u00b7del"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "APPR", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Noch gro\u00df von mitteln bin.", "tokens": ["Noch", "gro\u00df", "von", "mit\u00b7teln", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "VVINF", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "8. Wiewohl ich tadle nicht das essen gar zu scharff/", "tokens": ["Wie\u00b7wohl", "ich", "tad\u00b7le", "nicht", "das", "es\u00b7sen", "gar", "zu", "scharff", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PTKNEG", "PDS", "VVFIN", "ADV", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer nur nicht esel fleisch aus noth gebrauchen darff/", "tokens": ["Wer", "nur", "nicht", "e\u00b7sel", "fleisch", "aus", "noth", "ge\u00b7brau\u00b7chen", "darff", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PTKNEG", "ADJD", "ADJD", "APPR", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der wird noch nicht verderben:", "tokens": ["Der", "wird", "noch", "nicht", "ver\u00b7der\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Es weist sich manchmahl aus/", "tokens": ["Es", "weist", "sich", "manch\u00b7mahl", "aus", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "PTKVZ", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Eh man wil hunger sterben/", "tokens": ["Eh", "man", "wil", "hun\u00b7ger", "ster\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VMFIN", "ADJD", "VVINF", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.6": {"text": "So f\u00e4ngt man eine mau\u00df/", "tokens": ["So", "f\u00e4ngt", "man", "ei\u00b7ne", "mau\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "9. Jetzt geh ich in den kram/ und suche guten rath/", "tokens": ["Jetzt", "geh", "ich", "in", "den", "kram", "/", "und", "su\u00b7che", "gu\u00b7ten", "rath", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$(", "KON", "ADJA", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer wei\u00df/ wer schon dasfleisch zuvor beschnuppert hat/", "tokens": ["Wer", "wei\u00df", "/", "wer", "schon", "das\u00b7fleisch", "zu\u00b7vor", "be\u00b7schnup\u00b7pert", "hat", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$(", "PWS", "ADV", "ADJD", "ADV", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man mu\u00df sich doch begn\u00fcgen/", "tokens": ["Man", "mu\u00df", "sich", "doch", "be\u00b7gn\u00fc\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PRF", "ADV", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Es wird doch alls bezahlt/", "tokens": ["Es", "wird", "doch", "alls", "be\u00b7zahlt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und h\u00e4tten es die fliegen", "tokens": ["Und", "h\u00e4t\u00b7ten", "es", "die", "flie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ART", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Gantz sprenglich ausgemahlt.", "tokens": ["Gantz", "spreng\u00b7lich", "aus\u00b7ge\u00b7mahlt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "10. Ich halte/ mancher kriegt ein olle putterie/", "tokens": ["Ich", "hal\u00b7te", "/", "man\u00b7cher", "kriegt", "ein", "ol\u00b7le", "put\u00b7te\u00b7rie", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PIS", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie schmeckt nach allerley/ und gleichwohl lobt er sie/", "tokens": ["Sie", "schmeckt", "nach", "al\u00b7ler\u00b7ley", "/", "und", "gleich\u00b7wohl", "lobt", "er", "sie", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "$(", "KON", "ADV", "VVFIN", "PPER", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drum will ich mich beqvemen/", "tokens": ["Drum", "will", "ich", "mich", "be\u00b7qve\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "PRF", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und will in kurtzer frist", "tokens": ["Und", "will", "in", "kurt\u00b7zer", "frist"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Das erste bi\u00dfgen nehmen/", "tokens": ["Das", "ers\u00b7te", "bi\u00df\u00b7gen", "neh\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Das mir bescheret ist.", "tokens": ["Das", "mir", "be\u00b7sche\u00b7ret", "ist", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}