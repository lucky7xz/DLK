{"textgrid.poem.46142": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Brautlied zu ehren der hochzeit Filanders und seiner Cloris", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als mein Filander nu mit lust", "tokens": ["Als", "mein", "Fi\u00b7lan\u00b7der", "nu", "mit", "lust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "die lang begehrte edle blust", "tokens": ["die", "lang", "be\u00b7gehr\u00b7te", "ed\u00b7le", "blust"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und seiner buhlschaft frucht errungen,", "tokens": ["und", "sei\u00b7ner", "buhl\u00b7schaft", "frucht", "er\u00b7run\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "hat ein hauf Liebelein gar laut", "tokens": ["hat", "ein", "hauf", "Lie\u00b7be\u00b7lein", "gar", "laut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "NN", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "dem br\u00e4utigam und seiner braut", "tokens": ["dem", "br\u00e4u\u00b7ti\u00b7gam", "und", "sei\u00b7ner", "braut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NE", "KON", "PPOSAT", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "zu ehren dises lied gesungen.", "tokens": ["zu", "eh\u00b7ren", "di\u00b7ses", "lied", "ge\u00b7sun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "O da\u00df ihr m\u00f6get, allezeit", "tokens": ["O", "da\u00df", "ihr", "m\u00f6\u00b7get", ",", "al\u00b7le\u00b7zeit"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["NE", "KOUS", "PPER", "VMFIN", "$,", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "einm\u00fctig, in sunst keinem streit,", "tokens": ["ein\u00b7m\u00fc\u00b7tig", ",", "in", "sunst", "kei\u00b7nem", "streit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "APPR", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "dan in dem liebesstreit nur leben!", "tokens": ["dan", "in", "dem", "lie\u00b7bes\u00b7streit", "nur", "le\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ADV", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "darinnen eines jeden herz", "tokens": ["da\u00b7rin\u00b7nen", "ei\u00b7nes", "je\u00b7den", "herz"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "dem andern m\u00f6g wollust und scherz", "tokens": ["dem", "an\u00b7dern", "m\u00f6g", "wol\u00b7lust", "und", "scherz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "f\u00fcr scherz und wollust widergeben.", "tokens": ["f\u00fcr", "scherz", "und", "wol\u00b7lust", "wi\u00b7der\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "KON", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Durch k\u00fc\u00df, von s\u00fc\u00dfem nectar feucht,", "tokens": ["Durch", "k\u00fc\u00df", ",", "von", "s\u00fc\u00b7\u00dfem", "nec\u00b7tar", "feucht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "$,", "APPR", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "das herz und seel von freuden leicht,", "tokens": ["das", "herz", "und", "seel", "von", "freu\u00b7den", "leicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "solt ihr euch nemen und mittheilen", "tokens": ["solt", "ihr", "euch", "ne\u00b7men", "und", "mit\u00b7thei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PPER", "VVINF", "KON", "VVINF"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "tiefwundend sollen eure k\u00fc\u00df,", "tokens": ["tief\u00b7wun\u00b7dend", "sol\u00b7len", "eu\u00b7re", "k\u00fc\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "PPOSAT", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "s\u00fc\u00dfheilend sollen eure b\u00fc\u00df,", "tokens": ["s\u00fc\u00df\u00b7hei\u00b7lend", "sol\u00b7len", "eu\u00b7re", "b\u00fc\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "verwundend euch, euch wider heilen.", "tokens": ["ver\u00b7wun\u00b7dend", "euch", ",", "euch", "wi\u00b7der", "hei\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "PPER", "$,", "PPER", "APPR", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Des einen mund soll mit wollust,", "tokens": ["Des", "ei\u00b7nen", "mund", "soll", "mit", "wol\u00b7lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VMFIN", "APPR", "NN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.2": {"text": "des andern herz aus seiner brust", "tokens": ["des", "an\u00b7dern", "herz", "aus", "sei\u00b7ner", "brust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "zu nemen, ihm die brust aufspalten:", "tokens": ["zu", "ne\u00b7men", ",", "ihm", "die", "brust", "auf\u00b7spal\u00b7ten", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "des andern herz soll mit dem mund,", "tokens": ["des", "an\u00b7dern", "herz", "soll", "mit", "dem", "mund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "durch s\u00fc\u00dfe k\u00fc\u00df verwundend, wund", "tokens": ["durch", "s\u00fc\u00b7\u00dfe", "k\u00fc\u00df", "ver\u00b7wun\u00b7dend", ",", "wund"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "der andern brust sich nicht enthalten.", "tokens": ["der", "an\u00b7dern", "brust", "sich", "nicht", "ent\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Mit euern armen stark und zart,", "tokens": ["Mit", "eu\u00b7ern", "ar\u00b7men", "stark", "und", "zart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mit euern glidern sanft und hart", "tokens": ["mit", "eu\u00b7ern", "gli\u00b7dern", "sanft", "und", "hart"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "solt ihr einander froh umfassen:", "tokens": ["solt", "ihr", "ein\u00b7an\u00b7der", "froh", "um\u00b7fas\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ihr solt einander auch f\u00fcrhin", "tokens": ["ihr", "solt", "ein\u00b7an\u00b7der", "auch", "f\u00fcr\u00b7hin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PRF", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "nicht, dan mit s\u00fc\u00dferem gewin", "tokens": ["nicht", ",", "dan", "mit", "s\u00fc\u00b7\u00dfe\u00b7rem", "ge\u00b7win"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "$,", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "euch wider umzufassen, lassen.", "tokens": ["euch", "wi\u00b7der", "um\u00b7zu\u00b7fas\u00b7sen", ",", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "APPR", "VVIZU", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Zwar jetzund deinen heldenmut,", "tokens": ["Zwar", "je\u00b7tzund", "dei\u00b7nen", "hel\u00b7den\u00b7mut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "nicht dein ererbtes heldenblut", "tokens": ["nicht", "dein", "er\u00b7erb\u00b7tes", "hel\u00b7den\u00b7blut"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKNEG", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "solt du gl\u00fcckseliger held sparen:", "tokens": ["solt", "du", "gl\u00fcck\u00b7se\u00b7li\u00b7ger", "held", "spa\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJA", "NN", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "lieb, lieber scherz und s\u00fc\u00dfer glimpf,", "tokens": ["lieb", ",", "lie\u00b7ber", "scherz", "und", "s\u00fc\u00b7\u00dfer", "glimpf", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADV", "ADJD", "KON", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "liebkosen, k\u00fc\u00df und k\u00fctzlens schimpf", "tokens": ["lieb\u00b7ko\u00b7sen", ",", "k\u00fc\u00df", "und", "k\u00fctz\u00b7lens", "schimpf"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "VVFIN", "KON", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "wird sie dir machen bald willfahren.", "tokens": ["wird", "sie", "dir", "ma\u00b7chen", "bald", "will\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "VVFIN", "ADV", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.7": {"line.1": {"text": "Wan aber dises ja nicht gnug,", "tokens": ["Wan", "a\u00b7ber", "di\u00b7ses", "ja", "nicht", "gnug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PDS", "ADV", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "solt k\u00fchner du mit gutem fug", "tokens": ["solt", "k\u00fch\u00b7ner", "du", "mit", "gu\u00b7tem", "fug"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADJD", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "an deine feindin freindlich fallen,", "tokens": ["an", "dei\u00b7ne", "fein\u00b7din", "freind\u00b7lich", "fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und la\u00df dir ihre scham und zucht,", "tokens": ["und", "la\u00df", "dir", "ih\u00b7re", "scham", "und", "zucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "PPOSAT", "NN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "ihr klagen, flehen und ausflucht", "tokens": ["ihr", "kla\u00b7gen", ",", "fle\u00b7hen", "und", "aus\u00b7flucht"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVINF", "$,", "VVINF", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "gefallen wol und doch misfallen.", "tokens": ["ge\u00b7fal\u00b7len", "wol", "und", "doch", "mis\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "ADV", "KON", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Durch den schwei\u00df nimmet die freud zu,", "tokens": ["Durch", "den", "schwei\u00df", "nim\u00b7met", "die", "freud", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJD", "VVFIN", "ART", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "die ruh ist s\u00fc\u00dfer nach unruh,", "tokens": ["die", "ruh", "ist", "s\u00fc\u00b7\u00dfer", "nach", "un\u00b7ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "und s\u00fc\u00dfer die k\u00fc\u00df so genetzet;", "tokens": ["und", "s\u00fc\u00b7\u00dfer", "die", "k\u00fc\u00df", "so", "ge\u00b7net\u00b7zet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "VVFIN", "ADV", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "also wan leidig deine freid,", "tokens": ["al\u00b7so", "wan", "lei\u00b7dig", "dei\u00b7ne", "freid", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWAV", "ADJD", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "also wan freidig auch ihr leid,", "tokens": ["al\u00b7so", "wan", "frei\u00b7dig", "auch", "ihr", "leid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWAV", "ADJD", "ADV", "PPER", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "wird beeder leid und freid ergetzet.", "tokens": ["wird", "bee\u00b7der", "leid", "und", "freid", "er\u00b7get\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADJD", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ach weh, wie forchtsam scheint sie doch!", "tokens": ["Ach", "weh", ",", "wie", "forcht\u00b7sam", "scheint", "sie", "doch", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "$,", "PWAV", "ADJD", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wie zittert sie doch ab dem joch,", "tokens": ["wie", "zit\u00b7tert", "sie", "doch", "ab", "dem", "joch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "darunder deine arm sie binden!", "tokens": ["da\u00b7run\u00b7der", "dei\u00b7ne", "arm", "sie", "bin\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "ADJD", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "dein mund kan, durstig, nu zumal", "tokens": ["dein", "mund", "kan", ",", "durs\u00b7tig", ",", "nu", "zu\u00b7mal"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "VMFIN", "$,", "ADJD", "$,", "ADV", "KOUS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "ein s\u00fc\u00dfes seufz- und z\u00e4hernmahl", "tokens": ["ein", "s\u00fc\u00b7\u00dfes", "seuf\u00b7z", "und", "z\u00e4\u00b7hern\u00b7mahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "TRUNC", "KON", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "auf ihrem mund und augen finden.", "tokens": ["auf", "ih\u00b7rem", "mund", "und", "au\u00b7gen", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "O himmelisches mahl! o speis!", "tokens": ["O", "him\u00b7me\u00b7li\u00b7sches", "mahl", "!", "o", "speis", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADJA", "ADV", "$.", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "o g\u00f6ttliches gedrank! mit flei\u00df", "tokens": ["o", "g\u00f6tt\u00b7li\u00b7ches", "ge\u00b7drank", "!", "mit", "flei\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["FM", "ADJA", "NN", "$.", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "in k\u00f6stliche gef\u00e4\u00df gegossen!", "tokens": ["in", "k\u00f6st\u00b7li\u00b7che", "ge\u00b7f\u00e4\u00df", "ge\u00b7gos\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "gef\u00e4\u00df, so sch\u00f6n, da\u00df auch kein got", "tokens": ["ge\u00b7f\u00e4\u00df", ",", "so", "sch\u00f6n", ",", "da\u00df", "auch", "kein", "got"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "ADV", "ADJD", "$,", "KOUS", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "aus sch\u00f6nern in der h\u00f6chsten not", "tokens": ["aus", "sch\u00f6\u00b7nern", "in", "der", "h\u00f6chs\u00b7ten", "not"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "der nahrung noch arznei genossen.", "tokens": ["der", "nah\u00b7rung", "noch", "arz\u00b7nei", "ge\u00b7nos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Damit nu ihrer s\u00fc\u00dfigkeit", "tokens": ["Da\u00b7mit", "nu", "ih\u00b7rer", "s\u00fc\u00b7\u00dfig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und beizenden holdseligkeit", "tokens": ["und", "bei\u00b7zen\u00b7den", "hold\u00b7se\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJA", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "du und sie m\u00f6get gar genie\u00dfen,", "tokens": ["du", "und", "sie", "m\u00f6\u00b7get", "gar", "ge\u00b7nie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PPER", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "so la\u00df dich kein bit um anstand,", "tokens": ["so", "la\u00df", "dich", "kein", "bit", "um", "an\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "PIAT", "ADJD", "APPR", "NE", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "kein widerstehen ihrer hand", "tokens": ["kein", "wi\u00b7der\u00b7ste\u00b7hen", "ih\u00b7rer", "hand"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "verhindern, fangen, noch verdrie\u00dfen.", "tokens": ["ver\u00b7hin\u00b7dern", ",", "fan\u00b7gen", ",", "noch", "ver\u00b7drie\u00b7\u00dfen", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVINF", "$,", "VVFIN", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Geh, fang nu mutig an die schlacht,", "tokens": ["Geh", ",", "fang", "nu", "mu\u00b7tig", "an", "die", "schlacht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "ADV", "ADJD", "APPR", "ART", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "gebrauch doch nicht zu gro\u00dfe macht,", "tokens": ["ge\u00b7brauch", "doch", "nicht", "zu", "gro\u00b7\u00dfe", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "PTKNEG", "PTKZU", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "sie nicht zu sehr gleich zu erschrecken;", "tokens": ["sie", "nicht", "zu", "sehr", "gleich", "zu", "er\u00b7schre\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "PTKA", "ADV", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "sondern gebrauch weil, list, betrug", "tokens": ["son\u00b7dern", "ge\u00b7brauch", "weil", ",", "list", ",", "be\u00b7trug"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["KON", "NN", "KOUS", "$,", "VVFIN", "$,", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "und falsche flucht, angrif, aufzug,", "tokens": ["und", "fal\u00b7sche", "flucht", ",", "an\u00b7grif", ",", "auf\u00b7zug", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "ADJA", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "damit die vestung zu entdecken.", "tokens": ["da\u00b7mit", "die", "ves\u00b7tung", "zu", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Und dan mit zitterender stim,", "tokens": ["Und", "dan", "mit", "zit\u00b7te\u00b7ren\u00b7der", "stim", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wan dan mit glei\u00dfnerischem grim", "tokens": ["wan", "dan", "mit", "glei\u00df\u00b7ne\u00b7ri\u00b7schem", "grim"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "sie dich wird arg, frech und b\u00f6s nennen,", "tokens": ["sie", "dich", "wird", "arg", ",", "frech", "und", "b\u00f6s", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "VAFIN", "ADJD", "$,", "ADJD", "KON", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.4": {"text": "h\u00f6r doch nicht auf, mit vollem lust", "tokens": ["h\u00f6r", "doch", "nicht", "auf", ",", "mit", "vol\u00b7lem", "lust"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PTKNEG", "PTKVZ", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "ihr aug, stirn, mund, hals, wangen, brust", "tokens": ["ihr", "aug", ",", "stirn", ",", "mund", ",", "hals", ",", "wan\u00b7gen", ",", "brust"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "$,", "NN", "$,", "ADV", "$,", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "mit tausend k\u00fcssen anzurennen.", "tokens": ["mit", "tau\u00b7send", "k\u00fcs\u00b7sen", "an\u00b7zu\u00b7ren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Sie mag lang sagen: \u00bbes ist gnug!", "tokens": ["Sie", "mag", "lang", "sa\u00b7gen", ":", "\u00bb", "es", "ist", "gnug", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "VVINF", "$.", "$(", "PPER", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "es ist gnug! seid ein wenig klug!\u00ab", "tokens": ["es", "ist", "gnug", "!", "seid", "ein", "we\u00b7nig", "klug", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$.", "VAFIN", "ART", "PIS", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und dir mit beeden h\u00e4nden wehren,", "tokens": ["und", "dir", "mit", "bee\u00b7den", "h\u00e4n\u00b7den", "weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "damit sie doch nicht unden lig;", "tokens": ["da\u00b7mit", "sie", "doch", "nicht", "un\u00b7den", "lig", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "ADJA", "ADJD", "$."], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.5": {"text": "heng du gleichwol stets nach dem sig", "tokens": ["heng", "du", "gleich\u00b7wol", "stets", "nach", "dem", "sig"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.6": {"text": "durch welchen sich die lieb mu\u00df nehren.", "tokens": ["durch", "wel\u00b7chen", "sich", "die", "lieb", "mu\u00df", "neh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "PRF", "ART", "ADJD", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Also in disem hei\u00dfen streit,", "tokens": ["Al\u00b7so", "in", "di\u00b7sem", "hei\u00b7\u00dfen", "streit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "begirig nach der s\u00fc\u00dfen beut,", "tokens": ["be\u00b7gi\u00b7rig", "nach", "der", "s\u00fc\u00b7\u00dfen", "beut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "kanst du den sturm widrum erneuen,", "tokens": ["kanst", "du", "den", "sturm", "wid\u00b7rum", "er\u00b7neu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und la\u00df von ihrer brust und scho\u00df,", "tokens": ["und", "la\u00df", "von", "ih\u00b7rer", "brust", "und", "scho\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "APPR", "PPOSAT", "NN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "wei\u00df, rund, steif, glat und mangellos", "tokens": ["wei\u00df", ",", "rund", ",", "steif", ",", "glat", "und", "man\u00b7gel\u00b7los"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "ADJD", "$,", "ADJD", "$,", "VVFIN", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "nichts deine geile hand abscheuen.", "tokens": ["nichts", "dei\u00b7ne", "gei\u00b7le", "hand", "ab\u00b7scheu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Wan du nu so nah bei dem platz", "tokens": ["Wan", "du", "nu", "so", "nah", "bei", "dem", "platz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "ADV", "ADJD", "APPR", "ART", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "solt du k\u00fc\u00df auf k\u00fc\u00df, schmatz auf schmatz,", "tokens": ["solt", "du", "k\u00fc\u00df", "auf", "k\u00fc\u00df", ",", "schmatz", "auf", "schmatz", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "APPR", "VVFIN", "$,", "ADJD", "APPR", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "schmuck auf schmuck, lieb auf lieb losschie\u00dfen;", "tokens": ["schmuck", "auf", "schmuck", ",", "lieb", "auf", "lieb", "los\u00b7schie\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJD", "$,", "ADJD", "APPR", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "alsdan solt du dein blut, den lohn", "tokens": ["als\u00b7dan", "solt", "du", "dein", "blut", ",", "den", "lohn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "der lieb und der lieb myrtenkron", "tokens": ["der", "lieb", "und", "der", "lieb", "myr\u00b7ten\u00b7kron"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "KON", "ART", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "zu \u00fcberkommen, steif vergie\u00dfen.", "tokens": ["zu", "\u00fc\u00b7ber\u00b7kom\u00b7men", ",", "steif", "ver\u00b7gie\u00b7\u00dfen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Mehr dan stern in der klaren nacht,", "tokens": ["Mehr", "dan", "stern", "in", "der", "kla\u00b7ren", "nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mehr dan bl\u00fcmlein des fr\u00fchlings pracht,", "tokens": ["mehr", "dan", "bl\u00fcm\u00b7lein", "des", "fr\u00fch\u00b7lings", "pracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "mehr dan auf Hybla binen fliegen,", "tokens": ["mehr", "dan", "auf", "Hy\u00b7bla", "bi\u00b7nen", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NE", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "tiefgr\u00fcndend, herzk\u00fctzlende k\u00fc\u00df,", "tokens": ["tief\u00b7gr\u00fcn\u00b7dend", ",", "herz\u00b7k\u00fctz\u00b7len\u00b7de", "k\u00fc\u00df", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJA", "NN", "$,"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.5": {"text": "und tiefempfindend s\u00fc\u00dfe b\u00fc\u00df,", "tokens": ["und", "tie\u00b7femp\u00b7fin\u00b7dend", "s\u00fc\u00b7\u00dfe", "b\u00fc\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "die m\u00fcssen ihre forcht betriegen.", "tokens": ["die", "m\u00fcs\u00b7sen", "ih\u00b7re", "forcht", "be\u00b7trie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Auch \u00e4chzen mit geilhafter schmach", "tokens": ["Auch", "\u00e4ch\u00b7zen", "mit", "geil\u00b7haf\u00b7ter", "schmach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und l\u00e4chlen mit scherzreicher sprach", "tokens": ["und", "l\u00e4ch\u00b7len", "mit", "scherz\u00b7rei\u00b7cher", "sprach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und bossen sollen da nicht fehlen:", "tokens": ["und", "bos\u00b7sen", "sol\u00b7len", "da", "nicht", "feh\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VMFIN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "schm\u00e4tz, seufzen, bitten, klag und lob,", "tokens": ["schm\u00e4tz", ",", "seuf\u00b7zen", ",", "bit\u00b7ten", ",", "klag", "und", "lob", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "VVINF", "$,", "VVFIN", "$,", "VVFIN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "schimpf, ernst, scherz, z\u00fcchtig, fein und grob", "tokens": ["schimpf", ",", "ernst", ",", "scherz", ",", "z\u00fcch\u00b7tig", ",", "fein", "und", "grob"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "$,", "ADJD", "$,", "ADJD", "$,", "ADJD", "$,", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "solt mit einander du verm\u00e4hlen.", "tokens": ["solt", "mit", "ein\u00b7an\u00b7der", "du", "ver\u00b7m\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "PRF", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Also durch der lieb rechte kunst", "tokens": ["Al\u00b7so", "durch", "der", "lieb", "rech\u00b7te", "kunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJD", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "wird sie ihr artliche ungunst", "tokens": ["wird", "sie", "ihr", "art\u00b7li\u00b7che", "un\u00b7gunst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "nach und nach artlicher verkehren", "tokens": ["nach", "und", "nach", "art\u00b7li\u00b7cher", "ver\u00b7keh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "KON", "APPR", "ADJA", "VVFIN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "und endlich, frei von forcht und zorn,", "tokens": ["und", "end\u00b7lich", ",", "frei", "von", "forcht", "und", "zorn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "mit gilg und rosen ganz ohn dorn,", "tokens": ["mit", "gilg", "und", "ro\u00b7sen", "ganz", "ohn", "dorn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "VVFIN", "ADV", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "mit ihrem deinen leib gern ehren.", "tokens": ["mit", "ih\u00b7rem", "dei\u00b7nen", "leib", "gern", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Alsdan auf eine neue art", "tokens": ["Als\u00b7dan", "auf", "ei\u00b7ne", "neu\u00b7e", "art"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mu\u00df bald mit k\u00fcssen, lang und hart,", "tokens": ["mu\u00df", "bald", "mit", "k\u00fcs\u00b7sen", ",", "lang", "und", "hart", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "VVINF", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "die seel aus ihr in dich selbs ziehen,", "tokens": ["die", "seel", "aus", "ihr", "in", "dich", "selbs", "zie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "APPR", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und sie wird auch auf gleiche weis,", "tokens": ["und", "sie", "wird", "auch", "auf", "glei\u00b7che", "weis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "APPR", "ADJA", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "sich und dich mit liebreichem flei\u00df", "tokens": ["sich", "und", "dich", "mit", "lieb\u00b7rei\u00b7chem", "flei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PRF", "KON", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "zu s\u00e4ttigen, sich selbs bem\u00fchen.", "tokens": ["zu", "s\u00e4t\u00b7ti\u00b7gen", ",", "sich", "selbs", "be\u00b7m\u00fc\u00b7hen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Und alsdan, frecher als zuvor,", "tokens": ["Und", "als\u00b7dan", ",", "fre\u00b7cher", "als", "zu\u00b7vor", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "ADJD", "KOKOM", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "erheb du das banier entbor", "tokens": ["er\u00b7heb", "du", "das", "ba\u00b7nier", "ent\u00b7bor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und fang von neuem an zu streiten,", "tokens": ["und", "fang", "von", "neu\u00b7em", "an", "zu", "strei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "APZR", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u00fcb aller s\u00fc\u00dfen schalkheit st\u00fcck,", "tokens": ["\u00fcb", "al\u00b7ler", "s\u00fc\u00b7\u00dfen", "schalk\u00b7heit", "st\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und aller s\u00fc\u00dfen bosheit d\u00fcck,", "tokens": ["und", "al\u00b7ler", "s\u00fc\u00b7\u00dfen", "bos\u00b7heit", "d\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und greif sie an auf allen seiten.", "tokens": ["und", "greif", "sie", "an", "auf", "al\u00b7len", "sei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Gebrauch list auf list, schmach auf schmach,", "tokens": ["Ge\u00b7brauch", "list", "auf", "list", ",", "schmach", "auf", "schmach", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "$,", "VVFIN", "APPR", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "bis sie froh ist, da\u00df sie zu schwach", "tokens": ["bis", "sie", "froh", "ist", ",", "da\u00df", "sie", "zu", "schwach"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$,", "KOUS", "PPER", "PTKA", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und zu verlieren, scharm\u00fctzieret;", "tokens": ["und", "zu", "ver\u00b7lie\u00b7ren", ",", "schar\u00b7m\u00fct\u00b7zie\u00b7ret", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PTKZU", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "gebrauch kunst, st\u00e4rk, betrug und macht,", "tokens": ["ge\u00b7brauch", "kunst", ",", "st\u00e4rk", ",", "be\u00b7trug", "und", "macht", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "ADJD", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "zwing sie zu einer freien schlacht,", "tokens": ["zwing", "sie", "zu", "ei\u00b7ner", "frei\u00b7en", "schlacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "da ihr beed siget und verlieret.", "tokens": ["da", "ihr", "beed", "si\u00b7get", "und", "ver\u00b7lie\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VVFIN", "KON", "VVFIN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}}, "stanza.23": {"line.1": {"text": "Und also euer frischer mut", "tokens": ["Und", "al\u00b7so", "eu\u00b7er", "fri\u00b7scher", "mut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "soll dieses s\u00fc\u00dfen kampfs ohn blut", "tokens": ["soll", "die\u00b7ses", "s\u00fc\u00b7\u00dfen", "kampfs", "ohn", "blut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PDAT", "ADJA", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "von neuem widrum euch gewehren,", "tokens": ["von", "neu\u00b7em", "wid\u00b7rum", "euch", "ge\u00b7weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "PWAV", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und, als oft Ph\u00f6be ihren glanz", "tokens": ["und", ",", "als", "oft", "Ph\u00f6\u00b7be", "ih\u00b7ren", "glanz"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "ADV", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "macht zw\u00f6lfmal halb und zw\u00f6lfmal ganz,", "tokens": ["macht", "zw\u00f6lf\u00b7mal", "halb", "und", "zw\u00f6lf\u00b7mal", "ganz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "KON", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "die welt durch eure frucht vermehren.", "tokens": ["die", "welt", "durch", "eu\u00b7re", "frucht", "ver\u00b7meh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}