{"dta.poem.1294": {"metadata": {"author": {"name": "Abschatz, Hans Assmann von", "birth": "N.A.", "death": "N.A."}, "title": "Himmel-Schl\u00fcssel  \n oder  \n Geistliche Gedichte.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1704", "urn": "urn:nbn:de:kobv:b4-200905199889", "language": ["de:0.99"], "booktitle": "Abschatz, Hans Assmann von: Poetische Ubersetzungen und Gedichte. Leipzig, 1704."}, "poem": {"stanza.1": {"line.1": {"text": "Der ungl\u00fcckselge Mensch kan kaum die Welt begr\u00fcssen/", "tokens": ["Der", "un\u00b7gl\u00fcck\u00b7sel\u00b7ge", "Mensch", "kan", "kaum", "die", "Welt", "be\u00b7gr\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "ADV", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df nicht ein Thr\u00e4nen-Flu\u00df/ eh das noch schwache Licht", "tokens": ["Da\u00df", "nicht", "ein", "Thr\u00e4\u00b7nen\u00b7Flu\u00df", "/", "eh", "das", "noch", "schwa\u00b7che", "Licht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "ART", "NN", "$(", "KOUS", "PDS", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den hellen Tag erkennt/ aus seinen Augen bricht/", "tokens": ["Den", "hel\u00b7len", "Tag", "er\u00b7kennt", "/", "aus", "sei\u00b7nen", "Au\u00b7gen", "bricht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$(", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wird frey und l\u00e4sset sich in neue Bande schl\u00fcssen.", "tokens": ["Wird", "frey", "und", "l\u00e4s\u00b7set", "sich", "in", "neu\u00b7e", "Ban\u00b7de", "schl\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KON", "VVFIN", "PRF", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Bringt seine Jahre zu gewiegt in Freud und Leyd/", "tokens": ["Bringt", "sei\u00b7ne", "Jah\u00b7re", "zu", "ge\u00b7wiegt", "in", "Freud", "und", "Leyd", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKZU", "VVFIN", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In Unruh/ Sorg und Angst/ in Hoffnung/ Furcht und Streit/", "tokens": ["In", "Un\u00b7ruh", "/", "Sorg", "und", "Angst", "/", "in", "Hoff\u00b7nung", "/", "Furcht", "und", "Streit", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "NN", "KON", "NN", "$(", "APPR", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bi\u00df ihn der lange Schlaff der Ruhe l\u00e4st gen\u00fcssen/", "tokens": ["Bi\u00df", "ihn", "der", "lan\u00b7ge", "Schlaff", "der", "Ru\u00b7he", "l\u00e4st", "ge\u00b7n\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was aber klagen wir? wann wir die Welt begr\u00fcssen", "tokens": ["Was", "a\u00b7ber", "kla\u00b7gen", "wir", "?", "wann", "wir", "die", "Welt", "be\u00b7gr\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "VVFIN", "PPER", "$.", "PWAV", "PPER", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "So hat uns JEsus Hand ein Freybad zugericht/", "tokens": ["So", "hat", "uns", "Je\u00b7sus", "Hand", "ein", "Frey\u00b7bad", "zu\u00b7ge\u00b7richt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NE", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "W\u00e4scht/ reiniget und st\u00e4rckt der bl\u00f6den Augen Licht/", "tokens": ["W\u00e4scht", "/", "rei\u00b7ni\u00b7get", "und", "st\u00e4rckt", "der", "bl\u00f6\u00b7den", "Au\u00b7gen", "Licht", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VVFIN", "KON", "VVFIN", "ART", "ADJA", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Befreyet von dem Strick der Erb-Schuld das Gewissen/", "tokens": ["Be\u00b7fre\u00b7yet", "von", "dem", "Strick", "der", "Er\u00b7bSchuld", "das", "Ge\u00b7wis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ART", "NN", "ART", "NN", "$("], "meter": "-+---+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sein Blut ist unsre Milch/ sein Unschuld unser Kleid/", "tokens": ["Sein", "Blut", "ist", "uns\u00b7re", "Milch", "/", "sein", "Un\u00b7schuld", "un\u00b7ser", "Kleid", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "$(", "PPOSAT", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Wiege seine Scho\u00df/ der Schlaff die Seligkeit.", "tokens": ["Die", "Wie\u00b7ge", "sei\u00b7ne", "Scho\u00df", "/", "der", "Schlaff", "die", "Se\u00b7lig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$(", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Di\u00df la\u00df mich auch/ O GOTT/ allhier und dort geniessen.", "tokens": ["Di\u00df", "la\u00df", "mich", "auch", "/", "O", "GoTT", "/", "all\u00b7hier", "und", "dort", "ge\u00b7nies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "$(", "NE", "NE", "$(", "ADV", "KON", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}