{"dta.poem.5513": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "N eu- J ahrs  G edancken  \n bey dem Eintritt des 1733sten Jahrs.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1736", "urn": "urn:nbn:de:kobv:b4-200905198582", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Der Erden Kreis-Lauf, dessen Ende", "tokens": ["Der", "Er\u00b7den", "Kreis\u00b7Lauf", ",", "des\u00b7sen", "En\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "NN", "$,", "PRELAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Uns immer mehr und mehr vom Licht der Sonnen", "tokens": ["Uns", "im\u00b7mer", "mehr", "und", "mehr", "vom", "Licht", "der", "Son\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "ADV", "KON", "ADV", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wodurch man immer mehr Nacht, Sturm und Frost ver-", "tokens": ["Wo\u00b7durch", "man", "im\u00b7mer", "mehr", "Nacht", ",", "Sturm", "und", "Frost", "ver"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ADV", "PIAT", "NN", "$,", "NN", "KON", "NN", "TRUNC"], "meter": "-+-+--++-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Ist heute, GOtt sey Lob! vollbracht. Die frohe Wende,", "tokens": ["Ist", "heu\u00b7te", ",", "Gott", "sey", "Lob", "!", "voll\u00b7bracht", ".", "Die", "fro\u00b7he", "Wen\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "NN", "VAFIN", "NN", "$.", "VVPP", "$.", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wodurch wir uns zur Sonne wieder drehn,", "tokens": ["Wo\u00b7durch", "wir", "uns", "zur", "Son\u00b7ne", "wie\u00b7der", "drehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "APPRART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Ist allbereit geschehn.", "tokens": ["Ist", "all\u00b7be\u00b7reit", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Selbst\u00e4ndige Weisheit! Selbst\u00e4ndige Liebe!", "tokens": ["Selb\u00b7st\u00e4n\u00b7di\u00b7ge", "Weis\u00b7heit", "!", "Selb\u00b7st\u00e4n\u00b7di\u00b7ge", "Lie\u00b7be", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Unendlicher ewiger Vater des Lichts!", "tokens": ["Un\u00b7end\u00b7li\u00b7cher", "e\u00b7wi\u00b7ger", "Va\u00b7ter", "des", "Lichts", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Du rieffest einst Allem, und schuffst es aus Nichts.", "tokens": ["Du", "rief\u00b7fest", "einst", "Al\u00b7lem", ",", "und", "schuffst", "es", "aus", "Nichts", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "$,", "KON", "VVFIN", "PPER", "APPR", "PIS", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Es drehn sich, durch deine bewegende Triebe,", "tokens": ["Es", "drehn", "sich", ",", "durch", "dei\u00b7ne", "be\u00b7we\u00b7gen\u00b7de", "Trie\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.5": {"text": "Die Himmlischen Kreise. Die Angel stehn", "tokens": ["Die", "Himm\u00b7li\u00b7schen", "Krei\u00b7se", ".", "Die", "An\u00b7gel", "stehn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "ART", "NN", "VVINF"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Auf deinen Befehl. Es verfliegen, vergehn", "tokens": ["Auf", "dei\u00b7nen", "Be\u00b7fehl", ".", "Es", "ver\u00b7flie\u00b7gen", ",", "ver\u00b7gehn"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["APPR", "PPOSAT", "NN", "$.", "PPER", "VVFIN", "$,", "VVINF"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.7": {"text": "Die Jahre nicht anders, als fl\u00fcchtige Stunden;", "tokens": ["Die", "Jah\u00b7re", "nicht", "an\u00b7ders", ",", "als", "fl\u00fcch\u00b7ti\u00b7ge", "Stun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "ADV", "$,", "KOUS", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.8": {"text": "Die Zeit scheint ein Punct-Flu\u00df von schnellen\nSecunden.", "tokens": ["Die", "Zeit", "scheint", "ein", "Punc\u00b7tFlu\u00df", "von", "schnel\u00b7len", "Se\u00b7cun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.9": {"text": "Ach la\u00df mich, zu deinen unendlichen Ehren,", "tokens": ["Ach", "la\u00df", "mich", ",", "zu", "dei\u00b7nen", "un\u00b7end\u00b7li\u00b7chen", "Eh\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVIMP", "PPER", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.10": {"text": "Nebst andern, so irdisch-als himmlischen, Ch\u00f6ren,", "tokens": ["Nebst", "an\u00b7dern", ",", "so", "ir\u00b7dischals", "himm\u00b7li\u00b7schen", ",", "Ch\u00f6\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "ADV", "ADV", "VVINF", "$,", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Bey unserer Jahre vollendeten Schrancken,", "tokens": ["Bey", "un\u00b7se\u00b7rer", "Jah\u00b7re", "voll\u00b7en\u00b7de\u00b7ten", "Schran\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.12": {"text": "Dein' Allmacht erheben, durch Loben und Dancken!", "tokens": ["Dein'", "All\u00b7macht", "er\u00b7he\u00b7ben", ",", "durch", "Lo\u00b7ben", "und", "Dan\u00b7cken", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$,", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Auf! auf, mein Geist! la\u00df Brunst und Andacht glimmen,", "tokens": ["Auf", "!", "auf", ",", "mein", "Geist", "!", "la\u00df", "Brunst", "und", "An\u00b7dacht", "glim\u00b7men", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "PTKVZ", "$,", "PPOSAT", "NN", "$.", "VVIMP", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf! auf, zu dieser Zeit, ein Danck-Lied anzustimmen", "tokens": ["Auf", "!", "auf", ",", "zu", "die\u00b7ser", "Zeit", ",", "ein", "Dan\u00b7ck\u00b7Lied", "an\u00b7zu\u00b7stim\u00b7men"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "$.", "PTKVZ", "$,", "APPR", "PDAT", "NN", "$,", "ART", "NN", "VVIZU"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Dem grossen All, das alles schafft, regiret,", "tokens": ["Dem", "gros\u00b7sen", "All", ",", "das", "al\u00b7les", "schafft", ",", "re\u00b7gi\u00b7ret", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PIS", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und aller Himmel Heer in solcher Ordnung f\u00fchret,", "tokens": ["Und", "al\u00b7ler", "Him\u00b7mel", "Heer", "in", "sol\u00b7cher", "Ord\u00b7nung", "f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "NN", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da\u00df alles unverr\u00fcckt besteht,", "tokens": ["Da\u00df", "al\u00b7les", "un\u00b7ver\u00b7r\u00fcckt", "be\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df nichts aus seinen Schrancken geht!", "tokens": ["Da\u00df", "nichts", "aus", "sei\u00b7nen", "Schran\u00b7cken", "geht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Und da ich dich, geliebter Freund, allhier,", "tokens": ["Und", "da", "ich", "dich", ",", "ge\u00b7lieb\u00b7ter", "Freund", ",", "all\u00b7hier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "$,", "ADJA", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "So wie vor dem einmahl, zu eben dieser Zeit,", "tokens": ["So", "wie", "vor", "dem", "ein\u00b7mahl", ",", "zu", "e\u00b7ben", "die\u00b7ser", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "APPR", "ART", "ADV", "$,", "APPR", "ADV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nicht ohn Vergn\u00fcgen bey mir finde;", "tokens": ["Nicht", "ohn", "Ver\u00b7gn\u00fc\u00b7gen", "bey", "mir", "fin\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So, bitt ich dich, verbinde", "tokens": ["So", ",", "bitt", "ich", "dich", ",", "ver\u00b7bin\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ADV", "$,", "VVFIN", "PPER", "PRF", "$,", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Dein Lob-Lied auch mit mir.", "tokens": ["Dein", "Lob\u00b7Lied", "auch", "mit", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Du hast, vor mehr als sieben Jahren,", "tokens": ["Du", "hast", ",", "vor", "mehr", "als", "sie\u00b7ben", "Jah\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "APPR", "PIAT", "KOKOM", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da wir im Neuen Jahr, wie jetzt, beysammen waren,", "tokens": ["Da", "wir", "im", "Neu\u00b7en", "Jahr", ",", "wie", "jetzt", ",", "bey\u00b7sam\u00b7men", "wa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN", "$,", "PWAV", "ADV", "$,", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mir einen grossen Dienst gethan,", "tokens": ["Mir", "ei\u00b7nen", "gros\u00b7sen", "Dienst", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und von der duncklen Zweifels-Bahn", "tokens": ["Und", "von", "der", "dunck\u00b7len", "Zwei\u00b7fels\u00b7Bahn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mich abgeleitet, unterwiesen,", "tokens": ["Mich", "ab\u00b7ge\u00b7lei\u00b7tet", ",", "un\u00b7ter\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und mir, des grossen Sch\u00f6pfers Macht,", "tokens": ["Und", "mir", ",", "des", "gros\u00b7sen", "Sch\u00f6p\u00b7fers", "Macht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So \u00fcberzeuglich beygebracht,", "tokens": ["So", "\u00fc\u00b7berz\u00b7eug\u00b7lich", "bey\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df ich dir oft gedauckt, den Sch\u00f6pfer oft gepriesen,", "tokens": ["Da\u00df", "ich", "dir", "oft", "ge\u00b7dauckt", ",", "den", "Sch\u00f6p\u00b7fer", "oft", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "VVPP", "$,", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich bin demnach von GOttes ew\u2019gem Wesen", "tokens": ["Ich", "bin", "dem\u00b7nach", "von", "Got\u00b7tes", "ew'\u00b7gem", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PAV", "APPR", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Von seiner Gr\u00f6sse Herrlichkeit,", "tokens": ["Von", "sei\u00b7ner", "Gr\u00f6s\u00b7se", "Herr\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Von seiner seeligen Vollkommenheit,", "tokens": ["Von", "sei\u00b7ner", "see\u00b7li\u00b7gen", "Voll\u00b7kom\u00b7men\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Genugsahm \u00fcberf\u00fchrt. Das Welt-Buch l\u00e4\u00dft mich lesen:", "tokens": ["Ge\u00b7nu\u00b7gsahm", "\u00fc\u00b7berf\u00b7\u00fchrt", ".", "Das", "Welt\u00b7Buch", "l\u00e4\u00dft", "mich", "le\u00b7sen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$.", "ART", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wie unbegreiflich-wunderbar", "tokens": ["Wie", "un\u00b7be\u00b7greif\u00b7lich\u00b7wun\u00b7der\u00b7bar"], "token_info": ["word", "word"], "pos": ["PWAV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Sein G\u00f6ttlich All an allen Orten sey.", "tokens": ["Sein", "G\u00f6tt\u00b7lich", "All", "an", "al\u00b7len", "Or\u00b7ten", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "APPR", "PIAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Allein mir f\u00e4llt noch oft ein alter Zweiffel bey.", "tokens": ["Al\u00b7lein", "mir", "f\u00e4llt", "noch", "oft", "ein", "al\u00b7ter", "Zweif\u00b7fel", "bey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Mich deucht, es sey noch lange nicht so klar,", "tokens": ["Mich", "deucht", ",", "es", "sey", "noch", "lan\u00b7ge", "nicht", "so", "klar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ADV", "ADV", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Da\u00df die Unsterblichkeit von unsern Seelen", "tokens": ["Da\u00df", "die", "U\u00b7nsterb\u00b7lich\u00b7keit", "von", "un\u00b7sern", "See\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.18": {"text": "Ohn Ungewi\u00dfheit sey. Ich kann dir nichts verheelen,", "tokens": ["Ohn", "Un\u00b7ge\u00b7wi\u00df\u00b7heit", "sey", ".", "Ich", "kann", "dir", "nichts", "ver\u00b7hee\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "$.", "PPER", "VMFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Ich f\u00fchle da\u00df mich noch verschiedne Zweiffel qv\u00e4len,", "tokens": ["Ich", "f\u00fch\u00b7le", "da\u00df", "mich", "noch", "ver\u00b7schied\u00b7ne", "Zweif\u00b7fel", "qv\u00e4\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOUS", "PPER", "ADV", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und w\u00fcnscht\u2019 ich inniglich,", "tokens": ["Und", "w\u00fcnscht'", "ich", "in\u00b7nig\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.21": {"text": "Da\u00df du, aus Mitleid, dich", "tokens": ["Da\u00df", "du", ",", "aus", "Mit\u00b7leid", ",", "dich"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "$,", "APPR", "NN", "$,", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.22": {"text": "So viel beliebtest zu bem\u00fchen,", "tokens": ["So", "viel", "be\u00b7lieb\u00b7test", "zu", "be\u00b7m\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Mich aus des Zweifels Meer noch einst heraus zu ziehen,", "tokens": ["Mich", "aus", "des", "Zwei\u00b7fels", "Meer", "noch", "einst", "he\u00b7raus", "zu", "zie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "NN", "ADV", "ADV", "APZR", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "In welchem ich noch treib\u2019.", "tokens": ["In", "wel\u00b7chem", "ich", "noch", "treib'", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Ich stellte dir", "tokens": ["Ich", "stell\u00b7te", "dir"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Ja dazumahl verschiedne Gr\u00fcnde f\u00fcr,", "tokens": ["Ja", "da\u00b7zu\u00b7mahl", "ver\u00b7schied\u00b7ne", "Gr\u00fcn\u00b7de", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ADJA", "NN", "APPR", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Die \u00fcberzeuglich gnug. Doch, da es GOtt zu Ehren", "tokens": ["Die", "\u00fc\u00b7berz\u00b7eug\u00b7lich", "gnug", ".", "Doch", ",", "da", "es", "Gott", "zu", "Eh\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADV", "$.", "KON", "$,", "KOUS", "PPER", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vermuthlich auch gereicht, wenn ich, zu dieser Zeit,", "tokens": ["Ver\u00b7muth\u00b7lich", "auch", "ge\u00b7reicht", ",", "wenn", "ich", ",", "zu", "die\u00b7ser", "Zeit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$,", "KOUS", "PPER", "$,", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Von seiner Liebe Gr\u00f6\u00df\u2019 und Unerm\u00e4\u00dflichkeit,", "tokens": ["Von", "sei\u00b7ner", "Lie\u00b7be", "Gr\u00f6\u00df'", "und", "Un\u00b7er\u00b7m\u00e4\u00df\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In Ansehn unsers Geists, was deutliches zu lehren", "tokens": ["In", "An\u00b7sehn", "un\u00b7sers", "Geists", ",", "was", "deut\u00b7li\u00b7ches", "zu", "leh\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "PPOSAT", "NN", "$,", "PRELS", "PIS", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mich jetzt besch\u00e4ftige;", "tokens": ["Mich", "jetzt", "be\u00b7sch\u00e4f\u00b7ti\u00b7ge", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "So will ich, auf dein Fragen,", "tokens": ["So", "will", "ich", ",", "auf", "dein", "Fra\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Dir nicht allein hier meine Meynung sagen;", "tokens": ["Dir", "nicht", "al\u00b7lein", "hier", "mei\u00b7ne", "Mey\u00b7nung", "sa\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ich will nachher, wie ich mir vorgenommen,", "tokens": ["Ich", "will", "nach\u00b7her", ",", "wie", "ich", "mir", "vor\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "$,", "PWAV", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "So, wie wir einst von der Materie", "tokens": ["So", ",", "wie", "wir", "einst", "von", "der", "Ma\u00b7te\u00b7rie"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PWAV", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Verschiedne Kr\u00e4ft\u2019, erstaunt, erwogen,", "tokens": ["Ver\u00b7schied\u00b7ne", "Kr\u00e4ft'", ",", "er\u00b7staunt", ",", "er\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVPP", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Durch einen neuen Trieb darzu gezogen,", "tokens": ["Durch", "ei\u00b7nen", "neu\u00b7en", "Trieb", "dar\u00b7zu", "ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Auch auf der Seelen Kr\u00e4fte kommen,", "tokens": ["Auch", "auf", "der", "See\u00b7len", "Kr\u00e4f\u00b7te", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Und, wo nicht mehr, doch minstens, eine Kraft", "tokens": ["Und", ",", "wo", "nicht", "mehr", ",", "doch", "mins\u00b7tens", ",", "ei\u00b7ne", "Kraft"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "$,", "PWAV", "PTKNEG", "ADV", "$,", "ADV", "ADV", "$,", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Und sonderbahre Eigenschaft", "tokens": ["Und", "son\u00b7der\u00b7bah\u00b7re", "Ei\u00b7gen\u00b7schaft"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Der Menschen auf der Welt vorhandnen Seel\u2019, erwegen,", "tokens": ["Der", "Men\u00b7schen", "auf", "der", "Welt", "vor\u00b7hand\u00b7nen", "Seel'", ",", "er\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Die deine Zweifel auch daneben", "tokens": ["Die", "dei\u00b7ne", "Zwei\u00b7fel", "auch", "da\u00b7ne\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "ADV", "PAV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Vielleicht geschickt am kr\u00e4ftigsten zu heben.", "tokens": ["Viel\u00b7leicht", "ge\u00b7schickt", "am", "kr\u00e4f\u00b7tigs\u00b7ten", "zu", "he\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "APPRART", "ADJA", "PTKZU", "VVINF", "$."], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.18": {"text": "Gieb, grosser Sch\u00f6pfer, doch zu beydem deinen Seegen!", "tokens": ["Gieb", ",", "gros\u00b7ser", "Sch\u00f6p\u00b7fer", ",", "doch", "zu", "bey\u00b7dem", "dei\u00b7nen", "See\u00b7gen", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "ADJA", "NN", "$,", "ADV", "PTKA", "PIS", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Was die Unsterblichkeit der Seelen nun betrift,", "tokens": ["Was", "die", "U\u00b7nsterb\u00b7lich\u00b7keit", "der", "See\u00b7len", "nun", "be\u00b7trift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.20": {"text": "Bedaur\u2019 ich zwar, da\u00df dich von dieser Wahrheit,", "tokens": ["Be\u00b7daur'", "ich", "zwar", ",", "da\u00df", "dich", "von", "die\u00b7ser", "Wahr\u00b7heit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "$,", "KOUS", "PPER", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "So wenig mein Gespr\u00e4ch, als auch die Schrift,", "tokens": ["So", "we\u00b7nig", "mein", "Ge\u00b7spr\u00e4ch", ",", "als", "auch", "die", "Schrift", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "$,", "KOUS", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Die doch hievon mit solcher Klarheit", "tokens": ["Die", "doch", "hie\u00b7von", "mit", "sol\u00b7cher", "Klar\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "PAV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Uns zeugt, dich \u00fcberzeugt. Drum will ich mich bequehmen,", "tokens": ["Uns", "zeugt", ",", "dich", "\u00fc\u00b7berz\u00b7eugt", ".", "Drum", "will", "ich", "mich", "be\u00b7queh\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVPP", "$.", "PAV", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Nebst ihnen die Vernunft zu H\u00fclff\u2019 zu nehmen.", "tokens": ["Nebst", "ih\u00b7nen", "die", "Ver\u00b7nunft", "zu", "H\u00fclff'", "zu", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Um dieses nun noch ferner zu erkl\u00e4ren,", "tokens": ["Um", "die\u00b7ses", "nun", "noch", "fer\u00b7ner", "zu", "er\u00b7kl\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PDAT", "ADV", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "So stell ich dir", "tokens": ["So", "stell", "ich", "dir"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "PPER", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.27": {"text": "Selbst aus der weisen Heyden Lehren,", "tokens": ["Selbst", "aus", "der", "wei\u00b7sen", "Hey\u00b7den", "Leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Von unsrer Seelen Daur, hier ihre Meynung f\u00fcr.", "tokens": ["Von", "uns\u00b7rer", "See\u00b7len", "Daur", ",", "hier", "ih\u00b7re", "Mey\u00b7nung", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,", "ADV", "PPOSAT", "NN", "APPR", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Es saget hievon Cicero,", "tokens": ["Es", "sa\u00b7get", "hie\u00b7von", "Ci\u00b7ce\u00b7ro", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "In Scipionis Traum, also:", "tokens": ["In", "Sci\u00b7pi\u00b7o\u00b7nis", "Traum", ",", "al\u00b7so", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NE", "NN", "$,", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Ein Wesen, das sich selbst beweget,", "tokens": ["Ein", "We\u00b7sen", ",", "das", "sich", "selbst", "be\u00b7we\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dem wird die Kraft, da\u00df es sich reget,", "tokens": ["Dem", "wird", "die", "Kraft", ",", "da\u00df", "es", "sich", "re\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "Weil es sich selbst nicht wird entstehn,", "tokens": ["Weil", "es", "sich", "selbst", "nicht", "wird", "ent\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "PTKNEG", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch nimmermehr vergehn.", "tokens": ["Auch", "nim\u00b7mer\u00b7mehr", "ver\u00b7gehn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Noch einen andern Grund", "tokens": ["Noch", "ei\u00b7nen", "an\u00b7dern", "Grund"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Legt Cicero Catoni in den Mund:", "tokens": ["Legt", "Ci\u00b7ce\u00b7ro", "Ca\u00b7to\u00b7ni", "in", "den", "Mund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "NE", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Da, spricht er, unser Geist so viel Geschwindigkeit", "tokens": ["Da", ",", "spricht", "er", ",", "un\u00b7ser", "Geist", "so", "viel", "Ge\u00b7schwin\u00b7dig\u00b7keit"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auch die Erinn\u2019rung hat von Dingen, die vergehen,", "tokens": ["Auch", "die", "Er\u00b7inn'\u00b7rung", "hat", "von", "Din\u00b7gen", ",", "die", "ver\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "APPR", "NN", "$,", "PRELS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da er voraus ersieht die Dinge k\u00fcnftger Zeit,", "tokens": ["Da", "er", "vo\u00b7raus", "er\u00b7sieht", "die", "Din\u00b7ge", "k\u00fcnft\u00b7ger", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die noch zu seyn nicht angefangen,", "tokens": ["Die", "noch", "zu", "seyn", "nicht", "an\u00b7ge\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PTKZU", "VAINF", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da so viel Kunst und Wissenschaften,", "tokens": ["Da", "so", "viel", "Kunst", "und", "Wis\u00b7sen\u00b7schaf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So manch\u2019 Erfindung an ihr haften;", "tokens": ["So", "man\u00b7ch'", "Er\u00b7fin\u00b7dung", "an", "ihr", "haf\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "So stimmt ja die\u00df mit ihr am meisten \u00fcberein,", "tokens": ["So", "stimmt", "ja", "die\u00df", "mit", "ihr", "am", "meis\u00b7ten", "\u00fc\u00b7be\u00b7re\u00b7in", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PDS", "APPR", "PPOSAT", "PTKA", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.8": {"text": "Sie m\u00fcsse von Natur unsterblich seyn.", "tokens": ["Sie", "m\u00fcs\u00b7se", "von", "Na\u00b7tur", "uns\u00b7terb\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Es spricht derselbe noch an einem andern Ort:", "tokens": ["Es", "spricht", "der\u00b7sel\u00b7be", "noch", "an", "ei\u00b7nem", "an\u00b7dern", "Ort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDAT", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Ich f\u00fchl\u2019 in meiner Seel, wie sie sich selbst erh\u00f6het,", "tokens": ["Ich", "f\u00fchl'", "in", "mei\u00b7ner", "Seel", ",", "wie", "sie", "sich", "selbst", "er\u00b7h\u00f6\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "PWAV", "PPER", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wie die Nachwelt ihr also vor Augen stehet,", "tokens": ["Und", "wie", "die", "Nach\u00b7welt", "ihr", "al\u00b7so", "vor", "Au\u00b7gen", "ste\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "PPER", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Als ob sie allererst, wenn sie von dieser Erde", "tokens": ["Als", "ob", "sie", "al\u00b7le\u00b7rerst", ",", "wenn", "sie", "von", "die\u00b7ser", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "PPER", "ADV", "$,", "KOUS", "PPER", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wird abgeschieden seyn, aufs neue leben werde.", "tokens": ["Wird", "ab\u00b7ge\u00b7schie\u00b7den", "seyn", ",", "aufs", "neu\u00b7e", "le\u00b7ben", "wer\u00b7de", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "VAINF", "$,", "APPRART", "ADJA", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wenn unsre Seele nicht unsterblich w\u00e4re;", "tokens": ["Wenn", "uns\u00b7re", "See\u00b7le", "nicht", "uns\u00b7terb\u00b7lich", "w\u00e4\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PTKNEG", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So w\u00fcrden wackrer Leute Seelen,", "tokens": ["So", "w\u00fcr\u00b7den", "wack\u00b7rer", "Leu\u00b7te", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Mit solcher M\u00fche, nicht des Nachruhms Ehre", "tokens": ["Mit", "sol\u00b7cher", "M\u00fc\u00b7he", ",", "nicht", "des", "Nach\u00b7ruhms", "Eh\u00b7re"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "PTKNEG", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und die Unsterblichkeit zu ihrem Zweck erwehlen.", "tokens": ["Und", "die", "U\u00b7nsterb\u00b7lich\u00b7keit", "zu", "ih\u00b7rem", "Zweck", "er\u00b7weh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.13": {"line.1": {"text": "Noch einen andern Grund bringt Xenophon uns bey:", "tokens": ["Noch", "ei\u00b7nen", "an\u00b7dern", "Grund", "bringt", "Xe\u00b7no\u00b7phon", "uns", "bey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "ADV", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Jhr seht, spricht er, wie nichts so \u00e4hnlich sey", "tokens": ["Ihr", "seht", ",", "spricht", "er", ",", "wie", "nichts", "so", "\u00e4hn\u00b7lich", "sey"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PPER", "$,", "PWAV", "PIS", "ADV", "ADJD", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dem Tod\u2019, als wie der Schlaff; nun zeigen Seelen,", "tokens": ["Dem", "Tod'", ",", "als", "wie", "der", "Schlaff", ";", "nun", "zei\u00b7gen", "See\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "KOKOM", "ART", "NN", "$.", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die schlaffen, ihre G\u00f6ttlichkeit", "tokens": ["Die", "schlaf\u00b7fen", ",", "ih\u00b7re", "G\u00f6tt\u00b7lich\u00b7keit"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PDS", "VVFIN", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vortreflich an. Indem sie frey;", "tokens": ["Vor\u00b7tre\u00b7flich", "an", ".", "In\u00b7dem", "sie", "frey", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "$.", "KOUS", "PPER", "ADJD", "$."], "meter": "+----+-+", "measure": "dactylic.init"}, "line.5": {"text": "Sieht jede, von der k\u00fcnftgen Zeit,", "tokens": ["Sieht", "je\u00b7de", ",", "von", "der", "k\u00fcnft\u00b7gen", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Verschiednes schon vorher. Daraus ist leicht zu", "tokens": ["Ver\u00b7schied\u00b7nes", "schon", "vor\u00b7her", ".", "Da\u00b7raus", "ist", "leicht", "zu"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ADV", "$.", "PAV", "VAFIN", "ADJD", "PTKZU"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.15": {"line.1": {"text": "Wie treflich Seelen seyn, ja noch erst werden m\u00fcssen,", "tokens": ["Wie", "tref\u00b7lich", "See\u00b7len", "seyn", ",", "ja", "noch", "erst", "wer\u00b7den", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "NN", "VAINF", "$,", "ADV", "ADV", "ADV", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn sie von ird\u2019scher Last nun v\u00f6llig erst befreyt.", "tokens": ["Wenn", "sie", "von", "ird'\u00b7scher", "Last", "nun", "v\u00f6l\u00b7lig", "erst", "be\u00b7freyt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "ADV", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Noch einen Grund sucht uns Alem\u00e4on vorzulegen:", "tokens": ["Noch", "ei\u00b7nen", "Grund", "sucht", "uns", "A\u00b7le\u00b7m\u00e4\u00b7on", "vor\u00b7zu\u00b7le\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PPER", "NE", "VVIZU", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.17": {"line.1": {"text": "Er schlie\u00dft: da\u00df unsre Seel\u2019 unsterblich sey, deswegen,", "tokens": ["Er", "schlie\u00dft", ":", "da\u00df", "uns\u00b7re", "Seel'", "uns\u00b7terb\u00b7lich", "sey", ",", "des\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "KOUS", "PPOSAT", "NN", "ADJD", "VAFIN", "$,", "PAV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Weil sie den Dingen gleich, die unverg\u00e4nglich seyn.", "tokens": ["Weil", "sie", "den", "Din\u00b7gen", "gleich", ",", "die", "un\u00b7ver\u00b7g\u00e4ng\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "$,", "PRELS", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Gleichheit nun trift darin ein,", "tokens": ["Die", "Gleich\u00b7heit", "nun", "trift", "da\u00b7rin", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PAV", "PTKVZ", "$,"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Da\u00df die Bewegung sich nie von der Seel entferne", "tokens": ["Da\u00df", "die", "Be\u00b7we\u00b7gung", "sich", "nie", "von", "der", "Seel", "ent\u00b7fer\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PRF", "ADV", "APPR", "ART", "NN", "VVFIN"], "meter": "---+--+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und da\u00df, was G\u00f6ttlich ist, die Sonne, Mond und", "tokens": ["Und", "da\u00df", ",", "was", "G\u00f6tt\u00b7lich", "ist", ",", "die", "Son\u00b7ne", ",", "Mond", "und"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "KOUS", "$,", "PRELS", "ADJD", "VAFIN", "$,", "ART", "NN", "$,", "NN", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ja aller Himmel Kreise", "tokens": ["Ja", "al\u00b7ler", "Him\u00b7mel", "Krei\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKANT", "PIAT", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Sich regen auf dieselbe Weise.", "tokens": ["Sich", "re\u00b7gen", "auf", "die\u00b7sel\u00b7be", "Wei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJA", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Noch giebt ein andrer uns den Unterricht,", "tokens": ["Noch", "giebt", "ein", "an\u00b7drer", "uns", "den", "Un\u00b7ter\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wenn er, wie folget, spricht:", "tokens": ["Wenn", "er", ",", "wie", "fol\u00b7get", ",", "spricht", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PWAV", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Die Seelen haben nur die Eigenschaft allein,", "tokens": ["Die", "See\u00b7len", "ha\u00b7ben", "nur", "die", "Ei\u00b7gen\u00b7schaft", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df sie stets j\u00fcnger sind, je \u00e4lter da\u00df sie seyn.", "tokens": ["Da\u00df", "sie", "stets", "j\u00fcn\u00b7ger", "sind", ",", "je", "\u00e4l\u00b7ter", "da\u00df", "sie", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,", "ADV", "ADJD", "KOUS", "PPER", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Die Gr\u00fcnde haben zwar von Wahrheit einen Schein;", "tokens": ["Die", "Gr\u00fcn\u00b7de", "ha\u00b7ben", "zwar", "von", "Wahr\u00b7heit", "ei\u00b7nen", "Schein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Allein,", "tokens": ["Al\u00b7lein", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Wenn man sie n\u00e4her \u00fcberleget,", "tokens": ["Wenn", "man", "sie", "n\u00e4\u00b7her", "\u00fc\u00b7ber\u00b7le\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und ihre W\u00fcrcklichkeit erweget;", "tokens": ["Und", "ih\u00b7re", "W\u00fcrck\u00b7lich\u00b7keit", "er\u00b7we\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Verlieren sie von ihrem Schimmer viel.", "tokens": ["Ver\u00b7lie\u00b7ren", "sie", "von", "ih\u00b7rem", "Schim\u00b7mer", "viel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Sie sind mir wol bekannt, ich habe sie gelesen,", "tokens": ["Sie", "sind", "mir", "wol", "be\u00b7kannt", ",", "ich", "ha\u00b7be", "sie", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADJD", "$,", "PPER", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie sind mir lange nicht mehr unbewust gewesen;", "tokens": ["Sie", "sind", "mir", "lan\u00b7ge", "nicht", "mehr", "un\u00b7be\u00b7wust", "ge\u00b7we\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PTKNEG", "ADV", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Doch sind\u2019 ich jetzt, sie gehn nur gar zu weit vom Ziel.", "tokens": ["Doch", "sind'", "ich", "jetzt", ",", "sie", "gehn", "nur", "gar", "zu", "weit", "vom", "Ziel", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "ADV", "$,", "PPER", "VVFIN", "ADV", "ADV", "PTKA", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wir wollen, nach der Reihe, gehn,", "tokens": ["Wir", "wol\u00b7len", ",", "nach", "der", "Rei\u00b7he", ",", "gehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "APPR", "ART", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und sie mit Flei\u00df und Achtsamkeit besehn.", "tokens": ["Und", "sie", "mit", "Flei\u00df", "und", "Acht\u00b7sam\u00b7keit", "be\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Dein ersterer Beweis w\u00e4r\u2019 herrlich, w\u00e4r es nur", "tokens": ["Dein", "ers\u00b7te\u00b7rer", "Be\u00b7weis", "w\u00e4r'", "herr\u00b7lich", ",", "w\u00e4r", "es", "nur"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADJD", "$,", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Von ihr, als einer Creatur,", "tokens": ["Von", "ihr", ",", "als", "ei\u00b7ner", "Crea\u00b7tur", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "KOUS", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.13": {"text": "Erwei\u00dflich, da\u00df der Seelen Kraft", "tokens": ["Er\u00b7wei\u00df\u00b7lich", ",", "da\u00df", "der", "See\u00b7len", "Kraft"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "KOUS", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Und der Bewegung Eigenschaft", "tokens": ["Und", "der", "Be\u00b7we\u00b7gung", "Ei\u00b7gen\u00b7schaft"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Blo\u00df von ihr selbst, und nicht vielmehr", "tokens": ["Blo\u00df", "von", "ihr", "selbst", ",", "und", "nicht", "viel\u00b7mehr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "APPR", "PPER", "ADV", "$,", "KON", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Von ", "tokens": ["Von"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.17": {"text": "Entstanden und erhalten w\u00e4r.", "tokens": ["Ent\u00b7stan\u00b7den", "und", "er\u00b7hal\u00b7ten", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Denn w\u00e4re die\u00df; k\u00e4m\u2019 es ja gantz und gar", "tokens": ["Denn", "w\u00e4\u00b7re", "die\u00df", ";", "k\u00e4m'", "es", "ja", "gantz", "und", "gar"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PDS", "$.", "VVFIN", "PPER", "ADV", "ADV", "KON", "ADV"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.19": {"text": "Auf GOttes Willen an, wie lang\u2019 er g\u00f6nne,", "tokens": ["Auf", "Got\u00b7tes", "Wil\u00b7len", "an", ",", "wie", "lang'", "er", "g\u00f6n\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "PTKVZ", "$,", "PWAV", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Da\u00df sie sich so bewegen k\u00f6nne.", "tokens": ["Da\u00df", "sie", "sich", "so", "be\u00b7we\u00b7gen", "k\u00f6n\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Der andre Grund ist noch so kr\u00e4ftig nicht,", "tokens": ["Der", "and\u00b7re", "Grund", "ist", "noch", "so", "kr\u00e4f\u00b7tig", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "ADV", "ADJD", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Als wie der erste war.", "tokens": ["Als", "wie", "der", "ers\u00b7te", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "ADJA", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.23": {"text": "Ans diesem folget zwar", "tokens": ["Ans", "die\u00b7sem", "fol\u00b7get", "zwar"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PDAT", "VVFIN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.24": {"text": "Da\u00df unsrer Seel\u2019 es nicht an Kraft gebricht,", "tokens": ["Da\u00df", "uns\u00b7rer", "Seel'", "es", "nicht", "an", "Kraft", "ge\u00b7bricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "PTKNEG", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Da\u00df sie ein herrliches, vortreflichs Wesen.", "tokens": ["Da\u00df", "sie", "ein", "herr\u00b7li\u00b7ches", ",", "vor\u00b7tre\u00b7flichs", "We\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "$,", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Doch daraus folget nicht, da\u00df sie dazu erlesen,", "tokens": ["Doch", "da\u00b7raus", "fol\u00b7get", "nicht", ",", "da\u00df", "sie", "da\u00b7zu", "er\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PTKNEG", "$,", "KOUS", "PPER", "PAV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Da\u00df sie unsterblich sey. Weil die Erfahrung lehrt,", "tokens": ["Da\u00df", "sie", "uns\u00b7terb\u00b7lich", "sey", ".", "Weil", "die", "Er\u00b7fah\u00b7rung", "lehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$.", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Da\u00df oft das treflichste so lange, lange nicht,", "tokens": ["Da\u00df", "oft", "das", "tref\u00b7lichs\u00b7te", "so", "lan\u00b7ge", ",", "lan\u00b7ge", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "ADV", "ADV", "$,", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Als etwas, so geringer, w\u00e4hrt.", "tokens": ["Als", "et\u00b7was", ",", "so", "ge\u00b7rin\u00b7ger", ",", "w\u00e4hrt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "ADV", "ADJD", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Der dritte w\u00e4re gut, wofern nur dieser Trieb", "tokens": ["Der", "drit\u00b7te", "w\u00e4\u00b7re", "gut", ",", "wo\u00b7fern", "nur", "die\u00b7ser", "Trieb"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VAFIN", "ADJD", "$,", "KOUS", "ADV", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "In aller Menschen Seelen brennte,", "tokens": ["In", "al\u00b7ler", "Men\u00b7schen", "See\u00b7len", "brenn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Und man denn die Versichrung haben k\u00f6nnte,", "tokens": ["Und", "man", "denn", "die", "Ver\u00b7sich\u00b7rung", "ha\u00b7ben", "k\u00f6nn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADV", "ART", "NN", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.33": {"text": "Da\u00df GOtt, durch die Natur, ihn uns ins Hertze schrieb,", "tokens": ["Da\u00df", "Gott", ",", "durch", "die", "Na\u00b7tur", ",", "ihn", "uns", "ins", "Hert\u00b7ze", "schrieb", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "APPR", "ART", "NN", "$,", "PPER", "PRF", "APPRART", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Nicht, aber da\u00df vielmehr er \u00fcberall", "tokens": ["Nicht", ",", "a\u00b7ber", "da\u00df", "viel\u00b7mehr", "er", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "$,", "ADV", "KOUS", "ADV", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.35": {"text": "Sich ausgebreitet, durch den Fall,", "tokens": ["Sich", "aus\u00b7ge\u00b7brei\u00b7tet", ",", "durch", "den", "Fall", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "VVPP", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Da\u00df er vielleicht nur eine Schw\u00e4rmerey", "tokens": ["Da\u00df", "er", "viel\u00b7leicht", "nur", "ei\u00b7ne", "Schw\u00e4r\u00b7me\u00b7rey"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.37": {"text": "Und eine taube Frucht der eitlen Ehrsucht sey.", "tokens": ["Und", "ei\u00b7ne", "tau\u00b7be", "Frucht", "der", "eit\u00b7len", "Ehr\u00b7sucht", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Auf deinen vierten ist die Antwort leicht zu finden:", "tokens": ["Auf", "dei\u00b7nen", "vier\u00b7ten", "ist", "die", "Ant\u00b7wort", "leicht", "zu", "fin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "VAFIN", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Da\u00df Seelen in der That", "tokens": ["Da\u00df", "See\u00b7len", "in", "der", "That"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.40": {"text": "Oft, was zuk\u00fcnftig ist, im Schlaf empfinden,", "tokens": ["Oft", ",", "was", "zu\u00b7k\u00fcnf\u00b7tig", "ist", ",", "im", "Schlaf", "emp\u00b7fin\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PRELS", "ADJD", "VAFIN", "$,", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.41": {"text": "Ist, was ein weiser Mann, noch nie gel\u00e4ugnet hat.", "tokens": ["Ist", ",", "was", "ein", "wei\u00b7ser", "Mann", ",", "noch", "nie", "ge\u00b7l\u00e4ug\u00b7net", "hat", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PRELS", "ART", "ADJA", "NN", "$,", "ADV", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Ob aber das, was wir vom K\u00fcnftigen erlangen,", "tokens": ["Ob", "a\u00b7ber", "das", ",", "was", "wir", "vom", "K\u00fcnf\u00b7ti\u00b7gen", "er\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PDS", "$,", "PRELS", "PPER", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Nicht durch Empfindungen geschieht,", "tokens": ["Nicht", "durch", "Emp\u00b7fin\u00b7dun\u00b7gen", "ge\u00b7schieht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.44": {"text": "Von Dingen, welche man hier gegenw\u00e4rtig sieht,", "tokens": ["Von", "Din\u00b7gen", ",", "wel\u00b7che", "man", "hier", "ge\u00b7gen\u00b7w\u00e4r\u00b7tig", "sieht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PIS", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Die auf das K\u00fcnft\u2019ge schon zu wircken angefangen,", "tokens": ["Die", "auf", "das", "K\u00fcnft'\u00b7ge", "schon", "zu", "wir\u00b7cken", "an\u00b7ge\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADV", "PTKZU", "VVINF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Ist gantz ein\u2019 andre Frag? Und wenn es gleich geschehe,", "tokens": ["Ist", "gantz", "ein'", "and\u00b7re", "Frag", "?", "Und", "wenn", "es", "gleich", "ge\u00b7sche\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$.", "KON", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Da\u00df eine Seel auf andre Weise", "tokens": ["Da\u00df", "ei\u00b7ne", "Seel", "auf", "and\u00b7re", "Wei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.48": {"text": "Jm Traum zuk\u00fcnftge Dinge sehe;", "tokens": ["Jm", "Traum", "zu\u00b7k\u00fcnft\u00b7ge", "Din\u00b7ge", "se\u00b7he", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.49": {"text": "So folgte zwar daraus, da\u00df, an Beschaffenheit", "tokens": ["So", "folg\u00b7te", "zwar", "da\u00b7raus", ",", "da\u00df", ",", "an", "Be\u00b7schaf\u00b7fen\u00b7heit"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "PAV", "$,", "KOUS", "$,", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Sie gar vortreflich, herrlich, sch\u00f6n;", "tokens": ["Sie", "gar", "vor\u00b7tre\u00b7flich", ",", "herr\u00b7lich", ",", "sch\u00f6n", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "$,", "ADJD", "$,", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.51": {"text": "Doch k\u00f6nnte man ihr die Unsterblichkeit,", "tokens": ["Doch", "k\u00f6nn\u00b7te", "man", "ihr", "die", "U\u00b7nsterb\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIS", "PPER", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.52": {"text": "Allein hieraus, jedoch nicht zugestehn.", "tokens": ["Al\u00b7lein", "hier\u00b7aus", ",", "je\u00b7doch", "nicht", "zu\u00b7ge\u00b7stehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PAV", "$,", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.53": {"text": "Dein F\u00fcnfter setzt voraus der Alten Lehren,", "tokens": ["Dein", "F\u00fcnf\u00b7ter", "setzt", "vo\u00b7raus", "der", "Al\u00b7ten", "Leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.54": {"text": "Die Aristoteles absonderlich gegl\u00e4ubt,", "tokens": ["Die", "A\u00b7ris\u00b7to\u00b7te\u00b7les", "ab\u00b7son\u00b7der\u00b7lich", "ge\u00b7gl\u00e4ubt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.55": {"text": "Da\u00df alles Himmlische best\u00e4ndig bleibt,", "tokens": ["Da\u00df", "al\u00b7les", "Himm\u00b7li\u00b7sche", "be\u00b7st\u00e4n\u00b7dig", "bleibt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.56": {"text": "Und da\u00df die himmlischen Gesch\u00f6pf\u2019 ohn\u2019 Ende w\u00e4hren;", "tokens": ["Und", "da\u00df", "die", "himm\u00b7li\u00b7schen", "Ge\u00b7sch\u00f6pf'", "ohn'", "En\u00b7de", "w\u00e4h\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "So aber doch nicht zu erweisen.", "tokens": ["So", "a\u00b7ber", "doch", "nicht", "zu", "er\u00b7wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.58": {"text": "Ja, wenn auch endlich diese Lehre", "tokens": ["Ja", ",", "wenn", "auch", "end\u00b7lich", "die\u00b7se", "Leh\u00b7re"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "KOUS", "ADV", "ADV", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.59": {"text": "Erwei\u00dflich w\u00e4re;", "tokens": ["Er\u00b7wei\u00df\u00b7lich", "w\u00e4\u00b7re", ";"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VAFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.60": {"text": "So w\u00fcrde doch, was sie dahero schliessen,", "tokens": ["So", "w\u00fcr\u00b7de", "doch", ",", "was", "sie", "da\u00b7he\u00b7ro", "schlies\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "$,", "PRELS", "PPER", "PAV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.61": {"text": "Daraus nicht fliessen.", "tokens": ["Da\u00b7raus", "nicht", "flies\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.62": {"text": "Denn, h\u00e4tten gleich mit jenen Himmels-Kreisen,", "tokens": ["Denn", ",", "h\u00e4t\u00b7ten", "gleich", "mit", "je\u00b7nen", "Him\u00b7mels\u00b7Krei\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VAFIN", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.63": {"text": "Die Seelen die Bewegungs-Kraft gemein;", "tokens": ["Die", "See\u00b7len", "die", "Be\u00b7we\u00b7gungs\u00b7Kraft", "ge\u00b7mein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.64": {"text": "So folget doch noch nicht,", "tokens": ["So", "fol\u00b7get", "doch", "noch", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.65": {"text": "Sie m\u00fcsten all gleich unverg\u00e4nglich seyn.", "tokens": ["Sie", "m\u00fcs\u00b7ten", "all", "gleich", "un\u00b7ver\u00b7g\u00e4ng\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIAT", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.66": {"text": "Es fehlt der Schlu\u00df ja weit,", "tokens": ["Es", "fehlt", "der", "Schlu\u00df", "ja", "weit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.67": {"text": "Und ist durchaus nicht einerley,", "tokens": ["Und", "ist", "durc\u00b7haus", "nicht", "ei\u00b7ner\u00b7ley", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.68": {"text": "Da\u00df die Bewegungs-Kraft das erste Wesen,", "tokens": ["Da\u00df", "die", "Be\u00b7we\u00b7gungs\u00b7Kraft", "das", "ers\u00b7te", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.69": {"text": "Und da\u00df die Unverg\u00e4nglichkeit", "tokens": ["Und", "da\u00df", "die", "Un\u00b7ver\u00b7g\u00e4ng\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.70": {"text": "Desselben Wesens Wirckung sey.", "tokens": ["Des\u00b7sel\u00b7ben", "We\u00b7sens", "Wir\u00b7ckung", "sey", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.71": {"text": "Dein sechster Schlu\u00df hat auch viel minder Kraft, als", "tokens": ["Dein", "sechs\u00b7ter", "Schlu\u00df", "hat", "auch", "viel", "min\u00b7der", "Kraft", ",", "als"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "PIAT", "ADJA", "NN", "$,", "KOUS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.72": {"text": "Mit der Erfahrung stimmt zwar dieses \u00fcberein:", "tokens": ["Mit", "der", "Er\u00b7fah\u00b7rung", "stimmt", "zwar", "die\u00b7ses", "\u00fc\u00b7be\u00b7re\u00b7in", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ADV", "PDS", "PTKVZ", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.73": {"text": "Je l\u00e4nger Seelen hier im Leib\u2019 und auf der Erden;", "tokens": ["Je", "l\u00e4n\u00b7ger", "See\u00b7len", "hier", "im", "Leib'", "und", "auf", "der", "Er\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "NN", "ADV", "APPRART", "NN", "KON", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Je reicher sie, an Witz und an Erfahrung, werden.", "tokens": ["Je", "rei\u00b7cher", "sie", ",", "an", "Witz", "und", "an", "Er\u00b7fah\u00b7rung", ",", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "$,", "APPR", "NN", "KON", "APPR", "NN", "$,", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Hieraus nun scheint zu folgen, da\u00df die Seelen", "tokens": ["Hier\u00b7aus", "nun", "scheint", "zu", "fol\u00b7gen", ",", "da\u00df", "die", "See\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "ADV", "VVFIN", "PTKZU", "VVINF", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.76": {"text": "Vor sich nicht k\u00f6nnen untergehn,", "tokens": ["Vor", "sich", "nicht", "k\u00f6n\u00b7nen", "un\u00b7ter\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "PTKNEG", "VMFIN", "VVINF", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.77": {"text": "Denn alles, was verdirbt (wie wir an C\u00f6rpern sehn)", "tokens": ["Denn", "al\u00b7les", ",", "was", "ver\u00b7dirbt", "(", "wie", "wir", "an", "C\u00f6r\u00b7pern", "sehn", ")"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PWS", "VVFIN", "$(", "PWAV", "PPER", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Dem f\u00e4ngt es allgemach an Kr\u00e4ften an zu fehlen.", "tokens": ["Dem", "f\u00e4ngt", "es", "all\u00b7ge\u00b7mach", "an", "Kr\u00e4f\u00b7ten", "an", "zu", "feh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPR", "NN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Ein Wesen aber, das sich stets an Kr\u00e4ften mehret,", "tokens": ["Ein", "We\u00b7sen", "a\u00b7ber", ",", "das", "sich", "stets", "an", "Kr\u00e4f\u00b7ten", "meh\u00b7ret", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "PRELS", "PRF", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Je l\u00e4nger da\u00df es w\u00e4hret,", "tokens": ["Je", "l\u00e4n\u00b7ger", "da\u00df", "es", "w\u00e4h\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.81": {"text": "Scheint, weil es immer w\u00e4chst und nimmer ab-", "tokens": ["Scheint", ",", "weil", "es", "im\u00b7mer", "w\u00e4chst", "und", "nim\u00b7mer", "ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ADV", "VVFIN", "KON", "ADV", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.82": {"text": "Zum Ende nie zu kommen.", "tokens": ["Zum", "En\u00b7de", "nie", "zu", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.83": {"text": "Allein es zeigt sich auch,", "tokens": ["Al\u00b7lein", "es", "zeigt", "sich", "auch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PRF", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.84": {"text": "Da\u00df bey Veralteten die Kraft verrauch\u2019,", "tokens": ["Da\u00df", "bey", "Ver\u00b7al\u00b7te\u00b7ten", "die", "Kraft", "ver\u00b7rauch'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.85": {"text": "Und sich verringere durch allerley Beschwehrden,", "tokens": ["Und", "sich", "ver\u00b7rin\u00b7ge\u00b7re", "durch", "al\u00b7ler\u00b7ley", "Be\u00b7schwehr\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Da alte Leute kindisch werden.", "tokens": ["Da", "al\u00b7te", "Leu\u00b7te", "kin\u00b7disch", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.87": {"text": "Man spreche nicht,", "tokens": ["Man", "spre\u00b7che", "nicht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.88": {"text": "Es k\u00f6mmt, wenn die\u00df geschicht,", "tokens": ["Es", "k\u00f6mmt", ",", "wenn", "die\u00df", "ge\u00b7schicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PDS", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.89": {"text": "Blo\u00df von Ver\u00e4nderung der Lebens-Geister her,", "tokens": ["Blo\u00df", "von", "Ver\u00b7\u00e4n\u00b7de\u00b7rung", "der", "Le\u00b7bens\u00b7Geis\u00b7ter", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Nicht von Ver\u00e4ndrung unsrer Seelen.", "tokens": ["Nicht", "von", "Ver\u00b7\u00e4n\u00b7drung", "uns\u00b7rer", "See\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.91": {"text": "Denn wenn dem also w\u00e4r;", "tokens": ["Denn", "wenn", "dem", "al\u00b7so", "w\u00e4r", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADV", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.92": {"text": "So k\u00f6nnte die\u00df nicht fehlen:", "tokens": ["So", "k\u00f6nn\u00b7te", "die\u00df", "nicht", "feh\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PDS", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.93": {"text": "Es sey, wenn Seelen zugenommen,", "tokens": ["Es", "sey", ",", "wenn", "See\u00b7len", "zu\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.94": {"text": "Von Aenderung der Lebens-Geister auch,", "tokens": ["Von", "A\u00b7en\u00b7de\u00b7rung", "der", "Le\u00b7bens\u00b7Geis\u00b7ter", "auch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "ADV", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.95": {"text": "Nicht von der Aenderung der Seelen, hergekommen.", "tokens": ["Nicht", "von", "der", "A\u00b7en\u00b7de\u00b7rung", "der", "See\u00b7len", ",", "her\u00b7ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "ART", "NN", "$,", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}}, "stanza.21": {"line.1": {"text": "Ich mu\u00df es zwar gestehn,", "tokens": ["Ich", "mu\u00df", "es", "zwar", "ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Von diesen Gr\u00fcnden, giebt", "tokens": ["Von", "die\u00b7sen", "Gr\u00fcn\u00b7den", ",", "giebt"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["APPR", "PDAT", "NN", "$,", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein jeder zwar insonderheit,", "tokens": ["Ein", "je\u00b7der", "zwar", "in\u00b7son\u00b7der\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht g\u00fcltigen Bewei\u00df von der Unsterblichkeit.", "tokens": ["Nicht", "g\u00fcl\u00b7ti\u00b7gen", "Be\u00b7wei\u00df", "von", "der", "U\u00b7nsterb\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Doch, wenn man sie zusammen bindet,", "tokens": ["Doch", ",", "wenn", "man", "sie", "zu\u00b7sam\u00b7men", "bin\u00b7det", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PIS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und, als Erfahrungen betrachtet; so befindet", "tokens": ["Und", ",", "als", "Er\u00b7fah\u00b7run\u00b7gen", "be\u00b7trach\u00b7tet", ";", "so", "be\u00b7fin\u00b7det"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "$,", "KOUS", "NN", "VVPP", "$.", "ADV", "VVFIN"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.7": {"text": "In ihr, ohn\u2019 alle Dunckelheit,", "tokens": ["In", "ihr", ",", "ohn'", "al\u00b7le", "Dun\u00b7ckel\u00b7heit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "KOUI", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sich mehr doch als Wahrscheinlichkeit.", "tokens": ["Sich", "mehr", "doch", "als", "Wahr\u00b7schein\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADV", "KOUS", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Absonderlich, wenn man noch andre dazu f\u00fcget,", "tokens": ["Ab\u00b7son\u00b7der\u00b7lich", ",", "wenn", "man", "noch", "and\u00b7re", "da\u00b7zu", "f\u00fc\u00b7get", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "PIS", "ADV", "PIS", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Als nemlich: man mu\u00df ja gestehen,", "tokens": ["Als", "nem\u00b7lich", ":", "man", "mu\u00df", "ja", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$.", "PIS", "VMFIN", "ADV", "VVPP", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.11": {"text": "Da\u00df C\u00f6rper nicht einmahl vergehen.", "tokens": ["Da\u00df", "C\u00f6r\u00b7per", "nicht", "ein\u00b7mahl", "ver\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Zu nichts wird nichts, und mit Ver\u00e4ndrung", "tokens": ["Zu", "nichts", "wird", "nichts", ",", "und", "mit", "Ver\u00b7\u00e4n\u00b7drung"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIS", "VAFIN", "PIS", "$,", "KON", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Vergn\u00fcgt sich die Natur, nicht mit Vernichtigung.", "tokens": ["Ver\u00b7gn\u00fcgt", "sich", "die", "Na\u00b7tur", ",", "nicht", "mit", "Ver\u00b7nich\u00b7ti\u00b7gung", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "$,", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Vergehen nun nicht einst die C\u00f6rper, die von Erden,", "tokens": ["Ver\u00b7ge\u00b7hen", "nun", "nicht", "einst", "die", "C\u00f6r\u00b7per", ",", "die", "von", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKNEG", "ADV", "ART", "NN", "$,", "PRELS", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wie k\u00f6nnen Seelen denn vernichtigt werden?", "tokens": ["Wie", "k\u00f6n\u00b7nen", "See\u00b7len", "denn", "ver\u00b7nich\u00b7tigt", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "NN", "KON", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Und ferner: Da\u00df der Mensch des h\u00f6chsten Willen,", "tokens": ["Und", "fer\u00b7ner", ":", "Da\u00df", "der", "Mensch", "des", "h\u00f6chs\u00b7ten", "Wil\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$.", "KOUS", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Auf manche Art, geschickt sey, zu erf\u00fcllen,", "tokens": ["Auf", "man\u00b7che", "Art", ",", "ge\u00b7schickt", "sey", ",", "zu", "er\u00b7f\u00fcl\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "VVPP", "VAFIN", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Da\u00df wir, vor allen Thieren,", "tokens": ["Da\u00df", "wir", ",", "vor", "al\u00b7len", "Thie\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.19": {"text": "So viele Vorz\u00fcg\u2019 in ihm sp\u00fchren,", "tokens": ["So", "vie\u00b7le", "Vor\u00b7z\u00fcg'", "in", "ihm", "sp\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Da\u00df GOtt sich ihm, auf so bekannte Art,", "tokens": ["Da\u00df", "Gott", "sich", "ihm", ",", "auf", "so", "be\u00b7kann\u00b7te", "Art", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PRF", "PPER", "$,", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.21": {"text": "Bekannt gemacht und offenbahrt;", "tokens": ["Be\u00b7kannt", "ge\u00b7macht", "und", "of\u00b7fen\u00b7bahrt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Aus allen diesen folgt, in einer heitern Klarheit,", "tokens": ["Aus", "al\u00b7len", "die\u00b7sen", "folgt", ",", "in", "ei\u00b7ner", "hei\u00b7tern", "Klar\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PDS", "VVFIN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Die Himmel-feste Warheit:", "tokens": ["Die", "Him\u00b7mel\u00b7fes\u00b7te", "War\u00b7heit", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Man kann durchaus nicht sehen,", "tokens": ["Man", "kann", "durc\u00b7haus", "nicht", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Noch auf die minste Weise\u2019 nur", "tokens": ["Noch", "auf", "die", "mins\u00b7te", "Wei\u00b7se'", "nur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Ursach, und den Grund, verstehen,", "tokens": ["Die", "Ur\u00b7sach", ",", "und", "den", "Grund", ",", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "ART", "NN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie und wozu die Seelen solche Gaben,", "tokens": ["Wie", "und", "wo\u00b7zu", "die", "See\u00b7len", "sol\u00b7che", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "KON", "PWAV", "ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "So manchen Vorzug doch, vor aller Creatur,", "tokens": ["So", "man\u00b7chen", "Vor\u00b7zug", "doch", ",", "vor", "al\u00b7ler", "Crea\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "ADV", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "Von GOtt, erhalten haben.", "tokens": ["Von", "Gott", ",", "er\u00b7hal\u00b7ten", "ha\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "VVPP", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Da wir, so gar in der Gestirne Prangen,", "tokens": ["Da", "wir", ",", "so", "gar", "in", "der", "Ge\u00b7stir\u00b7ne", "Pran\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ADV", "ADV", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und, in derselben Wissenschaft,", "tokens": ["Und", ",", "in", "der\u00b7sel\u00b7ben", "Wis\u00b7sen\u00b7schaft", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Von seiner Majest\u00e4t und Herrlichkeit", "tokens": ["Von", "sei\u00b7ner", "Ma\u00b7jes\u00b7t\u00e4t", "und", "Herr\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Noch allererst, vor kurtzer Zeit,", "tokens": ["Noch", "al\u00b7le\u00b7rerst", ",", "vor", "kurt\u00b7zer", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Solch eine grosse Prob\u2019 empfangen.", "tokens": ["Solch", "ei\u00b7ne", "gros\u00b7se", "Prob'", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Wenn GOtt an selbiger vor andern allen", "tokens": ["Wenn", "Gott", "an", "sel\u00b7bi\u00b7ger", "vor", "an\u00b7dern", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "APPR", "ADJD", "APPR", "PIS", "PIAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Nicht h\u00e4tt\u2019 ein gn\u00e4diges Gefallen", "tokens": ["Nicht", "h\u00e4tt'", "ein", "gn\u00e4\u00b7di\u00b7ges", "Ge\u00b7fal\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKNEG", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Und sie nicht liebete; was man nun liebt, erh\u00e4lt", "tokens": ["Und", "sie", "nicht", "lie\u00b7be\u00b7te", ";", "was", "man", "nun", "liebt", ",", "er\u00b7h\u00e4lt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PPER", "PTKNEG", "VVFIN", "$.", "PWS", "PIS", "ADV", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und sch\u00fctzt man, wenn man kann. Da GOTT, ein", "tokens": ["Und", "sch\u00fctzt", "man", ",", "wenn", "man", "kann", ".", "Da", "GoTT", ",", "ein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KON", "VVFIN", "PIS", "$,", "KOUS", "PIS", "VMFIN", "$.", "KOUS", "NE", "$,", "ART"], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.16": {"text": "Unstreitig alles kann; erh\u00e4lt er, was er liebet,", "tokens": ["Un\u00b7strei\u00b7tig", "al\u00b7les", "kann", ";", "er\u00b7h\u00e4lt", "er", ",", "was", "er", "lie\u00b7bet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "PIS", "VMFIN", "$.", "VVFIN", "PPER", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.17": {"text": "Und weil er ewig liebt; so kann es ja nicht fehlen,", "tokens": ["Und", "weil", "er", "e\u00b7wig", "liebt", ";", "so", "kann", "es", "ja", "nicht", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "VVFIN", "$.", "ADV", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Da\u00df er ein\u2019 ew\u2019ge Daur auch unsern Seelen,", "tokens": ["Da\u00df", "er", "ein'", "ew'\u00b7ge", "Daur", "auch", "un\u00b7sern", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ADV", "PPOSAT", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.19": {"text": "Die seiner Liebe sich nicht unwehrt machen, giebet.", "tokens": ["Die", "sei\u00b7ner", "Lie\u00b7be", "sich", "nicht", "un\u00b7wehrt", "ma\u00b7chen", ",", "gie\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "PRF", "PTKNEG", "ADJD", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Weil aber GOtt jedoch nun auch gerecht,", "tokens": ["Weil", "a\u00b7ber", "Gott", "je\u00b7doch", "nun", "auch", "ge\u00b7recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Und die so seine Huld, die ewig ist, verachten,", "tokens": ["Und", "die", "so", "sei\u00b7ne", "Huld", ",", "die", "e\u00b7wig", "ist", ",", "ver\u00b7ach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "ADV", "PPOSAT", "NN", "$,", "PRELS", "ADJD", "VAFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Auch ewig straffen kann; so scheint es wahr zu seyn", "tokens": ["Auch", "e\u00b7wig", "straf\u00b7fen", "kann", ";", "so", "scheint", "es", "wahr", "zu", "seyn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVINF", "VMFIN", "$.", "ADV", "VVFIN", "PPER", "ADJD", "PTKZU", "VAINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Da\u00df b\u00f6se Seelen auch, um ihren Fehl zu b\u00fcssen,", "tokens": ["Da\u00df", "b\u00f6\u00b7se", "See\u00b7len", "auch", ",", "um", "ih\u00b7ren", "Fehl", "zu", "b\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ADV", "$,", "KOUI", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Unsterblich seyn und lange dauren m\u00fcssen.", "tokens": ["U\u00b7nsterb\u00b7lich", "seyn", "und", "lan\u00b7ge", "dau\u00b7ren", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAINF", "KON", "ADV", "VVINF", "VMINF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}}}}