{"textgrid.poem.32246": {"metadata": {"author": {"name": "Fischart, Johann", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wolkomen seist du, Edler Frank,", "genre": "verse", "period": "N.A.", "pub_year": 1568, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wolkomen seist du, Edler Frank,", "tokens": ["Wol\u00b7ko\u00b7men", "seist", "du", ",", "Ed\u00b7ler", "Frank", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Dir wais das gantze Teutschland dank,", "tokens": ["Dir", "wais", "das", "gant\u00b7ze", "Teutschland", "dank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vnd f\u00fcrnamlich wir, die am Rain,", "tokens": ["Vnd", "f\u00fcr\u00b7nam\u00b7lich", "wir", ",", "die", "am", "Rain", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "$,", "PRELS", "APPRART", "NN", "$,"], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die von dir frankfrei gmachet sein", "tokens": ["Die", "von", "dir", "frank\u00b7frei", "gma\u00b7chet", "sein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PPER", "ADJD", "VVFIN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von dem fremden R\u00f6mischen trang,", "tokens": ["Von", "dem", "frem\u00b7den", "R\u00f6\u00b7mi\u00b7schen", "trang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Den lezlich dein gewalt vertrang,", "tokens": ["Den", "lez\u00b7lich", "dein", "ge\u00b7walt", "ver\u00b7trang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Vnd [pracht] schlos die R\u00f6misch R\u00fcmling all", "tokens": ["Vnd", "pracht", "schlos", "die", "R\u00f6\u00b7misch", "R\u00fcm\u00b7ling", "all"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$(", "VVFIN", "$(", "ADJD", "ART", "NN", "NE", "PIAT"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Wider inn iren alten stall", "tokens": ["Wi\u00b7der", "inn", "i\u00b7ren", "al\u00b7ten", "stall"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ADJA", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Hinder die schnegro Alpenberg,", "tokens": ["Hin\u00b7der", "die", "schne\u00b7gro", "Al\u00b7pen\u00b7berg", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Das [hierseit] disseit kainer nichts verherg,", "tokens": ["Das", "hier\u00b7seit", "dis\u00b7seit", "kai\u00b7ner", "nichts", "ver\u00b7herg", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "ADV", "$(", "NN", "ADJA", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Vnd schm\u00e4lert inen ire Zins,", "tokens": ["Vnd", "schm\u00e4\u00b7lert", "i\u00b7nen", "i\u00b7re", "Zins", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Ja nam in ein auch ir provinz,", "tokens": ["Ja", "nam", "in", "ein", "auch", "ir", "pro\u00b7vinz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VVFIN", "APPR", "ART", "ADV", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Namlich das weite Gallierland,", "tokens": ["Nam\u00b7lich", "das", "wei\u00b7te", "Gal\u00b7li\u00b7er\u00b7land", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.14": {"text": "Welchs noch euch R\u00f6mern heut zur schand", "tokens": ["Welchs", "noch", "euch", "R\u00f6\u00b7mern", "heut", "zur", "schand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "PPER", "NN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Mus Frankreich haisen zum sigzaichen,", "tokens": ["Mus", "Fran\u00b7kreich", "hai\u00b7sen", "zum", "sig\u00b7zai\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "APPRART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Das Teutsche nicht den R\u00f6mern weichen.", "tokens": ["Das", "Teut\u00b7sche", "nicht", "den", "R\u00f6\u00b7mern", "wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "O, wie oft hat die Fr\u00e4nkisch r\u00fcstung", "tokens": ["O", ",", "wie", "oft", "hat", "die", "Fr\u00e4n\u00b7kisch", "r\u00fcs\u00b7tung"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "PWAV", "ADV", "VAFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Euch auch erschreckt inn euerer nistung,", "tokens": ["Euch", "auch", "er\u00b7schreckt", "inn", "eu\u00b7e\u00b7rer", "nis\u00b7tung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.19": {"text": "Das billich ir erschrecken sollet,", "tokens": ["Das", "bil\u00b7lich", "ir", "er\u00b7schre\u00b7cken", "sol\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "So ir sie hie secht abgemolet.", "tokens": ["So", "ir", "sie", "hie", "secht", "ab\u00b7ge\u00b7mo\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Dan oft ains tapferen feindes schatten", "tokens": ["Dan", "oft", "ains", "tap\u00b7fe\u00b7ren", "fein\u00b7des", "schat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPRART", "ADJA", "NN", "VVFIN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Pflegt sein widerthail zuermatten,", "tokens": ["Pflegt", "sein", "wi\u00b7dert\u00b7hail", "zu\u00b7er\u00b7mat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAINF", "VMFIN", "VVINF", "$,"], "meter": "----+--+-", "measure": "iambic.di.relaxed"}, "line.23": {"text": "Aber vns soll sie sein ain fr\u00e4ud", "tokens": ["A\u00b7ber", "vns", "soll", "sie", "sein", "ain", "fr\u00e4ud"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.24": {"text": "Vnd manung zu mehr tapferkait.", "tokens": ["Vnd", "ma\u00b7nung", "zu", "mehr", "tap\u00b7fer\u00b7kait", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Vns soll sie sein ain raizung heut,", "tokens": ["Vns", "soll", "sie", "sein", "ain", "rai\u00b7zung", "heut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PPOSAT", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Zusch\u00fctzen vnser freihait weit,", "tokens": ["Zu\u00b7sch\u00fct\u00b7zen", "vn\u00b7ser", "frei\u00b7hait", "weit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Ja vns manen zur dankbarkait,", "tokens": ["Ja", "vns", "ma\u00b7nen", "zur", "dank\u00b7bar\u00b7kait", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.28": {"text": "Zudanken vm solch Frankbarkait", "tokens": ["Zu\u00b7dan\u00b7ken", "vm", "solch", "Frank\u00b7bar\u00b7kait"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Vnsern Vorfarn, den Liben Franken,", "tokens": ["Vn\u00b7sern", "Vor\u00b7farn", ",", "den", "Li\u00b7ben", "Fran\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.30": {"text": "Den wir hiemit noch ainmal danken.", "tokens": ["Den", "wir", "hie\u00b7mit", "noch", "ain\u00b7mal", "dan\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PAV", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}