{"textgrid.poem.48558": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "7. Auf Frau Helenen Ilgens, Herrn Peter Kuchens seligen Ehegattens, Ableben", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dennoch ist der Wundsch erf\u00fcllet", "tokens": ["Den\u00b7noch", "ist", "der", "Wund\u00b7sch", "er\u00b7f\u00fcl\u00b7let"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVFIN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "und das sehnlich Tun gestillet,", "tokens": ["und", "das", "sehn\u00b7lich", "Tun", "ge\u00b7stil\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ADV", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "dennoch ist ihr recht geschehn.", "tokens": ["den\u00b7noch", "ist", "ihr", "recht", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "La\u00dft, ihr Eltern, la\u00dft die Z\u00e4hren!", "tokens": ["La\u00dft", ",", "ihr", "El\u00b7tern", ",", "la\u00dft", "die", "Z\u00e4h\u00b7ren", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "PPOSAT", "NN", "$,", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Es ergeht ihr nach Begehren,", "tokens": ["Es", "er\u00b7geht", "ihr", "nach", "Be\u00b7geh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "sie hat ihren Zweck ersehn.", "tokens": ["sie", "hat", "ih\u00b7ren", "Zweck", "er\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Wenn uns Gott gebeut zu gehen,", "tokens": ["Wenn", "uns", "Gott", "ge\u00b7beut", "zu", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VVPP", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "so soll man nicht widerstehen.", "tokens": ["so", "soll", "man", "nicht", "wi\u00b7der\u00b7ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "PTKNEG", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Eurer Tochter ist gar wol.", "tokens": ["Eu\u00b7rer", "Toch\u00b7ter", "ist", "gar", "wol", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihres Geists wird wol gepflogen;", "tokens": ["Ih\u00b7res", "Geists", "wird", "wol", "ge\u00b7pflo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "nur ihr Leib ist hingezogen,", "tokens": ["nur", "ihr", "Leib", "ist", "hin\u00b7ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wohin Alles ist und soll.", "tokens": ["wo\u00b7hin", "Al\u00b7les", "ist", "und", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VAFIN", "KON", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Wir sind in den Lebensorden", "tokens": ["Wir", "sind", "in", "den", "Le\u00b7ben\u00b7sor\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ohngef\u00e4hr gesetzt nicht worden,", "tokens": ["ohn\u00b7ge\u00b7f\u00e4hr", "ge\u00b7setzt", "nicht", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "PTKNEG", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "da\u00df wir, wenn wir alles Leid,", "tokens": ["da\u00df", "wir", ",", "wenn", "wir", "al\u00b7les", "Leid", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "KOUS", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "alles B\u00f6ses ausgestanden,", "tokens": ["al\u00b7les", "B\u00f6\u00b7ses", "aus\u00b7ge\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "nachmals blieben in den Banden", "tokens": ["nach\u00b7mals", "blie\u00b7ben", "in", "den", "Ban\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "ewiger Verstorbenheit.", "tokens": ["e\u00b7wi\u00b7ger", "Ver\u00b7stor\u00b7ben\u00b7heit", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}}, "stanza.4": {"line.1": {"text": "Niemand kan zu Himmel kommen,", "tokens": ["Nie\u00b7mand", "kan", "zu", "Him\u00b7mel", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "es sei ihm denn das benommen,", "tokens": ["es", "sei", "ihm", "denn", "das", "be\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ART", "ADJA", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "worvon er noch sterblich hei\u00dft.", "tokens": ["wor\u00b7von", "er", "noch", "sterb\u00b7lich", "hei\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was entlehnt ist von der Erden,", "tokens": ["Was", "ent\u00b7lehnt", "ist", "von", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVPP", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "das mu\u00df ihr hinwieder werden,", "tokens": ["das", "mu\u00df", "ihr", "hin\u00b7wie\u00b7der", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "eh' der Geist von hinnen reist.", "tokens": ["eh'", "der", "Geist", "von", "hin\u00b7nen", "reist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "La\u00dft uns ihren Glanz besinnen", "tokens": ["La\u00dft", "uns", "ih\u00b7ren", "Glanz", "be\u00b7sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und das Himmlische beginnen,", "tokens": ["und", "das", "Himm\u00b7li\u00b7sche", "be\u00b7gin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Anfangs nun, nun Endes blo\u00df!", "tokens": ["An\u00b7fangs", "nun", ",", "nun", "En\u00b7des", "blo\u00df", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "ADV", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wer will ihre Lust beschreiben,", "tokens": ["Wer", "will", "ih\u00b7re", "Lust", "be\u00b7schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "die sie wird ohn' Ende treiben", "tokens": ["die", "sie", "wird", "ohn'", "En\u00b7de", "trei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PRELS", "PPER", "VAFIN", "APPR", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "in des Allerliebsten Scho\u00df'?", "tokens": ["in", "des", "Al\u00b7ler\u00b7liebs\u00b7ten", "Scho\u00df'", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Sind wir hier im Leben lange,", "tokens": ["Sind", "wir", "hier", "im", "Le\u00b7ben", "lan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPRART", "NN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "so ist uns auch lange bange,", "tokens": ["so", "ist", "uns", "auch", "lan\u00b7ge", "ban\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.3": {"text": "leben desto minder doch.", "tokens": ["le\u00b7ben", "des\u00b7to", "min\u00b7der", "doch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und wem solte fast gel\u00fcsten,", "tokens": ["Und", "wem", "sol\u00b7te", "fast", "ge\u00b7l\u00fcs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VMFIN", "ADV", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "mehr zu irren in der W\u00fcsten,", "tokens": ["mehr", "zu", "ir\u00b7ren", "in", "der", "W\u00fcs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "mehr zu ziehen dieses Joch?", "tokens": ["mehr", "zu", "zie\u00b7hen", "die\u00b7ses", "Joch", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Ph\u00f6bus k\u00fcrzt nun ab die Tage,", "tokens": ["Ph\u00f6\u00b7bus", "k\u00fcrzt", "nun", "ab", "die", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "doch darmit nicht unsre Plage,", "tokens": ["doch", "dar\u00b7mit", "nicht", "uns\u00b7re", "Pla\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PAV", "PTKNEG", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "die rings um uns schl\u00e4get ein.", "tokens": ["die", "rings", "um", "uns", "schl\u00e4\u00b7get", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Nun der Sommer ist entwichen,", "tokens": ["Nun", "der", "Som\u00b7mer", "ist", "ent\u00b7wi\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "k\u00f6mt der faule Herbst geschlichen,", "tokens": ["k\u00f6mt", "der", "fau\u00b7le", "Herbst", "ge\u00b7schli\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "sagt, es werde Winter sein.", "tokens": ["sagt", ",", "es", "wer\u00b7de", "Win\u00b7ter", "sein", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "VAFIN", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}