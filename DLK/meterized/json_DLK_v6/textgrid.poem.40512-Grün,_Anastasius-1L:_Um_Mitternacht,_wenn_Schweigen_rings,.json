{"textgrid.poem.40512": {"metadata": {"author": {"name": "Gr\u00fcn, Anastasius", "birth": "N.A.", "death": "N.A."}, "title": "1L: Um Mitternacht, wenn Schweigen rings,", "genre": "verse", "period": "N.A.", "pub_year": 1842, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Um Mitternacht, wenn Schweigen rings,", "tokens": ["Um", "Mit\u00b7ter\u00b7nacht", ",", "wenn", "Schwei\u00b7gen", "rings", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "$,", "KOUS", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Beginnt's durch Waldesr\u00e4ume,", "tokens": ["Be\u00b7ginnt's", "durch", "Wal\u00b7des\u00b7r\u00e4u\u00b7me", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und wo sonst B\u00fcsch' und B\u00e4ume stehn,", "tokens": ["Und", "wo", "sonst", "B\u00fcsch'", "und", "B\u00e4u\u00b7me", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu fl\u00fcstern, rascheln und zu wehn,", "tokens": ["Zu", "fl\u00fcs\u00b7tern", ",", "ra\u00b7scheln", "und", "zu", "wehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "VVFIN", "KON", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Denn Zwiesprach halten die B\u00e4ume.", "tokens": ["Denn", "Zwie\u00b7sprach", "hal\u00b7ten", "die", "B\u00e4u\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Der Rosenbaum loht lustig auf,", "tokens": ["Der", "Ro\u00b7sen\u00b7baum", "loht", "lus\u00b7tig", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Duft raucht aus seinen Gluthen:", "tokens": ["Duft", "raucht", "aus", "sei\u00b7nen", "Glu\u00b7then", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "++-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbein Rosenleben reicht nicht weit,", "tokens": ["\u00bb", "ein", "Ro\u00b7sen\u00b7le\u00b7ben", "reicht", "nicht", "weit", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Drum soll's, je k\u00fcrzer seine Zeit,", "tokens": ["Drum", "soll's", ",", "je", "k\u00fcr\u00b7zer", "sei\u00b7ne", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "$,", "ADV", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So voller, heller verbluten!\u00ab", "tokens": ["So", "vol\u00b7ler", ",", "hel\u00b7ler", "ver\u00b7blu\u00b7ten", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJA", "$,", "ADJD", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Die Esche spricht: \u00bbGesunkner Tag,", "tokens": ["Die", "E\u00b7sche", "spricht", ":", "\u00bb", "Ge\u00b7sun\u00b7kner", "Tag", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mich t\u00e4uscht nicht Glanz und Flittern!", "tokens": ["Mich", "t\u00e4uscht", "nicht", "Glanz", "und", "Flit\u00b7tern", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dein Sonnenstrahl ist Todesstahl,", "tokens": ["Dein", "Son\u00b7nen\u00b7strahl", "ist", "To\u00b7des\u00b7stahl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gez\u00fcckt aufs Rosenherz zumal,", "tokens": ["Ge\u00b7z\u00fcckt", "aufs", "Ro\u00b7sen\u00b7herz", "zu\u00b7mal", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPRART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch auch wir Andern zittern!\u00ab", "tokens": ["Doch", "auch", "wir", "An\u00b7dern", "zit\u00b7tern", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "PPER", "ADJA", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Die schlanke Pappel spricht, und h\u00e4lt", "tokens": ["Die", "schlan\u00b7ke", "Pap\u00b7pel", "spricht", ",", "und", "h\u00e4lt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zum Himmel die Arm' erhoben:", "tokens": ["Zum", "Him\u00b7mel", "die", "Arm'", "er\u00b7ho\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u00bbdort str\u00f6mt ein lichter Siegesquell,", "tokens": ["\u00bb", "dort", "str\u00f6mt", "ein", "lich\u00b7ter", "Sie\u00b7ges\u00b7quell", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der rauscht so s\u00fc\u00df und gl\u00e4nzt so hell,", "tokens": ["Der", "rauscht", "so", "s\u00fc\u00df", "und", "gl\u00e4nzt", "so", "hell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADJD", "KON", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Drum wall' ich sehnend nach oben!\u00ab", "tokens": ["Drum", "wall'", "ich", "seh\u00b7nend", "nach", "o\u00b7ben", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADJD", "APPR", "ADV", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Die Weide blickt zur Erd' und spricht:", "tokens": ["Die", "Wei\u00b7de", "blickt", "zur", "Erd'", "und", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbo da\u00df mein Arm dich umwinde,", "tokens": ["\u00bb", "o", "da\u00df", "mein", "Arm", "dich", "um\u00b7win\u00b7de", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "KOUS", "PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Mein wallend Haar neig' ich zu dir,", "tokens": ["Mein", "wal\u00b7lend", "Haar", "neig'", "ich", "zu", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Drein flechte deine Blumen mir,", "tokens": ["Drein", "flech\u00b7te", "dei\u00b7ne", "Blu\u00b7men", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie M\u00fctterlein dem Kinde.\u00ab", "tokens": ["Wie", "M\u00fct\u00b7ter\u00b7lein", "dem", "Kin\u00b7de", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Drauf seufzt der reiche Pflaumenbaum:", "tokens": ["Drauf", "seufzt", "der", "rei\u00b7che", "Pflau\u00b7men\u00b7baum", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbach, meine F\u00fcll' erdr\u00fcckt mich!", "tokens": ["\u00bb", "ach", ",", "mei\u00b7ne", "F\u00fcll'", "er\u00b7dr\u00fcckt", "mich", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "PPOSAT", "NN", "VVFIN", "PPER", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Nehmt doch die Last vom R\u00fccken mein!", "tokens": ["Nehmt", "doch", "die", "Last", "vom", "R\u00fc\u00b7cken", "mein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPRART", "NN", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht trag' ich sie f\u00fcr mich allein;", "tokens": ["Nicht", "trag'", "ich", "sie", "f\u00fcr", "mich", "al\u00b7lein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "PPER", "PPER", "APPR", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Was ihr mir raubt, erquickt mich!\u00ab", "tokens": ["Was", "ihr", "mir", "raubt", ",", "er\u00b7quickt", "mich", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PWS", "PPER", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Es spricht die Tanne guten Muths:", "tokens": ["Es", "spricht", "die", "Tan\u00b7ne", "gu\u00b7ten", "Muths", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbob auch an Bl\u00fcthen ich darbe,", "tokens": ["\u00bb", "ob", "auch", "an", "Bl\u00fc\u00b7then", "ich", "dar\u00b7be", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "ADV", "APPR", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Mein Reichthum ist Best\u00e4ndigkeit;", "tokens": ["Mein", "Reicht\u00b7hum", "ist", "Be\u00b7st\u00e4n\u00b7dig\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ob Sonne scheint, ob's st\u00fcrmt und schneit,", "tokens": ["Ob", "Son\u00b7ne", "scheint", ",", "ob's", "st\u00fcrmt", "und", "schneit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "$,", "NE", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nie \u00e4ndr' ich meine Farbe!\u00ab", "tokens": ["Nie", "\u00e4ndr'", "ich", "mei\u00b7ne", "Far\u00b7be", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Der hohe stolze Eichbaum spricht:", "tokens": ["Der", "ho\u00b7he", "stol\u00b7ze", "Eich\u00b7baum", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbich zittre vor Gottes Blitzen!", "tokens": ["\u00bb", "ich", "zitt\u00b7re", "vor", "Got\u00b7tes", "Blit\u00b7zen", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPR", "NN", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Kein Sturm ist mich zu beugen stark,", "tokens": ["Kein", "Sturm", "ist", "mich", "zu", "beu\u00b7gen", "stark", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "PTKZU", "VVINF", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kraft ist mein Stamm, und Kraft mein Mark,", "tokens": ["Kraft", "ist", "mein", "Stamm", ",", "und", "Kraft", "mein", "Mark", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$,", "KON", "NN", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Ihr Schw\u00e4chern, euch will ich sch\u00fctzen!\u00ab", "tokens": ["Ihr", "Schw\u00e4\u00b7chern", ",", "euch", "will", "ich", "sch\u00fct\u00b7zen", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPER", "VMFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Die Epheuranke th\u00e4t an ihn", "tokens": ["Die", "E\u00b7pheu\u00b7ran\u00b7ke", "th\u00e4t", "an", "ihn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sich inniger nun f\u00fcgen:", "tokens": ["Sich", "in\u00b7ni\u00b7ger", "nun", "f\u00fc\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbwer f\u00fcr sich selbst zu schwach und klein,", "tokens": ["\u00bb", "wer", "f\u00fcr", "sich", "selbst", "zu", "schwach", "und", "klein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "APPR", "PRF", "ADV", "PTKA", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und wer nicht gerne steht allein,", "tokens": ["Und", "wer", "nicht", "ger\u00b7ne", "steht", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PTKNEG", "ADV", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mag an den Freund sich schmiegen!\u00ab", "tokens": ["Mag", "an", "den", "Freund", "sich", "schmie\u00b7gen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "PRF", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Drauf sprachen sie so Manches noch,", "tokens": ["Drauf", "spra\u00b7chen", "sie", "so", "Man\u00b7ches", "noch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "PIS", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich hab' es halb vergessen.", "tokens": ["Ich", "hab'", "es", "halb", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Noch fl\u00fcsterte manch' heimlich Wort,", "tokens": ["Noch", "fl\u00fcs\u00b7ter\u00b7te", "man\u00b7ch'", "heim\u00b7lich", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "ADJD", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Es schwiegen nur am Grabe dort", "tokens": ["Es", "schwie\u00b7gen", "nur", "am", "Gra\u00b7be", "dort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die trauernden Cypressen.", "tokens": ["Die", "trau\u00b7ern\u00b7den", "Cyp\u00b7res\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+--", "measure": "iambic.di.relaxed"}}, "stanza.11": {"line.1": {"text": "O da\u00df die leisen Spr\u00fcchlein all'", "tokens": ["O", "da\u00df", "die", "lei\u00b7sen", "Spr\u00fcch\u00b7lein", "all'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "KOUS", "ART", "ADJA", "NN", "PIAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Menschenherz doch trafen!", "tokens": ["Ein", "Men\u00b7schen\u00b7herz", "doch", "tra\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was Wunder, wenn sie's trafen nicht?", "tokens": ["Was", "Wun\u00b7der", ",", "wenn", "sie's", "tra\u00b7fen", "nicht", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$,", "KOUS", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die B\u00e4ume pred'gen beim Sternenlicht,", "tokens": ["Die", "B\u00e4u\u00b7me", "pre\u00b7d'\u00b7gen", "beim", "Ster\u00b7nen\u00b7licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Da m\u00fcssen wir ja schlafen.", "tokens": ["Da", "m\u00fcs\u00b7sen", "wir", "ja", "schla\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}