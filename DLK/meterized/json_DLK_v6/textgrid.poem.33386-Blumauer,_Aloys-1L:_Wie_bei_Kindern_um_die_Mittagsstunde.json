{"textgrid.poem.33386": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wie bei Kindern um die Mittagsstunde", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie bei Kindern um die Mittagsstunde", "tokens": ["Wie", "bei", "Kin\u00b7dern", "um", "die", "Mit\u00b7tags\u00b7stun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Aus Gewohnheit sich der Magen regt,", "tokens": ["Aus", "Ge\u00b7wohn\u00b7heit", "sich", "der", "Ma\u00b7gen", "regt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Eben so steigt Wasser mir zu Munde,", "tokens": ["E\u00b7ben", "so", "steigt", "Was\u00b7ser", "mir", "zu", "Mun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "NN", "PPER", "APPR", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Wenn die Glock' jetzt Eilfe schl\u00e4gt.", "tokens": ["Wenn", "die", "Glock'", "jetzt", "Eil\u00b7fe", "schl\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nicht nach Essen, denn die Zeit ist l\u00e4ngst vor\u00fcber,", "tokens": ["Nicht", "nach", "Es\u00b7sen", ",", "denn", "die", "Zeit", "ist", "l\u00e4ngst", "vor\u00b7\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "$,", "KON", "ART", "NN", "VAFIN", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Wo noch ein gebraten Taubenpaar", "tokens": ["Wo", "noch", "ein", "ge\u00b7bra\u00b7ten", "Tau\u00b7ben\u00b7paar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Mir \u2013 und dir vielleicht auch \u2013 lieber,", "tokens": ["Mir", "\u2013", "und", "dir", "viel\u00b7leicht", "auch", "\u2013", "lie\u00b7ber", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "$(", "KON", "PPER", "ADV", "ADV", "$(", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Als sein Welttheil dem Columbus, war.", "tokens": ["Als", "sein", "Welt\u00b7theil", "dem", "Co\u00b7lum\u00b7bus", ",", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "NN", "$,", "VAFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Nein, nach dir, nach dir, o Lieber,", "tokens": ["Nein", ",", "nach", "dir", ",", "nach", "dir", ",", "o", "Lie\u00b7ber", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "APPR", "PPER", "$,", "APPR", "PPER", "$,", "FM", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "W\u00e4ssert t\u00e4glich mir der Zahn,", "tokens": ["W\u00e4s\u00b7sert", "t\u00e4g\u00b7lich", "mir", "der", "Zahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Und da ich mit dir nicht schwatzen kann,", "tokens": ["Und", "da", "ich", "mit", "dir", "nicht", "schwat\u00b7zen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "PPER", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.12": {"text": "Denk' ich dein, und schreibe nieder,", "tokens": ["Denk'", "ich", "dein", ",", "und", "schrei\u00b7be", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "$,", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Was ich dir nicht m\u00fcndlich sagen kann;", "tokens": ["Was", "ich", "dir", "nicht", "m\u00fcnd\u00b7lich", "sa\u00b7gen", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPER", "PTKNEG", "ADJD", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.14": {"text": "Und so f\u00e4ngt mein Brief gleich mit der Frage an:", "tokens": ["Und", "so", "f\u00e4ngt", "mein", "Brief", "gleich", "mit", "der", "Fra\u00b7ge", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.15": {"text": "Lieber Freund, wann k\u00f6mmst du wieder?", "tokens": ["Lie\u00b7ber", "Freund", ",", "wann", "k\u00f6mmst", "du", "wie\u00b7der", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "$,", "PWAV", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Wieder? \u2013 bin ich doch kaum fort! \u2013", "tokens": ["Wie\u00b7der", "?", "\u2013", "bin", "ich", "doch", "kaum", "fort", "!", "\u2013"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "$.", "$(", "VAFIN", "PPER", "ADV", "ADV", "PTKVZ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.17": {"text": "Wahr! \u2013 doch Lieber, auf mein Wort,", "tokens": ["Wahr", "!", "\u2013", "doch", "Lie\u00b7ber", ",", "auf", "mein", "Wort", ","], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$.", "$(", "ADV", "ADJD", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.18": {"text": "Dieses kaum deucht mir schon m\u00e4chtig lange,", "tokens": ["Die\u00b7ses", "kaum", "deucht", "mir", "schon", "m\u00e4ch\u00b7tig", "lan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "PPER", "ADV", "ADJD", "ADV", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.19": {"text": "Weil die Freundschaft, oder was es ist,", "tokens": ["Weil", "die", "Freund\u00b7schaft", ",", "o\u00b7der", "was", "es", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "KON", "PWS", "PPER", "VAFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.20": {"text": "Ihre Tage nicht, wie der Kalender, mi\u00dft,", "tokens": ["Ih\u00b7re", "Ta\u00b7ge", "nicht", ",", "wie", "der", "Ka\u00b7len\u00b7der", ",", "mi\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "$,", "PWAV", "ART", "NN", "$,", "VVFIN", "$,"], "meter": "+-+--+-+--+", "measure": "trochaic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Wenn ich oft so sitz', und M\u00fccken fange,", "tokens": ["Wenn", "ich", "oft", "so", "sitz'", ",", "und", "M\u00fc\u00b7cken", "fan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVFIN", "$,", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Die selbst Liebe nicht, noch Wein", "tokens": ["Die", "selbst", "Lie\u00b7be", "nicht", ",", "noch", "Wein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADV", "NN", "PTKNEG", "$,", "ADV", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aus dem Kopf mir jagen, da f\u00e4llst du mir ein:", "tokens": ["Aus", "dem", "Kopf", "mir", "ja\u00b7gen", ",", "da", "f\u00e4llst", "du", "mir", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "VVINF", "$,", "ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und wahrhaftig, ich verlange,", "tokens": ["Und", "wahr\u00b7haf\u00b7tig", ",", "ich", "ver\u00b7lan\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn ich gr\u00e4mle, oft nicht mehr,", "tokens": ["Wenn", "ich", "gr\u00e4m\u00b7le", ",", "oft", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "ADV", "PTKNEG", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Als noch einen Gr\u00e4mler um mich her. \u2013", "tokens": ["Als", "noch", "ei\u00b7nen", "Gr\u00e4m\u00b7ler", "um", "mich", "her", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "APPR", "PPER", "PTKVZ", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Aber Freund, wie k\u00f6mmt's denn, da\u00df gerade", "tokens": ["A\u00b7ber", "Freund", ",", "wie", "k\u00f6mmt's", "denn", ",", "da\u00df", "ge\u00b7ra\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "$,", "PWAV", "NE", "KON", "$,", "KOUS", "ADV"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Bei uns armen Wissenschaftlern Spleen,", "tokens": ["Bei", "uns", "ar\u00b7men", "Wis\u00b7sen\u00b7schaft\u00b7lern", "Spleen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Lebenseckel, tr\u00fcber Sinn,", "tokens": ["Le\u00b7bens\u00b7e\u00b7ckel", ",", "tr\u00fc\u00b7ber", "Sinn", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Hypochonder u.s.w. zur Parade", "tokens": ["Hy\u00b7po\u00b7chon\u00b7der", "u.", "s.", "w.", "zur", "Pa\u00b7ra\u00b7de"], "token_info": ["word", "abbreviation", "abbreviation", "abbreviation", "word", "word"], "pos": ["NE", "KON", "VVIMP", "NN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Auf in unsere Gesichter zieh'n? \u2013", "tokens": ["Auf", "in", "un\u00b7se\u00b7re", "Ge\u00b7sich\u00b7ter", "zieh'n", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "APPR", "PPOSAT", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.12": {"text": "Sprich, was n\u00fctzt's, die Freuden alle kennen,", "tokens": ["Sprich", ",", "was", "n\u00fctzt's", ",", "die", "Freu\u00b7den", "al\u00b7le", "ken\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "PRELS", "NE", "$,", "ART", "NN", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.13": {"text": "Ihren inneren Gehalt", "tokens": ["Ih\u00b7ren", "in\u00b7ne\u00b7ren", "Ge\u00b7halt"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.14": {"text": "Von der \u00e4ussern, oft nur gl\u00e4nzenden Gestalt,", "tokens": ["Von", "der", "\u00e4us\u00b7sern", ",", "oft", "nur", "gl\u00e4n\u00b7zen\u00b7den", "Ge\u00b7stalt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$,", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.15": {"text": "Mit gesch\u00e4rftem Blicke trennen,", "tokens": ["Mit", "ge\u00b7sch\u00e4rf\u00b7tem", "Bli\u00b7cke", "tren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Ihre Schlacken wegzufegen, sie", "tokens": ["Ih\u00b7re", "Schla\u00b7cken", "weg\u00b7zu\u00b7fe\u00b7gen", ",", "sie"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["PPOSAT", "NN", "VVPP", "$,", "PPER"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.17": {"text": "Auf der Wage der Philosophie", "tokens": ["Auf", "der", "Wa\u00b7ge", "der", "Phi\u00b7lo\u00b7so\u00b7phie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.18": {"text": "Auf's genau'ste abzuw\u00e4gen wissen,", "tokens": ["Auf's", "ge\u00b7nau'\u00b7ste", "ab\u00b7zu\u00b7w\u00e4\u00b7gen", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVIZU", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.19": {"text": "Dient dies alles nicht dazu,", "tokens": ["Dient", "dies", "al\u00b7les", "nicht", "da\u00b7zu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "PIS", "PTKNEG", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.20": {"text": "Uns den Kelch des Lebens zu vers\u00fcssen?", "tokens": ["Uns", "den", "Kelch", "des", "Le\u00b7bens", "zu", "ver\u00b7s\u00fcs\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Dennoch, Freund, wo ist der, der in Ruh'", "tokens": ["Den\u00b7noch", ",", "Freund", ",", "wo", "ist", "der", ",", "der", "in", "Ruh'"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "NN", "$,", "PWAV", "VAFIN", "ART", "$,", "PRELS", "APPR", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Seinen Becher, den er noch dazu", "tokens": ["Sei\u00b7nen", "Be\u00b7cher", ",", "den", "er", "noch", "da\u00b7zu"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PPER", "ADV", "PAV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Selber mit dem Saft der Freude voll gedr\u00fccket,", "tokens": ["Sel\u00b7ber", "mit", "dem", "Saft", "der", "Freu\u00b7de", "voll", "ge\u00b7dr\u00fc\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Ausleert, und nicht stets dabei", "tokens": ["Aus\u00b7leert", ",", "und", "nicht", "stets", "da\u00b7bei"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "KON", "PTKNEG", "ADV", "PAV"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Nach des Bechers Boden blicket,", "tokens": ["Nach", "des", "Be\u00b7chers", "Bo\u00b7den", "bli\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ob nicht Hefen noch darinen sei? \u2013", "tokens": ["Ob", "nicht", "He\u00b7fen", "noch", "da\u00b7ri\u00b7nen", "sei", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PTKNEG", "NN", "ADV", "PAV", "VAFIN", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Wahr, Freund, ist der Satz, obschon nicht neu:", "tokens": ["Wahr", ",", "Freund", ",", "ist", "der", "Satz", ",", "ob\u00b7schon", "nicht", "neu", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "VAFIN", "ART", "NN", "$,", "KOUS", "PTKNEG", "ADJD", "$."], "meter": "++--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Wer die Lust nicht kennt, geniesset sie,", "tokens": ["Wer", "die", "Lust", "nicht", "kennt", ",", "ge\u00b7nies\u00b7set", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "PTKNEG", "VVFIN", "$,", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Wer sie kennt, genie\u00dft sie nie.", "tokens": ["Wer", "sie", "kennt", ",", "ge\u00b7nie\u00dft", "sie", "nie", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Selbst auch dieses, leider! wissen", "tokens": ["Selbst", "auch", "die\u00b7ses", ",", "lei\u00b7der", "!", "wis\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["ADV", "ADV", "PDAT", "$,", "ADV", "$.", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Wir genau, und dennoch m\u00fcssen", "tokens": ["Wir", "ge\u00b7nau", ",", "und", "den\u00b7noch", "m\u00fcs\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADJD", "$,", "KON", "ADV", "VMFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Wir stets schielen nach dem Grund,", "tokens": ["Wir", "stets", "schie\u00b7len", "nach", "dem", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "Halten wir den Becher gleich am Mund.", "tokens": ["Hal\u00b7ten", "wir", "den", "Be\u00b7cher", "gleich", "am", "Mund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "ADV", "APPRART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.14": {"text": "Sage, Lieber, hei\u00dft das nicht hienieden", "tokens": ["Sa\u00b7ge", ",", "Lie\u00b7ber", ",", "hei\u00dft", "das", "nicht", "hien\u00b7ie\u00b7den"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "ADJD", "$,", "VVFIN", "PDS", "PTKNEG", "ADV"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.15": {"text": "Sich an seines Geist's Galeere schmieden,", "tokens": ["Sich", "an", "sei\u00b7nes", "Geist's", "Ga\u00b7lee\u00b7re", "schmie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "PPOSAT", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.16": {"text": "Oder ist's nicht eitel Prahlerei:", "tokens": ["O\u00b7der", "ist's", "nicht", "ei\u00b7tel", "Prah\u00b7le\u00b7rei", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "ADJD", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.17": {"text": "Da\u00df der Weise freier, als der Dummkopf sei?", "tokens": ["Da\u00df", "der", "Wei\u00b7se", "frei\u00b7er", ",", "als", "der", "Dumm\u00b7kopf", "sei", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJD", "$,", "KOUS", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.4": {"line.1": {"text": "Beide tragen ihre Kette,", "tokens": ["Bei\u00b7de", "tra\u00b7gen", "ih\u00b7re", "Ket\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nur verschied'nen Herren dienen sie:", "tokens": ["Nur", "ver\u00b7schie\u00b7d'\u00b7nen", "Her\u00b7ren", "die\u00b7nen", "sie", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Dieser seinem Bauch und seinem Bette,", "tokens": ["Die\u00b7ser", "sei\u00b7nem", "Bauch", "und", "sei\u00b7nem", "Bet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Jener der Philosophie.", "tokens": ["Je\u00b7ner", "der", "Phi\u00b7lo\u00b7so\u00b7phie", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und so recht bei'm Licht besehen,", "tokens": ["Und", "so", "recht", "bei'm", "Licht", "be\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "APPRART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist der erste Unterthan", "tokens": ["Ist", "der", "ers\u00b7te", "Un\u00b7ter\u00b7than"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Immer besser, als der zweite, d'ran:", "tokens": ["Im\u00b7mer", "bes\u00b7ser", ",", "als", "der", "zwei\u00b7te", ",", "d'\u00b7ran", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "ART", "ADJA", "$,", "PTKVZ", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "Wenigstens wirst du mir eingestehen,", "tokens": ["We\u00b7nigs\u00b7tens", "wirst", "du", "mir", "ein\u00b7ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "Da\u00df der erstere Tyrann", "tokens": ["Da\u00df", "der", "ers\u00b7te\u00b7re", "Ty\u00b7rann"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Leicht befriedigt ist, inde\u00df den andern", "tokens": ["Leicht", "be\u00b7frie\u00b7digt", "ist", ",", "in\u00b7de\u00df", "den", "an\u00b7dern"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "VVPP", "VAFIN", "$,", "ADV", "ART", "ADJA"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.11": {"text": "Ein Erob'rungsgl\u00fcck von zwanzig Alexandern", "tokens": ["Ein", "Er\u00b7ob'\u00b7rungs\u00b7gl\u00fcck", "von", "zwan\u00b7zig", "A\u00b7lex\u00b7an\u00b7dern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "CARD", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.12": {"text": "Im Gebiete der Ideenwelt", "tokens": ["Im", "Ge\u00b7bie\u00b7te", "der", "Id\u00b7een\u00b7welt"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.13": {"text": "Nimmermehr zufrieden stellt.", "tokens": ["Nim\u00b7mer\u00b7mehr", "zu\u00b7frie\u00b7den", "stellt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.14": {"text": "All' sein Sinnen, all' sein Wahrheitjagen", "tokens": ["All'", "sein", "Sin\u00b7nen", ",", "all'", "sein", "Wahr\u00b7heit\u00b7ja\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "PPOSAT", "NN", "$,", "PIAT", "PPOSAT", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.15": {"text": "Lohnt der uners\u00e4ttliche Tyrann, \u2013", "tokens": ["Lohnt", "der", "un\u00b7er\u00b7s\u00e4tt\u00b7li\u00b7che", "Ty\u00b7rann", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.16": {"text": "Denk nur, ob man schlechter lohnen kann, \u2013", "tokens": ["Denk", "nur", ",", "ob", "man", "schlech\u00b7ter", "loh\u00b7nen", "kann", ",", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "ADV", "$,", "KOUS", "PIS", "ADJD", "VVINF", "VMFIN", "$,", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.17": {"text": "Ihm mit schwarzer Gall' und krankem Magen.", "tokens": ["Ihm", "mit", "schwar\u00b7zer", "Gall'", "und", "kran\u00b7kem", "Ma\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.18": {"text": "R\u00fchme mir nur nicht der Nachwelt Lohn;", "tokens": ["R\u00fch\u00b7me", "mir", "nur", "nicht", "der", "Nach\u00b7welt", "Lohn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PTKNEG", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.19": {"text": "Wenn du todt bist, hast du was davon?", "tokens": ["Wenn", "du", "todt", "bist", ",", "hast", "du", "was", "da\u00b7von", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$,", "VAFIN", "PPER", "PIS", "PAV", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.20": {"text": "Tausend Dinge kann der K\u00f6rper missen,", "tokens": ["Tau\u00b7send", "Din\u00b7ge", "kann", "der", "K\u00f6r\u00b7per", "mis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VMFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.21": {"text": "Die der Luxus doch Bed\u00fcrfni\u00df hei\u00dft;", "tokens": ["Die", "der", "Lu\u00b7xus", "doch", "Be\u00b7d\u00fcrf\u00b7ni\u00df", "hei\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.22": {"text": "Aber ist \u2013 so manches wissen:", "tokens": ["A\u00b7ber", "ist", "\u2013", "so", "man\u00b7ches", "wis\u00b7sen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$(", "ADV", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.23": {"text": "Was zum Beispiel, dies und jenes hei\u00dft,", "tokens": ["Was", "zum", "Bei\u00b7spiel", ",", "dies", "und", "je\u00b7nes", "hei\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPRART", "NN", "$,", "PDS", "KON", "PDS", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.24": {"text": "Was f\u00fcr L\u00e4nder Pallas durchgereist,", "tokens": ["Was", "f\u00fcr", "L\u00e4n\u00b7der", "Pal\u00b7las", "durch\u00b7ge\u00b7reist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "NE", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.25": {"text": "Und wie die und jene Pflanze,", "tokens": ["Und", "wie", "die", "und", "je\u00b7ne", "Pflan\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "KON", "PDAT", "NN", "$,"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.26": {"text": "Die Sibirien hervorbringt, hei\u00dft?", "tokens": ["Die", "Si\u00b7bi\u00b7ri\u00b7en", "her\u00b7vor\u00b7bringt", ",", "hei\u00dft", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.27": {"text": "Ob die Griechen sich bei'm Tanze", "tokens": ["Ob", "die", "Grie\u00b7chen", "sich", "bei'm", "Tan\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PRF", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.28": {"text": "Nur auf einem Bein herumgedreht?", "tokens": ["Nur", "auf", "ei\u00b7nem", "Bein", "her\u00b7um\u00b7ge\u00b7dreht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.29": {"text": "Ob denn wirklich falsch, wie in der Bibel steht,", "tokens": ["Ob", "denn", "wirk\u00b7lich", "falsch", ",", "wie", "in", "der", "Bi\u00b7bel", "steht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "ADJD", "$,", "PWAV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.30": {"text": "Da\u00df die Sonne um den Erdball geht?", "tokens": ["Da\u00df", "die", "Son\u00b7ne", "um", "den", "Erd\u00b7ball", "geht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.31": {"text": "Ob der erste uns'rer V\u00e4ter", "tokens": ["Ob", "der", "ers\u00b7te", "un\u00b7s'\u00b7rer", "V\u00e4\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "PPOSAT", "NN"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.32": {"text": "Wirklich Adam und nicht anders hie\u00df?", "tokens": ["Wirk\u00b7lich", "A\u00b7dam", "und", "nicht", "an\u00b7ders", "hie\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "KON", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.33": {"text": "Ob des ersten Weibes Apfelbi\u00df", "tokens": ["Ob", "des", "ers\u00b7ten", "Wei\u00b7bes", "Ap\u00b7fel\u00b7bi\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.34": {"text": "Hunger, Krieg und Pest und Donnerwetter", "tokens": ["Hun\u00b7ger", ",", "Krieg", "und", "Pest", "und", "Don\u00b7ner\u00b7wet\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN", "KON", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.35": {"text": "Auf die Erde kommen lie\u00df?", "tokens": ["Auf", "die", "Er\u00b7de", "kom\u00b7men", "lie\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.36": {"text": "Ob der Schlange List dies alles that,", "tokens": ["Ob", "der", "Schlan\u00b7ge", "List", "dies", "al\u00b7les", "that", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "PDS", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.37": {"text": "Oder ob's damit ein ander Nist hat?", "tokens": ["O\u00b7der", "ob's", "da\u00b7mit", "ein", "an\u00b7der", "Nist", "hat", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "PAV", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.38": {"text": "Ob das Instrument, womit in Adams Tagen", "tokens": ["Ob", "das", "Inst\u00b7ru\u00b7ment", ",", "wo\u00b7mit", "in", "A\u00b7dams", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "$,", "PWAV", "APPR", "NE", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.39": {"text": "Kain den Abel todt geschlagen,", "tokens": ["Kain", "den", "A\u00b7bel", "todt", "ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.40": {"text": "Eine Kolbe, oder auch wohl gar", "tokens": ["Ei\u00b7ne", "Kol\u00b7be", ",", "o\u00b7der", "auch", "wohl", "gar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KON", "ADV", "ADV", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.41": {"text": "Eine Ofenkr\u00fccke war? \u2013", "tokens": ["Ei\u00b7ne", "O\u00b7fen\u00b7kr\u00fc\u00b7cke", "war", "?", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.42": {"text": "Dies und hundert solcher Dinge,", "tokens": ["Dies", "und", "hun\u00b7dert", "sol\u00b7cher", "Din\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "KON", "CARD", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.43": {"text": "Sammt und sonders so geringe,", "tokens": ["Sammt", "und", "son\u00b7ders", "so", "ge\u00b7rin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADV", "ADV", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.44": {"text": "Da\u00df ein Heer davon, wie es bei'm Wieland hei\u00dft,", "tokens": ["Da\u00df", "ein", "Heer", "da\u00b7von", ",", "wie", "es", "bei'm", "Wie\u00b7land", "hei\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PAV", "$,", "PWAV", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.45": {"text": "Leicht auf einem M\u00fcckenschwanze reist,", "tokens": ["Leicht", "auf", "ei\u00b7nem", "M\u00fc\u00b7cken\u00b7schwan\u00b7ze", "reist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.46": {"text": "Sag', ist das nicht Luxus f\u00fcr den Geist?", "tokens": ["Sag'", ",", "ist", "das", "nicht", "Lu\u00b7xus", "f\u00fcr", "den", "Geist", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "PDS", "PTKNEG", "NN", "APPR", "ART", "NN", "$."], "meter": "+---+-+-+", "measure": "dactylic.init"}}, "stanza.5": {"line.1": {"text": "Das ist Spreu des Wissens, wirst du sagen.", "tokens": ["Das", "ist", "Spreu", "des", "Wis\u00b7sens", ",", "wirst", "du", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "ART", "NN", "$,", "VAFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Gut \u2013 was frommt es aber auch,", "tokens": ["Gut", "\u2013", "was", "frommt", "es", "a\u00b7ber", "auch", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$(", "PWS", "VVFIN", "PPER", "ADV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sich nach grosser Geister Brauch", "tokens": ["Sich", "nach", "gros\u00b7ser", "Geis\u00b7ter", "Brauch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "In das Heiligthum der Wahrheit selbst zu wagen,", "tokens": ["In", "das", "Hei\u00b7lig\u00b7thum", "der", "Wahr\u00b7heit", "selbst", "zu", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Und von ihrem heil'gen Feu'r", "tokens": ["Und", "von", "ih\u00b7rem", "heil'\u00b7gen", "Feu'r"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Hie und da ein F\u00fcnkchen zu erjagen?", "tokens": ["Hie", "und", "da", "ein", "F\u00fcnk\u00b7chen", "zu", "er\u00b7ja\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "ADV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "O, den siebenfachen Schlei'r,", "tokens": ["O", ",", "den", "sie\u00b7ben\u00b7fa\u00b7chen", "Schlei'r", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Der von unten auf bis oben", "tokens": ["Der", "von", "un\u00b7ten", "auf", "bis", "o\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ADV", "APPR", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Zehnfach sie umgibt, hat keines Sterblichen", "tokens": ["Zehn\u00b7fach", "sie", "um\u00b7gibt", ",", "hat", "kei\u00b7nes", "Sterb\u00b7li\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "VVFIN", "$,", "VAFIN", "PIAT", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.10": {"text": "Hand so k\u00fchn noch aufgehoben;", "tokens": ["Hand", "so", "k\u00fchn", "noch", "auf\u00b7ge\u00b7ho\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJD", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Denn die Spr\u00f6de l\u00e4\u00dft sich nicht gewandlos seh'n.", "tokens": ["Denn", "die", "Spr\u00f6\u00b7de", "l\u00e4\u00dft", "sich", "nicht", "ge\u00b7wand\u00b7los", "seh'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KON", "ART", "NN", "VVFIN", "PRF", "PTKNEG", "ADJD", "VVFIN", "NE"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.12": {"text": "Mache, was du willst, um deinen Blick zu sch\u00e4rfen,", "tokens": ["Ma\u00b7che", ",", "was", "du", "willst", ",", "um", "dei\u00b7nen", "Blick", "zu", "sch\u00e4r\u00b7fen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWS", "PPER", "VMFIN", "$,", "KOUI", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.13": {"text": "Nimm die besten Gl\u00e4ser vor's Gesicht,", "tokens": ["Nimm", "die", "bes\u00b7ten", "Gl\u00e4\u00b7ser", "vor's", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.14": {"text": "Guck' \u00e4onenlang, spreng' deiner Augen Nerven,", "tokens": ["Guck'", "\u00e4\u00b7o\u00b7nen\u00b7lang", ",", "spreng'", "dei\u00b7ner", "Au\u00b7gen", "Ner\u00b7ven", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "VVFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.15": {"text": "Durch den Schleier dringst du nicht!", "tokens": ["Durch", "den", "Schlei\u00b7er", "dringst", "du", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.16": {"text": "Wisse, seit sechstausend Jahren", "tokens": ["Wis\u00b7se", ",", "seit", "sech\u00b7stau\u00b7send", "Jah\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "APPR", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Gucken Millionen Augen schon nach ihr,", "tokens": ["Gu\u00b7cken", "Mil\u00b7lion\u00b7en", "Au\u00b7gen", "schon", "nach", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "NN", "ADV", "APPR", "PPER", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.18": {"text": "Aber, Lieber, glaube mir,", "tokens": ["A\u00b7ber", ",", "Lie\u00b7ber", ",", "glau\u00b7be", "mir", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "ADJD", "$,", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.19": {"text": "Nicht ein Einziger hat noch erfahren,", "tokens": ["Nicht", "ein", "Ein\u00b7zi\u00b7ger", "hat", "noch", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "VAFIN", "ADV", "VVINF", "$,"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.20": {"text": "Ob die Dame, die der Schlei'r umschlie\u00dft,", "tokens": ["Ob", "die", "Da\u00b7me", ",", "die", "der", "Schlei'r", "um\u00b7schlie\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.21": {"text": "Eine Weisse oder eine Mohrin ist? \u2013", "tokens": ["Ei\u00b7ne", "Weis\u00b7se", "o\u00b7der", "ei\u00b7ne", "Moh\u00b7rin", "ist", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VAFIN", "$.", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.6": {"line.1": {"text": "O wie viele sind der Wahrheit auf der Spur,", "tokens": ["O", "wie", "vie\u00b7le", "sind", "der", "Wahr\u00b7heit", "auf", "der", "Spur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PWAV", "PIS", "VAFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Doch vergebens, denn sie \u00e4fft sie nur.", "tokens": ["Doch", "ver\u00b7ge\u00b7bens", ",", "denn", "sie", "\u00e4fft", "sie", "nur", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KON", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Auf dem Meer der Zweifel treibet", "tokens": ["Auf", "dem", "Meer", "der", "Zwei\u00b7fel", "trei\u00b7bet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hie und da ein Sch\u00e4chtelchen", "tokens": ["Hie", "und", "da", "ein", "Sch\u00e4ch\u00b7tel\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KON", "ADV", "ART", "NN"], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.5": {"text": "Mit der Inschrift: Sterblichen,", "tokens": ["Mit", "der", "In\u00b7schrift", ":", "Sterb\u00b7li\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Die mein Innerstes er\u00f6ffnen, bleibet", "tokens": ["Die", "mein", "In\u00b7ners\u00b7tes", "er\u00b7\u00f6ff\u00b7nen", ",", "blei\u00b7bet"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "PPOSAT", "NN", "VVINF", "$,", "VVFIN"], "meter": "-++-+-+-+-", "measure": "unknown.measure.penta"}, "line.7": {"text": "Nichts verborgen. \u2013 Hurtig \u00f6ffnet man", "tokens": ["Nichts", "ver\u00b7bor\u00b7gen", ".", "\u2013", "Hur\u00b7tig", "\u00f6ff\u00b7net", "man"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word"], "pos": ["PIS", "VVPP", "$.", "$(", "ADJD", "VVFIN", "PIS"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Nun die erste H\u00fclle, dann", "tokens": ["Nun", "die", "ers\u00b7te", "H\u00fcl\u00b7le", ",", "dann"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "$,", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Auch die zweite, dritte, vierte H\u00fcll';", "tokens": ["Auch", "die", "zwei\u00b7te", ",", "drit\u00b7te", ",", "vier\u00b7te", "H\u00fcll'", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "$,", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "Aber immer ist man nicht am Ziel.", "tokens": ["A\u00b7ber", "im\u00b7mer", "ist", "man", "nicht", "am", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PIS", "PTKNEG", "APPRART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.11": {"text": "Nun die Tausendste? Ha, kleiner,", "tokens": ["Nun", "die", "Tau\u00b7sends\u00b7te", "?", "Ha", ",", "klei\u00b7ner", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "ART", "NN", "$.", "NE", "$,", "ADJA", "$,"], "meter": "--++-++-", "measure": "anapaest.init"}, "line.12": {"text": "Ruft entz\u00fcckt der Gr\u00fcbler einer,", "tokens": ["Ruft", "ent\u00b7z\u00fcckt", "der", "Gr\u00fcb\u00b7ler", "ei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "ART", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Kleiner kann kein Sch\u00e4chtelchen mehr sein,", "tokens": ["Klei\u00b7ner", "kann", "kein", "Sch\u00e4ch\u00b7tel\u00b7chen", "mehr", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PIAT", "NN", "ADV", "VAINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.14": {"text": "Ha! dies schlie\u00dft die Wahrheit selber ein! \u2013", "tokens": ["Ha", "!", "dies", "schlie\u00dft", "die", "Wahr\u00b7heit", "sel\u00b7ber", "ein", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ITJ", "$.", "PDS", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.15": {"text": "Auf, und sieh, auch dies ist offen,", "tokens": ["Auf", ",", "und", "sieh", ",", "auch", "dies", "ist", "of\u00b7fen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$,", "KON", "VVFIN", "$,", "ADV", "PDS", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Und der Gr\u00fcbler liest betroffen:", "tokens": ["Und", "der", "Gr\u00fcb\u00b7ler", "liest", "be\u00b7trof\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Thor, das Resultat von deinen Schl\u00fcssen hei\u00dft:", "tokens": ["Thor", ",", "das", "Re\u00b7sul\u00b7tat", "von", "dei\u00b7nen", "Schl\u00fcs\u00b7sen", "hei\u00dft", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.18": {"text": "Da\u00df du nichts von allem wei\u00dft! \u2013", "tokens": ["Da\u00df", "du", "nichts", "von", "al\u00b7lem", "wei\u00dft", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PIS", "APPR", "PIS", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.19": {"text": "Nun, was hat der Gr\u00fcbler? \u2013 Bl\u00f6de Augen,", "tokens": ["Nun", ",", "was", "hat", "der", "Gr\u00fcb\u00b7ler", "?", "\u2013", "Bl\u00f6\u00b7de", "Au\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VAFIN", "ART", "NN", "$.", "$(", "NN", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.20": {"text": "Sinnen, die zu keinem Dienst mehr taugen,", "tokens": ["Sin\u00b7nen", ",", "die", "zu", "kei\u00b7nem", "Dienst", "mehr", "tau\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "APPR", "PIAT", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.21": {"text": "Einen siechen Leib, ein bleich Gesicht,", "tokens": ["Ei\u00b7nen", "sie\u00b7chen", "Leib", ",", "ein", "bleich", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJD", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.22": {"text": "Zweifel, aber keine Wahrheit nicht! \u2013", "tokens": ["Zwei\u00b7fel", ",", "a\u00b7ber", "kei\u00b7ne", "Wahr\u00b7heit", "nicht", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "ADV", "PIAT", "NN", "PTKNEG", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "La\u00df dies Bild dich nicht emp\u00f6ren,", "tokens": ["La\u00df", "dies", "Bild", "dich", "nicht", "em\u00b7p\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PDS", "NN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Es ist Copie, der es in der Welt", "tokens": ["Es", "ist", "Co\u00b7pie", ",", "der", "es", "in", "der", "Welt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "$,", "PRELS", "PPER", "APPR", "ART", "NN"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Sicherlich nicht an Modellen fehlt.", "tokens": ["Si\u00b7cher\u00b7lich", "nicht", "an", "Mo\u00b7del\u00b7len", "fehlt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKNEG", "APPR", "NN", "VVFIN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Alle Gr\u00fcbelei macht freudenleer,", "tokens": ["Al\u00b7le", "Gr\u00fc\u00b7be\u00b7lei", "macht", "freu\u00b7den\u00b7leer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Dient zu nichts, als h\u00f6chstens nur das Heer", "tokens": ["Dient", "zu", "nichts", ",", "als", "h\u00f6chs\u00b7tens", "nur", "das", "Heer"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PIS", "$,", "KOUS", "ADV", "ADV", "ART", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Uns'rer Uebel zu vermehren.", "tokens": ["Un\u00b7s'\u00b7rer", "Ue\u00b7bel", "zu", "ver\u00b7meh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Willst du den Beweis noch sichtlicher?", "tokens": ["Willst", "du", "den", "Be\u00b7weis", "noch", "sicht\u00b7li\u00b7cher", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Gut, so sehe nur den Mann", "tokens": ["Gut", ",", "so", "se\u00b7he", "nur", "den", "Mann"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "ADV", "VVFIN", "ADV", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Mit der Pflugschaar und den Gr\u00fcbler an,", "tokens": ["Mit", "der", "Pflug\u00b7schaar", "und", "den", "Gr\u00fcb\u00b7ler", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "Und dein Auge wird ihn, ohne Gr\u00fcnden,", "tokens": ["Und", "dein", "Au\u00b7ge", "wird", "ihn", ",", "oh\u00b7ne", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PPER", "$,", "KOUI", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.11": {"text": "In der beiden Seelenausblick finden.", "tokens": ["In", "der", "bei\u00b7den", "See\u00b7le\u00b7naus\u00b7blick", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}}}}