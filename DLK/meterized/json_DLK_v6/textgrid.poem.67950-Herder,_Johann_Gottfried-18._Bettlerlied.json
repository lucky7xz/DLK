{"textgrid.poem.67950": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "18. Bettlerlied", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der lustge Paul \u00fcber Feld allhier", "tokens": ["Der", "lust\u00b7ge", "Paul", "\u00fc\u00b7ber", "Feld", "all\u00b7hier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Kam manchen Tag und Abend zu mir,", "tokens": ["Kam", "man\u00b7chen", "Tag", "und", "A\u00b7bend", "zu", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NN", "KON", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Sprach: gute Frau, gebt doch Quartier", "tokens": ["Sprach", ":", "gu\u00b7te", "Frau", ",", "gebt", "doch", "Quar\u00b7tier"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "ADJA", "NN", "$,", "VVFIN", "ADV", "NN"], "meter": "-+-+--++", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Einem armen Bettelmann!", "tokens": ["Ei\u00b7nem", "ar\u00b7men", "Bet\u00b7tel\u00b7mann", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Die Nacht war kalt, der Mann war na\u00df;", "tokens": ["Die", "Nacht", "war", "kalt", ",", "der", "Mann", "war", "na\u00df", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zu uns er nieder ans Feuer sa\u00df,", "tokens": ["Zu", "uns", "er", "nie\u00b7der", "ans", "Feu\u00b7er", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PPER", "PTKVZ", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Meiner Tochter Schulter er freundlich ma\u00df", "tokens": ["Mei\u00b7ner", "Toch\u00b7ter", "Schul\u00b7ter", "er", "freund\u00b7lich", "ma\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "NN", "PPER", "ADJD", "NN"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "War lustig, erz\u00e4hlt' und sang.", "tokens": ["War", "lus\u00b7tig", ",", "er\u00b7z\u00e4hlt'", "und", "sang", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Und o sprach er: \u00bbw\u00e4r ich noch so frei,", "tokens": ["Und", "o", "sprach", "er", ":", "\u00bb", "w\u00e4r", "ich", "noch", "so", "frei", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "FM", "VVFIN", "PPER", "$.", "$(", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Als einst ich kam der Gegend bei,", "tokens": ["Als", "einst", "ich", "kam", "der", "Ge\u00b7gend", "bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie lustig und fr\u00f6lich wollt ich seyn,", "tokens": ["Wie", "lus\u00b7tig", "und", "fr\u00f6\u00b7lich", "wollt", "ich", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "KON", "ADJD", "VMFIN", "PPER", "VAINF", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Mich nicht bedenken lang!\u00ab", "tokens": ["Mich", "nicht", "be\u00b7den\u00b7ken", "lang", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "PTKNEG", "VVINF", "ADJD", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und er that lieb und sie that sch\u00f6n;", "tokens": ["Und", "er", "that", "lieb", "und", "sie", "that", "sch\u00f6n", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "KON", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch wenig konnt Mama verstehn,", "tokens": ["Doch", "we\u00b7nig", "konnt", "Ma\u00b7ma", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Was mit einander die Zwei begehn,", "tokens": ["Was", "mit", "ein\u00b7an\u00b7der", "die", "Zwei", "be\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PRF", "ART", "CARD", "VVINF", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.8": {"text": "Und th\u00e4ten so eng und drang?", "tokens": ["Und", "th\u00e4\u00b7ten", "so", "eng", "und", "drang", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "KON", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "\u00bbund o, sprach er, w\u00e4rst schwarz und w\u00fcst,", "tokens": ["\u00bb", "und", "o", ",", "sprach", "er", ",", "w\u00e4rst", "schwarz", "und", "w\u00fcst", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "FM", "$,", "VVFIN", "PPER", "$,", "VAFIN", "ADJD", "KON", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Wie dort der Hut dein's Pappa's ist,", "tokens": ["Wie", "dort", "der", "Hut", "dein's", "Pap\u00b7pa's", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich n\u00e4hm' dich auf 'n R\u00fccken, wie du bist,", "tokens": ["Ich", "n\u00e4hm'", "dich", "auf", "'n", "R\u00fc\u00b7cken", ",", "wie", "du", "bist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "$,", "PWAV", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und ging' mit dir davon!\u00ab", "tokens": ["Und", "ging'", "mit", "dir", "da\u00b7von", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "PAV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "\u00bbund o sprach sie, w\u00e4r ich wei\u00df und sch\u00f6n,", "tokens": ["\u00bb", "und", "o", "sprach", "sie", ",", "w\u00e4r", "ich", "wei\u00df", "und", "sch\u00f6n", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "FM", "VVFIN", "PPER", "$,", "VAFIN", "PPER", "VVFIN", "KON", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Wie Schnee, gefallen von Himmelsh\u00f6hn,", "tokens": ["Wie", "Schnee", ",", "ge\u00b7fal\u00b7len", "von", "Him\u00b7mels\u00b7h\u00f6hn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "VVPP", "APPR", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Eine Edelfrau, in Kleidern sch\u00f6n;", "tokens": ["Ei\u00b7ne", "E\u00b7del\u00b7frau", ",", "in", "Klei\u00b7dern", "sch\u00f6n", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "NN", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Ich ginge mit dir davon.\u00ab", "tokens": ["Ich", "gin\u00b7ge", "mit", "dir", "da\u00b7von", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "PAV", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Und so die Zwei kamen \u00fcberein", "tokens": ["Und", "so", "die", "Zwei", "ka\u00b7men", "\u00fc\u00b7be\u00b7re\u00b7in"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "CARD", "VVFIN", "PTKVZ"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sie stunden auf, eh der Hahn th\u00e4t schrein;", "tokens": ["Sie", "stun\u00b7den", "auf", ",", "eh", "der", "Hahn", "th\u00e4t", "schrein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "KOUS", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sie schlossen die Th\u00fcr, so sacht und fein,", "tokens": ["Sie", "schlos\u00b7sen", "die", "Th\u00fcr", ",", "so", "sacht", "und", "fein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und gingen Feld hinan.", "tokens": ["Und", "gin\u00b7gen", "Feld", "hi\u00b7nan", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Fr\u00fchmorgen das alte Weib stand auf", "tokens": ["Fr\u00fch\u00b7mor\u00b7gen", "das", "al\u00b7te", "Weib", "stand", "auf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN", "VVFIN", "APPR"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Zog an sich lang und trappelt drauf", "tokens": ["Zog", "an", "sich", "lang", "und", "trap\u00b7pelt", "drauf"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PRF", "ADJD", "KON", "VVFIN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zu Dienstvolks Betten und tappt hinauf,", "tokens": ["Zu", "Dienst\u00b7volks", "Bet\u00b7ten", "und", "tappt", "hin\u00b7auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Tappt nach dem Bettelmann.", "tokens": ["Tappt", "nach", "dem", "Bet\u00b7tel\u00b7mann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.5": {"line.1": {"text": "Und als sie kam vors Bettlers Bett,", "tokens": ["Und", "als", "sie", "kam", "vors", "Bett\u00b7lers", "Bett", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPRART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Streu war kalt, der Bettler weg,", "tokens": ["Die", "Streu", "war", "kalt", ",", "der", "Bett\u00b7ler", "weg", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbo weh, wenn der bestohlen uns h\u00e4tt!\u00ab", "tokens": ["\u00bb", "o", "weh", ",", "wenn", "der", "be\u00b7stoh\u00b7len", "uns", "h\u00e4tt", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "PTKVZ", "$,", "KOUS", "ART", "VVFIN", "PPER", "VAFIN", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und rang die H\u00e4nd' und schrie.", "tokens": ["Und", "rang", "die", "H\u00e4nd'", "und", "schrie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Zu Kisten und Kasten ein jedes rannt;", "tokens": ["Zu", "Kis\u00b7ten", "und", "Kas\u00b7ten", "ein", "je\u00b7des", "rannt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ART", "PIAT", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Doch alles stand in gutem Stand.", "tokens": ["Doch", "al\u00b7les", "stand", "in", "gu\u00b7tem", "Stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u00bbjughei!\u00ab sie tanzt auf eigne Hand:", "tokens": ["\u00bb", "jug\u00b7hei", "!", "\u00ab", "sie", "tanzt", "auf", "eig\u00b7ne", "Hand", ":"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$.", "$(", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "\u00bbein'n Schelm herberg' ich nie.\u00ab", "tokens": ["\u00bb", "ein'n", "Schelm", "her\u00b7ber\u00b7g'", "ich", "nie", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "PPER", "ADV", "$.", "$("], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.6": {"line.1": {"text": "Und als nun nichts gemangelt h\u00e4tt,", "tokens": ["Und", "als", "nun", "nichts", "ge\u00b7man\u00b7gelt", "h\u00e4tt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "PIS", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und alles stand an Ort und St\u00e4t':", "tokens": ["Und", "al\u00b7les", "stand", "an", "Ort", "und", "St\u00e4t'", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bblauft, sprach sie, zu meiner Tochter Bett;", "tokens": ["\u00bb", "lauft", ",", "sprach", "sie", ",", "zu", "mei\u00b7ner", "Toch\u00b7ter", "Bett", ";"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "VVFIN", "PPER", "$,", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "La\u00dft flugs sie kommen heran!\u00ab", "tokens": ["La\u00dft", "flugs", "sie", "kom\u00b7men", "he\u00b7ran", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "ADV", "PPER", "VVFIN", "PTKVZ", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Die Magd, sie lief zu der Jungfer Bett;", "tokens": ["Die", "Magd", ",", "sie", "lief", "zu", "der", "Jung\u00b7fer", "Bett", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Das Bett war kalt, die Jungfer weg:", "tokens": ["Das", "Bett", "war", "kalt", ",", "die", "Jung\u00b7fer", "weg", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u00bbo weh, wenn der gestohlen sie h\u00e4tt'!", "tokens": ["\u00bb", "o", "weh", ",", "wenn", "der", "ge\u00b7stoh\u00b7len", "sie", "h\u00e4tt'", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "PTKVZ", "$,", "KOUS", "ART", "ADJA", "PPER", "VAFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "Ist fort mit dem Bettelmann.\u00ab", "tokens": ["Ist", "fort", "mit", "dem", "Bet\u00b7tel\u00b7mann", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PTKVZ", "APPR", "ART", "NN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "\u00bbo Pfui denn reitet, o Pfui denn rennt!", "tokens": ["\u00bb", "o", "Pfui", "denn", "rei\u00b7tet", ",", "o", "Pfui", "denn", "rennt", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "FM", "KON", "VVFIN", "$,", "FM", "FM", "KON", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und greift sie, was ihr greifen k\u00f6nnt,", "tokens": ["Und", "greift", "sie", ",", "was", "ihr", "grei\u00b7fen", "k\u00f6nnt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PWS", "PPER", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ihn h\u00e4ngt auf, und sie verbrennt! \u2013", "tokens": ["Und", "ihn", "h\u00e4ngt", "auf", ",", "und", "sie", "ver\u00b7brennt", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKVZ", "$,", "KON", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Schelm vom Bettelmann!\u00ab", "tokens": ["Der", "Schelm", "vom", "Bet\u00b7tel\u00b7mann", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Sie ritten zu Pferd, sie rannten zu Fu\u00df", "tokens": ["Sie", "rit\u00b7ten", "zu", "Pferd", ",", "sie", "rann\u00b7ten", "zu", "Fu\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "PPER", "VVFIN", "APPR", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Das Weib war aus sich vor Verdru\u00df", "tokens": ["Das", "Weib", "war", "aus", "sich", "vor", "Ver\u00b7dru\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "PRF", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Konnt regen weder Hand noch Fu\u00df", "tokens": ["Konnt", "re\u00b7gen", "we\u00b7der", "Hand", "noch", "Fu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "KON", "NN", "ADV", "NN"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.8": {"text": "Und flucht' ihm Fluch und Bann.", "tokens": ["Und", "flucht'", "ihm", "Fluch", "und", "Bann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Als mittlerweil' \u00fcber Feld alldar,", "tokens": ["Als", "mitt\u00b7ler\u00b7weil'", "\u00fc\u00b7ber", "Feld", "all\u00b7dar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Zwei, sie sassen lieblich gar", "tokens": ["Die", "Zwei", ",", "sie", "sas\u00b7sen", "lieb\u00b7lich", "gar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "CARD", "$,", "PPER", "VVFIN", "ADJD", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Im Thal, wo keiner sie ward gewahr,", "tokens": ["Im", "Thal", ",", "wo", "kei\u00b7ner", "sie", "ward", "ge\u00b7wahr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PWAV", "PIS", "PPER", "VAFIN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und schnitten ein'n K\u00e4s' sich an", "tokens": ["Und", "schnit\u00b7ten", "ein'n", "K\u00e4s'", "sich", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "PRF", "APPR"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Der K\u00e4s' er schmeckt, er schmeckt ihn'n beid", "tokens": ["Der", "K\u00e4s'", "er", "schmeckt", ",", "er", "schmeckt", "ihn'n", "beid"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie nimmer zu lassen, th\u00e4t er ihr Eid:", "tokens": ["Sie", "nim\u00b7mer", "zu", "las\u00b7sen", ",", "th\u00e4t", "er", "ihr", "Eid", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKZU", "VVINF", "$,", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "\u00bbdich je zu lassen w\u00e4r Herzeleid", "tokens": ["\u00bb", "dich", "je", "zu", "las\u00b7sen", "w\u00e4r", "Her\u00b7ze\u00b7leid"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "ADV", "PTKZU", "VVINF", "VAFIN", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Mein lieber Bettelmann.\u00ab", "tokens": ["Mein", "lie\u00b7ber", "Bet\u00b7tel\u00b7mann", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "O w\u00fcst' meine Mutter, ich w\u00e4r mit dir", "tokens": ["O", "w\u00fcst'", "mei\u00b7ne", "Mut\u00b7ter", ",", "ich", "w\u00e4r", "mit", "dir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPOSAT", "NN", "$,", "PPER", "VAFIN", "APPR", "PPER"], "meter": "+---+--+-+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Wie hustet' sie und fluchte dir:", "tokens": ["Wie", "hus\u00b7tet'", "sie", "und", "fluch\u00b7te", "dir", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbnun geb ich nimmer auch mehr Quartier", "tokens": ["\u00bb", "nun", "geb", "ich", "nim\u00b7mer", "auch", "mehr", "Quar\u00b7tier"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADV", "ADV", "PIAT", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Einem Schelm von Bettelmann.\u00ab", "tokens": ["Ei\u00b7nem", "Schelm", "von", "Bet\u00b7tel\u00b7mann", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "\u00bbmein Lieb, sprach er, bist aber jung", "tokens": ["\u00bb", "mein", "Lieb", ",", "sprach", "er", ",", "bist", "a\u00b7ber", "jung"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "$,", "VAFIN", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und kannst nicht reden die Bettlerzung", "tokens": ["Und", "kannst", "nicht", "re\u00b7den", "die", "Bett\u00b7ler\u00b7zung"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PTKNEG", "VVINF", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Ist mir zu folgen dir gut genung?", "tokens": ["Ist", "mir", "zu", "fol\u00b7gen", "dir", "gut", "ge\u00b7nung", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKZU", "VVINF", "PPER", "ADJD", "NN", "$."], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Einen armen Bettelmann.\u00ab", "tokens": ["Ei\u00b7nen", "ar\u00b7men", "Bet\u00b7tel\u00b7mann", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Mit Spinnen und Weben schaff ' ich Brod", "tokens": ["Mit", "Spin\u00b7nen", "und", "We\u00b7ben", "schaff", "'", "ich", "Brod"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$(", "PPER", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Mit Spinnen und Weben hats nimmer Noth", "tokens": ["Mit", "Spin\u00b7nen", "und", "We\u00b7ben", "hats", "nim\u00b7mer", "Noth"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VAFIN", "ADV", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Durchs liebe Leben, bis in den Tod", "tokens": ["Durchs", "lie\u00b7be", "Le\u00b7ben", ",", "bis", "in", "den", "Tod"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "$,", "KOUS", "APPR", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Meinen Bettler f\u00fchr' ich. O!", "tokens": ["Mei\u00b7nen", "Bett\u00b7ler", "f\u00fchr'", "ich", ".", "O", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "$.", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und zieh den Fu\u00df und knick mein Knie", "tokens": ["Und", "zieh", "den", "Fu\u00df", "und", "knick", "mein", "Knie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "KON", "VVIMP", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und bind ein Tuch \u00fcbers Auge hie", "tokens": ["Und", "bind", "ein", "Tuch", "\u00fc\u00b7bers", "Au\u00b7ge", "hie"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN", "APPRART", "NN", "ADV"], "meter": "-+-++-+-+", "measure": "unknown.measure.penta"}, "line.7": {"text": "Da sprechen sie: ach! die Arme \u2013 die", "tokens": ["Da", "spre\u00b7chen", "sie", ":", "ach", "!", "die", "Ar\u00b7me", "\u2013", "die"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "PPER", "$.", "XY", "$.", "ART", "NN", "$(", "ART"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Und wir leben fr\u00f6hlich \u2013 O!", "tokens": ["Und", "wir", "le\u00b7ben", "fr\u00f6h\u00b7lich", "\u2013", "O", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "$(", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}