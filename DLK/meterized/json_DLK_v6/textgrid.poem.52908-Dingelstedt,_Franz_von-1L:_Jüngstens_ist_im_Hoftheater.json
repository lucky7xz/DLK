{"textgrid.poem.52908": {"metadata": {"author": {"name": "Dingelstedt, Franz von", "birth": "N.A.", "death": "N.A."}, "title": "1L: J\u00fcngstens ist im Hoftheater", "genre": "verse", "period": "N.A.", "pub_year": 1847, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "J\u00fcngstens ist im Hoftheater", "tokens": ["J\u00fcng\u00b7stens", "ist", "im", "Hof\u00b7the\u00b7a\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsrem lieben Landesvater", "tokens": ["Uns\u00b7rem", "lie\u00b7ben", "Lan\u00b7des\u00b7va\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Folgendes Malheur passiert,", "tokens": ["Fol\u00b7gen\u00b7des", "Mal\u00b7heur", "pas\u00b7siert", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.4": {"text": "Wie die Chronik referiert.", "tokens": ["Wie", "die", "Chro\u00b7nik", "re\u00b7fe\u00b7riert", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.2": {"line.1": {"text": "Durch die f\u00fcrstliche Lorgnette", "tokens": ["Durch", "die", "f\u00fcrst\u00b7li\u00b7che", "Lorg\u00b7net\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+--++-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Blickend von gewohnter St\u00e4tte,", "tokens": ["Bli\u00b7ckend", "von", "ge\u00b7wohn\u00b7ter", "St\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Fand der adlersicht'ge HErr", "tokens": ["Fand", "der", "ad\u00b7ler\u00b7sicht'\u00b7ge", "Herr"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Einen Fremdling im Parterr.", "tokens": ["Ei\u00b7nen", "Fremd\u00b7ling", "im", "Par\u00b7terr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "War kein Kerl wie andre Fremde,", "tokens": ["War", "kein", "Kerl", "wie", "and\u00b7re", "Frem\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "KOKOM", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Trug ein blaugestreiftes Hemde", "tokens": ["Trug", "ein", "blau\u00b7ge\u00b7streif\u00b7tes", "Hem\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ein tricolores Tuch, \u2013", "tokens": ["Und", "ein", "tri\u00b7co\u00b7lo\u00b7res", "Tuch", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gr\u00fcnde zum Verdacht genug!", "tokens": ["Gr\u00fcn\u00b7de", "zum", "Ver\u00b7dacht", "ge\u00b7nug", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Sein Gesicht von roter Farbe", "tokens": ["Sein", "Ge\u00b7sicht", "von", "ro\u00b7ter", "Far\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zeigte eine breite Narbe,", "tokens": ["Zeig\u00b7te", "ei\u00b7ne", "brei\u00b7te", "Nar\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und der rundgezogne Bart", "tokens": ["Und", "der", "rund\u00b7ge\u00b7zog\u00b7ne", "Bart"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Schien verp\u00f6nter Hambachs-Art.", "tokens": ["Schien", "ver\u00b7p\u00f6n\u00b7ter", "Ham\u00b7bachs\u00b7Art", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Auf der Stirne b\u00f6se Falten,", "tokens": ["Auf", "der", "Stir\u00b7ne", "b\u00f6\u00b7se", "Fal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aber doch zur\u00fcckgehalten,", "tokens": ["A\u00b7ber", "doch", "zu\u00b7r\u00fcck\u00b7ge\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Fragt der HErr den Kammerherr,", "tokens": ["Fragt", "der", "Herr", "den", "Kam\u00b7mer\u00b7herr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wer der Fremdling im Parterr?", "tokens": ["Wer", "der", "Fremd\u00b7ling", "im", "Par\u00b7terr", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Und der Kammerherr schickt's weiter", "tokens": ["Und", "der", "Kam\u00b7mer\u00b7herr", "schickt's", "wei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "An des F\u00fcrsten Leibbereiter,", "tokens": ["An", "des", "F\u00fcrs\u00b7ten", "Leib\u00b7be\u00b7rei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "An den Rat und Adjutant \u2013", "tokens": ["An", "den", "Rat", "und", "Ad\u00b7ju\u00b7tant", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Keiner hat den Kerl gekannt.", "tokens": ["Kei\u00b7ner", "hat", "den", "Kerl", "ge\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "In den Logen ersten Ranges", "tokens": ["In", "den", "Lo\u00b7gen", "ers\u00b7ten", "Ran\u00b7ges"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hob darauf ein leises, banges,", "tokens": ["Hob", "da\u00b7rauf", "ein", "lei\u00b7ses", ",", "ban\u00b7ges", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "PAV", "ART", "ADJA", "$,", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Scheues Flistern ringsum an,", "tokens": ["Scheu\u00b7es", "Flis\u00b7tern", "ring\u00b7sum", "an", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Alles f\u00fcr den fremden Mann.", "tokens": ["Al\u00b7les", "f\u00fcr", "den", "frem\u00b7den", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "\u00bbdurchlaucht spricht von Propagande,", "tokens": ["\u00bb", "durch\u00b7laucht", "spricht", "von", "Pro\u00b7pa\u00b7gan\u00b7de", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVPP", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fort mit ihm aus unsrem Lande,", "tokens": ["Fort", "mit", "ihm", "aus", "uns\u00b7rem", "Lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weh ihm, wenn in Tagesfrist", "tokens": ["Weh", "ihm", ",", "wenn", "in", "Ta\u00b7ges\u00b7frist"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "KOUS", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Er noch hier zu finden ist!\u00ab", "tokens": ["Er", "noch", "hier", "zu", "fin\u00b7den", "ist", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "ADV", "ADV", "PTKZU", "VVINF", "VAFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "So ein Polizei-Beamte,", "tokens": ["So", "ein", "Po\u00b7li\u00b7zei\u00b7Be\u00b7am\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Welchen heil'ger Zorn entflammte,", "tokens": ["Wel\u00b7chen", "heil'\u00b7ger", "Zorn", "ent\u00b7flamm\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber Durchlaucht winkte still,", "tokens": ["A\u00b7ber", "Durch\u00b7laucht", "wink\u00b7te", "still", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df er's selber ordnen will.", "tokens": ["Da\u00df", "er's", "sel\u00b7ber", "ord\u00b7nen", "will", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Seiner Diener schickt er einen,", "tokens": ["Sei\u00b7ner", "Die\u00b7ner", "schickt", "er", "ei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ART", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vor dem Fremdling zu erscheinen", "tokens": ["Vor", "dem", "Fremd\u00b7ling", "zu", "er\u00b7schei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und zu fragen frank und frei,", "tokens": ["Und", "zu", "fra\u00b7gen", "frank", "und", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKZU", "VVINF", "VVFIN", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wer, woher und was er sei?", "tokens": ["Wer", ",", "wo\u00b7her", "und", "was", "er", "sei", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "PWAV", "KON", "PWS", "PPER", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Nach minutenlangem Harren,", "tokens": ["Nach", "mi\u00b7nu\u00b7ten\u00b7lan\u00b7gem", "Har\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00c4ngstlichem Hinunterstarren,", "tokens": ["\u00c4ngst\u00b7li\u00b7chem", "Hin\u00b7un\u00b7ter\u00b7star\u00b7ren", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Kommt mit klug verschwiegnem Blick", "tokens": ["Kommt", "mit", "klug", "ver\u00b7schwieg\u00b7nem", "Blick"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ADJD", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Der Lakai zum HErrn zur\u00fcck.", "tokens": ["Der", "La\u00b7kai", "zum", "Herrn", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "\u00bbdurchlaucht! dieser Fremdling,\u00ab spricht er,", "tokens": ["\u00bb", "durch\u00b7laucht", "!", "die\u00b7ser", "Fremd\u00b7ling", ",", "\u00ab", "spricht", "er", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "VVPP", "$.", "PDAT", "NN", "$,", "$(", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbnennt sich Johann Jacob Richter,", "tokens": ["\u00bb", "nennt", "sich", "Jo\u00b7hann", "Ja\u00b7cob", "Rich\u00b7ter", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PRF", "NE", "NE", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Macht in Senf f\u00fcr eignes Haus\u00ab \u2013 \u2013", "tokens": ["Macht", "in", "Senf", "f\u00fcr", "eig\u00b7nes", "Haus", "\u00ab", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "APPR", "NE", "APPR", "ADJA", "NN", "$(", "$(", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "\u2013 \u00bbStille!\u00ab \u2013 Und der Spuk war aus!", "tokens": ["\u2013", "\u00bb", "Stil\u00b7le", "!", "\u00ab", "\u2013", "Und", "der", "Spuk", "war", "aus", "!"], "token_info": ["punct", "punct", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "$(", "NN", "$.", "$(", "$(", "KON", "ART", "NN", "VAFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}