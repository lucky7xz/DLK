{"dta.poem.10592": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "Antwort auff Herren Balthasaris Venatoris  \n Teutsches Carmen an mich geschriben.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1624", "urn": "urn:nbn:de:kobv:b4-200905197859", "language": ["de:0.99"], "booktitle": "Opitz, Martin: Teutsche P\u00f6emata und: Aristarchvs Wieder die verachtung Teutscher Sprach. Stra\u00dfburg, 1624."}, "poem": {"stanza.1": {"line.1": {"text": "Wie ich empfangen ward/ wie man mich angenommen/", "tokens": ["Wie", "ich", "emp\u00b7fan\u00b7gen", "ward", "/", "wie", "man", "mich", "an\u00b7ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVPP", "VAFIN", "$(", "PWAV", "PIS", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Al\u00df ich auff Helicon bin dieser Tage kommen/", "tokens": ["Al\u00df", "ich", "auff", "He\u00b7li\u00b7con", "bin", "die\u00b7ser", "Ta\u00b7ge", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "VAFIN", "PDAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Au\u00df Venus anbefehl zu ", "tokens": ["Au\u00df", "Ve\u00b7nus", "an\u00b7be\u00b7fehl", "zu"], "token_info": ["word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ist mir am besten selbst vnd mehr als wohl bekandt.", "tokens": ["Ist", "mir", "am", "bes\u00b7ten", "selbst", "vnd", "mehr", "als", "wohl", "be\u00b7kandt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKA", "ADJD", "ADV", "KON", "PIS", "KOKOM", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich war den hohen Berg kaum recht hinan gestiegen/", "tokens": ["Ich", "war", "den", "ho\u00b7hen", "Berg", "kaum", "recht", "hi\u00b7nan", "ge\u00b7stie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "ADV", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da sah ich vmb mein Haupt mit grossem sturme fliegen", "tokens": ["Da", "sah", "ich", "vmb", "mein", "Haupt", "mit", "gros\u00b7sem", "stur\u00b7me", "flie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Fl\u00f6t\u2019/ Harfen/ vnd Pandor: Es wardt ein gro\u00df gelauff/", "tokens": ["Fl\u00f6t'", "/", "Har\u00b7fen", "/", "vnd", "Pan\u00b7dor", ":", "Es", "wardt", "ein", "gro\u00df", "ge\u00b7lauff", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "KON", "NE", "$.", "PPER", "VAFIN", "ART", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Apollo schrie mich an/ die Musen stunden auff.", "tokens": ["A\u00b7pol\u00b7lo", "schrie", "mich", "an", "/", "die", "Mu\u00b7sen", "stun\u00b7den", "auff", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKVZ", "$(", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Euterpe sonderlich springt zornig zu dem Bronnen", "tokens": ["Eu\u00b7ter\u00b7pe", "son\u00b7der\u00b7lich", "springt", "zor\u00b7nig", "zu", "dem", "Bron\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADJD", "VVFIN", "ADJD", "APPR", "ART", "NN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.10": {"text": "Den Pegasus gemacht/ eh ich mich wenden k\u00f6nnen/", "tokens": ["Den", "Pe\u00b7ga\u00b7sus", "ge\u00b7macht", "/", "eh", "ich", "mich", "wen\u00b7den", "k\u00f6n\u00b7nen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVPP", "$(", "KOUS", "PPER", "PRF", "VVINF", "VMINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Geu\u00dft heuffig auff mich zu/ macht durch vnd durch mich na\u00df/", "tokens": ["Geu\u00dft", "heuf\u00b7fig", "auff", "mich", "zu", "/", "macht", "durch", "vnd", "durch", "mich", "na\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "APPR", "PPER", "PTKZU", "$(", "VVFIN", "APPR", "KON", "APPR", "PPER", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Da\u00df ich der Musen gern vnd fast mein selbst verga\u00df.", "tokens": ["Da\u00df", "ich", "der", "Mu\u00b7sen", "gern", "vnd", "fast", "mein", "selbst", "ver\u00b7ga\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "KON", "ADV", "PPOSAT", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ich machte mich beyseit/ vnd setzt au\u00df scham mich nider", "tokens": ["Ich", "mach\u00b7te", "mich", "bey\u00b7seit", "/", "vnd", "setzt", "au\u00df", "scham", "mich", "ni\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$(", "KON", "VVFIN", "PTKVZ", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Bey einem Lorbeerbaum/ bedachte hin vnd wider", "tokens": ["Bey", "ei\u00b7nem", "Lor\u00b7beer\u00b7baum", "/", "be\u00b7dach\u00b7te", "hin", "vnd", "wi\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$(", "ADJA", "PTKVZ", "KON", "PTKVZ"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wie hefftig ich gejrrt/ da\u00df ich solch ding begehrt", "tokens": ["Wie", "heff\u00b7tig", "ich", "ge\u00b7jrrt", "/", "da\u00df", "ich", "solch", "ding", "be\u00b7gehrt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "PPER", "VVPP", "$(", "KOUS", "PPER", "PIAT", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Da\u00df keinen vor der Zeit die Musen je gewehrt.", "tokens": ["Da\u00df", "kei\u00b7nen", "vor", "der", "Zeit", "die", "Mu\u00b7sen", "je", "ge\u00b7wehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "APPR", "ART", "NN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "In dem ich also sa\u00df in Scham vnd tieffen Sinnen/", "tokens": ["In", "dem", "ich", "al\u00b7so", "sa\u00df", "in", "Scham", "vnd", "tief\u00b7fen", "Sin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "VVFIN", "APPR", "NN", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Kam Meleager her der J\u00e4ger der G\u00f6ttinnen/", "tokens": ["Kam", "Me\u00b7le\u00b7a\u00b7ger", "her", "der", "J\u00e4\u00b7ger", "der", "G\u00f6t\u00b7tin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APZR", "ART", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Sagt/ da\u00df er jetzundt erst vorbey gegangen sey/", "tokens": ["Sagt", "/", "da\u00df", "er", "je\u00b7tzundt", "erst", "vor\u00b7bey", "ge\u00b7gan\u00b7gen", "sey", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "KOUS", "PPER", "ADV", "ADV", "ADV", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Vnd heimlich zugeh\u00f6rt/ wie Erato so frey", "tokens": ["Vnd", "heim\u00b7lich", "zu\u00b7ge\u00b7h\u00f6rt", "/", "wie", "E\u00b7ra\u00b7to", "so", "frey"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVPP", "$(", "KOKOM", "NE", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "F\u00fcr mich geredet hab/ vnd hesstig sehr gestritten/", "tokens": ["F\u00fcr", "mich", "ge\u00b7re\u00b7det", "hab", "/", "vnd", "hess\u00b7tig", "sehr", "ge\u00b7strit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "VAFIN", "$(", "KON", "ADJD", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Es w\u00fcrde Venus nicht so trewlich f\u00fcr mich bitten", "tokens": ["Es", "w\u00fcr\u00b7de", "Ve\u00b7nus", "nicht", "so", "trew\u00b7lich", "f\u00fcr", "mich", "bit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "PTKNEG", "ADV", "ADJD", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Wann ich es nicht verdient: Darauff hab also bald", "tokens": ["Wann", "ich", "es", "nicht", "ver\u00b7dient", ":", "Dar\u00b7auff", "hab", "al\u00b7so", "bald"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PPER", "PTKNEG", "VVPP", "$.", "PAV", "VAFIN", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Apollo sie vnd sich gar wol zu fried gestalt.", "tokens": ["A\u00b7pol\u00b7lo", "sie", "vnd", "sich", "gar", "wol", "zu", "fried", "ge\u00b7stalt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "KON", "PRF", "ADV", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Dem sey nun wie jhm will/ so lieb ich doch vor allen/", "tokens": ["Dem", "sey", "nun", "wie", "jhm", "will", "/", "so", "lieb", "ich", "doch", "vor", "al\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "KOKOM", "PPER", "VMFIN", "$(", "ADV", "ADJD", "PPER", "ADV", "APPR", "PIAT", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Da\u00df Meleager jhm mich l\u00e4st so wolgefallen.", "tokens": ["Da\u00df", "Me\u00b7le\u00b7a\u00b7ger", "jhm", "mich", "l\u00e4st", "so", "wol\u00b7ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "PPER", "VVFIN", "ADV", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Lobt er vnd Erato mein newes Seytenspiel/", "tokens": ["Lobt", "er", "vnd", "E\u00b7ra\u00b7to", "mein", "ne\u00b7wes", "Sey\u00b7ten\u00b7spiel", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KON", "NE", "PPOSAT", "ADJA", "NN", "$("], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.28": {"text": "Der gantze Helicon mag bleiben wer er will.", "tokens": ["Der", "gant\u00b7ze", "He\u00b7li\u00b7con", "mag", "blei\u00b7ben", "wer", "er", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "VVINF", "PWS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}