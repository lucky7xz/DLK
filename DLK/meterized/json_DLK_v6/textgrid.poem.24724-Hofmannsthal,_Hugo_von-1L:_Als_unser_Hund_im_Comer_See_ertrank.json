{"textgrid.poem.24724": {"metadata": {"author": {"name": "Hofmannsthal, Hugo von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Als unser Hund im Comer See ertrank", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als unser Hund im Comer See ertrank", "tokens": ["Als", "un\u00b7ser", "Hund", "im", "Co\u00b7mer", "See", "er\u00b7trank"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "APPRART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und wir zusahen und nicht helfen konnten", "tokens": ["Und", "wir", "zu\u00b7sa\u00b7hen", "und", "nicht", "hel\u00b7fen", "konn\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVINF", "KON", "PTKNEG", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da sahst Du lange nach auf der besonnten", "tokens": ["Da", "sahst", "Du", "lan\u00b7ge", "nach", "auf", "der", "be\u00b7sonn\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "APPR", "ART", "ADJA"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und dunklen Flut der kleinen wei\u00dfen Leiche", "tokens": ["Und", "dunk\u00b7len", "Flut", "der", "klei\u00b7nen", "wei\u00b7\u00dfen", "Lei\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die, treibend, ganz zerging in goldner Bleiche,", "tokens": ["Die", ",", "trei\u00b7bend", ",", "ganz", "zer\u00b7ging", "in", "gold\u00b7ner", "Blei\u00b7che", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADJD", "$,", "ADV", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Dann sagtest Du: \u00bbEs war am Ende gut", "tokens": ["Dann", "sag\u00b7test", "Du", ":", "\u00bb", "Es", "war", "am", "En\u00b7de", "gut"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$.", "$(", "PPER", "VAFIN", "APPRART", "NN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Da\u00df er jetzt fort ist und f\u00fcr uns der gleiche", "tokens": ["Da\u00df", "er", "jetzt", "fort", "ist", "und", "f\u00fcr", "uns", "der", "glei\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PTKVZ", "VAFIN", "KON", "APPR", "PPER", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "In der Erinn'rung dieser Tage ruht:", "tokens": ["In", "der", "Er\u00b7inn'\u00b7rung", "die\u00b7ser", "Ta\u00b7ge", "ruht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Denn kl\u00e4glich h\u00e4\u00dflich ist ein altes Tier", "tokens": ["Denn", "kl\u00e4g\u00b7lich", "h\u00e4\u00df\u00b7lich", "ist", "ein", "al\u00b7tes", "Tier"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "ADJD", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und grauenvoll in mancher Abendstunde", "tokens": ["Und", "grau\u00b7en\u00b7voll", "in", "man\u00b7cher", "A\u00b7bends\u00b7tun\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Dann sp\u00e4ter uns, den jungen, Dir und mir:", "tokens": ["Dann", "sp\u00e4\u00b7ter", "uns", ",", "den", "jun\u00b7gen", ",", "Dir", "und", "mir", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "$,", "ART", "ADJA", "$,", "PPER", "KON", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Denn er w\u00e4r alt und wir noch jung gewesen", "tokens": ["Denn", "er", "w\u00e4r", "alt", "und", "wir", "noch", "jung", "ge\u00b7we\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "KON", "PPER", "ADV", "ADJD", "VAPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Und wie aus eines offnen Grabes Munde", "tokens": ["Und", "wie", "aus", "ei\u00b7nes", "off\u00b7nen", "Gra\u00b7bes", "Mun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "So h\u00e4tte Gott geschrien aus diesem Wesen\u00ab ...", "tokens": ["So", "h\u00e4t\u00b7te", "Gott", "ge\u00b7schri\u00b7en", "aus", "die\u00b7sem", "We\u00b7sen", "\u00ab", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "NN", "VVPP", "APPR", "PDAT", "NN", "$(", "$("], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Mir aber kam ganz anders in den Sinn", "tokens": ["Mir", "a\u00b7ber", "kam", "ganz", "an\u00b7ders", "in", "den", "Sinn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Dieselbe Sache, da\u00df der Hund ertrank:", "tokens": ["Die\u00b7sel\u00b7be", "Sa\u00b7che", ",", "da\u00df", "der", "Hund", "er\u00b7trank", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Ich sah die wundersch\u00f6ne Uferbank", "tokens": ["Ich", "sah", "die", "wun\u00b7der\u00b7sch\u00f6\u00b7ne", "U\u00b7fer\u00b7bank"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Wohin ihn sp\u00fclt das gleitende Gerinn,", "tokens": ["Wo\u00b7hin", "ihn", "sp\u00fclt", "das", "glei\u00b7ten\u00b7de", "Ge\u00b7rinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Und in den Zweigen s\u00fc\u00dfen zarten Wind", "tokens": ["Und", "in", "den", "Zwei\u00b7gen", "s\u00fc\u00b7\u00dfen", "zar\u00b7ten", "Wind"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Und dort zwei Menschen wie wir beide sind:", "tokens": ["Und", "dort", "zwei", "Men\u00b7schen", "wie", "wir", "bei\u00b7de", "sind", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "CARD", "NN", "KOKOM", "PPER", "PIS", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Und ihre Sch\u00f6nheit drang in mich hinein", "tokens": ["Und", "ih\u00b7re", "Sch\u00f6n\u00b7heit", "drang", "in", "mich", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPR", "PRF", "APZR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Und dann: die Einigkeit von alledem im Sein.", "tokens": ["Und", "dann", ":", "die", "Ei\u00b7nig\u00b7keit", "von", "al\u00b7le\u00b7dem", "im", "Sein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$.", "ART", "NN", "APPR", "PIS", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}