{"textgrid.poem.31769": {"metadata": {"author": {"name": "Weerth, Georg", "birth": "N.A.", "death": "N.A."}, "title": "7.", "genre": "verse", "period": "N.A.", "pub_year": 1839, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gendarmen hasse ich wie die Pest;", "tokens": ["Gen\u00b7dar\u00b7men", "has\u00b7se", "ich", "wie", "die", "Pest", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "KOKOM", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ich hasse sie mehr als Spinnen,", "tokens": ["Ich", "has\u00b7se", "sie", "mehr", "als", "Spin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "KOUS", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Als gr\u00fcne Seife \u2013 Du lieber Gott,", "tokens": ["Als", "gr\u00fc\u00b7ne", "Sei\u00b7fe", "\u2013", "Du", "lie\u00b7ber", "Gott", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "$(", "PPER", "ADV", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Was soll ich nun beginnen!", "tokens": ["Was", "soll", "ich", "nun", "be\u00b7gin\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Der eine zog ein Signalement", "tokens": ["Der", "ei\u00b7ne", "zog", "ein", "Sig\u00b7na\u00b7le\u00b7ment"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Aus seiner sch\u00e4bigen Tasche.", "tokens": ["Aus", "sei\u00b7ner", "sch\u00e4\u00b7bi\u00b7gen", "Ta\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und mich betrachtend mit stierem Blick,", "tokens": ["Und", "mich", "be\u00b7trach\u00b7tend", "mit", "stie\u00b7rem", "Blick", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Begann er zu murmeln rasche:", "tokens": ["Be\u00b7gann", "er", "zu", "mur\u00b7meln", "ra\u00b7sche", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "\u00bbf\u00fcnf Fu\u00df, zehn Zoll \u2013 die Haare blond \u2013", "tokens": ["\u00bb", "f\u00fcnf", "Fu\u00df", ",", "zehn", "Zoll", "\u2013", "die", "Haa\u00b7re", "blond", "\u2013"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "CARD", "NN", "$,", "CARD", "NN", "$(", "ART", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Olympisch gew\u00f6lbt die Stirne \u2013", "tokens": ["O\u00b7lym\u00b7pisch", "ge\u00b7w\u00f6lbt", "die", "Stir\u00b7ne", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ein roter Bart \u2013 Statur ist schlank \u2013", "tokens": ["Ein", "ro\u00b7ter", "Bart", "\u2013", "Sta\u00b7tur", "ist", "schlank", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "NN", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kennzeichen: Viel Gehirne. \u2013", "tokens": ["Kenn\u00b7zei\u00b7chen", ":", "Viel", "Ge\u00b7hir\u00b7ne", ".", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "PIAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Auch macht er Verse \u2013 spricht kein Latein", "tokens": ["Auch", "macht", "er", "Ver\u00b7se", "\u2013", "spricht", "kein", "La\u00b7tein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$(", "VVFIN", "PIAT", "NN"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Bla\u00df ist er wie gro\u00dfe Geister \u2013", "tokens": ["Bla\u00df", "ist", "er", "wie", "gro\u00b7\u00dfe", "Geis\u00b7ter", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "KOKOM", "ADJA", "NN", "$("], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.3": {"text": "Die Z\u00e4hne sind gut \u2013 \u2013 Verehrter Herr,", "tokens": ["Die", "Z\u00e4h\u00b7ne", "sind", "gut", "\u2013", "\u2013", "Ver\u00b7ehr\u00b7ter", "Herr", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$(", "$(", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ohne Umschweife viel: wie hei\u00dft er?\u00ab", "tokens": ["Oh\u00b7ne", "Um\u00b7schwei\u00b7fe", "viel", ":", "wie", "hei\u00dft", "er", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "ADV", "$.", "PWAV", "VVFIN", "PPER", "$.", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.5": {"line.1": {"text": "Da hob ich mich w\u00fcrdig empor und sprach:", "tokens": ["Da", "hob", "ich", "mich", "w\u00fcr\u00b7dig", "em\u00b7por", "und", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJD", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "\u00bbich hei\u00dfe Charlemagne!", "tokens": ["\u00bb", "ich", "hei\u00b7\u00dfe", "Char\u00b7le\u00b7mag\u00b7ne", "!"], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wollh\u00e4ndler bin ich in Aachen und trink", "tokens": ["Woll\u00b7h\u00e4nd\u00b7ler", "bin", "ich", "in", "Aa\u00b7chen", "und", "trink"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "PPER", "APPR", "NE", "KON", "VVFIN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Recht gerne den Wein der Champagne.", "tokens": ["Recht", "ger\u00b7ne", "den", "Wein", "der", "Cham\u00b7pag\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.6": {"line.1": {"text": "Ich spekuliere in Tr\u00fcffeln und \u00d6l,", "tokens": ["Ich", "spe\u00b7ku\u00b7lie\u00b7re", "in", "Tr\u00fcf\u00b7feln", "und", "\u00d6l", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mein Bankier empf\u00e4ngt mich pr\u00e4chtig.\u00ab", "tokens": ["Mein", "Ban\u00b7kier", "emp\u00b7f\u00e4ngt", "mich", "pr\u00e4ch\u00b7tig", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADJD", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da sprach der erste Gendarme: \u00bbMein Herr,", "tokens": ["Da", "sprach", "der", "ers\u00b7te", "Gen\u00b7dar\u00b7me", ":", "\u00bb", "Mein", "Herr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$.", "$(", "PPOSAT", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Dies ist ausnehmend verd\u00e4chtig!\u00ab", "tokens": ["Dies", "ist", "aus\u00b7neh\u00b7mend", "ver\u00b7d\u00e4ch\u00b7tig", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "ADJD", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Ich aber fuhr fort: \u00bbAuch Spiritus", "tokens": ["Ich", "a\u00b7ber", "fuhr", "fort", ":", "\u00bb", "Auch", "Spi\u00b7ri\u00b7tus"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "PTKVZ", "$.", "$(", "ADV", "NE"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Verkauf ich von hoher Reinheit,", "tokens": ["Ver\u00b7kauf", "ich", "von", "ho\u00b7her", "Rein\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Nahm Aktien auf jede Luftschiffahrt", "tokens": ["Nahm", "Ak\u00b7ti\u00b7en", "auf", "je\u00b7de", "Luft\u00b7schif\u00b7fahrt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Sowie auf die deutsche Einheit.", "tokens": ["So\u00b7wie", "auf", "die", "deut\u00b7sche", "Ein\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Bei Tage besorge ich mein Gesch\u00e4ft,", "tokens": ["Bei", "Ta\u00b7ge", "be\u00b7sor\u00b7ge", "ich", "mein", "Ge\u00b7sch\u00e4ft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Doch nachts, da treibe ich Sp\u00e4\u00dfe.\u00ab \u2013", "tokens": ["Doch", "nachts", ",", "da", "trei\u00b7be", "ich", "Sp\u00e4\u00b7\u00dfe", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "ADV", "$,", "ADV", "VVFIN", "PPER", "NN", "$.", "$(", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da sprach der zweite Gendarme: \u00bbMein Herr,", "tokens": ["Da", "sprach", "der", "zwei\u00b7te", "Gen\u00b7dar\u00b7me", ":", "\u00bb", "Mein", "Herr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$.", "$(", "PPOSAT", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wo haben Sie Ihre P\u00e4sse?\u00ab", "tokens": ["Wo", "ha\u00b7ben", "Sie", "Ih\u00b7re", "P\u00e4s\u00b7se", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PPOSAT", "NN", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "\u00bbmeinen Pa\u00df! Meinen Pa\u00df! \u2013 Oh, wollen Sie nicht", "tokens": ["\u00bb", "mei\u00b7nen", "Pa\u00df", "!", "Mei\u00b7nen", "Pa\u00df", "!", "\u2013", "Oh", ",", "wol\u00b7len", "Sie", "nicht"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word"], "pos": ["$(", "PPOSAT", "NN", "$.", "PPOSAT", "NN", "$.", "$(", "ITJ", "$,", "VMFIN", "PPER", "PTKNEG"], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Sich g\u00fctigst ein wenig setzen?", "tokens": ["Sich", "g\u00fc\u00b7tigst", "ein", "we\u00b7nig", "set\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "ART", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Oh, trinken Sie doch einen Becher Wein,", "tokens": ["Oh", ",", "trin\u00b7ken", "Sie", "doch", "ei\u00b7nen", "Be\u00b7cher", "Wein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "PPER", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Das w\u00fcrde mich sehr ergetzen!", "tokens": ["Das", "w\u00fcr\u00b7de", "mich", "sehr", "er\u00b7get\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Mein Pa\u00df! Mein Pa\u00df! \u2013 Ach leider ist", "tokens": ["Mein", "Pa\u00df", "!", "Mein", "Pa\u00df", "!", "\u2013", "Ach", "lei\u00b7der", "ist"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$.", "PPOSAT", "NN", "$.", "$(", "ITJ", "ADV", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er gescheitert am Lurlei neulich.", "tokens": ["Er", "ge\u00b7schei\u00b7tert", "am", "Lur\u00b7lei", "neu\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "APPRART", "NN", "ADV", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Oh, trinken Sie doch einen Becher Wein,", "tokens": ["Oh", ",", "trin\u00b7ken", "Sie", "doch", "ei\u00b7nen", "Be\u00b7cher", "Wein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "PPER", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Das w\u00e4re mir sehr erfreulich!\u00ab", "tokens": ["Das", "w\u00e4\u00b7re", "mir", "sehr", "er\u00b7freu\u00b7lich", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADJD", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Und dein gedacht ich und deiner Tat,", "tokens": ["Und", "dein", "ge\u00b7dacht", "ich", "und", "dei\u00b7ner", "Tat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "VVPP", "PPER", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Odysseus, du r\u00e4nkevoller!", "tokens": ["O\u00b7dys\u00b7seus", ",", "du", "r\u00e4n\u00b7ke\u00b7vol\u00b7ler", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und meine beiden Zyklopen lie\u00df", "tokens": ["Und", "mei\u00b7ne", "bei\u00b7den", "Zyk\u00b7lo\u00b7pen", "lie\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ich saufen toller und toller.", "tokens": ["Ich", "sau\u00b7fen", "tol\u00b7ler", "und", "tol\u00b7ler", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "KON", "ADJA", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "Und lobte die deutsche Zentralgewalt", "tokens": ["Und", "lob\u00b7te", "die", "deut\u00b7sche", "Zent\u00b7ral\u00b7ge\u00b7walt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und Herrn Engels, den Stadtkommandanten,", "tokens": ["Und", "Herrn", "En\u00b7gels", ",", "den", "Stadt\u00b7kom\u00b7man\u00b7dan\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "NE", "$,", "ART", "NN", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Und sagte, Herr DuMont geh\u00f6re zu", "tokens": ["Und", "sag\u00b7te", ",", "Herr", "Du\u00b7Mont", "ge\u00b7h\u00f6\u00b7re", "zu"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "NN", "NE", "VVFIN", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Meinen allerbesten Bekannten.", "tokens": ["Mei\u00b7nen", "al\u00b7ler\u00b7bes\u00b7ten", "Be\u00b7kann\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.13": {"line.1": {"text": "Und pries Herrn Levy und Br\u00fcggemann", "tokens": ["Und", "pries", "Herrn", "Le\u00b7vy", "und", "Br\u00fcg\u00b7ge\u00b7mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "NN", "NE", "KON", "NN"], "meter": "-++-+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Und Herrn Wolffers und all die andern", "tokens": ["Und", "Herrn", "Wolf\u00b7fers", "und", "all", "die", "an\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "NE", "KON", "PIAT", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und schimpfte wie ein Rohrsperling", "tokens": ["Und", "schimpf\u00b7te", "wie", "ein", "Rohr\u00b7sper\u00b7ling"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf die Republikaner von Kandern.", "tokens": ["Auf", "die", "Re\u00b7pub\u00b7li\u00b7ka\u00b7ner", "von", "Kan\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.14": {"line.1": {"text": "Und sagte: es freue mich ungemein,", "tokens": ["Und", "sag\u00b7te", ":", "es", "freu\u00b7e", "mich", "un\u00b7ge\u00b7mein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+++-+-+", "measure": "zehnsilber"}, "line.2": {"text": "Da\u00df die Rheinische Zeitung erdr\u00fcckt sei", "tokens": ["Da\u00df", "die", "Rhei\u00b7ni\u00b7sche", "Zei\u00b7tung", "er\u00b7dr\u00fcckt", "sei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVPP", "VAFIN"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Und da\u00df der Putsch von Frankfurt und K\u00f6ln", "tokens": ["Und", "da\u00df", "der", "Putsch", "von", "Frank\u00b7furt", "und", "K\u00f6ln"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "APPR", "NE", "KON", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "So wunderherrlich mi\u00dfgl\u00fcckt sei.", "tokens": ["So", "wun\u00b7der\u00b7herr\u00b7lich", "mi\u00df\u00b7gl\u00fcckt", "sei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Und sagte: mein lieber Herr Vetter sitz", "tokens": ["Und", "sag\u00b7te", ":", "mein", "lie\u00b7ber", "Herr", "Vet\u00b7ter", "sitz"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$.", "PPOSAT", "ADJA", "NN", "NE", "NE"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Im Parlament auf der Rechten", "tokens": ["Im", "Par\u00b7la\u00b7ment", "auf", "der", "Rech\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und stimme mit Jahn und mit Radowitz,", "tokens": ["Und", "stim\u00b7me", "mit", "Jahn", "und", "mit", "Ra\u00b7do\u00b7witz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "APPR", "NE", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Des Volkes Heil zu erfechten.", "tokens": ["Des", "Vol\u00b7kes", "Heil", "zu", "er\u00b7fech\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "Und meinte: die Linke in Berlin", "tokens": ["Und", "mein\u00b7te", ":", "die", "Lin\u00b7ke", "in", "Ber\u00b7lin"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$.", "ART", "NN", "APPR", "NE"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Und in Frankfurt sei wert, da\u00df sie h\u00e4nge,", "tokens": ["Und", "in", "Frank\u00b7furt", "sei", "wert", ",", "da\u00df", "sie", "h\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "VAFIN", "ADJD", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "--+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und nahm das Glas und sang, da\u00df es klang,", "tokens": ["Und", "nahm", "das", "Glas", "und", "sang", ",", "da\u00df", "es", "klang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "KON", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ein Dutz' patriot'scher Ges\u00e4nge.", "tokens": ["Ein", "Dutz'", "pa\u00b7tri\u00b7ot'\u00b7scher", "Ge\u00b7s\u00e4n\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Und versicherte: K\u00f6ln befinde sich wohl", "tokens": ["Und", "ver\u00b7si\u00b7cher\u00b7te", ":", "K\u00f6ln", "be\u00b7fin\u00b7de", "sich", "wohl"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$.", "NE", "VVFIN", "PRF", "ADV"], "meter": "+-+--+-+--+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Bei seinem Belagerungszustand. \u2013", "tokens": ["Bei", "sei\u00b7nem", "Be\u00b7la\u00b7ge\u00b7rungs\u00b7zu\u00b7stand", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Da schwieg ich \u2013 \u2013 die beiden Zyklopen war'n", "tokens": ["Da", "schwieg", "ich", "\u2013", "\u2013", "die", "bei\u00b7den", "Zyk\u00b7lo\u00b7pen", "wa\u00b7r'n"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$(", "$(", "ART", "PIAT", "NN", "VVINF"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "In dem komfortabelsten Zustand.", "tokens": ["In", "dem", "kom\u00b7for\u00b7ta\u00b7bels\u00b7ten", "Zu\u00b7stand", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}}, "stanza.18": {"line.1": {"text": "Sie schnarchten, wie einst das Volk geschnarcht,", "tokens": ["Sie", "schnarch\u00b7ten", ",", "wie", "einst", "das", "Volk", "ge\u00b7schnarcht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das deutsche, und ihre Beine", "tokens": ["Das", "deut\u00b7sche", ",", "und", "ih\u00b7re", "Bei\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "$,", "KON", "PPOSAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und Arme, die starrten regungslos", "tokens": ["Und", "Ar\u00b7me", ",", "die", "starr\u00b7ten", "re\u00b7gungs\u00b7los"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "$,", "PRELS", "VVFIN", "ADJD"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von Schlaf und s\u00fc\u00dfem Weine.", "tokens": ["Von", "Schlaf", "und", "s\u00fc\u00b7\u00dfem", "Wei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}