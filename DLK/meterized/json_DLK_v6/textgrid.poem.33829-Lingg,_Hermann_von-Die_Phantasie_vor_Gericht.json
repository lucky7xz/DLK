{"textgrid.poem.33829": {"metadata": {"author": {"name": "Lingg, Hermann von", "birth": "N.A.", "death": "N.A."}, "title": "Die Phantasie vor Gericht", "genre": "verse", "period": "N.A.", "pub_year": 1862, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Schon lange war sie sehr verd\u00e4chtig,", "tokens": ["Schon", "lan\u00b7ge", "war", "sie", "sehr", "ver\u00b7d\u00e4ch\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Gekleidet ging sie wunderpr\u00e4chtig", "tokens": ["Ge\u00b7klei\u00b7det", "ging", "sie", "wun\u00b7der\u00b7pr\u00e4ch\u00b7tig"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und schweifte frei durch Wald und Flur;", "tokens": ["Und", "schweif\u00b7te", "frei", "durch", "Wald", "und", "Flur", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Man kam ihr endlich auf die Spur.", "tokens": ["Man", "kam", "ihr", "end\u00b7lich", "auf", "die", "Spur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie zogen aus mit Spie\u00df und Stangen,", "tokens": ["Sie", "zo\u00b7gen", "aus", "mit", "Spie\u00df", "und", "Stan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Als g\u00e4lt' es einen Wolf zu fangen.", "tokens": ["Als", "g\u00e4lt'", "es", "ei\u00b7nen", "Wolf", "zu", "fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "ART", "NE", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "\u00bbhalt!\u00ab schrien sie, \u00bbfreche Dirne du!\u00ab \u2013", "tokens": ["\u00bb", "halt", "!", "\u00ab", "schri\u00b7en", "sie", ",", "\u00bb", "fre\u00b7che", "Dir\u00b7ne", "du", "!", "\u00ab", "\u2013"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "VVFIN", "$.", "$(", "VVFIN", "PPER", "$,", "$(", "ADJA", "NN", "PPER", "$.", "$(", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Sie lachte nur dazu.", "tokens": ["Sie", "lach\u00b7te", "nur", "da\u00b7zu", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Sie lachte nicht mehr, als ihr Stricke", "tokens": ["Sie", "lach\u00b7te", "nicht", "mehr", ",", "als", "ihr", "Stri\u00b7cke"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Die Hand umschn\u00fcrt, in Weh zerschmolz", "tokens": ["Die", "Hand", "um\u00b7schn\u00fcrt", ",", "in", "Weh", "zer\u00b7schmolz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "$,", "APPR", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Ihr trotzig Wort, und nur im Blicke", "tokens": ["Ihr", "trot\u00b7zig", "Wort", ",", "und", "nur", "im", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADJD", "NN", "$,", "KON", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Lag noch ein unbesiegter Stolz.", "tokens": ["Lag", "noch", "ein", "un\u00b7be\u00b7sieg\u00b7ter", "Stolz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Gew\u00f6hnt, die Menschen zu beschenken,", "tokens": ["Ge\u00b7w\u00f6hnt", ",", "die", "Men\u00b7schen", "zu", "be\u00b7schen\u00b7ken", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Erscheint \u2013 unm\u00f6glich fast zu denken \u2013", "tokens": ["Er\u00b7scheint", "\u2013", "un\u00b7m\u00f6g\u00b7lich", "fast", "zu", "den\u00b7ken", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "ADJD", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Phantasie nun vor Gericht.", "tokens": ["Die", "Phan\u00b7ta\u00b7sie", "nun", "vor", "Ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu Tod bleich ist ihr Angesicht. \u2013", "tokens": ["Zu", "Tod", "bleich", "ist", "ihr", "An\u00b7ge\u00b7sicht", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "ADJD", "VAFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie, ganz Empfindung und Gedanke,", "tokens": ["Sie", ",", "ganz", "Emp\u00b7fin\u00b7dung", "und", "Ge\u00b7dan\u00b7ke", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Steht zwischen Schergen vor der Schranke,", "tokens": ["Steht", "zwi\u00b7schen", "Scher\u00b7gen", "vor", "der", "Schran\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Von allem Volke p\u00f6belhaft", "tokens": ["Von", "al\u00b7lem", "Vol\u00b7ke", "p\u00f6\u00b7bel\u00b7haft"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIS", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Beschn\u00fcffelt und begafft.", "tokens": ["Be\u00b7schn\u00fcf\u00b7felt", "und", "be\u00b7gafft", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Was kann der Strenge sie erwidern,", "tokens": ["Was", "kann", "der", "Stren\u00b7ge", "sie", "er\u00b7wi\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "So grausam innerst blo\u00dfgelegt?", "tokens": ["So", "grau\u00b7sam", "in\u00b7nerst", "blo\u00df\u00b7ge\u00b7legt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Seht, unter Messern zum Zergliedern,", "tokens": ["Seht", ",", "un\u00b7ter", "Mes\u00b7sern", "zum", "Zer\u00b7glie\u00b7dern", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "APPR", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Ein arm Gesch\u00f6pf, das sich noch regt! \u2013", "tokens": ["Ein", "arm", "Ge\u00b7sch\u00f6pf", ",", "das", "sich", "noch", "regt", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJD", "NN", "$,", "PRELS", "PRF", "ADV", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Und auf der Bank der \u00dcbelt\u00e4ter", "tokens": ["Und", "auf", "der", "Bank", "der", "\u00dc\u00b7belt\u00b7\u00e4\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Befragt: Wo sind Sie her? \u2013 Vom \u00c4ther,", "tokens": ["Be\u00b7fragt", ":", "Wo", "sind", "Sie", "her", "?", "\u2013", "Vom", "\u00c4\u00b7ther", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["VVPP", "$.", "PWAV", "VAFIN", "PPER", "PTKVZ", "$.", "$(", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Entgegnet sie. \u2013 Wie alt? \u2013 So alt,", "tokens": ["Ent\u00b7geg\u00b7net", "sie", ".", "\u2013", "Wie", "alt", "?", "\u2013", "So", "alt", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "$(", "PWAV", "ADJD", "$.", "$(", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie eure Welt. \u2013 Ihr Unterhalt? \u2013", "tokens": ["Wie", "eu\u00b7re", "Welt", ".", "\u2013", "Ihr", "Un\u00b7ter\u00b7halt", "?", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "$.", "$(", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich lebe von dem Duft der Blume,", "tokens": ["Ich", "le\u00b7be", "von", "dem", "Duft", "der", "Blu\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Vom reinen edlen Menschentume,", "tokens": ["Vom", "rei\u00b7nen", "ed\u00b7len", "Men\u00b7schen\u00b7tu\u00b7me", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ach dort, wohin mir nie bis jetzt", "tokens": ["Ach", "dort", ",", "wo\u00b7hin", "mir", "nie", "bis", "jetzt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "ADV", "$,", "PWAV", "PPER", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Verfolgung nachgesetzt. \u2013", "tokens": ["Ver\u00b7fol\u00b7gung", "nach\u00b7ge\u00b7setzt", ".", "\u2013"], "token_info": ["word", "word", "punct", "punct"], "pos": ["NN", "VVPP", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Bekennen Sie sich schuldig? \u2013 Schuldig?", "tokens": ["Be\u00b7ken\u00b7nen", "Sie", "sich", "schul\u00b7dig", "?", "\u2013", "Schul\u00b7dig", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["NN", "PPER", "PRF", "ADJD", "$.", "$(", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Was ist das? Nie h\u00f6rt' ich dies Wort. \u2013", "tokens": ["Was", "ist", "das", "?", "Nie", "h\u00f6rt'", "ich", "dies", "Wort", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VAFIN", "PDS", "$.", "ADV", "VVFIN", "PPER", "PDS", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Die Richter werden ungeduldig", "tokens": ["Die", "Rich\u00b7ter", "wer\u00b7den", "un\u00b7ge\u00b7dul\u00b7dig"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Und schreiten gleich zur Klage fort.", "tokens": ["Und", "schrei\u00b7ten", "gleich", "zur", "Kla\u00b7ge", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Sie haben Aufruhr angestiftet,", "tokens": ["Sie", "ha\u00b7ben", "Auf\u00b7ruhr", "an\u00b7ge\u00b7stif\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den ruhigen Verstand vergiftet,", "tokens": ["Den", "ru\u00b7hi\u00b7gen", "Ver\u00b7stand", "ver\u00b7gif\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Verbotnes Feuer angesch\u00fcrt,", "tokens": ["Ver\u00b7bot\u00b7nes", "Feu\u00b7er", "an\u00b7ge\u00b7sch\u00fcrt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verlockt, betrogen und verf\u00fchrt. \u2013", "tokens": ["Ver\u00b7lockt", ",", "be\u00b7tro\u00b7gen", "und", "ver\u00b7f\u00fchrt", ".", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "$,", "VVPP", "KON", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "O mehr noch, ruft sie; aber Richter", "tokens": ["O", "mehr", "noch", ",", "ruft", "sie", ";", "a\u00b7ber", "Rich\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NE", "ADV", "ADV", "$,", "VVFIN", "PPER", "$.", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Seid ", "tokens": ["Seid"], "token_info": ["word"], "pos": ["VAIMP"], "meter": "-", "measure": "single.down"}, "line.7": {"text": "Ist sie \u2013 wie hoch mit einemmal! \u2013", "tokens": ["Ist", "sie", "\u2013", "wie", "hoch", "mit", "ei\u00b7nem\u00b7mal", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "$(", "PWAV", "ADJD", "APPR", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Entschwunden aus dem Saal.", "tokens": ["Ent\u00b7schwun\u00b7den", "aus", "dem", "Saal", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Still wird es in dem dumpfen Pferche,", "tokens": ["Still", "wird", "es", "in", "dem", "dum\u00b7pfen", "Pfer\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Doch vor den Fenstergittern singt", "tokens": ["Doch", "vor", "den", "Fens\u00b7ter\u00b7git\u00b7tern", "singt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Im Freien eine Fr\u00fchlingslerche,", "tokens": ["Im", "Frei\u00b7en", "ei\u00b7ne", "Fr\u00fch\u00b7lings\u00b7ler\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Die jubelnd sich zum \u00c4ther schwingt.", "tokens": ["Die", "ju\u00b7belnd", "sich", "zum", "\u00c4\u00b7ther", "schwingt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PRF", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}