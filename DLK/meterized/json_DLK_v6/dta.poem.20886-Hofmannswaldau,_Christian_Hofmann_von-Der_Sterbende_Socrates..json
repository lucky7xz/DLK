{"dta.poem.20886": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Der  \n Sterbende  \n  Socrates.", "genre": "Lyrik; Prosa; Drama", "period": "N.A.", "pub_year": "1679", "urn": "urn:nbn:de:kobv:b4-20289-1", "language": ["de:0.99"], "booktitle": "Hofmann von Hofmannswaldau, Christian: Deutsche Ubersetzungen und Gedichte. Breslau, 1679."}, "poem": {"stanza.1": {"line.1": {"text": "Wann unser Fleisch in Jrre geht/", "tokens": ["Wann", "un\u00b7ser", "Fleisch", "in", "Jr\u00b7re", "geht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und auf der letzten Staffel steht/", "tokens": ["Und", "auf", "der", "letz\u00b7ten", "Staf\u00b7fel", "steht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die heisse Regung zu erf\u00fcllen;", "tokens": ["Die", "heis\u00b7se", "Re\u00b7gung", "zu", "er\u00b7f\u00fcl\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So trennt der Geist den falschen Wahn/", "tokens": ["So", "trennt", "der", "Geist", "den", "fal\u00b7schen", "Wahn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er ist bem\u00fcht die Lust zu stillen/", "tokens": ["Er", "ist", "be\u00b7m\u00fcht", "die", "Lust", "zu", "stil\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und weg zu thun/ was schaden kan.", "tokens": ["Und", "weg", "zu", "thun", "/", "was", "scha\u00b7den", "kan", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKZU", "VVINF", "$(", "PWS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Wann man von Hitz und Staub entz\u00fcndet/", "tokens": ["Wann", "man", "von", "Hitz", "und", "Staub", "ent\u00b7z\u00fcn\u00b7det", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPR", "NN", "KON", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Offt eine reine Qvelle findet/", "tokens": ["Offt", "ei\u00b7ne", "rei\u00b7ne", "Qvel\u00b7le", "fin\u00b7det", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So Hertz und Auge fr\u00f6lich macht/", "tokens": ["So", "Hertz", "und", "Au\u00b7ge", "fr\u00f6\u00b7lich", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So l\u00e4st die Furcht uns nicht bald eilen.", "tokens": ["So", "l\u00e4st", "die", "Furcht", "uns", "nicht", "bald", "ei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ein ieder Geist ist dann bedacht/", "tokens": ["Ein", "ie\u00b7der", "Geist", "ist", "dann", "be\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zuvor ein wenig zu verweilen.", "tokens": ["Zu\u00b7vor", "ein", "we\u00b7nig", "zu", "ver\u00b7wei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wann sich die Regung nicht wil d\u00e4mpffen/", "tokens": ["Wann", "sich", "die", "Re\u00b7gung", "nicht", "wil", "d\u00e4mpf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "PTKNEG", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So f\u00e4ngt die Seel auch anzuk\u00e4mpffen/", "tokens": ["So", "f\u00e4ngt", "die", "Seel", "auch", "an\u00b7zu\u00b7k\u00e4mpf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "VVIZU", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Allhier hilfft nicht das feste Band/", "tokens": ["All\u00b7hier", "hilfft", "nicht", "das", "fes\u00b7te", "Band", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKNEG", "ART", "ADJA", "NN", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "So Leib und Seele steiff verbindet/", "tokens": ["So", "Leib", "und", "See\u00b7le", "steiff", "ver\u00b7bin\u00b7det", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "VVFIN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "In dem die Lust und der Verstand", "tokens": ["In", "dem", "die", "Lust", "und", "der", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sich allezeit in Waffen findet.", "tokens": ["Sich", "al\u00b7le\u00b7zeit", "in", "Waf\u00b7fen", "fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}