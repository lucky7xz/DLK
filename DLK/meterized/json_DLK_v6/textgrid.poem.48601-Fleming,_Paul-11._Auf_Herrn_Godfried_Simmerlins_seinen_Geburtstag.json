{"textgrid.poem.48601": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "11. Auf Herrn Godfried Simmerlins seinen Geburtstag", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Werd' ich euch auch wieder gr\u00fc\u00dfen,", "tokens": ["Werd'", "ich", "euch", "auch", "wie\u00b7der", "gr\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ihr vor lieben B\u00fccher ihr,", "tokens": ["ihr", "vor", "lie\u00b7ben", "B\u00fc\u00b7cher", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADJA", "NN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und auf euch so sein beflissen,", "tokens": ["und", "auf", "euch", "so", "sein", "be\u00b7flis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "ADV", "PPOSAT", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aristotel und Porphyr,", "tokens": ["A\u00b7ris\u00b7to\u00b7tel", "und", "Por\u00b7phyr", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "als ich wol bevor gewesen,", "tokens": ["als", "ich", "wol", "be\u00b7vor", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKVZ", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "da ich \u00fcber eurem Lesen", "tokens": ["da", "ich", "\u00fc\u00b7ber", "eu\u00b7rem", "Le\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "manchen Tag und manche Nacht", "tokens": ["man\u00b7chen", "Tag", "und", "man\u00b7che", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "lustig habe durchgebracht?", "tokens": ["lus\u00b7tig", "ha\u00b7be", "durch\u00b7ge\u00b7bracht", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Und du zweier Kunst' Erfinder,", "tokens": ["Und", "du", "zwei\u00b7er", "Kunst'", "Er\u00b7fin\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "des Arznei und Saiten sind,", "tokens": ["des", "Arz\u00b7nei", "und", "Sai\u00b7ten", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VAFIN", "$,"], "meter": "-++-+-+", "measure": "unknown.measure.tetra"}, "line.3": {"text": "wo doch lass' ich deine Kinder,", "tokens": ["wo", "doch", "lass'", "ich", "dei\u00b7ne", "Kin\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "meine Br\u00fcder, so geschwind'?", "tokens": ["mei\u00b7ne", "Br\u00fc\u00b7der", ",", "so", "ge\u00b7schwind'", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "der mich sch\u00f6ne Sachen lehrte,", "tokens": ["der", "mich", "sch\u00f6\u00b7ne", "Sa\u00b7chen", "lehr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "flieh' ich itzt als meinen Feind.", "tokens": ["flieh'", "ich", "itzt", "als", "mei\u00b7nen", "Feind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "KOUS", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Auch die deutschen Kastalinnen,", "tokens": ["Auch", "die", "deut\u00b7schen", "Kas\u00b7ta\u00b7lin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "meine Zier und ander Preis,", "tokens": ["mei\u00b7ne", "Zier", "und", "an\u00b7der", "Preis", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "ADJD", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "sind ein Ekel meiner Sinnen.", "tokens": ["sind", "ein", "E\u00b7kel", "mei\u00b7ner", "Sin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Pegasis wird mir zu Eis.", "tokens": ["Pe\u00b7ga\u00b7sis", "wird", "mir", "zu", "Eis", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Hippokrene ist versogen,", "tokens": ["Hip\u00b7po\u00b7kre\u00b7ne", "ist", "ver\u00b7so\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "hat mir allen Saft entzogen.", "tokens": ["hat", "mir", "al\u00b7len", "Saft", "ent\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Was mir sonsten Sehnen war,", "tokens": ["Was", "mir", "sons\u00b7ten", "Seh\u00b7nen", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJA", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "ist mir itzt ein Grauen gar.", "tokens": ["ist", "mir", "itzt", "ein", "Grau\u00b7en", "gar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Nein! Ich kan nicht mehr so sitzen,", "tokens": ["Nein", "!", "Ich", "kan", "nicht", "mehr", "so", "sit\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PPER", "VMFIN", "PTKNEG", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "mich tun in den eiteln Bann", "tokens": ["mich", "tun", "in", "den", "ei\u00b7teln", "Bann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "und mit dem den Leib abn\u00fctzen,", "tokens": ["und", "mit", "dem", "den", "Leib", "ab\u00b7n\u00fct\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "das ihm doch nichts frommen kan.", "tokens": ["das", "ihm", "doch", "nichts", "from\u00b7men", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "PIS", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Soll ich fort und fort studiren", "tokens": ["Soll", "ich", "fort", "und", "fort", "stu\u00b7di\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PTKVZ", "KON", "PTKVZ", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "und ein blasses Leben f\u00fchren,", "tokens": ["und", "ein", "blas\u00b7ses", "Le\u00b7ben", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "da ich sterbe wie der Man,", "tokens": ["da", "ich", "ster\u00b7be", "wie", "der", "Man", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "KOKOM", "ART", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "der wie ich stirbt und nichts kan?", "tokens": ["der", "wie", "ich", "stirbt", "und", "nichts", "kan", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PWAV", "PPER", "VVFIN", "KON", "PIS", "VMFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.5": {"line.1": {"text": "Er indessen braucht der Freuden", "tokens": ["Er", "in\u00b7des\u00b7sen", "braucht", "der", "Freu\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und giebt seinen Wundsch darein.", "tokens": ["und", "giebt", "sei\u00b7nen", "Wund\u00b7sch", "da\u00b7rein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PAV", "$."], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wir nur sind so unbescheiden,", "tokens": ["Wir", "nur", "sind", "so", "un\u00b7be\u00b7schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "die wir weise wollen sein,", "tokens": ["die", "wir", "wei\u00b7se", "wol\u00b7len", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "VMFIN", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df wir da ein Ding erw\u00e4hlen,", "tokens": ["da\u00df", "wir", "da", "ein", "Ding", "er\u00b7w\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "das doch nur beschwert die Seelen,", "tokens": ["das", "doch", "nur", "be\u00b7schwert", "die", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "das nur ist ein blo\u00dfer Wahn,", "tokens": ["das", "nur", "ist", "ein", "blo\u00b7\u00dfer", "Wahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.8": {"text": "der uns so verz\u00e4ubern kan.", "tokens": ["der", "uns", "so", "ver\u00b7z\u00e4u\u00b7bern", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Soll ich mir solch Elend machen,", "tokens": ["Soll", "ich", "mir", "solch", "E\u00b7lend", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "mich ins Finstre sperren ein,", "tokens": ["mich", "ins", "Finst\u00b7re", "sper\u00b7ren", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "wenig schlafen, lange wachen,", "tokens": ["we\u00b7nig", "schla\u00b7fen", ",", "lan\u00b7ge", "wa\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVINF", "$,", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "halbsatt essen, durstig sein?", "tokens": ["hal\u00b7bsatt", "es\u00b7sen", ",", "durs\u00b7tig", "sein", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "$,", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "H\u00e4tt' ich Lust zu diesem Orden,", "tokens": ["H\u00e4tt'", "ich", "Lust", "zu", "die\u00b7sem", "Or\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "so w\u00e4r' ich ein M\u00f6nch l\u00e4ngst worden,", "tokens": ["so", "w\u00e4r'", "ich", "ein", "M\u00f6nch", "l\u00e4ngst", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "ADV", "VAPP", "$,"], "meter": "++--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "die, ob man sie gleich sperrt ein,", "tokens": ["die", ",", "ob", "man", "sie", "gleich", "sperrt", "ein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PIS", "PPER", "ADV", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "doch in ihrer Freiheit sein.", "tokens": ["doch", "in", "ih\u00b7rer", "Frei\u00b7heit", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Weg, ihr Klugen! Ich bin kl\u00fcger.", "tokens": ["Weg", ",", "ihr", "Klu\u00b7gen", "!", "Ich", "bin", "kl\u00fc\u00b7ger", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$.", "PPER", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Liberei, gehab dich wol!", "tokens": ["Li\u00b7be\u00b7rei", ",", "ge\u00b7hab", "dich", "wol", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Plato, du bist ein Betrieger!", "tokens": ["Pla\u00b7to", ",", "du", "bist", "ein", "Be\u00b7trie\u00b7ger", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ich wei\u00df, was ich wissen soll.", "tokens": ["Ich", "wei\u00df", ",", "was", "ich", "wis\u00b7sen", "soll", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Ich will in das Gr\u00fcne gehen,", "tokens": ["Ich", "will", "in", "das", "Gr\u00fc\u00b7ne", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "wo die dicksten Blumen stehen,", "tokens": ["wo", "die", "dicks\u00b7ten", "Blu\u00b7men", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "wo des Jahrs Apell, der Mai", "tokens": ["wo", "des", "Jahrs", "A\u00b7pell", ",", "der", "Mai"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "ART", "NN", "NE", "$,", "ART", "NN"], "meter": "+-+---+", "measure": "unknown.measure.tri"}, "line.8": {"text": "Alles malet mancherlei.", "tokens": ["Al\u00b7les", "ma\u00b7let", "man\u00b7cher\u00b7lei", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Meine Lust ist bei den B\u00e4chen", "tokens": ["Mei\u00b7ne", "Lust", "ist", "bei", "den", "B\u00e4\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "um manch stummes Wasserkind,", "tokens": ["um", "manch", "stum\u00b7mes", "Was\u00b7ser\u00b7kind", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "wo die tollen Fr\u00f6sche zechen", "tokens": ["wo", "die", "tol\u00b7len", "Fr\u00f6\u00b7sche", "ze\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und in stetem Jauchzen sind,", "tokens": ["und", "in", "ste\u00b7tem", "Jauch\u00b7zen", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "wo die freierischen Westen", "tokens": ["wo", "die", "frei\u00b7e\u00b7ri\u00b7schen", "Wes\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.6": {"text": "bulen mit den schwanken \u00c4sten", "tokens": ["bu\u00b7len", "mit", "den", "schwan\u00b7ken", "\u00c4s\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "und weh'n einen Hall darein,", "tokens": ["und", "weh'n", "ei\u00b7nen", "Hall", "da\u00b7rein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PAV", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "als es solten K\u00fcsse sein.", "tokens": ["als", "es", "sol\u00b7ten", "K\u00fcs\u00b7se", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Hier sind Auen, hier sind W\u00e4lder,", "tokens": ["Hier", "sind", "Au\u00b7en", ",", "hier", "sind", "W\u00e4l\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "$,", "ADV", "VAFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "hier sind Str\u00f6me, hier Fontein,", "tokens": ["hier", "sind", "Str\u00f6\u00b7me", ",", "hier", "Fon\u00b7tein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "$,", "ADV", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "hier sind dickbewachsne Felder", "tokens": ["hier", "sind", "dick\u00b7be\u00b7wachs\u00b7ne", "Fel\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und was tausent Freuden sein.", "tokens": ["und", "was", "tau\u00b7sent", "Freu\u00b7den", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hier sind Hirten, da sind Heerden,", "tokens": ["Hier", "sind", "Hir\u00b7ten", ",", "da", "sind", "Heer\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "$,", "ADV", "VAFIN", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "so auf weicher, feuchter Erden", "tokens": ["so", "auf", "wei\u00b7cher", ",", "feuch\u00b7ter", "Er\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "$,", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "nach dem Tone der Schalmei", "tokens": ["nach", "dem", "To\u00b7ne", "der", "Schal\u00b7mei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "springen in gew\u00fcndschter Rei'.", "tokens": ["sprin\u00b7gen", "in", "ge\u00b7w\u00fcnd\u00b7schter", "Rei'", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Und da werd' ich dich auch finden,", "tokens": ["Und", "da", "werd'", "ich", "dich", "auch", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PRF", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Freund, und eine dicke Schaar,", "tokens": ["Freund", ",", "und", "ei\u00b7ne", "di\u00b7cke", "Schaar", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "die dir bunte Kr\u00e4nze winden", "tokens": ["die", "dir", "bun\u00b7te", "Kr\u00e4n\u00b7ze", "win\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "in dein schwarzes, krauses Haar,", "tokens": ["in", "dein", "schwar\u00b7zes", ",", "krau\u00b7ses", "Haar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "die mit Blumen auf dich streiten", "tokens": ["die", "mit", "Blu\u00b7men", "auf", "dich", "strei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "APPR", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "und mit Gr\u00fcnem ganz bespreiten,", "tokens": ["und", "mit", "Gr\u00fc\u00b7nem", "ganz", "be\u00b7sprei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "die in einem Schreien schrein:", "tokens": ["die", "in", "ei\u00b7nem", "Schrei\u00b7en", "schrein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Freund, du solst gebunden sein!", "tokens": ["Freund", ",", "du", "solst", "ge\u00b7bun\u00b7den", "sein", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VMFIN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Ich, der Kleinest' unter Allen,", "tokens": ["Ich", ",", "der", "Klei\u00b7nest'", "un\u00b7ter", "Al\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "APPR", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "an Person, an Freundschaft nicht,", "tokens": ["an", "Per\u00b7son", ",", "an", "Freund\u00b7schaft", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "NN", "PTKNEG", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "will dir auch tun zu Gefallen,", "tokens": ["will", "dir", "auch", "tun", "zu", "Ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVINF", "APPR", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "was allda ein Ieder spricht.", "tokens": ["was", "all\u00b7da", "ein", "Ie\u00b7der", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Sei gebunden! Ich mu\u00df sorgen,", "tokens": ["Sei", "ge\u00b7bun\u00b7den", "!", "Ich", "mu\u00df", "sor\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$.", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "da\u00df, ie besser du dich morgen", "tokens": ["da\u00df", ",", "ie", "bes\u00b7ser", "du", "dich", "mor\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "$,", "ADV", "ADJD", "PPER", "PRF", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "l\u00f6sen wirst, ie mehr wirstu", "tokens": ["l\u00f6\u00b7sen", "wirst", ",", "ie", "mehr", "wirs\u00b7tu"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVINF", "VAFIN", "$,", "ADV", "ADV", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "diese Schlingen ziehen zu!", "tokens": ["die\u00b7se", "Schlin\u00b7gen", "zie\u00b7hen", "zu", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}