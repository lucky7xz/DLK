{"textgrid.poem.49816": {"metadata": {"author": {"name": "Sachs, Hans", "birth": "N.A.", "death": "N.A."}, "title": "1L: Als ich in meinem alter war", "genre": "verse", "period": "N.A.", "pub_year": 1557, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als ich in meinem alter war", "tokens": ["Als", "ich", "in", "mei\u00b7nem", "al\u00b7ter", "war"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "ADJA", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "gleich im zwei und sechzigsten jar,", "tokens": ["gleich", "im", "zwei", "und", "sech\u00b7zigs\u00b7ten", "jar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "CARD", "KON", "ADJA", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "da mich gar in mancherlei st\u00fccken", "tokens": ["da", "mich", "gar", "in", "man\u00b7cher\u00b7lei", "st\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PIS", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "das schwere alter hart was dr\u00fccken,", "tokens": ["das", "schwe\u00b7re", "al\u00b7ter", "hart", "was", "dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "ADJD", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "da dacht ich mit seufzender klag", "tokens": ["da", "dacht", "ich", "mit", "seuf\u00b7zen\u00b7der", "klag"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "an meiner jugent gute tag,", "tokens": ["an", "mei\u00b7ner", "ju\u00b7gent", "gu\u00b7te", "tag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "die ich so unn\u00fctz het verzert;", "tokens": ["die", "ich", "so", "un\u00b7n\u00fctz", "het", "ver\u00b7zert", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "ADV", "ADJD", "VAFIN", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.8": {"text": "das mir geleich mein schmerzen mert,", "tokens": ["das", "mir", "ge\u00b7leich", "mein", "schmer\u00b7zen", "mert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "PPOSAT", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "und warf mich im bet hin und her,", "tokens": ["und", "warf", "mich", "im", "bet", "hin", "und", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPRART", "VVFIN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "dacht: o das ein arzenei wer", "tokens": ["dacht", ":", "o", "das", "ein", "ar\u00b7ze\u00b7nei", "wer"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$.", "FM", "ART", "ART", "NN", "PWS"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "f\u00fcr das alter oder ein salben,", "tokens": ["f\u00fcr", "das", "al\u00b7ter", "o\u00b7der", "ein", "sal\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "KON", "ART", "VVINF", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.12": {"text": "wie wert w\u00fcrt sie sein allenthalben!", "tokens": ["wie", "wert", "w\u00fcrt", "sie", "sein", "al\u00b7len\u00b7thal\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "PPOSAT", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "in dem nachdenken ich gar tief", "tokens": ["in", "dem", "nach\u00b7den\u00b7ken", "ich", "gar", "tief"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "verwickelter sam halb entschlief.", "tokens": ["ver\u00b7wi\u00b7ckel\u00b7ter", "sam", "halb", "ent\u00b7schlief", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "mir traumt, wie ich kem wolbesunnen", "tokens": ["mir", "traumt", ",", "wie", "ich", "kem", "wol\u00b7be\u00b7sun\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "zu einem gro\u00dfen runden brunnen", "tokens": ["zu", "ei\u00b7nem", "gro\u00b7\u00dfen", "run\u00b7den", "brun\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "von merbelstein, polieret klar,", "tokens": ["von", "mer\u00b7bel\u00b7stein", ",", "po\u00b7lie\u00b7ret", "klar", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "$,", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "darein das wa\u00dfer rinnen war", "tokens": ["da\u00b7rein", "das", "wa\u00b7\u00dfer", "rin\u00b7nen", "war"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "ADJA", "VVINF", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "warm unde kalt wol aus zw\u00f6lf r\u00f6rn,", "tokens": ["warm", "un\u00b7de", "kalt", "wol", "aus", "zw\u00f6lf", "r\u00f6rn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "ADJD", "ADV", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "gleich eim wiltbad; tut wunder h\u00f6rn:", "tokens": ["gleich", "eim", "wilt\u00b7bad", ";", "tut", "wun\u00b7der", "h\u00f6rn", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$.", "VVFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "das wa\u00dfer het so gro\u00dfe kraft,", "tokens": ["das", "wa\u00b7\u00dfer", "het", "so", "gro\u00b7\u00dfe", "kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "welch mensch mit alter war behaft,", "tokens": ["welch", "mensch", "mit", "al\u00b7ter", "war", "be\u00b7haft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "APPR", "ADJA", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "ob er schon achtzigjerig was,", "tokens": ["ob", "er", "schon", "acht\u00b7zig\u00b7je\u00b7rig", "was", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "PWS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "wan er ein stunt im brunnen sa\u00df,", "tokens": ["wan", "er", "ein", "stunt", "im", "brun\u00b7nen", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.25": {"text": "so teten sich verj\u00fcngen wider", "tokens": ["so", "te\u00b7ten", "sich", "ver\u00b7j\u00fcn\u00b7gen", "wi\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "sein gm\u00fct, herz und alle gelider.", "tokens": ["sein", "gm\u00fct", ",", "herz", "und", "al\u00b7le", "ge\u00b7li\u00b7der", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NN", "KON", "PIAT", "NN", "$."], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.27": {"text": "umb den brunnen war ein gedreng,", "tokens": ["umb", "den", "brun\u00b7nen", "war", "ein", "ge\u00b7dreng", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "ART", "ADJD", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.28": {"text": "wan darzu kam ein gro\u00dfe meng,", "tokens": ["wan", "dar\u00b7zu", "kam", "ein", "gro\u00b7\u00dfe", "meng", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PAV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.29": {"text": "allerlei nation und gschlecht,", "tokens": ["al\u00b7ler\u00b7lei", "na\u00b7ti\u00b7on", "und", "gschlecht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.30": {"text": "m\u00f6nnich, pfaffen, ritter und knecht,", "tokens": ["m\u00f6n\u00b7nich", ",", "pfaf\u00b7fen", ",", "rit\u00b7ter", "und", "knecht", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "VVFIN", "$,", "ADJA", "KON", "VVFIN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.31": {"text": "burger, bauer und hantwerker,", "tokens": ["bur\u00b7ger", ",", "bau\u00b7er", "und", "hant\u00b7wer\u00b7ker", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "KON", "NN", "$,"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.32": {"text": "der kam on zal zum brunnen her", "tokens": ["der", "kam", "on", "zal", "zum", "brun\u00b7nen", "her"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "VVFIN", "APPR", "NE", "APPRART", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "und wolten sich verj\u00fcngen la\u00dfen.", "tokens": ["und", "wol\u00b7ten", "sich", "ver\u00b7j\u00fcn\u00b7gen", "la\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "vol zog es zu auf steig und stra\u00dfen", "tokens": ["vol", "zog", "es", "zu", "auf", "steig", "und", "stra\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "PTKZU", "APPR", "ADJD", "KON", "VVFIN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.35": {"text": "aus allen landen nah und ferren", "tokens": ["aus", "al\u00b7len", "lan\u00b7den", "nah", "und", "fer\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "ADJD", "KON", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.36": {"text": "auf senften, schlitten, wegn und kerren.", "tokens": ["auf", "senf\u00b7ten", ",", "schlit\u00b7ten", ",", "wegn", "und", "ker\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "VVFIN", "$,", "APPR", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.37": {"text": "ir vil man auf radwerben zug,", "tokens": ["ir", "vil", "man", "auf", "rad\u00b7wer\u00b7ben", "zug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PIS", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "etlich man auf mistberen trug,", "tokens": ["et\u00b7lich", "man", "auf", "mist\u00b7be\u00b7ren", "trug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PIS", "APPR", "ADJA", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.39": {"text": "und ir vil trug man auf dem rucken,", "tokens": ["und", "ir", "vil", "trug", "man", "auf", "dem", "ru\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "VVFIN", "PIS", "APPR", "ART", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.40": {"text": "etlich giengen herzu auf krucken.", "tokens": ["et\u00b7lich", "gien\u00b7gen", "her\u00b7zu", "auf", "kru\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ADV", "APPR", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.41": {"text": "zusamen kam ein hauf der alten,", "tokens": ["zu\u00b7sa\u00b7men", "kam", "ein", "hauf", "der", "al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.42": {"text": "wunderlich, entisch, ungestalten,", "tokens": ["wun\u00b7der\u00b7lich", ",", "en\u00b7tisch", ",", "un\u00b7ge\u00b7stal\u00b7ten", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "ADJA", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.43": {"text": "gerunzelt, zanlucket und kal,", "tokens": ["ge\u00b7run\u00b7zelt", ",", "zan\u00b7lu\u00b7cket", "und", "kal", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.44": {"text": "zittrent und kretzig \u00fcberal,", "tokens": ["zitt\u00b7rent", "und", "kret\u00b7zig", "\u00fc\u00b7be\u00b7ral", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.45": {"text": "dunkler augen und ungeh\u00f6ret,", "tokens": ["dunk\u00b7ler", "au\u00b7gen", "und", "un\u00b7ge\u00b7h\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJD", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.46": {"text": "verge\u00dfen, doppet und halb t\u00f6ret,", "tokens": ["ver\u00b7ge\u00b7\u00dfen", ",", "dop\u00b7pet", "und", "halb", "t\u00f6\u00b7ret", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "KON", "ADJD", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.47": {"text": "ganz mat, bleich, bogrucket und krum.", "tokens": ["ganz", "mat", ",", "bleich", ",", "bo\u00b7gru\u00b7cket", "und", "krum", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADJD", "$,", "VVFIN", "KON", "NE", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.48": {"text": "da war in summa summarum", "tokens": ["da", "war", "in", "sum\u00b7ma", "sum\u00b7ma\u00b7rum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.49": {"text": "ein husten, reuspern und ein kreisten,", "tokens": ["ein", "hus\u00b7ten", ",", "reus\u00b7pern", "und", "ein", "kreis\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "VVFIN", "KON", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.50": {"text": "ein echzen, seufzen und ein feisten,", "tokens": ["ein", "ech\u00b7zen", ",", "seuf\u00b7zen", "und", "ein", "feis\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "VVINF", "KON", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.51": {"text": "als obs in einem spital wer.", "tokens": ["als", "obs", "in", "ei\u00b7nem", "spi\u00b7tal", "wer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "APPR", "ART", "ADJD", "PWS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.52": {"text": "zw\u00f6lf man waren bestellet her,", "tokens": ["zw\u00f6lf", "man", "wa\u00b7ren", "be\u00b7stel\u00b7let", "her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "PIS", "VAFIN", "ADJD", "PTKVZ", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.53": {"text": "die allen alten, die sie funnen,", "tokens": ["die", "al\u00b7len", "al\u00b7ten", ",", "die", "sie", "fun\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.54": {"text": "solten helfen in den junkbrunnen;", "tokens": ["sol\u00b7ten", "hel\u00b7fen", "in", "den", "junk\u00b7brun\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "APPR", "ART", "ADJA", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.55": {"text": "die teten sich alle verj\u00fcngen:", "tokens": ["die", "te\u00b7ten", "sich", "al\u00b7le", "ver\u00b7j\u00fcn\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PRF", "PIS", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.56": {"text": "nach einer stunt mit freien spr\u00fcngen", "tokens": ["nach", "ei\u00b7ner", "stunt", "mit", "frei\u00b7en", "spr\u00fcn\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJD", "APPR", "ADJA", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.57": {"text": "sprangen sie aus dem brunnen runt,", "tokens": ["spran\u00b7gen", "sie", "aus", "dem", "brun\u00b7nen", "runt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.58": {"text": "sch\u00f6n, wolgefarb, frisch, jung und gsunt,", "tokens": ["sch\u00f6n", ",", "wol\u00b7ge\u00b7farb", ",", "frisch", ",", "jung", "und", "gsunt", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "$,", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.59": {"text": "ganz leichtsinnig und wol geberig,", "tokens": ["ganz", "leicht\u00b7sin\u00b7nig", "und", "wol", "ge\u00b7be\u00b7rig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "ADJD", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.60": {"text": "als ob sie weren zweinzigjerig.", "tokens": ["als", "ob", "sie", "we\u00b7ren", "zwein\u00b7zig\u00b7je\u00b7rig", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "PPER", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.61": {"text": "balt sich ein rot verj\u00fcnget fein,", "tokens": ["balt", "sich", "ein", "rot", "ver\u00b7j\u00fcn\u00b7get", "fein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "ART", "ADJD", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.62": {"text": "so steig darnach ein andre ein.", "tokens": ["so", "steig", "dar\u00b7nach", "ein", "and\u00b7re", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PAV", "ART", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.63": {"text": "da dacht ich mir im schlaf f\u00fcrwar!", "tokens": ["da", "dacht", "ich", "mir", "im", "schlaf", "f\u00fcr\u00b7war", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.64": {"text": "alt bist auch zwei und sechzig jar,", "tokens": ["alt", "bist", "auch", "zwei", "und", "sech\u00b7zig", "jar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ADV", "CARD", "KON", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.65": {"text": "dir get ab an gh\u00f6r und gesicht.", "tokens": ["dir", "get", "ab", "an", "gh\u00f6r", "und", "ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "APPR", "NE", "KON", "VVPP", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.66": {"text": "was zeichst du dich, das du auch nicht", "tokens": ["was", "zeichst", "du", "dich", ",", "das", "du", "auch", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "PRF", "$,", "PRELS", "PPER", "ADV", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.67": {"text": "wol halt in den junkbrunnen sitzest,", "tokens": ["wol", "halt", "in", "den", "junk\u00b7brun\u00b7nen", "sit\u00b7zest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "ADJA", "VVFIN", "$,"], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}, "line.68": {"text": "die alten haut auch von dir schwitzest?", "tokens": ["die", "al\u00b7ten", "haut", "auch", "von", "dir", "schwit\u00b7zest", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ADV", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.69": {"text": "abzoch ich alles mein gewant,", "tokens": ["ab\u00b7zoch", "ich", "al\u00b7les", "mein", "ge\u00b7want", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PIS", "PPOSAT", "VVPP", "$,"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.70": {"text": "daucht mich im schlaf alda zuhant,", "tokens": ["daucht", "mich", "im", "schlaf", "al\u00b7da", "zu\u00b7hant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.71": {"text": "ich stig in junkbrunnen, zu baden,", "tokens": ["ich", "stig", "in", "junk\u00b7brun\u00b7nen", ",", "zu", "ba\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "ADJA", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.72": {"text": "abzukommen des alters schaden.", "tokens": ["ab\u00b7zu\u00b7kom\u00b7men", "des", "al\u00b7ters", "scha\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIZU", "ART", "ADJA", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.73": {"text": "in dem einsteigen ich erwacht,", "tokens": ["in", "dem", "ein\u00b7stei\u00b7gen", "ich", "er\u00b7wacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.74": {"text": "meins verj\u00fcngens ich selber lacht,", "tokens": ["meins", "ver\u00b7j\u00fcn\u00b7gens", "ich", "sel\u00b7ber", "lacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.75": {"text": "dacht mir: ich mu\u00df nun bei mein tagen", "tokens": ["dacht", "mir", ":", "ich", "mu\u00df", "nun", "bei", "mein", "ta\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$.", "PPER", "VMFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.76": {"text": "die alten haut mein lebtag tragen,", "tokens": ["die", "al\u00b7ten", "haut", "mein", "leb\u00b7tag", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.77": {"text": "weil kein kraut auf ert ist gewachsen,", "tokens": ["weil", "kein", "kraut", "auf", "ert", "ist", "ge\u00b7wach\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ADJD", "APPR", "VVPP", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.78": {"text": "heut zu verj\u00fcngen mich, Hans Sachsen.", "tokens": ["heut", "zu", "ver\u00b7j\u00fcn\u00b7gen", "mich", ",", "Hans", "Sach\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "PPER", "$,", "NE", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}