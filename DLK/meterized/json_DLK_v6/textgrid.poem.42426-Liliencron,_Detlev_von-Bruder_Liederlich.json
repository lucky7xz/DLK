{"textgrid.poem.42426": {"metadata": {"author": {"name": "Liliencron, Detlev von", "birth": "N.A.", "death": "N.A."}, "title": "Bruder Liederlich", "genre": "verse", "period": "N.A.", "pub_year": 1876, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Feder am Sturmhut in Spiel und Gefahren", "tokens": ["Die", "Fe\u00b7der", "am", "Sturm\u00b7hut", "in", "Spiel", "und", "Ge\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Halli.", "tokens": ["Hal\u00b7li", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Nie lernt' ich im Leben zu fasten, zu sparen,", "tokens": ["Nie", "lernt'", "ich", "im", "Le\u00b7ben", "zu", "fas\u00b7ten", ",", "zu", "spa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN", "PTKZU", "VVINF", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "Hallo.", "tokens": ["Hal\u00b7lo", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Der Dirne lass' ich die Wege nicht frei,", "tokens": ["Der", "Dir\u00b7ne", "lass'", "ich", "die", "We\u00b7ge", "nicht", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Wo M\u00e4nner sich raufen, da bin ich dabei,", "tokens": ["Wo", "M\u00e4n\u00b7ner", "sich", "rau\u00b7fen", ",", "da", "bin", "ich", "da\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PRF", "VVFIN", "$,", "ADV", "VAFIN", "PPER", "PAV", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.7": {"text": "Und wo sie saufen, da sauf' ich f\u00fcr drei.", "tokens": ["Und", "wo", "sie", "sau\u00b7fen", ",", "da", "sauf'", "ich", "f\u00fcr", "drei", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "APPR", "CARD", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Halli und Hallo.", "tokens": ["Hal\u00b7li", "und", "Hal\u00b7lo", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.2": {"line.1": {"text": "Verdammt, es blieb mir ein M\u00e4dchen h\u00e4ngen,", "tokens": ["Ver\u00b7dammt", ",", "es", "blieb", "mir", "ein", "M\u00e4d\u00b7chen", "h\u00e4n\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PPER", "VVFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Halli.", "tokens": ["Hal\u00b7li", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Ich kann sie nur nicht aus dem Herzen zw\u00e4ngen,", "tokens": ["Ich", "kann", "sie", "nur", "nicht", "aus", "dem", "Her\u00b7zen", "zw\u00e4n\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Hallo.", "tokens": ["Hal\u00b7lo", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Ich glaube, sie war erst sechszehn Jahr,", "tokens": ["Ich", "glau\u00b7be", ",", "sie", "war", "erst", "sechs\u00b7zehn", "Jahr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ADV", "CARD", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Trug rote B\u00e4nder im schwarzem Haar,", "tokens": ["Trug", "ro\u00b7te", "B\u00e4n\u00b7der", "im", "schwar\u00b7zem", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Und plauderte wie der lustigste Staar.", "tokens": ["Und", "plau\u00b7der\u00b7te", "wie", "der", "lus\u00b7tigs\u00b7te", "Staar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Halli und Hallo.", "tokens": ["Hal\u00b7li", "und", "Hal\u00b7lo", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.3": {"line.1": {"text": "Was hatte das M\u00e4del zwei frische Backen,", "tokens": ["Was", "hat\u00b7te", "das", "M\u00e4\u00b7del", "zwei", "fri\u00b7sche", "Ba\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "CARD", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Halli.", "tokens": ["Hal\u00b7li", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Krach, konnten die Z\u00e4hne die Haselnu\u00df knacken,", "tokens": ["Krach", ",", "konn\u00b7ten", "die", "Z\u00e4h\u00b7ne", "die", "Ha\u00b7sel\u00b7nu\u00df", "kna\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VMFIN", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "Hallo.", "tokens": ["Hal\u00b7lo", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Sie hat mir das Zimmer mit Blumen geschm\u00fcckt,", "tokens": ["Sie", "hat", "mir", "das", "Zim\u00b7mer", "mit", "Blu\u00b7men", "ge\u00b7schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Die wir auf heimlichen Wegen gepfl\u00fcckt,", "tokens": ["Die", "wir", "auf", "heim\u00b7li\u00b7chen", "We\u00b7gen", "ge\u00b7pfl\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.7": {"text": "Wie hab' ich daf\u00fcr an's Herz sie gedr\u00fcckt.", "tokens": ["Wie", "hab'", "ich", "da\u00b7f\u00fcr", "an's", "Herz", "sie", "ge\u00b7dr\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PAV", "APPRART", "NN", "PPER", "VVPP", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Halli und Hallo.", "tokens": ["Hal\u00b7li", "und", "Hal\u00b7lo", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.4": {"line.1": {"text": "Ich schenkt' ihr ein Kleidchen von gelber Seiden,", "tokens": ["Ich", "schenkt'", "ihr", "ein", "Kleid\u00b7chen", "von", "gel\u00b7ber", "Sei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Halli.", "tokens": ["Hal\u00b7li", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Sie sagte, sie m\u00f6cht' mich uns\u00e4glich gern leiden,", "tokens": ["Sie", "sag\u00b7te", ",", "sie", "m\u00f6cht'", "mich", "un\u00b7s\u00e4g\u00b7lich", "gern", "lei\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "Hallo.", "tokens": ["Hal\u00b7lo", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Und als ich die Taschen ihr vollgesteckt", "tokens": ["Und", "als", "ich", "die", "Ta\u00b7schen", "ihr", "voll\u00b7ge\u00b7steckt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "PPER", "VVFIN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Mit Pralines, Feigen und feinem Confeckt,", "tokens": ["Mit", "Pra\u00b7li\u00b7nes", ",", "Fei\u00b7gen", "und", "fei\u00b7nem", "Con\u00b7feckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.7": {"text": "Da hat sie von Morgens bis Abends geschleckt.", "tokens": ["Da", "hat", "sie", "von", "Mor\u00b7gens", "bis", "A\u00b7bends", "ge\u00b7schleckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Halli und Hallo.", "tokens": ["Hal\u00b7li", "und", "Hal\u00b7lo", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.5": {"line.1": {"text": "Wir haben s\u00fcperb uns die Zeit vertrieben,", "tokens": ["Wir", "ha\u00b7ben", "s\u00fc\u00b7perb", "uns", "die", "Zeit", "ver\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Halli.", "tokens": ["Hal\u00b7li", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Ich wollte wir w\u00e4ren zusammen geblieben,", "tokens": ["Ich", "woll\u00b7te", "wir", "w\u00e4\u00b7ren", "zu\u00b7sam\u00b7men", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "Hallo.", "tokens": ["Hal\u00b7lo", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Doch wurde die Sache mir stark ennuyant,", "tokens": ["Doch", "wur\u00b7de", "die", "Sa\u00b7che", "mir", "stark", "en\u00b7nu\u00b7yant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Ich sagt' ihr, da\u00df mich die Regierung ernannt,", "tokens": ["Ich", "sagt'", "ihr", ",", "da\u00df", "mich", "die", "Re\u00b7gie\u00b7rung", "er\u00b7nannt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.7": {"text": "Kamele zu kaufen in Samarkand.", "tokens": ["Ka\u00b7me\u00b7le", "zu", "kau\u00b7fen", "in", "Sa\u00b7mar\u00b7kand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "APPR", "NE", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Halli und Hallo.", "tokens": ["Hal\u00b7li", "und", "Hal\u00b7lo", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.6": {"line.1": {"text": "Und als ich zum Abschied die Hand gab der Kleinen,", "tokens": ["Und", "als", "ich", "zum", "Ab\u00b7schied", "die", "Hand", "gab", "der", "Klei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPRART", "NN", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Halli,", "tokens": ["Hal\u00b7li", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Da fing sie bitterlich an zu weinen,", "tokens": ["Da", "fing", "sie", "bit\u00b7ter\u00b7lich", "an", "zu", "wei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hallo.", "tokens": ["Hal\u00b7lo", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Was denk' ich just heut ohn' Unterla\u00df,", "tokens": ["Was", "denk'", "ich", "just", "heut", "ohn'", "Un\u00b7ter\u00b7la\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ADV", "APPR", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Da\u00df ich ihr so rauh gab den Reisepa\u00df ...", "tokens": ["Da\u00df", "ich", "ihr", "so", "rauh", "gab", "den", "Rei\u00b7se\u00b7pa\u00df", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADJD", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Wein her, zum Henker, und da liegt Trumpf A\u00df.", "tokens": ["Wein", "her", ",", "zum", "Hen\u00b7ker", ",", "und", "da", "liegt", "Trumpf", "A\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "APPRART", "NN", "$,", "KON", "ADV", "VVFIN", "NN", "NE", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.8": {"text": "Halli und Hallo.", "tokens": ["Hal\u00b7li", "und", "Hal\u00b7lo", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}}}}