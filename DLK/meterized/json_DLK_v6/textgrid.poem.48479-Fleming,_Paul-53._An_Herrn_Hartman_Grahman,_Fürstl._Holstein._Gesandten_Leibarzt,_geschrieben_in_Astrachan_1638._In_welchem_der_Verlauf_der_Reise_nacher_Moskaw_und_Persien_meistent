{"textgrid.poem.48479": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "53. An Herrn Hartman Grahman, F\u00fcrstl. Holstein. Gesandten Leibarzt, geschrieben in Astrachan 1638. In welchem der Verlauf der Reise nacher Moskaw und Persien meistenteils angef\u00fcret wird", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gott, Bruder, und denn du, ihr beide habts getan,", "tokens": ["Gott", ",", "Bru\u00b7der", ",", "und", "denn", "du", ",", "ihr", "bei\u00b7de", "habts", "ge\u00b7tan", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "KON", "KON", "PPER", "$,", "PPER", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "da\u00df ich nun wieder wol zur\u00fccke ziehen kan.", "tokens": ["da\u00df", "ich", "nun", "wie\u00b7der", "wol", "zu\u00b7r\u00fc\u00b7cke", "zie\u00b7hen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADV", "VVFIN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Euch geb' ich allen Preis f\u00fcr meine ganze Habe,", "tokens": ["Euch", "geb'", "ich", "al\u00b7len", "Preis", "f\u00fcr", "mei\u00b7ne", "gan\u00b7ze", "Ha\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "f\u00fcr Leben, Gl\u00fcck und Stand. Euch brech' ich Palmen abe,", "tokens": ["f\u00fcr", "Le\u00b7ben", ",", "Gl\u00fcck", "und", "Stand", ".", "Euch", "brech'", "ich", "Pal\u00b7men", "a\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$.", "PPER", "VVFIN", "PPER", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "z\u00fcnd' \u00d6l und Weirauch an und sag' euch einen Dank,", "tokens": ["z\u00fcnd'", "\u00d6l", "und", "Wei\u00b7rauch", "an", "und", "sag'", "euch", "ei\u00b7nen", "Dank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "KON", "NN", "PTKVZ", "KON", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "der mit der alten Welt fast anf\u00e4ngt einen Zank,", "tokens": ["der", "mit", "der", "al\u00b7ten", "Welt", "fast", "an\u00b7f\u00e4ngt", "ei\u00b7nen", "Zank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "wil l\u00e4nger stehn als sie. Bis hieher bin ich wilde", "tokens": ["wil", "l\u00e4n\u00b7ger", "stehn", "als", "sie", ".", "Bis", "hie\u00b7her", "bin", "ich", "wil\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADJD", "VVINF", "KOKOM", "PPER", "$.", "APPR", "PAV", "VAFIN", "PPER", "ADJA"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.8": {"text": "zu klagen umb mein Leid. Hier wird mein Wehmut milde,", "tokens": ["zu", "kla\u00b7gen", "umb", "mein", "Leid", ".", "Hier", "wird", "mein", "Weh\u00b7mut", "mil\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "PPOSAT", "NN", "$.", "ADV", "VAFIN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "der mich fast durch hat bracht, mein Wehmut umb die Zeit,", "tokens": ["der", "mich", "fast", "durch", "hat", "bracht", ",", "mein", "Weh\u00b7mut", "umb", "die", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "APPR", "VAFIN", "VVFIN", "$,", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "die ich hier richte bin ganz ohne Nutzbarkeit.", "tokens": ["die", "ich", "hier", "rich\u00b7te", "bin", "ganz", "oh\u00b7ne", "Nutz\u00b7bar\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "ADV", "VVFIN", "VAFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Fort werd' ich Alles mir aus meinem Sinne schlagen.", "tokens": ["Fort", "werd'", "ich", "Al\u00b7les", "mir", "aus", "mei\u00b7nem", "Sin\u00b7ne", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "PIS", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich falle, wo ich mag, es mu\u00df mir doch behagen.", "tokens": ["Ich", "fal\u00b7le", ",", "wo", "ich", "mag", ",", "es", "mu\u00df", "mir", "doch", "be\u00b7ha\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "VMFIN", "$,", "PPER", "VMFIN", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Komm' ich denn da und da und dort nicht wieder hin,", "tokens": ["Komm'", "ich", "denn", "da", "und", "da", "und", "dort", "nicht", "wie\u00b7der", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "KON", "ADV", "KON", "ADV", "PTKNEG", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "so wei\u00df ich, da\u00df ich da vorhin gewesen bin.", "tokens": ["so", "wei\u00df", "ich", ",", "da\u00df", "ich", "da", "vor\u00b7hin", "ge\u00b7we\u00b7sen", "bin", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "ADV", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Weiser fraget nicht, wo, wie und wenn er stirbet.", "tokens": ["Ein", "Wei\u00b7ser", "fra\u00b7get", "nicht", ",", "wo", ",", "wie", "und", "wenn", "er", "stir\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "$,", "PWAV", "$,", "PWAV", "KON", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Er wei\u00df, da\u00df dieser Leib gleich \u00fcberall verdirbet.", "tokens": ["Er", "wei\u00df", ",", "da\u00df", "die\u00b7ser", "Leib", "gleich", "\u00fc\u00b7be\u00b7rall", "ver\u00b7dir\u00b7bet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PDAT", "NN", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein Tod, der ist es nur, der tausentf\u00e4ltig k\u00f6mt", "tokens": ["Ein", "Tod", ",", "der", "ist", "es", "nur", ",", "der", "tau\u00b7sent\u00b7f\u00e4l\u00b7tig", "k\u00f6mt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "VAFIN", "PPER", "ADV", "$,", "PRELS", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "und ihrer tausent wol auf tausent Arten nimt.", "tokens": ["und", "ih\u00b7rer", "tau\u00b7sent", "wol", "auf", "tau\u00b7sent", "Ar\u00b7ten", "nimt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "APPR", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So gilts ihm auch stets gleich; er h\u00e4lt sich allzeit fertig;", "tokens": ["So", "gilts", "ihm", "auch", "stets", "gleich", ";", "er", "h\u00e4lt", "sich", "all\u00b7zeit", "fer\u00b7tig", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ADV", "$.", "PPER", "VVFIN", "PRF", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "wird er gefordert auf, so steht er gegenw\u00e4rtig;", "tokens": ["wird", "er", "ge\u00b7for\u00b7dert", "auf", ",", "so", "steht", "er", "ge\u00b7gen\u00b7w\u00e4r\u00b7tig", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "wei\u00df, da\u00df so bald er hat zu leben hier erkiest,", "tokens": ["wei\u00df", ",", "da\u00df", "so", "bald", "er", "hat", "zu", "le\u00b7ben", "hier", "er\u00b7kiest", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ADV", "ADV", "PPER", "VAFIN", "PTKZU", "VVINF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "er auch schon alt genung zum Tode worden ist.", "tokens": ["er", "auch", "schon", "alt", "ge\u00b7nung", "zum", "To\u00b7de", "wor\u00b7den", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "ADJD", "ADV", "APPRART", "NN", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Kein graues Haar macht alt. Vom Geiste mu\u00df es kommen,", "tokens": ["Kein", "grau\u00b7es", "Haar", "macht", "alt", ".", "Vom", "Geis\u00b7te", "mu\u00df", "es", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "ADJD", "$.", "APPRART", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "das von der Weisheit wird f\u00fcr Alter angenommen;", "tokens": ["das", "von", "der", "Weis\u00b7heit", "wird", "f\u00fcr", "Al\u00b7ter", "an\u00b7ge\u00b7nom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "so grob hat keiner noch der Rechenkunst gefehlt,", "tokens": ["so", "grob", "hat", "kei\u00b7ner", "noch", "der", "Re\u00b7chen\u00b7kunst", "ge\u00b7fehlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "PIS", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "als der sein Alter nur von seinen Jahren z\u00e4lt.", "tokens": ["als", "der", "sein", "Al\u00b7ter", "nur", "von", "sei\u00b7nen", "Jah\u00b7ren", "z\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PPOSAT", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ich habe satt gelebt. Di\u00df bleibt mir ungestorben,", "tokens": ["Ich", "ha\u00b7be", "satt", "ge\u00b7lebt", ".", "Di\u00df", "bleibt", "mir", "un\u00b7ge\u00b7stor\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "VVPP", "$.", "PDS", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "was ich durch Flei\u00df und Schwei\u00df mir habe nun erworben,", "tokens": ["was", "ich", "durch", "Flei\u00df", "und", "Schwei\u00df", "mir", "ha\u00b7be", "nun", "er\u00b7wor\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "NN", "KON", "NN", "PPER", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "den Ruhm der Poesie, die ", "tokens": ["den", "Ruhm", "der", "Poe\u00b7sie", ",", "die"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "ART", "NN", "$,", "PRELS"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.20": {"text": "zu allerersten hat in Hochdeutsch aufgebracht.", "tokens": ["zu", "al\u00b7le\u00b7rers\u00b7ten", "hat", "in", "Hoch\u00b7deutsch", "auf\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ich schw\u00f6r' es, Vaterland, bei Kindespflicht und Treuen:", "tokens": ["Ich", "schw\u00f6r'", "es", ",", "Va\u00b7ter\u00b7land", ",", "bei", "Kin\u00b7des\u00b7pflicht", "und", "Treu\u00b7en", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "NN", "$,", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "dein Lob ists, welches mich hei\u00dft keine M\u00fche scheuen.", "tokens": ["dein", "Lob", "ists", ",", "wel\u00b7ches", "mich", "hei\u00dft", "kei\u00b7ne", "M\u00fc\u00b7he", "scheu\u00b7en", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "$,", "PRELS", "PPER", "VVFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Ich k\u00f6nte ja so wol, als etwan jener tut,", "tokens": ["Ich", "k\u00f6n\u00b7te", "ja", "so", "wol", ",", "als", "et\u00b7wan", "je\u00b7ner", "tut", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "ADV", "$,", "KOUS", "ADV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "auch umb die Ofenbank mir w\u00e4rmen Blut und Mut,", "tokens": ["auch", "umb", "die", "O\u00b7fen\u00b7bank", "mir", "w\u00e4r\u00b7men", "Blut", "und", "Mut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PPER", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "nach Wundsche stehn geehrt, mich meines Wesens wehren", "tokens": ["nach", "Wund\u00b7sche", "stehn", "ge\u00b7ehrt", ",", "mich", "mei\u00b7nes", "We\u00b7sens", "weh\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVINF", "VVPP", "$,", "PPER", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "und meiner Eltern Gut in stiller Lust verzehren,", "tokens": ["und", "mei\u00b7ner", "El\u00b7tern", "Gut", "in", "stil\u00b7ler", "Lust", "ver\u00b7zeh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADJD", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "wie schlecht und klein es ist. So hast dus auch nicht Not,", "tokens": ["wie", "schlecht", "und", "klein", "es", "ist", ".", "So", "hast", "dus", "auch", "nicht", "Not", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "KON", "ADJD", "PPER", "VAFIN", "$.", "ADV", "VAFIN", "NE", "ADV", "PTKNEG", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "da\u00df ich f\u00fcr Gott und dich mich lasse schlagen tot", "tokens": ["da\u00df", "ich", "f\u00fcr", "Gott", "und", "dich", "mich", "las\u00b7se", "schla\u00b7gen", "tot"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "KON", "PPER", "PPER", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "in einer tollen Schlacht. Ich habe nichts gelernet,", "tokens": ["in", "ei\u00b7ner", "tol\u00b7len", "Schlacht", ".", "Ich", "ha\u00b7be", "nichts", "ge\u00b7ler\u00b7net", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "PPER", "VAFIN", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "das gro\u00df von weitem sieht und nur alleine fernet,", "tokens": ["das", "gro\u00df", "von", "wei\u00b7tem", "sieht", "und", "nur", "al\u00b7lei\u00b7ne", "fer\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "PIS", "VVFIN", "KON", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "bin leichtem Scheine feind. Ich bin von Jugend her", "tokens": ["bin", "leich\u00b7tem", "Schei\u00b7ne", "feind", ".", "Ich", "bin", "von", "Ju\u00b7gend", "her"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADJA", "NN", "NN", "$.", "PPER", "VAFIN", "APPR", "NN", "APZR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "der Wissenschaften Freund, die ich nicht ohngefehr", "tokens": ["der", "Wis\u00b7sen\u00b7schaf\u00b7ten", "Freund", ",", "die", "ich", "nicht", "ohn\u00b7ge\u00b7fehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PPER", "PTKNEG", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "und obenhin nur wei\u00df. Apollo hie\u00df mich trinken", "tokens": ["und", "o\u00b7ben\u00b7hin", "nur", "wei\u00df", ".", "A\u00b7pol\u00b7lo", "hie\u00df", "mich", "trin\u00b7ken"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "VVFIN", "$.", "NE", "VVFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "aus seiner Kastalis. Sobald ich f\u00fchlte sinken", "tokens": ["aus", "sei\u00b7ner", "Kas\u00b7ta\u00b7lis", ".", "So\u00b7bald", "ich", "f\u00fchl\u00b7te", "sin\u00b7ken"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$.", "KOUS", "PPER", "VVFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "in mich den milden Rausch, der voll an N\u00fcchternheit", "tokens": ["in", "mich", "den", "mil\u00b7den", "Rausch", ",", "der", "voll", "an", "N\u00fcch\u00b7tern\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PRF", "ART", "ADJA", "NN", "$,", "PRELS", "ADJD", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "und satt an Hunger macht, der nach der Weisheit schreit,", "tokens": ["und", "satt", "an", "Hun\u00b7ger", "macht", ",", "der", "nach", "der", "Weis\u00b7heit", "schreit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "NN", "VVFIN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "da stank mir alle Lust, da ha\u00dft' ich alle Liebe,", "tokens": ["da", "stank", "mir", "al\u00b7le", "Lust", ",", "da", "ha\u00dft'", "ich", "al\u00b7le", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "$,", "ADV", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "die au\u00dferhalb der Kunst mich so an etwas triebe,", "tokens": ["die", "au\u00b7\u00dfer\u00b7halb", "der", "Kunst", "mich", "so", "an", "et\u00b7was", "trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "PPER", "ADV", "APPR", "PIS", "VVFIN", "$,"], "meter": "-+-+-+--++-+-", "measure": "iambic.hexa.relaxed"}, "line.39": {"text": "das gut scheint und nur scheint. Ich trug f\u00fcr manchen Sieg", "tokens": ["das", "gut", "scheint", "und", "nur", "scheint", ".", "Ich", "trug", "f\u00fcr", "man\u00b7chen", "Sieg"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADJD", "VVFIN", "KON", "ADV", "VVFIN", "$.", "PPER", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "schon manchen Lorberkranz. Als aber gleich der Krieg,", "tokens": ["schon", "man\u00b7chen", "Lor\u00b7ber\u00b7kranz", ".", "Als", "a\u00b7ber", "gleich", "der", "Krieg", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$.", "KOUS", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "erbarm' es Gott, der Krieg, mit welchem wir uns Deutschen", "tokens": ["er\u00b7barm'", "es", "Gott", ",", "der", "Krieg", ",", "mit", "wel\u00b7chem", "wir", "uns", "Deut\u00b7schen"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "NN", "$,", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "PRF", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "von so viel Jahren her nun ganz zu Tode peitschen,", "tokens": ["von", "so", "viel", "Jah\u00b7ren", "her", "nun", "ganz", "zu", "To\u00b7de", "peit\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "NN", "APZR", "ADV", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "mein ", "tokens": ["mein"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "-", "measure": "single.down"}, "line.44": {"text": "die niemand schelten kan und ich mir oft gesucht.", "tokens": ["die", "nie\u00b7mand", "schel\u00b7ten", "kan", "und", "ich", "mir", "oft", "ge\u00b7sucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVINF", "VMFIN", "KON", "PPER", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Ganz einem Vogel gleich, der fluck ist auszufliegen", "tokens": ["Ganz", "ei\u00b7nem", "Vo\u00b7gel", "gleich", ",", "der", "fluck", "ist", "aus\u00b7zu\u00b7flie\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ADV", "$,", "ART", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "und gleichwol noch nicht traut, schaut, wenn et Luft kan kriegen;", "tokens": ["und", "gleich\u00b7wol", "noch", "nicht", "traut", ",", "schaut", ",", "wenn", "et", "Luft", "kan", "krie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "PTKNEG", "VVFIN", "$,", "VVFIN", "$,", "KOUS", "NE", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "die Eltern, die sind aus, der Habicht ohngefehr", "tokens": ["die", "El\u00b7tern", ",", "die", "sind", "aus", ",", "der", "Ha\u00b7bicht", "ohn\u00b7ge\u00b7fehr"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "PTKVZ", "$,", "ART", "NN", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "setzt auf das blo\u00dfe Nest aus freien L\u00fcften her;", "tokens": ["setzt", "auf", "das", "blo\u00b7\u00dfe", "Nest", "aus", "frei\u00b7en", "L\u00fcf\u00b7ten", "her", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "die Not erweckt den Mut: er rei\u00dft sich aus den N\u00f6ten,", "tokens": ["die", "Not", "er\u00b7weckt", "den", "Mut", ":", "er", "rei\u00dft", "sich", "aus", "den", "N\u00f6\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$.", "PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "fleugt hier und da umbher und traut sich sichern St\u00e4ten.", "tokens": ["fleugt", "hier", "und", "da", "um\u00b7bher", "und", "traut", "sich", "si\u00b7chern", "St\u00e4\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "ADV", "ADJD", "KON", "VVFIN", "PRF", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Mein Bleiben war nicht mehr. Zudem war die\u00df mein Rat:", "tokens": ["Mein", "Blei\u00b7ben", "war", "nicht", "mehr", ".", "Zu\u00b7dem", "war", "die\u00df", "mein", "Rat", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKNEG", "ADV", "$.", "PAV", "VAFIN", "PDS", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.52": {"text": "was gilt bei uns ein Man, der nicht gereiset hat?", "tokens": ["was", "gilt", "bei", "uns", "ein", "Man", ",", "der", "nicht", "ge\u00b7rei\u00b7set", "hat", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "PPER", "ART", "PIS", "$,", "PRELS", "PTKNEG", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Ich gab mich in die Welt, da ich zur guten Stunde", "tokens": ["Ich", "gab", "mich", "in", "die", "Welt", ",", "da", "ich", "zur", "gu\u00b7ten", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "$,", "KOUS", "PPER", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "dich, Bruder, und mit dir ein gutes Mittel funde,", "tokens": ["dich", ",", "Bru\u00b7der", ",", "und", "mit", "dir", "ein", "gu\u00b7tes", "Mit\u00b7tel", "fun\u00b7de", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "$,", "KON", "APPR", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "in Aufgang einen Zug, auf den die ganze Welt", "tokens": ["in", "Auf\u00b7gang", "ei\u00b7nen", "Zug", ",", "auf", "den", "die", "gan\u00b7ze", "Welt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ART", "NN", "$,", "APPR", "ART", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "nun Aug' und Ohren hat. Der ", "tokens": ["nun", "Aug'", "und", "Oh\u00b7ren", "hat", ".", "Der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "NN", "KON", "NN", "VAFIN", "$.", "ART"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.57": {"text": "der Vorsicht werter Sohn, verschicket' Abgesandten", "tokens": ["der", "Vor\u00b7sicht", "wer\u00b7ter", "Sohn", ",", "ver\u00b7schi\u00b7cket'", "Ab\u00b7ge\u00b7sand\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "VVFIN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "in ", "tokens": ["in"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.59": {"text": "doch aber kanten nicht. Die trauten dir ihr Heil,", "tokens": ["doch", "a\u00b7ber", "kan\u00b7ten", "nicht", ".", "Die", "trau\u00b7ten", "dir", "ihr", "Heil", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PTKNEG", "$.", "ART", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "das du n\u00e4chst Gott erh\u00e4ltst, und lie\u00dfen mich ein Teil", "tokens": ["das", "du", "n\u00e4chst", "Gott", "er\u00b7h\u00e4ltst", ",", "und", "lie\u00b7\u00dfen", "mich", "ein", "Teil"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "VVFIN", "NN", "VVFIN", "$,", "KON", "VVFIN", "PRF", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "auch ihrer Sorgen sein. Wer priese dieses St\u00fccke", "tokens": ["auch", "ih\u00b7rer", "Sor\u00b7gen", "sein", ".", "Wer", "prie\u00b7se", "die\u00b7ses", "St\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "VAINF", "$.", "PWS", "VVFIN", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "zur selben Zeit an uns nicht vor ein sonders Gl\u00fccke?", "tokens": ["zur", "sel\u00b7ben", "Zeit", "an", "uns", "nicht", "vor", "ein", "son\u00b7ders", "Gl\u00fc\u00b7cke", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "PPER", "PTKNEG", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Wir schifften durch den Belt und brachten ", "tokens": ["Wir", "schiff\u00b7ten", "durch", "den", "Belt", "und", "brach\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "KON", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.64": {"text": "was unsers F\u00fcrsten Rat wolt' haben hier getan,", "tokens": ["was", "un\u00b7sers", "F\u00fcrs\u00b7ten", "Rat", "wolt'", "ha\u00b7ben", "hier", "ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "NN", "VMFIN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "das damals zwar nicht nein zu unsrer Sachen sagte,", "tokens": ["das", "da\u00b7mals", "zwar", "nicht", "nein", "zu", "uns\u00b7rer", "Sa\u00b7chen", "sag\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "PTKNEG", "PTKANT", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "doch, da\u00df es sich mit uns hier\u00fcber mehr betagte,", "tokens": ["doch", ",", "da\u00df", "es", "sich", "mit", "uns", "hier\u00b7\u00fc\u00b7ber", "mehr", "be\u00b7tag\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "PRF", "APPR", "PPER", "PAV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "ganz w\u00e4re mit uns eins, so wandten wir uns um", "tokens": ["ganz", "w\u00e4\u00b7re", "mit", "uns", "eins", ",", "so", "wand\u00b7ten", "wir", "uns", "um"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "PPER", "PIS", "$,", "ADV", "VVFIN", "PPER", "PRF", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "und holten \u00fcber di\u00df des Herzogs klare Stimm'", "tokens": ["und", "hol\u00b7ten", "\u00fc\u00b7ber", "di\u00df", "des", "Her\u00b7zogs", "kla\u00b7re", "Stimm'"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PDS", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "und seinen ganzen Sinn. Da w\u00e4r' es bald geschehen,", "tokens": ["und", "sei\u00b7nen", "gan\u00b7zen", "Sinn", ".", "Da", "w\u00e4r'", "es", "bald", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$.", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "da\u00df wir dich unter uns mehr h\u00e4tten nicht gesehen:", "tokens": ["da\u00df", "wir", "dich", "un\u00b7ter", "uns", "mehr", "h\u00e4t\u00b7ten", "nicht", "ge\u00b7se\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "PPER", "ADV", "VAFIN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "der gro\u00dfe ", "tokens": ["der", "gro\u00b7\u00dfe"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.72": {"text": "den dein Verh\u00e4ngn\u00fc\u00df doch zu der Zeit widerrief;", "tokens": ["den", "dein", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df", "doch", "zu", "der", "Zeit", "wi\u00b7der\u00b7rief", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.73": {"text": "es gunt' uns l\u00e4nger dich. Kamst derowegen wieder,", "tokens": ["es", "gunt'", "uns", "l\u00e4n\u00b7ger", "dich", ".", "Kamst", "de\u00b7ro\u00b7we\u00b7gen", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "PPER", "$.", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.74": {"text": "erf\u00fcllt mit Seelenangst, mit Furcht durch alle Glieder,", "tokens": ["er\u00b7f\u00fcllt", "mit", "See\u00b7len\u00b7angst", ",", "mit", "Furcht", "durch", "al\u00b7le", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "$,", "APPR", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "die dir die See gebar. Du kamst in ", "tokens": ["die", "dir", "die", "See", "ge\u00b7bar", ".", "Du", "kamst", "in"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPER", "ART", "NN", "ADJD", "$.", "PPER", "VVFIN", "APPR"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.76": {"text": "die nachmals dich und mich noch mehr verbunden hat.", "tokens": ["die", "nach\u00b7mals", "dich", "und", "mich", "noch", "mehr", "ver\u00b7bun\u00b7den", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KOUS", "PPER", "KON", "PPER", "ADV", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Wir lie\u00dfen ", "tokens": ["Wir", "lie\u00b7\u00dfen"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.78": {"text": "und \u00fcbergaben uns dem wolgeb\u00e4hnten Merzen.", "tokens": ["und", "\u00fc\u00b7berg\u00b7a\u00b7ben", "uns", "dem", "wol\u00b7ge\u00b7b\u00e4hn\u00b7ten", "Mer\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Wir flogen gleichsam fort und zogen gro\u00df und klein", "tokens": ["Wir", "flo\u00b7gen", "gleich\u00b7sam", "fort", "und", "zo\u00b7gen", "gro\u00df", "und", "klein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "KON", "VVFIN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "in Ru\u00dflands gr\u00f6\u00dfte Stadt noch selben Monat ein.", "tokens": ["in", "Ru\u00df\u00b7lands", "gr\u00f6\u00df\u00b7te", "Stadt", "noch", "sel\u00b7ben", "Mo\u00b7nat", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Ganz ", "tokens": ["Ganz"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.82": {"text": "Sein Zaar verh\u00f6rt' uns bald, gab sicheres Geleite", "tokens": ["Sein", "Zaar", "ver\u00b7h\u00f6rt'", "uns", "bald", ",", "gab", "si\u00b7che\u00b7res", "Ge\u00b7lei\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$,", "VVFIN", "ADJA", "NN"], "meter": "-+-+--+-++-+-", "measure": "iambic.hexa.relaxed"}, "line.83": {"text": "durch sein so langes Land und zeugte klar und frei,", "tokens": ["durch", "sein", "so", "lan\u00b7ges", "Land", "und", "zeug\u00b7te", "klar", "und", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADV", "ADJA", "NN", "KON", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "wie lieb ihm unser F\u00fcrst und dieser Handel sei.", "tokens": ["wie", "lieb", "ihm", "un\u00b7ser", "F\u00fcrst", "und", "die\u00b7ser", "Han\u00b7del", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "PPOSAT", "NN", "KON", "PDAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Wir schrieben gute Nacht ein ieder an die Seinen", "tokens": ["Wir", "schrie\u00b7ben", "gu\u00b7te", "Nacht", "ein", "ie\u00b7der", "an", "die", "Sei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "ART", "PIAT", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "und letzten uns vermischt mit Lachen und mit Weinen,", "tokens": ["und", "letz\u00b7ten", "uns", "ver\u00b7mischt", "mit", "La\u00b7chen", "und", "mit", "Wei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "PPER", "VVFIN", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "halb furchtsam und halb froh. Wir traten in das Kahn", "tokens": ["halb", "furcht\u00b7sam", "und", "halb", "froh", ".", "Wir", "tra\u00b7ten", "in", "das", "Kahn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "ADJD", "KON", "ADJD", "ADJD", "$.", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "und sungen ", "tokens": ["und", "sun\u00b7gen"], "token_info": ["word", "word"], "pos": ["KON", "VVINF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.89": {"text": "So schwummen wir dahin mit Nymphen ganz umbsprungen.", "tokens": ["So", "schwum\u00b7men", "wir", "da\u00b7hin", "mit", "Nym\u00b7phen", "ganz", "umbs\u00b7prun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PAV", "APPR", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Die klare ", "tokens": ["Die", "kla\u00b7re"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.91": {"text": "Die Schwester der Napeen, die ", "tokens": ["Die", "Schwes\u00b7ter", "der", "Na\u00b7peen", ",", "die"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "ART", "NN", "$,", "PRELS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.92": {"text": "sagt' uns der ", "tokens": ["sagt'", "uns", "der"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.93": {"text": "der k\u00fchne ", "tokens": ["der", "k\u00fch\u00b7ne"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.94": {"text": "das durch ganz Reu\u00dfen hoch und seltsam ward gepriesen,", "tokens": ["das", "durch", "ganz", "Reu\u00b7\u00dfen", "hoch", "und", "selt\u00b7sam", "ward", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ADV", "NN", "ADJD", "KON", "ADJD", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "uns ganz am Mute gleich, nahm uns mit Freuden auf", "tokens": ["uns", "ganz", "am", "Mu\u00b7te", "gleich", ",", "nahm", "uns", "mit", "Freu\u00b7den", "auf"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "APPRART", "NN", "ADV", "$,", "VVFIN", "PPER", "APPR", "NN", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "und wagte sich mit uns auf unsern weiten Lauf,", "tokens": ["und", "wag\u00b7te", "sich", "mit", "uns", "auf", "un\u00b7sern", "wei\u00b7ten", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PPER", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "der anfangs langsam fuhr, gehemmt von falschen Gr\u00fcnden.", "tokens": ["der", "an\u00b7fangs", "lang\u00b7sam", "fuhr", ",", "ge\u00b7hemmt", "von", "fal\u00b7schen", "Gr\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VVFIN", "$,", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "das laute ", "tokens": ["das", "lau\u00b7te"], "token_info": ["word", "word"], "pos": ["PDS", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.99": {"text": "Das edele ", "tokens": ["Das", "e\u00b7de\u00b7le"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+--", "measure": "dactylic.init"}, "line.100": {"text": "wolt', als wie auch ", "tokens": ["wolt'", ",", "als", "wie", "auch"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VMFIN", "$,", "KOUS", "KOKOM", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.101": {"text": "Samara tanzt' uns nach mit ihrem reinen Flusse.", "tokens": ["Sa\u00b7ma\u00b7ra", "tanzt'", "uns", "nach", "mit", "ih\u00b7rem", "rei\u00b7nen", "Flus\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "APPR", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "sah' uns von fernen zu. ", "tokens": ["sah'", "uns", "von", "fer\u00b7nen", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "PTKVZ", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.103": {"text": "das ", "tokens": ["das"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.104": {"text": "Der strenge ", "tokens": ["Der", "stren\u00b7ge"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.105": {"text": "lief umb die Ufer her nicht halb so wild und k\u00fchne,", "tokens": ["lief", "umb", "die", "U\u00b7fer", "her", "nicht", "halb", "so", "wild", "und", "k\u00fch\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "APZR", "PTKNEG", "ADJD", "ADV", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "warf Pfeil' und Bogen hin und neigte seine Brust.", "tokens": ["warf", "Pfeil'", "und", "Bo\u00b7gen", "hin", "und", "neig\u00b7te", "sei\u00b7ne", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "PTKVZ", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "So hatt' auch kein ", "tokens": ["So", "hatt'", "auch", "kein"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "PIAT"], "meter": "-+-+", "measure": "iambic.di"}, "line.108": {"text": "Wir kamen unversehrt an ", "tokens": ["Wir", "ka\u00b7men", "un\u00b7ver\u00b7sehrt", "an"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.109": {"text": "das, alsobald es uns mit treflichem Get\u00f6ne", "tokens": ["das", ",", "al\u00b7so\u00b7bald", "es", "uns", "mit", "tref\u00b7li\u00b7chem", "Ge\u00b7t\u00f6\u00b7ne"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "$,", "KOUS", "PPER", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "vor seinen Mauren h\u00f6rt', aus Haus und Toren lief", "tokens": ["vor", "sei\u00b7nen", "Mau\u00b7ren", "h\u00f6rt'", ",", "aus", "Haus", "und", "To\u00b7ren", "lief"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "APPR", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "und \u00fcberlaut \u00bbGl\u00fcck zu\u00ab in unsre Salven rief.", "tokens": ["und", "\u00fc\u00b7berl\u00b7aut", "\u00bb", "Gl\u00fcck", "zu", "\u00ab", "in", "uns\u00b7re", "Sal\u00b7ven", "rief", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$(", "NN", "PTKZU", "$(", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Der Flaggen hoher Flug, der Blitz der Falkenetten,", "tokens": ["Der", "Flag\u00b7gen", "ho\u00b7her", "Flug", ",", "der", "Blitz", "der", "Fal\u00b7ke\u00b7net\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "der St\u00fccken Donnerschlag, das Jauchzen der Trompetten,", "tokens": ["der", "St\u00fc\u00b7cken", "Don\u00b7ner\u00b7schlag", ",", "das", "Jauch\u00b7zen", "der", "Trom\u00b7pet\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "der Spiele voller L\u00e4rm vermengten Furcht und Lust,", "tokens": ["der", "Spie\u00b7le", "vol\u00b7ler", "L\u00e4rm", "ver\u00b7meng\u00b7ten", "Furcht", "und", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "so da\u00df man Scherz und Ernst fast nicht zu scheiden wust'.", "tokens": ["so", "da\u00df", "man", "Scherz", "und", "Ernst", "fast", "nicht", "zu", "schei\u00b7den", "wust'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "NN", "KON", "NE", "ADV", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "Der fl\u00fcchtige ", "tokens": ["Der", "fl\u00fcch\u00b7ti\u00b7ge"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-+", "measure": "iambic.di"}, "line.117": {"text": "erschrak und fiel zu Pferd' aus seinem Schilf und Horden,", "tokens": ["er\u00b7schrak", "und", "fiel", "zu", "Pferd'", "aus", "sei\u00b7nem", "Schilf", "und", "Hor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "APPR", "NN", "APPR", "PPOSAT", "NN", "KON", "NE", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "und, als er endlich sah' uns freundgesinnten Feind,", "tokens": ["und", ",", "als", "er", "end\u00b7lich", "sah'", "uns", "freund\u00b7ge\u00b7sinn\u00b7ten", "Feind", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADV", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.119": {"text": "erz\u00fcrnt' er, da\u00df es nicht zum Treffen war gemeint.", "tokens": ["er\u00b7z\u00fcrnt'", "er", ",", "da\u00df", "es", "nicht", "zum", "Tref\u00b7fen", "war", "ge\u00b7meint", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "PTKNEG", "APPRART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.120": {"text": "Von hieraus wiesen uns die Tartrischen Silenen,", "tokens": ["Von", "hier\u00b7aus", "wie\u00b7sen", "uns", "die", "Tar\u00b7tri\u00b7schen", "Si\u00b7le\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PAV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.121": {"text": "als welche Buhler sind der Kaspischen Sirenen,", "tokens": ["als", "wel\u00b7che", "Buh\u00b7ler", "sind", "der", "Kas\u00b7pi\u00b7schen", "Si\u00b7re\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.122": {"text": "in das ber\u00fchmte Meer. Sie, Amphitrite, stund,", "tokens": ["in", "das", "be\u00b7r\u00fchm\u00b7te", "Meer", ".", "Sie", ",", "Am\u00b7phit\u00b7ri\u00b7te", ",", "stund", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "PPER", "$,", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.123": {"text": "bot unserm ", "tokens": ["bot", "un\u00b7serm"], "token_info": ["word", "word"], "pos": ["VVFIN", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.124": {"text": "So bald di\u00df der ", "tokens": ["So", "bald", "di\u00df", "der"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "PDS", "ART"], "meter": "+-+-", "measure": "trochaic.di"}, "line.125": {"text": "da kam er Rasens voll recht an uns angeschwommen,", "tokens": ["da", "kam", "er", "Ra\u00b7sens", "voll", "recht", "an", "uns", "an\u00b7ge\u00b7schwom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "ADJD", "ADJD", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.126": {"text": "reizt' auf sein gr\u00fcnes Salz, ruft \u00c4oln aus der Kluft.", "tokens": ["reizt'", "auf", "sein", "gr\u00fc\u00b7nes", "Salz", ",", "ruft", "\u00c4\u00b7oln", "aus", "der", "Kluft", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,", "VVFIN", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.127": {"text": "Da stritten wider uns Grund, Wetter, See und Luft.", "tokens": ["Da", "strit\u00b7ten", "wi\u00b7der", "uns", "Grund", ",", "Wet\u00b7ter", ",", "See", "und", "Luft", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPER", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.128": {"text": "Wir flogen Himmel an und Hellen ab mit Schrecken;", "tokens": ["Wir", "flo\u00b7gen", "Him\u00b7mel", "an", "und", "Hel\u00b7len", "ab", "mit", "Schre\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PTKVZ", "KON", "NN", "PTKVZ", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.129": {"text": "die Seen kamen ganz das schwache Schiff zu decken", "tokens": ["die", "Seen", "ka\u00b7men", "ganz", "das", "schwa\u00b7che", "Schiff", "zu", "de\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "--+-+-+-+-+-", "measure": "anapaest.init"}, "line.130": {"text": "und spielten h\u00e4ufig ein. Die Schlupe, die gieng fort,", "tokens": ["und", "spiel\u00b7ten", "h\u00e4u\u00b7fig", "ein", ".", "Die", "Schlu\u00b7pe", ",", "die", "gieng", "fort", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PTKVZ", "$.", "ART", "NN", "$,", "PRELS", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.131": {"text": "das feste Rohr sprang ab, der Mast schlug \u00fcber Bord.", "tokens": ["das", "fes\u00b7te", "Rohr", "sprang", "ab", ",", "der", "Mast", "schlug", "\u00fc\u00b7ber", "Bord", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$,", "ART", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.132": {"text": "Der ungetreue Grund lie\u00df hier die Anker schlippen,", "tokens": ["Der", "un\u00b7ge\u00b7treu\u00b7e", "Grund", "lie\u00df", "hier", "die", "An\u00b7ker", "schlip\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.133": {"text": "von dort her schreckten uns, ", "tokens": ["von", "dort", "her", "schreck\u00b7ten", "uns", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APZR", "VVFIN", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.134": {"text": "Kein Helfen half uns mehr, wir st\u00fcrzten auf das Land.", "tokens": ["Kein", "Hel\u00b7fen", "half", "uns", "mehr", ",", "wir", "st\u00fcrz\u00b7ten", "auf", "das", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "ADV", "$,", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.135": {"text": "Da starb das edle Schiff an der ", "tokens": ["Da", "starb", "das", "ed\u00b7le", "Schiff", "an", "der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "ART"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.136": {"text": "am Sande ", "tokens": ["am", "San\u00b7de"], "token_info": ["word", "word"], "pos": ["APPRART", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.137": {"text": "mit welchen erstlich wir das Persien beschritten!", "tokens": ["mit", "wel\u00b7chen", "erst\u00b7lich", "wir", "das", "Per\u00b7si\u00b7en", "be\u00b7schrit\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "ADJD", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.138": {"text": "Die Ufer \u00fcber uns, der Furcht und Wunderns voll,", "tokens": ["Die", "U\u00b7fer", "\u00fc\u00b7ber", "uns", ",", "der", "Furcht", "und", "Wun\u00b7derns", "voll", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "$,", "ART", "NN", "KON", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.139": {"text": "empfiengen uns mit Trost und sprachen alles wol.", "tokens": ["emp\u00b7fi\u00b7en\u00b7gen", "uns", "mit", "Trost", "und", "spra\u00b7chen", "al\u00b7les", "wol", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "KON", "VVFIN", "PIS", "ADV", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.140": {"text": "die angenehme Lust der quellenden Najaden,", "tokens": ["die", "an\u00b7ge\u00b7neh\u00b7me", "Lust", "der", "quel\u00b7len\u00b7den", "Na\u00b7ja\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.141": {"text": "da Pan zu Feld und Tal und Berge ruft und pfeift", "tokens": ["da", "Pan", "zu", "Feld", "und", "Tal", "und", "Ber\u00b7ge", "ruft", "und", "pfeift"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "APPR", "NN", "KON", "NN", "KON", "NN", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.142": {"text": "und nach der Dryas hier, dort nach der Syrinx l\u00e4uft,", "tokens": ["und", "nach", "der", "Dryas", "hier", ",", "dort", "nach", "der", "Sy\u00b7rinx", "l\u00e4uft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "$,", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.143": {"text": "wie pr\u00e4chtig nahms uns an, wie blies es die Posaunen,", "tokens": ["wie", "pr\u00e4ch\u00b7tig", "nahms", "uns", "an", ",", "wie", "blies", "es", "die", "Po\u00b7sau\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "APPR", "PPER", "PTKVZ", "$,", "PWAV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.144": {"text": "wie sprungen umb uns her die bockgef\u00fc\u00dften Faunen,", "tokens": ["wie", "sprun\u00b7gen", "umb", "uns", "her", "die", "bock\u00b7ge\u00b7f\u00fc\u00df\u00b7ten", "Fau\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "APPR", "PRF", "APZR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.145": {"text": "da uns Ly\u00e4us selbst, der Herzog einer Schaar,", "tokens": ["da", "uns", "Ly\u00b7\u00e4us", "selbst", ",", "der", "Her\u00b7zog", "ei\u00b7ner", "Schaar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "ADV", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.146": {"text": "die umb die H\u00e4upter gr\u00fcn in vollem Winter war,", "tokens": ["die", "umb", "die", "H\u00e4up\u00b7ter", "gr\u00fcn", "in", "vol\u00b7lem", "Win\u00b7ter", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADJD", "APPR", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.147": {"text": "gar weit entgegenkam! Bei diesem Ebenteuer", "tokens": ["gar", "weit", "ent\u00b7ge\u00b7gen\u00b7kam", "!", "Bei", "die\u00b7sem", "E\u00b7ben\u00b7teu\u00b7er"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "$.", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.148": {"text": "war ganz der Tag voll Lust, die Nacht voll Freudenfeuer.", "tokens": ["war", "ganz", "der", "Tag", "voll", "Lust", ",", "die", "Nacht", "voll", "Freu\u00b7den\u00b7feu\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADJD", "NN", "$,", "ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.149": {"text": "Latona macht ihr Licht zum vierten Male voll,", "tokens": ["La\u00b7to\u00b7na", "macht", "ihr", "Licht", "zum", "vier\u00b7ten", "Ma\u00b7le", "voll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPOSAT", "NN", "APPRART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.150": {"text": "es deucht uns kurze Zeit; wir waren allzeit wol,", "tokens": ["es", "deucht", "uns", "kur\u00b7ze", "Zeit", ";", "wir", "wa\u00b7ren", "all\u00b7zeit", "wol", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJA", "NN", "$.", "PPER", "VAFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.151": {"text": "bald auf Dianens Jagd, bald bei Osiris Festen.", "tokens": ["bald", "auf", "Di\u00b7a\u00b7nens", "Jagd", ",", "bald", "bei", "O\u00b7si\u00b7ris", "Fes\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "NN", "$,", "ADV", "APPR", "NE", "NN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.152": {"text": "Itzt waren sie bei uns, itzt waren wir bei G\u00e4sten.", "tokens": ["Itzt", "wa\u00b7ren", "sie", "bei", "uns", ",", "itzt", "wa\u00b7ren", "wir", "bei", "G\u00e4s\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PPER", "$,", "ADV", "VAFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.153": {"text": "Nach diesem suchten wir das edel ", "tokens": ["Nach", "die\u00b7sem", "such\u00b7ten", "wir", "das", "e\u00b7del"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.154": {"text": "das unser ", "tokens": ["das", "un\u00b7ser"], "token_info": ["word", "word"], "pos": ["PDS", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.155": {"text": "an Heiligt\u00fcmern reich, erbaut in reichen Gr\u00fcnden,", "tokens": ["an", "Hei\u00b7lig\u00b7t\u00fc\u00b7mern", "reich", ",", "er\u00b7baut", "in", "rei\u00b7chen", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "$,", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.156": {"text": "an Gartenlust geziert, durchweht von vielen Winden,", "tokens": ["an", "Gar\u00b7ten\u00b7lust", "ge\u00b7ziert", ",", "durch\u00b7weht", "von", "vie\u00b7len", "Win\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.157": {"text": "das uns neun Wochen fast zu so viel Tagen macht'.", "tokens": ["das", "uns", "neun", "Wo\u00b7chen", "fast", "zu", "so", "viel", "Ta\u00b7gen", "macht'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "CARD", "NN", "ADV", "APPR", "ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.158": {"text": "In Einem aber uns wird ewig sein verdacht,", "tokens": ["In", "Ei\u00b7nem", "a\u00b7ber", "uns", "wird", "e\u00b7wig", "sein", "ver\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "ADV", "PPER", "VAFIN", "ADJD", "VAINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.159": {"text": "da\u00df, Bruder, dir dein Tod schon vor den Lippen lebte,", "tokens": ["da\u00df", ",", "Bru\u00b7der", ",", "dir", "dein", "Tod", "schon", "vor", "den", "Lip\u00b7pen", "leb\u00b7te", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "NN", "$,", "PPER", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.160": {"text": "und dein verhauchter Geist dir auf der Zungen schwebte", "tokens": ["und", "dein", "ver\u00b7hauch\u00b7ter", "Geist", "dir", "auf", "der", "Zun\u00b7gen", "schweb\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "PPER", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.161": {"text": "und wolte nun hindurch. Dein Gott und deine Kunst", "tokens": ["und", "wol\u00b7te", "nun", "hin\u00b7durch", ".", "Dein", "Gott", "und", "dei\u00b7ne", "Kunst"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADV", "PAV", "$.", "PPOSAT", "NN", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.162": {"text": "und unsre N\u00f6tigkeit entri\u00df dich dieser Brunst,", "tokens": ["und", "uns\u00b7re", "N\u00f6\u00b7tig\u00b7keit", "ent\u00b7ri\u00df", "dich", "die\u00b7ser", "Brunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.163": {"text": "die dich hier wieder kreischt. Gott aber sei gepriesen,", "tokens": ["die", "dich", "hier", "wie\u00b7der", "kreischt", ".", "Gott", "a\u00b7ber", "sei", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "VVFIN", "$.", "NN", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.164": {"text": "der sich auch di\u00dfmal uns so gn\u00e4dig hat erwiesen,", "tokens": ["der", "sich", "auch", "di\u00df\u00b7mal", "uns", "so", "gn\u00e4\u00b7dig", "hat", "er\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADV", "ADV", "PPER", "ADV", "ADJD", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.165": {"text": "dich dir und uns geschenkt! Und di\u00df beweist nun viel,", "tokens": ["dich", "dir", "und", "uns", "ge\u00b7schenkt", "!", "Und", "di\u00df", "be\u00b7weist", "nun", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "KON", "PPER", "VVPP", "$.", "KON", "PDS", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.166": {"text": "da\u00df er den Deinen dich ganz wieder geben will.", "tokens": ["da\u00df", "er", "den", "Dei\u00b7nen", "dich", "ganz", "wie\u00b7der", "ge\u00b7ben", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "PPOSAT", "PRF", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.167": {"text": "Von daraus stiegen wir hoch auf des ", "tokens": ["Von", "da\u00b7raus", "stie\u00b7gen", "wir", "hoch", "auf", "des"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PAV", "VVFIN", "PPER", "ADJD", "APPR", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.168": {"text": "wiewol begleitet nicht von unsern sch\u00f6nen St\u00fccken;", "tokens": ["wie\u00b7wol", "be\u00b7glei\u00b7tet", "nicht", "von", "un\u00b7sern", "sch\u00f6\u00b7nen", "St\u00fc\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKNEG", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.169": {"text": "hier ist kein Weg f\u00fcr sie. Da traf uns redlich ein,", "tokens": ["hier", "ist", "kein", "Weg", "f\u00fcr", "sie", ".", "Da", "traf", "uns", "red\u00b7lich", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "APPR", "PPER", "$.", "ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.170": {"text": "da\u00df h\u00f6chste Berge da, wo tiefste T\u00e4ler sein.", "tokens": ["da\u00df", "h\u00f6chs\u00b7te", "Ber\u00b7ge", "da", ",", "wo", "tiefs\u00b7te", "T\u00e4\u00b7ler", "sein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "PTKVZ", "$,", "PWAV", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.171": {"text": "Der strenge rote Strom scho\u00df zwischen seinen Kl\u00fcften", "tokens": ["Der", "stren\u00b7ge", "ro\u00b7te", "Strom", "scho\u00df", "zwi\u00b7schen", "sei\u00b7nen", "Kl\u00fcf\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.172": {"text": "hin, schnellen Pfeilen gleich und Blitzen in den L\u00fcften.", "tokens": ["hin", ",", "schnel\u00b7len", "Pfei\u00b7len", "gleich", "und", "Blit\u00b7zen", "in", "den", "L\u00fcf\u00b7ten", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "$,", "ADJA", "NN", "ADV", "KON", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.173": {"text": "Wir klommen Tag und Nacht die krummen Klippen an,", "tokens": ["Wir", "klom\u00b7men", "Tag", "und", "Nacht", "die", "krum\u00b7men", "Klip\u00b7pen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.174": {"text": "halb furchtsam und halb froh. Worauf uns denn", "tokens": ["halb", "furcht\u00b7sam", "und", "halb", "froh", ".", "Wo\u00b7rauf", "uns", "denn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "ADJD", "KON", "ADJD", "ADJD", "$.", "PAV", "PPER", "ADV"], "meter": "-+--++-+-+", "measure": "iambic.penta.relaxed"}, "line.175": {"text": "entgegen freundlich trug zur Labung seine Fr\u00fcchte.", "tokens": ["ent\u00b7ge\u00b7gen", "freund\u00b7lich", "trug", "zur", "La\u00b7bung", "sei\u00b7ne", "Fr\u00fcch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "VVFIN", "APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.176": {"text": "Bald trat uns ", "tokens": ["Bald", "trat", "uns"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.177": {"text": "das ebne Sultanie, das viel der ewgen Stadt", "tokens": ["das", "eb\u00b7ne", "Sul\u00b7ta\u00b7nie", ",", "das", "viel", "der", "ew\u00b7gen", "Stadt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.178": {"text": "an alter Trefflichkeit der B\u00e4ue gleiches hat.", "tokens": ["an", "al\u00b7ter", "Treff\u00b7lich\u00b7keit", "der", "B\u00e4u\u00b7e", "glei\u00b7ches", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "PIS", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.179": {"text": "Drauf sahen wir ", "tokens": ["Drauf", "sa\u00b7hen", "wir"], "token_info": ["word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.180": {"text": "in der der gro\u00df' ", "tokens": ["in", "der", "der", "gro\u00df'"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PRELS", "ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.181": {"text": "eh' denn er sein ", "tokens": ["eh'", "denn", "er", "sein"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "KON", "PPER", "PPOSAT"], "meter": "-+-+", "measure": "iambic.di"}, "line.182": {"text": "und mehr als er gehabt in seine Hand bekam;", "tokens": ["und", "mehr", "als", "er", "ge\u00b7habt", "in", "sei\u00b7ne", "Hand", "be\u00b7kam", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KOUS", "PPER", "VAPP", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.183": {"text": "das treffliche ", "tokens": ["das", "treff\u00b7li\u00b7che"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+--", "measure": "dactylic.init"}, "line.184": {"text": "umb welcher Berge man die sch\u00f6nsten Marmor brechen", "tokens": ["umb", "wel\u00b7cher", "Ber\u00b7ge", "man", "die", "sch\u00f6ns\u00b7ten", "Mar\u00b7mor", "bre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "NN", "PIS", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.185": {"text": "und weit verschicken sieht, die gro\u00dfe, reiche Stadt,", "tokens": ["und", "weit", "ver\u00b7schi\u00b7cken", "sieht", ",", "die", "gro\u00b7\u00dfe", ",", "rei\u00b7che", "Stadt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVINF", "VVFIN", "$,", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.186": {"text": "die Wein und Brot und Gold und Lust die F\u00fclle hat.", "tokens": ["die", "Wein", "und", "Brot", "und", "Gold", "und", "Lust", "die", "F\u00fcl\u00b7le", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "KON", "NN", "KON", "NN", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.187": {"text": "Hier sahn wir Indien uns selbst entgegen rennen;", "tokens": ["Hier", "sahn", "wir", "In\u00b7di\u00b7en", "uns", "selbst", "ent\u00b7ge\u00b7gen", "ren\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "PPER", "ADV", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.188": {"text": "Cythera sung uns ein, lie\u00df Schauspiel' uns ernennen,", "tokens": ["Cy\u00b7the\u00b7ra", "sung", "uns", "ein", ",", "lie\u00df", "Schau\u00b7spiel'", "uns", "er\u00b7nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PPER", "PTKVZ", "$,", "VVFIN", "NN", "PPER", "VVINF", "$,"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.189": {"text": "trug K\u00f6nigswasser auf; und weil wir waren schwach,", "tokens": ["trug", "K\u00f6\u00b7nigs\u00b7was\u00b7ser", "auf", ";", "und", "weil", "wir", "wa\u00b7ren", "schwach", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PTKVZ", "$.", "KON", "KOUS", "PPER", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.190": {"text": "so wars ihr Lust mit uns zu haben Ungemach.", "tokens": ["so", "wars", "ihr", "Lust", "mit", "uns", "zu", "ha\u00b7ben", "Un\u00b7ge\u00b7mach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "APPR", "PPER", "PTKZU", "VAINF", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.191": {"text": "darmit dein Bachus kan der Vorsicht Sinn berauben,", "tokens": ["dar\u00b7mit", "dein", "Ba\u00b7chus", "kan", "der", "Vor\u00b7sicht", "Sinn", "be\u00b7rau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "NE", "VMFIN", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.192": {"text": "die mich verf\u00fchrten auch? Und Kom, wo la\u00df ich dich,", "tokens": ["die", "mich", "ver\u00b7f\u00fchr\u00b7ten", "auch", "?", "Und", "Kom", ",", "wo", "la\u00df", "ich", "dich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "ADV", "$.", "KON", "VVFIN", "$,", "PWAV", "VVIMP", "PPER", "PRF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.193": {"text": "allda ich selbsten bald gelassen h\u00e4tte mich,", "tokens": ["all\u00b7da", "ich", "selbs\u00b7ten", "bald", "ge\u00b7las\u00b7sen", "h\u00e4t\u00b7te", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVPP", "VAFIN", "PPER", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.194": {"text": "schon jenem auf der Spur? Auch, Bruder, dir zu Danke", "tokens": ["schon", "je\u00b7nem", "auf", "der", "Spur", "?", "Auch", ",", "Bru\u00b7der", ",", "dir", "zu", "Dan\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PDAT", "APPR", "ART", "NN", "$.", "ADV", "$,", "NN", "$,", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.195": {"text": "erw\u00e4hn' ich dieses hier. Hier stunden fast im Zanke", "tokens": ["er\u00b7w\u00e4hn'", "ich", "die\u00b7ses", "hier", ".", "Hier", "stun\u00b7den", "fast", "im", "Zan\u00b7ke"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PDS", "ADV", "$.", "ADV", "VVFIN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.196": {"text": "die G\u00f6tter \u00fcber uns, ob auch der M\u00fcglichkeit", "tokens": ["die", "G\u00f6t\u00b7ter", "\u00fc\u00b7ber", "uns", ",", "ob", "auch", "der", "M\u00fcg\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPER", "$,", "KOUS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.197": {"text": "wol k\u00f6nte m\u00fcglich sein uns alle selbter Zeit", "tokens": ["wol", "k\u00f6n\u00b7te", "m\u00fcg\u00b7lich", "sein", "uns", "al\u00b7le", "selb\u00b7ter", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADJD", "VAINF", "PPER", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.198": {"text": "zu f\u00fchren weiter fort. Der hei\u00dfe Hundsstern brante,", "tokens": ["zu", "f\u00fch\u00b7ren", "wei\u00b7ter", "fort", ".", "Der", "hei\u00b7\u00dfe", "Hunds\u00b7stern", "bran\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ADV", "PTKVZ", "$.", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.199": {"text": "als Titan durch das Haus des starken L\u00f6wens rante.", "tokens": ["als", "Ti\u00b7tan", "durch", "das", "Haus", "des", "star\u00b7ken", "L\u00f6\u00b7wens", "ran\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.200": {"text": "Die wilde Glut schlug aus, sie schlug in unser Blut,", "tokens": ["Die", "wil\u00b7de", "Glut", "schlug", "aus", ",", "sie", "schlug", "in", "un\u00b7ser", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$,", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.201": {"text": "es war umb einen Schlag, da lag uns Blut und Mut.", "tokens": ["es", "war", "umb", "ei\u00b7nen", "Schlag", ",", "da", "lag", "uns", "Blut", "und", "Mut", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.202": {"text": "Die H\u00e4upter waren krank, die Glieder schwach und m\u00fcde.", "tokens": ["Die", "H\u00e4up\u00b7ter", "wa\u00b7ren", "krank", ",", "die", "Glie\u00b7der", "schwach", "und", "m\u00fc\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.203": {"text": "Auch du, o aller Arzt, inmitten Krieg und Friede,", "tokens": ["Auch", "du", ",", "o", "al\u00b7ler", "Arzt", ",", "in\u00b7mit\u00b7ten", "Krieg", "und", "Frie\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "FM", "PIAT", "NN", "$,", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.204": {"text": "inmitten Furcht und Trost, verga\u00dfest fast dein Tun,", "tokens": ["in\u00b7mit\u00b7ten", "Furcht", "und", "Trost", ",", "ver\u00b7ga\u00b7\u00dfest", "fast", "dein", "Tun", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.205": {"text": "erfuhrest, was es hei\u00dft: Arzt, hilf dir selbsten nun!", "tokens": ["er\u00b7fuh\u00b7rest", ",", "was", "es", "hei\u00dft", ":", "Arzt", ",", "hilf", "dir", "selbs\u00b7ten", "nun", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWS", "PPER", "VVFIN", "$.", "NN", "$,", "VVIMP", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.206": {"text": "Wir mu\u00dften gleichwol fort, wir lie\u00dfen ", "tokens": ["Wir", "mu\u00df\u00b7ten", "gleich\u00b7wol", "fort", ",", "wir", "lie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "PTKVZ", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.207": {"text": "sein Sandfeld ausgeschwemt und seine sch\u00f6ne Br\u00fccke", "tokens": ["sein", "Sand\u00b7feld", "aus\u00b7ge\u00b7schwemt", "und", "sei\u00b7ne", "sch\u00f6\u00b7ne", "Br\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVPP", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.208": {"text": "und seinen Wunderberg. Wir kehrten Tag in Nacht", "tokens": ["und", "sei\u00b7nen", "Wun\u00b7der\u00b7berg", ".", "Wir", "kehr\u00b7ten", "Tag", "in", "Nacht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "$.", "PPER", "VVFIN", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.209": {"text": "und wieder Nacht in Tag. Du, eine halbe Tracht", "tokens": ["und", "wie\u00b7der", "Nacht", "in", "Tag", ".", "Du", ",", "ei\u00b7ne", "hal\u00b7be", "Tracht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "NN", "APPR", "NN", "$.", "PPER", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.210": {"text": "des lastbaren Kamels, hast damals satt empfunden,", "tokens": ["des", "last\u00b7ba\u00b7ren", "Ka\u00b7mels", ",", "hast", "da\u00b7mals", "satt", "emp\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "VAFIN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.211": {"text": "wie wol euch Kranken war, wie \u00fcbel uns Gesunden.", "tokens": ["wie", "wol", "euch", "Kran\u00b7ken", "war", ",", "wie", "\u00fc\u00b7bel", "uns", "Ge\u00b7sun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "NN", "VAFIN", "$,", "PWAV", "ADJD", "PPER", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.212": {"text": "die zwar viel Gift gebiert, doch auch viel Goldes zeugt.", "tokens": ["die", "zwar", "viel", "Gift", "ge\u00b7biert", ",", "doch", "auch", "viel", "Gol\u00b7des", "zeugt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "NN", "VVPP", "$,", "ADV", "ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.213": {"text": "Das bergichte ", "tokens": ["Das", "ber\u00b7gich\u00b7te"], "token_info": ["word", "word"], "pos": ["PDS", "VVFIN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.214": {"text": "der Sperber obgesiegt, allda noch seine Zier", "tokens": ["der", "Sper\u00b7ber", "ob\u00b7ge\u00b7siegt", ",", "all\u00b7da", "noch", "sei\u00b7ne", "Zier"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "$,", "KOUS", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.215": {"text": "und deine Schande steht, lie\u00df seine B\u00e4che gehen", "tokens": ["und", "dei\u00b7ne", "Schan\u00b7de", "steht", ",", "lie\u00df", "sei\u00b7ne", "B\u00e4\u00b7che", "ge\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.216": {"text": "und die gek\u00fchlte Luft verst\u00e4rkter auf uns wehen.", "tokens": ["und", "die", "ge\u00b7k\u00fchl\u00b7te", "Luft", "ver\u00b7st\u00e4rk\u00b7ter", "auf", "uns", "we\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.217": {"text": "Das Ziel war nun vor uns, der Berg, der war erstiegen,", "tokens": ["Das", "Ziel", "war", "nun", "vor", "uns", ",", "der", "Berg", ",", "der", "war", "er\u00b7stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "PPER", "$,", "ART", "NN", "$,", "PRELS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.218": {"text": "wir sahen ", "tokens": ["wir", "sa\u00b7hen"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.219": {"text": "die k\u00f6nigliche die, die, wie man mir bringt ein,", "tokens": ["die", "k\u00f6\u00b7nig\u00b7li\u00b7che", "die", ",", "die", ",", "wie", "man", "mir", "bringt", "ein", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ART", "$,", "PRELS", "$,", "PWAV", "PIS", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.220": {"text": "von hundert Pforten soll genennet worden sein.", "tokens": ["von", "hun\u00b7dert", "Pfor\u00b7ten", "soll", "ge\u00b7nen\u00b7net", "wor\u00b7den", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VMFIN", "VVPP", "VAPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.221": {"text": "Was aber tr\u00e4gt sich zu? Wir waren kaum empfangen,", "tokens": ["Was", "a\u00b7ber", "tr\u00e4gt", "sich", "zu", "?", "Wir", "wa\u00b7ren", "kaum", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "PRF", "PTKVZ", "$.", "PPER", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.222": {"text": "kaum von den Pferden ab in unser' Zimmer gangen,", "tokens": ["kaum", "von", "den", "Pfer\u00b7den", "ab", "in", "un\u00b7ser'", "Zim\u00b7mer", "gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKVZ", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.223": {"text": "als der ", "tokens": ["als", "der"], "token_info": ["word", "word"], "pos": ["KOUS", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.224": {"text": "uns alle sich verschwur auf eins zu bringen \u00fcm.", "tokens": ["uns", "al\u00b7le", "sich", "ver\u00b7schwur", "auf", "eins", "zu", "brin\u00b7gen", "\u00fcm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "PRF", "VVFIN", "APPR", "PIS", "PTKZU", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.225": {"text": "Der Sturm stie\u00df auf das Haus, in welchem wir verschlossen", "tokens": ["Der", "Sturm", "stie\u00df", "auf", "das", "Haus", ",", "in", "wel\u00b7chem", "wir", "ver\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.226": {"text": "mit voller Raserei stets auf einander schossen.", "tokens": ["mit", "vol\u00b7ler", "Ra\u00b7se\u00b7rei", "stets", "auf", "ein\u00b7an\u00b7der", "schos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.227": {"text": "Uns drungen Mord und Raub, und war die h\u00f6chste Zeit,", "tokens": ["Uns", "drun\u00b7gen", "Mord", "und", "Raub", ",", "und", "war", "die", "h\u00f6chs\u00b7te", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "KON", "NN", "$,", "KON", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.228": {"text": "da\u00df durch des K\u00f6nigs Hand zerrissen ward der Streit.", "tokens": ["da\u00df", "durch", "des", "K\u00f6\u00b7nigs", "Hand", "zer\u00b7ris\u00b7sen", "ward", "der", "Streit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "NN", "VVPP", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.229": {"text": "Nim meinen Dank auch hier, o Gott, f\u00fcr deine Gnade,", "tokens": ["Nim", "mei\u00b7nen", "Dank", "auch", "hier", ",", "o", "Gott", ",", "f\u00fcr", "dei\u00b7ne", "Gna\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "ADV", "ADV", "$,", "FM", "NN", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.230": {"text": "da\u00df mich auf diese Zeit befallen hat kein Schade!", "tokens": ["da\u00df", "mich", "auf", "die\u00b7se", "Zeit", "be\u00b7fal\u00b7len", "hat", "kein", "Scha\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "NN", "VVPP", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.231": {"text": "Da mich Verlust und Tod in allen Winkeln sucht',", "tokens": ["Da", "mich", "Ver\u00b7lust", "und", "Tod", "in", "al\u00b7len", "Win\u00b7keln", "sucht'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "KON", "NN", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.232": {"text": "so hast du mich gef\u00fchrt in einer sichern Flucht,", "tokens": ["so", "hast", "du", "mich", "ge\u00b7f\u00fchrt", "in", "ei\u00b7ner", "si\u00b7chern", "Flucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "VVPP", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.233": {"text": "selbst in dein Haus versteckt. Ihr acht erschlagnen Br\u00fcder,", "tokens": ["selbst", "in", "dein", "Haus", "ver\u00b7steckt", ".", "Ihr", "acht", "er\u00b7schlag\u00b7nen", "Br\u00fc\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VVPP", "$.", "PPER", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.234": {"text": "fallt willig, wie ihr tut, legt Wehr und Leiber nieder!", "tokens": ["fallt", "wil\u00b7lig", ",", "wie", "ihr", "tut", ",", "legt", "Wehr", "und", "Lei\u00b7ber", "nie\u00b7der", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$,", "PWAV", "PPER", "VVFIN", "$,", "VVFIN", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.235": {"text": "Mu\u00df ja denn euer Tod f\u00fcr unser Leben sein,", "tokens": ["Mu\u00df", "ja", "denn", "eu\u00b7er", "Tod", "f\u00fcr", "un\u00b7ser", "Le\u00b7ben", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.236": {"text": "so nehmt das selge Feld mit andern Helden ein!", "tokens": ["so", "nehmt", "das", "sel\u00b7ge", "Feld", "mit", "an\u00b7dern", "Hel\u00b7den", "ein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.237": {"text": "Der treffliche ", "tokens": ["Der", "treff\u00b7li\u00b7che"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+--", "measure": "dactylic.init"}, "line.238": {"text": "macht' uns ein k\u00f6stlichs Mahl und lie\u00df uns wol geschehen,", "tokens": ["macht'", "uns", "ein", "k\u00f6st\u00b7lichs", "Mahl", "und", "lie\u00df", "uns", "wol", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "KON", "VVFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.239": {"text": "nahm unsern ", "tokens": ["nahm", "un\u00b7sern"], "token_info": ["word", "word"], "pos": ["VVFIN", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.240": {"text": "was er ihm legte vor, war alles wol getan.", "tokens": ["was", "er", "ihm", "leg\u00b7te", "vor", ",", "war", "al\u00b7les", "wol", "ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPER", "VVFIN", "PTKVZ", "$,", "VAFIN", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.241": {"text": "Erinnre, Bruder, dich, wie manche s\u00fc\u00dfe Stunden", "tokens": ["E\u00b7rinn\u00b7re", ",", "Bru\u00b7der", ",", "dich", ",", "wie", "man\u00b7che", "s\u00fc\u00b7\u00dfe", "Stun\u00b7den"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "NN", "$,", "PPER", "$,", "PWAV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.242": {"text": "uns umb den ", "tokens": ["uns", "umb", "den"], "token_info": ["word", "word", "word"], "pos": ["PPER", "APPR", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.243": {"text": "wenn jener von Schiras so in den Jaspis sprang", "tokens": ["wenn", "je\u00b7ner", "von", "Schi\u00b7ras", "so", "in", "den", "Jas\u00b7pis", "sprang"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PDS", "APPR", "NN", "ADV", "APPR", "ART", "NE", "VVFIN"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.244": {"text": "und uns zugleich in Mund und Stirn' und Seele drang.", "tokens": ["und", "uns", "zu\u00b7gleich", "in", "Mund", "und", "Stirn'", "und", "See\u00b7le", "drang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "APPR", "NN", "KON", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.245": {"text": "Entsinn dich gleichfalls auch der Ursach' unsrer Freuden,", "tokens": ["Ent\u00b7sinn", "dich", "gleich\u00b7falls", "auch", "der", "Ur\u00b7sach'", "uns\u00b7rer", "Freu\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.246": {"text": "die meistens traurig war! Gedachten wir an Leiden,", "tokens": ["die", "meis\u00b7tens", "trau\u00b7rig", "war", "!", "Ge\u00b7dach\u00b7ten", "wir", "an", "Lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VAFIN", "$.", "NN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.247": {"text": "so dachten warlich wir an dich auch, roter Wein,", "tokens": ["so", "dach\u00b7ten", "war\u00b7lich", "wir", "an", "dich", "auch", ",", "ro\u00b7ter", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPER", "APPR", "PPER", "ADV", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.248": {"text": "als der du einig uns nicht l\u00e4ssest m\u00fchsam sein.", "tokens": ["als", "der", "du", "ei\u00b7nig", "uns", "nicht", "l\u00e4s\u00b7sest", "m\u00fch\u00b7sam", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PPER", "ADJD", "PPER", "PTKNEG", "VVFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.249": {"text": "Wenn Sorgen stehen auf, und die und die Gedanken", "tokens": ["Wenn", "Sor\u00b7gen", "ste\u00b7hen", "auf", ",", "und", "die", "und", "die", "Ge\u00b7dan\u00b7ken"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "VVFIN", "PTKVZ", "$,", "KON", "ART", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.250": {"text": "sich \u00fcber dem und dem bald so, bald anders zanken,", "tokens": ["sich", "\u00fc\u00b7ber", "dem", "und", "dem", "bald", "so", ",", "bald", "an\u00b7ders", "zan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "KON", "ART", "ADV", "ADV", "$,", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.251": {"text": "so ist Eleusius der beste Schiedeman,", "tokens": ["so", "ist", "E\u00b7leu\u00b7si\u00b7us", "der", "bes\u00b7te", "Schie\u00b7de\u00b7man", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.252": {"text": "wenn sonst nichts auf der Welt die Geister stillen kan.", "tokens": ["wenn", "sonst", "nichts", "auf", "der", "Welt", "die", "Geis\u00b7ter", "stil\u00b7len", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIS", "APPR", "ART", "NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.253": {"text": "So hat uns auch das Haus der Herren ", "tokens": ["So", "hat", "uns", "auch", "das", "Haus", "der", "Her\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.254": {"text": "der ", "tokens": ["der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.255": {"text": "der ", "tokens": ["der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.256": {"text": "(", "tokens": ["("], "token_info": ["punct"], "pos": ["$("]}, "line.257": {"text": "tr\u00fcg' er ein deutsches Kleid, f\u00fcr Landsman solten hei\u00dfen,", "tokens": ["tr\u00fcg'", "er", "ein", "deut\u00b7sches", "Kleid", ",", "f\u00fcr", "Lands\u00b7man", "sol\u00b7ten", "hei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,", "APPR", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.258": {"text": "wie vielmal hat er uns die lange Zeit verk\u00fcrzt", "tokens": ["wie", "viel\u00b7mal", "hat", "er", "uns", "die", "lan\u00b7ge", "Zeit", "ver\u00b7k\u00fcrzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "PRF", "ART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.259": {"text": "und froh und frei mit uns die Schalen umbgest\u00fcrzt!", "tokens": ["und", "froh", "und", "frei", "mit", "uns", "die", "Scha\u00b7len", "umb\u00b7ge\u00b7st\u00fcrzt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "APPR", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.260": {"text": "Bald stillten unsern Sinn die k\u00f6niglichen Jagden,", "tokens": ["Bald", "still\u00b7ten", "un\u00b7sern", "Sinn", "die", "k\u00f6\u00b7nig\u00b7li\u00b7chen", "Jag\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.261": {"text": "bald der ", "tokens": ["bald", "der"], "token_info": ["word", "word"], "pos": ["ADV", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.262": {"text": "des gro\u00dfen Kanzlers Mahl, der G\u00e4rten teurer Preis,", "tokens": ["des", "gro\u00b7\u00dfen", "Kanz\u00b7lers", "Mahl", ",", "der", "G\u00e4r\u00b7ten", "teu\u00b7rer", "Preis", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.263": {"text": "der B\u00e4ue Trefflichkeit, der Wasserk\u00fcnste Flei\u00df,", "tokens": ["der", "B\u00e4u\u00b7e", "Treff\u00b7lich\u00b7keit", ",", "der", "Was\u00b7ser\u00b7k\u00fcns\u00b7te", "Flei\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.264": {"text": "des K\u00f6nigs Schimpf und Ernst, die Weise zu regieren,", "tokens": ["des", "K\u00f6\u00b7nigs", "Schimpf", "und", "Ernst", ",", "die", "Wei\u00b7se", "zu", "re\u00b7gie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NE", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.265": {"text": "des Adels hoher Stand, das Muster im Turnieren,", "tokens": ["des", "A\u00b7dels", "ho\u00b7her", "Stand", ",", "das", "Mus\u00b7ter", "im", "Tur\u00b7nie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.266": {"text": "so vieler V\u00f6lker Schar, so mancher Waren Wahl", "tokens": ["so", "vie\u00b7ler", "V\u00f6l\u00b7ker", "Schar", ",", "so", "man\u00b7cher", "Wa\u00b7ren", "Wahl"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "NN", "$,", "ADV", "PIAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.267": {"text": "und so viel Anders mehr in ungez\u00e4hlter Zahl.", "tokens": ["und", "so", "viel", "An\u00b7ders", "mehr", "in", "un\u00b7ge\u00b7z\u00e4hl\u00b7ter", "Zahl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADV", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ich war gesonnen zwar den ", "tokens": ["Ich", "war", "ge\u00b7son\u00b7nen", "zwar", "den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "ADV", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "und was Seleukus hier, dort Ctesiphon erbauen,", "tokens": ["und", "was", "Se\u00b7leu\u00b7kus", "hier", ",", "dort", "Cte\u00b7si\u00b7phon", "er\u00b7bau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "NE", "ADV", "$,", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "was er vor Altes weist von jener gro\u00dfen Stadt.", "tokens": ["was", "er", "vor", "Al\u00b7tes", "weist", "von", "je\u00b7ner", "gro\u00b7\u00dfen", "Stadt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "NN", "VVFIN", "APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mir lag ", "tokens": ["Mir", "lag"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "mich deucht', ich liefe schon von ", "tokens": ["mich", "deucht'", ",", "ich", "lie\u00b7fe", "schon", "von"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "APPR"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "die See um ", "tokens": ["die", "See", "um"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Der Wind, der trug mich wol vor ", "tokens": ["Der", "Wind", ",", "der", "trug", "mich", "wol", "vor"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "PPER", "ADV", "APPR"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": "Bald war ich um den ", "tokens": ["Bald", "war", "ich", "um", "den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.9": {"text": "bald, strenger ", "tokens": ["bald", ",", "stren\u00b7ger"], "token_info": ["word", "punct", "word"], "pos": ["ADV", "$,", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.10": {"text": "da\u00df ich solt' hinter mich und so mich kehren umb.", "tokens": ["da\u00df", "ich", "solt'", "hin\u00b7ter", "mich", "und", "so", "mich", "keh\u00b7ren", "umb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "APPR", "PPER", "KON", "ADV", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Mein Anschlag aber fiel, wie weislich ich ihn fa\u00dfte;", "tokens": ["Mein", "An\u00b7schlag", "a\u00b7ber", "fiel", ",", "wie", "weis\u00b7lich", "ich", "ihn", "fa\u00df\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVFIN", "$,", "PWAV", "ADJD", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "wie flei\u00dfig ich auf ihn zu Nacht und Tage pa\u00dfte,", "tokens": ["wie", "flei\u00b7\u00dfig", "ich", "auf", "ihn", "zu", "Nacht", "und", "Ta\u00b7ge", "pa\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "APPR", "PPER", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "so must' ich Andre sehn gl\u00fcckselger sein als mich;", "tokens": ["so", "must'", "ich", "And\u00b7re", "sehn", "gl\u00fcck\u00b7sel\u00b7ger", "sein", "als", "mich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PIS", "VVFIN", "ADJD", "VAINF", "KOKOM", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "des Andern Schlu\u00df gieng vor, der meine hinter sich.", "tokens": ["des", "An\u00b7dern", "Schlu\u00df", "gieng", "vor", ",", "der", "mei\u00b7ne", "hin\u00b7ter", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$,", "PRELS", "PPOSAT", "APPR", "PRF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ein Weg mu\u00df sehr gut sein, den man soll zweimal machen.", "tokens": ["Ein", "Weg", "mu\u00df", "sehr", "gut", "sein", ",", "den", "man", "soll", "zwei\u00b7mal", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ADJD", "VAINF", "$,", "PRELS", "PIS", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Den aber mu\u00df ich tun, wie wenig er von Lachen,", "tokens": ["Den", "a\u00b7ber", "mu\u00df", "ich", "tun", ",", "wie", "we\u00b7nig", "er", "von", "La\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VMFIN", "PPER", "VVINF", "$,", "PWAV", "PIS", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "wie viel er Weinens hat: doch spricht mich di\u00df zur Ruh',", "tokens": ["wie", "viel", "er", "Wei\u00b7nens", "hat", ":", "doch", "spricht", "mich", "di\u00df", "zur", "Ruh'", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "NN", "VAFIN", "$.", "ADV", "VVFIN", "PPER", "PDS", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "da\u00df ich ihn noch mit dir und meinesgleichen tu'.", "tokens": ["da\u00df", "ich", "ihn", "noch", "mit", "dir", "und", "mei\u00b7nes\u00b7glei\u00b7chen", "tu'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "APPR", "PPER", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Sind iemals Freunde Not, so sind sie Not im Reisen;", "tokens": ["Sind", "ie\u00b7mals", "Freun\u00b7de", "Not", ",", "so", "sind", "sie", "Not", "im", "Rei\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "NN", "$,", "ADV", "VAFIN", "PPER", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "ihr Beisein ist vor Gold und Sch\u00e4tzen weit zu preisen.", "tokens": ["ihr", "Bei\u00b7sein", "ist", "vor", "Gold", "und", "Sch\u00e4t\u00b7zen", "weit", "zu", "prei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "NN", "KON", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Sie mindern die Gefahr, halbiren den Verdru\u00df", "tokens": ["Sie", "min\u00b7dern", "die", "Ge\u00b7fahr", ",", "hal\u00b7bi\u00b7ren", "den", "Ver\u00b7dru\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADV", "ART", "NN", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "und sind einander selbst f\u00fcr Wagen, Stab und Fu\u00df.", "tokens": ["und", "sind", "ein\u00b7an\u00b7der", "selbst", "f\u00fcr", "Wa\u00b7gen", ",", "Stab", "und", "Fu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Steh ewig, ", "tokens": ["Steh", "e\u00b7wig", ","], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "und werde nimmermehr den Feinden eine Beute,", "tokens": ["und", "wer\u00b7de", "nim\u00b7mer\u00b7mehr", "den", "Fein\u00b7den", "ei\u00b7ne", "Beu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "reut alles Unkraut aus, geh \u00fcber ", "tokens": ["reut", "al\u00b7les", "Un\u00b7kraut", "aus", ",", "geh", "\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PIAT", "NN", "PTKVZ", "$,", "VVFIN", "APPR"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "das deinen Adel schimpft, mach alles wie ", "tokens": ["das", "dei\u00b7nen", "A\u00b7del", "schimpft", ",", "mach", "al\u00b7les", "wie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "PIS", "KOKOM"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "das deine St\u00e4rke trutzt! Wir wollen dein Behagen", "tokens": ["das", "dei\u00b7ne", "St\u00e4r\u00b7ke", "trutzt", "!", "Wir", "wol\u00b7len", "dein", "Be\u00b7ha\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$.", "PPER", "VMFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "und deine Trefflichkeit mit uns zu Hause tragen", "tokens": ["und", "dei\u00b7ne", "Treff\u00b7lich\u00b7keit", "mit", "uns", "zu", "Hau\u00b7se", "tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "APPR", "PPER", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "und streuen in die Welt. Habt itzt nun gute Nacht,", "tokens": ["und", "streu\u00b7en", "in", "die", "Welt", ".", "Habt", "itzt", "nun", "gu\u00b7te", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$.", "VAFIN", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "ihr Freunde, die ihr uns oft habet froh gemacht!", "tokens": ["ihr", "Freun\u00b7de", ",", "die", "ihr", "uns", "oft", "ha\u00b7bet", "froh", "ge\u00b7macht", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PPER", "PPER", "ADV", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Mit diesem kr\u00e4nzten wir ", "tokens": ["Mit", "die\u00b7sem", "kr\u00e4nz\u00b7ten", "wir"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "VVFIN", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "der Taurus Bruder ist. Wir warfen Weirauchk\u00f6rner", "tokens": ["der", "Tau\u00b7rus", "Bru\u00b7der", "ist", ".", "Wir", "war\u00b7fen", "Wei\u00b7rauch\u00b7k\u00f6r\u00b7ner"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VAFIN", "$.", "PPER", "VVFIN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "den G\u00f6ttern in die Glut und wandten von ", "tokens": ["den", "G\u00f6t\u00b7tern", "in", "die", "Glut", "und", "wand\u00b7ten", "von"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "KON", "VVFIN", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "uns in ein Nordenland, da ewig Blumen bl\u00fchn,", "tokens": ["uns", "in", "ein", "Nor\u00b7den\u00b7land", ",", "da", "e\u00b7wig", "Blu\u00b7men", "bl\u00fchn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "$,", "ADV", "ADJD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "da Sand und D\u00fcrre stirbt, da Frucht und F\u00fclle lebet,", "tokens": ["da", "Sand", "und", "D\u00fcr\u00b7re", "stirbt", ",", "da", "Frucht", "und", "F\u00fcl\u00b7le", "le\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "VVFIN", "$,", "KOUS", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "da stetigs ein Lenz nur umb Tal und H\u00fcgel schwebet:", "tokens": ["da", "ste\u00b7tigs", "ein", "Lenz", "nur", "umb", "Tal", "und", "H\u00fc\u00b7gel", "schwe\u00b7bet", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "ADV", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "in Persiens sein Mark, das treffliche ", "tokens": ["in", "Per\u00b7siens", "sein", "Mark", ",", "das", "treff\u00b7li\u00b7che"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NE", "PPOSAT", "NN", "$,", "ART", "ADJA"], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "das Rom und Frankreich trutzt und Spanien schimpfen kan, \u2013", "tokens": ["das", "Rom", "und", "Fran\u00b7kreich", "trutzt", "und", "Spa\u00b7ni\u00b7en", "schimp\u00b7fen", "kan", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NE", "KON", "NE", "VVFIN", "KON", "NE", "VVINF", "VMFIN", "$,", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "hier hat es die Natur mit Bergen rings verschlossen,", "tokens": ["hier", "hat", "es", "die", "Na\u00b7tur", "mit", "Ber\u00b7gen", "rings", "ver\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "APPR", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "hier mit der strengen See, die r\u00fchmlich hei\u00dft, umbgossen \u2013,", "tokens": ["hier", "mit", "der", "stren\u00b7gen", "See", ",", "die", "r\u00fchm\u00b7lich", "hei\u00dft", ",", "umb\u00b7gos\u00b7sen", "\u2013", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$,", "VVPP", "$(", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "das lustige ", "tokens": ["das", "lus\u00b7ti\u00b7ge"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-+", "measure": "iambic.di"}, "line.12": {"text": "das seinen trucknen Durst im ", "tokens": ["das", "sei\u00b7nen", "truck\u00b7nen", "Durst", "im"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "PPOSAT", "ADJA", "NN", "APPRART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Das reichdurchflo\u00dfne Tal, die stets bes\u00e4ten Felder,", "tokens": ["Das", "reich\u00b7durch\u00b7flo\u00df\u00b7ne", "Tal", ",", "die", "stets", "be\u00b7s\u00e4\u00b7ten", "Fel\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "das immergr\u00fcne Haar der unverletzten W\u00e4lder", "tokens": ["das", "im\u00b7mer\u00b7gr\u00fc\u00b7ne", "Haar", "der", "un\u00b7ver\u00b7letz\u00b7ten", "W\u00e4l\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "folgt uns bis in ", "tokens": ["folgt", "uns", "bis", "in"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR"], "meter": "-+-+", "measure": "iambic.di"}, "line.16": {"text": "und gleichwol Wild und Vieh und Menschen unterh\u00e4lt.", "tokens": ["und", "gleich\u00b7wol", "Wild", "und", "Vieh", "und", "Men\u00b7schen", "un\u00b7ter\u00b7h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "KON", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "sein leimicht Wasser w\u00e4lzt und breit wird zwanzig Ruten,", "tokens": ["sein", "lei\u00b7micht", "Was\u00b7ser", "w\u00e4lzt", "und", "breit", "wird", "zwan\u00b7zig", "Ru\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "VVFIN", "KON", "ADJD", "VAFIN", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "flo\u00df unter unserm Fu\u00df' als wie gez\u00e4hmte hin.", "tokens": ["flo\u00df", "un\u00b7ter", "un\u00b7serm", "Fu\u00df'", "als", "wie", "ge\u00b7z\u00e4hm\u00b7te", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "KOUS", "KOKOM", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Das ewige ", "tokens": ["Das", "e\u00b7wi\u00b7ge"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-+", "measure": "iambic.di"}, "line.20": {"text": "f\u00fcr dem die Skythen noch erschrocken sich verkriechen,", "tokens": ["f\u00fcr", "dem", "die", "Sky\u00b7then", "noch", "er\u00b7schro\u00b7cken", "sich", "ver\u00b7krie\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "ADV", "VVFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "das jung f\u00fcr Alter sieht und noch die Mauer zeigt,", "tokens": ["das", "jung", "f\u00fcr", "Al\u00b7ter", "sieht", "und", "noch", "die", "Mau\u00b7er", "zeigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "APPR", "NN", "VVFIN", "KON", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "die hier von einer See bis an die ander' reicht,", "tokens": ["die", "hier", "von", "ei\u00b7ner", "See", "bis", "an", "die", "an\u00b7der'", "reicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "ADV", "APPR", "ART", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "lie\u00df sich uns wol durchsehn. Bis hieher lie\u00df sichs trauen.", "tokens": ["lie\u00df", "sich", "uns", "wol", "durch\u00b7sehn", ".", "Bis", "hie\u00b7her", "lie\u00df", "sichs", "trau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PPER", "ADV", "VVINF", "$.", "APPR", "PAV", "VVFIN", "PIS", "VVINF", "$."], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.24": {"text": "Von hieraus hub uns an, zwar nicht umbsonst, zu grauen.", "tokens": ["Von", "hier\u00b7aus", "hub", "uns", "an", ",", "zwar", "nicht", "um\u00b7bsonst", ",", "zu", "grau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PAV", "VVFIN", "PPER", "PTKVZ", "$,", "ADV", "PTKNEG", "ADV", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Wir r\u00fcckten wachsam fort. Der V\u00f6lker neue Tracht,", "tokens": ["Wir", "r\u00fcck\u00b7ten", "wach\u00b7sam", "fort", ".", "Der", "V\u00f6l\u00b7ker", "neu\u00b7e", "Tracht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "$.", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "ja selbst das neue Land, das machte sich verdacht.", "tokens": ["ja", "selbst", "das", "neu\u00b7e", "Land", ",", "das", "mach\u00b7te", "sich", "ver\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "$,", "PDS", "VVFIN", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Wie der ", "tokens": ["Wie", "der"], "token_info": ["word", "word"], "pos": ["PWAV", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.28": {"text": "der ", "tokens": ["der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.29": {"text": "der ", "tokens": ["der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.30": {"text": "uns ofte bla\u00df gemacht, das denke du hierbei!", "tokens": ["uns", "of\u00b7te", "bla\u00df", "ge\u00b7macht", ",", "das", "den\u00b7ke", "du", "hier\u00b7bei", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "VVPP", "$,", "PDS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Wie lag sichs vor ", "tokens": ["Wie", "lag", "sichs", "vor"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PIS", "APPR"], "meter": "-+-+", "measure": "iambic.di"}, "line.32": {"text": "hier des ", "tokens": ["hier", "des"], "token_info": ["word", "word"], "pos": ["ADV", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.33": {"text": "Da schwur der ", "tokens": ["Da", "schwur", "der"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.34": {"text": "vor, umb und hinter uns war nichts als eitel Not,", "tokens": ["vor", ",", "umb", "und", "hin\u00b7ter", "uns", "war", "nichts", "als", "ei\u00b7tel", "Not", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "$,", "KOUI", "KON", "APPR", "PPER", "VAFIN", "PIS", "KOKOM", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "von innen Qual und Angst, von au\u00dfen Furcht und Zagen.", "tokens": ["von", "in\u00b7nen", "Qual", "und", "Angst", ",", "von", "au\u00b7\u00dfen", "Furcht", "und", "Za\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$,", "APPR", "ADV", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Da h\u00f6rte man von nichts als Blut und Raube sagen;", "tokens": ["Da", "h\u00f6r\u00b7te", "man", "von", "nichts", "als", "Blut", "und", "Rau\u00b7be", "sa\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "PIS", "KOKOM", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "es muste sein gewagt. Was der verhasset' Ort", "tokens": ["es", "mus\u00b7te", "sein", "ge\u00b7wagt", ".", "Was", "der", "ver\u00b7has\u00b7set'", "Ort"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "VVPP", "$.", "PWS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "mit Pferden nicht versieht, das mu\u00df zu Fu\u00dfe fort.", "tokens": ["mit", "Pfer\u00b7den", "nicht", "ver\u00b7sieht", ",", "das", "mu\u00df", "zu", "Fu\u00b7\u00dfe", "fort", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKNEG", "VVFIN", "$,", "PDS", "VMFIN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "und ", "tokens": ["und"], "token_info": ["word"], "pos": ["KON"], "meter": "-", "measure": "single.down"}, "line.40": {"text": "uns freundlich \u00fcberbracht und du auch, o ", "tokens": ["uns", "freund\u00b7lich", "\u00fc\u00b7berb\u00b7racht", "und", "du", "auch", ",", "o"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "ADJD", "VVPP", "KON", "PPER", "ADV", "$,", "FM"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.41": {"text": "mehr durch des Vatern Schuld als deinen eignen Fall", "tokens": ["mehr", "durch", "des", "Va\u00b7tern", "Schuld", "als", "dei\u00b7nen", "eig\u00b7nen", "Fall"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "NN", "KOKOM", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "den Nachbarn hoch verdacht; behersche dein Geb\u00fcrge,", "tokens": ["den", "Nach\u00b7barn", "hoch", "ver\u00b7dacht", ";", "be\u00b7her\u00b7sche", "dein", "Ge\u00b7b\u00fcr\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVPP", "$.", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "nim deiner T\u00e4ler war, da\u00df kein Feind drinnen w\u00fcrge!", "tokens": ["nim", "dei\u00b7ner", "T\u00e4\u00b7ler", "war", ",", "da\u00df", "kein", "Feind", "drin\u00b7nen", "w\u00fcr\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "VAFIN", "$,", "KOUS", "PIAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+++-+-", "measure": "unknown.measure.septa"}, "line.44": {"text": "Ihr Heiden, gute Nacht! Erkennt einst, wer ihr seid!", "tokens": ["Ihr", "Hei\u00b7den", ",", "gu\u00b7te", "Nacht", "!", "Er\u00b7kennt", "einst", ",", "wer", "ihr", "seid", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADJA", "NN", "$.", "VVFIN", "ADV", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Wir setzen nun den Fu\u00df in unsre Christenheit.", "tokens": ["Wir", "set\u00b7zen", "nun", "den", "Fu\u00df", "in", "uns\u00b7re", "Chris\u00b7ten\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Mit diesem gr\u00fc\u00dften wir die manlichen ", "tokens": ["Mit", "die\u00b7sem", "gr\u00fc\u00df\u00b7ten", "wir", "die", "man\u00b7li\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+--++--", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "die sich, zwar Christen nicht, doch christlich herschen lassen.", "tokens": ["die", "sich", ",", "zwar", "Chris\u00b7ten", "nicht", ",", "doch", "christ\u00b7lich", "her\u00b7schen", "las\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PRF", "$,", "ADV", "NN", "PTKNEG", "$,", "ADV", "ADJD", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ihr ", "tokens": ["Ihr"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "hat unsre Wiederkunft von Herzen sehr gepreist.", "tokens": ["hat", "uns\u00b7re", "Wie\u00b7der\u00b7kunft", "von", "Her\u00b7zen", "sehr", "ge\u00b7preist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "APPR", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das Sandfeld, das die Flucht der schnellen Tartern kennet", "tokens": ["Das", "Sand\u00b7feld", ",", "das", "die", "Flucht", "der", "schnel\u00b7len", "Tar\u00b7tern", "ken\u00b7net"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "und von der Sonnen Glut oft lichter Lohe brennet,", "tokens": ["und", "von", "der", "Son\u00b7nen", "Glut", "oft", "lich\u00b7ter", "Lo\u00b7he", "bren\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "ADV", "ADJD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "war ietzt nun noch vor uns, der Reise strengster Teil,", "tokens": ["war", "ietzt", "nun", "noch", "vor", "uns", ",", "der", "Rei\u00b7se", "strengs\u00b7ter", "Teil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "APPR", "PPER", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "da nichts als Staub und Salz und Salz umbsonst steht feil.", "tokens": ["da", "nichts", "als", "Staub", "und", "Salz", "und", "Salz", "um\u00b7bsonst", "steht", "feil", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "KOKOM", "NN", "KON", "NN", "KON", "NN", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Zu mangeln zwar gewohnt, nicht aber gar zu darben,", "tokens": ["Zu", "man\u00b7geln", "zwar", "ge\u00b7wohnt", ",", "nicht", "a\u00b7ber", "gar", "zu", "dar\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ADV", "VVPP", "$,", "PTKNEG", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "mu\u00dft' ich auch mitte fort; auch selbst die Tartern starben,", "tokens": ["mu\u00dft'", "ich", "auch", "mit\u00b7te", "fort", ";", "auch", "selbst", "die", "Tar\u00b7tern", "star\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "PTKVZ", "$.", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "des Landes eigen Volk. Die dritte Nacht brach an,", "tokens": ["des", "Lan\u00b7des", "ei\u00b7gen", "Volk", ".", "Die", "drit\u00b7te", "Nacht", "brach", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "$.", "ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "ich hatte weder Mahl, noch Schlaf, noch nichts getan.", "tokens": ["ich", "hat\u00b7te", "we\u00b7der", "Mahl", ",", "noch", "Schlaf", ",", "noch", "nichts", "ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KON", "NN", "$,", "ADV", "NN", "$,", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die Erde war mein Pf\u00fcl, mein \u00dcberzug der Himmel,", "tokens": ["Die", "Er\u00b7de", "war", "mein", "Pf\u00fcl", ",", "mein", "\u00dc\u00b7ber\u00b7zug", "der", "Him\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "der Trunk zerschmolznes Salz, das Essen fauler Schimmel.", "tokens": ["der", "Trunk", "zer\u00b7schmolz\u00b7nes", "Salz", ",", "das", "Es\u00b7sen", "fau\u00b7ler", "Schim\u00b7mel", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wie nah' hatt' uns doch da nicht g\u00e4nzlich umgebracht", "tokens": ["Wie", "nah'", "hatt'", "uns", "doch", "da", "nicht", "g\u00e4nz\u00b7lich", "um\u00b7ge\u00b7bracht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "ADV", "ADV", "PTKNEG", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "bei Tage Hitz' und Durst, die M\u00fccken bei der Nacht!", "tokens": ["bei", "Ta\u00b7ge", "Hitz'", "und", "Durst", ",", "die", "M\u00fc\u00b7cken", "bei", "der", "Nacht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "KON", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Verzeih mirs, Evian, dem sich der Himmel neiget,", "tokens": ["Ver\u00b7zeih", "mirs", ",", "E\u00b7vi\u00b7an", ",", "dem", "sich", "der", "Him\u00b7mel", "nei\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NE", "$,", "NE", "$,", "PRELS", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "ich habe mich noch nie so tief vor dir gebeuget", "tokens": ["ich", "ha\u00b7be", "mich", "noch", "nie", "so", "tief", "vor", "dir", "ge\u00b7beu\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "als vor der ", "tokens": ["als", "vor", "der"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "APPR", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "und einen langen Zug t\u00e4t aus der Hand der ", "tokens": ["und", "ei\u00b7nen", "lan\u00b7gen", "Zug", "t\u00e4t", "aus", "der", "Hand", "der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "ADJD", "APPR", "ART", "NN", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "aus ihrer s\u00fc\u00dfen Hand. Ich schwere bei den Schalen,", "tokens": ["aus", "ih\u00b7rer", "s\u00fc\u00b7\u00dfen", "Hand", ".", "Ich", "schwe\u00b7re", "bei", "den", "Scha\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$.", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "daraus ihr G\u00f6tter trinkt auf euren besten Mahlen:", "tokens": ["da\u00b7raus", "ihr", "G\u00f6t\u00b7ter", "trinkt", "auf", "eu\u00b7ren", "bes\u00b7ten", "Mah\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "NN", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "der schlechte tr\u00fcbe Trunk durchginge mir das Blut", "tokens": ["der", "schlech\u00b7te", "tr\u00fc\u00b7be", "Trunk", "durch\u00b7gin\u00b7ge", "mir", "das", "Blut"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "mehr als Diespitern sein bester Nectar tut.", "tokens": ["mehr", "als", "Dies\u00b7pi\u00b7tern", "sein", "bes\u00b7ter", "Nec\u00b7tar", "tut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "NN", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}}, "stanza.8": {"line.1": {"text": "Verzeihs uns, Vaterland, da\u00df wir nicht ehe kommen!", "tokens": ["Ver\u00b7zeihs", "uns", ",", "Va\u00b7ter\u00b7land", ",", "da\u00df", "wir", "nicht", "e\u00b7he", "kom\u00b7men", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "NN", "$,", "KOUS", "PPER", "PTKNEG", "KOUS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es ist kein schlechter Sprung, den wir uns vorgenommen,", "tokens": ["Es", "ist", "kein", "schlech\u00b7ter", "Sprung", ",", "den", "wir", "uns", "vor\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "ADJA", "NN", "$,", "PRELS", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "wir tun kein schwaches Werk. Sechs Jahre gehn uns hin.", "tokens": ["wir", "tun", "kein", "schwa\u00b7ches", "Werk", ".", "Sechs", "Jah\u00b7re", "gehn", "uns", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN", "$.", "CARD", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Di\u00df, was uns ist Verlust, ist, Mutter, dein Gewin!", "tokens": ["Di\u00df", ",", "was", "uns", "ist", "Ver\u00b7lust", ",", "ist", ",", "Mut\u00b7ter", ",", "dein", "Ge\u00b7win", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PPER", "VAFIN", "NN", "$,", "VAFIN", "$,", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Durch uns k\u00f6mpt ", "tokens": ["Durch", "uns", "k\u00f6mpt"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "von welchem nun die Post ist \u00fcberweit geflogen;", "tokens": ["von", "wel\u00b7chem", "nun", "die", "Post", "ist", "\u00fc\u00b7ber\u00b7weit", "ge\u00b7flo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "ART", "NN", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "die V\u00f6lker dr\u00e4ngen sich in ungez\u00e4lter Zahl", "tokens": ["die", "V\u00f6l\u00b7ker", "dr\u00e4n\u00b7gen", "sich", "in", "un\u00b7ge\u00b7z\u00e4l\u00b7ter", "Zahl"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "umb ", "tokens": ["umb"], "token_info": ["word"], "pos": ["KOUI"], "meter": "+", "measure": "single.up"}}, "stanza.9": {"line.1": {"text": "Was wird di\u00df, Bruder, dir f\u00fcr Ruhm ink\u00fcnftig geben,", "tokens": ["Was", "wird", "di\u00df", ",", "Bru\u00b7der", ",", "dir", "f\u00fcr", "Ruhm", "in\u00b7k\u00fcnf\u00b7tig", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PDS", "$,", "NN", "$,", "PPER", "APPR", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "da\u00df wir auf wenge noch noch alle fr\u00f6lich leben,", "tokens": ["da\u00df", "wir", "auf", "wen\u00b7ge", "noch", "noch", "al\u00b7le", "fr\u00f6\u00b7lich", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADV", "ADV", "ADV", "PIS", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "auf wenge noch, die teils der Feind warf in das Gras,", "tokens": ["auf", "wen\u00b7ge", "noch", ",", "die", "teils", "der", "Feind", "warf", "in", "das", "Gras", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "den wir uns reizten selbst, teils ihr Bedr\u00e4ngn\u00fc\u00df fra\u00df.", "tokens": ["den", "wir", "uns", "reiz\u00b7ten", "selbst", ",", "teils", "ihr", "Be\u00b7dr\u00e4ng\u00b7n\u00fc\u00df", "fra\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "VVFIN", "ADV", "$,", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Der gro\u00dfe ", "tokens": ["Der", "gro\u00b7\u00dfe"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Zur guten Zeit gesagt, noch Keiner liegt darnieder,", "tokens": ["Zur", "gu\u00b7ten", "Zeit", "ge\u00b7sagt", ",", "noch", "Kei\u00b7ner", "liegt", "dar\u00b7nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVPP", "$,", "ADV", "PIS", "VVFIN", "PAV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "den unser F\u00fcrst betraut. Des Dankes guter Teil", "tokens": ["den", "un\u00b7ser", "F\u00fcrst", "be\u00b7traut", ".", "Des", "Dan\u00b7kes", "gu\u00b7ter", "Teil"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "VVPP", "$.", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "w\u00e4chst dir hier\u00fcber zu, du unsers Lebens Heil,", "tokens": ["w\u00e4chst", "dir", "hier\u00b7\u00fc\u00b7ber", "zu", ",", "du", "un\u00b7sers", "Le\u00b7bens", "Heil", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "PTKVZ", "$,", "PPER", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "du unsrer Krankheit Tod! Ists auch erh\u00f6ret worden?", "tokens": ["du", "uns\u00b7rer", "Krank\u00b7heit", "Tod", "!", "Ists", "auch", "er\u00b7h\u00f6\u00b7ret", "wor\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "NN", "$.", "NE", "ADV", "VVPP", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So lange reisen wir von Westen aus in Norden,", "tokens": ["So", "lan\u00b7ge", "rei\u00b7sen", "wir", "von", "Wes\u00b7ten", "aus", "in", "Nor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "APPR", "NN", "APPR", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "von Nord in Ost und S\u00fcd, durch Regen, Hitz' und Schnee,", "tokens": ["von", "Nord", "in", "Ost", "und", "S\u00fcd", ",", "durch", "Re\u00b7gen", ",", "Hitz'", "und", "Schnee", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "durch Mangel und Gefahr, durch Wald, durch Sand und See,", "tokens": ["durch", "Man\u00b7gel", "und", "Ge\u00b7fahr", ",", "durch", "Wald", ",", "durch", "Sand", "und", "See", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "so mancher Krankheit Ziel, so vieler F\u00e4lle Scherze;", "tokens": ["so", "man\u00b7cher", "Krank\u00b7heit", "Ziel", ",", "so", "vie\u00b7ler", "F\u00e4l\u00b7le", "Scher\u00b7ze", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "NN", "$,", "ADV", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Gott Lob und dir auch Dank, uns kr\u00e4nket noch kein Schmerze,", "tokens": ["Gott", "Lob", "und", "dir", "auch", "Dank", ",", "uns", "kr\u00e4n\u00b7ket", "noch", "kein", "Schmer\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "PPER", "ADV", "NN", "$,", "PPER", "VVFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "uns fri\u00dft noch keine Sucht. Wir trutzen Neid und Not", "tokens": ["uns", "fri\u00dft", "noch", "kei\u00b7ne", "Sucht", ".", "Wir", "trut\u00b7zen", "Neid", "und", "Not"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN", "$.", "PPER", "VVFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "und sind bis hieher noch nichts weniger als tot.", "tokens": ["und", "sind", "bis", "hie\u00b7her", "noch", "nichts", "we\u00b7ni\u00b7ger", "als", "tot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PAV", "ADV", "PIS", "PIS", "KOKOM", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Ich habe satt gelebt, wirst du mich nur versichern,", "tokens": ["Ich", "ha\u00b7be", "satt", "ge\u00b7lebt", ",", "wirst", "du", "mich", "nur", "ver\u00b7si\u00b7chern", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "VVPP", "$,", "VAFIN", "PPER", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "mein Bruder, diese Gunst zu tun an meinen B\u00fcchern:", "tokens": ["mein", "Bru\u00b7der", ",", "die\u00b7se", "Gunst", "zu", "tun", "an", "mei\u00b7nen", "B\u00fc\u00b7chern", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PDAT", "NN", "PTKZU", "VVINF", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "sie f\u00fchren an den Ort, da mein' und ihre Zier", "tokens": ["sie", "f\u00fch\u00b7ren", "an", "den", "Ort", ",", "da", "mein'", "und", "ih\u00b7re", "Zier"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "KOUS", "PPOSAT", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "den Kranz der Ewigkeit auch auf wird setzen dir.", "tokens": ["den", "Kranz", "der", "E\u00b7wig\u00b7keit", "auch", "auf", "wird", "set\u00b7zen", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADV", "APPR", "VAFIN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dein Lohn wird dieser sein: sie werden nicht vergehen,", "tokens": ["Dein", "Lohn", "wird", "die\u00b7ser", "sein", ":", "sie", "wer\u00b7den", "nicht", "ver\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PDAT", "VAINF", "$.", "PPER", "VAFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "die Namen, die allhier mit angezeichnet stehen.", "tokens": ["die", "Na\u00b7men", ",", "die", "all\u00b7hier", "mit", "an\u00b7ge\u00b7zeich\u00b7net", "ste\u00b7hen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "APPR", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sonst alles Ander' stirbt: was eine Feder schreibt,", "tokens": ["Sonst", "al\u00b7les", "An\u00b7der'", "stirbt", ":", "was", "ei\u00b7ne", "Fe\u00b7der", "schreibt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "$.", "PWS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "die Glut und Seele hat, das glaube, da\u00df es bleibt,", "tokens": ["die", "Glut", "und", "See\u00b7le", "hat", ",", "das", "glau\u00b7be", ",", "da\u00df", "es", "bleibt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VAFIN", "$,", "PDS", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "wenn nichts mehr etwas ist! Ich kan nicht ganz verwesen;", "tokens": ["wenn", "nichts", "mehr", "et\u00b7was", "ist", "!", "Ich", "kan", "nicht", "ganz", "ver\u00b7we\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "PIS", "VAFIN", "$.", "PPER", "VMFIN", "PTKNEG", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "mein bester Teil bleibt frisch, wenn dieses mit dem Besen", "tokens": ["mein", "bes\u00b7ter", "Teil", "bleibt", "frisch", ",", "wenn", "die\u00b7ses", "mit", "dem", "Be\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "ADJD", "$,", "KOUS", "PDAT", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "zusammen wird gekehrt. Gesetzt, di\u00df sei nicht viel,", "tokens": ["zu\u00b7sam\u00b7men", "wird", "ge\u00b7kehrt", ".", "Ge\u00b7setzt", ",", "di\u00df", "sei", "nicht", "viel", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "VVPP", "$.", "VVPP", "$,", "PDS", "VAFIN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "doch will ich, was ich hab' und habe, was ich will.", "tokens": ["doch", "will", "ich", ",", "was", "ich", "hab'", "und", "ha\u00b7be", ",", "was", "ich", "will", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "$,", "PWS", "PPER", "VAFIN", "KON", "VAFIN", "$,", "PWS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und ob auch dieses hier wird schlecht genung gehalten", "tokens": ["Und", "ob", "auch", "die\u00b7ses", "hier", "wird", "schlecht", "ge\u00b7nung", "ge\u00b7hal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADV", "PDAT", "ADV", "VAFIN", "ADJD", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "und minder oft als nichts, so la\u00df die Zeiten walten!", "tokens": ["und", "min\u00b7der", "oft", "als", "nichts", ",", "so", "la\u00df", "die", "Zei\u00b7ten", "wal\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "KOUS", "PIS", "$,", "ADV", "VVIMP", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Du weist es doch mit mir, da\u00df tausent Andre sein", "tokens": ["Du", "weist", "es", "doch", "mit", "mir", ",", "da\u00df", "tau\u00b7sent", "And\u00b7re", "sein"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$,", "KOUS", "VVFIN", "PIS", "PPOSAT"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "und tausent Andre noch, die allen andern Schein", "tokens": ["und", "tau\u00b7sent", "And\u00b7re", "noch", ",", "die", "al\u00b7len", "an\u00b7dern", "Schein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIS", "ADV", "$,", "PRELS", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "dem Lichte setzen nach. Wer eine Kunst will treiben,", "tokens": ["dem", "Lich\u00b7te", "set\u00b7zen", "nach", ".", "Wer", "ei\u00b7ne", "Kunst", "will", "trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$.", "PWS", "ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "der mu\u00df bei ihrer Schul' und seinesgleichen bleiben.", "tokens": ["der", "mu\u00df", "bei", "ih\u00b7rer", "Schul'", "und", "sei\u00b7nes\u00b7glei\u00b7chen", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "APPR", "PPOSAT", "NN", "KON", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Wer fremde Herren sucht, der findet fremden Sinn;", "tokens": ["Wer", "frem\u00b7de", "Her\u00b7ren", "sucht", ",", "der", "fin\u00b7det", "frem\u00b7den", "Sinn", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "VVFIN", "$,", "PRELS", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "nicht nur der Leib allein, auch sein Gem\u00fct ist hin.", "tokens": ["nicht", "nur", "der", "Leib", "al\u00b7lein", ",", "auch", "sein", "Ge\u00b7m\u00fct", "ist", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "ADV", "$,", "ADV", "PPOSAT", "NN", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Wir kommen wieder hin zu unsern freien Geistern,", "tokens": ["Wir", "kom\u00b7men", "wie\u00b7der", "hin", "zu", "un\u00b7sern", "frei\u00b7en", "Geis\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "da Kunst und Tugend gilt, da Niemand uns darf meistern.", "tokens": ["da", "Kunst", "und", "Tu\u00b7gend", "gilt", ",", "da", "Nie\u00b7mand", "uns", "darf", "meis\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "VVFIN", "$,", "KOUS", "PIS", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Ists Wunder, da\u00df ein Land und Volk die K\u00fcnste ha\u00dft,", "tokens": ["Ists", "Wun\u00b7der", ",", "da\u00df", "ein", "Land", "und", "Volk", "die", "K\u00fcns\u00b7te", "ha\u00dft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "KOUS", "ART", "NN", "KON", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "das, weil es hat gew\u00e4hrt, nicht eine hat gefa\u00dft?", "tokens": ["das", ",", "weil", "es", "hat", "ge\u00b7w\u00e4hrt", ",", "nicht", "ei\u00b7ne", "hat", "ge\u00b7fa\u00dft", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "KOUS", "PPER", "VAFIN", "VVPP", "$,", "PTKNEG", "PIS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Fehlt mir denn gleich der Wundsch und ich soll hier noch fallen,", "tokens": ["Fehlt", "mir", "denn", "gleich", "der", "Wund\u00b7sch", "und", "ich", "soll", "hier", "noch", "fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "KON", "PPER", "VMFIN", "ADV", "ADV", "VVINF", "$,"], "meter": "+--+--+-+-+-+-", "measure": "elegiambus"}, "line.26": {"text": "so la\u00df mich, wo ich bin, mit meinen Andern allen!", "tokens": ["so", "la\u00df", "mich", ",", "wo", "ich", "bin", ",", "mit", "mei\u00b7nen", "An\u00b7dern", "al\u00b7len", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "$,", "PWAV", "PPER", "VAFIN", "$,", "APPR", "PPOSAT", "ADJA", "PIAT", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Di\u00df nimb nur mit anheim, die Finger voll Papier!", "tokens": ["Di\u00df", "nimb", "nur", "mit", "an\u00b7heim", ",", "die", "Fin\u00b7ger", "voll", "Pa\u00b7pier", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "NE", "$,", "ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Da leb' ich ohne Tod, da bleib' ich \u00e4hnlich mir.", "tokens": ["Da", "leb'", "ich", "oh\u00b7ne", "Tod", ",", "da", "bleib'", "ich", "\u00e4hn\u00b7lich", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "$,", "ADV", "VVFIN", "PPER", "ADJD", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Di\u00df ist mein Ebenbild. Was, Bild? Mein ganzes Wesen,", "tokens": ["Di\u00df", "ist", "mein", "E\u00b7ben\u00b7bild", ".", "Was", ",", "Bild", "?", "Mein", "gan\u00b7zes", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "$.", "PWS", "$,", "NN", "$.", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "das du zwar hier noch siehst, dort weit wirst besser lesen.", "tokens": ["das", "du", "zwar", "hier", "noch", "siehst", ",", "dort", "weit", "wirst", "bes\u00b7ser", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "ADV", "VVFIN", "$,", "ADV", "ADJD", "VAFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Verla\u00df die sieche Stadt und tu dich, Bruder, an!", "tokens": ["Ver\u00b7la\u00df", "die", "sie\u00b7che", "Stadt", "und", "tu", "dich", ",", "Bru\u00b7der", ",", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "KON", "VVFIN", "PPER", "$,", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "La\u00df sehen, ob ich dich recht fr\u00f6lich machen kan!", "tokens": ["La\u00df", "se\u00b7hen", ",", "ob", "ich", "dich", "recht", "fr\u00f6\u00b7lich", "ma\u00b7chen", "kan", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "VVINF", "$,", "KOUS", "PPER", "PRF", "ADJD", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Lauf, Junger, hol uns her Melonen aus Bucharen,", "tokens": ["Lauf", ",", "Jun\u00b7ger", ",", "hol", "uns", "her", "Me\u00b7lo\u00b7nen", "aus", "Buc\u00b7ha\u00b7ren", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "$,", "VVFIN", "PRF", "APZR", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Arpusen von der Rha und andre solche Waren!", "tokens": ["Ar\u00b7pu\u00b7sen", "von", "der", "Rha", "und", "and\u00b7re", "sol\u00b7che", "Wa\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "KON", "PIS", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du, Ander, eile bald und bring uns auf der Post", "tokens": ["Du", ",", "An\u00b7der", ",", "ei\u00b7le", "bald", "und", "bring", "uns", "auf", "der", "Post"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "NE", "$,", "VVFIN", "ADV", "KON", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "kalt Bier, gew\u00fcrzten Meth und jungen roten Most,", "tokens": ["kalt", "Bier", ",", "ge\u00b7w\u00fcrz\u00b7ten", "Me\u00b7th", "und", "jun\u00b7gen", "ro\u00b7ten", "Most", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "$,", "ADJA", "NN", "KON", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "der Zucker leiden mag! Das Erste, das ich leere,", "tokens": ["der", "Zu\u00b7cker", "lei\u00b7den", "mag", "!", "Das", "Ers\u00b7te", ",", "das", "ich", "lee\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VMFIN", "$.", "ART", "ADJA", "$,", "PRELS", "PPER", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "ist, Bruder, da\u00df du lebst, aus diesem weiten Meere,", "tokens": ["ist", ",", "Bru\u00b7der", ",", "da\u00df", "du", "lebst", ",", "aus", "die\u00b7sem", "wei\u00b7ten", "Mee\u00b7re", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "NN", "$,", "KOUS", "PPER", "VVFIN", "$,", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "das, wie hier der Hyrkan, viel Fl\u00fcsse schlingt in sich", "tokens": ["das", ",", "wie", "hier", "der", "Hyr\u00b7kan", ",", "viel", "Fl\u00fcs\u00b7se", "schlingt", "in", "sich"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "$,", "PWAV", "ADV", "ART", "NN", "$,", "PIAT", "NN", "VVFIN", "APPR", "PRF"], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "und keinen Auslauf hat, als welcher f\u00e4llt in mich.", "tokens": ["und", "kei\u00b7nen", "Aus\u00b7lauf", "hat", ",", "als", "wel\u00b7cher", "f\u00e4llt", "in", "mich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "$,", "KOUS", "PIS", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Das Ander' la\u00df ich sein auf dein und meiner Lieben,", "tokens": ["Das", "An\u00b7der'", "la\u00df", "ich", "sein", "auf", "dein", "und", "mei\u00b7ner", "Lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIMP", "PPER", "PPOSAT", "APPR", "PPOSAT", "KON", "PPOSAT", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "die sich vielleicht um uns nicht sehr mehr nun betr\u00fcben.", "tokens": ["die", "sich", "viel\u00b7leicht", "um", "uns", "nicht", "sehr", "mehr", "nun", "be\u00b7tr\u00fc\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PRF", "ADV", "APPR", "PPER", "PTKNEG", "ADV", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Das Dritte tu mir nach durch diesen engen Ring,", "tokens": ["Das", "Drit\u00b7te", "tu", "mir", "nach", "durch", "die\u00b7sen", "en\u00b7gen", "Ring", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "APPR", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "den ich zu guter Letzt von lieber Hand empfing,", "tokens": ["den", "ich", "zu", "gu\u00b7ter", "Letzt", "von", "lie\u00b7ber", "Hand", "emp\u00b7fing", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN", "APPR", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Gott wei\u00df, worauf und wo! Doch dir ist Nichts nicht fremde,", "tokens": ["Gott", "wei\u00df", ",", "wo\u00b7rauf", "und", "wo", "!", "Doch", "dir", "ist", "Nichts", "nicht", "frem\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PWAV", "KON", "PWAV", "$.", "KON", "PPER", "VAFIN", "PIS", "PTKNEG", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "was mir verborgen liegt hier unter diesem Hemde.", "tokens": ["was", "mir", "ver\u00b7bor\u00b7gen", "liegt", "hier", "un\u00b7ter", "die\u00b7sem", "Hem\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "VVFIN", "ADV", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "So, Bruder, trink noch Eins, auf Treue zu bestehen,", "tokens": ["So", ",", "Bru\u00b7der", ",", "trink", "noch", "Eins", ",", "auf", "Treu\u00b7e", "zu", "be\u00b7ste\u00b7hen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NN", "$,", "VVFIN", "ADV", "NN", "$,", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "denn morgen werden wir, wills Gott, zu Segel gehen!", "tokens": ["denn", "mor\u00b7gen", "wer\u00b7den", "wir", ",", "wills", "Gott", ",", "zu", "Se\u00b7gel", "ge\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "$,", "VMFIN", "NN", "$,", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}