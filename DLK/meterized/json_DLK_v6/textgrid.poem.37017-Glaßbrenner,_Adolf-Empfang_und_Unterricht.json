{"textgrid.poem.37017": {"metadata": {"author": {"name": "Gla\u00dfbrenner, Adolf", "birth": "N.A.", "death": "N.A."}, "title": "Empfang und Unterricht", "genre": "verse", "period": "N.A.", "pub_year": 1843, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Seine Zopfigkeit, der ernste", "tokens": ["Sei\u00b7ne", "Zop\u00b7fig\u00b7keit", ",", "der", "erns\u00b7te"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ober-Mufti, mich nach guter,", "tokens": ["O\u00b7ber\u00b7Muf\u00b7ti", ",", "mich", "nach", "gu\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRF", "APPR", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Alter Sitt' empfangend, k\u00fc\u00dfte", "tokens": ["Al\u00b7ter", "Sitt'", "emp\u00b7fan\u00b7gend", ",", "k\u00fc\u00df\u00b7te"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["NN", "NN", "VVPP", "$,", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Meines Schlafrocks Saum und nahm dann", "tokens": ["Mei\u00b7nes", "Schla\u00b7frocks", "Saum", "und", "nahm", "dann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "NN", "KON", "VVFIN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Meine rebenblut'ge Spende", "tokens": ["Mei\u00b7ne", "re\u00b7ben\u00b7blut'\u00b7ge", "Spen\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mit der gr\u00f6\u00dften Huld entgegen,", "tokens": ["Mit", "der", "gr\u00f6\u00df\u00b7ten", "Huld", "ent\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "W\u00e4hrend ich, gleichwie zum Segen,", "tokens": ["W\u00e4h\u00b7rend", "ich", ",", "gleich\u00b7wie", "zum", "Se\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "KON", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Mu\u00dfte meine beiden H\u00e4nde", "tokens": ["Mu\u00df\u00b7te", "mei\u00b7ne", "bei\u00b7den", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPOSAT", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Ihm auf Bauch und Gurgel legen.", "tokens": ["Ihm", "auf", "Bauch", "und", "Gur\u00b7gel", "le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.2": {"line.1": {"text": "Und nachdem nun diese Handlung,", "tokens": ["Und", "nach\u00b7dem", "nun", "die\u00b7se", "Hand\u00b7lung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ganz so geistvoll wie erhaben,", "tokens": ["Ganz", "so", "geist\u00b7voll", "wie", "er\u00b7ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "KOKOM", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ich vollbracht und seine Diener", "tokens": ["Ich", "voll\u00b7bracht", "und", "sei\u00b7ne", "Die\u00b7ner"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVPP", "KON", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sich entfernt, ergriff der Mufti", "tokens": ["Sich", "ent\u00b7fernt", ",", "er\u00b7griff", "der", "Muf\u00b7ti"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PRF", "ADJD", "$,", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Eine goldkrystall'ne Flasche,", "tokens": ["Ei\u00b7ne", "gold\u00b7kry\u00b7stall'\u00b7ne", "Fla\u00b7sche", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Go\u00df aus dieser in ein spitzes,", "tokens": ["Go\u00df", "aus", "die\u00b7ser", "in", "ein", "spit\u00b7zes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDAT", "APPR", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Goldkrystall'nes, frommes Kelchglas", "tokens": ["Gold\u00b7kry\u00b7stall'\u00b7nes", ",", "from\u00b7mes", "Kelchg\u00b7las"], "token_info": ["word", "punct", "word", "word"], "pos": ["NE", "$,", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "K\u00f6stlich duftende und gold'ne", "tokens": ["K\u00f6st\u00b7lich", "duf\u00b7ten\u00b7de", "und", "gold'\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "ADJA", "KON", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Feine Kr\u00e4utertropfen, die er", "tokens": ["Fei\u00b7ne", "Kr\u00e4u\u00b7ter\u00b7trop\u00b7fen", ",", "die", "er"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "PRELS", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "\u00bbwohlgef\u00e4ll'gen Bittern\u00ab nannte,", "tokens": ["\u00bb", "wohl\u00b7ge\u00b7f\u00e4ll'\u00b7gen", "Bit\u00b7tern", "\u00ab", "nann\u00b7te", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$(", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Und von denen er betheuernd", "tokens": ["Und", "von", "de\u00b7nen", "er", "be\u00b7theu\u00b7ernd"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PRELS", "PPER", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Sagte, da\u00df sie ganz so schmackhaft", "tokens": ["Sag\u00b7te", ",", "da\u00df", "sie", "ganz", "so", "schmack\u00b7haft"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ADV", "ADV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Und belebend wie zutr\u00e4glich", "tokens": ["Und", "be\u00b7le\u00b7bend", "wie", "zu\u00b7tr\u00e4g\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJD", "KOKOM", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Der Gesundheit seien \u2013 go\u00df er", "tokens": ["Der", "Ge\u00b7sund\u00b7heit", "sei\u00b7en", "\u2013", "go\u00df", "er"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VAFIN", "$(", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Diese edeln Kr\u00e4utertropfen", "tokens": ["Die\u00b7se", "e\u00b7deln", "Kr\u00e4u\u00b7ter\u00b7trop\u00b7fen"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Langsam in den Mund und Schlund ", "tokens": ["Lang\u00b7sam", "in", "den", "Mund", "und", "Schlund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.17": {"text": "Schnalzete und sprach zu mir dann", "tokens": ["Schnal\u00b7ze\u00b7te", "und", "sprach", "zu", "mir", "dann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "KON", "VVFIN", "APPR", "PPER", "ADV"], "meter": "+---+--+", "measure": "iambic.tri.chol"}, "line.18": {"text": "Freundlich nickend: \u00bbWohl bekomm's Euch!\u00ab", "tokens": ["Freund\u00b7lich", "ni\u00b7ckend", ":", "\u00bb", "Wohl", "be\u00b7kom\u00b7m's", "Euch", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVPP", "$.", "$(", "ADV", "VVFIN", "PPER", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Ich erstaunte und sann dr\u00fcber", "tokens": ["Ich", "er\u00b7staun\u00b7te", "und", "sann", "dr\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PAV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nach, woher es wohl mag kommen,", "tokens": ["Nach", ",", "wo\u00b7her", "es", "wohl", "mag", "kom\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$,", "PWAV", "PPER", "ADV", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df auf diesem Stern die Menschen", "tokens": ["Da\u00df", "auf", "die\u00b7sem", "Stern", "die", "Men\u00b7schen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PDAT", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alle, selbst die hochgestellten,", "tokens": ["Al\u00b7le", ",", "selbst", "die", "hoch\u00b7ge\u00b7stell\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "ADV", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Stets den Aberglauben hegen:", "tokens": ["Stets", "den", "A\u00b7berg\u00b7lau\u00b7ben", "he\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Das, was sie nur f\u00fcr sich selbst thun,", "tokens": ["Das", ",", "was", "sie", "nur", "f\u00fcr", "sich", "selbst", "thun", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PPER", "ADV", "APPR", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Anderen gethan zu haben?", "tokens": ["An\u00b7de\u00b7ren", "ge\u00b7than", "zu", "ha\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "\u00bbihr seid von mir hergerufen,\u00ab", "tokens": ["\u00bb", "ihr", "seid", "von", "mir", "her\u00b7ge\u00b7ru\u00b7fen", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "APPR", "PPER", "VVPP", "$,", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Sprach der Mufti jetzt, nachdem er", "tokens": ["Sprach", "der", "Muf\u00b7ti", "jetzt", ",", "nach\u00b7dem", "er"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "ART", "NN", "ADV", "$,", "KOUS", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sich auf einen goldbetroddelt-", "tokens": ["Sich", "auf", "ei\u00b7nen", "gold\u00b7be\u00b7trod\u00b7del\u00b7t"], "token_info": ["word", "word", "word", "word"], "pos": ["PRF", "APPR", "ART", "TRUNC"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Sammetrothen Sopha wohlig", "tokens": ["Sam\u00b7me\u00b7tro\u00b7then", "So\u00b7pha", "woh\u00b7lig"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "In der ganzen K\u00f6rperl\u00e4nge", "tokens": ["In", "der", "gan\u00b7zen", "K\u00f6r\u00b7per\u00b7l\u00e4n\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ausgerecket und gestrecket,", "tokens": ["Aus\u00b7ge\u00b7re\u00b7cket", "und", "ge\u00b7stre\u00b7cket", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und ein Gleiches auf dem gleichen", "tokens": ["Und", "ein", "Glei\u00b7ches", "auf", "dem", "glei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Gegen\u00fcberstehnden Sopha", "tokens": ["Ge\u00b7gen\u00b7\u00fc\u00b7bers\u00b7tehn\u00b7den", "So\u00b7pha"], "token_info": ["word", "word"], "pos": ["NN", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.9": {"text": "Mich zu thun bedeutet hatte:", "tokens": ["Mich", "zu", "thun", "be\u00b7deu\u00b7tet", "hat\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "VVFIN", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "\u00bbihr seid von mir herberufen,", "tokens": ["\u00bb", "ihr", "seid", "von", "mir", "her\u00b7be\u00b7ru\u00b7fen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "Um die Kenntni\u00df zu empfangen", "tokens": ["Um", "die", "Kennt\u00b7ni\u00df", "zu", "emp\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUI", "ART", "NN", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Unsrer ", "tokens": ["Uns\u00b7rer"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.13": {"text": "Sie ist einfach, und f\u00fcr Geister", "tokens": ["Sie", "ist", "ein\u00b7fach", ",", "und", "f\u00fcr", "Geis\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "KON", "APPR", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.14": {"text": "Eures Schlages, welche schnell sich", "tokens": ["Eu\u00b7res", "Schla\u00b7ges", ",", "wel\u00b7che", "schnell", "sich"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ADJD", "PRF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Angeochst- und aufgedrung'nem", "tokens": ["An\u00b7geochst", "und", "auf\u00b7ge\u00b7drung'\u00b7nem"], "token_info": ["word", "word", "word"], "pos": ["TRUNC", "KON", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.16": {"text": "Wust entschlagen, leicht erfa\u00dfbar.", "tokens": ["Wust", "ent\u00b7schla\u00b7gen", ",", "leicht", "er\u00b7fa\u00df\u00b7bar", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "ADJD", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "G\u00e4nzlich m\u00fc\u00dft Ihr Euch, zum Beispiel", "tokens": ["G\u00e4nz\u00b7lich", "m\u00fc\u00dft", "Ihr", "Euch", ",", "zum", "Bei\u00b7spiel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "VMFIN", "PPER", "PPER", "$,", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "Von dem christlich-j\u00fcd'schen Denken", "tokens": ["Von", "dem", "christ\u00b7lich\u00b7j\u00fcd'\u00b7schen", "Den\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "(wenn man dieses captivirte,", "tokens": ["(", "wenn", "man", "die\u00b7ses", "cap\u00b7ti\u00b7vir\u00b7te", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PIS", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "Abgezogne, blinde Tappen", "tokens": ["Ab\u00b7ge\u00b7zog\u00b7ne", ",", "blin\u00b7de", "Tap\u00b7pen"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$,", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Und dies Vorschrifts-Drumherumgehn,", "tokens": ["Und", "dies", "Vor\u00b7schrifts\u00b7Drum\u00b7her\u00b7um\u00b7gehn", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PDS", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.22": {"text": "Dies sophist'sche Absichschwei\u00dfen", "tokens": ["Dies", "so\u00b7phist'\u00b7sche", "Ab\u00b7sich\u00b7schwei\u00b7\u00dfen"], "token_info": ["word", "word", "word"], "pos": ["PDS", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.23": {"text": "In dem Nichtigen und Flachen", "tokens": ["In", "dem", "Nich\u00b7ti\u00b7gen", "und", "Fla\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.24": {"text": "Ueberhaupt kann ", "tokens": ["Ue\u00b7ber\u00b7haupt", "kann"], "token_info": ["word", "word"], "pos": ["ADV", "VMFIN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.25": {"text": "Oder F\u00fchlen frei Euch machen.\u00ab", "tokens": ["O\u00b7der", "F\u00fch\u00b7len", "frei", "Euch", "ma\u00b7chen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NN", "ADJD", "PPER", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "\u00bbwie?\u00ab rief ich, erhitzt aufspringend", "tokens": ["\u00bb", "wie", "?", "\u00ab", "rief", "ich", ",", "er\u00b7hitzt", "auf\u00b7sprin\u00b7gend"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "PWAV", "$.", "$(", "VVFIN", "PPER", "$,", "VVFIN", "VVPP"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Von dem Lager, \u00bbwollt Ihr Alles,", "tokens": ["Von", "dem", "La\u00b7ger", ",", "\u00bb", "wollt", "Ihr", "Al\u00b7les", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "$(", "VMFIN", "PPER", "PIS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was im Geist und gegenst\u00e4ndlich", "tokens": ["Was", "im", "Geist", "und", "ge\u00b7gen\u00b7st\u00e4nd\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "APPRART", "NN", "KON", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Offenbart ist und als heil'ge", "tokens": ["Of\u00b7fen\u00b7bart", "ist", "und", "als", "heil'\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "KON", "KOUS", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ueberzeugung unvertilgbar", "tokens": ["Ue\u00b7ber\u00b7zeu\u00b7gung", "un\u00b7ver\u00b7tilg\u00b7bar"], "token_info": ["word", "word"], "pos": ["NN", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "In Millionen und in mir lebt,", "tokens": ["In", "Mil\u00b7lion\u00b7en", "und", "in", "mir", "lebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "In dem Scheidewasser Eures", "tokens": ["In", "dem", "Schei\u00b7de\u00b7was\u00b7ser", "Eu\u00b7res"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Irren, ewig wirren Gr\u00fcbelns", "tokens": ["Ir\u00b7ren", ",", "e\u00b7wig", "wir\u00b7ren", "Gr\u00fc\u00b7belns"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "ADJD", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.9": {"text": "Und Vern\u00fcnftelns, Eures heidnisch", "tokens": ["Und", "Ver\u00b7n\u00fcnf\u00b7telns", ",", "Eu\u00b7res", "heid\u00b7nisch"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Sogenannten abso ...\u00ab", "tokens": ["So\u00b7ge\u00b7nann\u00b7ten", "ab\u00b7so", "...", "\u00ab"], "token_info": ["word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "$(", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.11": {"text": "\u00bbnicht doch!\u00ab", "tokens": ["\u00bb", "nicht", "doch", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct"], "pos": ["$(", "PTKNEG", "ADV", "$.", "$("], "meter": "-+", "measure": "iambic.single"}, "line.12": {"text": "Unterbrach der Mufti mich und", "tokens": ["Un\u00b7ter\u00b7brach", "der", "Muf\u00b7ti", "mich", "und"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PPER", "KON"], "meter": "+-+-+-++", "measure": "unknown.measure.penta"}, "line.13": {"text": "Gab Befehl mir, wieder langaus", "tokens": ["Gab", "Be\u00b7fehl", "mir", ",", "wie\u00b7der", "lan\u00b7gaus"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "NN", "PPER", "$,", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Auf dem Sopha mich zu strecken.", "tokens": ["Auf", "dem", "So\u00b7pha", "mich", "zu", "stre\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "PTKZU", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.15": {"text": "\u00bbich will Euch durchaus nicht zwingen,", "tokens": ["\u00bb", "ich", "will", "Euch", "durc\u00b7haus", "nicht", "zwin\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.16": {"text": "Unsern Glauben anzunehmen,", "tokens": ["Un\u00b7sern", "Glau\u00b7ben", "an\u00b7zu\u00b7neh\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Den zu glauben hier Gesetz ist.", "tokens": ["Den", "zu", "glau\u00b7ben", "hier", "Ge\u00b7setz", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKZU", "VVFIN", "ADV", "NN", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "Ihr h\u00f6rt ruhig an mich, h\u00f6ret,", "tokens": ["Ihr", "h\u00f6rt", "ru\u00b7hig", "an", "mich", ",", "h\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "PPER", "$,", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.19": {"text": "Was Ihr denken, f\u00fchlen, glauben", "tokens": ["Was", "Ihr", "den\u00b7ken", ",", "f\u00fch\u00b7len", ",", "glau\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PWS", "PPER", "VVINF", "$,", "VVFIN", "$,", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "(denn Gedank', Gef\u00fchl und Glaube", "tokens": ["(", "denn", "Ge\u00b7dank'", ",", "Ge\u00b7f\u00fchl", "und", "Glau\u00b7be"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "KON", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Ist ja Eines!) sollt, und wenn dann", "tokens": ["Ist", "ja", "Ei\u00b7nes", "!", ")", "sollt", ",", "und", "wenn", "dann"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PIS", "$.", "$(", "VMFIN", "$,", "KON", "KOUS", "ADV"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.22": {"text": "Noch nach eines Jahr's Verlauf Ihr", "tokens": ["Noch", "nach", "ei\u00b7nes", "Jahr's", "Ver\u00b7lauf", "Ihr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "NN", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.23": {"text": "Christ seid \u2013 denn ich wei\u00df, Ihr seid es,", "tokens": ["Christ", "seid", "\u2013", "denn", "ich", "wei\u00df", ",", "Ihr", "seid", "es", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$(", "KON", "PPER", "VVFIN", "$,", "PPER", "VAFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.24": {"text": "Seid ein \u00e4chter Christ \u2013 so werdet", "tokens": ["Seid", "ein", "\u00e4ch\u00b7ter", "Christ", "\u2013", "so", "wer\u00b7det"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAIMP", "ART", "ADJA", "NN", "$(", "ADV", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.25": {"text": "Nach dem Paragraphe Sechszehn", "tokens": ["Nach", "dem", "Pa\u00b7ra\u00b7gra\u00b7phe", "Sechs\u00b7zehn"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "CARD"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.26": {"text": "Unsres Toleranz-Ediktes", "tokens": ["Uns\u00b7res", "To\u00b7le\u00b7ranz\u00b7E\u00b7dik\u00b7tes"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.27": {"text": "Ihr, wie's w\u00f6rtlich hei\u00dft, \u203aaus Unserm", "tokens": ["Ihr", ",", "wie's", "w\u00f6rt\u00b7lich", "hei\u00dft", ",", "\u203a", "aus", "Un\u00b7serm"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["PPER", "$,", "VVFIN", "ADJD", "VVFIN", "$,", "$(", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.28": {"text": "Horizont beseitigt,\u2039 n\u00e4mlich,", "tokens": ["Ho\u00b7ri\u00b7zont", "be\u00b7sei\u00b7tigt", ",", "\u2039", "n\u00e4m\u00b7lich", ","], "token_info": ["word", "word", "punct", "punct", "word", "punct"], "pos": ["NE", "VVPP", "$,", "$(", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.29": {"text": "Wenn Ihr nicht, was ich Euch lehrte", "tokens": ["Wenn", "Ihr", "nicht", ",", "was", "ich", "Euch", "lehr\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "$,", "PWS", "PPER", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.30": {"text": "Anerkennt als letztes Wissen:", "tokens": ["An\u00b7er\u00b7kennt", "als", "letz\u00b7tes", "Wis\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.31": {"text": "Aus dem Sterne, die Verkehrte", "tokens": ["Aus", "dem", "Ster\u00b7ne", ",", "die", "Ver\u00b7kehr\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.32": {"text": "Welt, sofort hinausgeschmissen.", "tokens": ["Welt", ",", "so\u00b7fort", "hin\u00b7aus\u00b7ge\u00b7schmis\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "H\u00f6rt nun weiter! Wir besitzen", "tokens": ["H\u00f6rt", "nun", "wei\u00b7ter", "!", "Wir", "be\u00b7sit\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVIMP", "ADV", "ADV", "$.", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Religion in Eurem Sinne", "tokens": ["Re\u00b7li\u00b7gi\u00b7on", "in", "Eu\u00b7rem", "Sin\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "PPOSAT", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Gar nicht; wir besitzen ", "tokens": ["Gar", "nicht", ";", "wir", "be\u00b7sit\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADV", "PTKNEG", "$.", "PPER", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Aber jenen \u00e4u\u00dferst starken,", "tokens": ["A\u00b7ber", "je\u00b7nen", "\u00e4u\u00b7\u00dferst", "star\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Der mit Wissen synonym ist.", "tokens": ["Der", "mit", "Wis\u00b7sen", "syn\u00b7o\u00b7nym", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Was Ich, was der Ober-Mufti", "tokens": ["Was", "Ich", ",", "was", "der", "O\u00b7ber\u00b7Muf\u00b7ti"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "PPER", "$,", "PRELS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Glaubt, ist Wissen und ist Glaube", "tokens": ["Glaubt", ",", "ist", "Wis\u00b7sen", "und", "ist", "Glau\u00b7be"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "VAFIN", "NN", "KON", "VAFIN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Jedes Einzelnen der ", "tokens": ["Je\u00b7des", "Ein\u00b7zel\u00b7nen", "der"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "ART"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.9": {"text": "Wie wir, ", "tokens": ["Wie", "wir", ","], "token_info": ["word", "word", "punct"], "pos": ["PWAV", "PPER", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.10": {"text": "Was ich glaube, das ist Wahrheit,", "tokens": ["Was", "ich", "glau\u00b7be", ",", "das", "ist", "Wahr\u00b7heit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "PDS", "VAFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Denn in mir ist ", "tokens": ["Denn", "in", "mir", "ist"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PPER", "VAFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.12": {"text": "Sind die Icher alle, gleichwie", "tokens": ["Sind", "die", "I\u00b7cher", "al\u00b7le", ",", "gleich\u00b7wie"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "ART", "NN", "PIS", "$,", "KON"], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.13": {"text": "Ich in ihnen. Und da Glauben", "tokens": ["Ich", "in", "ih\u00b7nen", ".", "Und", "da", "Glau\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "APPR", "PPER", "$.", "KON", "KOUS", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Eins mit F\u00fchlen ist und Denken:", "tokens": ["Eins", "mit", "F\u00fch\u00b7len", "ist", "und", "Den\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VAFIN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "F\u00fchl' und denke ich im Grunde", "tokens": ["F\u00fchl'", "und", "den\u00b7ke", "ich", "im", "Grun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "VVFIN", "PPER", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Ganz alleine, denn die Freiheit", "tokens": ["Ganz", "al\u00b7lei\u00b7ne", ",", "denn", "die", "Frei\u00b7heit"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Alles Wissens, F\u00fchlens, Denkens", "tokens": ["Al\u00b7les", "Wis\u00b7sens", ",", "F\u00fch\u00b7lens", ",", "Den\u00b7kens"], "token_info": ["word", "word", "punct", "word", "punct", "word"], "pos": ["PIAT", "NN", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "Ist beschr\u00e4nkt im Ober-Mufti.", "tokens": ["Ist", "be\u00b7schr\u00e4nkt", "im", "O\u00b7ber\u00b7Muf\u00b7ti", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Oder,\u00ab sprach er seufzend weiter,", "tokens": ["O\u00b7der", ",", "\u00ab", "sprach", "er", "seuf\u00b7zend", "wei\u00b7ter", ","], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "$(", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}, "line.21": {"text": "Gibt's hier rationale Hetzer,", "tokens": ["Gibt's", "hier", "ra\u00b7ti\u00b7o\u00b7na\u00b7le", "Het\u00b7zer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADJA", "NN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.22": {"text": "Die den Denkerplebs beth\u00f6ren;", "tokens": ["Die", "den", "Den\u00b7ker\u00b7plebs", "be\u00b7th\u00f6\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.23": {"text": "Giebt's hier, wie Ihr gleich sollt h\u00f6ren", "tokens": ["Giebt's", "hier", ",", "wie", "Ihr", "gleich", "sollt", "h\u00f6\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "$,", "PWAV", "PPER", "ADV", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.24": {"text": "Auch in unserm Reiche Ketzer!", "tokens": ["Auch", "in", "un\u00b7serm", "Rei\u00b7che", "Ket\u00b7zer", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Gott der G\u00f6tter und der Zeiten.", "tokens": ["Gott", "der", "G\u00f6t\u00b7ter", "und", "der", "Zei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihm der n\u00e4chst' an Macht und Herrschaft", "tokens": ["Ihm", "der", "n\u00e4chst'", "an", "Macht", "und", "Herr\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist Gott ", "tokens": ["Ist", "Gott"], "token_info": ["word", "word"], "pos": ["VAFIN", "NN"], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "Und der Gott des Reichthums ", "tokens": ["Und", "der", "Gott", "des", "Reicht\u00b7hums"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Gott und der gemeinen Hiebe;", "tokens": ["Gott", "und", "der", "ge\u00b7mei\u00b7nen", "Hie\u00b7be", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Fr\u00fcher hatten wir noch Andre,", "tokens": ["Fr\u00fc\u00b7her", "hat\u00b7ten", "wir", "noch", "And\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "PIS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die jedoch ob ihres Starrsinns,", "tokens": ["Die", "je\u00b7doch", "ob", "ih\u00b7res", "Starr\u00b7sinns", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "KOUS", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Den sie den prophet'schen Worten", "tokens": ["Den", "sie", "den", "pro\u00b7phet'\u00b7schen", "Wor\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unsres Ober-Muftithumes", "tokens": ["Uns\u00b7res", "O\u00b7ber\u00b7Muf\u00b7tit\u00b7hu\u00b7mes"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Gegen\u00fcber sich erfrechten,", "tokens": ["Ge\u00b7gen\u00b7\u00fc\u00b7ber", "sich", "er\u00b7frech\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Bis auf Weit'res suspendirt sind.", "tokens": ["Bis", "auf", "Weit'\u00b7res", "sus\u00b7pen\u00b7dirt", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "NN", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Welches Recht, die G\u00f6tter \u2013 ", "tokens": ["Wel\u00b7ches", "Recht", ",", "die", "G\u00f6t\u00b7ter", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWAT", "NN", "$,", "ART", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "Ausgenommen nur und ", "tokens": ["Aus\u00b7ge\u00b7nom\u00b7men", "nur", "und"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADV", "KON"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.9": {"text": "Abzusetzen, der Funktionen", "tokens": ["Ab\u00b7zu\u00b7set\u00b7zen", ",", "der", "Funk\u00b7ti\u00b7o\u00b7nen"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$,", "ART", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.10": {"text": "Sie zeitweilig zu entheben,", "tokens": ["Sie", "zeit\u00b7wei\u00b7lig", "zu", "ent\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Wenn sie st\u00f6rrig, eigensinnig,", "tokens": ["Wenn", "sie", "st\u00f6r\u00b7rig", ",", "ei\u00b7gen\u00b7sin\u00b7nig", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "$,", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Jedem Ober-Mufti zusteht.\u00ab", "tokens": ["Je\u00b7dem", "O\u00b7ber\u00b7Muf\u00b7ti", "zu\u00b7steht", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.9": {"line.1": {"text": "\u00bbdarf ich mir an Eure Zopfheit", "tokens": ["\u00bb", "darf", "ich", "mir", "an", "Eu\u00b7re", "Zopf\u00b7heit"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VMFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eine Frage wohl erlauben?\u00ab", "tokens": ["Ei\u00b7ne", "Fra\u00b7ge", "wohl", "er\u00b7lau\u00b7ben", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "\u00bbgerne!\u00ab", "tokens": ["\u00bb", "ger\u00b7ne", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "punct"], "pos": ["$(", "ADV", "$.", "$("], "meter": "+-", "measure": "trochaic.single"}}, "stanza.11": {"line.1": {"text": "\u00bbwie ist's m\u00f6glich, da\u00df Ihr", "tokens": ["\u00bb", "wie", "ist's", "m\u00f6g\u00b7lich", ",", "da\u00df", "Ihr"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "KOKOM", "VAFIN", "ADJD", "$,", "KOUS", "PPER"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "F\u00fcr so nah verwandte Dinge,", "tokens": ["F\u00fcr", "so", "nah", "ver\u00b7wand\u00b7te", "Din\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie die Pr\u00fcgel sind und Keile,", "tokens": ["Wie", "die", "Pr\u00fc\u00b7gel", "sind", "und", "Kei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VAFIN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zwei der G\u00f6tter habt statt Eines?\u00ab", "tokens": ["Zwei", "der", "G\u00f6t\u00b7ter", "habt", "statt", "Ei\u00b7nes", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["CARD", "ART", "NN", "VAFIN", "APPR", "PIS", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "\u00bbnah' verwandt? ", "tokens": ["\u00bb", "nah'", "ver\u00b7wandt", "?"], "token_info": ["punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "VVPP", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Und seid nah' daran, den Ketzern", "tokens": ["Und", "seid", "nah'", "da\u00b7ran", ",", "den", "Ket\u00b7zern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VAFIN", "ADJD", "PAV", "$,", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Beizutreten, welche eben", "tokens": ["Bei\u00b7zu\u00b7tre\u00b7ten", ",", "wel\u00b7che", "e\u00b7ben"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$,", "PRELS", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unsern ", "tokens": ["Un\u00b7sern"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Und als schlechte Egoisten", "tokens": ["Und", "als", "schlech\u00b7te", "E\u00b7gois\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADJA", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Nur den ", "tokens": ["Nur", "den"], "token_info": ["word", "word"], "pos": ["ADV", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "We\u00dfhalb wir sie Ateisten", "tokens": ["We\u00df\u00b7halb", "wir", "sie", "At\u00b7eis\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PPER", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Oder Tibianer nennen.\u00ab", "tokens": ["O\u00b7der", "Ti\u00b7bi\u00b7a\u00b7ner", "nen\u00b7nen", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["KON", "NE", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "\u00bbeuer Zopfigkeit verzeihen,\u00ab", "tokens": ["\u00bb", "eu\u00b7er", "Zop\u00b7fig\u00b7keit", "ver\u00b7zei\u00b7hen", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "NN", "VVINF", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sprach ich, \u00bbdoch es wird von Eurer", "tokens": ["Sprach", "ich", ",", "\u00bb", "doch", "es", "wird", "von", "Eu\u00b7rer"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "$(", "KON", "PPER", "VAFIN", "APPR", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mytheologie so dumm mir", "tokens": ["My\u00b7theo\u00b7lo\u00b7gie", "so", "dumm", "mir"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "ADJD", "PPER"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Als ob (G\u00f6the'n sehr verbessernd)", "tokens": ["Als", "ob", "(", "G\u00f6\u00b7the'n", "sehr", "ver\u00b7bes\u00b7sernd", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "$(", "NE", "ADV", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Drei mal drei zelot'sche Rabbi's", "tokens": ["Drei", "mal", "drei", "ze\u00b7lot'\u00b7sche", "Rab\u00b7bi's"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "ADV", "CARD", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und raviate Kirchenv\u00e4ter", "tokens": ["Und", "ra\u00b7vi\u00b7a\u00b7te", "Kir\u00b7chen\u00b7v\u00e4\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Tappten in dem Kopf herum mir.\u00ab", "tokens": ["Tapp\u00b7ten", "in", "dem", "Kopf", "he\u00b7rum", "mir", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "ART", "NN", "APZR", "PPER", "$.", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.14": {"line.1": {"text": "\u00bbes soll bald Euch Licht drinn werden,\u00ab", "tokens": ["\u00bb", "es", "soll", "bald", "Euch", "Licht", "drinn", "wer\u00b7den", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VMFIN", "ADV", "PPER", "NN", "ADV", "VAINF", "$,", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "L\u00e4chelte der Mufti, seine", "tokens": ["L\u00e4\u00b7chel\u00b7te", "der", "Muf\u00b7ti", ",", "sei\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["VVFIN", "ART", "NN", "$,", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ausgestreckte Sophalage", "tokens": ["Aus\u00b7ge\u00b7streck\u00b7te", "So\u00b7pha\u00b7la\u00b7ge"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Beibehaltend und sprach also:", "tokens": ["Bei\u00b7be\u00b7hal\u00b7tend", "und", "sprach", "al\u00b7so", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "ADV", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "\u00bbzwischen Pr\u00fcgel, Freund, und Keile", "tokens": ["\u00bb", "zwi\u00b7schen", "Pr\u00fc\u00b7gel", ",", "Freund", ",", "und", "Kei\u00b7le"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["$(", "APPR", "NN", "$,", "NN", "$,", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist nach Unserem Begriff hier", "tokens": ["Ist", "nach", "Un\u00b7se\u00b7rem", "Be\u00b7griff", "hier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Ein tieffrommer Unterschied noch.", "tokens": ["Ein", "tief\u00b7from\u00b7mer", "Un\u00b7ter\u00b7schied", "noch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Ateisten-Ketzer auf auch,", "tokens": ["A\u00b7teis\u00b7ten\u00b7Ket\u00b7zer", "auf", "auch", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Ist das rohe, allgemeine,", "tokens": ["Ist", "das", "ro\u00b7he", ",", "all\u00b7ge\u00b7mei\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "$,", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Demokratische, profane", "tokens": ["De\u00b7mo\u00b7kra\u00b7ti\u00b7sche", ",", "pro\u00b7fa\u00b7ne"], "token_info": ["word", "punct", "word"], "pos": ["NN", "$,", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Element, sind P\u00fcff' und Hiebe,", "tokens": ["E\u00b7le\u00b7ment", ",", "sind", "P\u00fcff'", "und", "Hie\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.12": {"text": "Welche unter ", "tokens": ["Wel\u00b7che", "un\u00b7ter"], "token_info": ["word", "word"], "pos": ["PWAT", "APPR"], "meter": "+-+-", "measure": "trochaic.di"}, "line.13": {"text": "Gleichberechtigt, gegenseitig", "tokens": ["Gleich\u00b7be\u00b7rech\u00b7tigt", ",", "ge\u00b7gen\u00b7sei\u00b7tig"], "token_info": ["word", "punct", "word"], "pos": ["VVPP", "$,", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Sich mit St\u00f6cken, Peitschen, H\u00e4nden", "tokens": ["Sich", "mit", "St\u00f6\u00b7cken", ",", "Peit\u00b7schen", ",", "H\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PRF", "APPR", "NN", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Mensch und Thier tagt\u00e4glich spenden.", "tokens": ["Mensch", "und", "Thier", "tag\u00b7t\u00e4g\u00b7lich", "spen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Heil'ge Element, mit Einem", "tokens": ["Heil'\u00b7ge", "E\u00b7le\u00b7ment", ",", "mit", "Ei\u00b7nem"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "APPR", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Worte: ist die ", "tokens": ["Wor\u00b7te", ":", "ist", "die"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$.", "VAFIN", "ART"], "meter": "+-+-", "measure": "trochaic.di"}, "line.18": {"text": "Ueber die von Uns und Pampeln", "tokens": ["Ue\u00b7ber", "die", "von", "Uns", "und", "Pam\u00b7peln"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "APPR", "PPER", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Nicht gesetzlich sanctionirten", "tokens": ["Nicht", "ge\u00b7setz\u00b7lich", "sanc\u00b7ti\u00b7o\u00b7nir\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["PTKNEG", "ADJD", "VVFIN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.20": {"text": "Kleinen Knecht- und Kinderstrafen;", "tokens": ["Klei\u00b7nen", "Knecht", "und", "Kin\u00b7der\u00b7stra\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "TRUNC", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Ueber P\u00fcffe, Ruthenhiebe,", "tokens": ["Ue\u00b7ber", "P\u00fcf\u00b7fe", ",", "Ru\u00b7then\u00b7hie\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.22": {"text": "Fu\u00dftritte und Katzenk\u00f6pfe,", "tokens": ["Fu\u00df\u00b7trit\u00b7te", "und", "Kat\u00b7zen\u00b7k\u00f6p\u00b7fe", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "++--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.23": {"text": "Kantschu-, Faust- und Backenschl\u00e4ge,", "tokens": ["Kant\u00b7schu", ",", "Faust", "und", "Ba\u00b7cken\u00b7schl\u00e4\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["TRUNC", "$,", "TRUNC", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.24": {"text": "Oder h\u00f6chstens \u00fcber Tabagieen-", "tokens": ["O\u00b7der", "h\u00f6chs\u00b7tens", "\u00fc\u00b7ber", "Ta\u00b7ba\u00b7gie\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "TRUNC"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.25": {"text": "Klubb's und Kneipen-Saufereien,", "tokens": ["Klub\u00b7b's", "und", "Knei\u00b7pen\u00b7Sau\u00b7fe\u00b7rei\u00b7en", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Und Casino's-, Harmonieen-", "tokens": ["Und", "Ca\u00b7si\u00b7no'\u00b7s", ",", "Har\u00b7mo\u00b7nie\u00b7en"], "token_info": ["word", "word", "punct", "word"], "pos": ["KON", "TRUNC", "$,", "TRUNC"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Oder Volksfest-Raufereien.", "tokens": ["O\u00b7der", "Volks\u00b7fest\u00b7Rau\u00b7fe\u00b7rei\u00b7en", "."], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.28": {"text": "Gott der Schlachten, ", "tokens": ["Gott", "der", "Schlach\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.29": {"text": "Und so fassen die Teisten,", "tokens": ["Und", "so", "fas\u00b7sen", "die", "Teis\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.30": {"text": "Unsres Tempels guten Schafe,", "tokens": ["Uns\u00b7res", "Tem\u00b7pels", "gu\u00b7ten", "Scha\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.31": {"text": "Auch die Pr\u00fcgel auf und nehmen", "tokens": ["Auch", "die", "Pr\u00fc\u00b7gel", "auf", "und", "neh\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "PTKVZ", "KON", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.32": {"text": "Sie als s\u00fc\u00dfe Himmelsstrafe.\u00ab", "tokens": ["Sie", "als", "s\u00fc\u00b7\u00dfe", "Him\u00b7mels\u00b7stra\u00b7fe", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "KOUS", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "\u00bbalso\u00ab, fragt' ich, \u00bbdie Tibianer", "tokens": ["\u00bb", "al\u00b7so", "\u00ab", ",", "fragt'", "ich", ",", "\u00bb", "die", "Ti\u00b7bi\u00b7a\u00b7ner"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word"], "pos": ["$(", "ADV", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "ART", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Oder Ateisten wollen", "tokens": ["O\u00b7der", "At\u00b7eis\u00b7ten", "wol\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["KON", "NN", "VMFIN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Prinzipiell nicht Pr\u00fcgel haben?\u00ab", "tokens": ["Prin\u00b7zi\u00b7pi\u00b7ell", "nicht", "Pr\u00fc\u00b7gel", "ha\u00b7ben", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PTKNEG", "NN", "VAFIN", "$.", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.16": {"line.1": {"text": "\u00bbnein!\u00ab erwiederte der Mufti.", "tokens": ["\u00bb", "nein", "!", "\u00ab", "er\u00b7wie\u00b7der\u00b7te", "der", "Muf\u00b7ti", "."], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$.", "$(", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbdiese unfromm-demokrat'schen", "tokens": ["\u00bb", "die\u00b7se", "un\u00b7from\u00b7mde\u00b7mo\u00b7krat'\u00b7schen"], "token_info": ["punct", "word", "word"], "pos": ["$(", "PDAT", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wichte nennen Keile: Keile!", "tokens": ["Wich\u00b7te", "nen\u00b7nen", "Kei\u00b7le", ":", "Kei\u00b7le", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "VVINF", "NN", "$.", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sondern nicht von der gemeinen", "tokens": ["Son\u00b7dern", "nicht", "von", "der", "ge\u00b7mei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "APPR", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Unsre h\u00f6here. Sie schelten", "tokens": ["Uns\u00b7re", "h\u00f6\u00b7he\u00b7re", ".", "Sie", "schel\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "ADJA", "$.", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Krieg und Zweikampf: Luxus-Keile,", "tokens": ["Krieg", "und", "Zwei\u00b7kampf", ":", "Lu\u00b7xus\u00b7Kei\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "KON", "NN", "$.", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Oder Keile nur im Gro\u00dfen;", "tokens": ["O\u00b7der", "Kei\u00b7le", "nur", "im", "Gro\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Leugnen ", "tokens": ["Leug\u00b7nen"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.9": {"text": "Gegen unsere dictirte", "tokens": ["Ge\u00b7gen", "un\u00b7se\u00b7re", "dic\u00b7tir\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Balsam-Pr\u00fcgel, die verlor'ner", "tokens": ["Bal\u00b7sam\u00b7Pr\u00fc\u00b7gel", ",", "die", "ver\u00b7lor'\u00b7ner"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$,", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Ehr' und Tugend Wunden heilet,", "tokens": ["Ehr'", "und", "Tu\u00b7gend", "Wun\u00b7den", "hei\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Nur Diejen'ge anerkennend,", "tokens": ["Nur", "Die\u00b7jen'\u00b7ge", "an\u00b7er\u00b7ken\u00b7nend", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Die der Mensch kraft angebor'ner", "tokens": ["Die", "der", "Mensch", "kraft", "an\u00b7ge\u00b7bor'\u00b7ner"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "ADJD", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Freiheit selber sich ertheilet.\u00ab", "tokens": ["Frei\u00b7heit", "sel\u00b7ber", "sich", "er\u00b7thei\u00b7let", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADV", "PRF", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "\u00bbeine Frage noch erlaubt mir,\u00ab", "tokens": ["\u00bb", "ei\u00b7ne", "Fra\u00b7ge", "noch", "er\u00b7laubt", "mir", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "ADV", "VVFIN", "PPER", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sprach ich nach erlangter Pr\u00fcgel-", "tokens": ["Sprach", "ich", "nach", "er\u00b7lang\u00b7ter", "Pr\u00fc\u00b7gel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "APPR", "ADJA", "TRUNC"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Kenntni\u00df, \u00bbEine noch, betreffend", "tokens": ["Kennt\u00b7ni\u00df", ",", "\u00bb", "Ei\u00b7ne", "noch", ",", "be\u00b7tref\u00b7fend"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word"], "pos": ["NN", "$,", "$(", "ART", "ADV", "$,", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Euern Gott der Liebe, ", "tokens": ["Eu\u00b7ern", "Gott", "der", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Mir f\u00e4llt's n\u00e4mlich auf, da\u00df er dem", "tokens": ["Mir", "f\u00e4llt's", "n\u00e4m\u00b7lich", "auf", ",", "da\u00df", "er", "dem"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$,", "KOUS", "PPER", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Namen nach ist der verkehrte", "tokens": ["Na\u00b7men", "nach", "ist", "der", "ver\u00b7kehr\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "VAFIN", "ART", "ADJA"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.7": {"text": "Liebesgott der Alten: ", "tokens": ["Lie\u00b7bes\u00b7gott", "der", "Al\u00b7ten", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "Und so m\u00f6cht' ich gerne wissen,", "tokens": ["Und", "so", "m\u00f6cht'", "ich", "ger\u00b7ne", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Ob er anders auch geartet", "tokens": ["Ob", "er", "an\u00b7ders", "auch", "ge\u00b7ar\u00b7tet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Als der unmoralisch-lose,", "tokens": ["Als", "der", "un\u00b7mo\u00b7ra\u00b7lischlo\u00b7se", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Kleine, flatterhafte Pfeilsch\u00fctz?", "tokens": ["Klei\u00b7ne", ",", "flat\u00b7ter\u00b7haf\u00b7te", "Pfeil\u00b7sch\u00fctz", "?"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJA", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Als der Bringer s\u00fc\u00dfen Schmerzes;", "tokens": ["Als", "der", "Brin\u00b7ger", "s\u00fc\u00b7\u00dfen", "Schmer\u00b7zes", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Als der himmlisch-holde Schalk", "tokens": ["Als", "der", "himm\u00b7lischhol\u00b7de", "Schalk"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.14": {"text": "Jener gro\u00dfen, ernsten Liebe", "tokens": ["Je\u00b7ner", "gro\u00b7\u00dfen", ",", "erns\u00b7ten", "Lie\u00b7be"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PDAT", "ADJA", "$,", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Die das All schuf und gestaltet,", "tokens": ["Die", "das", "All", "schuf", "und", "ge\u00b7stal\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "KON", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Der, so klein, als gr\u00f6\u00dfter Heros", "tokens": ["Der", ",", "so", "klein", ",", "als", "gr\u00f6\u00df\u00b7ter", "He\u00b7ros"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "$,", "ADV", "ADJD", "$,", "KOUS", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Ueber alle Wesen schaltet?", "tokens": ["Ue\u00b7ber", "al\u00b7le", "We\u00b7sen", "schal\u00b7tet", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "Als Cupido, ", "tokens": ["Als", "Cu\u00b7pi\u00b7do", ","], "token_info": ["word", "word", "punct"], "pos": ["KOUS", "NE", "$,"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.18": {"line.1": {"text": "\u00bbsohn des ", "tokens": ["\u00bb", "sohn", "des"], "token_info": ["punct", "word", "word"], "pos": ["$(", "APPR", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Hat in unserm Reich mit ", "tokens": ["Hat", "in", "un\u00b7serm", "Reich", "mit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN", "APPR"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wenig oder Nichts zu schaffen.", "tokens": ["We\u00b7nig", "o\u00b7der", "Nichts", "zu", "schaf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "PIS", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Er ist Knabe noch an Jahren", "tokens": ["Er", "ist", "Kna\u00b7be", "noch", "an", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Aber ernster, w\u00fcrd'ger Haltung,", "tokens": ["A\u00b7ber", "erns\u00b7ter", ",", "w\u00fcrd'\u00b7ger", "Hal\u00b7tung", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sittig, anstandsvoll gekleidet;", "tokens": ["Sit\u00b7tig", ",", "an\u00b7stands\u00b7voll", "ge\u00b7klei\u00b7det", ";"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Eine Peitsche in der Rechten,", "tokens": ["Ei\u00b7ne", "Peit\u00b7sche", "in", "der", "Rech\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Strebt er, Maid- und J\u00fcnglingsseele", "tokens": ["Strebt", "er", ",", "Mai\u00b7d", "und", "J\u00fcng\u00b7lings\u00b7see\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "TRUNC", "KON", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.9": {"text": "Stets zur Liebe anzufeuern,", "tokens": ["Stets", "zur", "Lie\u00b7be", "an\u00b7zu\u00b7feu\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Auf da\u00df nimmer es an Knechten", "tokens": ["Auf", "da\u00df", "nim\u00b7mer", "es", "an", "Knech\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "ADV", "PPER", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Unserm theuern Staate fehle", "tokens": ["Un\u00b7serm", "theu\u00b7ern", "Staa\u00b7te", "feh\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Oder, deutlicher, an Steuern.\u00ab", "tokens": ["O\u00b7der", ",", "deut\u00b7li\u00b7cher", ",", "an", "Steu\u00b7ern", ".", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "ADJD", "$,", "APPR", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "\u00bbalso ", "tokens": ["\u00bb", "al\u00b7so"], "token_info": ["punct", "word"], "pos": ["$(", "ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "\u00bbja,", "tokens": ["\u00bb", "ja", ","], "token_info": ["punct", "word", "punct"], "pos": ["$(", "PTKANT", "$,"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Freilich! Knabe ist und bleibt er,", "tokens": ["Frei\u00b7lich", "!", "Kna\u00b7be", "ist", "und", "bleibt", "er", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "NN", "VAFIN", "KON", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn wenn gr\u00f6\u00dfer er und \u00e4lter", "tokens": ["Denn", "wenn", "gr\u00f6\u00b7\u00dfer", "er", "und", "\u00e4l\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADJD", "PPER", "KON", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "W\u00fcrde, k\u00f6nnte er vielleicht ja", "tokens": ["W\u00fcr\u00b7de", ",", "k\u00f6nn\u00b7te", "er", "viel\u00b7leicht", "ja"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "$,", "VMFIN", "PPER", "ADV", "ADV"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Sclave werden, wo er herrschte;", "tokens": ["Scla\u00b7ve", "wer\u00b7den", ",", "wo", "er", "herrschte", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAINF", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "K\u00f6nnte er ein M\u00e4dchen finden,", "tokens": ["K\u00f6nn\u00b7te", "er", "ein", "M\u00e4d\u00b7chen", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Dem er weihete sein Leben;", "tokens": ["Dem", "er", "wei\u00b7he\u00b7te", "sein", "Le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "K\u00f6nnt' sich ", "tokens": ["K\u00f6nnt'", "sich"], "token_info": ["word", "word"], "pos": ["VMFIN", "PRF"], "meter": "+-", "measure": "trochaic.single"}, "line.10": {"text": "Und dann sein Gesch\u00e4ft aufgeben!\u00ab", "tokens": ["Und", "dann", "sein", "Ge\u00b7sch\u00e4ft", "auf\u00b7ge\u00b7ben", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "\u00bbdas hei\u00dft: wenn er Eh'mann w\u00e4re,", "tokens": ["\u00bb", "das", "hei\u00dft", ":", "wenn", "er", "Eh'\u00b7mann", "w\u00e4\u00b7re", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VVFIN", "$.", "KOUS", "PPER", "NN", "VAFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "W\u00e4r' die Liebe nicht sein Reich mehr?", "tokens": ["W\u00e4r'", "die", "Lie\u00b7be", "nicht", "sein", "Reich", "mehr", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PTKNEG", "PPOSAT", "NN", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihr habt hier h\u00f6chst wunderbare\u00ab", "tokens": ["Ihr", "habt", "hier", "h\u00f6chst", "wun\u00b7der\u00b7ba\u00b7re", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJA", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "(wagte ich hinzuzuf\u00fcgen)", "tokens": ["(", "wag\u00b7te", "ich", "hin\u00b7zu\u00b7zu\u00b7f\u00fc\u00b7gen", ")"], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "\u00bbansichten von Eh' und Liebe!", "tokens": ["\u00bb", "an\u00b7sich\u00b7ten", "von", "Eh'", "und", "Lie\u00b7be", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und noch wunderbarer sind,", "tokens": ["Und", "noch", "wun\u00b7der\u00b7ba\u00b7rer", "sind", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Wie ich leider selbst vor Kurzem", "tokens": ["Wie", "ich", "lei\u00b7der", "selbst", "vor", "Kur\u00b7zem"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Schon erfahren mu\u00dfte, diese", "tokens": ["Schon", "er\u00b7fah\u00b7ren", "mu\u00df\u00b7te", ",", "die\u00b7se"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ADV", "VVINF", "VMFIN", "$,", "PDAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Ansichten manifestiret.", "tokens": ["An\u00b7sich\u00b7ten", "ma\u00b7ni\u00b7fes\u00b7ti\u00b7ret", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Denn sich trauen lassen, hei\u00dft hier:", "tokens": ["Denn", "sich", "trau\u00b7en", "las\u00b7sen", ",", "hei\u00dft", "hier", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PRF", "VVINF", "VVINF", "$,", "VVFIN", "ADV", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.11": {"text": "Seiner Seele sch\u00f6n're H\u00e4lfte", "tokens": ["Sei\u00b7ner", "See\u00b7le", "sch\u00f6n'\u00b7re", "H\u00e4lf\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Ach! auf immerdar verlieren;", "tokens": ["Ach", "!", "auf", "im\u00b7mer\u00b7dar", "ver\u00b7lie\u00b7ren", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "APPR", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Hei\u00dft: die Herzerkor'ne, statt in", "tokens": ["Hei\u00dft", ":", "die", "Herz\u00b7er\u00b7kor'\u00b7ne", ",", "statt", "in"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "$.", "ART", "NN", "$,", "KOUI", "APPR"], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.14": {"text": "S\u00fc\u00dfer Eh' mit ihr zu leben", "tokens": ["S\u00fc\u00b7\u00dfer", "Eh'", "mit", "ihr", "zu", "le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "APPR", "PPER", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Als \u2013 ich will's so nennen \u2013 ", "tokens": ["Als", "\u2013", "ich", "will's", "so", "nen\u00b7nen", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "PPER", "VMFIN", "ADV", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.16": {"text": "Euern Dienern \u00fcbergeben!\u00ab", "tokens": ["Eu\u00b7ern", "Die\u00b7nern", "\u00fc\u00b7ber\u00b7ge\u00b7ben", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "W\u00e4hrenddem ich diese Worte", "tokens": ["W\u00e4h\u00b7rend\u00b7dem", "ich", "die\u00b7se", "Wor\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "Schmerzbewegt, entr\u00fcstet sprach,", "tokens": ["Schmerz\u00b7be\u00b7wegt", ",", "ent\u00b7r\u00fcs\u00b7tet", "sprach", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVPP", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.19": {"text": "Hielt der Mufti einen scharfen,", "tokens": ["Hielt", "der", "Muf\u00b7ti", "ei\u00b7nen", "schar\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "Pr\u00fcfenden Blick auf mich gerichtet,", "tokens": ["Pr\u00fc\u00b7fen\u00b7den", "Blick", "auf", "mich", "ge\u00b7rich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "PPER", "VVPP", "$,"], "meter": "+--++--+-", "measure": "trochaic.tetra.relaxed"}, "line.21": {"text": "Lie\u00df denselben aber fallen,", "tokens": ["Lie\u00df", "den\u00b7sel\u00b7ben", "a\u00b7ber", "fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.22": {"text": "Als ich ihm mein Haupt zuwandte,", "tokens": ["Als", "ich", "ihm", "mein", "Haupt", "zu\u00b7wand\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.23": {"text": "Und gab dann mir diese Antwort:", "tokens": ["Und", "gab", "dann", "mir", "die\u00b7se", "Ant\u00b7wort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PPER", "PDAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.21": {"line.1": {"text": "\u00bbhei\u00dft denn, Freund, sich trauen lassen,", "tokens": ["\u00bb", "hei\u00dft", "denn", ",", "Freund", ",", "sich", "trau\u00b7en", "las\u00b7sen", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "$,", "NN", "$,", "PRF", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nicht bei Euch und \u00fcberall auch:", "tokens": ["Nicht", "bei", "Euch", "und", "\u00fc\u00b7be\u00b7rall", "auch", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "PPER", "KON", "ADV", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "Opfern auf der Frau Gemahlin?", "tokens": ["Op\u00b7fern", "auf", "der", "Frau", "Ge\u00b7mah\u00b7lin", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wahre Liebe ", "tokens": ["Wah\u00b7re", "Lie\u00b7be"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Himmlischer als irgend einer!", "tokens": ["Himm\u00b7li\u00b7scher", "als", "ir\u00b7gend", "ei\u00b7ner", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ADV", "ART", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wahre, gegenseitige Liebe", "tokens": ["Wah\u00b7re", ",", "ge\u00b7gen\u00b7sei\u00b7ti\u00b7ge", "Lie\u00b7be"], "token_info": ["word", "punct", "word", "word"], "pos": ["ADJA", "$,", "ADJA", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Lieb', die W\u00fcrde, Halt und Glanz sucht", "tokens": ["Lieb'", ",", "die", "W\u00fcr\u00b7de", ",", "Halt", "und", "Glanz", "sucht"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "ART", "NN", "$,", "NN", "KON", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Mehr als sie in sich empfindet,", "tokens": ["Mehr", "als", "sie", "in", "sich", "emp\u00b7fin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "PPER", "APPR", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Retten wir durch schnelle Trennung,", "tokens": ["Ret\u00b7ten", "wir", "durch", "schnel\u00b7le", "Tren\u00b7nung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Deren Wunde bald vernarbt ist,", "tokens": ["De\u00b7ren", "Wun\u00b7de", "bald", "ver\u00b7narbt", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "ADV", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Vor dem grausen Schmerz und Elend", "tokens": ["Vor", "dem", "grau\u00b7sen", "Schmerz", "und", "E\u00b7lend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Zwangvereinigten Entzweitseins.", "tokens": ["Zwang\u00b7ver\u00b7ei\u00b7nig\u00b7ten", "Ent\u00b7zweit\u00b7seins", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+---+-", "measure": "unknown.measure.tri"}}, "stanza.22": {"line.1": {"text": "Aechte, wahre Liebe h\u00fctet", "tokens": ["A\u00b7ech\u00b7te", ",", "wah\u00b7re", "Lie\u00b7be", "h\u00fc\u00b7tet"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ihre s\u00fc\u00dfe Freiheit besser", "tokens": ["Ih\u00b7re", "s\u00fc\u00b7\u00dfe", "Frei\u00b7heit", "bes\u00b7ser"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Als die fl\u00fccht'ge, die den Titel", "tokens": ["Als", "die", "fl\u00fccht'\u00b7ge", ",", "die", "den", "Ti\u00b7tel"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "$,", "PRELS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sucht und findet, der ihr Schutz giebt. \u2013", "tokens": ["Sucht", "und", "fin\u00b7det", ",", "der", "ihr", "Schutz", "giebt", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Hier, Freund, schlie\u00dft die Liebes-Ehen", "tokens": ["Hier", ",", "Freund", ",", "schlie\u00dft", "die", "Lie\u00b7bes\u00b7E\u00b7hen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "NN", "$,", "VVFIN", "ART", "NN"], "meter": "-+--++-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Wirklich und allein der Himmel,", "tokens": ["Wirk\u00b7lich", "und", "al\u00b7lein", "der", "Him\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wirklich und allein Gott ", "tokens": ["Wirk\u00b7lich", "und", "al\u00b7lein", "Gott"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "KON", "ADV", "NN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.8": {"text": "Hier bleibt jeder Liebste Liebster!", "tokens": ["Hier", "bleibt", "je\u00b7der", "Liebs\u00b7te", "Liebs\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Hier bleibt der Verbindung Myrthe", "tokens": ["Hier", "bleibt", "der", "Ver\u00b7bin\u00b7dung", "Myr\u00b7the"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Bl\u00fchend, wie das Haar auch graut!", "tokens": ["Bl\u00fc\u00b7hend", ",", "wie", "das", "Haar", "auch", "graut", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PWAV", "ART", "NN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Hier bleibt von den Liebe-Frauen", "tokens": ["Hier", "bleibt", "von", "den", "Lie\u00b7be\u00b7Frau\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Jede eine Himmelsbraut!", "tokens": ["Je\u00b7de", "ei\u00b7ne", "Him\u00b7mels\u00b7braut", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "Hier, Freund, ", "tokens": ["Hier", ",", "Freund", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADV", "$,", "NN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.14": {"text": "Weil man selber sich hier traut!\u00ab", "tokens": ["Weil", "man", "sel\u00b7ber", "sich", "hier", "traut", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "ADV", "PRF", "ADV", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}