{"textgrid.poem.36983": {"metadata": {"author": {"name": "Gla\u00dfbrenner, Adolf", "birth": "N.A.", "death": "N.A."}, "title": "Der Stiefelputzer", "genre": "verse", "period": "N.A.", "pub_year": 1843, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbo weh mir!\u00ab so schrie ich am Morgen darauf", "tokens": ["\u00bb", "o", "weh", "mir", "!", "\u00ab", "so", "schrie", "ich", "am", "Mor\u00b7gen", "da\u00b7rauf"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "FM", "ADV", "PPER", "$.", "$(", "ADV", "VVFIN", "PPER", "APPRART", "NN", "PAV"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Die Augen ge\u00f6ffenet kaum noch.", "tokens": ["Die", "Au\u00b7gen", "ge\u00b7\u00f6f\u00b7fe\u00b7net", "kaum", "noch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich f\u00fchlte schon wirkliche Pr\u00fcgel, trotzdem", "tokens": ["Ich", "f\u00fchl\u00b7te", "schon", "wirk\u00b7li\u00b7che", "Pr\u00fc\u00b7gel", ",", "trotz\u00b7dem"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADJA", "NN", "$,", "PAV"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Mich umfing ein lieblicher Traum noch.", "tokens": ["Mich", "um\u00b7fing", "ein", "lieb\u00b7li\u00b7cher", "Traum", "noch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "ADV", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "\u00bbhilf, Himmel! Was ist das? Er, L\u00fcmmel, wird Er \u2013", "tokens": ["\u00bb", "hilf", ",", "Him\u00b7mel", "!", "Was", "ist", "das", "?", "Er", ",", "L\u00fcm\u00b7mel", ",", "wird", "Er", "\u2013"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVIMP", "$,", "NN", "$.", "PWS", "VAFIN", "PDS", "$.", "PPER", "$,", "NN", "$,", "VAFIN", "PPER", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Au! Au! \u2013 wohl in Ruhe mich lassen!\u00ab", "tokens": ["Au", "!", "Au", "!", "\u2013", "wohl", "in", "Ru\u00b7he", "mich", "las\u00b7sen", "!", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "NN", "$.", "$(", "ADV", "APPR", "NN", "PPER", "VVINF", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "So schrie ich, doch konnt' ich mich selber noch nicht,", "tokens": ["So", "schrie", "ich", ",", "doch", "konnt'", "ich", "mich", "sel\u00b7ber", "noch", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADV", "VMFIN", "PPER", "PRF", "ADV", "ADV", "PTKNEG", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Geschweige den St\u00f6renfried fassen.", "tokens": ["Ge\u00b7schwei\u00b7ge", "den", "St\u00f6\u00b7ren\u00b7fried", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.3": {"line.1": {"text": "Derselbe, er stellte sich vor als Wichsier,", "tokens": ["Der\u00b7sel\u00b7be", ",", "er", "stell\u00b7te", "sich", "vor", "als", "Wich\u00b7sier", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "$,", "PPER", "VVFIN", "PRF", "APPR", "KOUS", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Als ich endlich vollst\u00e4ndig erwachte;", "tokens": ["Als", "ich", "end\u00b7lich", "voll\u00b7st\u00e4n\u00b7dig", "er\u00b7wach\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Er klopfete spanischen Rohres mich aus;", "tokens": ["Er", "klop\u00b7fe\u00b7te", "spa\u00b7ni\u00b7schen", "Roh\u00b7res", "mich", "aus", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "PPER", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Die Comtesse, die Lotte, sie lachte.", "tokens": ["Die", "Com\u00b7tes\u00b7se", ",", "die", "Lot\u00b7te", ",", "sie", "lach\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "NE", "$,", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Sie lachte, bis da\u00df mir der Klopfer befahl", "tokens": ["Sie", "lach\u00b7te", ",", "bis", "da\u00df", "mir", "der", "Klop\u00b7fer", "be\u00b7fahl"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KON", "KOUS", "PPER", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Nunmehr mir die Kleider zu rein'gen", "tokens": ["Nun\u00b7mehr", "mir", "die", "Klei\u00b7der", "zu", "rein'\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Und ihm, da\u00df er ordentlich aus mich geklopft,", "tokens": ["Und", "ihm", ",", "da\u00df", "er", "or\u00b7dent\u00b7lich", "aus", "mich", "ge\u00b7klopft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "KOUS", "PPER", "ADJD", "APPR", "PPER", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Durch Siegel und Schrift zu beschein'gen.", "tokens": ["Durch", "Sie\u00b7gel", "und", "Schrift", "zu", "be\u00b7schein'\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.5": {"line.1": {"text": "Dann fuhr mit 'ner B\u00fcrste er \u00fcber den Frack,", "tokens": ["Dann", "fuhr", "mit", "'ner", "B\u00fcrs\u00b7te", "er", "\u00fc\u00b7ber", "den", "Frack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ADJA", "NN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Den seinigen, einige Mal sich;", "tokens": ["Den", "sei\u00b7ni\u00b7gen", ",", "ei\u00b7ni\u00b7ge", "Mal", "sich", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPOSS", "$,", "PIAT", "NN", "PRF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Sang mir das \u00bbHeil, Pampel!\u00ab die Volkshymne, vor", "tokens": ["Sang", "mir", "das", "\u00bb", "Heil", ",", "Pam\u00b7pel", "!", "\u00ab", "die", "Volks\u00b7hym\u00b7ne", ",", "vor"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "punct", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "ART", "$(", "NN", "$,", "NE", "$.", "$(", "ART", "NN", "$,", "APPR"], "meter": "++--+--+--+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Mit vielem Gef\u00fchl, und empfahl sich.", "tokens": ["Mit", "vie\u00b7lem", "Ge\u00b7f\u00fchl", ",", "und", "emp\u00b7fahl", "sich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "$,", "KON", "VVFIN", "PRF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.6": {"line.1": {"text": "\u00bber ist,\u00ab so erkl\u00e4rte mir Lotte, das Bad", "tokens": ["\u00bb", "er", "ist", ",", "\u00ab", "so", "er\u00b7kl\u00e4r\u00b7te", "mir", "Lot\u00b7te", ",", "das", "Bad"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "PPER", "VAFIN", "$,", "$(", "ADV", "VVFIN", "PPER", "NE", "$,", "PRELS", "NE"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Von rothem Champagner bereitend,", "tokens": ["Von", "ro\u00b7them", "Cham\u00b7pag\u00b7ner", "be\u00b7rei\u00b7tend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "\u00bbaus\u00fcbender Ministerialrath, im Fach", "tokens": ["\u00bb", "aus\u00b7\u00fc\u00b7ben\u00b7der", "Mi\u00b7nis\u00b7te\u00b7ri\u00b7al\u00b7rath", ",", "im", "Fach"], "token_info": ["punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "ADJA", "NN", "$,", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der spanischen R\u00f6hre arbeitend.", "tokens": ["Der", "spa\u00b7ni\u00b7schen", "R\u00f6h\u00b7re", "ar\u00b7bei\u00b7tend", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.7": {"line.1": {"text": "Da die B\u00fcrger den Kopf sich mit schlechten Ideen", "tokens": ["Da", "die", "B\u00fcr\u00b7ger", "den", "Kopf", "sich", "mit", "schlech\u00b7ten", "I\u00b7deen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "PRF", "APPR", "ADJA", "NN"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.2": {"text": "Im Gespr\u00e4ch und aus B\u00fcchern vollpfropfen,", "tokens": ["Im", "Ge\u00b7spr\u00e4ch", "und", "aus", "B\u00fc\u00b7chern", "voll\u00b7pfrop\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "APPR", "NN", "VVINF", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "So l\u00e4\u00dft die Regierung tagt\u00e4glich sie", "tokens": ["So", "l\u00e4\u00dft", "die", "Re\u00b7gie\u00b7rung", "tag\u00b7t\u00e4g\u00b7lich", "sie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "PPER"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Des Morgens geh\u00f6rig ausklopfen.", "tokens": ["Des", "Mor\u00b7gens", "ge\u00b7h\u00f6\u00b7rig", "aus\u00b7klop\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VVIZU", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.8": {"line.1": {"text": "Ich lachte, weil Du, der Du freilich noch nicht", "tokens": ["Ich", "lach\u00b7te", ",", "weil", "Du", ",", "der", "Du", "frei\u00b7lich", "noch", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "$,", "PRELS", "PPER", "ADV", "ADV", "PTKNEG"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Dich an diese Erfrischung gew\u00f6hnt hast,", "tokens": ["Dich", "an", "die\u00b7se", "Er\u00b7fri\u00b7schung", "ge\u00b7w\u00f6hnt", "hast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PDAT", "NN", "VVPP", "VAFIN", "$,"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Die kein Dummdummdummer entbehren mehr mag,", "tokens": ["Die", "kein", "Dumm\u00b7dumm\u00b7dum\u00b7mer", "ent\u00b7beh\u00b7ren", "mehr", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "ADV", "VMFIN", "$,"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "So erg\u00f6tzlich gepl\u00e4rrt und gest\u00f6hnt hast.\u00ab", "tokens": ["So", "er\u00b7g\u00f6tz\u00b7lich", "ge\u00b7pl\u00e4rrt", "und", "ge\u00b7st\u00f6hnt", "hast", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "VVPP", "KON", "VVPP", "VAFIN", "$.", "$("], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}}}}