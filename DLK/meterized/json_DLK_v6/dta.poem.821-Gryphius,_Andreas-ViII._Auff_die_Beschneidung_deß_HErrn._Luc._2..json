{"dta.poem.821": {"metadata": {"author": {"name": "Gryphius, Andreas", "birth": "N.A.", "death": "N.A."}, "title": "ViII.  Auff die Beschneidung de\u00df HErrn.  \n Luc. 2.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1650", "urn": "urn:nbn:de:kobv:b4-20218-7", "language": ["de:0.99"], "booktitle": "Gryphius, Andreas: Teutsche Reim-Gedichte. Frankfurt (Main), 1650."}, "poem": {"stanza.1": {"line.1": {"text": "O Blut! o reines Blut! das meine Blutschuld wendet! ", "tokens": ["O", "Blut", "!", "o", "rei\u00b7nes", "Blut", "!", "das", "mei\u00b7ne", "Blut\u00b7schuld", "wen\u00b7det", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "FM", "ADJA", "NN", "$.", "ART", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "O Werthes Kind das mich zu Gottes Kinde mach\u2019t", "tokens": ["O", "Wert\u00b7hes", "Kind", "das", "mich", "zu", "Got\u00b7tes", "Kin\u00b7de", "mach't"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "ART", "PPER", "APPR", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "O Glantz der Herrligkeit/ der die sehr lange Nacht", "tokens": ["O", "Glantz", "der", "Herr\u00b7lig\u00b7keit", "/", "der", "die", "sehr", "lan\u00b7ge", "Nacht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "NN", "ART", "NN", "$(", "ART", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vnd alte Finstern\u00fc\u00df auff diesen tag vollendet!", "tokens": ["Vnd", "al\u00b7te", "Fins\u00b7ter\u00b7n\u00fc\u00df", "auff", "die\u00b7sen", "tag", "voll\u00b7en\u00b7det", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "O Schatz; den vns Gott selbst/ de\u00df Reichthumbs abgrund", "tokens": ["O", "Schatz", ";", "den", "vns", "Gott", "selbst", "/", "de\u00df", "Reicht\u00b7humbs", "ab\u00b7grund"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NN", "$.", "ART", "PPER", "NN", "ADV", "$(", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "sendet! ", "tokens": ["sen\u00b7det", "!"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "O Namen/ der mir hat den Namen wieder-bracht", "tokens": ["O", "Na\u00b7men", "/", "der", "mir", "hat", "den", "Na\u00b7men", "wie\u00b7der\u00b7bracht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "NN", "$(", "PRELS", "PPER", "VAFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df ich de\u00df h\u00f6chsten Bild/ vnd der mich seelig macht", "tokens": ["Da\u00df", "ich", "de\u00df", "h\u00f6chs\u00b7ten", "Bild", "/", "vnd", "der", "mich", "see\u00b7lig", "macht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "$(", "KON", "ART", "PPER", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vnd herrlich/ wenn mich S\u00fcnd v\u00f1 Todt vnd Teufel sch\u00e4ndet.", "tokens": ["Vnd", "herr\u00b7lich", "/", "wenn", "mich", "S\u00fcnd", "v\u00f1", "Todt", "vnd", "Teu\u00b7fel", "sch\u00e4n\u00b7det", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$(", "KOUS", "PPER", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "O H\u00f6chste Reinigkeit nimb alles von mir hin", "tokens": ["O", "H\u00f6chs\u00b7te", "Rei\u00b7nig\u00b7keit", "nimb", "al\u00b7les", "von", "mir", "hin"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "VVFIN", "PIS", "APPR", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Damit von Sathan ich so sehr verstellet bin.", "tokens": ["Da\u00b7mit", "von", "Sa\u00b7than", "ich", "so", "sehr", "ver\u00b7stel\u00b7let", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "APPR", "NE", "PPER", "ADV", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Schneid weg/ womit mich wil die rohe welt anbinden.", "tokens": ["Schneid", "weg", "/", "wo\u00b7mit", "mich", "wil", "die", "ro\u00b7he", "welt", "an\u00b7bin\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$(", "PWAV", "PPER", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Schneid weg was jrrdisch heist/ Pracht/ Ehrgeitz/ Frewd", "tokens": ["Schneid", "weg", "was", "jrr\u00b7disch", "heist", "/", "Pracht", "/", "Ehr\u00b7geitz", "/", "Frewd"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NN", "ADV", "PWS", "PPER", "VVFIN", "$(", "NN", "$(", "NN", "$(", "NN"], "meter": "-+-+--++-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "vnd Lust/ ", "tokens": ["vnd", "Lust", "/"], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$("], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Neyd/ Zweifel/ Angst vnd Furcht/ wasch ab der S\u00fcnden", "tokens": ["Neyd", "/", "Zwei\u00b7fel", "/", "Angst", "vnd", "Furcht", "/", "wasch", "ab", "der", "S\u00fcn\u00b7den"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$(", "NN", "$(", "NN", "KON", "NN", "$(", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "wust ", "tokens": ["wust"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Darmit ich m\u00f6ge rein/ das reine Wohnhau\u00df finden.", "tokens": ["Dar\u00b7mit", "ich", "m\u00f6\u00b7ge", "rein", "/", "das", "rei\u00b7ne", "Wohn\u00b7hau\u00df", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "ADJD", "$(", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}