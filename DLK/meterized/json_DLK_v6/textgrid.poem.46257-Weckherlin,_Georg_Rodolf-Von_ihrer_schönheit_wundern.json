{"textgrid.poem.46257": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Von ihrer sch\u00f6nheit wundern", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Seind es haar oder garn das krauslecht reine gold,", "tokens": ["Seind", "es", "haar", "o\u00b7der", "garn", "das", "kraus\u00b7lecht", "rei\u00b7ne", "gold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "KON", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "nach dessen purem schatz die g\u00f6tter ein verlangen?", "tokens": ["nach", "des\u00b7sen", "pu\u00b7rem", "schatz", "die", "g\u00f6t\u00b7ter", "ein", "ver\u00b7lan\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "ADJA", "NN", "ART", "ADJA", "ART", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "ach! es seind zarte haar, meiner lieb werter sold:", "tokens": ["ach", "!", "es", "seind", "zar\u00b7te", "haar", ",", "mei\u00b7ner", "lieb", "wer\u00b7ter", "sold", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "PPER", "VAFIN", "ADJA", "NN", "$,", "PPOSAT", "ADJD", "VAINF", "VMFIN", "$."], "meter": "+--+-+--+--+", "measure": "iambic.penta.invert"}, "line.4": {"text": "nein! es seind starke garn, da sich die seelen fangen.", "tokens": ["nein", "!", "es", "seind", "star\u00b7ke", "garn", ",", "da", "sich", "die", "see\u00b7len", "fan\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PPER", "VAFIN", "ADJA", "NN", "$,", "KOUS", "PRF", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}}, "stanza.2": {"line.1": {"text": "Ein gestirn oder stirn ist dan das helfenbein,", "tokens": ["Ein", "ge\u00b7stirn", "o\u00b7der", "stirn", "ist", "dan", "das", "hel\u00b7fen\u00b7bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADJD", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "darauf sich mayestet, weisheit und zucht erfreuet?", "tokens": ["da\u00b7rauf", "sich", "ma\u00b7ye\u00b7stet", ",", "weis\u00b7heit", "und", "zucht", "er\u00b7freu\u00b7et", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PRF", "VVFIN", "$,", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "es ist ein glatte stirn, die hofnung meiner pein,", "tokens": ["es", "ist", "ein", "glat\u00b7te", "stirn", ",", "die", "hof\u00b7nung", "mei\u00b7ner", "pein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "nein! es ist ein gestirn, das die freche bedr\u00e4uet.", "tokens": ["nein", "!", "es", "ist", "ein", "ge\u00b7stirn", ",", "das", "die", "fre\u00b7che", "be\u00b7dr\u00e4u\u00b7et", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PPER", "VAFIN", "ART", "NN", "$,", "PRELS", "ART", "ADJA", "VVFIN", "$."], "meter": "+-+--+--+--+-", "measure": "trochaic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Seind es blick oder blitz der schnell und helle glanz,", "tokens": ["Seind", "es", "blick", "o\u00b7der", "blitz", "der", "schnell", "und", "hel\u00b7le", "glanz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "KON", "VVIMP", "ART", "ADJD", "KON", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "darab wir uns zugleich entsetzen und ergetzen?", "tokens": ["da\u00b7rab", "wir", "uns", "zu\u00b7gleich", "ent\u00b7set\u00b7zen", "und", "er\u00b7get\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PRF", "ADV", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "ach! es seind s\u00fc\u00dfe blick aus Amors starker schanz:", "tokens": ["ach", "!", "es", "seind", "s\u00fc\u00b7\u00dfe", "blick", "aus", "A\u00b7mors", "star\u00b7ker", "schanz", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "PPER", "VAFIN", "ADJA", "NN", "APPR", "NE", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "nein! es seind scharfe blitz, so die herzen verletzen.", "tokens": ["nein", "!", "es", "seind", "schar\u00b7fe", "blitz", ",", "so", "die", "her\u00b7zen", "ver\u00b7let\u00b7zen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PPER", "VAFIN", "ADJA", "NN", "$,", "ADV", "ART", "NN", "VVINF", "$."], "meter": "+-+--+--+--+-", "measure": "trochaic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "Ist ein brust oder blust der zwirigbobend thron,", "tokens": ["Ist", "ein", "brust", "o\u00b7der", "blust", "der", "zwi\u00b7rig\u00b7bo\u00b7bend", "thron", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "KON", "VVFIN", "ART", "CARD", "NN", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "darauf die Charites den Liebelein liebkosen?", "tokens": ["da\u00b7rauf", "die", "Cha\u00b7ri\u00b7tes", "den", "Lie\u00b7be\u00b7lein", "lieb\u00b7ko\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "es ist ein veste brust, da wohnet all mein wohn;", "tokens": ["es", "ist", "ein", "ves\u00b7te", "brust", ",", "da", "woh\u00b7net", "all", "mein", "wohn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,", "ADV", "VVFIN", "PIAT", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "es ist ein edle blust von erdbeer, gilg und rosen.", "tokens": ["es", "ist", "ein", "ed\u00b7le", "blust", "von", "erd\u00b7beer", ",", "gilg", "und", "ro\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "APPR", "NN", "$,", "VVFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ist ein hand oder band der f\u00fcnfgezinkte ast,", "tokens": ["Ist", "ein", "hand", "o\u00b7der", "band", "der", "f\u00fcnf\u00b7ge\u00b7zink\u00b7te", "ast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "KON", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "dessen schneewei\u00dfer pracht das aug und herz verblindet?", "tokens": ["des\u00b7sen", "schnee\u00b7wei\u00b7\u00dfer", "pracht", "das", "aug", "und", "herz", "ver\u00b7blin\u00b7det", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "VVFIN", "ART", "NN", "KON", "NN", "VVPP", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "es ist ein zarte hand, erleuchtend der lieb last:", "tokens": ["es", "ist", "ein", "zar\u00b7te", "hand", ",", "er\u00b7leuch\u00b7tend", "der", "lieb", "last", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,", "VVPP", "ART", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "es ist ein hartes band, das die freiheit verbindet.", "tokens": ["es", "ist", "ein", "har\u00b7tes", "band", ",", "das", "die", "frei\u00b7heit", "ver\u00b7bin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "VVFIN", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "Wie selig bin ich doch, o haar, stirn, blick, brust, hand,", "tokens": ["Wie", "se\u00b7lig", "bin", "ich", "doch", ",", "o", "haar", ",", "stirn", ",", "blick", ",", "brust", ",", "hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "ADV", "$,", "FM", "FM", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "so k\u00f6stlich, freindlich, klar, anm\u00fctig und begl\u00fccket!", "tokens": ["so", "k\u00f6st\u00b7lich", ",", "freind\u00b7lich", ",", "klar", ",", "an\u00b7m\u00fc\u00b7tig", "und", "be\u00b7gl\u00fc\u00b7cket", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADJD", "$,", "ADJD", "$,", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "da\u00df ich durch solches garn, gestirn, blitz, blust und band", "tokens": ["da\u00df", "ich", "durch", "sol\u00b7ches", "garn", ",", "ge\u00b7stirn", ",", "blitz", ",", "blust", "und", "band"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PIAT", "NN", "$,", "VVPP", "$,", "VVIMP", "$,", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "gefangen bin, frei, wund, erquicket und verstricket!", "tokens": ["ge\u00b7fan\u00b7gen", "bin", ",", "frei", ",", "wund", ",", "er\u00b7quic\u00b7ket", "und", "ver\u00b7stri\u00b7cket", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,", "ADJD", "$,", "ADJD", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}