{"textgrid.poem.39414": {"metadata": {"author": {"name": "Schlegel, August Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "1L: Es tritt ein Wandersmann herf\u00fcr", "genre": "verse", "period": "N.A.", "pub_year": 1801, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es tritt ein Wandersmann herf\u00fcr", "tokens": ["Es", "tritt", "ein", "Wan\u00b7ders\u00b7mann", "her\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An eines Dorfes Schenke,", "tokens": ["An", "ei\u00b7nes", "Dor\u00b7fes", "Schen\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Er setzt sich vor des Hauses Th\u00fcr", "tokens": ["Er", "setzt", "sich", "vor", "des", "Hau\u00b7ses", "Th\u00fcr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im Schatten auf die B\u00e4nke;", "tokens": ["Im", "Schat\u00b7ten", "auf", "die", "B\u00e4n\u00b7ke", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Legt sein B\u00fcndel neben sich,", "tokens": ["Legt", "sein", "B\u00fcn\u00b7del", "ne\u00b7ben", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "PRF", "$,"], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.6": {"text": "Bittet den Wirth bescheidentlich,", "tokens": ["Bit\u00b7tet", "den", "Wirth", "be\u00b7schei\u00b7dent\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Mit einem Trunk ihn zu laben.", "tokens": ["Mit", "ei\u00b7nem", "Trunk", "ihn", "zu", "la\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Da zechen an dem n\u00e4chsten Tisch", "tokens": ["Da", "ze\u00b7chen", "an", "dem", "n\u00e4chs\u00b7ten", "Tisch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zwei wilde rohe Buben.", "tokens": ["Zwei", "wil\u00b7de", "ro\u00b7he", "Bu\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Heda, Herr Wirth! und gebt uns frisch:", "tokens": ["He\u00b7da", ",", "Herr", "Wirth", "!", "und", "gebt", "uns", "frisch", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "NN", "$.", "KON", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was kauzt ihr in den Stuben?", "tokens": ["Was", "kauzt", "ihr", "in", "den", "Stu\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Diese Nacht so durchgeschw\u00e4rmt,", "tokens": ["Die\u00b7se", "Nacht", "so", "durch\u00b7ge\u00b7schw\u00e4rmt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Heute von Morgens fr\u00fch gel\u00e4rmt!", "tokens": ["Heu\u00b7te", "von", "Mor\u00b7gens", "fr\u00fch", "ge\u00b7l\u00e4rmt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADV", "ADJD", "VVPP", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Wir wollen nicht n\u00fcchtern werden.", "tokens": ["Wir", "wol\u00b7len", "nicht", "n\u00fcch\u00b7tern", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Ha, Bruder, war das nicht ein Spa\u00df,", "tokens": ["Ha", ",", "Bru\u00b7der", ",", "war", "das", "nicht", "ein", "Spa\u00df", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "NN", "$,", "VAFIN", "PDS", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es geht mir nichts dar\u00fcber.", "tokens": ["Es", "geht", "mir", "nichts", "da\u00b7r\u00fc\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "PAV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und lieb' ich schon das volle Glas,", "tokens": ["Und", "lieb'", "ich", "schon", "das", "vol\u00b7le", "Glas", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hab' ich doch Unfug lieber.", "tokens": ["Hab'", "ich", "doch", "Un\u00b7fug", "lie\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "NN", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ach wie wird verwundert sein", "tokens": ["Ach", "wie", "wird", "ver\u00b7wun\u00b7dert", "sein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KOKOM", "VAFIN", "VVPP", "VAINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "All die werthe Christengemein!", "tokens": ["All", "die", "wert\u00b7he", "Chris\u00b7ten\u00b7ge\u00b7mein", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Wie wird der Pfaffe nicht toben!", "tokens": ["Wie", "wird", "der", "Pfaf\u00b7fe", "nicht", "to\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Da drau\u00dfen erst den Nepomuk", "tokens": ["Da", "drau\u00b7\u00dfen", "erst", "den", "Ne\u00b7po\u00b7muk"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit seinen sieben Sternen,", "tokens": ["Mit", "sei\u00b7nen", "sie\u00b7ben", "Ster\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich schob ihn an den Rand zuruck,", "tokens": ["Ich", "schob", "ihn", "an", "den", "Rand", "zu\u00b7ruck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bald mu\u00df er schwimmen lernen,", "tokens": ["Bald", "mu\u00df", "er", "schwim\u00b7men", "ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sch\u00fcttert was, so plumpt er 'nein,", "tokens": ["Sch\u00fct\u00b7tert", "was", ",", "so", "plumpt", "er", "'n\u00b7ein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "ADV", "VVFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Rudert wohl mit dem Jesulein,", "tokens": ["Ru\u00b7dert", "wohl", "mit", "dem", "Je\u00b7su\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Den h\u00e4lt der Narr in den Armen.", "tokens": ["Den", "h\u00e4lt", "der", "Narr", "in", "den", "Ar\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Alsdann hinunter l\u00e4ngs dem Thal", "tokens": ["Als\u00b7dann", "hin\u00b7un\u00b7ter", "l\u00e4ngs", "dem", "Thal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Wallfahrt Stationen,", "tokens": ["Der", "Wall\u00b7fahrt", "Sta\u00b7ti\u00b7o\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die dreizehn Steine allzumal", "tokens": ["Die", "drei\u00b7zehn", "Stei\u00b7ne", "all\u00b7zu\u00b7mal"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "CARD", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Christi Passionen,", "tokens": ["Mit", "Chris\u00b7ti", "Pas\u00b7si\u00b7o\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "So beschmiert, verziert auf's Fest,", "tokens": ["So", "be\u00b7schmiert", ",", "ver\u00b7ziert", "auf's", "Fest", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$,", "VVFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df das Lachen kein Einz'ger l\u00e4\u00dft,", "tokens": ["Da\u00df", "das", "La\u00b7chen", "kein", "Einz'\u00b7ger", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Wenn sie zum Beten da knieen.", "tokens": ["Wenn", "sie", "zum", "Be\u00b7ten", "da", "kni\u00b7e\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Der Andre sprach: Wenn's Prahlen gilt,", "tokens": ["Der", "And\u00b7re", "sprach", ":", "Wenn's", "Prah\u00b7len", "gilt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$.", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So steh' ich alle Wetten.", "tokens": ["So", "steh'", "ich", "al\u00b7le", "Wet\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Schnurrbart am Marienbild,", "tokens": ["Der", "Schnurr\u00b7bart", "am", "Ma\u00b7ri\u00b7en\u00b7bild", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und dann die Kron' aus Kletten,", "tokens": ["Und", "dann", "die", "Kron'", "aus", "Klet\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Die ich ihm zu Nacht bescheert,", "tokens": ["Die", "ich", "ihm", "zu", "Nacht", "be\u00b7scheert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sind wohl deine Geschichten werth,", "tokens": ["Sind", "wohl", "dei\u00b7ne", "Ge\u00b7schich\u00b7ten", "werth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "ADJD", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Und es ist noch nicht das beste.", "tokens": ["Und", "es", "ist", "noch", "nicht", "das", "bes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "PTKNEG", "ART", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Dort auf dem Fels am hohen Kreuz,", "tokens": ["Dort", "auf", "dem", "Fels", "am", "ho\u00b7hen", "Kreuz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Statt Christi leid'ger Fratze,", "tokens": ["Statt", "Chris\u00b7ti", "lei\u00b7d'\u00b7ger", "Frat\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "H\u00e4ngt nun \u2013 o in der Seel' erfreut's! \u2013", "tokens": ["H\u00e4ngt", "nun", "\u2013", "o", "in", "der", "Seel'", "er\u00b7freut's", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ADV", "$(", "FM", "APPR", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des Nachbars todte Katze.", "tokens": ["Des", "Nach\u00b7bars", "tod\u00b7te", "Kat\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wenn sie nun auf ihrer Bahn", "tokens": ["Wenn", "sie", "nun", "auf", "ih\u00b7rer", "Bahn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ziehn die Stufen zur Kirch' hinan,", "tokens": ["Ziehn", "die", "Stu\u00b7fen", "zur", "Kirch'", "hi\u00b7nan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Das wird was erbauliches werden.", "tokens": ["Das", "wird", "was", "er\u00b7bau\u00b7li\u00b7ches", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIS", "ADJA", "VAINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.8": {"line.1": {"text": "Der Wandersmann schaut ernst und still,", "tokens": ["Der", "Wan\u00b7ders\u00b7mann", "schaut", "ernst", "und", "still", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da sie die Red' erhuben.", "tokens": ["Da", "sie", "die", "Red'", "er\u00b7hu\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie achten erst nicht, was er will,", "tokens": ["Sie", "ach\u00b7ten", "erst", "nicht", ",", "was", "er", "will", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "$,", "PWS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In ihrem Rausch, die Buben.", "tokens": ["In", "ih\u00b7rem", "Rausch", ",", "die", "Bu\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Beide riefen dann zugleich:", "tokens": ["Bei\u00b7de", "rie\u00b7fen", "dann", "zu\u00b7gleich", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "K\u00fcmmert euch, Tuckm\u00e4user, um euch!", "tokens": ["K\u00fcm\u00b7mert", "euch", ",", "Tuck\u00b7m\u00e4u\u00b7ser", ",", "um", "euch", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "NN", "$,", "KOUI", "PPER", "$."], "meter": "+--++--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Was soll das Gaffen und Horchen?", "tokens": ["Was", "soll", "das", "Gaf\u00b7fen", "und", "Hor\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Der Wandersmann sagt nicht ein Wort,", "tokens": ["Der", "Wan\u00b7ders\u00b7mann", "sagt", "nicht", "ein", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und schaut nur unbeweglich,", "tokens": ["Und", "schaut", "nur", "un\u00b7be\u00b7weg\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und ihnen wurde fort und fort", "tokens": ["Und", "ih\u00b7nen", "wur\u00b7de", "fort", "und", "fort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "PTKVZ", "KON", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sein Blick mehr unertr\u00e4glich.", "tokens": ["Sein", "Blick", "mehr", "un\u00b7er\u00b7tr\u00e4g\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wenn ihr nicht die Frechheit la\u00dft,", "tokens": ["Wenn", "ihr", "nicht", "die", "Frech\u00b7heit", "la\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sagten sie, solchen Heuchler-Gast,", "tokens": ["Sag\u00b7ten", "sie", ",", "sol\u00b7chen", "Heuch\u00b7ler\u00b7Gast", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PIAT", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Den mu\u00df man mit Schl\u00e4gen verjagen.", "tokens": ["Den", "mu\u00df", "man", "mit", "Schl\u00e4\u00b7gen", "ver\u00b7ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PIS", "APPR", "NN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.10": {"line.1": {"text": "Mich schl\u00e4gt ein Andrer wohl als ihr,", "tokens": ["Mich", "schl\u00e4gt", "ein", "A\u00b7ndrer", "wohl", "als", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "KOUS", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr m\u00f6gt kein Haar mir kr\u00e4nken.", "tokens": ["Ihr", "m\u00f6gt", "kein", "Haar", "mir", "kr\u00e4n\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich bin auf kurze Frist nur hier,", "tokens": ["Ich", "bin", "auf", "kur\u00b7ze", "Frist", "nur", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch sollt ihr mein gedenken.", "tokens": ["Doch", "sollt", "ihr", "mein", "ge\u00b7den\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PPOSAT", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Junges Blut hat Frevelmuth:", "tokens": ["Jun\u00b7ges", "Blut", "hat", "Fre\u00b7vel\u00b7muth", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Thut nicht ferner, so wie ihr thut,", "tokens": ["Thut", "nicht", "fer\u00b7ner", ",", "so", "wie", "ihr", "thut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "ADV", "$,", "ADV", "KOKOM", "PPER", "VVFIN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Und la\u00dft bei Zeiten euch warnen.", "tokens": ["Und", "la\u00dft", "bei", "Zei\u00b7ten", "euch", "war\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "PPER", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Sonst schlie\u00dft ihr einen Bund der Treu", "tokens": ["Sonst", "schlie\u00dft", "ihr", "ei\u00b7nen", "Bund", "der", "Treu"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Judas falscher Rotte:", "tokens": ["Mit", "Ju\u00b7das", "fal\u00b7scher", "Rot\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Den Heiland kreuzigt ihr auf's neu", "tokens": ["Den", "Hei\u00b7land", "kreu\u00b7zigt", "ihr", "auf's", "neu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPRART", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit solchem kecken Spotte. \u2013", "tokens": ["Mit", "sol\u00b7chem", "ke\u00b7cken", "Spot\u00b7te", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ja doch, da gesch\u00e4h' ihm recht,", "tokens": ["Ja", "doch", ",", "da", "ge\u00b7sch\u00e4\u00b7h'", "ihm", "recht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "$,", "ADV", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Weil sich der einf\u00e4ltige Knecht", "tokens": ["Weil", "sich", "der", "ein\u00b7f\u00e4l\u00b7ti\u00b7ge", "Knecht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "ART", "ADJA", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "Das erstemal kreuzigen la\u00dfen. \u2013", "tokens": ["Das", "ers\u00b7te\u00b7mal", "kreu\u00b7zi\u00b7gen", "la\u00b7\u00dfen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "ADV", "VVINF", "VVINF", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.12": {"line.1": {"text": "Ich wei\u00df gewi\u00df, ihr spr\u00e4cht nicht so,", "tokens": ["Ich", "wei\u00df", "ge\u00b7wi\u00df", ",", "ihr", "spr\u00e4cht", "nicht", "so", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "W\u00e4rt ihr einst mitgegangen;", "tokens": ["W\u00e4rt", "ihr", "einst", "mit\u00b7ge\u00b7gan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ihr h\u00e4ttet nicht, der Qualen froh,", "tokens": ["Ihr", "h\u00e4t\u00b7tet", "nicht", ",", "der", "Qua\u00b7len", "froh", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Am Kreuz ihn sehen hangen,", "tokens": ["Am", "Kreuz", "ihn", "se\u00b7hen", "han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wie aus bittern Wunden quoll,", "tokens": ["Wie", "aus", "bit\u00b7tern", "Wun\u00b7den", "quoll", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Aller Lieb' und Erbarmung voll,", "tokens": ["Al\u00b7ler", "Lieb'", "und", "Er\u00b7bar\u00b7mung", "voll", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "ADJD", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Sein heilig g\u00f6ttliches Leben.", "tokens": ["Sein", "hei\u00b7lig", "g\u00f6tt\u00b7li\u00b7ches", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.13": {"line.1": {"text": "Wie um ihn, ewig hoffnungslos,", "tokens": ["Wie", "um", "ihn", ",", "e\u00b7wig", "hoff\u00b7nungs\u00b7los", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "APPR", "PPER", "$,", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Freund' und Mutter standen,", "tokens": ["Die", "Freund'", "und", "Mut\u00b7ter", "stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und er im Busen trug ihr Loo\u00df,", "tokens": ["Und", "er", "im", "Bu\u00b7sen", "trug", "ihr", "Loo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bei grimmen Todesbanden;", "tokens": ["Bei", "grim\u00b7men", "To\u00b7des\u00b7ban\u00b7den", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Neigt sein Haupt in Finsterni\u00df,", "tokens": ["Neigt", "sein", "Haupt", "in", "Fins\u00b7ter\u00b7ni\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Durch die Himmel geschieht ein Ri\u00df,", "tokens": ["Durch", "die", "Him\u00b7mel", "ge\u00b7schieht", "ein", "Ri\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Und innerlich schauert die Erde. \u2013", "tokens": ["Und", "in\u00b7ner\u00b7lich", "schau\u00b7ert", "die", "Er\u00b7de", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJD", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.14": {"line.1": {"text": "Ei seht, der macht uns glauben gar,", "tokens": ["Ei", "seht", ",", "der", "macht", "uns", "glau\u00b7ben", "gar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PRELS", "VVFIN", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er w\u00e4r' dabei gewesen.", "tokens": ["Er", "w\u00e4r'", "da\u00b7bei", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "VAPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was er erz\u00e4hlt, kann man f\u00fcrwahr", "tokens": ["Was", "er", "er\u00b7z\u00e4hlt", ",", "kann", "man", "f\u00fcr\u00b7wahr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VMFIN", "PIS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In alten Tr\u00f6stern lesen.", "tokens": ["In", "al\u00b7ten", "Tr\u00f6s\u00b7tern", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sagt uns doch, wie alt ihr seid,", "tokens": ["Sagt", "uns", "doch", ",", "wie", "alt", "ihr", "seid", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "PWAV", "ADJD", "PPER", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df ihr sah't, was vor ew'ger Zeit", "tokens": ["Da\u00df", "ihr", "sah't", ",", "was", "vor", "ew'\u00b7ger", "Zeit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PRELS", "APPR", "ADJA", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Und nimmer vielleicht ist geschehen? \u2013", "tokens": ["Und", "nim\u00b7mer", "viel\u00b7leicht", "ist", "ge\u00b7sche\u00b7hen", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "ADV", "VAFIN", "VVPP", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Ich bin nicht alt, ich bin nicht jung,", "tokens": ["Ich", "bin", "nicht", "alt", ",", "ich", "bin", "nicht", "jung", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "$,", "PPER", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Leben ist kein Leben.", "tokens": ["Mein", "Le\u00b7ben", "ist", "kein", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wie rastlos krei\u00df't der Sonnen Schwung,", "tokens": ["Wie", "rast\u00b7los", "krei\u00df't", "der", "Son\u00b7nen", "Schwung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mu\u00df ich hier unten schweben.", "tokens": ["Mu\u00df", "ich", "hier", "un\u00b7ten", "schwe\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Greiser wird das Haar mir nicht,", "tokens": ["Grei\u00b7ser", "wird", "das", "Haar", "mir", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "PPER", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Nicht gerunzelter mein Gesicht,", "tokens": ["Nicht", "ge\u00b7run\u00b7zel\u00b7ter", "mein", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Das niemals lachet noch weinet.", "tokens": ["Das", "nie\u00b7mals", "la\u00b7chet", "noch", "wei\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "ADV", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "Ich war wie ihr von frechem Muth", "tokens": ["Ich", "war", "wie", "ihr", "von", "fre\u00b7chem", "Muth"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "KOKOM", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In meinen ersten Tagen.", "tokens": ["In", "mei\u00b7nen", "ers\u00b7ten", "Ta\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "An mir that keine Lehre gut,", "tokens": ["An", "mir", "that", "kei\u00b7ne", "Leh\u00b7re", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PIAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kein Warnen half noch Sagen.", "tokens": ["Kein", "War\u00b7nen", "half", "noch", "Sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADV", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Als der Hohenpriester Amt", "tokens": ["Als", "der", "Ho\u00b7hen\u00b7pries\u00b7ter", "Amt"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Heuchlerisch nun den Christ verdammt,", "tokens": ["Heuch\u00b7le\u00b7risch", "nun", "den", "Christ", "ver\u00b7dammt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.7": {"text": "Da wollt' ich mein M\u00fcthchen auch k\u00fchlen.", "tokens": ["Da", "wollt'", "ich", "mein", "M\u00fcth\u00b7chen", "auch", "k\u00fch\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.17": {"line.1": {"text": "Und als mit schwerer Kreuzeslast", "tokens": ["Und", "als", "mit", "schwe\u00b7rer", "Kreu\u00b7zes\u00b7last"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zum Thor ihn schleppt die Menge,", "tokens": ["Zum", "Thor", "ihn", "schleppt", "die", "Men\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da hatt' ich vor den andern Hast,", "tokens": ["Da", "hatt'", "ich", "vor", "den", "an\u00b7dern", "Hast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und stie\u00df ihn im Gedr\u00e4nge.", "tokens": ["Und", "stie\u00df", "ihn", "im", "Ge\u00b7dr\u00e4n\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Matt und lechzend, ohne Schrei'n,", "tokens": ["Matt", "und", "lech\u00b7zend", ",", "oh\u00b7ne", "Schrei'n", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "$,", "KOUI", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wollt' er rasten auf einem Stein,", "tokens": ["Wollt'", "er", "ras\u00b7ten", "auf", "ei\u00b7nem", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Da schlug ich ihn mit den F\u00e4usten.", "tokens": ["Da", "schlug", "ich", "ihn", "mit", "den", "F\u00e4us\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}}, "stanza.18": {"line.1": {"text": "Geh, rief ich, Jesus! fort mit dir!", "tokens": ["Geh", ",", "rief", "ich", ",", "Je\u00b7sus", "!", "fort", "mit", "dir", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "PPER", "$,", "NE", "$.", "PTKVZ", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zum Tod dich endlich schicke!", "tokens": ["Zum", "Tod", "dich", "end\u00b7lich", "schi\u00b7cke", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Heiland sah sich um nach mir,", "tokens": ["Der", "Hei\u00b7land", "sah", "sich", "um", "nach", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sprach mit stillem Blicke:", "tokens": ["Und", "sprach", "mit", "stil\u00b7lem", "Bli\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ich zwar gehe bald zur Ruh,", "tokens": ["Ich", "zwar", "ge\u00b7he", "bald", "zur", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "APPRART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Aber wandern sollst nun du,", "tokens": ["A\u00b7ber", "wan\u00b7dern", "sollst", "nun", "du", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VMFIN", "ADV", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und warten, bis ich komme.", "tokens": ["Und", "war\u00b7ten", ",", "bis", "ich", "kom\u00b7me", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Die\u00df Wort, die\u00df Wort, die\u00df Eine Wort", "tokens": ["Die\u00df", "Wort", ",", "die\u00df", "Wort", ",", "die\u00df", "Ei\u00b7ne", "Wort"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "NN", "$,", "PDS", "NN", "$,", "PDS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War Heil mir und Verderben.", "tokens": ["War", "Heil", "mir", "und", "Ver\u00b7der\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "PPER", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es schirmt mich vor der Seele Mord,", "tokens": ["Es", "schirmt", "mich", "vor", "der", "See\u00b7le", "Mord", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch wehrt's mein leiblich Sterben.", "tokens": ["Doch", "wehrt's", "mein", "leib\u00b7lich", "Ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und mich treibt's von Land zu Land,", "tokens": ["Und", "mich", "treibt's", "von", "Land", "zu", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und bin manchem zum Grau'n bekannt,", "tokens": ["Und", "bin", "man\u00b7chem", "zum", "Grau'n", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIAT", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.7": {"text": "Der ewige wandernde Jude.", "tokens": ["Der", "e\u00b7wi\u00b7ge", "wan\u00b7dern\u00b7de", "Ju\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.20": {"line.1": {"text": "Der Fremdling sprach es alles aus", "tokens": ["Der", "Fremd\u00b7ling", "sprach", "es", "al\u00b7les", "aus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "PIS", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit unbewegter Miene,", "tokens": ["Mit", "un\u00b7be\u00b7weg\u00b7ter", "Mie\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch brennend durch die Stirn heraus", "tokens": ["Doch", "bren\u00b7nend", "durch", "die", "Stirn", "he\u00b7raus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPR", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein blutroth Kreuz erschiene.", "tokens": ["Ein", "blut\u00b7roth", "Kreuz", "er\u00b7schie\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Als die Zwei das Zeichen sahn,", "tokens": ["Als", "die", "Zwei", "das", "Zei\u00b7chen", "sahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "CARD", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "F\u00e4llt sie an der Verzweiflung Wahn,", "tokens": ["F\u00e4llt", "sie", "an", "der", "Ver\u00b7zwei\u00b7flung", "Wahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Sie glaubten sich schon in der H\u00f6lle.", "tokens": ["Sie", "glaub\u00b7ten", "sich", "schon", "in", "der", "H\u00f6l\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+++-+-", "measure": "unknown.measure.penta"}}, "stanza.21": {"line.1": {"text": "Und eh sie Seel' und Leibeskraft", "tokens": ["Und", "eh", "sie", "Seel'", "und", "Lei\u00b7bes\u00b7kraft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Sinne wiederfunden,", "tokens": ["Und", "Sin\u00b7ne", "wie\u00b7der\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hat er sein B\u00fcndel aufgerafft,", "tokens": ["Hat", "er", "sein", "B\u00fcn\u00b7del", "auf\u00b7ge\u00b7rafft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und ist schon weit verschwunden.", "tokens": ["Und", "ist", "schon", "weit", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "An des letzten H\u00fcgels Rand,", "tokens": ["An", "des", "letz\u00b7ten", "H\u00fc\u00b7gels", "Rand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sehn sie noch, den Stab in der Hand,", "tokens": ["Sehn", "sie", "noch", ",", "den", "Stab", "in", "der", "Hand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Die irre Gestalt hinwanken.", "tokens": ["Die", "ir\u00b7re", "Ge\u00b7stalt", "hin\u00b7wan\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.22": {"line.1": {"text": "Gott l\u00e4\u00dft mit sich nicht scherzen;", "tokens": ["Gott", "l\u00e4\u00dft", "mit", "sich", "nicht", "scher\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Es brennt das feurig blut'ge Kreuz", "tokens": ["Es", "brennt", "das", "feu\u00b7rig", "blut'\u00b7ge", "Kreuz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In den lieblosen Herzen.", "tokens": ["In", "den", "lieb\u00b7lo\u00b7sen", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Kirchentrost ward nicht gespart,", "tokens": ["Kir\u00b7chent\u00b7rost", "ward", "nicht", "ge\u00b7spart", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Bu\u00dfe, Gebet und Pilgerfahrt,", "tokens": ["Bu\u00b7\u00dfe", ",", "Ge\u00b7bet", "und", "Pil\u00b7ger\u00b7fahrt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.6": {"text": "Doch lebten die Sp\u00f6tter nicht lange.", "tokens": ["Doch", "leb\u00b7ten", "die", "Sp\u00f6t\u00b7ter", "nicht", "lan\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKNEG", "ADV", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}}}}