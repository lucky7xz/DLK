{"dta.poem.10304": {"metadata": {"author": {"name": "Liliencron, Detlev von", "birth": "N.A.", "death": "N.A."}, "title": "Verbannt.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1883", "urn": "urn:nbn:de:kobv:b4-200905197184", "language": ["de:0.99"], "booktitle": "Liliencron, Detlev von: Adjutantenritte und andere Gedichte. Leipzig, [1883]."}, "poem": {"stanza.1": {"line.1": {"text": "Gleichviel we\u00dfhalb, ich bin's, ich bin verbannt             ", "tokens": ["Gleich\u00b7viel", "we\u00df\u00b7halb", ",", "ich", "bin's", ",", "ich", "bin", "ver\u00b7bannt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "PPER", "VAFIN", "$,", "PPER", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Auf eine kleine, deichumrahmte Insel.", "tokens": ["Auf", "ei\u00b7ne", "klei\u00b7ne", ",", "deich\u00b7um\u00b7rahm\u00b7te", "In\u00b7sel", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Weit liegt mein walddurchrauschtes Vaterland.", "tokens": ["Weit", "liegt", "mein", "wald\u00b7durc\u00b7hrauschtes", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+--++-+-+", "measure": "dactylic.init"}, "line.4": {"text": "Hier schleicht und kriecht das Wattenmeergerinsel", "tokens": ["Hier", "schleicht", "und", "kriecht", "das", "Wat\u00b7ten\u00b7meer\u00b7ge\u00b7rin\u00b7sel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Durch Schlick und Schlamm, ein schmutzig gelbes Band.", "tokens": ["Durch", "Schlick", "und", "Schlamm", ",", "ein", "schmut\u00b7zig", "gel\u00b7bes", "Band", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "ART", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Poltert der Sturm nicht, n\u00f6rgelt Windgewinsel.", "tokens": ["Pol\u00b7tert", "der", "Sturm", "nicht", ",", "n\u00f6r\u00b7gelt", "Wind\u00b7ge\u00b7win\u00b7sel", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "PTKNEG", "$,", "VVFIN", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.2": {"line.1": {"text": "Der Reiher, dem das Nest zerschossen wird,", "tokens": ["Der", "Rei\u00b7her", ",", "dem", "das", "Nest", "zer\u00b7schos\u00b7sen", "wird", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Er baut sich an im ersten besten Walde.", "tokens": ["Er", "baut", "sich", "an", "im", "ers\u00b7ten", "bes\u00b7ten", "Wal\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "APPRART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Fl\u00fcchtling, der von Land zu L\u00e4ndern irrt,", "tokens": ["Der", "Fl\u00fccht\u00b7ling", ",", "der", "von", "Land", "zu", "L\u00e4n\u00b7dern", "irrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Erreicht vielleicht noch eine gr\u00fcne Halde,", "tokens": ["Er\u00b7reicht", "viel\u00b7leicht", "noch", "ei\u00b7ne", "gr\u00fc\u00b7ne", "Hal\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wo s\u00fc\u00df und sanft die Friedenstaube girrt,", "tokens": ["Wo", "s\u00fc\u00df", "und", "sanft", "die", "Frie\u00b7dens\u00b7tau\u00b7be", "girrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "KON", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und er die reichste Ruhe findet balde.", "tokens": ["Und", "er", "die", "reichs\u00b7te", "Ru\u00b7he", "fin\u00b7det", "bal\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "ADJA", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Zwar hab\u2019 ich sonst, was nur das Herz begehrt,", "tokens": ["Zwar", "hab'", "ich", "sonst", ",", "was", "nur", "das", "Herz", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "$,", "PRELS", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Cigarren, B\u00fccher, Schreibpapier und Tinte.", "tokens": ["Ci\u00b7gar\u00b7ren", ",", "B\u00fc\u00b7cher", ",", "Schreib\u00b7pa\u00b7pier", "und", "Tin\u00b7te", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Auch ist die Seehundjagd mir nicht verwehrt", "tokens": ["Auch", "ist", "die", "See\u00b7hund\u00b7jagd", "mir", "nicht", "ver\u00b7wehrt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPER", "PTKNEG", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und was an V\u00f6geln fliegt in meine Flinte.", "tokens": ["Und", "was", "an", "V\u00f6\u00b7geln", "fliegt", "in", "mei\u00b7ne", "Flin\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPR", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Jedwede Woche kommt ein Schiff, beschwert", "tokens": ["Jed\u00b7we\u00b7de", "Wo\u00b7che", "kommt", "ein", "Schiff", ",", "be\u00b7schwert"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["PIAT", "NN", "VVFIN", "ART", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Mit Briefen, Packen, Zucker, \u00d6l, Korinthe.", "tokens": ["Mit", "Brie\u00b7fen", ",", "Pa\u00b7cken", ",", "Zu\u00b7cker", ",", "\u00d6l", ",", "Ko\u00b7rin\u00b7the", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "$,", "NE", "$,", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Wie mu\u00df, heimdenkend, oft am Deich ich lehnen,", "tokens": ["Wie", "mu\u00df", ",", "heim\u00b7den\u00b7kend", ",", "oft", "am", "Deich", "ich", "leh\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "$,", "VVPP", "$,", "ADV", "APPRART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mir jedes ferne dunkle P\u00fcnktchen buchend.", "tokens": ["Mir", "je\u00b7des", "fer\u00b7ne", "dunk\u00b7le", "P\u00fcnkt\u00b7chen", "bu\u00b7chend", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "ADJA", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Gleich Iphigenie, mit endlosem Sehnen,", "tokens": ["Gleich", "Ip\u00b7hi\u00b7ge\u00b7nie", ",", "mit", "end\u00b7lo\u00b7sem", "Seh\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-++-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Das Land der Griechen mit der Seele suchend.", "tokens": ["Das", "Land", "der", "Grie\u00b7chen", "mit", "der", "See\u00b7le", "su\u00b7chend", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Kein Schiff in Sicht, nur rege wei\u00dfe M\u00e4hnen,", "tokens": ["Kein", "Schiff", "in", "Sicht", ",", "nur", "re\u00b7ge", "wei\u00b7\u00dfe", "M\u00e4h\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "NN", "$,", "ADV", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und ich entferne mich, den Tag verfluchend.", "tokens": ["Und", "ich", "ent\u00b7fer\u00b7ne", "mich", ",", "den", "Tag", "ver\u00b7flu\u00b7chend", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$,", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Im Osten, weit, noch hinterm Horizonte,", "tokens": ["Im", "Os\u00b7ten", ",", "weit", ",", "noch", "hin\u00b7term", "Ho\u00b7ri\u00b7zon\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "ADJD", "$,", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn dies Paradoxon vielleicht erlaubt ist,", "tokens": ["Wenn", "dies", "Pa\u00b7ra\u00b7do\u00b7xon", "viel\u00b7leicht", "er\u00b7laubt", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "NN", "ADV", "VVPP", "VAFIN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Zeigt sich ein Rauch gleich einer Nebelfronte,", "tokens": ["Zeigt", "sich", "ein", "Rauch", "gleich", "ei\u00b7ner", "Ne\u00b7bel\u00b7fron\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "(verzeihung f\u00fcr das Wort, das sehr geschraubt ist.)", "tokens": ["(", "ver\u00b7zei\u00b7hung", "f\u00fcr", "das", "Wort", ",", "das", "sehr", "ge\u00b7schraubt", "ist", ".", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NN", "APPR", "ART", "NN", "$,", "PRELS", "ADV", "VVPP", "VAFIN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Doch n\u00e4her, wie bestimmt ich sehen konnte,", "tokens": ["Doch", "n\u00e4\u00b7her", ",", "wie", "be\u00b7stimmt", "ich", "se\u00b7hen", "konn\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "PWAV", "VVFIN", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Erscheint ein schwarzer Schornstein, der behaubt ist.", "tokens": ["Er\u00b7scheint", "ein", "schwar\u00b7zer", "Schorn\u00b7stein", ",", "der", "be\u00b7haubt", "ist", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,", "PRELS", "VVPP", "VAFIN", "$."], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}}, "stanza.6": {"line.1": {"text": "Was bringt die Post, was kann sie Alles bringen,", "tokens": ["Was", "bringt", "die", "Post", ",", "was", "kann", "sie", "Al\u00b7les", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "$,", "PWS", "VMFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Tr\u00fcbsal und Trost, Freud\u2019, Bettelbrief und Trauer.", "tokens": ["Tr\u00fcb\u00b7sal", "und", "Trost", ",", "Freud'", ",", "Bet\u00b7tel\u00b7brief", "und", "Trau\u00b7er", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Heut eine Nachricht, da\u00df wir \u00fcberspringen", "tokens": ["Heut", "ei\u00b7ne", "Nach\u00b7richt", ",", "da\u00df", "wir", "\u00fc\u00b7bers\u00b7prin\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "KOUS", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Im Jubelrausch die allerh\u00f6chste Mauer.", "tokens": ["Im", "Ju\u00b7belr\u00b7ausch", "die", "al\u00b7ler\u00b7h\u00f6chs\u00b7te", "Mau\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Kann sein, da\u00df morgen wir die H\u00e4nde ringen,", "tokens": ["Kann", "sein", ",", "da\u00df", "mor\u00b7gen", "wir", "die", "H\u00e4n\u00b7de", "rin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VAINF", "$,", "KOUS", "ADV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Mi\u00dflaunig sitzen wie der Kauz im Bauer.", "tokens": ["Mi\u00df\u00b7lau\u00b7nig", "sit\u00b7zen", "wie", "der", "Kauz", "im", "Bau\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "KOKOM", "ART", "NN", "APPRART", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.7": {"line.1": {"text": "Es brachte mir die Post heut Allerlei:", "tokens": ["Es", "brach\u00b7te", "mir", "die", "Post", "heut", "Al\u00b7ler\u00b7lei", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Rundschau, Magazin und Nord und S\u00fcd,", "tokens": ["Die", "Rund\u00b7schau", ",", "Ma\u00b7ga\u00b7zin", "und", "Nord", "und", "S\u00fcd", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "KON", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Kaluga\u2019s Fahrt vom Ob zum Jenisei;", "tokens": ["Ka\u00b7lu\u00b7ga's", "Fahrt", "vom", "Ob", "zum", "Je\u00b7ni\u00b7sei", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPRART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df mir zwei F\u00fcllen fielen im Gest\u00fct.", "tokens": ["Da\u00df", "mir", "zwei", "F\u00fcl\u00b7len", "fie\u00b7len", "im", "Ge\u00b7st\u00fct", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "CARD", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ein Freundesbrief klang frisch und kummerfrei,             ", "tokens": ["Ein", "Freun\u00b7des\u00b7brief", "klang", "frisch", "und", "kum\u00b7mer\u00b7frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Ein andrer trostlos, tr\u00fcb und wegesm\u00fcd.", "tokens": ["Ein", "an\u00b7drer", "trost\u00b7los", ",", "tr\u00fcb", "und", "we\u00b7ges\u00b7m\u00fcd", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "$,", "ADJD", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Ganz unten lag ein rosenrot Couvert,", "tokens": ["Ganz", "un\u00b7ten", "lag", "ein", "ro\u00b7sen\u00b7rot", "Cou\u00b7vert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit Monogramm ", "tokens": ["Mit", "Mo\u00b7no\u00b7gramm"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Ich wu\u00dfte, da\u00df genannt er Adalbert,", "tokens": ["Ich", "wu\u00df\u00b7te", ",", "da\u00df", "ge\u00b7nannt", "er", "A\u00b7dal\u00b7bert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "VVPP", "PPER", "NE", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sie konnte mit dem Namen Laura blinken.", "tokens": ["Sie", "konn\u00b7te", "mit", "dem", "Na\u00b7men", "Lau\u00b7ra", "blin\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Essence d\u2019Ixora war dem Brief Gef\u00e4hrt\u2019,", "tokens": ["Es\u00b7sen\u00b7ce", "d'\u00b7I\u00b7xo\u00b7ra", "war", "dem", "Brief", "Ge\u00b7f\u00e4hrt'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.6": {"text": "Ihr H\u00e4ndchen wollte mir entgegenwinken.", "tokens": ["Ihr", "H\u00e4nd\u00b7chen", "woll\u00b7te", "mir", "ent\u00b7ge\u00b7gen\u00b7win\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Der Abend wurde mir verh\u00e4ngni\u00dfvoll,", "tokens": ["Der", "A\u00b7bend", "wur\u00b7de", "mir", "ver\u00b7h\u00e4ng\u00b7ni\u00df\u00b7voll", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Zu reizend war die kleine Baronesse.", "tokens": ["Zu", "rei\u00b7zend", "war", "die", "klei\u00b7ne", "Ba\u00b7ro\u00b7nes\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ich liebte bald wie rasend sie und toll,", "tokens": ["Ich", "lieb\u00b7te", "bald", "wie", "ra\u00b7send", "sie", "und", "toll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KOKOM", "VVPP", "PPER", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Auch zeigte sie mir mehr als Politesse.", "tokens": ["Auch", "zeig\u00b7te", "sie", "mir", "mehr", "als", "Po\u00b7li\u00b7tes\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "KOUS", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Doch wurde aus dem Duraccord ein Moll,", "tokens": ["Doch", "wur\u00b7de", "aus", "dem", "Du\u00b7rac\u00b7cord", "ein", "Moll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Aus dunkeln Rosen bog sich die Cypresse.", "tokens": ["Aus", "dun\u00b7keln", "Ro\u00b7sen", "bog", "sich", "die", "Cyp\u00b7res\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.10": {"line.1": {"text": "Ich glaubte gl\u00fccklich sie mit ihrem Mann,", "tokens": ["Ich", "glaub\u00b7te", "gl\u00fcck\u00b7lich", "sie", "mit", "ih\u00b7rem", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "An den sie nun zehn Jahr gekettet war.", "tokens": ["An", "den", "sie", "nun", "zehn", "Jahr", "ge\u00b7ket\u00b7tet", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPER", "ADV", "CARD", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Aus ihren Zeilen, ach, erfuhr ich dann,", "tokens": ["Aus", "ih\u00b7ren", "Zei\u00b7len", ",", "ach", ",", "er\u00b7fuhr", "ich", "dann", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ITJ", "$,", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wie schlecht das arme Weib gebettet war.", "tokens": ["Wie", "schlecht", "das", "ar\u00b7me", "Weib", "ge\u00b7bet\u00b7tet", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "ADJA", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Da\u00df ein Verschwender er und Haustyrann,", "tokens": ["Da\u00df", "ein", "Ver\u00b7schwen\u00b7der", "er", "und", "Haus\u00b7ty\u00b7rann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Aus dem Concurse nichts gerettet war.", "tokens": ["Aus", "dem", "Con\u00b7cur\u00b7se", "nichts", "ge\u00b7ret\u00b7tet", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PIS", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Im Leben mag\u2019s zum Schwersten wohl geh\u00f6ren,", "tokens": ["Im", "Le\u00b7ben", "mag's", "zum", "Schwers\u00b7ten", "wohl", "ge\u00b7h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NE", "APPRART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Aus Glanz und Reichtum pl\u00f6tzlich arm zu werden.", "tokens": ["Aus", "Glanz", "und", "Reich\u00b7tum", "pl\u00f6tz\u00b7lich", "arm", "zu", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ADJD", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie mu\u00df es unser Innerstes emp\u00f6ren,", "tokens": ["Wie", "mu\u00df", "es", "un\u00b7ser", "In\u00b7ners\u00b7tes", "em\u00b7p\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wenn Hinz und Kunz wir sehn auf unsern Pferden,", "tokens": ["Wenn", "Hinz", "und", "Kunz", "wir", "sehn", "auf", "un\u00b7sern", "Pfer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wenn Hinz und Kunz uns unser Heim zerst\u00f6ren,", "tokens": ["Wenn", "Hinz", "und", "Kunz", "uns", "un\u00b7ser", "Heim", "zer\u00b7st\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NE", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Den Rest uns nehmen, was uns lieb auf Erden.", "tokens": ["Den", "Rest", "uns", "neh\u00b7men", ",", "was", "uns", "lieb", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVINF", "$,", "PRELS", "PPER", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Genug, genug. Wir alle danken Gott,", "tokens": ["Ge\u00b7nug", ",", "ge\u00b7nug", ".", "Wir", "al\u00b7le", "dan\u00b7ken", "Gott", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "$.", "PPER", "PIS", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wenn wir zur schnellen H\u00fclfe Mittel haben.", "tokens": ["Wenn", "wir", "zur", "schnel\u00b7len", "H\u00fcl\u00b7fe", "Mit\u00b7tel", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Nahm wer, wir helfen auf und machen flott,", "tokens": ["Nahm", "wer", ",", "wir", "hel\u00b7fen", "auf", "und", "ma\u00b7chen", "flott", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PWS", "$,", "PPER", "VVFIN", "PTKVZ", "KON", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Im Lebenssteeplechase zu kurz den Graben,", "tokens": ["Im", "Le\u00b7bens\u00b7stee\u00b7plec\u00b7ha\u00b7se", "zu", "kurz", "den", "Gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKA", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Und lassen dann ihn ohne Hohn und Spott,", "tokens": ["Und", "las\u00b7sen", "dann", "ihn", "oh\u00b7ne", "Hohn", "und", "Spott", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und ohne viel zu fragen, weiter traben.", "tokens": ["Und", "oh\u00b7ne", "viel", "zu", "fra\u00b7gen", ",", "wei\u00b7ter", "tra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "APPR", "PIS", "PTKZU", "VVINF", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Thay Thasen\u2019s h\u00fcbsches achtzehnj\u00e4hrig Kind", "tokens": ["Thay", "Tha\u00b7sen's", "h\u00fcb\u00b7sches", "acht\u00b7zehn\u00b7j\u00e4h\u00b7rig", "Kind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "ADJA", "CARD", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mu\u00df mir den Thee bereiten, Kaffee kochen,", "tokens": ["Mu\u00df", "mir", "den", "Thee", "be\u00b7rei\u00b7ten", ",", "Kaf\u00b7fee", "ko\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$,", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Flickt meine W\u00e4sche, st\u00e4rkt mich mit Absinth,", "tokens": ["Flickt", "mei\u00b7ne", "W\u00e4\u00b7sche", ",", "st\u00e4rkt", "mich", "mit", "Ab\u00b7sinth", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "VVFIN", "PRF", "APPR", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Will mich ein Hungermangel unterjochen.", "tokens": ["Will", "mich", "ein", "Hun\u00b7ger\u00b7man\u00b7gel", "un\u00b7ter\u00b7jo\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sie st\u00e4ubt den Schreibtisch ab, mein Kleiderspind,", "tokens": ["Sie", "st\u00e4ubt", "den", "Schreib\u00b7tisch", "ab", ",", "mein", "Klei\u00b7der\u00b7spind", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und dient mir so seit vier und zwanzig Wochen.", "tokens": ["Und", "dient", "mir", "so", "seit", "vier", "und", "zwan\u00b7zig", "Wo\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "CARD", "KON", "CARD", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Thay Thaysen ist mein Hausvogt, Moiken\u2019s Vater.", "tokens": ["Thay", "Thay\u00b7sen", "ist", "mein", "Haus\u00b7vogt", ",", "Moi\u00b7ken's", "Va\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "PPOSAT", "NN", "$,", "NE", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Er lehrte fr\u00fch sie jede Fischerregel.", "tokens": ["Er", "lehr\u00b7te", "fr\u00fch", "sie", "je\u00b7de", "Fi\u00b7scher\u00b7re\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Beim Krabbenfangen ist er Schlickdurchwater,", "tokens": ["Beim", "Krab\u00b7ben\u00b7fan\u00b7gen", "ist", "er", "Schlick\u00b7durch\u00b7wa\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wie er hantiert auch sie mit Seil und Segel.", "tokens": ["Wie", "er", "han\u00b7tiert", "auch", "sie", "mit", "Seil", "und", "Se\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "ADV", "PPER", "APPR", "NN", "KON", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Was immer f\u00fcr sie thun er konnte, \u201ethat er,\u201c", "tokens": ["Was", "im\u00b7mer", "f\u00fcr", "sie", "thun", "er", "konn\u00b7te", ",", "\u201e", "that", "er", ",", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["PWS", "ADV", "APPR", "PPER", "VVFIN", "PPER", "VMFIN", "$,", "$(", "VVFIN", "PPER", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Doch las er nicht mit ihr Horaz und Hegel.", "tokens": ["Doch", "las", "er", "nicht", "mit", "ihr", "Ho\u00b7raz", "und", "He\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "APPR", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.15": {"line.1": {"text": "Ich liebe sehr die k\u00fchne Reigerbeize,", "tokens": ["Ich", "lie\u00b7be", "sehr", "die", "k\u00fch\u00b7ne", "Rei\u00b7ger\u00b7bei\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zur Seiten einer wunderholden Frau.", "tokens": ["Zur", "Sei\u00b7ten", "ei\u00b7ner", "wun\u00b7der\u00b7hol\u00b7den", "Frau", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dornhecken \u00fcber ohne viel Gespreize,", "tokens": ["Dorn\u00b7he\u00b7cken", "\u00fc\u00b7ber", "oh\u00b7ne", "viel", "Ge\u00b7sprei\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "APPR", "PIAT", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Hep! \u00fcber Gr\u00e4ben, H\u00fcrd\u2019, Verhack, Verhau.", "tokens": ["Hep", "!", "\u00fc\u00b7ber", "Gr\u00e4\u00b7ben", ",", "H\u00fcrd'", ",", "Ver\u00b7hack", ",", "Ver\u00b7hau", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$.", "APPR", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Das Alles hat ja ganz besondre Reize:", "tokens": ["Das", "Al\u00b7les", "hat", "ja", "ganz", "be\u00b7sond\u00b7re", "Rei\u00b7ze", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VAFIN", "ADV", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die sch\u00f6ne Frau, die Falken, Himmesblau.", "tokens": ["Die", "sch\u00f6\u00b7ne", "Frau", ",", "die", "Fal\u00b7ken", ",", "Him\u00b7mes\u00b7blau", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Komm\u2019 ich vom Entenschie\u00dfen m\u00fcd\u2019 zur\u00fcck,", "tokens": ["Komm'", "ich", "vom", "En\u00b7ten\u00b7schie\u00b7\u00dfen", "m\u00fcd'", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPRART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Eilt Moiken auf der Werfte mir entgegen,", "tokens": ["Eilt", "Moi\u00b7ken", "auf", "der", "Werf\u00b7te", "mir", "ent\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "ART", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Nimmt mir das Jagdger\u00e4t ab, St\u00fcck f\u00fcr St\u00fcck,", "tokens": ["Nimmt", "mir", "das", "Jagd\u00b7ge\u00b7r\u00e4t", "ab", ",", "St\u00fcck", "f\u00fcr", "St\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Um dann die J\u00e4gersuppe vorzulegen.", "tokens": ["Um", "dann", "die", "J\u00e4\u00b7ger\u00b7sup\u00b7pe", "vor\u00b7zu\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Aus allen Ecken lacht mich an das Gl\u00fcck,", "tokens": ["Aus", "al\u00b7len", "E\u00b7cken", "lacht", "mich", "an", "das", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Ich mu\u00df das M\u00e4dchen still am Herzen hegen.", "tokens": ["Ich", "mu\u00df", "das", "M\u00e4d\u00b7chen", "still", "am", "Her\u00b7zen", "he\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADJD", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Wir plaudern Abends h\u00e4ufig am Kamin,", "tokens": ["Wir", "plau\u00b7dern", "A\u00b7bends", "h\u00e4u\u00b7fig", "am", "Ka\u00b7min", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Moiken erz\u00e4hlt mir Inselm\u00e4rchen, Sagen,", "tokens": ["Moi\u00b7ken", "er\u00b7z\u00e4hlt", "mir", "In\u00b7sel\u00b7m\u00e4r\u00b7chen", ",", "Sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "NN", "$,", "VVFIN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Ich ihr von Wien, Turin, Dublin, Berlin,", "tokens": ["Ich", "ihr", "von", "Wi\u00b7en", ",", "Tu\u00b7rin", ",", "Dub\u00b7lin", ",", "Ber\u00b7lin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "PPER", "APPR", "NE", "$,", "NN", "$,", "NE", "$,", "NE", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Sie wieder mir von Flut und Sturmestagen.", "tokens": ["Sie", "wie\u00b7der", "mir", "von", "Flut", "und", "Stur\u00b7mes\u00b7ta\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PPER", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Erschreckt st\u00fctzt sie die H\u00e4ndchen auf die Knie\u2019,", "tokens": ["Er\u00b7schreckt", "st\u00fctzt", "sie", "die", "H\u00e4nd\u00b7chen", "auf", "die", "Knie'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Meld\u2019 ich von Schlacht und wildem Rossesjagen.", "tokens": ["Meld'", "ich", "von", "Schlacht", "und", "wil\u00b7dem", "Ros\u00b7ses\u00b7ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Wie reizend ist\u2019s, bestaunt sie meine Sachen,", "tokens": ["Wie", "rei\u00b7zend", "ist's", ",", "be\u00b7staunt", "sie", "mei\u00b7ne", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVPP", "VAFIN", "$,", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Denn Alles ist ihr neu noch und ein Wunder.", "tokens": ["Denn", "Al\u00b7les", "ist", "ihr", "neu", "noch", "und", "ein", "Wun\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "PPER", "ADJD", "ADV", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Sie sah bisher nur Netz und Fischernachen,", "tokens": ["Sie", "sah", "bis\u00b7her", "nur", "Netz", "und", "Fi\u00b7scher\u00b7na\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Den Seehund, Flut und Ebbe, Dorsch und Flunder.", "tokens": ["Den", "See\u00b7hund", ",", "Flut", "und", "Eb\u00b7be", ",", "Dorsch", "und", "Flun\u00b7der", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "KON", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wie freut sie sich, wie lieblich ist ihr Lachen,", "tokens": ["Wie", "freut", "sie", "sich", ",", "wie", "lieb\u00b7lich", "ist", "ihr", "La\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PRF", "$,", "PWAV", "ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Schenk\u2019 ich ein St\u00fcckchen ihr von all dem Plunder.", "tokens": ["Schenk'", "ich", "ein", "St\u00fcck\u00b7chen", "ihr", "von", "all", "dem", "Plun\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PPER", "APPR", "PIAT", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Mein Platen ist zum Beispiel gut gebunden,", "tokens": ["Mein", "Pla\u00b7ten", "ist", "zum", "Bei\u00b7spiel", "gut", "ge\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPRART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den hat sie sich zum Lesen auserkoren.", "tokens": ["Den", "hat", "sie", "sich", "zum", "Le\u00b7sen", "au\u00b7ser\u00b7ko\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "PRF", "APPRART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Neulich hab\u2019 ich im Grafen sie gefunden,", "tokens": ["Neu\u00b7lich", "hab'", "ich", "im", "Gra\u00b7fen", "sie", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPRART", "NN", "PPER", "VVPP", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Mit ihren Fingern schlo\u00df sie sich die Ohren.", "tokens": ["Mit", "ih\u00b7ren", "Fin\u00b7gern", "schlo\u00df", "sie", "sich", "die", "Oh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Doch schien ihr die Lekt\u00fcre nicht zu munden,", "tokens": ["Doch", "schien", "ihr", "die", "Lek\u00b7t\u00fc\u00b7re", "nicht", "zu", "mun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wahrscheinlich ging der Faden ihr verloren.", "tokens": ["Wahr\u00b7schein\u00b7lich", "ging", "der", "Fa\u00b7den", "ihr", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Wie sch\u00e4tz\u2019 ich Platen, seine Prachtsonette,", "tokens": ["Wie", "sch\u00e4tz'", "ich", "Pla\u00b7ten", ",", "sei\u00b7ne", "Pracht\u00b7so\u00b7net\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie dank\u2019 ich Geibel, da\u00df sein sch\u00f6nstes Lied", "tokens": ["Wie", "dank'", "ich", "Gei\u00b7bel", ",", "da\u00df", "sein", "sch\u00f6ns\u00b7tes", "Lied"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PPER", "NN", "$,", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ihn feiert: wundervoll sind die Terzette,", "tokens": ["Ihn", "fei\u00b7ert", ":", "wun\u00b7der\u00b7voll", "sind", "die", "Ter\u00b7zet\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Durch die sein roter Zornesfaden zieht.", "tokens": ["Durch", "die", "sein", "ro\u00b7ter", "Zor\u00b7nes\u00b7fa\u00b7den", "zieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Platens Balladen sind zwar sehr honette,", "tokens": ["Pla\u00b7tens", "Bal\u00b7la\u00b7den", "sind", "zwar", "sehr", "ho\u00b7net\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-++--+--+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Doch ohne Funkelfeuer, Kolorit.", "tokens": ["Doch", "oh\u00b7ne", "Fun\u00b7kel\u00b7feu\u00b7er", ",", "Ko\u00b7lo\u00b7rit", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "APPR", "NN", "$,", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Die Worte: Busen, duften, kosen, wallen,", "tokens": ["Die", "Wor\u00b7te", ":", "Bu\u00b7sen", ",", "duf\u00b7ten", ",", "ko\u00b7sen", ",", "wal\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$.", "NN", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sind alte deutsche Worte, sch\u00f6n, verstehlich.", "tokens": ["Sind", "al\u00b7te", "deut\u00b7sche", "Wor\u00b7te", ",", "sch\u00f6n", ",", "ver\u00b7steh\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VAFIN", "ADJA", "ADJA", "NN", "$,", "ADJD", "$,", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Dichter bringt sie gern in ganzen Ballen,", "tokens": ["Der", "Dich\u00b7ter", "bringt", "sie", "gern", "in", "gan\u00b7zen", "Bal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Aus unsrer Sprache sind sie unverwehlich.", "tokens": ["Aus", "uns\u00b7rer", "Spra\u00b7che", "sind", "sie", "un\u00b7ver\u00b7weh\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wie kommt es, da\u00df sie nimmer mir gefallen,", "tokens": ["Wie", "kommt", "es", ",", "da\u00df", "sie", "nim\u00b7mer", "mir", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ich finde scheuslich sie, ganz unausstehlich.", "tokens": ["Ich", "fin\u00b7de", "scheus\u00b7lich", "sie", ",", "ganz", "un\u00b7aus\u00b7steh\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PPER", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "Wall\u201ee\u201ct das Haar auch, duftend, auf die Socken,", "tokens": ["Wall", "\u201e", "e", "\u201c", "t", "das", "Haar", "auch", ",", "duf\u00b7tend", ",", "auf", "die", "So\u00b7cken", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NE", "$(", "VVFIN", "ART", "NN", "ADV", "$,", "VVPP", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Nicht kos\u201ee\u201ct mehr ihr Busen an dem meinen.", "tokens": ["Nicht", "kos", "\u201e", "e", "\u201c", "t", "mehr", "ihr", "Bu\u00b7sen", "an", "dem", "mei\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NE", "$(", "NE", "$(", "VVFIN", "ADV", "PPOSAT", "NN", "APPR", "ART", "VVFIN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Im Gegenteil, ihr Busen wallt erschrocken,", "tokens": ["Im", "Ge\u00b7gen\u00b7teil", ",", "ihr", "Bu\u00b7sen", "wallt", "er\u00b7schro\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PPOSAT", "NN", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und ach, die s\u00fc\u00dfesten der Augen weinen.", "tokens": ["Und", "ach", ",", "die", "s\u00fc\u00b7\u00dfes\u00b7ten", "der", "Au\u00b7gen", "wei\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$,", "PRELS", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ihr Herzchen wallt, doch nicht wie Abendglocken,", "tokens": ["Ihr", "Herz\u00b7chen", "wallt", ",", "doch", "nicht", "wie", "A\u00b7bend\u00b7glo\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "ADV", "PTKNEG", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Es wallt wie Sturm das Herzchen meiner Kleinen.", "tokens": ["Es", "wallt", "wie", "Sturm", "das", "Herz\u00b7chen", "mei\u00b7ner", "Klei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "NN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "Mein gutes M\u00e4dchen, sei mir nicht mehr b\u00f6se,", "tokens": ["Mein", "gu\u00b7tes", "M\u00e4d\u00b7chen", ",", "sei", "mir", "nicht", "mehr", "b\u00f6\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "VAFIN", "PPER", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df ich dich, wie du meinst, ge\u00e4rgert habe.", "tokens": ["Da\u00df", "ich", "dich", ",", "wie", "du", "meinst", ",", "ge\u00b7\u00e4r\u00b7gert", "ha\u00b7be", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "$,", "PWAV", "PPER", "ADV", "$,", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "N\u00e4h\u2019 freundlich wieder Kn\u00f6pfe mir und \u00d6se,", "tokens": ["N\u00e4h'", "freund\u00b7lich", "wie\u00b7der", "Kn\u00f6p\u00b7fe", "mir", "und", "\u00d6\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "ADV", "NN", "PPER", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Durchkrame wieder meine ganze Habe.", "tokens": ["Durch\u00b7kra\u00b7me", "wie\u00b7der", "mei\u00b7ne", "gan\u00b7ze", "Ha\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Du wei\u00dft, ich bin zuweilen sehr nerv\u00f6se,", "tokens": ["Du", "wei\u00dft", ",", "ich", "bin", "zu\u00b7wei\u00b7len", "sehr", "ner\u00b7v\u00f6\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ADV", "ADV", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Sei wieder gut, sonst schelt\u2019 ich noch im Grabe", "tokens": ["Sei", "wie\u00b7der", "gut", ",", "sonst", "schelt'", "ich", "noch", "im", "Gra\u00b7be"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADJD", "$,", "ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "Ich hatte Kom\u00f6dianten kommen lassen,", "tokens": ["Ich", "hat\u00b7te", "Ko\u00b7m\u00f6\u00b7di\u00b7an\u00b7ten", "kom\u00b7men", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "VVINF", "VVINF", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Um mir die Zeit ein wenig zu verk\u00fcrzen", "tokens": ["Um", "mir", "die", "Zeit", "ein", "we\u00b7nig", "zu", "ver\u00b7k\u00fcr\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "PPER", "ART", "NN", "ART", "PIS", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und meinen treuen biedern Wassersassen", "tokens": ["Und", "mei\u00b7nen", "treu\u00b7en", "bie\u00b7dern", "Was\u00b7ser\u00b7sas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Einmal den rauhen Seemannstag zu w\u00fcrzen.", "tokens": ["Ein\u00b7mal", "den", "rau\u00b7hen", "See\u00b7manns\u00b7tag", "zu", "w\u00fcr\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.5": {"text": "War das ein Jux und Jubel, kaum zu fassen,", "tokens": ["War", "das", "ein", "Jux", "und", "Ju\u00b7bel", ",", "kaum", "zu", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "KON", "NN", "$,", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ich sah sie lachend sich entgegenst\u00fcrzen", "tokens": ["Ich", "sah", "sie", "la\u00b7chend", "sich", "ent\u00b7ge\u00b7gen\u00b7st\u00fcr\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "PRF", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.25": {"line.1": {"text": "Der Herr Direktor war ein alter Mann", "tokens": ["Der", "Herr", "Di\u00b7rek\u00b7tor", "war", "ein", "al\u00b7ter", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit wei\u00dfem Haar und dicker roter Nase.", "tokens": ["Mit", "wei\u00b7\u00dfem", "Haar", "und", "di\u00b7cker", "ro\u00b7ter", "Na\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die gr\u00f6\u00dften Mimen that er in den Bann,", "tokens": ["Die", "gr\u00f6\u00df\u00b7ten", "Mi\u00b7men", "that", "er", "in", "den", "Bann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Was waren Devrient und Friedrich Haase.", "tokens": ["Was", "wa\u00b7ren", "Dev\u00b7ri\u00b7ent", "und", "Fried\u00b7rich", "Haa\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "NE", "KON", "NE", "NE", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Als Gast war er sogar in Ispahan,", "tokens": ["Als", "Gast", "war", "er", "so\u00b7gar", "in", "Is\u00b7pa\u00b7han", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAFIN", "PPER", "ADV", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Sprach er von dort, geriet er in Extase.", "tokens": ["Sprach", "er", "von", "dort", ",", "ge\u00b7riet", "er", "in", "Ex\u00b7ta\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "ADV", "$,", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "Die Frau Direktor, eine kleine Dame", "tokens": ["Die", "Frau", "Di\u00b7rek\u00b7tor", ",", "ei\u00b7ne", "klei\u00b7ne", "Da\u00b7me"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von sechzig Lenzen und vielleicht dar\u00fcber,", "tokens": ["Von", "sech\u00b7zig", "Len\u00b7zen", "und", "viel\u00b7leicht", "da\u00b7r\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "KON", "ADV", "PAV", "$,"], "meter": "-+-+--++-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "War einst gefeiert, ein ber\u00fchmter Name,", "tokens": ["War", "einst", "ge\u00b7fei\u00b7ert", ",", "ein", "be\u00b7r\u00fchm\u00b7ter", "Na\u00b7me", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Bis m\u00e4hlig tr\u00fcber ward ihr Stern und tr\u00fcber,", "tokens": ["Bis", "m\u00e4h\u00b7lig", "tr\u00fc\u00b7ber", "ward", "ihr", "Stern", "und", "tr\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJD", "VAFIN", "PPOSAT", "NN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Bis ihr das Leben gab, das m\u00fchesame,", "tokens": ["Bis", "ihr", "das", "Le\u00b7ben", "gab", ",", "das", "m\u00fc\u00b7he\u00b7sa\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "VVFIN", "$,", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Das Leben, ach, zu viele Nasenst\u00fcber.", "tokens": ["Das", "Le\u00b7ben", ",", "ach", ",", "zu", "vie\u00b7le", "Na\u00b7sen\u00b7st\u00fc\u00b7ber", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ITJ", "$,", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.27": {"line.1": {"text": "Liebhaber Nummer Eins, er hie\u00df Maresche,", "tokens": ["Lieb\u00b7ha\u00b7ber", "Num\u00b7mer", "Eins", ",", "er", "hie\u00df", "Ma\u00b7re\u00b7sche", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "NN", "$,", "PPER", "VVFIN", "NE", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "War Heldenvater auch und Intriguant.", "tokens": ["War", "Hel\u00b7den\u00b7va\u00b7ter", "auch", "und", "Int\u00b7ri\u00b7gu\u00b7ant", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "KON", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Liebhaber Nummer Zwei, er hie\u00df Manesche,", "tokens": ["Lieb\u00b7ha\u00b7ber", "Num\u00b7mer", "Zwei", ",", "er", "hie\u00df", "Ma\u00b7ne\u00b7sche", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "CARD", "$,", "PPER", "VVFIN", "PIS", "$,"], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "War noch ein junger siebzehnj\u00e4hriger Fant.", "tokens": ["War", "noch", "ein", "jun\u00b7ger", "sieb\u00b7zehn\u00b7j\u00e4h\u00b7ri\u00b7ger", "Fant", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "Nicht immer trugen sie die reinste W\u00e4sche,", "tokens": ["Nicht", "im\u00b7mer", "tru\u00b7gen", "sie", "die", "reins\u00b7te", "W\u00e4\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Doch waren sonst sie fein und elegant,", "tokens": ["Doch", "wa\u00b7ren", "sonst", "sie", "fein", "und", "e\u00b7le\u00b7gant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.28": {"line.1": {"text": "Nat\u00fcrlich fehlte auch nicht die Soubrette,", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "fehl\u00b7te", "auch", "nicht", "die", "Soub\u00b7ret\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sie war ein junges allerliebstes Ding.", "tokens": ["Sie", "war", "ein", "jun\u00b7ges", "al\u00b7ler\u00b7liebs\u00b7tes", "Ding", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Tag\u00fcber lag sie freilich gern im Bette,", "tokens": ["Ta\u00b7g\u00fc\u00b7ber", "lag", "sie", "frei\u00b7lich", "gern", "im", "Bet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wenn ihr das Leben nicht nach Laune ging.", "tokens": ["Wenn", "ihr", "das", "Le\u00b7ben", "nicht", "nach", "Lau\u00b7ne", "ging", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Zuweilen sangen wir bei mir Duette,", "tokens": ["Zu\u00b7wei\u00b7len", "san\u00b7gen", "wir", "bei", "mir", "Du\u00b7et\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Es war f\u00fcr Schumann ihr Talent gering.", "tokens": ["Es", "war", "f\u00fcr", "Schu\u00b7mann", "ihr", "Ta\u00b7lent", "ge\u00b7ring", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "Nun sitzen beide wieder wir alleine,", "tokens": ["Nun", "sit\u00b7zen", "bei\u00b7de", "wie\u00b7der", "wir", "al\u00b7lei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sei, Moiken, artig, so, gieb mir die Hand.", "tokens": ["Sei", ",", "Moi\u00b7ken", ",", "ar\u00b7tig", ",", "so", ",", "gieb", "mir", "die", "Hand", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "NN", "$,", "ADJD", "$,", "ADV", "$,", "VVIMP", "PPER", "ART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Auf dieser Insel bin ich ganz der deine,", "tokens": ["Auf", "die\u00b7ser", "In\u00b7sel", "bin", "ich", "ganz", "der", "dei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "PPER", "ADV", "ART", "PPOSAT", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wo uns so manche sch\u00f6ne Stunde schwand.", "tokens": ["Wo", "uns", "so", "man\u00b7che", "sch\u00f6\u00b7ne", "Stun\u00b7de", "schwand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "PIAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und bin auch einst ich ferne, liebe Kleine,", "tokens": ["Und", "bin", "auch", "einst", "ich", "fer\u00b7ne", ",", "lie\u00b7be", "Klei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "PPER", "ADV", "$,", "VVFIN", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ich denke oft zur\u00fcck an unsern Strand.", "tokens": ["Ich", "den\u00b7ke", "oft", "zu\u00b7r\u00fcck", "an", "un\u00b7sern", "Strand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "Hier fand ich Ruhe, die nicht ich gefunden", "tokens": ["Hier", "fand", "ich", "Ru\u00b7he", ",", "die", "nicht", "ich", "ge\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,", "PRELS", "PTKNEG", "PPER", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Im Treiben der Gesellschaft, in den Schenken.", "tokens": ["Im", "Trei\u00b7ben", "der", "Ge\u00b7sell\u00b7schaft", ",", "in", "den", "Schen\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Hier fand ich Ruhe, um in vielen Stunden", "tokens": ["Hier", "fand", "ich", "Ru\u00b7he", ",", "um", "in", "vie\u00b7len", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,", "KOUI", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "In unsre Dichter ganz mich zu versenken,", "tokens": ["In", "uns\u00b7re", "Dich\u00b7ter", "ganz", "mich", "zu", "ver\u00b7sen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Von alten Wunden endlich zu gesunden,", "tokens": ["Von", "al\u00b7ten", "Wun\u00b7den", "end\u00b7lich", "zu", "ge\u00b7sun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Vergangnes Leben ernst zu \u00fcberdenken.", "tokens": ["Ver\u00b7gang\u00b7nes", "Le\u00b7ben", "ernst", "zu", "\u00fc\u00b7ber\u00b7den\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.31": {"line.1": {"text": "Bin ich entfesselt der Verbannungsbande,", "tokens": ["Bin", "ich", "ent\u00b7fes\u00b7selt", "der", "Ver\u00b7ban\u00b7nungs\u00b7ban\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Leuchtet zur\u00fcck vom Heimatufer mir", "tokens": ["Leuch\u00b7tet", "zu\u00b7r\u00fcck", "vom", "Hei\u00b7ma\u00b7tu\u00b7fer", "mir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKVZ", "APPRART", "NN", "PPER"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Die Fackel, hoch auf rotem Felsenrande,", "tokens": ["Die", "Fa\u00b7ckel", ",", "hoch", "auf", "ro\u00b7tem", "Fel\u00b7sen\u00b7ran\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ich will ins Meer mich st\u00fcrzen voller Gier", "tokens": ["Ich", "will", "ins", "Meer", "mich", "st\u00fcr\u00b7zen", "vol\u00b7ler", "Gier"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPRART", "NN", "PPER", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und schwimmen, bis ich bin im Vaterlande,", "tokens": ["Und", "schwim\u00b7men", ",", "bis", "ich", "bin", "im", "Va\u00b7ter\u00b7lan\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "VAFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wo mich umrauscht das alte Reichspanier.", "tokens": ["Wo", "mich", "um\u00b7rauscht", "das", "al\u00b7te", "Reich\u00b7spa\u00b7nier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.32": {"line.1": {"text": "Schelt\u2019 ich den Diener, da\u00df ich nicht am Bette", "tokens": ["Schelt'", "ich", "den", "Die\u00b7ner", ",", "da\u00df", "ich", "nicht", "am", "Bet\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "KOUS", "PPER", "PTKNEG", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den Siphon fand, trank ich zu viel Lik\u00f6r;", "tokens": ["Den", "Si\u00b7phon", "fand", ",", "trank", "ich", "zu", "viel", "Li\u00b7k\u00f6r", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "VVFIN", "PPER", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Zerstreu\u2019 ich mich heut Abend am Roulette", "tokens": ["Zer\u00b7streu'", "ich", "mich", "heut", "A\u00b7bend", "am", "Rou\u00b7let\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PRF", "ADV", "NN", "APPRART", "NN"], "meter": "-+-+-+--++-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und Morgen auf dem Ball beim Gouverneur;", "tokens": ["Und", "Mor\u00b7gen", "auf", "dem", "Ball", "beim", "Gou\u00b7ver\u00b7neur", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "H\u00e4lt wieder mich im Zaum die Etiquette,", "tokens": ["H\u00e4lt", "wie\u00b7der", "mich", "im", "Zaum", "die", "E\u00b7ti\u00b7quet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die gro\u00dfe Stadt und all ihr Zubeh\u00f6r;", "tokens": ["Die", "gro\u00b7\u00dfe", "Stadt", "und", "all", "ihr", "Zu\u00b7be\u00b7h\u00f6r", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "PIAT", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.33": {"line.1": {"text": "An jene Tage, als mit meiner Bracke", "tokens": ["An", "je\u00b7ne", "Ta\u00b7ge", ",", "als", "mit", "mei\u00b7ner", "Bra\u00b7cke"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "$,", "KOUS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Jagend ich einsam durch die Watten schlich,", "tokens": ["Ja\u00b7gend", "ich", "ein\u00b7sam", "durch", "die", "Wat\u00b7ten", "schlich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Von eines alten R\u00e4uberturmes Zacke", "tokens": ["Von", "ei\u00b7nes", "al\u00b7ten", "R\u00e4u\u00b7ber\u00b7tur\u00b7mes", "Za\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ringsum ersah den letzten grauen Strich", "tokens": ["Ring\u00b7sum", "er\u00b7sah", "den", "letz\u00b7ten", "grau\u00b7en", "Strich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "ADJA", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Endlosen Wassers, aus dem schwarze Wracke", "tokens": ["End\u00b7lo\u00b7sen", "Was\u00b7sers", ",", "aus", "dem", "schwar\u00b7ze", "Wra\u00b7cke"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NN", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "Bei tiefer Ebb\u2019 aufragen trotziglich.", "tokens": ["Bei", "tie\u00b7fer", "Ebb'", "auf\u00b7ra\u00b7gen", "trot\u00b7zig\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVIZU", "ADJD", "$."], "meter": "-+-+---+-+", "measure": "zehnsilber"}}}}}