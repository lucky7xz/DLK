{"textgrid.poem.67397": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ein Staar, entflohen seinem Stande", "genre": "verse", "period": "N.A.", "pub_year": 1789, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein Staar, entflohen seinem Stande", "tokens": ["Ein", "Staar", ",", "ent\u00b7flo\u00b7hen", "sei\u00b7nem", "Stan\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der k\u00fcnstlichen Cultur, kam in den Hain zur\u00fcck.", "tokens": ["Der", "k\u00fcnst\u00b7li\u00b7chen", "Cul\u00b7tur", ",", "kam", "in", "den", "Hain", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die V\u00f6gel gr\u00fc\u00dften ihn: \u00bbWillkommen hier im Lande", "tokens": ["Die", "V\u00f6\u00b7gel", "gr\u00fc\u00df\u00b7ten", "ihn", ":", "\u00bb", "Will\u00b7kom\u00b7men", "hier", "im", "Lan\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "$.", "$(", "NN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der fr\u00f6hlichen Natur!\u00ab und w\u00fcnscheten ihm Gl\u00fcck.", "tokens": ["Der", "fr\u00f6h\u00b7li\u00b7chen", "Na\u00b7tur", "!", "\u00ab", "und", "w\u00fcn\u00b7sche\u00b7ten", "ihm", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$(", "KON", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+---+", "measure": "unknown.measure.penta"}, "line.5": {"text": "Die Lerche stieg hinauf in Kreisen,", "tokens": ["Die", "Ler\u00b7che", "stieg", "hin\u00b7auf", "in", "Krei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die Nachtigall sprang hier und dort,", "tokens": ["Die", "Nach\u00b7ti\u00b7gall", "sprang", "hier", "und", "dort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "KON", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die Amsel schlug. \u00bbIch bringe von den Reisen", "tokens": ["Die", "Am\u00b7sel", "schlug", ".", "\u00bb", "Ich", "brin\u00b7ge", "von", "den", "Rei\u00b7sen"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Normal-Instruction, mein schwer erlerntes Wort.", "tokens": ["Nor\u00b7ma\u00b7lIn\u00b7struc\u00b7ti\u00b7on", ",", "mein", "schwer", "er\u00b7lern\u00b7tes", "Wort", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "ADJD", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.9": {"text": "Es ist gelehrt; von allen Facult\u00e4ten", "tokens": ["Es", "ist", "ge\u00b7lehrt", ";", "von", "al\u00b7len", "Fa\u00b7cul\u00b7t\u00e4\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Ist's anerkannt. O seid darum gebeten", "tokens": ["Ist's", "an\u00b7er\u00b7kannt", ".", "O", "seid", "da\u00b7rum", "ge\u00b7be\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVPP", "$.", "NE", "VAFIN", "PAV", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Und lagert Euch um mich sofort!\u00ab", "tokens": ["Und", "la\u00b7gert", "Euch", "um", "mich", "so\u00b7fort", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PPER", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Er sprach es aus, ohn' alle Varianten,", "tokens": ["Er", "sprach", "es", "aus", ",", "ohn'", "al\u00b7le", "Va\u00b7ri\u00b7an\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Wie einen wahren Rechtsbescheid.", "tokens": ["Wie", "ei\u00b7nen", "wah\u00b7ren", "Rechts\u00b7be\u00b7scheid", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Es h\u00f6reten jetzt alle Reichsverwandten", "tokens": ["Es", "h\u00f6\u00b7re\u00b7ten", "jetzt", "al\u00b7le", "Reichs\u00b7ver\u00b7wand\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN"], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Und sprachen: \u00bbFreund, es thut uns leid,", "tokens": ["Und", "spra\u00b7chen", ":", "\u00bb", "Freund", ",", "es", "thut", "uns", "leid", ","], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "NN", "$,", "PPER", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir waren einst Dir trauliche Bekannten;", "tokens": ["Wir", "wa\u00b7ren", "einst", "Dir", "trau\u00b7li\u00b7che", "Be\u00b7kann\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Doch dieses Wort ist nicht f\u00fcr Ort und Zeit.\u00ab", "tokens": ["Doch", "die\u00b7ses", "Wort", "ist", "nicht", "f\u00fcr", "Ort", "und", "Zeit", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PDAT", "NN", "VAFIN", "PTKNEG", "APPR", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Die Lerche schwang sich auf in Kreisen,", "tokens": ["Die", "Ler\u00b7che", "schwang", "sich", "auf", "in", "Krei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die Nachtigall sang lieblich fort,", "tokens": ["Die", "Nach\u00b7ti\u00b7gall", "sang", "lieb\u00b7lich", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die Amsel schlug, nach seinen langen Reisen", "tokens": ["Die", "Am\u00b7sel", "schlug", ",", "nach", "sei\u00b7nen", "lan\u00b7gen", "Rei\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Begann der Storch und klappert' hie und dort;", "tokens": ["Be\u00b7gann", "der", "Storch", "und", "klap\u00b7pert'", "hie", "und", "dort", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "KON", "VVFIN", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Der Staar, wie alle Afterweisen,", "tokens": ["Der", "Staar", ",", "wie", "al\u00b7le", "Af\u00b7ter\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Blieb einsam stehn und declamirt' sein Wort.", "tokens": ["Blieb", "ein\u00b7sam", "stehn", "und", "de\u00b7cla\u00b7mirt'", "sein", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "VVINF", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}}}}