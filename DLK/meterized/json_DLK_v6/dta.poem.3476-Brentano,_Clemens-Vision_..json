{"dta.poem.3476": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Vision .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1808", "urn": "urn:nbn:de:kobv:b4-20090519172", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ueber den Kirchhof gieng ich allein               ", "tokens": ["Ue\u00b7ber", "den", "Kirch\u00b7hof", "gieng", "ich", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "ADV"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Zu meines Liebchens K\u00e4mmerlein,", "tokens": ["Zu", "mei\u00b7nes", "Lieb\u00b7chens", "K\u00e4m\u00b7mer\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und als ich wollt von dannen gehn,", "tokens": ["Und", "als", "ich", "wollt", "von", "dan\u00b7nen", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VMFIN", "APPR", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da hielt es mich, ich mu\u00dft da stehn.", "tokens": ["Da", "hielt", "es", "mich", ",", "ich", "mu\u00dft", "da", "stehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$,", "PPER", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ein Seel stand traurig an eim Grab,", "tokens": ["Ein", "Seel", "stand", "trau\u00b7rig", "an", "eim", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und schrie mit heller Stimm hinab,", "tokens": ["Und", "schrie", "mit", "hel\u00b7ler", "Stimm", "hin\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201esteh auf mein Leib, verantwort dich,", "tokens": ["\u201e", "steh", "auf", "mein", "Leib", ",", "ver\u00b7ant\u00b7wort", "dich", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201edann ich bin hier, beschuldge dich.", "tokens": ["\u201e", "dann", "ich", "bin", "hier", ",", "be\u00b7schuld\u00b7ge", "dich", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "PPER", "VAFIN", "ADV", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Da hebet sich des Grabes Stein,", "tokens": ["Da", "he\u00b7bet", "sich", "des", "Gra\u00b7bes", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und geht hervor ein weis Gebein,", "tokens": ["Und", "geht", "her\u00b7vor", "ein", "weis", "Ge\u00b7bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Leib steht auf gar bald und schnell,", "tokens": ["Der", "Leib", "steht", "auf", "gar", "bald", "und", "schnell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADV", "ADV", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und geht dahin, spricht zu der Seel:", "tokens": ["Und", "geht", "da\u00b7hin", ",", "spricht", "zu", "der", "Seel", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "$,", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.4": {"line.1": {"text": "\u201ewer ist daraus, der mein begehrt,", "tokens": ["\u201e", "wer", "ist", "da\u00b7raus", ",", "der", "mein", "be\u00b7gehrt", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "PAV", "$,", "PRELS", "PPOSAT", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eder mich da rufet aus der Erd,", "tokens": ["\u201e", "der", "mich", "da", "ru\u00b7fet", "aus", "der", "Erd", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PRELS", "PPER", "ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201ebist du es Seele, die vor Jahren", "tokens": ["\u201e", "bist", "du", "es", "See\u00b7le", ",", "die", "vor", "Jah\u00b7ren"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "VAFIN", "PPER", "PPER", "NN", "$,", "PRELS", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eaus meinem Leibe ist gefahren?", "tokens": ["\u201e", "aus", "mei\u00b7nem", "Lei\u00b7be", "ist", "ge\u00b7fah\u00b7ren", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPOSAT", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Die Seele sprach: \u201eHab ich beten w\u00f6llen,", "tokens": ["Die", "See\u00b7le", "sprach", ":", "\u201e", "Hab", "ich", "be\u00b7ten", "w\u00f6l\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "NN", "PPER", "VVINF", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u201eda pflegtest du dich krank zu stellen,", "tokens": ["\u201e", "da", "pfleg\u00b7test", "du", "dich", "krank", "zu", "stel\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PRF", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u201ewenn ich anfieng das Abendgebet,", "tokens": ["\u201e", "wenn", "ich", "an\u00b7fi\u00b7eng", "das", "A\u00b7bend\u00b7ge\u00b7bet", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "\u201eda hast du dich gleich schlafen gelegt.", "tokens": ["\u201e", "da", "hast", "du", "dich", "gleich", "schla\u00b7fen", "ge\u00b7legt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "PRF", "ADV", "VVINF", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.6": {"line.1": {"text": "Der Leib sprach: \u201eAch ich schien nur faul,", "tokens": ["Der", "Leib", "sprach", ":", "\u201e", "Ach", "ich", "schien", "nur", "faul", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "ITJ", "PPER", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eund g\u00e4hnte, macht ein schiefes Maul,", "tokens": ["\u201e", "und", "g\u00e4hn\u00b7te", ",", "macht", "ein", "schie\u00b7fes", "Maul", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VVFIN", "$,", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201eund war zum niederknien verdrossen,", "tokens": ["\u201e", "und", "war", "zum", "nie\u00b7der\u00b7kni\u00b7en", "ver\u00b7dros\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VAFIN", "APPRART", "PIS", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u201edenn ich hatt einen Bettgenossen.", "tokens": ["\u201e", "denn", "ich", "hatt", "ei\u00b7nen", "Bett\u00b7ge\u00b7nos\u00b7sen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "\u201each weh! Ach weh, antwort die Seel,", "tokens": ["\u201e", "ach", "weh", "!", "Ach", "weh", ",", "ant\u00b7wort", "die", "Seel", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PTKVZ", "$.", "NN", "PTKVZ", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "\u201eda\u00df ich gewesen dein Gesell,", "tokens": ["\u201e", "da\u00df", "ich", "ge\u00b7we\u00b7sen", "dein", "Ge\u00b7sell", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "VAPP", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201ewovon die Ursach du allein", "tokens": ["\u201e", "wo\u00b7von", "die", "Ur\u00b7sach", "du", "al\u00b7lein"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "ART", "NN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201edarum leid ich die H\u00f6llenpein.", "tokens": ["\u201e", "da\u00b7rum", "leid", "ich", "die", "H\u00f6l\u00b7len\u00b7pein", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PAV", "ADJD", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "\u201eim Thal Josaphat am J\u00fcngsten Tag,", "tokens": ["\u201e", "im", "Thal", "Jo\u00b7sa\u00b7phat", "am", "J\u00fcng\u00b7sten", "Tag", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPRART", "NN", "NE", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u201eda will ich f\u00fchren grosse Klag,", "tokens": ["\u201e", "da", "will", "ich", "f\u00fch\u00b7ren", "gros\u00b7se", "Klag", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "VVINF", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201ealsdann wird angehn auch dein Leid,", "tokens": ["\u201e", "als\u00b7dann", "wird", "an\u00b7gehn", "auch", "dein", "Leid", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "VVPP", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201edu wirst brennen in Ewigkeit.", "tokens": ["\u201e", "du", "wirst", "bren\u00b7nen", "in", "E\u00b7wig\u00b7keit", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "VVINF", "APPR", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.9": {"line.1": {"text": "Da sprach der Leib: \u201eDu seyst verklagt,", "tokens": ["Da", "sprach", "der", "Leib", ":", "\u201e", "Du", "seyst", "ver\u00b7klagt", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "$(", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edu warst die Frau, und ich die Magd,", "tokens": ["\u201e", "du", "warst", "die", "Frau", ",", "und", "ich", "die", "Magd", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "$,", "KON", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201edu tr\u00e4gst mit mir die S\u00fcndenlast,", "tokens": ["\u201e", "du", "tr\u00e4gst", "mit", "mir", "die", "S\u00fcn\u00b7den\u00b7last", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPR", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eweil du mich b\u00f6s gef\u00fchret hast.", "tokens": ["\u201e", "weil", "du", "mich", "b\u00f6s", "ge\u00b7f\u00fch\u00b7ret", "hast", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PRF", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}