{"dta.poem.10262": {"metadata": {"author": {"name": "Liliencron, Detlev von", "birth": "N.A.", "death": "N.A."}, "title": "Kurz ist der Fr\u00fchling.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1883", "urn": "urn:nbn:de:kobv:b4-200905197184", "language": ["de:0.99"], "booktitle": "Liliencron, Detlev von: Adjutantenritte und andere Gedichte. Leipzig, [1883]."}, "poem": {"stanza.1": {"line.1": {"text": "Kam in ein Wirtshaus, ich wei\u00df nicht wie,             ", "tokens": ["Kam", "in", "ein", "Wirts\u00b7haus", ",", "ich", "wei\u00df", "nicht", "wie", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,", "PPER", "VVFIN", "PTKNEG", "KOKOM", "$,"], "meter": "---+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Tanzt der Soldate, tanzt der Commis.", "tokens": ["Tanzt", "der", "Sol\u00b7da\u00b7te", ",", "tanzt", "der", "Com\u00b7mis", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "War ein so sch\u00f6ner Fr\u00fchlingstag,", "tokens": ["War", "ein", "so", "sch\u00f6\u00b7ner", "Fr\u00fch\u00b7lings\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Schlug mein Herz so besonderen Schlag.", "tokens": ["Schlug", "mein", "Herz", "so", "be\u00b7son\u00b7de\u00b7ren", "Schlag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "ADJA", "NN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.5": {"text": "Trug ein wunderbar Verlangen,", "tokens": ["Trug", "ein", "wun\u00b7der\u00b7bar", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mit einem M\u00e4del heut anzufangen.", "tokens": ["Mit", "ei\u00b7nem", "M\u00e4\u00b7del", "heut", "an\u00b7zu\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VVIZU", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Und, alle Wetter, da seh\u2019 ich sie tanzen,", "tokens": ["Und", ",", "al\u00b7le", "Wet\u00b7ter", ",", "da", "seh'", "ich", "sie", "tan\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PIAT", "NN", "$,", "ADV", "VVFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Dichtete gleich zehntausend Stanzen.", "tokens": ["Dich\u00b7te\u00b7te", "gleich", "zehn\u00b7tau\u00b7send", "Stan\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "CARD", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.2": {"line.1": {"text": "Als wieder am Platze die T\u00e4nzerin,", "tokens": ["Als", "wie\u00b7der", "am", "Plat\u00b7ze", "die", "T\u00e4n\u00b7ze\u00b7rin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Ging ich stracks zu der Kleinen hin.", "tokens": ["Ging", "ich", "stracks", "zu", "der", "Klei\u00b7nen", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Bat sie, ein Glas zu trinken mit mir,", "tokens": ["Bat", "sie", ",", "ein", "Glas", "zu", "trin\u00b7ken", "mit", "mir", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "NN", "PTKZU", "VVINF", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ja, sagte sie gleich und ohne Gezier.", "tokens": ["Ja", ",", "sag\u00b7te", "sie", "gleich", "und", "oh\u00b7ne", "Ge\u00b7zier", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "ADV", "KON", "APPR", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Bestellt\u2019 ich uns eine kalte Flaschen,", "tokens": ["Be\u00b7stellt'", "ich", "uns", "ei\u00b7ne", "kal\u00b7te", "Fla\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und dem Holdchen etwas zum Naschen.", "tokens": ["Und", "dem", "Hold\u00b7chen", "et\u00b7was", "zum", "Na\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "APPRART", "NN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Blitzt mir ihr Auge dankbar entgegen,", "tokens": ["Blitzt", "mir", "ihr", "Au\u00b7ge", "dank\u00b7bar", "ent\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "ADJD", "PTKVZ", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Zuckt um die Lippen es noch verlegen.", "tokens": ["Zuckt", "um", "die", "Lip\u00b7pen", "es", "noch", "ver\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PPER", "ADV", "VVINF", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.3": {"line.1": {"text": "Kindel, mein Kutscher schlief drau\u00dfen aus,", "tokens": ["Kin\u00b7del", ",", "mein", "Kut\u00b7scher", "schlief", "drau\u00b7\u00dfen", "aus", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Wir fahren, ich bitt\u2019 dich, nun nach Haus.", "tokens": ["Wir", "fah\u00b7ren", ",", "ich", "bitt'", "dich", ",", "nun", "nach", "Haus", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "$,", "ADV", "APPR", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Lacht sie, die schelmische T\u00e4nzerin,", "tokens": ["Lacht", "sie", ",", "die", "schel\u00b7mi\u00b7sche", "T\u00e4n\u00b7ze\u00b7rin", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Das w\u00e4re gar nicht nach ihrem Sinn.", "tokens": ["Das", "w\u00e4\u00b7re", "gar", "nicht", "nach", "ih\u00b7rem", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Lie\u00df ich mich weiter von ihr bestricken,", "tokens": ["Lie\u00df", "ich", "mich", "wei\u00b7ter", "von", "ihr", "be\u00b7stri\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.6": {"text": "Mu\u00dfte den Kutscher zum Kuckuck schicken.", "tokens": ["Mu\u00df\u00b7te", "den", "Kut\u00b7scher", "zum", "Ku\u00b7ckuck", "schi\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.7": {"text": "Doch als der Morgen in Saal und Ecken,", "tokens": ["Doch", "als", "der", "Mor\u00b7gen", "in", "Saal", "und", "E\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "F\u00fchrt\u2019 ich am Arm sie durch Schlehdornhecken.", "tokens": ["F\u00fchrt'", "ich", "am", "Arm", "sie", "durch", "Schleh\u00b7dorn\u00b7he\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "PPER", "APPR", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "War so ein s\u00fc\u00dfes, verliebtes Ding,", "tokens": ["War", "so", "ein", "s\u00fc\u00b7\u00dfes", ",", "ver\u00b7lieb\u00b7tes", "Ding", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Noch ohne Schmuck und noch ohne Ring.", "tokens": ["Noch", "oh\u00b7ne", "Schmuck", "und", "noch", "oh\u00b7ne", "Ring", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "ADV", "APPR", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Freute sich kindisch \u00fcber ein Band,", "tokens": ["Freu\u00b7te", "sich", "kin\u00b7disch", "\u00fc\u00b7ber", "ein", "Band", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "\u00dcber ein Kettchen und allerlei Tand.", "tokens": ["\u00dc\u00b7ber", "ein", "Kett\u00b7chen", "und", "al\u00b7ler\u00b7lei", "Tand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "PIAT", "NN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.5": {"text": "Tranken zusammen die Chokolade,", "tokens": ["Tran\u00b7ken", "zu\u00b7sam\u00b7men", "die", "Cho\u00b7ko\u00b7la\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.6": {"text": "Besahen uns dann die Wachtparade,", "tokens": ["Be\u00b7sa\u00b7hen", "uns", "dann", "die", "Wacht\u00b7pa\u00b7ra\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Kaufte zum Hut ihr eine Feder,", "tokens": ["Kauf\u00b7te", "zum", "Hut", "ihr", "ei\u00b7ne", "Fe\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPRART", "NN", "PPER", "ART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Schenkt\u2019 ihr Handschuh von feinstem Leder.", "tokens": ["Schenkt'", "ihr", "Hand\u00b7schuh", "von", "feins\u00b7tem", "Le\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Wohnten im h\u00fcbschen Vorstadthaus,", "tokens": ["Wohn\u00b7ten", "im", "h\u00fcb\u00b7schen", "Vor\u00b7stadt\u00b7haus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Fern vom Markt und vom Stra\u00dfengebraus.", "tokens": ["Fern", "vom", "Markt", "und", "vom", "Stra\u00b7\u00dfen\u00b7ge\u00b7braus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "KON", "APPRART", "NN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Schaut in die Welt ihr Auge braun,", "tokens": ["Schaut", "in", "die", "Welt", "ihr", "Au\u00b7ge", "braun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ging ihre Welt bis zum Gartenzaun.", "tokens": ["Ging", "ih\u00b7re", "Welt", "bis", "zum", "Gar\u00b7ten\u00b7zaun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "APPRART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "War so gef\u00e4llig, war so bescheiden,", "tokens": ["War", "so", "ge\u00b7f\u00e4l\u00b7lig", ",", "war", "so", "be\u00b7schei\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "$,", "VAFIN", "ADV", "ADJD", "$,"], "meter": "---+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Dacht\u2019 ich nimmer an Scheiden und Meiden.", "tokens": ["Dacht'", "ich", "nim\u00b7mer", "an", "Schei\u00b7den", "und", "Mei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "Doch als der Sommer kam in die Lande,", "tokens": ["Doch", "als", "der", "Som\u00b7mer", "kam", "in", "die", "Lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Trennten sich unsere Liebesbande.", "tokens": ["Trenn\u00b7ten", "sich", "un\u00b7se\u00b7re", "Lie\u00b7bes\u00b7ban\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PPOSAT", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}}}}