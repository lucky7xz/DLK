{"textgrid.poem.67714": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "1L: Da\u00df er die Bande brach und aus den kalten Schatten", "genre": "verse", "period": "N.A.", "pub_year": 1777, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Da\u00df er die Bande brach und aus den kalten Schatten", "tokens": ["Da\u00df", "er", "die", "Ban\u00b7de", "brach", "und", "aus", "den", "kal\u00b7ten", "Schat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Finsterni\u00df, ein Morgenstern,", "tokens": ["Der", "Fins\u00b7ter\u00b7ni\u00df", ",", "ein", "Mor\u00b7gens\u00b7tern", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.3": {"text": "Hervorging, Allen, die in Nacht geseufzet hatten,", "tokens": ["Her\u00b7vor\u00b7ging", ",", "Al\u00b7len", ",", "die", "in", "Nacht", "ge\u00b7seuf\u00b7zet", "hat\u00b7ten", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NE", "$,", "PRELS", "APPR", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein s\u00fc\u00dfes Licht vom Herrn:", "tokens": ["Ein", "s\u00fc\u00b7\u00dfes", "Licht", "vom", "Herrn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Mein Geist, de\u00df freue Dich! und freue sich, wer liebet", "tokens": ["Mein", "Geist", ",", "de\u00df", "freu\u00b7e", "Dich", "!", "und", "freu\u00b7e", "sich", ",", "wer", "lie\u00b7bet"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "ART", "ADJA", "PPER", "$.", "KON", "VVFIN", "PRF", "$,", "PWS", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der hohen Mittagssonne Pracht,", "tokens": ["Der", "ho\u00b7hen", "Mit\u00b7tags\u00b7son\u00b7ne", "Pracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Freu' sich des Morgensterns! und wer ihn tr\u00fcbet,", "tokens": ["Freu'", "sich", "des", "Mor\u00b7gens\u00b7terns", "!", "und", "wer", "ihn", "tr\u00fc\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "$.", "KON", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Weich' in die alte Nacht!", "tokens": ["Weich'", "in", "die", "al\u00b7te", "Nacht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Gott kam, und Wolken unter seinen F\u00fc\u00dfen", "tokens": ["Gott", "kam", ",", "und", "Wol\u00b7ken", "un\u00b7ter", "sei\u00b7nen", "F\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "$,", "KON", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zerrannen, weite S\u00fcndfluth go\u00df", "tokens": ["Zer\u00b7ran\u00b7nen", ",", "wei\u00b7te", "S\u00fcnd\u00b7fluth", "go\u00df"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hinweg den alten Staub, und als die Wolken rissen", "tokens": ["Hin\u00b7weg", "den", "al\u00b7ten", "Staub", ",", "und", "als", "die", "Wol\u00b7ken", "ris\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "$,", "KON", "KOUS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und weite S\u00fcndfluth flo\u00df \u2013", "tokens": ["Und", "wei\u00b7te", "S\u00fcnd\u00b7fluth", "flo\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Noch d\u00e4mmert's tief. Der Griechen sch\u00f6ne Pfade,", "tokens": ["Noch", "d\u00e4m\u00b7mert's", "tief", ".", "Der", "Grie\u00b7chen", "sch\u00f6\u00b7ne", "Pfa\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "$.", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So hell, so eben, lagen da", "tokens": ["So", "hell", ",", "so", "e\u00b7ben", ",", "la\u00b7gen", "da"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADV", "$,", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vergangen. Alles schaut' auf d\u00fcstre, krumme Pfade,", "tokens": ["Ver\u00b7gan\u00b7gen", ".", "Al\u00b7les", "schaut'", "auf", "d\u00fcst\u00b7re", ",", "krum\u00b7me", "Pfa\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "PIS", "VVFIN", "APPR", "VVFIN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem d\u00fcstern Orkus nah.", "tokens": ["Dem", "d\u00fcs\u00b7tern", "Or\u00b7kus", "nah", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NE", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "An Licht, an freiem Blick gebrach's! Im Staube", "tokens": ["An", "Licht", ",", "an", "frei\u00b7em", "Blick", "ge\u00b7brach's", "!", "Im", "Stau\u00b7be"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "$,", "APPR", "ADJA", "NN", "NE", "$.", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Lag noch das heil'ge Morgenland,", "tokens": ["Lag", "noch", "das", "heil'\u00b7ge", "Mor\u00b7gen\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Jehovah's altes Wort, der Wahrheit Quell, zum Raube", "tokens": ["Je\u00b7ho\u00b7vah's", "al\u00b7tes", "Wort", ",", "der", "Wahr\u00b7heit", "Quell", ",", "zum", "Rau\u00b7be"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "ADJA", "NN", "$,", "ART", "NN", "NN", "$,", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Des Unsinns, unerkannt", "tokens": ["Des", "Un\u00b7sinns", ",", "un\u00b7er\u00b7kannt"], "token_info": ["word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Und unverstanden. Da ging auf aus Hainen,", "tokens": ["Und", "un\u00b7ver\u00b7stan\u00b7den", ".", "Da", "ging", "auf", "aus", "Hai\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$.", "ADV", "VVFIN", "APPR", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "O Suevien, Dein Morgenstern!", "tokens": ["O", "Sue\u00b7vi\u00b7en", ",", "Dein", "Mor\u00b7gens\u00b7tern", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.3": {"text": "Und leuchtete so sch\u00f6n, so thauicht, wie im reinen", "tokens": ["Und", "leuch\u00b7te\u00b7te", "so", "sch\u00f6n", ",", "so", "thau\u00b7icht", ",", "wie", "im", "rei\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "$,", "ADV", "VVFIN", "$,", "PWAV", "APPRART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Urglanz der Welt, von fern.", "tokens": ["Ur\u00b7glanz", "der", "Welt", ",", "von", "fern", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "APPR", "ADJD", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.7": {"line.1": {"text": "Ein Vater neuer Zeit, die ihm an Seele", "tokens": ["Ein", "Va\u00b7ter", "neu\u00b7er", "Zeit", ",", "die", "ihm", "an", "See\u00b7le"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "PRELS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und Mund und Antlitz, an der Hand", "tokens": ["Und", "Mund", "und", "Ant\u00b7litz", ",", "an", "der", "Hand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Geweihten Z\u00fcgen hing, er hob sie aus der H\u00f6hle", "tokens": ["Ge\u00b7weih\u00b7ten", "Z\u00fc\u00b7gen", "hing", ",", "er", "hob", "sie", "aus", "der", "H\u00f6h\u00b7le"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dort in sein Morgenland.", "tokens": ["Dort", "in", "sein", "Mor\u00b7gen\u00b7land", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Wohl ist mir's, wohl an Dir, o Vater! f\u00fchrest", "tokens": ["Wohl", "ist", "mir's", ",", "wohl", "an", "Dir", ",", "o", "Va\u00b7ter", "!", "f\u00fch\u00b7rest"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "VAFIN", "NE", "$,", "ADV", "APPR", "PPER", "$,", "FM", "NN", "$.", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So fern uns und so milde fort", "tokens": ["So", "fern", "uns", "und", "so", "mil\u00b7de", "fort"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "PPER", "KON", "ADV", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In innres, tiefes Gottgeheimni\u00df und regierest", "tokens": ["In", "inn\u00b7res", ",", "tie\u00b7fes", "Gott\u00b7ge\u00b7heim\u00b7ni\u00df", "und", "re\u00b7gie\u00b7rest"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "$,", "ADJA", "NN", "KON", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Uns mit dem ", "tokens": ["Uns", "mit", "dem"], "token_info": ["word", "word", "word"], "pos": ["PPER", "APPR", "ART"], "meter": "++-", "measure": "unknown.measure.di"}}, "stanza.9": {"line.1": {"text": "Wolauf, wolauf, mein Lied! Erwach und schalle", "tokens": ["Wo\u00b7lauf", ",", "wo\u00b7lauf", ",", "mein", "Lied", "!", "Er\u00b7wach", "und", "schal\u00b7le"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "$,", "VMFIN", "$,", "PPOSAT", "NN", "$.", "NN", "KON", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dem Sieger seiner Sieger, ihm,", "tokens": ["Dem", "Sie\u00b7ger", "sei\u00b7ner", "Sie\u00b7ger", ",", "ihm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der mit Verlassnen auszog und im Wunderhalle", "tokens": ["Der", "mit", "Ver\u00b7lass\u00b7nen", "aus\u00b7zog", "und", "im", "Wun\u00b7der\u00b7hal\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "VVFIN", "KON", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vollendete, ", "tokens": ["Voll\u00b7en\u00b7de\u00b7te", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "-+--", "measure": "dactylic.init"}}, "stanza.10": {"line.1": {"text": "Sie kamen (H\u00f6llenfackeln in den H\u00e4nden),", "tokens": ["Sie", "ka\u00b7men", "(", "H\u00f6l\u00b7len\u00b7fa\u00b7ckeln", "in", "den", "H\u00e4n\u00b7den", ")", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$(", "NN", "APPR", "ART", "NN", "$(", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der unterdr\u00fcckten J\u00fcdenschaar", "tokens": ["Der", "un\u00b7ter\u00b7dr\u00fcck\u00b7ten", "J\u00fc\u00b7den\u00b7schaar"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die B\u00fccher wegzugl\u00fchn und mit den H\u00f6llenbr\u00e4nden", "tokens": ["Die", "B\u00fc\u00b7cher", "weg\u00b7zu\u00b7gl\u00fchn", "und", "mit", "den", "H\u00f6l\u00b7len\u00b7br\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zu prangen vorm Altar.", "tokens": ["Zu", "pran\u00b7gen", "vorm", "Al\u00b7tar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Und Kaisers Wort ging aus. Die alten Schatten", "tokens": ["Und", "Kai\u00b7sers", "Wort", "ging", "aus", ".", "Die", "al\u00b7ten", "Schat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "NN", "VVFIN", "PTKVZ", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "In weiser J\u00fcden Heiligthum", "tokens": ["In", "wei\u00b7ser", "J\u00fc\u00b7den", "Hei\u00b7lig\u00b7thum"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Erbebten dem Gericht: \u00bbWer wird uns, wer erstatten,", "tokens": ["Er\u00b7beb\u00b7ten", "dem", "Ge\u00b7richt", ":", "\u00bb", "Wer", "wird", "uns", ",", "wer", "er\u00b7stat\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$.", "$(", "PWS", "VAFIN", "PPER", "$,", "PWS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer retten unsern Ruhm?\u00ab", "tokens": ["Wer", "ret\u00b7ten", "un\u00b7sern", "Ruhm", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VVFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Da zog er aus und stritt und drang zum Kaiser.", "tokens": ["Da", "zog", "er", "aus", "und", "stritt", "und", "drang", "zum", "Kai\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "KON", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und Wespen-, Schlangen-Ungest\u00fcm", "tokens": ["Und", "Wes\u00b7pen", ",", "Schlan\u00b7gen\u00b7Un\u00b7ge\u00b7st\u00fcm"], "token_info": ["word", "word", "punct", "word"], "pos": ["KON", "TRUNC", "$,", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Lag auf ihm. Er erstand's! und sieget' einmal. Kaiser,", "tokens": ["Lag", "auf", "ihm", ".", "Er", "er\u00b7stan\u00b7d's", "!", "und", "sie\u00b7get'", "ein\u00b7mal", ".", "Kai\u00b7ser", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "APPR", "PPER", "$.", "PPER", "PIS", "$.", "KON", "VVFIN", "ADV", "$.", "NN", "$,"], "meter": "-+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Du kannst nicht helfen ihm!", "tokens": ["Du", "kannst", "nicht", "hel\u00b7fen", "ihm", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Der Wespenschwarm erbraust. Die Schaar der Schlangen", "tokens": ["Der", "Wes\u00b7pen\u00b7schwarm", "er\u00b7braust", ".", "Die", "Schaar", "der", "Schlan\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Verstopft ihr Ohr dem Zauberwort", "tokens": ["Ver\u00b7stopft", "ihr", "Ohr", "dem", "Zau\u00b7ber\u00b7wort"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des Rufers. Sickingen, Du rufst umsonst! Sie hangen", "tokens": ["Des", "Ru\u00b7fers", ".", "Si\u00b7ckin\u00b7gen", ",", "Du", "rufst", "um\u00b7sonst", "!", "Sie", "han\u00b7gen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$.", "NE", "$,", "PPER", "VVFIN", "ADV", "$.", "PPER", "VVINF"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Nur an dem Edeln dort,", "tokens": ["Nur", "an", "dem", "E\u00b7deln", "dort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ADV", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.14": {"line.1": {"text": "Anspeien ihn mit Giftstrom; all sein Leben", "tokens": ["An\u00b7spei\u00b7en", "ihn", "mit", "Gifts\u00b7trom", ";", "all", "sein", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "APPR", "NN", "$.", "PIAT", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Erkranket, siechet fort und fort.", "tokens": ["Er\u00b7kran\u00b7ket", ",", "sie\u00b7chet", "fort", "und", "fort", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Erstirbt er? Nein! auf ihm liegt Siegel Gottes! Beben", "tokens": ["Er\u00b7stirbt", "er", "?", "Nein", "!", "auf", "ihm", "liegt", "Sie\u00b7gel", "Got\u00b7tes", "!", "Be\u00b7ben"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "$.", "PTKANT", "$.", "APPR", "PPER", "VVFIN", "NN", "NN", "$.", "NN"], "meter": "-+-+--++-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Geht aus vom ", "tokens": ["Geht", "aus", "vom"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "APPR", "APPRART"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.15": {"line.1": {"text": "Er ruft nach Rom zum dritten Mal. Sie blitzen", "tokens": ["Er", "ruft", "nach", "Rom", "zum", "drit\u00b7ten", "Mal", ".", "Sie", "blit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NE", "APPRART", "ADJA", "NN", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Voran und werfen siegerisch", "tokens": ["Vo\u00b7ran", "und", "wer\u00b7fen", "sie\u00b7ge\u00b7risch"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Schon ihre Kronen auf. \u00bbWer soll in Rom Dich sch\u00fctzen?\u00ab", "tokens": ["Schon", "ih\u00b7re", "Kro\u00b7nen", "auf", ".", "\u00bb", "Wer", "soll", "in", "Rom", "Dich", "sch\u00fct\u00b7zen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PTKVZ", "$.", "$(", "PWS", "VMFIN", "APPR", "NE", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und z\u00fcngeln, stechen frisch.", "tokens": ["Und", "z\u00fcn\u00b7geln", ",", "ste\u00b7chen", "frisch", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "VVFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Und nun genug! Er steht! die Schlangen funkeln", "tokens": ["Und", "nun", "ge\u00b7nug", "!", "Er", "steht", "!", "die", "Schlan\u00b7gen", "fun\u00b7keln"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "$.", "PPER", "VVFIN", "$.", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf seinem Haupte, Kronen nun!", "tokens": ["Auf", "sei\u00b7nem", "Haup\u00b7te", ",", "Kro\u00b7nen", "nun", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Neu gl\u00e4nzt der Morgenstern nach schwerem Kampf im Dunkeln", "tokens": ["Neu", "gl\u00e4nzt", "der", "Mor\u00b7gens\u00b7tern", "nach", "schwe\u00b7rem", "Kampf", "im", "Dun\u00b7keln"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "APPRART", "NN"], "meter": "++-+---+-+-+-", "measure": "unknown.measure.hexa"}, "line.4": {"text": "Und ruht und kann nun ruhn.", "tokens": ["Und", "ruht", "und", "kann", "nun", "ruhn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Sein sind die Edeln. Alle Edeln waren", "tokens": ["Sein", "sind", "die", "E\u00b7deln", ".", "Al\u00b7le", "E\u00b7deln", "wa\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "VAFIN", "ART", "NN", "$.", "PIAT", "NN", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mit ihm im Kampf geheim und treu.", "tokens": ["Mit", "ihm", "im", "Kampf", "ge\u00b7heim", "und", "treu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPRART", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wolan, wolan, mein Lied! nenn ihre treuen Schaaren,", "tokens": ["Wo\u00b7lan", ",", "wo\u00b7lan", ",", "mein", "Lied", "!", "nenn", "ih\u00b7re", "treu\u00b7en", "Schaa\u00b7ren", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "$,", "PPOSAT", "NN", "$.", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df rings ihr Name sei!", "tokens": ["Da\u00df", "rings", "ihr", "Na\u00b7me", "sei", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Held Hutten ging voran und blitzt' im Feuer", "tokens": ["Held", "Hut\u00b7ten", "ging", "vo\u00b7ran", "und", "blitzt'", "im", "Feu\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "NN", "VVFIN", "PTKVZ", "KON", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und geht voran itzt und singt froh:", "tokens": ["Und", "geht", "vo\u00b7ran", "itzt", "und", "singt", "froh", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u00bbmein Deutschland! Kennst Du Dich, sind Dir die Deinen theuer,", "tokens": ["\u00bb", "mein", "Deutschland", "!", "Kennst", "Du", "Dich", ",", "sind", "Dir", "die", "Dei\u00b7nen", "theu\u00b7er", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$.", "VVFIN", "PPER", "PPER", "$,", "VAFIN", "PPER", "ART", "PPOSAT", "ADJD", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "So singe mit, Jo!\u00ab", "tokens": ["So", "sin\u00b7ge", "mit", ",", "Jo", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PTKVZ", "$,", "NE", "$.", "$("], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.19": {"line.1": {"text": "Und Sickingen und Busch und Bilibald und Alle,", "tokens": ["Und", "Si\u00b7ckin\u00b7gen", "und", "Busch", "und", "Bi\u00b7li\u00b7bald", "und", "Al\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "KON", "NN", "KON", "PIS", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Benignus und Graf Nuenar,", "tokens": ["Be\u00b7nig\u00b7nus", "und", "Graf", "Nu\u00b7e\u00b7nar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "NE", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Selbst Maximilian frohlockt zum Jubelschalle.", "tokens": ["Selbst", "Ma\u00b7xi\u00b7mi\u00b7li\u00b7an", "froh\u00b7lockt", "zum", "Ju\u00b7bel\u00b7schal\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auch Du bist in der Schaar,", "tokens": ["Auch", "Du", "bist", "in", "der", "Schaar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-----+", "measure": "unknown.measure.single"}}, "stanza.20": {"line.1": {"text": "Erasmus? und verg\u00f6ttest itzt? Und bliebest", "tokens": ["Er\u00b7as\u00b7mus", "?", "und", "ver\u00b7g\u00f6t\u00b7test", "itzt", "?", "Und", "blie\u00b7best"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "$.", "KON", "VVFIN", "ADV", "$.", "KON", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So still einst, \u00fcberlegtest Dir!", "tokens": ["So", "still", "einst", ",", "\u00fc\u00b7ber\u00b7leg\u00b7test", "Dir", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und sondertest Dich aus, weil Du den ", "tokens": ["Und", "son\u00b7der\u00b7test", "Dich", "aus", ",", "weil", "Du", "den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "PPER", "ART"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Und warst nicht mit uns hier.", "tokens": ["Und", "warst", "nicht", "mit", "uns", "hier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "APPR", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Und liebst nicht J\u00fcdengrillen, bliebst, zu lauschen", "tokens": ["Und", "liebst", "nicht", "J\u00fc\u00b7den\u00b7gril\u00b7len", ",", "bliebst", ",", "zu", "lau\u00b7schen"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "NN", "$,", "VVFIN", "$,", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dem Bl\u00f6ken Deiner Heerde zart", "tokens": ["Dem", "Bl\u00f6\u00b7ken", "Dei\u00b7ner", "Heer\u00b7de", "zart"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wie? nun bebst Du nicht und kommst, da Jubelrauschen", "tokens": ["Und", "wie", "?", "nun", "bebst", "Du", "nicht", "und", "kommst", ",", "da", "Ju\u00b7belr\u00b7au\u00b7schen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PWAV", "$.", "ADV", "VVFIN", "PPER", "PTKNEG", "KON", "VVFIN", "$,", "KOUS", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es allweg offenbart.", "tokens": ["Es", "all\u00b7weg", "of\u00b7fen\u00b7bart", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Sieh auf! blick auf! dort geben andre Seelen", "tokens": ["Sieh", "auf", "!", "blick", "auf", "!", "dort", "ge\u00b7ben", "and\u00b7re", "See\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "PTKVZ", "$.", "VVIMP", "PTKVZ", "$.", "ADV", "VVINF", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ihr Leben reichlich in den Tod", "tokens": ["Ihr", "Le\u00b7ben", "reich\u00b7lich", "in", "den", "Tod"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und stehn auf Feldesh\u00f6h und blicken nicht aus H\u00f6hlen", "tokens": ["Und", "stehn", "auf", "Fel\u00b7des\u00b7h\u00f6h", "und", "bli\u00b7cken", "nicht", "aus", "H\u00f6h\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "VVFIN", "PTKNEG", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ins stille Morgenroth.", "tokens": ["Ins", "stil\u00b7le", "Mor\u00b7gen\u00b7roth", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Die F\u00fcrsten sind im Kampf. Da kommt und segnet", "tokens": ["Die", "F\u00fcrs\u00b7ten", "sind", "im", "Kampf", ".", "Da", "kommt", "und", "seg\u00b7net"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "$.", "ADV", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den Greis Reuchlin, den Gottesmann,", "tokens": ["Den", "Greis", "Reuch\u00b7lin", ",", "den", "Got\u00b7tes\u00b7mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der's aushielt, Luther, und geht f\u00fcrder und begegnet", "tokens": ["Der's", "aus\u00b7hielt", ",", "Lu\u00b7ther", ",", "und", "geht", "f\u00fcr\u00b7der", "und", "be\u00b7geg\u00b7net"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "NE", "$,", "KON", "VVFIN", "ADJD", "KON", "VVFIN"], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "(wer, der ihm ob sein kann?)", "tokens": ["(", "wer", ",", "der", "ihm", "ob", "sein", "kann", "?", ")"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "$,", "PRELS", "PPER", "KOUS", "VAINF", "VMFIN", "$.", "$("], "meter": "---+-+", "measure": "unknown.measure.di"}}, "stanza.24": {"line.1": {"text": "Noch tiefrer Mitternacht. Und an ihm gl\u00e4nzet", "tokens": ["Noch", "tief\u00b7rer", "Mit\u00b7ter\u00b7nacht", ".", "Und", "an", "ihm", "gl\u00e4n\u00b7zet"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "$.", "KON", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sein Streitgeno\u00df, ein Zwillingsstern,", "tokens": ["Sein", "Streit\u00b7ge\u00b7no\u00df", ",", "ein", "Zwil\u00b7lings\u00b7stern", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Melanchthon, den Reuchlin ihm gab. Zwar Castor grenzet", "tokens": ["Me\u00b7lanch\u00b7thon", ",", "den", "Reuch\u00b7lin", "ihm", "gab", ".", "Zwar", "Cas\u00b7tor", "gren\u00b7zet"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "ART", "NE", "PPER", "VVFIN", "$.", "ADV", "NE", "VVFIN"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "An Halbgott Pollux fern", "tokens": ["An", "Halb\u00b7gott", "Pol\u00b7lux", "fern"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "NE", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Und sterblich nur; doch Br\u00fcder, theilen Beide", "tokens": ["Und", "sterb\u00b7lich", "nur", ";", "doch", "Br\u00fc\u00b7der", ",", "thei\u00b7len", "Bei\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADJD", "ADV", "$.", "ADV", "NN", "$,", "VVFIN", "PIS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sich Tag um Tag nun Ewigkeit;", "tokens": ["Sich", "Tag", "um", "Tag", "nun", "E\u00b7wig\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "NN", "APPR", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und alle Sterne sind in lauten Kampfes Freude", "tokens": ["Und", "al\u00b7le", "Ster\u00b7ne", "sind", "in", "lau\u00b7ten", "Kamp\u00b7fes", "Freu\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VAFIN", "APPR", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und siegen weit und breit;", "tokens": ["Und", "sie\u00b7gen", "weit", "und", "breit", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Und Himmelsb\u00e4che flie\u00dfen, w\u00e4lzen pr\u00e4chtig,", "tokens": ["Und", "Him\u00b7mels\u00b7b\u00e4\u00b7che", "flie\u00b7\u00dfen", ",", "w\u00e4l\u00b7zen", "pr\u00e4ch\u00b7tig", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "$,", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von Weisheit stark, die Leichen fort.", "tokens": ["Von", "Weis\u00b7heit", "stark", ",", "die", "Lei\u00b7chen", "fort", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "$,", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Tritt auf die Starken, Geist des Liedes, die so m\u00e4chtig", "tokens": ["Tritt", "auf", "die", "Star\u00b7ken", ",", "Geist", "des", "Lie\u00b7des", ",", "die", "so", "m\u00e4ch\u00b7tig"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,", "NN", "ART", "NN", "$,", "PRELS", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da liegen hie und dort!", "tokens": ["Da", "lie\u00b7gen", "hie", "und", "dort", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Die Rosse strauchelten am Siegeswagen", "tokens": ["Die", "Ros\u00b7se", "strau\u00b7chel\u00b7ten", "am", "Sie\u00b7ges\u00b7wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Und wandten sich; sie jagt die Schaar,", "tokens": ["Und", "wand\u00b7ten", "sich", ";", "sie", "jagt", "die", "Schaar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "$.", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie jagt sich selbst. Ihm Fluch, der konnte f\u00fcr uns zagen,", "tokens": ["Sie", "jagt", "sich", "selbst", ".", "Ihm", "Fluch", ",", "der", "konn\u00b7te", "f\u00fcr", "uns", "za\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "$.", "PPER", "NN", "$,", "PRELS", "VMFIN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit Gott und uns nicht war!", "tokens": ["Mit", "Gott", "und", "uns", "nicht", "war", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "PPER", "PTKNEG", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Und Heil ihm, der voranging, fremder Sache", "tokens": ["Und", "Heil", "ihm", ",", "der", "vor\u00b7an\u00b7ging", ",", "frem\u00b7der", "Sa\u00b7che"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "PPER", "$,", "PRELS", "VVFIN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Erk\u00e4mpfend schon all ", "tokens": ["Er\u00b7k\u00e4mp\u00b7fend", "schon", "all"], "token_info": ["word", "word", "word"], "pos": ["VVPP", "ADV", "PIAT"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Sie gierten J\u00fcdengold, die B\u00fccherbrenner. Rache", "tokens": ["Sie", "gier\u00b7ten", "J\u00fc\u00b7den\u00b7gold", ",", "die", "B\u00fc\u00b7cher\u00b7bren\u00b7ner", ".", "Ra\u00b7che"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "NE", "$,", "ART", "NN", "$.", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem Thier in Goldesdampf!", "tokens": ["Dem", "Thier", "in", "Gol\u00b7des\u00b7dampf", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "Hoogstraten, Rache Dir! Du gierst? Zum Lohne", "tokens": ["Hoogs\u00b7tra\u00b7ten", ",", "Ra\u00b7che", "Dir", "!", "Du", "gierst", "?", "Zum", "Loh\u00b7ne"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NE", "$,", "NN", "PPER", "$.", "PPER", "VVFIN", "$.", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wird Dir statt Goldes Blei; das fa\u00dft", "tokens": ["Wird", "Dir", "statt", "Gol\u00b7des", "Blei", ";", "das", "fa\u00dft"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "NN", "NN", "$.", "PDS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des fr\u00f6mmsten Mannes Hand und dr\u00fcckt's Dir auf zur Krone;", "tokens": ["Des", "fr\u00f6mms\u00b7ten", "Man\u00b7nes", "Hand", "und", "dr\u00fcckt's", "Dir", "auf", "zur", "Kro\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "KON", "VVFIN", "PPER", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da kr\u00fcmmt' er sich, erbla\u00dft,", "tokens": ["Da", "kr\u00fcmmt'", "er", "sich", ",", "er\u00b7bla\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$,", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Der Ketzerheld, zu Boden. \u00bbWie? sein Wagen", "tokens": ["Der", "Ket\u00b7zer\u00b7held", ",", "zu", "Bo\u00b7den", ".", "\u00bb", "Wie", "?", "sein", "Wa\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "APPR", "NN", "$.", "$(", "PWAV", "$.", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Verzeucht noch stets? Es weilet lang'", "tokens": ["Ver\u00b7zeucht", "noch", "stets", "?", "Es", "wei\u00b7let", "lang'"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ADV", "ADV", "$.", "PPER", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In Rom sein Siegesr\u00e4derrasseln!\u00ab So mit Zagen", "tokens": ["In", "Rom", "sein", "Sie\u00b7ges\u00b7r\u00e4\u00b7der\u00b7ras\u00b7seln", "!", "\u00ab", "So", "mit", "Za\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "PPOSAT", "NN", "$.", "$(", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sah Mutter K\u00f6ln und bang", "tokens": ["Sah", "Mut\u00b7ter", "K\u00f6ln", "und", "bang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "NE", "KON", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "Nach ihrem Sohn zum Fenster. \u00bbEr theilt Beute,\u00ab", "tokens": ["Nach", "ih\u00b7rem", "Sohn", "zum", "Fens\u00b7ter", ".", "\u00bb", "Er", "theilt", "Beu\u00b7te", ",", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "NN", "$.", "$(", "PPER", "VVFIN", "NN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sprach Vater Ortuin; \u00bbden Raub", "tokens": ["Sprach", "Va\u00b7ter", "Or\u00b7tu\u00b7in", ";", "\u00bb", "den", "Raub"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word"], "pos": ["NN", "NN", "NE", "$.", "$(", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der J\u00fcden bringt er uns und unsern Dirnen heute", "tokens": ["Der", "J\u00fc\u00b7den", "bringt", "er", "uns", "und", "un\u00b7sern", "Dir\u00b7nen", "heu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "PPER", "KON", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und trat sie l\u00e4ngst in Staub!\u00ab", "tokens": ["Und", "trat", "sie", "l\u00e4ngst", "in", "Staub", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "So m\u00fcssen sie vergehn, die Wahrheitwonne", "tokens": ["So", "m\u00fcs\u00b7sen", "sie", "ver\u00b7gehn", ",", "die", "Wahr\u00b7heit\u00b7won\u00b7ne"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "VVINF", "$,", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Vertauschen mit der L\u00fcge Nacht;", "tokens": ["Ver\u00b7tau\u00b7schen", "mit", "der", "L\u00fc\u00b7ge", "Nacht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wer Dich liebet, Herr, sei, wie die helle Sonne", "tokens": ["Und", "wer", "Dich", "lie\u00b7bet", ",", "Herr", ",", "sei", ",", "wie", "die", "hel\u00b7le", "Son\u00b7ne"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,", "NN", "$,", "VAFIN", "$,", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Aufgeht in ihrer Macht!", "tokens": ["Auf\u00b7geht", "in", "ih\u00b7rer", "Macht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}