{"dta.poem.8397": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "IiI.  \n  Venator.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1630", "urn": "urn:nbn:de:kobv:b4-200905197863", "language": ["de:0.99"], "booktitle": "Opitz, Martin: Sch\u00e4fferey Von der Nimfen Hercinie. Breslau, 1630."}, "poem": {"stanza.1": {"line.1": {"text": "Ihr Schwestern/ derer geist auff vns Poeten schwebet/", "tokens": ["Ihr", "Schwes\u00b7tern", "/", "de\u00b7rer", "geist", "auff", "vns", "Po\u00b7et\u00b7en", "schwe\u00b7bet", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PDS", "NN", "APPR", "PPER", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Anietzt begehr ich nicht zue ewrem Helicon;", "tokens": ["An\u00b7ietzt", "be\u00b7gehr", "ich", "nicht", "zue", "ew\u00b7rem", "He\u00b7li\u00b7con", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Ihr Wa\u00dfernimfen kompt/ sucht einen s\u00fc\u00dfen thon/", "tokens": ["Ihr", "Wa\u00b7\u00dfer\u00b7nim\u00b7fen", "kompt", "/", "sucht", "ei\u00b7nen", "s\u00fc\u00b7\u00dfen", "thon", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$(", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Damit jhr de\u00dfen rhum der euch auch ziehrt erhebet.", "tokens": ["Da\u00b7mit", "jhr", "de\u00b7\u00dfen", "rhum", "der", "euch", "auch", "ziehrt", "er\u00b7he\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "PPER", "ADV", "VVFIN", "VVFIN", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.2": {"line.1": {"text": "Ihm dancket da\u00df jhr ietzt das quell noch sch\u00f6ner gebet/", "tokens": ["Ihm", "dan\u00b7cket", "da\u00df", "jhr", "ietzt", "das", "quell", "noch", "sch\u00f6\u00b7ner", "ge\u00b7bet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOUS", "PPER", "ADV", "ART", "NN", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Seht jung au\u00df wie jhr seidt/ besitzet einen thron", "tokens": ["Seht", "jung", "au\u00df", "wie", "jhr", "seidt", "/", "be\u00b7sit\u00b7zet", "ei\u00b7nen", "thron"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "PTKVZ", "KOKOM", "PPER", "VAFIN", "$(", "VVFIN", "ART", "NN"], "meter": "-+-++--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der scha wens w\u00fcrdig ist/ da Venus vndt jhr Sohn/", "tokens": ["Der", "scha", "wens", "w\u00fcr\u00b7dig", "ist", "/", "da", "Ve\u00b7nus", "vndt", "jhr", "Sohn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADV", "ADJD", "VAFIN", "$(", "KOUS", "NN", "KON", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vndt alle Gratien/ vndt rhue/ vndt frewde lebet.", "tokens": ["Vndt", "al\u00b7le", "Gra\u00b7ti\u00b7en", "/", "vndt", "rhue", "/", "vndt", "frew\u00b7de", "le\u00b7bet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$(", "KON", "VVFIN", "$(", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Du heldt/ dem dieses Badt von alters zuegeh\u00f6rt/", "tokens": ["Du", "heldt", "/", "dem", "die\u00b7ses", "Badt", "von", "al\u00b7ters", "zu\u00b7e\u00b7ge\u00b7h\u00f6rt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "ART", "ADJA", "NN", "APPR", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Du hast jhm seine ziehr durch deinen baw vermehrt/", "tokens": ["Du", "hast", "jhm", "sei\u00b7ne", "ziehr", "durch", "dei\u00b7nen", "baw", "ver\u00b7mehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drumb hebt ein weiser sinn dich billich hoch auff erden.", "tokens": ["Drumb", "hebt", "ein", "wei\u00b7ser", "sinn", "dich", "bil\u00b7lich", "hoch", "auff", "er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "ADJA", "NN", "PRF", "ADJD", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Nach dem durch dein verdienst/ durch thaten/ durch verstandt/", "tokens": ["Nach", "dem", "durch", "dein", "ver\u00b7dienst", "/", "durch", "tha\u00b7ten", "/", "durch", "ver\u00b7standt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "APPR", "PPOSAT", "NN", "$(", "APPR", "VVFIN", "$(", "APPR", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dein schuldner worden ist das gantze Vaterlandt/", "tokens": ["Dein", "schuld\u00b7ner", "wor\u00b7den", "ist", "das", "gant\u00b7ze", "Va\u00b7ter\u00b7landt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "VAPP", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So mu\u00df das wa\u00dfer auch von dir begabet werden.", "tokens": ["So", "mu\u00df", "das", "wa\u00b7\u00dfer", "auch", "von", "dir", "be\u00b7ga\u00b7bet", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "ADV", "APPR", "PPER", "VVFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}