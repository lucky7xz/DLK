{"dta.poem.11942": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "103.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1839", "urn": "urn:nbn:de:kobv:b4-200905195119", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "La\u00df uns besonnen seyn! Wir waren unbesonnen,", "tokens": ["La\u00df", "uns", "be\u00b7son\u00b7nen", "seyn", "!", "Wir", "wa\u00b7ren", "un\u00b7be\u00b7son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVPP", "VAINF", "$.", "PPER", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dar\u00fcber ist die Frist des Lebens fast verronnen.", "tokens": ["Da\u00b7r\u00fc\u00b7ber", "ist", "die", "Frist", "des", "Le\u00b7bens", "fast", "ver\u00b7ron\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ART", "NN", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Bedenken wir es recht! wir sannen Eitlem nach,", "tokens": ["Be\u00b7den\u00b7ken", "wir", "es", "recht", "!", "wir", "san\u00b7nen", "Eit\u00b7lem", "nach", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "ADJD", "$.", "PPER", "VVFIN", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das gab dem kranken Sinn kein Heil, das ihm gebrach.", "tokens": ["Das", "gab", "dem", "kran\u00b7ken", "Sinn", "kein", "Heil", ",", "das", "ihm", "ge\u00b7brach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "PIAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "La\u00df uns bescheiden seyn! Wir waren unbescheiden,", "tokens": ["La\u00df", "uns", "be\u00b7schei\u00b7den", "seyn", "!", "Wir", "wa\u00b7ren", "un\u00b7be\u00b7schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVPP", "VAINF", "$.", "PPER", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wollten neben uns nicht gleichen Anspruch leiden.", "tokens": ["Und", "woll\u00b7ten", "ne\u00b7ben", "uns", "nicht", "glei\u00b7chen", "An\u00b7spruch", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "PPER", "PTKNEG", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Bedenken wir es recht, bescheiden uns damit,", "tokens": ["Be\u00b7den\u00b7ken", "wir", "es", "recht", ",", "be\u00b7schei\u00b7den", "uns", "da\u00b7mit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "ADJD", "$,", "VVFIN", "PPER", "PAV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df selber neben sich manch besserer uns litt.", "tokens": ["Da\u00df", "sel\u00b7ber", "ne\u00b7ben", "sich", "manch", "bes\u00b7se\u00b7rer", "uns", "litt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "PRF", "PIAT", "ADJA", "PPER", "VVFIN", "$."], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "La\u00df uns zufrieden seyn! Wir waren unzufrieden,", "tokens": ["La\u00df", "uns", "zu\u00b7frie\u00b7den", "seyn", "!", "Wir", "wa\u00b7ren", "un\u00b7zu\u00b7frie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADJD", "VAINF", "$.", "PPER", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df uns nicht mehr, als wir verdienten, war beschieden.", "tokens": ["Da\u00df", "uns", "nicht", "mehr", ",", "als", "wir", "ver\u00b7dien\u00b7ten", ",", "war", "be\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$,", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Bedenken wir es recht! Man r\u00e4umt noch mehr uns ein,", "tokens": ["Be\u00b7den\u00b7ken", "wir", "es", "recht", "!", "Man", "r\u00e4umt", "noch", "mehr", "uns", "ein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "ADJD", "$.", "PIS", "VVFIN", "ADV", "ADV", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als uns geb\u00fchrt, und gnug, zufrieden auch zu seyn.", "tokens": ["Als", "uns", "ge\u00b7b\u00fchrt", ",", "und", "gnug", ",", "zu\u00b7frie\u00b7den", "auch", "zu", "seyn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "$,", "KON", "ADV", "$,", "ADJD", "ADV", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}