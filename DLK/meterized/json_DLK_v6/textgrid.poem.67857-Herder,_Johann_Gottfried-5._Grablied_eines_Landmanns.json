{"textgrid.poem.67857": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "5. Grablied eines Landmanns", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "1:", "tokens": [":"], "token_info": ["punct"], "pos": ["$."]}, "line.2": {"text": "Liege nun, dich ficht nicht an", "tokens": ["Lie\u00b7ge", "nun", ",", "dich", "ficht", "nicht", "an"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ADV", "$,", "PPER", "VVFIN", "PTKNEG", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Winterfrost und Sommerglut;", "tokens": ["Win\u00b7ter\u00b7frost", "und", "Som\u00b7mer\u00b7glut", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "All dein Tagwerk ist gethan,", "tokens": ["All", "dein", "Tag\u00b7werk", "ist", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Bist daheim, und hast es gut.", "tokens": ["Bist", "da\u00b7heim", ",", "und", "hast", "es", "gut", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "KON", "VAFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "AlLE:", "tokens": ["Al\u00b7LE", ":"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Goldne Frau'n und Herr'n ins Grab", "tokens": ["Gold\u00b7ne", "Frau'n", "und", "Herr'n", "ins", "Grab"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "KON", "NN", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "M\u00fcssen sie all zusamm'n hinab!", "tokens": ["M\u00fcs\u00b7sen", "sie", "all", "zu\u00b7sam\u00b7m'n", "hin\u00b7ab", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIAT", "NN", "PTKVZ", "$."], "meter": "+---+-+-+", "measure": "dactylic.init"}}, "stanza.3": {"line.1": {"text": "2:", "tokens": [":"], "token_info": ["punct"], "pos": ["$."]}, "line.2": {"text": "Liege nun, dir thut nichts mehr", "tokens": ["Lie\u00b7ge", "nun", ",", "dir", "thut", "nichts", "mehr"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ADV", "$,", "PPER", "VVFIN", "PIS", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Geissel, Frohn und hart Gericht.", "tokens": ["Geis\u00b7sel", ",", "Frohn", "und", "hart", "Ge\u00b7richt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "ADJD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Kleid'r- und Nahrungssorge schwer,", "tokens": ["Klei\u00b7d'\u00b7r", "und", "Nah\u00b7rungs\u00b7sor\u00b7ge", "schwer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "NN", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "All dir eins, und dr\u00fcckt dich nicht.", "tokens": ["All", "dir", "eins", ",", "und", "dr\u00fcckt", "dich", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIS", "$,", "KON", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "AlLE:", "tokens": ["Al\u00b7LE", ":"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Szepter, Arzt und Weis' ins Grab", "tokens": ["Szep\u00b7ter", ",", "Arzt", "und", "Weis'", "ins", "Grab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "M\u00fcss'n dir nach sie all hinab.", "tokens": ["M\u00fcss'n", "dir", "nach", "sie", "all", "hin\u00b7ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "PPER", "PIAT", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "1:", "tokens": [":"], "token_info": ["punct"], "pos": ["$."]}, "line.2": {"text": "Lieg, und f\u00fcrchte nun nicht mehr", "tokens": ["Lieg", ",", "und", "f\u00fcrch\u00b7te", "nun", "nicht", "mehr"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KON", "VVFIN", "ADV", "PTKNEG", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bliz und Donnerkeilen hart.", "tokens": ["Bliz", "und", "Don\u00b7ner\u00b7kei\u00b7len", "hart", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "2:", "tokens": [":"], "token_info": ["punct"], "pos": ["$."]}, "line.2": {"text": "Freund' und Feind' und L\u00e4sterer,", "tokens": ["Freund'", "und", "Feind'", "und", "L\u00e4s\u00b7te\u00b7rer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Leid' und Freud' bist du verscharrt.", "tokens": ["Leid'", "und", "Freud'", "bist", "du", "ver\u00b7scharrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "AlLE:", "tokens": ["Al\u00b7LE", ":"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Stuzer jung und sch\u00f6n, ins Grab", "tokens": ["Stu\u00b7zer", "jung", "und", "sch\u00f6n", ",", "ins", "Grab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "ADJD", "KON", "ADJD", "$,", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "M\u00fcss'n zu dir sie all hinab!", "tokens": ["M\u00fcss'n", "zu", "dir", "sie", "all", "hin\u00b7ab", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPER", "PPER", "PIAT", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "1:", "tokens": [":"], "token_info": ["punct"], "pos": ["$."]}, "line.2": {"text": "Kein Beschw\u00f6rer h\u00e4rme dich!", "tokens": ["Kein", "Be\u00b7schw\u00f6\u00b7rer", "h\u00e4r\u00b7me", "dich", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "2:", "tokens": [":"], "token_info": ["punct"], "pos": ["$."]}, "line.2": {"text": "Kein Bezaubrer l\u00e4rm um dich!", "tokens": ["Kein", "Be\u00b7zaub\u00b7rer", "l\u00e4rm", "um", "dich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJD", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "1:", "tokens": [":"], "token_info": ["punct"], "pos": ["$."]}, "line.2": {"text": "B\u00f6se Geister fliehn dich.", "tokens": ["B\u00f6\u00b7se", "Geis\u00b7ter", "fliehn", "dich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "PPER", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.11": {"line.1": {"text": "2:", "tokens": [":"], "token_info": ["punct"], "pos": ["$."]}, "line.2": {"text": "Sch\u00e4dliches nicht nahe sich!", "tokens": ["Sch\u00e4d\u00b7li\u00b7ches", "nicht", "na\u00b7he", "sich", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADJD", "PRF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "1:", "tokens": [":"], "token_info": ["punct"], "pos": ["$."]}, "line.2": {"text": "Habe sanfte Ruh im Grab'!", "tokens": ["Ha\u00b7be", "sanf\u00b7te", "Ruh", "im", "Grab'", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "2:", "tokens": [":"], "token_info": ["punct"], "pos": ["$."]}, "line.2": {"text": "Und dein Grab viel Ruhm hab'!", "tokens": ["Und", "dein", "Grab", "viel", "Ruhm", "hab'", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PIAT", "NN", "VAFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}