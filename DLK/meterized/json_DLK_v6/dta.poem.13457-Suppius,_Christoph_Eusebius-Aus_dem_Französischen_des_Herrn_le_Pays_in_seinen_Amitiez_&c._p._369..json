{"dta.poem.13457": {"metadata": {"author": {"name": "Suppius, Christoph Eusebius", "birth": "N.A.", "death": "N.A."}, "title": "Aus dem Franz\u00f6sischen des Herrn  \n  le Pays  \n in seinen  Amitiez &c. p.  369.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1749", "urn": "urn:nbn:de:kobv:b4-20594-7", "language": ["de:0.99"], "booktitle": "Suppius, Christoph Eusebius: Oden und Lieder. Gotha, 1749."}, "poem": {"stanza.1": {"line.1": {"text": "Verstehst du, Damon! die\u00df Latein?", "tokens": ["Ver\u00b7stehst", "du", ",", "Da\u00b7mon", "!", "die\u00df", "La\u00b7tein", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "NE", "$.", "PDS", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Hast du daraus gnug abgenommen,", "tokens": ["Hast", "du", "da\u00b7raus", "gnug", "ab\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PAV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df, wenn es mu\u00df geschmauset seyn,", "tokens": ["Da\u00df", ",", "wenn", "es", "mu\u00df", "ge\u00b7schmau\u00b7set", "seyn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUS", "PPER", "VMFIN", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Mensch sehr th\u00f6richt thut, der sich viel sperrt", "tokens": ["Ein", "Mensch", "sehr", "th\u00f6\u00b7richt", "thut", ",", "der", "sich", "viel", "sperrt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "ADJD", "VVFIN", "$,", "PRELS", "PRF", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Dir sagt ich von Muskatensekt,", "tokens": ["Dir", "sagt", "ich", "von", "Mus\u00b7ka\u00b7ten\u00b7sekt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.6": {"text": "Ich bat, ihn bey mir zu geniessen,", "tokens": ["Ich", "bat", ",", "ihn", "bey", "mir", "zu", "ge\u00b7nies\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und solltest du das nicht mehr wissen,", "tokens": ["Und", "soll\u00b7test", "du", "das", "nicht", "mehr", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PDS", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Reizt dich vielleicht kein Wein, der so vortrefflich", "tokens": ["Reizt", "dich", "viel\u00b7leicht", "kein", "Wein", ",", "der", "so", "vor\u00b7treff\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PIAT", "NN", "$,", "PRELS", "ADV", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Warum bis morgen ausgesetzt,", "tokens": ["Wa\u00b7rum", "bis", "mor\u00b7gen", "aus\u00b7ge\u00b7setzt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was sich noch heute l\u00e4\u00dft ver\u00fcben?", "tokens": ["Was", "sich", "noch", "heu\u00b7te", "l\u00e4\u00dft", "ver\u00b7\u00fc\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "ADV", "ADV", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das hei\u00dft, sich selbst nicht recht gesch\u00e4tzt,", "tokens": ["Das", "hei\u00dft", ",", "sich", "selbst", "nicht", "recht", "ge\u00b7sch\u00e4tzt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "PRF", "ADV", "PTKNEG", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn man kann gl\u00fccklich seyn, man will es doch", "tokens": ["Wenn", "man", "kann", "gl\u00fcck\u00b7lich", "seyn", ",", "man", "will", "es", "doch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "VMFIN", "ADJD", "VAINF", "$,", "PIS", "VMFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Es ist mit jeder Lust bald aus,", "tokens": ["Es", "ist", "mit", "je\u00b7der", "Lust", "bald", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PIAT", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Man mu\u00df sie im Vorbeyziehn fassen,", "tokens": ["Man", "mu\u00df", "sie", "im", "Vor\u00b7bey\u00b7ziehn", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "APPRART", "NN", "VVINF", "$,"], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Das giebet \u00fcberhaupt voraus,", "tokens": ["Das", "gie\u00b7bet", "\u00fc\u00b7ber\u00b7haupt", "vo\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Zur Sch\u00e4fer-Stunde sich bereit erfinden lassen.", "tokens": ["Zur", "Sch\u00e4\u00b7fer\u00b7Stun\u00b7de", "sich", "be\u00b7reit", "er\u00b7fin\u00b7den", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PRF", "ADJD", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Verderben kann die Zeit den Wein,", "tokens": ["Ver\u00b7der\u00b7ben", "kann", "die", "Zeit", "den", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Zeit, die alles Ding bestreitet;", "tokens": ["Die", "Zeit", ",", "die", "al\u00b7les", "Ding", "be\u00b7strei\u00b7tet", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Marmor heisset nichtig seyn,", "tokens": ["Die", "Mar\u00b7mor", "heis\u00b7set", "nich\u00b7tig", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verschont die Flaschen wohl, von Glase zubereitet?", "tokens": ["Ver\u00b7schont", "die", "Fla\u00b7schen", "wohl", ",", "von", "Gla\u00b7se", "zu\u00b7be\u00b7rei\u00b7tet", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Je crains quelque sinistre effort,", "tokens": ["Je", "crains", "quel\u00b7que", "si\u00b7nist\u00b7re", "ef\u00b7fort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "J'apprehende quelque pillage,", "tokens": ["J'\u00b7ap\u00b7pre\u00b7hen\u00b7de", "quel\u00b7que", "pil\u00b7la\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Je crains enfin quelque naufrage,", "tokens": ["Je", "crains", "en\u00b7fin", "quel\u00b7que", "nauf\u00b7ra\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-++-+-+", "measure": "unknown.measure.penta"}, "line.8": {"text": "Pour l'&#233;viter Damon, mettons ce vin au Port.", "tokens": ["Pour", "l'", "&#233;", "vi\u00b7ter", "Da\u00b7mon", ",", "met\u00b7tons", "ce", "vin", "au", "Port", "."], "token_info": ["word", "word", "XML_entity", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "$,", "FM", "FM", "FM", "NE", "NE", "$."], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Juge, quel seroit mon chagrin,", "tokens": ["Ju\u00b7ge", ",", "quel", "se\u00b7roit", "mon", "cha\u00b7grin", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Si par un accident &#233;trange,", "tokens": ["Si", "par", "un", "ac\u00b7ci\u00b7dent", "&#233;", "tran\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "XML_entity", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$(", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Quelque valet, quelque lutin", "tokens": ["Quel\u00b7que", "va\u00b7let", ",", "quel\u00b7que", "lu\u00b7tin"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["FM.la", "FM.la", "$,", "FM.la", "FM.la"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Venoit me d&#234;rober cette douce vendange;", "tokens": ["Ve\u00b7noit", "me", "d", "&#234;", "ro\u00b7ber", "cet\u00b7te", "dou\u00b7ce", "ven\u00b7dan\u00b7ge", ";"], "token_info": ["word", "word", "word", "XML_entity", "word", "word", "word", "word", "punct"], "pos": ["FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "$."], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Ou si quelque Demon jaloux", "tokens": ["Ou", "si", "quel\u00b7que", "De\u00b7mon", "ja\u00b7loux"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Du plaisir, que donnent les treilles,", "tokens": ["Du", "plai\u00b7sir", ",", "que", "don\u00b7nent", "les", "treil\u00b7les", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Venant renverser mes bouteilles,", "tokens": ["Ven\u00b7ant", "ren\u00b7ver\u00b7ser", "mes", "bou\u00b7teil\u00b7les", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "S'en venoit renverser mon &#233;spoir le plus doux.", "tokens": ["S'\u00b7en", "ve\u00b7noit", "ren\u00b7ver\u00b7ser", "mon", "&#233;", "spoir", "le", "plus", "doux", "."], "token_info": ["word", "word", "word", "word", "XML_entity", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+--+-+--+--+", "measure": "iambic.penta.invert"}}, "stanza.5": {"line.1": {"text": "Sauvons, ami, mon frontignac", "tokens": ["Sau\u00b7vons", ",", "a\u00b7mi", ",", "mon", "fron\u00b7tig\u00b7nac"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["NE", "$,", "NE", "$,", "FM.la", "FM.la"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "De quelque semblable avanture;", "tokens": ["De", "quel\u00b7que", "sem\u00b7blab\u00b7le", "a\u00b7van\u00b7tu\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["FM.fr", "FM.fr", "FM.fr", "FM.fr", "$."], "meter": "----+-+-+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "C'est un bon vin pour l'estomac,", "tokens": ["C'\u00b7est", "un", "bon", "vin", "pour", "l'\u00b7e\u00b7sto\u00b7mac", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "$,"], "meter": "+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Autant aimable au go&#251;t, qu'ami de la Nature;", "tokens": ["Au\u00b7tant", "ai\u00b7mab\u00b7le", "au", "go", "&#251;", "t", ",", "qu'\u00b7a\u00b7mi", "de", "la", "Na\u00b7tu\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "XML_entity", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "FM", "$,", "FM", "FM", "FM", "FM", "$."], "meter": "+--+-+--+-+-+-+-", "measure": "iambic.septa.invert"}, "line.5": {"text": "C'est un vin dont boiroit Bacchus,", "tokens": ["C'\u00b7est", "un", "vin", "dont", "boi\u00b7roit", "Bac\u00b7chus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Lui, qui n'en boit jamais du pire,", "tokens": ["Lui", ",", "qui", "n'\u00b7en", "boit", "ja\u00b7mais", "du", "pi\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Un vin, qui fait chanter &amp; rire,", "tokens": ["Un", "vin", ",", "qui", "fait", "chan\u00b7ter", "&amp;", "ri\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "XML_entity", "word", "punct"], "pos": ["NE", "NE", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Et qui fait au plus sots faire des impromptus.", "tokens": ["Et", "qui", "fait", "au", "plus", "sots", "fai\u00b7re", "des", "im\u00b7promp\u00b7tus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.6": {"line.1": {"text": "Vien donc ici demain d&#238;ner,", "tokens": ["Vi\u00b7en", "donc", "i\u00b7ci", "de\u00b7main", "d", "&#238;", "ner", ","], "token_info": ["word", "word", "word", "word", "word", "XML_entity", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Et ne me cherche point d'excuse;", "tokens": ["Et", "ne", "me", "cher\u00b7che", "po\u00b7int", "d'\u00b7ex\u00b7cu\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Mais ne manque pas d'ammener", "tokens": ["Mais", "ne", "man\u00b7que", "pas", "d'\u00b7am\u00b7me\u00b7ner"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Celui, qui quelque fois a caress&#233; ma muse;", "tokens": ["Ce\u00b7lui", ",", "qui", "quel\u00b7que", "fois", "a", "ca\u00b7ress", "&#233;", "ma", "mu\u00b7se", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "XML_entity", "word", "word", "punct"], "pos": ["NE", "$,", "FM", "FM", "FM", "FM", "FM", "FM", "FM", "FM", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Ce s&#231;avant, qui n'est point Pedant", "tokens": ["Ce", "s", "&#231;", "a\u00b7vant", ",", "qui", "n'\u00b7est", "po\u00b7int", "Pe\u00b7dant"], "token_info": ["word", "word", "XML_entity", "word", "punct", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$,", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.6": {"text": "Et fort propre a t'y tenir t&#234;te,", "tokens": ["Et", "fort", "prop\u00b7re", "a", "t'y", "te\u00b7nir", "t", "&#234;", "te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "XML_entity", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "FM", "FM", "FM", "FM", "$,"], "meter": "--+--+----", "measure": "anapaest.di.plus"}, "line.7": {"text": "Et pour pr&#233;sider a la f&#234;te", "tokens": ["Et", "pour", "pr", "&#233;", "si\u00b7der", "a", "la", "f", "&#234;", "te"], "token_info": ["word", "word", "word", "XML_entity", "word", "word", "word", "word", "XML_entity", "word"], "pos": ["FM", "FM", "FM", "FM", "FM", "FM", "FM", "FM", "FM", "FM"], "meter": "+-+-++-+-", "measure": "unknown.measure.penta"}, "line.8": {"text": "Nous aurons, tu le sais, un fameux Pr&#233;sident.", "tokens": ["Nous", "au\u00b7rons", ",", "tu", "le", "sais", ",", "un", "fa\u00b7meux", "Pr", "&#233;", "si\u00b7dent", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "XML_entity", "word", "punct"], "pos": ["FM.fr", "FM.fr", "$,", "FM.fr", "FM.fr", "FM.fr", "$,", "FM", "FM", "FM", "FM", "FM", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}