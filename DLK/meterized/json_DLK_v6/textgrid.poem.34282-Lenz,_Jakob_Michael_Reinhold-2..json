{"textgrid.poem.34282": {"metadata": {"author": {"name": "Lenz, Jakob Michael Reinhold", "birth": "N.A.", "death": "N.A."}, "title": "2.", "genre": "verse", "period": "N.A.", "pub_year": 1771, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie? unsern G\u00fcrtel hat er aufgel\u00f6st?", "tokens": ["Wie", "?", "un\u00b7sern", "G\u00fcr\u00b7tel", "hat", "er", "auf\u00b7ge\u00b7l\u00f6st", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "PPOSAT", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wie? unsre s\u00fcsse Sch\u00fcchternheit entbl\u00f6st?", "tokens": ["Wie", "?", "uns\u00b7re", "s\u00fcs\u00b7se", "Sch\u00fcch\u00b7tern\u00b7heit", "ent\u00b7bl\u00f6st", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Mit ungeweyhten k\u00fchnen B\u00e4renpfoten", "tokens": ["Mit", "un\u00b7ge\u00b7weyh\u00b7ten", "k\u00fch\u00b7nen", "B\u00e4\u00b7ren\u00b7pfo\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zerrissen unsre feinen Liebesknoten,", "tokens": ["Zer\u00b7ris\u00b7sen", "uns\u00b7re", "fei\u00b7nen", "Lie\u00b7bes\u00b7kno\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Womit oft Jahre lang die J\u00fcngferliche Hand", "tokens": ["Wo\u00b7mit", "oft", "Jah\u00b7re", "lang", "die", "J\u00fcng\u00b7fer\u00b7li\u00b7che", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "NN", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein unverrauchtes gutes Herz umwand?", "tokens": ["Ein", "un\u00b7ver\u00b7rauch\u00b7tes", "gu\u00b7tes", "Herz", "um\u00b7wand", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und das erhebt man? uns die wir erschrocken", "tokens": ["Und", "das", "er\u00b7hebt", "man", "?", "uns", "die", "wir", "er\u00b7schro\u00b7cken"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VVFIN", "PIS", "$.", "PPER", "ART", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Versteinert standen, unsre seidnen Locken,", "tokens": ["Ver\u00b7stei\u00b7nert", "stan\u00b7den", ",", "uns\u00b7re", "seid\u00b7nen", "Lo\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Den drinn verwahrten Veilchenkranz zerzaust", "tokens": ["Den", "drinn", "ver\u00b7wahr\u00b7ten", "Veil\u00b7chen\u00b7kranz", "zer\u00b7zaust"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und wie mit Gassenmenschern 'rumgehaust?", "tokens": ["Und", "wie", "mit", "Gas\u00b7sen\u00b7men\u00b7schern", "'r\u00b7um\u00b7ge\u00b7haust", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "APPR", "NN", "NE", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.11": {"text": "Ihr G\u00f6tter Rache, Rache! ganz verachtet", "tokens": ["Ihr", "G\u00f6t\u00b7ter", "Ra\u00b7che", ",", "Ra\u00b7che", "!", "ganz", "ver\u00b7ach\u00b7tet"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "NN", "$,", "NN", "$.", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Stehn wir anitzt, von jedem Gauch betrachtet", "tokens": ["Stehn", "wir", "a\u00b7nitzt", ",", "von", "je\u00b7dem", "Gauch", "be\u00b7trach\u00b7tet"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "VVFIN", "$,", "APPR", "PIAT", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Geh\u00f6hnt, gestossen, ausgelacht", "tokens": ["Ge\u00b7h\u00f6hnt", ",", "ges\u00b7tos\u00b7sen", ",", "aus\u00b7ge\u00b7lacht"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["VVPP", "$,", "VVPP", "$,", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Als w\u00e4ren wir f\u00fcr ihn gemacht.", "tokens": ["Als", "w\u00e4\u00b7ren", "wir", "f\u00fcr", "ihn", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Kein edler Mann darf ohne sich zu sch\u00e4men", "tokens": ["Kein", "ed\u00b7ler", "Mann", "darf", "oh\u00b7ne", "sich", "zu", "sch\u00e4\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "VMFIN", "APPR", "PRF", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Jetzt mehr vor uns den Hut herunter nehmen.", "tokens": ["Jetzt", "mehr", "vor", "uns", "den", "Hut", "her\u00b7un\u00b7ter", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "ART", "NN", "APZR", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Kein J\u00fcngling mehr, in dem noch Flammen wehn", "tokens": ["Kein", "J\u00fcng\u00b7ling", "mehr", ",", "in", "dem", "noch", "Flam\u00b7men", "wehn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "ADV", "$,", "APPR", "ART", "ADV", "NN", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Bleibt ohn' Err\u00f6then bey uns stehn.", "tokens": ["Bleibt", "ohn'", "Er\u00b7r\u00f6\u00b7then", "bey", "uns", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Ach unsre Macht ist aus, wir sind entehret.", "tokens": ["Ach", "uns\u00b7re", "Macht", "ist", "aus", ",", "wir", "sind", "en\u00b7teh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "PPOSAT", "NN", "VAFIN", "PTKVZ", "$,", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Ein jeder schale Kopf verraucht, zerst\u00f6ret,", "tokens": ["Ein", "je\u00b7der", "scha\u00b7le", "Kopf", "ver\u00b7raucht", ",", "zer\u00b7st\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "VVPP", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "R\u00fchmt sich anjetzt mehr als vertraut, gemein", "tokens": ["R\u00fchmt", "sich", "an\u00b7jetzt", "mehr", "als", "ver\u00b7traut", ",", "ge\u00b7mein"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PRF", "ADV", "PIAT", "KOKOM", "ADJD", "$,", "ADJD"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.22": {"text": "Initiirt in unserm Dienst zu seyn.", "tokens": ["I\u00b7ni\u00b7ti\u00b7irt", "in", "un\u00b7serm", "Dienst", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "O Rache Rache G\u00f6tter! in der Larve", "tokens": ["O", "Ra\u00b7che", "Ra\u00b7che", "G\u00f6t\u00b7ter", "!", "in", "der", "Lar\u00b7ve"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NN", "NN", "NN", "$.", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "Der Wei\u00dfheit stand er da wie Mendelson und Garve.", "tokens": ["Der", "Wei\u00df\u00b7heit", "stand", "er", "da", "wie", "Men\u00b7del\u00b7son", "und", "Gar\u00b7ve", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "KOKOM", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Voll Demuth schlich er, mit mehr Aengstlichkeit,", "tokens": ["Voll", "De\u00b7muth", "schlich", "er", ",", "mit", "mehr", "A\u00b7engst\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "ADJD", "PPER", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "---+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.26": {"text": "Als ehmals Ritter sich Prinze\u00dfinnen geweiht.", "tokens": ["Als", "eh\u00b7mals", "Rit\u00b7ter", "sich", "Prin\u00b7ze\u00b7\u00dfin\u00b7nen", "ge\u00b7weiht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "PRF", "NN", "VVPP", "$."], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.27": {"text": "Er kniete, ach er schmeichelte,", "tokens": ["Er", "knie\u00b7te", ",", "ach", "er", "schmei\u00b7chel\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "XY", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Wir halfen ihm aus Mitleid' in die H\u00f6h,", "tokens": ["Wir", "hal\u00b7fen", "ihm", "aus", "Mit\u00b7leid'", "in", "die", "H\u00f6h", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "Wir l\u00e4chelten ihm Muth ein \u2013 wie ein Tyger", "tokens": ["Wir", "l\u00e4\u00b7chel\u00b7ten", "ihm", "Muth", "ein", "\u2013", "wie", "ein", "Ty\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "NN", "ART", "$(", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "Fiel er \u00fcber uns her und spannte wie R\u00f6mische Sieger", "tokens": ["Fiel", "er", "\u00fc\u00b7ber", "uns", "her", "und", "spann\u00b7te", "wie", "R\u00f6\u00b7mi\u00b7sche", "Sie\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "PTKVZ", "KON", "VVFIN", "KOKOM", "ADJA", "NN"], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.31": {"text": "Uns vor seinen Wagen und lachte und jubelte drob", "tokens": ["Uns", "vor", "sei\u00b7nen", "Wa\u00b7gen", "und", "lach\u00b7te", "und", "ju\u00b7bel\u00b7te", "drob"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "KON", "VVFIN", "KON", "VVFIN", "ADV"], "meter": "--+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.32": {"text": "Und ewiger Hohn ward uns sein Lob.", "tokens": ["Und", "e\u00b7wi\u00b7ger", "Hohn", "ward", "uns", "sein", "Lob", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VAFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.33": {"text": "Komm mache dich auf Apoll, komm dein Gefolge zu r\u00e4chen!", "tokens": ["Komm", "ma\u00b7che", "dich", "auf", "A\u00b7poll", ",", "komm", "dein", "Ge\u00b7fol\u00b7ge", "zu", "r\u00e4\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVFIN", "PRF", "APPR", "NE", "$,", "VVFIN", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.34": {"text": "Sonst werden Furien selbst am Ende Hohn uns sprechen,", "tokens": ["Sonst", "wer\u00b7den", "Fu\u00b7ri\u00b7en", "selbst", "am", "En\u00b7de", "Hohn", "uns", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "ADV", "APPRART", "NN", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.35": {"text": "Und scheusliche Larven auf unserm Ruin", "tokens": ["Und", "scheus\u00b7li\u00b7che", "Lar\u00b7ven", "auf", "un\u00b7serm", "Ru\u00b7in"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.36": {"text": "Olinden sich nennen und Bastarde ziehn.", "tokens": ["O\u00b7lin\u00b7den", "sich", "nen\u00b7nen", "und", "Bas\u00b7tar\u00b7de", "ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PRF", "VVINF", "KON", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}}}}