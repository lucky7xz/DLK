{"textgrid.poem.59750": {"metadata": {"author": {"name": "Arndt, Ernst Moritz", "birth": "N.A.", "death": "N.A."}, "title": "Der D\u00e4mon des Sokrates", "genre": "verse", "period": "N.A.", "pub_year": 1814, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sokrates, der gro\u00dfe Geistesk\u00e4mpfer,", "tokens": ["Sok\u00b7ra\u00b7tes", ",", "der", "gro\u00b7\u00dfe", "Geis\u00b7tes\u00b7k\u00e4mp\u00b7fer", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Hatte einen Fl\u00fcstrer und Erreger,", "tokens": ["Hat\u00b7te", "ei\u00b7nen", "Fl\u00fcst\u00b7rer", "und", "Er\u00b7re\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "KON", "NN", "$,"], "meter": "+-+-+--+--", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Einen Weiser, Leiter, Halter, D\u00e4mpfer", "tokens": ["Ei\u00b7nen", "Wei\u00b7ser", ",", "Lei\u00b7ter", ",", "Hal\u00b7ter", ",", "D\u00e4mp\u00b7fer"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "NN", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Und auch Diener und Laternentr\u00e4ger,", "tokens": ["Und", "auch", "Die\u00b7ner", "und", "La\u00b7ter\u00b7nen\u00b7tr\u00e4\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "KON", "NN", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.5": {"text": "Wo es galt durch Finsternis zu wanken.", "tokens": ["Wo", "es", "galt", "durch", "Fins\u00b7ter\u00b7nis", "zu", "wan\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Dieser Ohrenfl\u00fcstrer, Haucher, Lauscher,", "tokens": ["Die\u00b7ser", "Oh\u00b7ren\u00b7fl\u00fcst\u00b7rer", ",", "Hau\u00b7cher", ",", "Lau\u00b7scher", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PDAT", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Aller seiner Triebe und Gedanken", "tokens": ["Al\u00b7ler", "sei\u00b7ner", "Trie\u00b7be", "und", "Ge\u00b7dan\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "KON", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Kluger Mitdurchsprecher, Gegentauscher", "tokens": ["Klu\u00b7ger", "Mit\u00b7durch\u00b7spre\u00b7cher", ",", "Ge\u00b7gen\u00b7tau\u00b7scher"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADJA", "NN", "$,", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "Galt ihm, wie uns andern das Gewissen;", "tokens": ["Galt", "ihm", ",", "wie", "uns", "an\u00b7dern", "das", "Ge\u00b7wis\u00b7sen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "PWAV", "PPER", "PIS", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.10": {"text": "All sein Ahnen, Lieben, Denken, Wollen \u2013", "tokens": ["All", "sein", "Ah\u00b7nen", ",", "Lie\u00b7ben", ",", "Den\u00b7ken", ",", "Wol\u00b7len", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PIAT", "PPOSAT", "NN", "$,", "ADJA", "$,", "NN", "$,", "NN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.11": {"text": "Wie in uns auch Geisterchen sich rollen \u2013", "tokens": ["Wie", "in", "uns", "auch", "Geis\u00b7ter\u00b7chen", "sich", "rol\u00b7len", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "PPER", "ADV", "NN", "PRF", "VVINF", "$("], "meter": "-+--+---+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Schob er diesem F\u00fchrer zu und Folger.", "tokens": ["Schob", "er", "die\u00b7sem", "F\u00fch\u00b7rer", "zu", "und", "Fol\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PDAT", "NN", "PTKVZ", "KON", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Ach! ruft jeder, lebt noch wo ein solcher?", "tokens": ["Ach", "!", "ruft", "je\u00b7der", ",", "lebt", "noch", "wo", "ein", "sol\u00b7cher", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PIS", "$,", "VVFIN", "ADV", "PWAV", "ART", "PIAT", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Sind sie denn erloschen, jene Sterne,", "tokens": ["Sind", "sie", "denn", "er\u00b7lo\u00b7schen", ",", "je\u00b7ne", "Ster\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVINF", "$,", "PDAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Woher solche Folger Menschen kamen?", "tokens": ["Wo\u00b7her", "sol\u00b7che", "Fol\u00b7ger", "Men\u00b7schen", "ka\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "O ihr Gaffer, Greifer in die Ferne!", "tokens": ["O", "ihr", "Gaf\u00b7fer", ",", "Grei\u00b7fer", "in", "die", "Fer\u00b7ne", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$,", "NE", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "K\u00f6nnt ihr des Begleiters kurzen Namen,", "tokens": ["K\u00f6nnt", "ihr", "des", "Be\u00b7glei\u00b7ters", "kur\u00b7zen", "Na\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Jenes weisen, gottgeweihten Griechen,", "tokens": ["Je\u00b7nes", "wei\u00b7sen", ",", "gott\u00b7ge\u00b7weih\u00b7ten", "Grie\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Euch in gutes Deutsch nicht \u00fcbersetzen?", "tokens": ["Euch", "in", "gu\u00b7tes", "Deutsch", "nicht", "\u00fc\u00b7bers\u00b7et\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADJA", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "M\u00fcsset durch den Hochmut doppelt siechen?", "tokens": ["M\u00fcs\u00b7set", "durch", "den", "Hoch\u00b7mut", "dop\u00b7pelt", "sie\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Drum herunter von den hohen Stufen!", "tokens": ["Drum", "her\u00b7un\u00b7ter", "von", "den", "ho\u00b7hen", "Stu\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "APZR", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.10": {"text": "Auf die Bank der Sch\u00fcler mit der Fibel!", "tokens": ["Auf", "die", "Bank", "der", "Sch\u00fc\u00b7ler", "mit", "der", "Fi\u00b7bel", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.11": {"text": "Dort wird auch der Kleinste lachend rufen:", "tokens": ["Dort", "wird", "auch", "der", "Kleins\u00b7te", "la\u00b7chend", "ru\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "ADJA", "ADJD", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}}}}