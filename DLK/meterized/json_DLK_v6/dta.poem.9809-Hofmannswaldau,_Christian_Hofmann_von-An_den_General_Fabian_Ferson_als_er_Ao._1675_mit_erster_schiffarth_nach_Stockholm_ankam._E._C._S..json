{"dta.poem.9809": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "An den General Fabian Ferson/ als er Ao. 1675  \n mit erster schiffarth nach Stockholm ankam.  \n E. C. S.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wenn/ welt-ber\u00fchmter held/ ein knecht sich darff erk\u00fchnen/", "tokens": ["Wenn", "/", "welt\u00b7be\u00b7r\u00fchm\u00b7ter", "held", "/", "ein", "knecht", "sich", "darff", "er\u00b7k\u00fch\u00b7nen", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "PWS", "VVFIN", "$(", "ART", "NN", "PRF", "PAV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nach aller m\u00f6glichkeit dich heute zu bedienen/", "tokens": ["Nach", "al\u00b7ler", "m\u00f6g\u00b7lich\u00b7keit", "dich", "heu\u00b7te", "zu", "be\u00b7die\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PPER", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So hab ich di\u00df zu thun vor andern gutes recht;", "tokens": ["So", "hab", "ich", "di\u00df", "zu", "thun", "vor", "an\u00b7dern", "gu\u00b7tes", "recht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PDS", "PTKZU", "VVINF", "APPR", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn ich erkenne mich f\u00fcr deinen schlechten knecht.", "tokens": ["Denn", "ich", "er\u00b7ken\u00b7ne", "mich", "f\u00fcr", "dei\u00b7nen", "schlech\u00b7ten", "knecht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich lege mich hiermit zu deinen f\u00fcssen nieder/", "tokens": ["Ich", "le\u00b7ge", "mich", "hier\u00b7mit", "zu", "dei\u00b7nen", "f\u00fcs\u00b7sen", "nie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PAV", "APPR", "PPOSAT", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und \u00fcberreiche dir die unvollkommne lieder/", "tokens": ["Und", "\u00fc\u00b7berr\u00b7ei\u00b7che", "dir", "die", "un\u00b7voll\u00b7komm\u00b7ne", "lie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Mit welchen ich in eil den frohen tag beehrt/", "tokens": ["Mit", "wel\u00b7chen", "ich", "in", "eil", "den", "fro\u00b7hen", "tag", "be\u00b7ehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "PPER", "APPR", "NN", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "An welchem du gesund bey uns bist eingekehrt.", "tokens": ["An", "wel\u00b7chem", "du", "ge\u00b7sund", "bey", "uns", "bist", "ein\u00b7ge\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADJD", "APPR", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wir dancken GOtt daf\u00fcr/ ob schon die lieben deinen/", "tokens": ["Wir", "dan\u00b7cken", "Gott", "da\u00b7f\u00fcr", "/", "ob", "schon", "die", "lie\u00b7ben", "dei\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PAV", "$(", "KOUS", "ADV", "ART", "ADJA", "PPOSAT", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die du zur\u00fccke liest/ umb dich noch traurig scheinen/", "tokens": ["Die", "du", "zu\u00b7r\u00fc\u00b7cke", "liest", "/", "umb", "dich", "noch", "trau\u00b7rig", "schei\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "VVFIN", "$(", "APPR", "PPER", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "F\u00fcrnehmlich weil ihr feind in voller r\u00fcstung steht/", "tokens": ["F\u00fcr\u00b7nehm\u00b7lich", "weil", "ihr", "feind", "in", "vol\u00b7ler", "r\u00fcs\u00b7tung", "steht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und/ wie berichtet wird/ an ihre gr\u00e4ntzen geht.", "tokens": ["Und", "/", "wie", "be\u00b7rich\u00b7tet", "wird", "/", "an", "ih\u00b7re", "gr\u00e4nt\u00b7zen", "geht", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "PWAV", "VVPP", "VAFIN", "$(", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Man sagt/ die D\u00fcn\u2019 als sie dein abseyn h\u00e4tt vernommen/", "tokens": ["Man", "sagt", "/", "die", "D\u00fcn'", "als", "sie", "dein", "ab\u00b7seyn", "h\u00e4tt", "ver\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$(", "ART", "NN", "KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Sey in der wilden see sehr weit dir nachgeschwommen/", "tokens": ["Sey", "in", "der", "wil\u00b7den", "see", "sehr", "weit", "dir", "nach\u00b7ge\u00b7schwom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "NN", "ADV", "ADJD", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und weil sie dich nicht fand/ hat sie/ die nun betagt/", "tokens": ["Und", "weil", "sie", "dich", "nicht", "fand", "/", "hat", "sie", "/", "die", "nun", "be\u00b7tagt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "PTKNEG", "VVFIN", "$(", "VAFIN", "PPER", "$(", "PRELS", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Jhr schilfficht haupt beraufft und dich sehr hoch beklagt.", "tokens": ["Ihr", "schilf\u00b7ficht", "haupt", "ber\u00b7aufft", "und", "dich", "sehr", "hoch", "be\u00b7klagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "KON", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Es rieff dir sehnlich nach ihr gantzes hoffgesinde/", "tokens": ["Es", "rieff", "dir", "sehn\u00b7lich", "nach", "ihr", "gant\u00b7zes", "hoff\u00b7ge\u00b7sin\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Vor allen andern doch die junge D\u00fcnam\u00fcnde/", "tokens": ["Vor", "al\u00b7len", "an\u00b7dern", "doch", "die", "jun\u00b7ge", "D\u00fc\u00b7na\u00b7m\u00fcn\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PIS", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Die ihre tochter ist/ rieff immer diese wort:", "tokens": ["Die", "ih\u00b7re", "toch\u00b7ter", "ist", "/", "rieff", "im\u00b7mer", "die\u00b7se", "wort", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VAFIN", "$(", "VVFIN", "ADV", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Ach vater! ziehst du weg? ach vater! ziehst du fort?", "tokens": ["Ach", "va\u00b7ter", "!", "ziehst", "du", "weg", "?", "ach", "va\u00b7ter", "!", "ziehst", "du", "fort", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$.", "VVFIN", "PPER", "PTKVZ", "$.", "XY", "NN", "$.", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "O ach! und l\u00e4ssest mich in h\u00e4nden meiner neider?", "tokens": ["O", "ach", "!", "und", "l\u00e4s\u00b7sest", "mich", "in", "h\u00e4n\u00b7den", "mei\u00b7ner", "nei\u00b7der", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ITJ", "$.", "KON", "VVFIN", "PRF", "APPR", "ADJA", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Indem sie dieses sprach/ zerri\u00df sie ihre kleider/", "tokens": ["In\u00b7dem", "sie", "die\u00b7ses", "sprach", "/", "zer\u00b7ri\u00df", "sie", "ih\u00b7re", "klei\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDS", "VVFIN", "$(", "VVFIN", "PPER", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Wie ihre mutter that; seit dieses ist geschehn/", "tokens": ["Wie", "ih\u00b7re", "mut\u00b7ter", "that", ";", "seit", "die\u00b7ses", "ist", "ge\u00b7schehn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "VVFIN", "$.", "APPR", "PDS", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Hat man sie beyde blo\u00df und nackend gehn gesehn.", "tokens": ["Hat", "man", "sie", "bey\u00b7de", "blo\u00df", "und", "na\u00b7ckend", "gehn", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PPER", "PIS", "ADV", "KON", "ADJD", "VVINF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Wie schmertzlich sie nun dort dein abseyn ietzt bereuen/", "tokens": ["Wie", "schmertz\u00b7lich", "sie", "nun", "dort", "dein", "ab\u00b7seyn", "ietzt", "be\u00b7reu\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "ADV", "ADV", "PPOSAT", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "So hertzlich k\u00f6nnen wir uns deiner ankunfft freuen;", "tokens": ["So", "hertz\u00b7lich", "k\u00f6n\u00b7nen", "wir", "uns", "dei\u00b7ner", "an\u00b7kunfft", "freu\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VMFIN", "PPER", "PRF", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Der alte Mehler selbst/ wie mir wird f\u00fcrgebracht/", "tokens": ["Der", "al\u00b7te", "Meh\u00b7ler", "selbst", "/", "wie", "mir", "wird", "f\u00fcr\u00b7ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "$(", "PWAV", "PPER", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Hat unter seinem ei\u00df heut \u00fcber laut gelacht.", "tokens": ["Hat", "un\u00b7ter", "sei\u00b7nem", "ei\u00df", "heut", "\u00fc\u00b7ber", "laut", "ge\u00b7lacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN", "ADV", "APPR", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Es str\u00f6hmte neben ihm die liebliche Syrene", "tokens": ["Es", "str\u00f6hm\u00b7te", "ne\u00b7ben", "ihm", "die", "lieb\u00b7li\u00b7che", "Sy\u00b7re\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.30": {"text": "Durch ihre silberfluth ein jauchzendes geth\u00f6ne/", "tokens": ["Durch", "ih\u00b7re", "sil\u00b7ber\u00b7fluth", "ein", "jauch\u00b7zen\u00b7des", "ge\u00b7th\u00f6\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "So da\u00df ihr heller schall den fluth-crystall durchbrach:", "tokens": ["So", "da\u00df", "ihr", "hel\u00b7ler", "schall", "den", "fluth\u00b7cry\u00b7stall", "durch\u00b7brach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPOSAT", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Die klippen sprachen ihm mit schweren lippen nach", "tokens": ["Die", "klip\u00b7pen", "spra\u00b7chen", "ihm", "mit", "schwe\u00b7ren", "lip\u00b7pen", "nach"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ADJA", "NN", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Und sperrten kl\u00fcffte auff; der hall fiel in die gr\u00fcffte/", "tokens": ["Und", "sperr\u00b7ten", "kl\u00fcff\u00b7te", "auff", ";", "der", "hall", "fiel", "in", "die", "gr\u00fcff\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVFIN", "PTKVZ", "$.", "ART", "NN", "VVFIN", "APPR", "ART", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Und Echo rieff ihm nach in weite breite l\u00fcffte/", "tokens": ["Und", "E\u00b7cho", "rieff", "ihm", "nach", "in", "wei\u00b7te", "brei\u00b7te", "l\u00fcff\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "APPR", "APPR", "ADJA", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Die l\u00fcffte drehten sich durch st\u00e4dte/ feld und wald:", "tokens": ["Die", "l\u00fcff\u00b7te", "dreh\u00b7ten", "sich", "durch", "st\u00e4d\u00b7te", "/", "feld", "und", "wald", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PRF", "APPR", "VVFIN", "$(", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "So ist dem ankunfft nun im gantzen land erschallt.", "tokens": ["So", "ist", "dem", "an\u00b7kunfft", "nun", "im", "gant\u00b7zen", "land", "er\u00b7schallt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Die meiste/ welche sich nebst mir derselben freuen/", "tokens": ["Die", "meis\u00b7te", "/", "wel\u00b7che", "sich", "nebst", "mir", "der\u00b7sel\u00b7ben", "freu\u00b7en", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$(", "PRELS", "PRF", "APPR", "PPER", "PDS", "VVINF", "$("], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.38": {"text": "Begunten \u00fcberall zu jauchzen und zu schreyen/", "tokens": ["Be\u00b7gun\u00b7ten", "\u00fc\u00b7be\u00b7rall", "zu", "jauch\u00b7zen", "und", "zu", "schre\u00b7yen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "So lange bi\u00df der L\u00f6w in dieser mitternacht", "tokens": ["So", "lan\u00b7ge", "bi\u00df", "der", "L\u00f6w", "in", "die\u00b7ser", "mit\u00b7ter\u00b7nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Von ihrem freuden-schall aus seinem schlaff erwacht.", "tokens": ["Von", "ih\u00b7rem", "freu\u00b7den\u00b7schall", "aus", "sei\u00b7nem", "schlaff", "er\u00b7wacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "PPOSAT", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Der hochgeehrtste L\u00f6w/ so seine g\u00fcldne klauen", "tokens": ["Der", "hoch\u00b7geehrts\u00b7te", "L\u00f6w", "/", "so", "sei\u00b7ne", "g\u00fcld\u00b7ne", "klau\u00b7en"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "ADV", "PPOSAT", "ADJA", "VVINF"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.42": {"text": "Anietzt zum ersten mahl den feinden giebt zu schauen/", "tokens": ["An\u00b7ietzt", "zum", "ers\u00b7ten", "mahl", "den", "fein\u00b7den", "giebt", "zu", "schau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "ADV", "ART", "ADJA", "VVFIN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Und gleich in schrancken springt/ erfreuete sich sehr/", "tokens": ["Und", "gleich", "in", "schran\u00b7cken", "springt", "/", "er\u00b7freu\u00b7e\u00b7te", "sich", "sehr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "VVINF", "VVFIN", "$(", "VVFIN", "PRF", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Als er die post vernahm: da\u00df Ferson kommen w\u00e4r.", "tokens": ["Als", "er", "die", "post", "ver\u00b7nahm", ":", "da\u00df", "Fer\u00b7son", "kom\u00b7men", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$.", "KOUS", "NE", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Sein pr\u00e4chtiges Stockholm/ nach dem es dich empfangen/", "tokens": ["Sein", "pr\u00e4ch\u00b7ti\u00b7ges", "Stock\u00b7holm", "/", "nach", "dem", "es", "dich", "emp\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$(", "APPR", "PRELS", "PPER", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Sprach: dieses ist der mann/ nach dem ich trug verlangen/", "tokens": ["Sprach", ":", "die\u00b7ses", "ist", "der", "mann", "/", "nach", "dem", "ich", "trug", "ver\u00b7lan\u00b7gen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PDS", "VAFIN", "ART", "NN", "$(", "APPR", "PRELS", "PPER", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Sey sehr willkommen hier/ du k\u00fchner krieges-held/", "tokens": ["Sey", "sehr", "will\u00b7kom\u00b7men", "hier", "/", "du", "k\u00fch\u00b7ner", "krie\u00b7ge\u00b7sheld", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "ADV", "$(", "PPER", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Dem selbst der wilde Mars verzagt zu s\u00fcssen f\u00e4llt.", "tokens": ["Dem", "selbst", "der", "wil\u00b7de", "Mars", "ver\u00b7zagt", "zu", "s\u00fcs\u00b7sen", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "ADJA", "NN", "VVPP", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Weil dir denn iederman rieff gl\u00fcck und heyl entgegen/", "tokens": ["Weil", "dir", "denn", "ie\u00b7der\u00b7man", "rieff", "gl\u00fcck", "und", "heyl", "ent\u00b7ge\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "VVFIN", "ADJD", "KON", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Beschlo\u00df ich meine pflicht in reimen abzulegen/", "tokens": ["Be\u00b7schlo\u00df", "ich", "mei\u00b7ne", "pflicht", "in", "rei\u00b7men", "ab\u00b7zu\u00b7le\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "APPR", "ADJA", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Und brach in h\u00f6chster eil/ wie unser Ph\u00f6bus wei\u00df/", "tokens": ["Und", "brach", "in", "h\u00f6chs\u00b7ter", "eil", "/", "wie", "un\u00b7ser", "Ph\u00f6\u00b7bus", "wei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$(", "KOKOM", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Held! dir zu ehren ab di\u00df d\u00fcrre lorbeer-rei\u00df.", "tokens": ["Held", "!", "dir", "zu", "eh\u00b7ren", "ab", "di\u00df", "d\u00fcr\u00b7re", "lor\u00b7beer\u00b7rei\u00df", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "PTKZU", "VVINF", "APPR", "PDS", "VMFIN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Ich hatte neulich zwar mir g\u00e4ntzlich f\u00fcrgenommen/", "tokens": ["Ich", "hat\u00b7te", "neu\u00b7lich", "zwar", "mir", "g\u00e4ntz\u00b7lich", "f\u00fcr\u00b7ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PPER", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Gantz nicht/ ja nimmermehr auff Aons h\u00f6h zu kommen/", "tokens": ["Gantz", "nicht", "/", "ja", "nim\u00b7mer\u00b7mehr", "auff", "A\u00b7ons", "h\u00f6h", "zu", "kom\u00b7men", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "$(", "ADV", "ADV", "APPR", "NE", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Nur darum/ weil man hier die tichterey verlacht/", "tokens": ["Nur", "da\u00b7rum", "/", "weil", "man", "hier", "die", "tich\u00b7te\u00b7rey", "ver\u00b7lacht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PAV", "$(", "KOUS", "PIS", "ADV", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Weil sie hans liederlich zum bettel-stabe macht.", "tokens": ["Weil", "sie", "hans", "lie\u00b7der\u00b7lich", "zum", "bet\u00b7tel\u00b7sta\u00b7be", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "ADJD", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Ich w\u00e4r auch gantz gewi\u00df bey diesem vorsatz blieben/", "tokens": ["Ich", "w\u00e4r", "auch", "gantz", "ge\u00b7wi\u00df", "bey", "die\u00b7sem", "vor\u00b7satz", "blie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "APPR", "PDAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Und h\u00e4tte diese kunst nicht wiederum getrieben/", "tokens": ["Und", "h\u00e4t\u00b7te", "die\u00b7se", "kunst", "nicht", "wie\u00b7de\u00b7rum", "ge\u00b7trie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PDS", "VMFIN", "PTKNEG", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Wo nicht mein freyer sinn/ der uners\u00e4ttlich geitzt/", "tokens": ["Wo", "nicht", "mein", "frey\u00b7er", "sinn", "/", "der", "un\u00b7er\u00b7s\u00e4tt\u00b7lich", "geitzt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "PPOSAT", "ADJA", "NN", "$(", "ART", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Nach grosser herren gunst mich hierzu angereitzt.", "tokens": ["Nach", "gros\u00b7ser", "her\u00b7ren", "gunst", "mich", "hier\u00b7zu", "an\u00b7ge\u00b7reitzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PRF", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Di\u00df aber reitzt mich mehr: Ich wei\u00df da\u00df du vordessen", "tokens": ["Di\u00df", "a\u00b7ber", "reitzt", "mich", "mehr", ":", "Ich", "wei\u00df", "da\u00df", "du", "vor\u00b7des\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "VVFIN", "PPER", "ADV", "$.", "PPER", "VVFIN", "KOUS", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Auf P\u00f6ons Helicon hast oben an gesessen/", "tokens": ["Auf", "P\u00f6ons", "He\u00b7li\u00b7con", "hast", "o\u00b7ben", "an", "ge\u00b7ses\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "VAFIN", "ADV", "APZR", "VVPP", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.63": {"text": "Und da\u00df du tichter wohl zu unterscheiden weist", "tokens": ["Und", "da\u00df", "du", "tich\u00b7ter", "wohl", "zu", "un\u00b7ter\u00b7schei\u00b7den", "weist"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADJA", "ADV", "PTKZU", "VVINF", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Von bettlern/ welche lang auf ihre kunst gereist.", "tokens": ["Von", "bett\u00b7lern", "/", "wel\u00b7che", "lang", "auf", "ih\u00b7re", "kunst", "ge\u00b7reist", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "$(", "PRELS", "ADJD", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Die gehen mich nichts an/ auch nicht die meister-s\u00e4nger/", "tokens": ["Die", "ge\u00b7hen", "mich", "nichts", "an", "/", "auch", "nicht", "die", "meis\u00b7ter\u00b7s\u00e4n\u00b7ger", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PIS", "PTKVZ", "$(", "ADV", "PTKNEG", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Die lange sylben kurtz und kurtze sylben l\u00e4nger/", "tokens": ["Die", "lan\u00b7ge", "syl\u00b7ben", "kurtz", "und", "kurt\u00b7ze", "syl\u00b7ben", "l\u00e4n\u00b7ger", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "ADJD", "KON", "ADJA", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Als sich geb\u00fchret/ ziehn/ nachdem das h\u00f6ltzgen ist/", "tokens": ["Als", "sich", "ge\u00b7b\u00fch\u00b7ret", "/", "ziehn", "/", "nach\u00b7dem", "das", "h\u00f6ltz\u00b7gen", "ist", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "VVPP", "$(", "VVINF", "$(", "KOUS", "ART", "ADJA", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Womit ihr aberwitz die armen reime mist.", "tokens": ["Wo\u00b7mit", "ihr", "a\u00b7ber\u00b7witz", "die", "ar\u00b7men", "rei\u00b7me", "mist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Wer nach der elen reimt/ den mu\u00df man tichter nennen/", "tokens": ["Wer", "nach", "der", "e\u00b7len", "reimt", "/", "den", "mu\u00df", "man", "tich\u00b7ter", "nen\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "ADJA", "VVFIN", "$(", "ART", "VMFIN", "PIS", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Ob am gedichte gleich nichts t\u00fcchtigs zu erkennen/", "tokens": ["Ob", "am", "ge\u00b7dich\u00b7te", "gleich", "nichts", "t\u00fcch\u00b7tigs", "zu", "er\u00b7ken\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPRART", "ADJA", "ADV", "PIS", "ADJA", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Er ist/ er heist und bleibt ein k\u00fcnstlicher poet/", "tokens": ["Er", "ist", "/", "er", "heist", "und", "bleibt", "ein", "k\u00fcnst\u00b7li\u00b7cher", "poet", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$(", "PPER", "ADJD", "KON", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.72": {"text": "Warum? weil P. L. C. nach seinem nahmen steht.", "tokens": ["Wa\u00b7rum", "?", "weil", "P.", "L.", "C.", "nach", "sei\u00b7nem", "nah\u00b7men", "steht", "."], "token_info": ["word", "punct", "word", "abbreviation", "abbreviation", "abbreviation", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "KOUS", "NE", "NE", "NE", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.73": {"text": "Di\u00df sey und bleib er auch/ bi\u00df andre ihn vertreiben/", "tokens": ["Di\u00df", "sey", "und", "bleib", "er", "auch", "/", "bi\u00df", "and\u00b7re", "ihn", "ver\u00b7trei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "KON", "VVFIN", "PPER", "ADV", "$(", "APPR", "PIS", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Und ihn zu N\u00fcrenberg in pritschen-orden schreiben.", "tokens": ["Und", "ihn", "zu", "N\u00fc\u00b7ren\u00b7berg", "in", "prit\u00b7schen\u00b7or\u00b7den", "schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NE", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Ich habe meines theils auf aff- und hasen-jagt", "tokens": ["Ich", "ha\u00b7be", "mei\u00b7nes", "theils", "auf", "aff", "und", "ha\u00b7sen\u00b7jagt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADV", "APPR", "TRUNC", "KON", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Noch keinen hund gehetzt/ auch keinen schlu\u00df gewagt.", "tokens": ["Noch", "kei\u00b7nen", "hund", "ge\u00b7hetzt", "/", "auch", "kei\u00b7nen", "schlu\u00df", "ge\u00b7wagt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVPP", "$(", "ADV", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "F\u00fcr diese schn\u00f6de lust bem\u00fch ich mich zu melden", "tokens": ["F\u00fcr", "die\u00b7se", "schn\u00f6\u00b7de", "lust", "be\u00b7m\u00fch", "ich", "mich", "zu", "mel\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN", "VVFIN", "PPER", "PRF", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Von grosser tapfferkeit ber\u00fchmter krieges-helden/", "tokens": ["Von", "gros\u00b7ser", "tapf\u00b7fer\u00b7keit", "be\u00b7r\u00fchm\u00b7ter", "krie\u00b7ge\u00b7shel\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Wie der und jener sich durch seine feinde drung/", "tokens": ["Wie", "der", "und", "je\u00b7ner", "sich", "durch", "sei\u00b7ne", "fein\u00b7de", "drung", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "KON", "PDS", "PRF", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Und sich durch schwerd un\u0303 spie\u00df un\u0303 dampf zun wolcke\u0303 schwung.", "tokens": ["Und", "sich", "durch", "schwerd", "u\u00f1", "spie\u00df", "u\u00f1", "dampf", "zun", "wolck\u1ebd", "schwung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.81": {"text": "Zwar ich bin nicht gesinnt vor dieses mahl zu sagen/", "tokens": ["Zwar", "ich", "bin", "nicht", "ge\u00b7sinnt", "vor", "die\u00b7ses", "mahl", "zu", "sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "PTKNEG", "ADJD", "APPR", "PDAT", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Was/ Ferson/ deine faust vor ruhm davon getragen/", "tokens": ["Was", "/", "Fer\u00b7son", "/", "dei\u00b7ne", "faust", "vor", "ruhm", "da\u00b7von", "ge\u00b7tra\u00b7gen", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$(", "NE", "$(", "PPOSAT", "NN", "APPR", "NN", "PAV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Als du mit selbiger Gradivum selbst bek\u00e4mpfft/", "tokens": ["Als", "du", "mit", "sel\u00b7bi\u00b7ger", "Gra\u00b7di\u00b7vum", "selbst", "be\u00b7k\u00e4mpfft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "ADV", "VVFIN", "$("], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.84": {"text": "Sein blutig schwerd geraubt und ihn damit ged\u00e4mpfft.", "tokens": ["Sein", "blu\u00b7tig", "schwerd", "ge\u00b7raubt", "und", "ihn", "da\u00b7mit", "ge\u00b7d\u00e4mpfft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "ADJD", "VVPP", "KON", "PPER", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Wer di\u00df verrichten soll/ mu\u00df Buchners hohe gaben/", "tokens": ["Wer", "di\u00df", "ver\u00b7rich\u00b7ten", "soll", "/", "mu\u00df", "Buch\u00b7ners", "ho\u00b7he", "ga\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDS", "VVINF", "VMFIN", "$(", "VMFIN", "NN", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Mu\u00df Gryphens hohen geist und donner-worte haben/", "tokens": ["Mu\u00df", "Gry\u00b7phens", "ho\u00b7hen", "geist", "und", "don\u00b7ner\u00b7wor\u00b7te", "ha\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "ADJA", "NN", "KON", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Er mu\u00df beredet seyn als unser Opitz ist/", "tokens": ["Er", "mu\u00df", "be\u00b7re\u00b7det", "seyn", "als", "un\u00b7ser", "O\u00b7pitz", "ist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVPP", "VAINF", "KOKOM", "PPOSAT", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Der erste teutsche schwan/ und r\u00fcstig seyn als Rist/", "tokens": ["Der", "ers\u00b7te", "teut\u00b7sche", "schwan", "/", "und", "r\u00fcs\u00b7tig", "seyn", "als", "Rist", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$(", "KON", "ADJD", "VAINF", "KOKOM", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Er mu\u00df entz\u00fcndet seyn von Flemmings himmels-flammen/", "tokens": ["Er", "mu\u00df", "ent\u00b7z\u00fcn\u00b7det", "seyn", "von", "Flem\u00b7mings", "him\u00b7mels\u00b7flam\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVPP", "VAINF", "APPR", "NE", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Wer nicht von jugend an der dreymal-dreyen ammen", "tokens": ["Wer", "nicht", "von", "ju\u00b7gend", "an", "der", "drey\u00b7ma\u00b7ldreyen", "am\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PTKNEG", "APPR", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+----", "measure": "unknown.measure.tetra"}, "line.91": {"text": "Gelehrte brust gesaugt/ darff sich nicht unterstehn/", "tokens": ["Ge\u00b7lehr\u00b7te", "brust", "ge\u00b7saugt", "/", "darff", "sich", "nicht", "un\u00b7ter\u00b7stehn", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "VVPP", "$(", "VMFIN", "PRF", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Dich sternen gleichen held noch h\u00f6her zu erh\u00f6hn.", "tokens": ["Dich", "ster\u00b7nen", "glei\u00b7chen", "held", "noch", "h\u00f6\u00b7her", "zu", "er\u00b7h\u00f6hn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "VVINF", "VVFIN", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Drum will ich deinen ruhm viel lieber hier verschweigen", "tokens": ["Drum", "will", "ich", "dei\u00b7nen", "ruhm", "viel", "lie\u00b7ber", "hier", "ver\u00b7schwei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VMFIN", "PPER", "PPOSAT", "NN", "ADV", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Und mich mit worten nicht/ wie Phaeton/ versteigen/", "tokens": ["Und", "mich", "mit", "wor\u00b7ten", "nicht", "/", "wie", "Phae\u00b7ton", "/", "ver\u00b7stei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "PTKNEG", "$(", "KOKOM", "NE", "$(", "VVINF", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.95": {"text": "Der/ weil er \u00fcberschritt sein vorgestecktes ziel/", "tokens": ["Der", "/", "weil", "er", "\u00fc\u00b7bersc\u00b7hritt", "sein", "vor\u00b7ge\u00b7steck\u00b7tes", "ziel", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "KOUS", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Schnell \u00fcber hals und kopff vom himmel runter fiel.", "tokens": ["Schnell", "\u00fc\u00b7ber", "hals", "und", "kopff", "vom", "him\u00b7mel", "run\u00b7ter", "fiel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "KON", "NN", "APPRART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Woferne dieser reim/ der dir zun f\u00fcssen lieget/", "tokens": ["Wo\u00b7fer\u00b7ne", "die\u00b7ser", "reim", "/", "der", "dir", "zun", "f\u00fcs\u00b7sen", "lie\u00b7get", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "$(", "PRELS", "PPER", "ADV", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Dein auge schauen kan/ so bin ich schon vergn\u00fcget;", "tokens": ["Dein", "au\u00b7ge", "schau\u00b7en", "kan", "/", "so", "bin", "ich", "schon", "ver\u00b7gn\u00fc\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "VMFIN", "$(", "ADV", "VAFIN", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "Wenn aber finsterni\u00df ihm solt im lichte stehn/", "tokens": ["Wenn", "a\u00b7ber", "fins\u00b7ter\u00b7ni\u00df", "ihm", "solt", "im", "lich\u00b7te", "stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VVFIN", "PPER", "VMFIN", "APPRART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "So wird die sonne mir heut blutig untergehn.", "tokens": ["So", "wird", "die", "son\u00b7ne", "mir", "heut", "blu\u00b7tig", "un\u00b7ter\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Damit nun dieser tag befreyet sey vom leide/", "tokens": ["Da\u00b7mit", "nun", "die\u00b7ser", "tag", "be\u00b7fre\u00b7yet", "sey", "vom", "lei\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "PDAT", "NN", "VVFIN", "VAFIN", "APPRART", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "So g\u00f6nn auch mir ein theil von deiner ankunffts-freude/", "tokens": ["So", "g\u00f6nn", "auch", "mir", "ein", "theil", "von", "dei\u00b7ner", "an\u00b7kunf\u00b7fts\u00b7freu\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+----+-", "measure": "unknown.measure.penta"}, "line.103": {"text": "Und nim/ ich wei\u00df du kanst/ dich deines dieners an/", "tokens": ["Und", "nim", "/", "ich", "wei\u00df", "du", "kanst", "/", "dich", "dei\u00b7nes", "die\u00b7ners", "an", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "$(", "PPER", "VVFIN", "PPER", "VMFIN", "$(", "PPER", "PPOSAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "Sonst ist es um mein gl\u00fcck und wolfarth gantz gethan.", "tokens": ["Sonst", "ist", "es", "um", "mein", "gl\u00fcck", "und", "wolf\u00b7arth", "gantz", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PPOSAT", "NN", "KON", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Ich bitte dich/ durch dich/ durch deine tapffre ahnen/", "tokens": ["Ich", "bit\u00b7te", "dich", "/", "durch", "dich", "/", "durch", "dei\u00b7ne", "tapf\u00b7fre", "ah\u00b7nen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "APPR", "PPER", "$(", "APPR", "PPOSAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "Durch deinen helden-muth/ durch deine sieges-fahnen/", "tokens": ["Durch", "dei\u00b7nen", "hel\u00b7den\u00b7muth", "/", "durch", "dei\u00b7ne", "sie\u00b7ges\u00b7fah\u00b7nen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$(", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "Durch dein verg\u00f6ttert lob/ das sich durch belt und feld", "tokens": ["Durch", "dein", "ver\u00b7g\u00f6t\u00b7tert", "lob", "/", "das", "sich", "durch", "belt", "und", "feld"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "VVFIN", "NN", "$(", "PRELS", "PRF", "APPR", "VVFIN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "Und welt geschwungen hat bi\u00df an der sternen zelt.", "tokens": ["Und", "welt", "ge\u00b7schwun\u00b7gen", "hat", "bi\u00df", "an", "der", "ster\u00b7nen", "zelt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVPP", "VAFIN", "ADV", "APPR", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.109": {"text": "La\u00df meine hoffnung nicht vor di\u00dfmahl mich betr\u00fcgen/", "tokens": ["La\u00df", "mei\u00b7ne", "hoff\u00b7nung", "nicht", "vor", "di\u00df\u00b7mahl", "mich", "be\u00b7tr\u00fc\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "PTKNEG", "APPR", "ADV", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Hilff mir durch deinen sieg mein ungl\u00fcck \u00fcbersiegen/", "tokens": ["Hilff", "mir", "durch", "dei\u00b7nen", "sieg", "mein", "un\u00b7gl\u00fcck", "\u00fc\u00b7ber\u00b7sie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PPOSAT", "NN", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "So soll der frohe tag/ an dem du eingekehrt/", "tokens": ["So", "soll", "der", "fro\u00b7he", "tag", "/", "an", "dem", "du", "ein\u00b7ge\u00b7kehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "$(", "APPR", "PRELS", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Benebenst dir/ von mir/ seyn ewig hochgeehrt.", "tokens": ["Be\u00b7ne\u00b7benst", "dir", "/", "von", "mir", "/", "seyn", "e\u00b7wig", "hoch\u00b7geehrt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$(", "APPR", "PPER", "$(", "PPOSAT", "ADJD", "VVPP", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}}}}