{"dta.poem.20627": {"metadata": {"author": {"name": "Karsch, Anna Luise", "birth": "N.A.", "death": "N.A."}, "title": "Ueber  \n die Vorz\u00fcge  \n des  \n  Prinzen Friedrichs  \n von Braunschweig .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1792", "urn": "urn:nbn:de:kobv:b4-200905193016", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Soll ich zuerst besingen den Befreyer,                 ", "tokens": ["Soll", "ich", "zu\u00b7erst", "be\u00b7sin\u00b7gen", "den", "Be\u00b7fre\u00b7yer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den Retter Braunschweigs? oder das                 ", "tokens": ["Den", "Ret\u00b7ter", "Braun\u00b7schweigs", "?", "o\u00b7der", "das"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "NE", "$.", "KON", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gef\u00fchl", "tokens": ["Ge\u00b7f\u00fchl"], "token_info": ["word"], "pos": ["NN"], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "Des gro\u00dfen Herzens und des sch\u00f6nen Geistes Feuer:", "tokens": ["Des", "gro\u00b7\u00dfen", "Her\u00b7zens", "und", "des", "sch\u00f6\u00b7nen", "Geis\u00b7tes", "Feu\u00b7er", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was w\u00e4hlest du mein Saitenspiel?", "tokens": ["Was", "w\u00e4h\u00b7lest", "du", "mein", "Sai\u00b7ten\u00b7spiel", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Den Heldenmuth des ", "tokens": ["Den", "Hel\u00b7den\u00b7muth", "des"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "S\u00fc\u00dfrednerische Suada, die voll Geist", "tokens": ["S\u00fc\u00df\u00b7red\u00b7ne\u00b7ri\u00b7sche", "Sua\u00b7da", ",", "die", "voll", "Geist"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "PRELS", "ADJD", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Von seinen Lippen rauscht, so wie durch Blumenhayne", "tokens": ["Von", "sei\u00b7nen", "Lip\u00b7pen", "rauscht", ",", "so", "wie", "durch", "Blu\u00b7men\u00b7hay\u00b7ne"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "ADV", "KOKOM", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Quell auf goldnem Sande fleu\u00dft.", "tokens": ["Der", "Quell", "auf", "gold\u00b7nem", "San\u00b7de", "fleu\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Dem Afrikaner Scipio, dem jungen", "tokens": ["Dem", "Af\u00b7ri\u00b7ka\u00b7ner", "Sci\u00b7pio", ",", "dem", "jun\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "NE", "$,", "ART", "ADJA"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Pompejus und dem Sieger \u00fcber ihn,", "tokens": ["Pom\u00b7pe\u00b7jus", "und", "dem", "Sie\u00b7ger", "\u00fc\u00b7ber", "ihn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ART", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dem C\u00e4sar selbst, ist niemahls eine That gelungen,", "tokens": ["Dem", "C\u00e4\u00b7sar", "selbst", ",", "ist", "nie\u00b7mahls", "ei\u00b7ne", "That", "ge\u00b7lun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADV", "$,", "VAFIN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die mehr des Lorbeers w\u00fcrdig schien", "tokens": ["Die", "mehr", "des", "Lor\u00b7beers", "w\u00fcr\u00b7dig", "schien"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Als diese That des k\u00fchnen jugendlichen", "tokens": ["Als", "die\u00b7se", "That", "des", "k\u00fch\u00b7nen", "ju\u00b7gend\u00b7li\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PDAT", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Besch\u00fctzers von der Aelterv\u00e4ter Grab;", "tokens": ["Be\u00b7sch\u00fct\u00b7zers", "von", "der", "A\u00b7el\u00b7ter\u00b7v\u00e4\u00b7ter", "Grab", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ihm g\u00fcrteten, nachdem des Feindes Macht entwichen,", "tokens": ["Ihm", "g\u00fcr\u00b7te\u00b7ten", ",", "nach\u00b7dem", "des", "Fein\u00b7des", "Macht", "ent\u00b7wi\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Grazien den Degen ab,", "tokens": ["Die", "Gra\u00b7zi\u00b7en", "den", "De\u00b7gen", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Und k\u00fc\u00dften Seine Kranzumwundne Schl\u00e4fe,", "tokens": ["Und", "k\u00fc\u00df\u00b7ten", "Sei\u00b7ne", "Kran\u00b7zum\u00b7wund\u00b7ne", "Schl\u00e4\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und ordneten Sein staubbepudert Haar,", "tokens": ["Und", "ord\u00b7ne\u00b7ten", "Sein", "staub\u00b7be\u00b7pu\u00b7dert", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und frugen, welcher Held und Halbgott \u00fcbertr\u00e4fe", "tokens": ["Und", "fru\u00b7gen", ",", "wel\u00b7cher", "Held", "und", "Halb\u00b7gott", "\u00fc\u00b7bert\u00b7r\u00e4\u00b7fe"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "$,", "PWAT", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den J\u00fcngling? der noch gl\u00fchend war", "tokens": ["Den", "J\u00fcng\u00b7ling", "?", "der", "noch", "gl\u00fc\u00b7hend", "war"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$.", "ART", "ADV", "ADJD", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Von einem Kampf, in welchem tausend St\u00f6\u00dfe", "tokens": ["Von", "ei\u00b7nem", "Kampf", ",", "in", "wel\u00b7chem", "tau\u00b7send", "St\u00f6\u00b7\u00dfe"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "PWAT", "CARD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sein schlanker Arm mit schnellgez\u00fccktem Speer", "tokens": ["Sein", "schlan\u00b7ker", "Arm", "mit", "schnell\u00b7ge\u00b7z\u00fcck\u00b7tem", "Speer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Den Feinden gab. Und jetzt schrieb Er: zu welcher Gr\u00f6\u00dfe", "tokens": ["Den", "Fein\u00b7den", "gab", ".", "Und", "jetzt", "schrieb", "Er", ":", "zu", "wel\u00b7cher", "Gr\u00f6\u00b7\u00dfe"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "KON", "ADV", "VVFIN", "PPER", "$.", "APPR", "PWAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das alte Rom gestiegen w\u00e4r", "tokens": ["Das", "al\u00b7te", "Rom", "ge\u00b7stie\u00b7gen", "w\u00e4r"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NE", "VVPP", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Zur Zeit, als von dem pflugzerri\u00dfnen Acker", "tokens": ["Zur", "Zeit", ",", "als", "von", "dem", "pflug\u00b7zer\u00b7ri\u00df\u00b7nen", "A\u00b7cker"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "KOUS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Best\u00e4ubt und braun, jedweder R\u00f6mer kam,", "tokens": ["Be\u00b7st\u00e4ubt", "und", "braun", ",", "jed\u00b7we\u00b7der", "R\u00f6\u00b7mer", "kam", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "$,", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und f\u00fcr das Vaterland mit schnellem Eifer, wacker", "tokens": ["Und", "f\u00fcr", "das", "Va\u00b7ter\u00b7land", "mit", "schnel\u00b7lem", "Ei\u00b7fer", ",", "wa\u00b7cker"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "$,", "ADJD"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die rostbefreyte Waffen nahm.", "tokens": ["Die", "rost\u00b7be\u00b7frey\u00b7te", "Waf\u00b7fen", "nahm", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Da liefen selbst des Sonnen-Wagens R\u00e4der", "tokens": ["Da", "lie\u00b7fen", "selbst", "des", "Son\u00b7nen\u00b7Wa\u00b7gens", "R\u00e4\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nicht schneller als der R\u00f6mer Siegesgl\u00fcck.", "tokens": ["Nicht", "schnel\u00b7ler", "als", "der", "R\u00f6\u00b7mer", "Sie\u00b7ges\u00b7gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Woll\u00fcstig flog noch nicht in salbenreiche B\u00e4der", "tokens": ["Wol\u00b7l\u00fcs\u00b7tig", "flog", "noch", "nicht", "in", "sal\u00b7ben\u00b7rei\u00b7che", "B\u00e4\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Ihr Feldherr aus der Schlacht zur\u00fcck.", "tokens": ["Ihr", "Feld\u00b7herr", "aus", "der", "Schlacht", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Als aber die Luculle, die Verschwender", "tokens": ["Als", "a\u00b7ber", "die", "Lu\u00b7cul\u00b7le", ",", "die", "Ver\u00b7schwen\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sich br\u00fcsteten an Tafeln gro\u00df zu seyn,", "tokens": ["Sich", "br\u00fcs\u00b7te\u00b7ten", "an", "Ta\u00b7feln", "gro\u00df", "zu", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "APPR", "NN", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da ward die Herrscherin der unterworfnen L\u00e4nder", "tokens": ["Da", "ward", "die", "Herr\u00b7sche\u00b7rin", "der", "un\u00b7ter\u00b7worf\u00b7nen", "L\u00e4n\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In reichgewordnen B\u00fcrgern klein.", "tokens": ["In", "reich\u00b7ge\u00b7word\u00b7nen", "B\u00fcr\u00b7gern", "klein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Als im Senat die Clodiusse sprachen,", "tokens": ["Als", "im", "Se\u00b7nat", "die", "Clo\u00b7di\u00b7us\u00b7se", "spra\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPRART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Und redend Gold sich um das Consulat", "tokens": ["Und", "re\u00b7dend", "Gold", "sich", "um", "das", "Con\u00b7su\u00b7lat"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "NN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Tief unterm Volk bewarb, und der erw\u00fcrgten Grachen", "tokens": ["Tief", "un\u00b7term", "Volk", "be\u00b7warb", ",", "und", "der", "er\u00b7w\u00fcrg\u00b7ten", "Gra\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "APPRART", "NN", "VVFIN", "$,", "KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vergo\u00dfnes Blut um Rache bat:", "tokens": ["Ver\u00b7go\u00df\u00b7nes", "Blut", "um", "Ra\u00b7che", "bat", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Da ward durch ihrer eignen Kinder W\u00fcten,", "tokens": ["Da", "ward", "durch", "ih\u00b7rer", "eig\u00b7nen", "Kin\u00b7der", "W\u00fc\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gest\u00fcrzt das stolze, hochgese\u00dfne Rom,", "tokens": ["Ge\u00b7st\u00fcrzt", "das", "stol\u00b7ze", ",", "hoch\u00b7ge\u00b7se\u00df\u00b7ne", "Rom", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "$,", "ADJA", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die K\u00f6nigin der Welt, vor welcher V\u00f6lker knieten", "tokens": ["Die", "K\u00f6\u00b7ni\u00b7gin", "der", "Welt", ",", "vor", "wel\u00b7cher", "V\u00f6l\u00b7ker", "knie\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "$,", "APPR", "PWAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vom Euphrat bis zum Donaustrom.", "tokens": ["Vom", "Eu\u00b7ph\u00b7rat", "bis", "zum", "Do\u00b7naus\u00b7trom", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NE", "APPR", "APPRART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Nun donnert sie den fernentlegnen Thronen", "tokens": ["Nun", "don\u00b7nert", "sie", "den", "fer\u00b7nent\u00b7leg\u00b7nen", "Thro\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nicht Schrecken mehr durch ihres Nahmens Klang,", "tokens": ["Nicht", "Schre\u00b7cken", "mehr", "durch", "ih\u00b7res", "Nah\u00b7mens", "Klang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "ADV", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ihr sonst ber\u00fchmter Strom sieht M\u00e4nner um sich", "tokens": ["Ihr", "sonst", "be\u00b7r\u00fchm\u00b7ter", "Strom", "sieht", "M\u00e4n\u00b7ner", "um", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "ADJA", "NN", "VVFIN", "NN", "APPR", "PRF"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "wohnen,", "tokens": ["woh\u00b7nen", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Gew\u00f6hnt zu weibischem Gesang.", "tokens": ["Ge\u00b7w\u00f6hnt", "zu", "wei\u00b7bi\u00b7schem", "Ge\u00b7sang", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "PTKZU", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Sie spricht nicht mehr die Sprache der Lateiner,", "tokens": ["Sie", "spricht", "nicht", "mehr", "die", "Spra\u00b7che", "der", "La\u00b7tei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und h\u00f6rt in ihrer neuen Mundesart", "tokens": ["Und", "h\u00f6rt", "in", "ih\u00b7rer", "neu\u00b7en", "Mun\u00b7des\u00b7art"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Durch ", "tokens": ["Durch"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "sie kleiner", "tokens": ["sie", "klei\u00b7ner"], "token_info": ["word", "word"], "pos": ["PPER", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Aus einer Frau zur Sclavin ward,", "tokens": ["Aus", "ei\u00b7ner", "Frau", "zur", "Scla\u00b7vin", "ward", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPRART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Und fr\u00e4gt erstaunt, \u201eob Tasso von den Schatten", "tokens": ["Und", "fr\u00e4gt", "er\u00b7staunt", ",", "\u201e", "ob", "Tas\u00b7so", "von", "den", "Schat\u00b7ten"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "$,", "$(", "KOUS", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gekommen, oder Pluto der Monarch", "tokens": ["Ge\u00b7kom\u00b7men", ",", "o\u00b7der", "Plu\u00b7to", "der", "Mon\u00b7arch"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "KON", "NN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Des Orcus, sich bezwang, die Reise zu verstatten", "tokens": ["Des", "Or\u00b7cus", ",", "sich", "be\u00b7zwang", ",", "die", "Rei\u00b7se", "zu", "ver\u00b7stat\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRF", "VVFIN", "$,", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem Laurasuchenden Perrarch?\u201e", "tokens": ["Dem", "Lau\u00b7ra\u00b7su\u00b7chen\u00b7den", "Per\u00b7rarch", "?", "\u201e"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}}}}