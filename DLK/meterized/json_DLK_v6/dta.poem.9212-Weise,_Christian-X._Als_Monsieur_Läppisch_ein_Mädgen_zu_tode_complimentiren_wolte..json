{"dta.poem.9212": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "X.  \n Als Monsieur L\u00e4ppisch ein M\u00e4dgen zu tode  \n complimentiren wolte.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Es ist ja sonsten gifft genung/", "tokens": ["Es", "ist", "ja", "sons\u00b7ten", "gifft", "ge\u00b7nung", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJA", "NN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir d\u00fcrffen keine feuer-schlangen", "tokens": ["Wir", "d\u00fcrf\u00b7fen", "kei\u00b7ne", "feu\u00b7er\u00b7schlan\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und irgeud d\u00fcrre kr\u00f6ten fangen/", "tokens": ["Und", "ir\u00b7geud", "d\u00fcr\u00b7re", "kr\u00f6\u00b7ten", "fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So haben wir den rechten trunck/", "tokens": ["So", "ha\u00b7ben", "wir", "den", "rech\u00b7ten", "trunck", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Auf allen nothfall thut es auch", "tokens": ["Auf", "al\u00b7len", "noth\u00b7fall", "thut", "es", "auch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein kleines bi\u00dfgen hutterauch.", "tokens": ["Ein", "klei\u00b7nes", "bi\u00df\u00b7gen", "hut\u00b7ter\u00b7auch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "2. Was treibt dich dann vor noth darzu/", "tokens": ["Was", "treibt", "dich", "dann", "vor", "noth", "dar\u00b7zu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPR", "NN", "PAV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df du den armen m\u00e4dgen eben", "tokens": ["Da\u00df", "du", "den", "ar\u00b7men", "m\u00e4d\u00b7gen", "e\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mit deinen worten wilst vergeben?", "tokens": ["Mit", "dei\u00b7nen", "wor\u00b7ten", "wilst", "ver\u00b7ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ach halt das maul und schaff ihr ruh/", "tokens": ["Ach", "halt", "das", "maul", "und", "schaff", "ihr", "ruh", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "ART", "NN", "KON", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dann hat sie ja den todt ersehn/", "tokens": ["Dann", "hat", "sie", "ja", "den", "todt", "er\u00b7sehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So k\u00f6nt es ohne dich geschehn.", "tokens": ["So", "k\u00f6nt", "es", "oh\u00b7ne", "dich", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "3. ", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Sechs hundert tausend eitelkeiten/", "tokens": ["Sechs", "hun\u00b7dert", "tau\u00b7send", "ei\u00b7tel\u00b7kei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "CARD", "CARD", "ADJA", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die weder gicks noch gacks bedeuten/", "tokens": ["Die", "we\u00b7der", "gicks", "noch", "gacks", "be\u00b7deu\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KON", "ADV", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Aus seiner lahme zunge f\u00fcr/", "tokens": ["Aus", "sei\u00b7ner", "lah\u00b7me", "zun\u00b7ge", "f\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da fippert er und radebrecht", "tokens": ["Da", "fip\u00b7pert", "er", "und", "ra\u00b7de\u00b7brecht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die reden als ein schinder-knecht.", "tokens": ["Die", "re\u00b7den", "als", "ein", "schin\u00b7der\u00b7knecht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "KOKOM", "ART", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "4. Jhr leute nun gedenckt an mich/", "tokens": ["Ihr", "leu\u00b7te", "nun", "ge\u00b7denckt", "an", "mich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "VVFIN", "APPR", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir haben morgen eine leiche/", "tokens": ["Wir", "ha\u00b7ben", "mor\u00b7gen", "ei\u00b7ne", "lei\u00b7che", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der g\u00fcmpel f\u00fchrt die stumpffen streiche", "tokens": ["Der", "g\u00fcm\u00b7pel", "f\u00fchrt", "die", "stumpf\u00b7fen", "strei\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bald oben hin/ bald nnter sich/", "tokens": ["Bald", "o\u00b7ben", "hin", "/", "bald", "nn\u00b7ter", "sich", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKVZ", "$(", "ADV", "ADJA", "PRF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Darumb/ sol ungel\u00fccke seyn/", "tokens": ["Da\u00b7rumb", "/", "sol", "un\u00b7ge\u00b7l\u00fc\u00b7cke", "seyn", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "$(", "PIAT", "NN", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So sticht er leicht zum hertzen nein.", "tokens": ["So", "sticht", "er", "leicht", "zum", "hert\u00b7zen", "nein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "PTKANT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "5. Es jammert mich das arme kind/", "tokens": ["Es", "jam\u00b7mert", "mich", "das", "ar\u00b7me", "kind", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df eben die beliebten sachen/", "tokens": ["Da\u00df", "e\u00b7ben", "die", "be\u00b7lieb\u00b7ten", "sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die andere m\u00e4dgen lustig machen/", "tokens": ["Die", "an\u00b7de\u00b7re", "m\u00e4d\u00b7gen", "lus\u00b7tig", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "ADJD", "VVINF", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Jhr an dem leben sch\u00e4dlichsind/", "tokens": ["Ihr", "an", "dem", "le\u00b7ben", "sch\u00e4d\u00b7lich\u00b7sind", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "VVFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und da\u00df ein wort/ das sonst verst\u00e4ubt/", "tokens": ["Und", "da\u00df", "ein", "wort", "/", "das", "sonst", "ver\u00b7st\u00e4ubt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "$(", "PDS", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Jhr an dem hertzen kleben bleibt.", "tokens": ["Ihr", "an", "dem", "hert\u00b7zen", "kle\u00b7ben", "bleibt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "6. Sie k\u00f6mmt in warheit nicht davon", "tokens": ["Sie", "k\u00f6mmt", "in", "war\u00b7heit", "nicht", "da\u00b7von"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PTKNEG", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dann wolte sie den leib purgieren/", "tokens": ["Dann", "wol\u00b7te", "sie", "den", "leib", "pur\u00b7gie\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und allen unflat von sich f\u00fchren/", "tokens": ["Und", "al\u00b7len", "un\u00b7flat", "von", "sich", "f\u00fch\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wo w\u00e4re die purgation?", "tokens": ["Wo", "w\u00e4\u00b7re", "die", "pur\u00b7ga\u00b7ti\u00b7on", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Ach nein/ sie stirbt in dieser qval/", "tokens": ["Ach", "nein", "/", "sie", "stirbt", "in", "die\u00b7ser", "qval", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "$(", "PPER", "VVFIN", "APPR", "PDAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wir sehn sie nun das letzte mahl.", "tokens": ["Wir", "sehn", "sie", "nun", "das", "letz\u00b7te", "mahl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "ADJA", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}