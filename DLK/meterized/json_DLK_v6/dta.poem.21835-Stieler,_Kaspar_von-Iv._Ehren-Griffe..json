{"dta.poem.21835": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "Iv.  \n  Ehren-Griffe.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.71", "et:0.28"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Was z\u00fckkstu denn zur\u00fckke/", "tokens": ["Was", "z\u00fckks\u00b7tu", "denn", "zu\u00b7r\u00fck\u00b7ke", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "PTKVZ", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "wenn diese meine Hand", "tokens": ["wenn", "die\u00b7se", "mei\u00b7ne", "Hand"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PDS", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "versuchen wil ihr Gl\u00fckke?", "tokens": ["ver\u00b7su\u00b7chen", "wil", "ihr", "Gl\u00fck\u00b7ke", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVINF", "VMFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "f\u00e4llt sie zu weit ins Land/", "tokens": ["f\u00e4llt", "sie", "zu", "weit", "ins", "Land", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKA", "ADJD", "APPRART", "NN", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.5": {"text": "Rosille wenn sie r\u00fchret", "tokens": ["Ro\u00b7sil\u00b7le", "wenn", "sie", "r\u00fch\u00b7ret"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KOUS", "PPER", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "was ihr ihr Jungfer Volk verdekket f\u00fchret?", "tokens": ["was", "ihr", "ihr", "Jung\u00b7fer", "Volk", "ver\u00b7dek\u00b7ket", "f\u00fch\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPOSAT", "NN", "NN", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Es wird einmahl doch kommen/", "tokens": ["Es", "wird", "ein\u00b7mahl", "doch", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "da\u00df dir die grosse Scheu", "tokens": ["da\u00df", "dir", "die", "gros\u00b7se", "Scheu"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zu halten wird benommen.", "tokens": ["Zu", "hal\u00b7ten", "wird", "be\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Was meinstu? tieffe Reu", "tokens": ["Was", "meins\u00b7tu", "?", "tief\u00b7fe", "Reu"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PWS", "VVFIN", "$.", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "wird dich alsdenn umfassen/", "tokens": ["wird", "dich", "als\u00b7denn", "um\u00b7fas\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "wo du mir meine Lust auch hast gelassen.", "tokens": ["wo", "du", "mir", "mei\u00b7ne", "Lust", "auch", "hast", "ge\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "PPOSAT", "NN", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Die unkostbahren T\u00fccher/", "tokens": ["Die", "un\u00b7kost\u00b7bah\u00b7ren", "T\u00fc\u00b7cher", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "betasten frey und sicher", "tokens": ["be\u00b7tas\u00b7ten", "frey", "und", "si\u00b7cher"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "die s\u00fcsse Wollust an", "tokens": ["die", "s\u00fcs\u00b7se", "Wol\u00b7lust", "an"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "den H\u00e4nden/ die doch beben", "tokens": ["den", "H\u00e4n\u00b7den", "/", "die", "doch", "be\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$(", "PRELS", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "wird so ein linder Strich nicht zugegeben.", "tokens": ["wird", "so", "ein", "lin\u00b7der", "Strich", "nicht", "zu\u00b7ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "PTKNEG", "VVPP", "$."], "meter": "---+-+-+-+-", "measure": "unknown.measure.tetra"}}, "stanza.4": {"line.1": {"text": "Ey! w\u00e4rstu au\u00df der Erden", "tokens": ["Ey", "!", "w\u00e4rs\u00b7tu", "au\u00df", "der", "Er\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "VAFIN", "APPR", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "in Indien erbaut/", "tokens": ["in", "In\u00b7di\u00b7en", "er\u00b7baut", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVPP", "$("], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "wo alle Weiber werden", "tokens": ["wo", "al\u00b7le", "Wei\u00b7ber", "wer\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "VAINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "ganz nakkend angeschaut:", "tokens": ["ganz", "nak\u00b7kend", "an\u00b7ge\u00b7schaut", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "wollstu dich dar auch sch\u00e4men/", "tokens": ["woll\u00b7stu", "dich", "dar", "auch", "sch\u00e4\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKVZ", "ADV", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "und einen schlechten Griff vor \u00fcbel nehmen.", "tokens": ["und", "ei\u00b7nen", "schlech\u00b7ten", "Griff", "vor", "\u00fc\u00b7bel", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Die Haut am ganzem Leibe/", "tokens": ["Die", "Haut", "am", "gan\u00b7zem", "Lei\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "ist/ d\u00fcnkt mich einerley/", "tokens": ["ist", "/", "d\u00fcnkt", "mich", "ei\u00b7ner\u00b7ley", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$(", "VVFIN", "PPER", "ADV", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "ob ich mich hieran reibe", "tokens": ["ob", "ich", "mich", "hie\u00b7ran", "rei\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "PAV", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "und gehe dort vorbey/", "tokens": ["und", "ge\u00b7he", "dort", "vor\u00b7bey", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PTKVZ", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "ist schlecht zu unterscheiden", "tokens": ["ist", "schlecht", "zu", "un\u00b7ter\u00b7schei\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "PTKZU", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Die Haut wird doch nicht ringer", "tokens": ["Die", "Haut", "wird", "doch", "nicht", "rin\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKNEG", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "und bleibet unbeflekkt/", "tokens": ["und", "blei\u00b7bet", "un\u00b7be\u00b7flekkt", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "ob sich schon je ein Finger", "tokens": ["ob", "sich", "schon", "je", "ein", "Fin\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "dar\u00fcber au\u00dfgestrekkt.", "tokens": ["da\u00b7r\u00fc\u00b7ber", "au\u00df\u00b7ge\u00b7strekkt", "."], "token_info": ["word", "word", "punct"], "pos": ["PAV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Man wird di\u00df an nicht sehen/", "tokens": ["Man", "wird", "di\u00df", "an", "nicht", "se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PDS", "APPR", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "ist schon ein Ehren-griff wohin geschehen.", "tokens": ["ist", "schon", "ein", "Eh\u00b7ren\u00b7griff", "wo\u00b7hin", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "PWAV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Du weist/ ich bin verschwiegen", "tokens": ["Du", "weist", "/", "ich", "bin", "ver\u00b7schwie\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VAFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "wo dir es darum ist", "tokens": ["wo", "dir", "es", "da\u00b7rum", "ist"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PPER", "PAV", "VAFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "man m\u00f6cht zuwissen kriegen/", "tokens": ["man", "m\u00f6cht", "zu\u00b7wis\u00b7sen", "krie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "VVINF", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "da\u00df meine Hand dich k\u00fc\u00dft:", "tokens": ["da\u00df", "mei\u00b7ne", "Hand", "dich", "k\u00fc\u00dft", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "den Zula\u00df soll kein Mensch je au\u00df mir h\u00f6ren.", "tokens": ["den", "Zu\u00b7la\u00df", "soll", "kein", "Mensch", "je", "au\u00df", "mir", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PIAT", "NN", "ADV", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Drum zukke nicht zur\u00fckke/", "tokens": ["Drum", "zuk\u00b7ke", "nicht", "zu\u00b7r\u00fck\u00b7ke", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PTKNEG", "PTKVZ", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "wenn diese meine Hand", "tokens": ["wenn", "die\u00b7se", "mei\u00b7ne", "Hand"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PDS", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "versuchen wil ihr Gl\u00fckke.", "tokens": ["ver\u00b7su\u00b7chen", "wil", "ihr", "Gl\u00fck\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVINF", "VMFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Es ist doch nur ein Tand", "tokens": ["Es", "ist", "doch", "nur", "ein", "Tand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "zu f\u00fchlen das/ sich wehren/", "tokens": ["zu", "f\u00fch\u00b7len", "das", "/", "sich", "weh\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ART", "$(", "PRF", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "was bald ein ander wird mit Macht zerst\u00f6ren.", "tokens": ["was", "bald", "ein", "an\u00b7der", "wird", "mit", "Macht", "zer\u00b7st\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "ADJD", "VAFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}