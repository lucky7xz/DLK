{"dta.poem.4224": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Das reifende Getrayde.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-20083-6", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Mit einer innern Lust und Freude", "tokens": ["Mit", "ei\u00b7ner", "in\u00b7nern", "Lust", "und", "Freu\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Beschau ich t\u00e4glich mein Getrayde,", "tokens": ["Be\u00b7schau", "ich", "t\u00e4g\u00b7lich", "mein", "Ge\u00b7tray\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das heuer so vortrefflich steht,", "tokens": ["Das", "heu\u00b7er", "so", "vor\u00b7treff\u00b7lich", "steht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df mancher, dem es nicht geh\u00f6rt,", "tokens": ["Da\u00df", "man\u00b7cher", ",", "dem", "es", "nicht", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "PRELS", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch \u00f6fters GOtt bewundernd ehrt,", "tokens": ["Doch", "\u00f6f\u00b7ters", "Gott", "be\u00b7wun\u00b7dernd", "ehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und Jhn, durch ein GOtt Lob! erh\u00f6ht.", "tokens": ["Und", "Jhn", ",", "durch", "ein", "Gott", "Lob", "!", "er\u00b7h\u00f6ht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "$,", "APPR", "ART", "NN", "NN", "$.", "VVPP", "$."], "meter": "-+-+++-+", "measure": "unknown.measure.penta"}, "line.7": {"text": "Noch neulich sah ein Ackersmann", "tokens": ["Noch", "neu\u00b7lich", "sah", "ein", "A\u00b7ckers\u00b7mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Bewundernd diesen Segen an,", "tokens": ["Be\u00b7wun\u00b7dernd", "die\u00b7sen", "Se\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "PDAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und sprach: Da\u00df er sich unterst\u00fcnde,", "tokens": ["Und", "sprach", ":", "Da\u00df", "er", "sich", "un\u00b7ter\u00b7st\u00fcn\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "KOUS", "PPER", "PRF", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Zu wetten, da\u00df auf hundert Meilen,", "tokens": ["Zu", "wet\u00b7ten", ",", "da\u00df", "auf", "hun\u00b7dert", "Mei\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "KOUS", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "In allen ganz vollkommnen Theilen,", "tokens": ["In", "al\u00b7len", "ganz", "voll\u00b7komm\u00b7nen", "Thei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Man keinen bessern Rocken f\u00fcnde.", "tokens": ["Man", "kei\u00b7nen", "bes\u00b7sern", "Ro\u00b7cken", "f\u00fcn\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PIAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Der Halm ist hoch, die Aehre gro\u00df,", "tokens": ["Der", "Halm", "ist", "hoch", ",", "die", "A\u00b7eh\u00b7re", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+----+", "measure": "unknown.measure.tri"}, "line.14": {"text": "Das Korn ist grob und ganz fast blo\u00df,", "tokens": ["Das", "Korn", "ist", "grob", "und", "ganz", "fast", "blo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KON", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Indem die ", "tokens": ["In\u00b7dem", "die"], "token_info": ["word", "word"], "pos": ["KOUS", "ART"], "meter": "+--", "measure": "dactylic.init"}, "line.16": {"text": "Sich meistens abgerieben finden.", "tokens": ["Sich", "meis\u00b7tens", "ab\u00b7ge\u00b7rie\u00b7ben", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Die K\u00f6rner glimmen recht und gl\u00e4nzen,", "tokens": ["Die", "K\u00f6r\u00b7ner", "glim\u00b7men", "recht", "und", "gl\u00e4n\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Durch die Beh\u00e4lter, welche sie,", "tokens": ["Durch", "die", "Be\u00b7h\u00e4l\u00b7ter", ",", "wel\u00b7che", "sie", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPER", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.19": {"text": "Nicht ohne M\u00fch,", "tokens": ["Nicht", "oh\u00b7ne", "M\u00fch", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.20": {"text": "Annoch begrenzen.", "tokens": ["An\u00b7noch", "be\u00b7gren\u00b7zen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.21": {"text": "Durch ihre Gr\u00f6sse sind die H\u00fclsen recht gedrengt,", "tokens": ["Durch", "ih\u00b7re", "Gr\u00f6s\u00b7se", "sind", "die", "H\u00fcl\u00b7sen", "recht", "ge\u00b7drengt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und scheinen gleichsam aufgesprengt,", "tokens": ["Und", "schei\u00b7nen", "gleich\u00b7sam", "auf\u00b7ge\u00b7sprengt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "So, da\u00df man \u00f6fters nichts, als die fast g\u00fcldne Saat,", "tokens": ["So", ",", "da\u00df", "man", "\u00f6f\u00b7ters", "nichts", ",", "als", "die", "fast", "g\u00fcld\u00b7ne", "Saat", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PIS", "ADV", "PIS", "$,", "KOUS", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "So eng\u2019 gepre\u00dft, als K\u00f6rner im Granat,", "tokens": ["So", "eng'", "ge\u00b7pre\u00dft", ",", "als", "K\u00f6r\u00b7ner", "im", "Gra\u00b7nat", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$,", "KOUS", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "An lauter grossen Aehren siehet.", "tokens": ["An", "lau\u00b7ter", "gros\u00b7sen", "A\u00b7eh\u00b7ren", "sie\u00b7het", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.26": {"text": "Die K\u00f6rner sitzen im Quadrat,", "tokens": ["Die", "K\u00f6r\u00b7ner", "sit\u00b7zen", "im", "Quad\u00b7rat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Und scheinen, da sie gleichsam g\u00fclden,", "tokens": ["Und", "schei\u00b7nen", ",", "da", "sie", "gleich\u00b7sam", "g\u00fcl\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "ADJD", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein g\u00fclden Viereck abzubilden.", "tokens": ["Ein", "g\u00fcl\u00b7den", "Vier\u00b7eck", "ab\u00b7zu\u00b7bil\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Aehren Blond scheint g\u00fclden auch, doch matt,", "tokens": ["Der", "A\u00b7eh\u00b7ren", "Blond", "scheint", "g\u00fcl\u00b7den", "auch", ",", "doch", "matt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "ADJD", "ADV", "$,", "ADV", "ADJD", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Das Gold der K\u00f6rner aber glatt.", "tokens": ["Das", "Gold", "der", "K\u00f6r\u00b7ner", "a\u00b7ber", "glatt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Glanz, womit sie angef\u00fcllt,", "tokens": ["Der", "Glanz", ",", "wo\u00b7mit", "sie", "an\u00b7ge\u00b7f\u00fcllt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und der sie gleichsam \u00fcberziehet,", "tokens": ["Und", "der", "sie", "gleich\u00b7sam", "\u00fc\u00b7ber\u00b7zie\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Zumahl wenn das Getrayd\u2019 im Strahl der Sonnen gl\u00fchet,", "tokens": ["Zu\u00b7mahl", "wenn", "das", "Ge\u00b7trayd'", "im", "Strahl", "der", "Son\u00b7nen", "gl\u00fc\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "APPRART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Entsteht durch ein klein Sonnen-Bild,", "tokens": ["Ent\u00b7steht", "durch", "ein", "klein", "Son\u00b7nen\u00b7Bild", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Das man auf ihrer glatten Haut,", "tokens": ["Das", "man", "auf", "ih\u00b7rer", "glat\u00b7ten", "Haut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wenn man es recht betrachtet, schaut.", "tokens": ["Wenn", "man", "es", "recht", "be\u00b7trach\u00b7tet", ",", "schaut", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ADJD", "VVPP", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Vom Fu\u00df der Aehren an bis an der Spitzen", "tokens": ["Vom", "Fu\u00df", "der", "A\u00b7eh\u00b7ren", "an", "bis", "an", "der", "Spit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN", "APPR", "KON", "APPR", "ART", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Ist alles von den kleinen Blitzen", "tokens": ["Ist", "al\u00b7les", "von", "den", "klei\u00b7nen", "Blit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Recht lieblich angef\u00fcllt. Wie angenehm, wie sch\u00f6n", "tokens": ["Recht", "lieb\u00b7lich", "an\u00b7ge\u00b7f\u00fcllt", ".", "Wie", "an\u00b7ge\u00b7nehm", ",", "wie", "sch\u00f6n"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "ADJD", "VVPP", "$.", "PWAV", "ADJD", "$,", "PWAV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die\u00df, nicht f\u00fcr ein betrachtend nur, ein Eigner-Auge, zu", "tokens": ["Die\u00df", ",", "nicht", "f\u00fcr", "ein", "be\u00b7trach\u00b7tend", "nur", ",", "ein", "Eig\u00b7ner\u00b7Au\u00b7ge", ",", "zu"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PDS", "$,", "PTKNEG", "APPR", "ART", "ADJD", "ADV", "$,", "ART", "NN", "$,", "APPR"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.15": {"text": "besehn,", "tokens": ["be\u00b7sehn", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.16": {"text": "Wird jeder leicht gedenken k\u00f6nnen.", "tokens": ["Wird", "je\u00b7der", "leicht", "ge\u00b7den\u00b7ken", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADJD", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Beym t\u00e4glichen Spatzierengehn", "tokens": ["Beym", "t\u00e4g\u00b7li\u00b7chen", "Spat\u00b7zie\u00b7ren\u00b7gehn"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Hab\u2019 ich, GOtt Lob! da\u00df Er mirs wollen g\u00f6nnen,", "tokens": ["Hab'", "ich", ",", "Gott", "Lob", "!", "da\u00df", "Er", "mirs", "wol\u00b7len", "g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "NN", "NN", "$.", "KOUS", "PPER", "NE", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und auch in dieser Frucht mir so viel Guts erwiesen,", "tokens": ["Und", "auch", "in", "die\u00b7ser", "Frucht", "mir", "so", "viel", "Guts", "er\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PDAT", "NN", "PPER", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Sch\u00f6pfer wenigstens in meiner Lust gepriesen.", "tokens": ["Den", "Sch\u00f6p\u00b7fer", "we\u00b7nigs\u00b7tens", "in", "mei\u00b7ner", "Lust", "ge\u00b7prie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich dank\u2019 Jhm auch annoch in dieser Stunde,", "tokens": ["Ich", "dank'", "Jhm", "auch", "an\u00b7noch", "in", "die\u00b7ser", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Mit froher Feder, Herz und Munde,", "tokens": ["Mit", "fro\u00b7her", "Fe\u00b7der", ",", "Herz", "und", "Mun\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Erkenne, da\u00df von Jhm allein", "tokens": ["Er\u00b7ken\u00b7ne", ",", "da\u00df", "von", "Jhm", "al\u00b7lein"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "APPR", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wir auf der Welt gesegnet seyn!", "tokens": ["Wir", "auf", "der", "Welt", "ge\u00b7seg\u00b7net", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ich w\u00fcnsche, da\u00df Er diesen Segen", "tokens": ["Ich", "w\u00fcn\u00b7sche", ",", "da\u00df", "Er", "die\u00b7sen", "Se\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Zu rechter Zeit la\u00df in die Scheuren legen,", "tokens": ["Zu", "rech\u00b7ter", "Zeit", "la\u00df", "in", "die", "Scheu\u00b7ren", "le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Und da\u00df wir Jhn auch denn von Herzen preisen m\u00f6gen!", "tokens": ["Und", "da\u00df", "wir", "Jhn", "auch", "denn", "von", "Her\u00b7zen", "prei\u00b7sen", "m\u00f6\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "ADV", "ADV", "APPR", "NN", "VVFIN", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}