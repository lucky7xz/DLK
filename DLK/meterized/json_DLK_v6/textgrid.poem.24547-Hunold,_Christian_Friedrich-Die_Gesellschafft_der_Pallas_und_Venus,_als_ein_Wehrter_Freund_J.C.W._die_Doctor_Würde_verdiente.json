{"textgrid.poem.24547": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Die Gesellschafft der Pallas und Venus, als ein Wehrter Freund/ J.C.W. die Doctor W\u00fcrde verdiente", "genre": "verse", "period": "N.A.", "pub_year": 1701, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Und deinem Wesen sich nicht wenig eingepr\u00e4gt/", "tokens": ["Und", "dei\u00b7nem", "We\u00b7sen", "sich", "nicht", "we\u00b7nig", "ein\u00b7ge\u00b7pr\u00e4gt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PRF", "PTKNEG", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "War dir von Jugend auf/ Geehrter Freund/ gewogen.", "tokens": ["War", "dir", "von", "Ju\u00b7gend", "auf", "/", "Ge\u00b7ehr\u00b7ter", "Freund", "/", "ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "APPR", "$(", "ADJA", "NN", "$(", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Verg\u00f6nne da\u00df mein Kiel der ", "tokens": ["Ver\u00b7g\u00f6n\u00b7ne", "da\u00df", "mein", "Kiel", "der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "KOUS", "PPOSAT", "NN", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sie hat dich erst belebt/ denn auch beliebt gemacht/", "tokens": ["Sie", "hat", "dich", "erst", "be\u00b7lebt", "/", "denn", "auch", "be\u00b7liebt", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$(", "KON", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Von edler Liebe wird die gantze Welt gezogen.", "tokens": ["Von", "ed\u00b7ler", "Lie\u00b7be", "wird", "die", "gant\u00b7ze", "Welt", "ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Die sich auf ein Gem\u00fcth/ das edel ist erstreckt/", "tokens": ["Die", "sich", "auf", "ein", "Ge\u00b7m\u00fcth", "/", "das", "e\u00b7del", "ist", "er\u00b7streckt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "ART", "NN", "$(", "ART", "ADJD", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die muntre Geister sucht und Feuer kan vertragen/", "tokens": ["Die", "mun\u00b7tre", "Geis\u00b7ter", "sucht", "und", "Feu\u00b7er", "kan", "ver\u00b7tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "KON", "NN", "VMFIN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gewann dich gleichfals lieb und hob den blinden Wahn/", "tokens": ["Ge\u00b7wann", "dich", "gleich\u00b7fals", "lieb", "und", "hob", "den", "blin\u00b7den", "Wahn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADJD", "KON", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nach welchem ", "tokens": ["Nach", "wel\u00b7chem"], "token_info": ["word", "word"], "pos": ["APPR", "PWAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Und Lieb und Wei\u00dfheit sich zusammen m\u00fc\u00dfen schlagen.", "tokens": ["Und", "Lieb", "und", "Wei\u00df\u00b7heit", "sich", "zu\u00b7sam\u00b7men", "m\u00fc\u00b7\u00dfen", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "PRF", "VVINF", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "In diesen Angeln ruht die klein und gro\u00dfe Welt.", "tokens": ["In", "die\u00b7sen", "An\u00b7geln", "ruht", "die", "klein", "und", "gro\u00b7\u00dfe", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "ART", "ADJD", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Drum hatte dir das Gl\u00fcck zwey Sterne zugesellt/", "tokens": ["Drum", "hat\u00b7te", "dir", "das", "Gl\u00fcck", "zwey", "Ster\u00b7ne", "zu\u00b7ge\u00b7sellt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ART", "NN", "CARD", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dadurch dein Lebenslauf beliebt und klug gewesen.", "tokens": ["Da\u00b7durch", "dein", "Le\u00b7bens\u00b7lauf", "be\u00b7liebt", "und", "klug", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "NN", "ADJD", "KON", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit deinen Jahren wuchs auch beyder Krafft in dir/", "tokens": ["Mit", "dei\u00b7nen", "Jah\u00b7ren", "wuchs", "auch", "bey\u00b7der", "Krafft", "in", "dir", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ADV", "PIAT", "NN", "APPR", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "In deiner Freundlichkeit that sich die ", "tokens": ["In", "dei\u00b7ner", "Freund\u00b7lich\u00b7keit", "that", "sich", "die"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PRF", "ART"], "meter": "-+-+-++--", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Aus allen \u00fcbrigen lie\u00df ", "tokens": ["Aus", "al\u00b7len", "\u00fcb\u00b7ri\u00b7gen", "lie\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "VVFIN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.4": {"line.1": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Hat \u00fcber dich geherrscht/ dadurch wir lernen sehn/", "tokens": ["Hat", "\u00fc\u00b7ber", "dich", "ge\u00b7herrscht", "/", "da\u00b7durch", "wir", "ler\u00b7nen", "sehn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "VVPP", "$(", "PAV", "PPER", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und Augen so vor uns/ als in die Welt bekommen/", "tokens": ["Und", "Au\u00b7gen", "so", "vor", "uns", "/", "als", "in", "die", "Welt", "be\u00b7kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "APPR", "PPER", "$(", "KOKOM", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hat/ weil Gelehrsamkeit/ die einsten recht besteht/", "tokens": ["Hat", "/", "weil", "Ge\u00b7lehr\u00b7sam\u00b7keit", "/", "die", "eins\u00b7ten", "recht", "be\u00b7steht", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$(", "KOUS", "NN", "$(", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mit ", "tokens": ["Mit"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Nach Holl- und Engeland den Lauf mit dir genommen.", "tokens": ["Nach", "Holl", "und", "En\u00b7ge\u00b7land", "den", "Lauf", "mit", "dir", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "TRUNC", "KON", "NN", "ART", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Die Liebe bothe sich zu der Gef\u00e4hrtin an.", "tokens": ["Die", "Lie\u00b7be", "bo\u00b7the", "sich", "zu", "der", "Ge\u00b7f\u00e4hr\u00b7tin", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Die Wei\u00dfheit/ welcher sie bi\u00dfhero nichts gethan/", "tokens": ["Die", "Wei\u00df\u00b7heit", "/", "wel\u00b7cher", "sie", "bi\u00df\u00b7he\u00b7ro", "nichts", "ge\u00b7than", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "ADV", "PIS", "VVPP", "$("], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Als was ihr mehren Glantz und Anmuth hat gegeben/", "tokens": ["Als", "was", "ihr", "meh\u00b7ren", "Glantz", "und", "An\u00b7muth", "hat", "ge\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWS", "PPER", "PIAT", "NN", "KON", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sprach: komme: nimt man mich nicht aller Orten ein/", "tokens": ["Sprach", ":", "kom\u00b7me", ":", "nimt", "man", "mich", "nicht", "al\u00b7ler", "Or\u00b7ten", "ein", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVFIN", "$.", "VVFIN", "PIS", "PRF", "PTKNEG", "PIAT", "NN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So ist der Wandersmann doch hold und freundlich seyn/", "tokens": ["So", "ist", "der", "Wan\u00b7ders\u00b7mann", "doch", "hold", "und", "freund\u00b7lich", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "ADJD", "KON", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der in der ferne kan/ als wie zu Hause leben.", "tokens": ["Der", "in", "der", "fer\u00b7ne", "kan", "/", "als", "wie", "zu", "Hau\u00b7se", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "VMFIN", "$(", "KOUS", "KOKOM", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Du hast den Wander-Stab/ der Reisende ergetzt/", "tokens": ["Du", "hast", "den", "Wan\u00b7der\u00b7Stab", "/", "der", "Rei\u00b7sen\u00b7de", "er\u00b7getzt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$(", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "An manche sch\u00f6ne Th\u00fcr in Engeland gesetzt;", "tokens": ["An", "man\u00b7che", "sch\u00f6\u00b7ne", "Th\u00fcr", "in", "En\u00b7ge\u00b7land", "ge\u00b7setzt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die H\u00f6flichkeit macht auch gelehrte Zimmer offen.", "tokens": ["Die", "H\u00f6f\u00b7lich\u00b7keit", "macht", "auch", "ge\u00b7lehr\u00b7te", "Zim\u00b7mer", "of\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Was Londen treffliches/ Oxfurt gelehrtes zeigt/", "tokens": ["Was", "Lon\u00b7den", "treff\u00b7li\u00b7ches", "/", "Ox\u00b7furt", "ge\u00b7lehr\u00b7tes", "zeigt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "ADJA", "$(", "NE", "ADJA", "VVFIN", "$("], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Wornach der muntre Flei\u00df in Leiden/ Utrecht steigt/", "tokens": ["Wor\u00b7nach", "der", "mun\u00b7tre", "Flei\u00df", "in", "Lei\u00b7den", "/", "Ut\u00b7recht", "steigt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "APPR", "NN", "$(", "NE", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Vergn\u00fcgt und zierte dich/ wie du es kontest hoffen.", "tokens": ["Ver\u00b7gn\u00fcgt", "und", "zier\u00b7te", "dich", "/", "wie", "du", "es", "kon\u00b7test", "hof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "PPER", "$(", "PWAV", "PPER", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Ob sich nun Engeland/ der ", "tokens": ["Ob", "sich", "nun", "En\u00b7ge\u00b7land", "/", "der"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PRF", "ADV", "NE", "$(", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mit seiner Sch\u00f6nheit dir besonders aufgethan/", "tokens": ["Mit", "sei\u00b7ner", "Sch\u00f6n\u00b7heit", "dir", "be\u00b7son\u00b7ders", "auf\u00b7ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und der Gedancken Schiff die Temse noch durchf\u00e4hret/", "tokens": ["Und", "der", "Ge\u00b7dan\u00b7cken", "Schiff", "die", "Tem\u00b7se", "noch", "durch\u00b7f\u00e4h\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "ART", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sey/ sag ich/ oder nicht. Di\u00df aber bleibt dein Ruhm:", "tokens": ["Sey", "/", "sag", "ich", "/", "o\u00b7der", "nicht", ".", "Di\u00df", "a\u00b7ber", "bleibt", "dein", "Ruhm", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$(", "VVIMP", "PPER", "$(", "KON", "PTKNEG", "$.", "PDS", "ADV", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du woltest niemahls nicht in ", "tokens": ["Du", "wol\u00b7test", "nie\u00b7mahls", "nicht", "in"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "PTKNEG", "APPR"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Di\u00df ", "tokens": ["Di\u00df"], "token_info": ["word"], "pos": ["PDS"], "meter": "+", "measure": "single.up"}}, "stanza.8": {"line.1": {"text": "Heut ist dein Ehren-Tag: der andre wird bald seyn.", "tokens": ["Heut", "ist", "dein", "Eh\u00b7ren\u00b7Tag", ":", "der", "and\u00b7re", "wird", "bald", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "$.", "ART", "PIS", "VAFIN", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Auf dem ", "tokens": ["Auf", "dem"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Hoch-Edler/ wenn es kommt/ so w\u00fcnsch ich tausend Gl\u00fcck.", "tokens": ["Hoch\u00b7Ed\u00b7ler", "/", "wenn", "es", "kommt", "/", "so", "w\u00fcnsch", "ich", "tau\u00b7send", "Gl\u00fcck", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "KOUS", "PPER", "VVFIN", "$(", "ADV", "ADJD", "PPER", "CARD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "In jenem Stande denck an di\u00df ", "tokens": ["In", "je\u00b7nem", "Stan\u00b7de", "denck", "an", "di\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVIMP", "APPR", "PDS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dein Wohlseyn m\u00fcsse so/ als wie dein Ruhm bestehen.", "tokens": ["Dein", "Wohl\u00b7seyn", "m\u00fcs\u00b7se", "so", "/", "als", "wie", "dein", "Ruhm", "be\u00b7ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "ADV", "$(", "KOUS", "KOKOM", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}