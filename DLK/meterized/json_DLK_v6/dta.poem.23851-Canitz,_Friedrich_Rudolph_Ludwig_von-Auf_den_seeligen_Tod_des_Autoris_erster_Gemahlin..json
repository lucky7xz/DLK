{"dta.poem.23851": {"metadata": {"author": {"name": "Canitz, Friedrich Rudolph Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "Auf den seeligen Tod des Autoris  \n erster Gemahlin.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1700", "urn": "urn:nbn:de:kobv:b4-200905197532", "language": ["de:0.99"], "booktitle": "[Canitz, Friedrich Rudolph Ludwig von]: Neben-Stunden Unterschiedener Gedichte. [Hrsg. v. Joachim Lange]. Berlin, 1700."}, "poem": {"stanza.1": {"line.1": {"text": "Sol ich meine Doris missen?", "tokens": ["Sol", "ich", "mei\u00b7ne", "Do\u00b7ris", "mis\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPOSAT", "NE", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat Sie mir der Tod entrissen?", "tokens": ["Hat", "Sie", "mir", "der", "Tod", "ent\u00b7ris\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Oder bringt die Phantasey", "tokens": ["O\u00b7der", "bringt", "die", "Phan\u00b7ta\u00b7sey"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mir vielleicht ein Schrecken bey?", "tokens": ["Mir", "viel\u00b7leicht", "ein", "Schre\u00b7cken", "bey", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Lebt Sie? Nein Sie ist verschwunden;", "tokens": ["Lebt", "Sie", "?", "Nein", "Sie", "ist", "ver\u00b7schwun\u00b7den", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PTKANT", "PPER", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Meine Doris deckt ein Grab;", "tokens": ["Mei\u00b7ne", "Do\u00b7ris", "deckt", "ein", "Grab", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Schneid/ Verh\u00e4ngni\u00df meinen Stunden", "tokens": ["Schneid", "/", "Ver\u00b7h\u00e4ng\u00b7ni\u00df", "mei\u00b7nen", "Stun\u00b7den"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$(", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Unges\u00e4umt den Faden ab!", "tokens": ["Un\u00b7ge\u00b7s\u00e4umt", "den", "Fa\u00b7den", "ab", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Solt\u2019 ich dich noch \u00fcberleben/", "tokens": ["Solt'", "ich", "dich", "noch", "\u00fc\u00b7berl\u00b7e\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der ich mehr als mir ergeben/", "tokens": ["Der", "ich", "mehr", "als", "mir", "er\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "KOUS", "PPER", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die ich in mein Hertz gedr\u00fcckt;", "tokens": ["Die", "ich", "in", "mein", "Hertz", "ge\u00b7dr\u00fcckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dich/ die du mich so begl\u00fcckt/", "tokens": ["Dich", "/", "die", "du", "mich", "so", "be\u00b7gl\u00fcckt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "PRELS", "PPER", "PRF", "ADV", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df die Welt mit Cron und Reichen", "tokens": ["Da\u00df", "die", "Welt", "mit", "Cron", "und", "Rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mich zu keinem Neid gebracht/", "tokens": ["Mich", "zu", "kei\u00b7nem", "Neid", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIAT", "NN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Weil ich sie/ dir zu vergleichen/", "tokens": ["Weil", "ich", "sie", "/", "dir", "zu", "ver\u00b7glei\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "$(", "PPER", "PTKZU", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Niemahls gro\u00df genug geacht?", "tokens": ["Nie\u00b7mahls", "gro\u00df", "ge\u00b7nug", "ge\u00b7acht", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Doris kanst du mich betr\u00fcben?", "tokens": ["Do\u00b7ris", "kanst", "du", "mich", "be\u00b7tr\u00fc\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo ist deine Treu geblieben/", "tokens": ["Wo", "ist", "dei\u00b7ne", "Treu", "ge\u00b7blie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPOSAT", "NN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die an meiner Lust und Graam", "tokens": ["Die", "an", "mei\u00b7ner", "Lust", "und", "Graam"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PPOSAT", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Immer gleichen Antheil nahm?", "tokens": ["Im\u00b7mer", "glei\u00b7chen", "An\u00b7theil", "nahm", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Du eylst zur bestirnten Strassen/", "tokens": ["Du", "eylst", "zur", "bes\u00b7tirn\u00b7ten", "Stras\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und hast nun zum ersten mahl", "tokens": ["Und", "hast", "nun", "zum", "ers\u00b7ten", "mahl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Mich und unsern Bund verlassen;", "tokens": ["Mich", "und", "un\u00b7sern", "Bund", "ver\u00b7las\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Deine Wonne schafft mir Quaal!", "tokens": ["Dei\u00b7ne", "Won\u00b7ne", "schafft", "mir", "Qua\u00b7al", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Was f\u00fcr ", "tokens": ["Was", "f\u00fcr"], "token_info": ["word", "word"], "pos": ["PWS", "APPR"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Schlagen \u00fcber mich zusammen!", "tokens": ["Schla\u00b7gen", "\u00fc\u00b7ber", "mich", "zu\u00b7sam\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Unaussprechlicher Verlust/", "tokens": ["Un\u00b7aus\u00b7sprech\u00b7li\u00b7cher", "Ver\u00b7lust", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie beklemmst du meine Brust!", "tokens": ["Wie", "be\u00b7klemmst", "du", "mei\u00b7ne", "Brust", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und wie kom\u0303ts? da ich mich kr\u00e4ncke/", "tokens": ["Und", "wie", "kom\u0303ts", "?", "da", "ich", "mich", "kr\u00e4n\u00b7cke", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "$.", "KOUS", "PPER", "PRF", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Werd ich gleichsam wie ergetzt/", "tokens": ["Werd", "ich", "gleich\u00b7sam", "wie", "er\u00b7getzt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "KOKOM", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Wenn ich nur an die gedencke/", "tokens": ["Wenn", "ich", "nur", "an", "die", "ge\u00b7den\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.8": {"text": "Die mich in das Leid gesetzt.", "tokens": ["Die", "mich", "in", "das", "Leid", "ge\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "M\u00f6chte mir ein Lied gelingen/", "tokens": ["M\u00f6ch\u00b7te", "mir", "ein", "Lied", "ge\u00b7lin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sie nach W\u00fcrden zu besingen!", "tokens": ["Sie", "nach", "W\u00fcr\u00b7den", "zu", "be\u00b7sin\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch ein untermengtes Ach", "tokens": ["Doch", "ein", "un\u00b7ter\u00b7meng\u00b7tes", "Ach"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Macht mir Hand und Stimme schwach;", "tokens": ["Macht", "mir", "Hand", "und", "Stim\u00b7me", "schwach", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Worte werden mir zu Thr\u00e4nen/", "tokens": ["Wor\u00b7te", "wer\u00b7den", "mir", "zu", "Thr\u00e4\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "APPR", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und so mu\u00df ich mir allein/", "tokens": ["Und", "so", "mu\u00df", "ich", "mir", "al\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "PPER", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "In dem allergr\u00f6\u00dften Sehnen/", "tokens": ["In", "dem", "al\u00b7ler\u00b7gr\u00f6\u00df\u00b7ten", "Seh\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Der betr\u00fcbte Zeuge seyn.", "tokens": ["Der", "be\u00b7tr\u00fcb\u00b7te", "Zeu\u00b7ge", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Ihr die ihr mit Schrifft und Tichten", "tokens": ["Ihr", "die", "ihr", "mit", "Schrifft", "und", "Tich\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "PRELS", "PPER", "APPR", "NN", "KON", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "K\u00f6nnt die Sterblichkeit vernichten/", "tokens": ["K\u00f6nnt", "die", "Sterb\u00b7lich\u00b7keit", "ver\u00b7nich\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Singt die Angst die mich verzehrt/", "tokens": ["Singt", "die", "Angst", "die", "mich", "ver\u00b7zehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "PPER", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und der Doris ihren Werth;", "tokens": ["Und", "der", "Do\u00b7ris", "ih\u00b7ren", "Werth", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NE", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df man sie nach langen Jahren", "tokens": ["Da\u00df", "man", "sie", "nach", "lan\u00b7gen", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mag bedauren/ und auch mich;", "tokens": ["Mag", "be\u00b7dau\u00b7ren", "/", "und", "auch", "mich", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$(", "KON", "ADV", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Doch ihr k\u00f6nnt die Arbeit spahren;", "tokens": ["Doch", "ihr", "k\u00f6nnt", "die", "Ar\u00b7beit", "spah\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Wer kennt beydes so wie ich?", "tokens": ["Wer", "kennt", "bey\u00b7des", "so", "wie", "ich", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "ADV", "KOKOM", "PPER", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Ihrer edlen Seelen Gaben", "tokens": ["Ih\u00b7rer", "ed\u00b7len", "See\u00b7len", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hielt sie zwar nicht als vergraben;", "tokens": ["Hielt", "sie", "zwar", "nicht", "als", "ver\u00b7gra\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "KOKOM", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nein/ sie waren Stadt und Land", "tokens": ["Nein", "/", "sie", "wa\u00b7ren", "Stadt", "und", "Land"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$(", "PPER", "VAFIN", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Meistens/ mir doch mehr bekandt.", "tokens": ["Meis\u00b7tens", "/", "mir", "doch", "mehr", "be\u00b7kandt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PPER", "ADV", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Manches Weib wird hoch gepriesen/", "tokens": ["Man\u00b7ches", "Weib", "wird", "hoch", "ge\u00b7prie\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "ADJD", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Das kaum so viel Tugend zehlt/", "tokens": ["Das", "kaum", "so", "viel", "Tu\u00b7gend", "zehlt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "PIAT", "NN", "VVFIN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Als die Seligste vor diesen", "tokens": ["Als", "die", "Se\u00b7ligs\u00b7te", "vor", "die\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "PDAT"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.8": {"text": "Aus Bescheidenheit verhehlt.", "tokens": ["Aus", "Be\u00b7schei\u00b7den\u00b7heit", "ver\u00b7hehlt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Da\u00df sie wol mit GOtt gestanden/", "tokens": ["Da\u00df", "sie", "wol", "mit", "Gott", "ge\u00b7stan\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sieht man/ da sie von den Banden", "tokens": ["Sieht", "man", "/", "da", "sie", "von", "den", "Ban\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "$(", "KOUS", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieses Lebens wird befreyt;", "tokens": ["Die\u00b7ses", "Le\u00b7bens", "wird", "be\u00b7freyt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Seht wie Sie der Tod bedr\u00e4ut/", "tokens": ["Seht", "wie", "Sie", "der", "Tod", "be\u00b7dr\u00e4ut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Aber selbst beginnt zu zittern!", "tokens": ["A\u00b7ber", "selbst", "be\u00b7ginnt", "zu", "zit\u00b7tern", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Denn sie zeigt ihm l\u00e4chlend an/", "tokens": ["Denn", "sie", "zeigt", "ihm", "l\u00e4ch\u00b7lend", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADJD", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df/ der die Natur ersch\u00fcttern/", "tokens": ["Da\u00df", "/", "der", "die", "Na\u00b7tur", "er\u00b7sch\u00fct\u00b7tern", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "ART", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Ihren Schlaaf kaum hindern kan.", "tokens": ["Ih\u00b7ren", "Schlaaf", "kaum", "hin\u00b7dern", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "In dem eiteln Welt-Gedrenge/", "tokens": ["In", "dem", "ei\u00b7teln", "Welt\u00b7Ged\u00b7ren\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$("], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.2": {"text": "Ward sie von der grossen Menge/", "tokens": ["Ward", "sie", "von", "der", "gros\u00b7sen", "Men\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die man allenthalben sp\u00fchrt/", "tokens": ["Die", "man", "al\u00b7len\u00b7thal\u00b7ben", "sp\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Der Verf\u00fchrten nicht verf\u00fchrt.", "tokens": ["Der", "Ver\u00b7f\u00fchr\u00b7ten", "nicht", "ver\u00b7f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Riemahls hatte sie erkohren", "tokens": ["Rie\u00b7mahls", "hat\u00b7te", "sie", "er\u00b7koh\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VAFIN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Einen Gifft der Zucker hie\u00df/", "tokens": ["Ei\u00b7nen", "Gifft", "der", "Zu\u00b7cker", "hie\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Weil ihr etwas angebohren/", "tokens": ["Weil", "ihr", "et\u00b7was", "an\u00b7ge\u00b7boh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Das so fort die Probe wie\u00df.", "tokens": ["Das", "so", "fort", "die", "Pro\u00b7be", "wie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PTKVZ", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Doch/ in Worten und in Wercken/", "tokens": ["Doch", "/", "in", "Wor\u00b7ten", "und", "in", "Wer\u00b7cken", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "APPR", "NN", "KON", "APPR", "NN", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Lie\u00df sie einen Umgang mercken/", "tokens": ["Lie\u00df", "sie", "ei\u00b7nen", "Um\u00b7gang", "mer\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der nicht fremdes Thun verh\u00f6nt/", "tokens": ["Der", "nicht", "frem\u00b7des", "Thun", "ver\u00b7h\u00f6nt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADJA", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und das Seinige besch\u00f6nt.", "tokens": ["Und", "das", "Sei\u00b7ni\u00b7ge", "be\u00b7sch\u00f6nt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPOSS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Was f\u00fcr kluge Tugend-S\u00e4tze", "tokens": ["Was", "f\u00fcr", "klu\u00b7ge", "Tu\u00b7gen\u00b7dS\u00e4t\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Macht indessen nicht ihr Mund/", "tokens": ["Macht", "in\u00b7des\u00b7sen", "nicht", "ihr", "Mund", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKNEG", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und f\u00fcr ungemeine Sch\u00e4tze", "tokens": ["Und", "f\u00fcr", "un\u00b7ge\u00b7mei\u00b7ne", "Sch\u00e4t\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Noch vielmehr ihr Wandel kund!", "tokens": ["Noch", "viel\u00b7mehr", "ihr", "Wan\u00b7del", "kund", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "G\u00fctig jederman begegnen/", "tokens": ["G\u00fc\u00b7tig", "je\u00b7der\u00b7man", "be\u00b7geg\u00b7nen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PIS", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lieb und Wolthat lassen regnen/", "tokens": ["Lieb", "und", "Wolt\u00b7hat", "las\u00b7sen", "reg\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Das war Ihre beste Kunst;", "tokens": ["Das", "war", "Ih\u00b7re", "bes\u00b7te", "Kunst", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Auch der h\u00f6chsten H\u00e4upter Gunst/", "tokens": ["Auch", "der", "h\u00f6chs\u00b7ten", "H\u00e4up\u00b7ter", "Gunst", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und ihr innerstes Vertrauen/", "tokens": ["Und", "ihr", "in\u00b7ners\u00b7tes", "Ver\u00b7trau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Hat Sie nie zum Stoltz bewegt.", "tokens": ["Hat", "Sie", "nie", "zum", "Stoltz", "be\u00b7wegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Wir/ und das worauf wir bauen/", "tokens": ["Wir", "/", "und", "das", "wo\u00b7rauf", "wir", "bau\u00b7en", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "KON", "ART", "PWAV", "PPER", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Sprach Sie/ wird in Staub gelegt.", "tokens": ["Sprach", "Sie", "/", "wird", "in", "Staub", "ge\u00b7legt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$(", "VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Durch verstelletes Beginnen", "tokens": ["Durch", "ver\u00b7stel\u00b7le\u00b7tes", "Be\u00b7gin\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fremden Beyfall zu ", "tokens": ["Frem\u00b7den", "Bey\u00b7fall", "zu"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "PTKZU"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "War ein zu ver\u00e4chtlich Spiel/", "tokens": ["War", "ein", "zu", "ver\u00b7\u00e4cht\u00b7lich", "Spiel", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "PTKA", "ADJD", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Das Ihr niemahls wolgefiel;", "tokens": ["Das", "Ihr", "nie\u00b7mahls", "wol\u00b7ge\u00b7fiel", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und was hatte Sies vonn\u00f6then?", "tokens": ["Und", "was", "hat\u00b7te", "Sies", "von\u00b7n\u00f6\u00b7then", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ihre Stirn die nie betrog/", "tokens": ["Ih\u00b7re", "Stirn", "die", "nie", "be\u00b7trog", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "ADV", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Machte so den Neid err\u00f6then/", "tokens": ["Mach\u00b7te", "so", "den", "Neid", "er\u00b7r\u00f6\u00b7then", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Als Sie Hertzen an sich zog.", "tokens": ["Als", "Sie", "Hert\u00b7zen", "an", "sich", "zog", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Von der Anmuht ihrer Sitten", "tokens": ["Von", "der", "An\u00b7muht", "ih\u00b7rer", "Sit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fand ich mich schon l\u00e4ngst bestritten/", "tokens": ["Fand", "ich", "mich", "schon", "l\u00e4ngst", "be\u00b7strit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "ADV", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch in unserm Ehestand", "tokens": ["Doch", "in", "un\u00b7serm", "E\u00b7hes\u00b7tand"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ward ich hefftiger entbrandt/", "tokens": ["Ward", "ich", "heff\u00b7ti\u00b7ger", "ent\u00b7brandt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Weil ich so ein Hertz erlesen/", "tokens": ["Weil", "ich", "so", "ein", "Hertz", "er\u00b7le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Das/ wenn Ungl\u00fcck auf uns stie\u00df/", "tokens": ["Das", "/", "wenn", "Un\u00b7gl\u00fcck", "auf", "uns", "stie\u00df", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "KOUS", "NN", "APPR", "PPER", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Eben so ein sanfftes Wesen/", "tokens": ["E\u00b7ben", "so", "ein", "sanff\u00b7tes", "We\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Als im Gl\u00fccke sp\u00fcren lie\u00df.", "tokens": ["Als", "im", "Gl\u00fc\u00b7cke", "sp\u00fc\u00b7ren", "lie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPRART", "NN", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Bey der liebsten Kinder Leichen", "tokens": ["Bey", "der", "liebs\u00b7ten", "Kin\u00b7der", "Lei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gab Sie kein verzagtes Zeichen/", "tokens": ["Gab", "Sie", "kein", "ver\u00b7zag\u00b7tes", "Zei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hof und Hau\u00df vergieng in Gluth/", "tokens": ["Hof", "und", "Hau\u00df", "ver\u00b7gieng", "in", "Gluth", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VVFIN", "APPR", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber nicht Ihr Helden-Muth;", "tokens": ["A\u00b7ber", "nicht", "Ihr", "Hel\u00b7den\u00b7Muth", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Regung/ Sinn und Wunsch zubrechen", "tokens": ["Re\u00b7gung", "/", "Sinn", "und", "Wunsch", "zu\u00b7bre\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$(", "NN", "KON", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nach des weisen Sch\u00f6pffers Raht/", "tokens": ["Nach", "des", "wei\u00b7sen", "Sch\u00f6pf\u00b7fers", "Raht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und mir tr\u00f6ftlich zuzusprechen/", "tokens": ["Und", "mir", "tr\u00f6ft\u00b7lich", "zu\u00b7zu\u00b7spre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJD", "VVIZU", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Das war alles was Sie that.", "tokens": ["Das", "war", "al\u00b7les", "was", "Sie", "that", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIS", "PWS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Mit was lieblichem Bezeigen", "tokens": ["Mit", "was", "lieb\u00b7li\u00b7chem", "Be\u00b7zei\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PRELS", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gab Sie sich mir gantz zu eigen!", "tokens": ["Gab", "Sie", "sich", "mir", "gantz", "zu", "ei\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "PPER", "ADV", "PTKA", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wie sehr war Sie bem\u00fcht/", "tokens": ["Und", "wie", "sehr", "war", "Sie", "be\u00b7m\u00fcht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "VAFIN", "PPER", "VVFIN", "$("], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Bi\u00df Sie meine Neigung rieth;", "tokens": ["Bi\u00df", "Sie", "mei\u00b7ne", "Nei\u00b7gung", "rieth", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Alles das hab ich verlohren!", "tokens": ["Al\u00b7les", "das", "hab", "ich", "ver\u00b7loh\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PDS", "VAFIN", "PPER", "VVPP", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.6": {"text": "Ach wie werd ich Traurens voll!", "tokens": ["Ach", "wie", "werd", "ich", "Trau\u00b7rens", "voll", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "VAFIN", "PPER", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Hat mein Unstern sich verschworen/", "tokens": ["Hat", "mein", "Uns\u00b7tern", "sich", "ver\u00b7schwo\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "PRF", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Da\u00df ich sterbend leben foll?", "tokens": ["Da\u00df", "ich", "ster\u00b7bend", "le\u00b7ben", "foll", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Seldst das Pfand von unserm Lieben/", "tokens": ["Seldst", "das", "Pfand", "von", "un\u00b7serm", "Lie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "PPOSAT", "ADJA", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Das von Sieben \u00fcbrig blieben/", "tokens": ["Das", "von", "Sie\u00b7ben", "\u00fcb\u00b7rig", "blie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "NN", "ADJD", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn ichs in der Unschuld seh/", "tokens": ["Wenn", "ichs", "in", "der", "Un\u00b7schuld", "seh", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Machet mir ein neues Weh;", "tokens": ["Ma\u00b7chet", "mir", "ein", "neu\u00b7es", "Weh", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Weil sein aufgeweckt Gebl\u00fcte/", "tokens": ["Weil", "sein", "auf\u00b7ge\u00b7weckt", "Ge\u00b7bl\u00fc\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "VVPP", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Seiner Mutter frohen Geist/", "tokens": ["Sei\u00b7ner", "Mut\u00b7ter", "fro\u00b7hen", "Geist", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und sein unverf\u00e4lscht Gem\u00fcthe/", "tokens": ["Und", "sein", "un\u00b7ver\u00b7f\u00e4lscht", "Ge\u00b7m\u00fc\u00b7the", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJD", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Ihren wahren Abdruck weist.", "tokens": ["Ih\u00b7ren", "wah\u00b7ren", "Ab\u00b7druck", "weist", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}