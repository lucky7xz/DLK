{"textgrid.poem.60690": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ein Fuhrmann blieb mit seinem Wagen", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein Fuhrmann blieb mit seinem Wagen", "tokens": ["Ein", "Fuhr\u00b7mann", "blieb", "mit", "sei\u00b7nem", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Voll Heu im tiefen Schlamm des schlechten Weges stecken", "tokens": ["Voll", "Heu", "im", "tie\u00b7fen", "Schlamm", "des", "schlech\u00b7ten", "We\u00b7ges", "ste\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "NN", "APPRART", "ADJA", "NN", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wollte fast verzagen,", "tokens": ["Und", "woll\u00b7te", "fast", "ver\u00b7za\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da rings kein Helfer zu entdecken.", "tokens": ["Da", "rings", "kein", "Hel\u00b7fer", "zu", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Es war in der Bretagne Unterland", "tokens": ["Es", "war", "in", "der", "Bre\u00b7tag\u00b7ne", "Un\u00b7ter\u00b7land"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "In einem Strich, der Quimper-Corentin genannt,", "tokens": ["In", "ei\u00b7nem", "Strich", ",", "der", "Quim\u00b7per\u00b7Co\u00b7ren\u00b7tin", "ge\u00b7nannt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und jeder wei\u00df wohl gut,", "tokens": ["Und", "je\u00b7der", "wei\u00df", "wohl", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Da\u00df dorthin das Geschick", "tokens": ["Da\u00df", "dor\u00b7thin", "das", "Ge\u00b7schick"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Nur Leute schickt, um sie in Wut", "tokens": ["Nur", "Leu\u00b7te", "schickt", ",", "um", "sie", "in", "Wut"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "NN", "VVFIN", "$,", "KOUI", "PPER", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Zu bringen. Himmel, sch\u00fctze uns vor dieser Reise!", "tokens": ["Zu", "brin\u00b7gen", ".", "Him\u00b7mel", ",", "sch\u00fct\u00b7ze", "uns", "vor", "die\u00b7ser", "Rei\u00b7se", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$.", "NN", "$,", "VVFIN", "PPER", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Doch kommen wir auf unsern K\u00e4rrner nun zur\u00fcck.", "tokens": ["Doch", "kom\u00b7men", "wir", "auf", "un\u00b7sern", "K\u00e4rr\u00b7ner", "nun", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Er steht und schimpft und flucht so recht nach Fuhrmannsweise,", "tokens": ["Er", "steht", "und", "schimpft", "und", "flucht", "so", "recht", "nach", "Fuhr\u00b7manns\u00b7wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "ADV", "ADJD", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Verw\u00fcnscht das Loch, wo er hineingeraten,", "tokens": ["Ver\u00b7w\u00fcnscht", "das", "Loch", ",", "wo", "er", "hin\u00b7ein\u00b7ge\u00b7ra\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Den Wagen, seine Pferde und sich selbst sogar,", "tokens": ["Den", "Wa\u00b7gen", ",", "sei\u00b7ne", "Pfer\u00b7de", "und", "sich", "selbst", "so\u00b7gar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPOSAT", "NN", "KON", "PRF", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und schlie\u00dflich fleht er zu dem Gotte, dessen Taten", "tokens": ["Und", "schlie\u00df\u00b7lich", "fleht", "er", "zu", "dem", "Got\u00b7te", ",", "des\u00b7sen", "Ta\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PRELAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ber\u00fchmt sind auf dem weiten Erdenkreise.", "tokens": ["Be\u00b7r\u00fchmt", "sind", "auf", "dem", "wei\u00b7ten", "Er\u00b7den\u00b7krei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "\u00bbherkules,\u00ab ruft er, \u00bbist es wahr,", "tokens": ["\u00bb", "her\u00b7ku\u00b7les", ",", "\u00ab", "ruft", "er", ",", "\u00bb", "ist", "es", "wahr", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Da\u00df einst dein R\u00fccken", "tokens": ["Da\u00df", "einst", "dein", "R\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PPOSAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.19": {"text": "Die ganze Himmelsw\u00f6lbung trug,", "tokens": ["Die", "gan\u00b7ze", "Him\u00b7mels\u00b7w\u00f6l\u00b7bung", "trug", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "So wird es deinem kleinen Finger gl\u00fccken,", "tokens": ["So", "wird", "es", "dei\u00b7nem", "klei\u00b7nen", "Fin\u00b7ger", "gl\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Mich hier herauszuziehn mit einem Zug.\u00ab", "tokens": ["Mich", "hier", "her\u00b7aus\u00b7zu\u00b7ziehn", "mit", "ei\u00b7nem", "Zug", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Da t\u00f6nt es fern vom Himmel her:", "tokens": ["Da", "t\u00f6nt", "es", "fern", "vom", "Him\u00b7mel", "her", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "\u00bbherkules will, da\u00df man sich selber r\u00fchre,", "tokens": ["\u00bb", "her\u00b7ku\u00b7les", "will", ",", "da\u00df", "man", "sich", "sel\u00b7ber", "r\u00fch\u00b7re", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VMFIN", "$,", "KOUS", "PIS", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "Dann steht er bei. Sieh hin und sp\u00fcre", "tokens": ["Dann", "steht", "er", "bei", ".", "Sieh", "hin", "und", "sp\u00fc\u00b7re"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$.", "NE", "PTKVZ", "KON", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Dem Hemmnis nach, das dich gest\u00f6rt so sehr.", "tokens": ["Dem", "Hemm\u00b7nis", "nach", ",", "das", "dich", "ge\u00b7st\u00f6rt", "so", "sehr", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "PRELS", "PPER", "VVPP", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Entferne um die R\u00e4der doch den Lehm, der schwer", "tokens": ["Ent\u00b7fer\u00b7ne", "um", "die", "R\u00e4\u00b7der", "doch", "den", "Lehm", ",", "der", "schwer"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "ADV", "ART", "NN", "$,", "PRELS", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Die Speichen dr\u00fcckt. Zerhaue jetzt die Steine hier,", "tokens": ["Die", "Spei\u00b7chen", "dr\u00fcckt", ".", "Zer\u00b7hau\u00b7e", "jetzt", "die", "Stei\u00b7ne", "hier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "VVFIN", "ADV", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Die hindernd liegen in der Bahn.", "tokens": ["Die", "hin\u00b7dernd", "lie\u00b7gen", "in", "der", "Bahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVPP", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "\u00bbja,\u00ab sprach der Mann. \u2013 \u00bbNun gut, so helf ich weiter dir,\u00ab", "tokens": ["\u00bb", "ja", ",", "\u00ab", "sprach", "der", "Mann", ".", "\u2013", "\u00bb", "Nun", "gut", ",", "so", "helf", "ich", "wei\u00b7ter", "dir", ",", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKANT", "$,", "$(", "VVFIN", "ART", "NN", "$.", "$(", "$(", "ADV", "ADJD", "$,", "ADV", "VVFIN", "PPER", "ADV", "PPER", "$,", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Rief's droben her, \u00bbdie Peitsche jetzt!\u00ab \u2013 \u00bbDie haben wir.", "tokens": ["Rie\u00b7f's", "dro\u00b7ben", "her", ",", "\u00bb", "die", "Peit\u00b7sche", "jetzt", "!", "\u00ab", "\u2013", "\u00bb", "Die", "ha\u00b7ben", "wir", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PTKVZ", "$,", "$(", "ART", "NN", "ADV", "$.", "$(", "$(", "$(", "PDS", "VAFIN", "PPER", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.31": {"text": "Ja, was ist das? Schon sind wir flott!", "tokens": ["Ja", ",", "was", "ist", "das", "?", "Schon", "sind", "wir", "flott", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PWS", "VAFIN", "PDS", "$.", "ADV", "VAFIN", "PPER", "VVFIN", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.32": {"text": "Gelobt sei Herkules!\u00ab \u2013 Da t\u00f6nt's aus Wolkenpracht:", "tokens": ["Ge\u00b7lobt", "sei", "Her\u00b7ku\u00b7les", "!", "\u00ab", "\u2013", "Da", "t\u00f6nt's", "aus", "Wol\u00b7ken\u00b7pracht", ":"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "NE", "$.", "$(", "$(", "ADV", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.33": {"text": "\u00bbdu siehst, wie leicht die Pferde alles gutgemacht.\u00ab", "tokens": ["\u00bb", "du", "siehst", ",", "wie", "leicht", "die", "Pfer\u00b7de", "al\u00b7les", "gut\u00b7ge\u00b7macht", ".", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "PWAV", "ADJD", "ART", "NN", "PIS", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Hilf selber dir, so hilft dir Gott.", "tokens": ["Hilf", "sel\u00b7ber", "dir", ",", "so", "hilft", "dir", "Gott", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PPER", "$,", "ADV", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}