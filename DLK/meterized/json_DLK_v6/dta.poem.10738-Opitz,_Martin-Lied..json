{"dta.poem.10738": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "Lied.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1624", "urn": "urn:nbn:de:kobv:b4-200905197859", "language": ["de:0.99"], "booktitle": "Opitz, Martin: Teutsche P\u00f6emata und: Aristarchvs Wieder die verachtung Teutscher Sprach. Stra\u00dfburg, 1624."}, "poem": {"stanza.1": {"line.1": {"text": "Hin vnd wider/ auff vnd ab/", "tokens": ["Hin", "vnd", "wi\u00b7der", "/", "auff", "vnd", "ab", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "PTKVZ", "$(", "APPR", "KON", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Vil Land vnd Leut durchreisethab,", "tokens": ["Vil", "Land", "vnd", "Leut", "durc\u00b7hrei\u00b7set\u00b7hab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu bekommen Lehr\u2019 vnd Verstand/", "tokens": ["Zu", "be\u00b7kom\u00b7men", "Lehr'", "vnd", "Ver\u00b7stand", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "NN", "KON", "NN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Auch frembder zungen sprach.", "tokens": ["Auch", "fremb\u00b7der", "zun\u00b7gen", "sprach", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Gedultet hab manch vngemach:", "tokens": ["Ge\u00b7dul\u00b7tet", "hab", "manch", "vn\u00b7ge\u00b7mach", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vmbsonst ist vil vnkosten angewand:", "tokens": ["Vmbsonst", "ist", "vil", "vn\u00b7kos\u00b7ten", "an\u00b7ge\u00b7wand", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Gethan mirs wohl het\u2019s Vatterland.", "tokens": ["Ge\u00b7than", "mirs", "wohl", "het's", "Vat\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Zu was nutz mir solchs gelinget/", "tokens": ["Zu", "was", "nutz", "mir", "solchs", "ge\u00b7lin\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "NN", "PPER", "PIS", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Wans widerum das Gl\u00fcck mir nit reinbringet?", "tokens": ["Wans", "wi\u00b7de\u00b7rum", "das", "Gl\u00fcck", "mir", "nit", "rein\u00b7brin\u00b7get", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "TentischlandTeutschland (sags mit vergunst)", "tokens": ["Ten\u00b7tischland", "Teutschland", "(", "sags", "mit", "ver\u00b7gunst", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$(", "ADV", "APPR", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Begabet ist mit mancher Kunst/", "tokens": ["Be\u00b7ga\u00b7bet", "ist", "mit", "man\u00b7cher", "Kunst", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Derer sichs garnit schemen thar.", "tokens": ["De\u00b7rer", "sichs", "gar\u00b7nit", "sche\u00b7men", "thar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hoch schetzen wir frembd ding/", "tokens": ["Hoch", "schet\u00b7zen", "wir", "frembd", "ding", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "ADJD", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Vnd achten vnsers f\u00fcr gering:", "tokens": ["Vnd", "ach\u00b7ten", "vn\u00b7sers", "f\u00fcr", "ge\u00b7ring", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "APPR", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So doch das vnsrig andrer kunst vnd l\u00e4r", "tokens": ["So", "doch", "das", "vns\u00b7rig", "an\u00b7drer", "kunst", "vnd", "l\u00e4r"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "ADJD", "ADJA", "NN", "KON", "XY"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Weit vbertrifft/ wie offenb\u00e4r.", "tokens": ["Weit", "vber\u00b7trifft", "/", "wie", "of\u00b7fen\u00b7b\u00e4r", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "$(", "PWAV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Was bringts dan f\u00fcr nutz vnd frommen/", "tokens": ["Was", "bringts", "dan", "f\u00fcr", "nutz", "vnd", "from\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "APPR", "NN", "KON", "ADJA", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "Sch\u00e4tz suchen anderswo/ doch lehr heimkommen?", "tokens": ["Sch\u00e4tz", "su\u00b7chen", "an\u00b7ders\u00b7wo", "/", "doch", "lehr", "heim\u00b7kom\u00b7men", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "$(", "ADV", "ADV", "VVINF", "$."], "meter": "++-+-+-+-+-", "measure": "iambic.penta.spondeus"}}, "stanza.3": {"line.1": {"text": "Ihren sachen gibt ein schein/", "tokens": ["Ih\u00b7ren", "sa\u00b7chen", "gibt", "ein", "schein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "VVFIN", "ART", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd blendet eim die Augen fein", "tokens": ["Vnd", "blen\u00b7det", "eim", "die", "Au\u00b7gen", "fein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der geferbet au\u00dflendisch pracht.", "tokens": ["Der", "ge\u00b7fer\u00b7bet", "au\u00df\u00b7len\u00b7disch", "pracht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADJD", "VVFIN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Was witzig ist vnd klug/", "tokens": ["Was", "wit\u00b7zig", "ist", "vnd", "klug", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "KON", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Merckt bald den anstrich vnd betrug:", "tokens": ["Merckt", "bald", "den", "an\u00b7strich", "vnd", "be\u00b7trug", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der aber solchs hoch helt aus vnbedacht/", "tokens": ["Der", "a\u00b7ber", "solchs", "hoch", "helt", "aus", "vn\u00b7be\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIS", "ADJD", "VVFIN", "APPR", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Wird in beth\u00f6rung fluchs gebracht/", "tokens": ["Wird", "in", "be\u00b7th\u00f6\u00b7rung", "fluchs", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Was thuts helffen oder nutzen/", "tokens": ["Was", "thuts", "helf\u00b7fen", "o\u00b7der", "nut\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "VVINF", "KON", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Da nichts darhinder ist/ etwas aufmutzen?", "tokens": ["Da", "nichts", "dar\u00b7hin\u00b7der", "ist", "/", "et\u00b7was", "auf\u00b7mut\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PAV", "VAFIN", "$(", "PIS", "VVIZU", "$."], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "Gold nit alles ist/ was gleist;", "tokens": ["Gold", "nit", "al\u00b7les", "ist", "/", "was", "gleist", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "PIS", "VAFIN", "$(", "PWS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sch\u00f6n ist nit alles/ was geweist.", "tokens": ["Sch\u00f6n", "ist", "nit", "al\u00b7les", "/", "was", "ge\u00b7weist", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PTKNEG", "PIS", "$(", "PWS", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sich Glasur vergat Edlem stein:", "tokens": ["Sich", "Gla\u00b7sur", "ver\u00b7gat", "Ed\u00b7lem", "stein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "G\u00f6tzbild dem Menschen gleicht;", "tokens": ["G\u00f6tz\u00b7bild", "dem", "Men\u00b7schen", "gleicht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Meuskot im Pfeffer sich verschleiche:", "tokens": ["Meus\u00b7kot", "im", "Pfef\u00b7fer", "sich", "ver\u00b7schlei\u00b7che", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "K\u00f6stlich gekleidet ist nit allzeit rein;", "tokens": ["K\u00f6st\u00b7lich", "ge\u00b7klei\u00b7det", "ist", "nit", "all\u00b7zeit", "rein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "VAFIN", "PTKNEG", "ADV", "ADJD", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.7": {"text": "Boxh\u00f6rner seind kein Elfenbein.", "tokens": ["Box\u00b7h\u00f6r\u00b7ner", "seind", "kein", "El\u00b7fen\u00b7bein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wilst vil Land nun sein durchzogen?", "tokens": ["Wilst", "vil", "Land", "nun", "sein", "durch\u00b7zo\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "NN", "ADV", "VAINF", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "O wandrer/ sich da\u00df du nit werst betrogen.", "tokens": ["O", "wand\u00b7rer", "/", "sich", "da\u00df", "du", "nit", "werst", "be\u00b7tro\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$(", "PRF", "KOUS", "PPER", "PTKNEG", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}