{"textgrid.poem.63342": {"metadata": {"author": {"name": "Klabund", "birth": "N.A.", "death": "N.A."}, "title": "Russische Revolution", "genre": "verse", "period": "N.A.", "pub_year": 1909, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sind arm. Sind arm.", "tokens": ["Sind", "arm", ".", "Sind", "arm", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$.", "VAFIN", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Kommen von weit her.", "tokens": ["Kom\u00b7men", "von", "weit", "her", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJD", "PTKVZ", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Aus Vologda. Aus Tomsk.", "tokens": ["Aus", "Vo\u00b7log\u00b7da", ".", "Aus", "Tomsk", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "$.", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Aus tausend Orten,", "tokens": ["Aus", "tau\u00b7send", "Or\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Die keinen Namen haben.", "tokens": ["Die", "kei\u00b7nen", "Na\u00b7men", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Willst du an Gott glauben?", "tokens": ["Willst", "du", "an", "Gott", "glau\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Glaube an uns!", "tokens": ["Glau\u00b7be", "an", "uns", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Willst du fr\u00f6hlich sein?", "tokens": ["Willst", "du", "fr\u00f6h\u00b7lich", "sein", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "VAINF", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.9": {"text": "Sieh uns l\u00e4cheln!", "tokens": ["Sieh", "uns", "l\u00e4\u00b7cheln", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "PPER", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.10": {"text": "Wir tragen in unseren rissigen Bauern- Arbeiterf\u00e4usten", "tokens": ["Wir", "tra\u00b7gen", "in", "un\u00b7se\u00b7ren", "ris\u00b7si\u00b7gen", "Bau\u00b7ern", "Ar\u00b7bei\u00b7ter\u00b7f\u00e4us\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "ADJA", "TRUNC", "NN"], "meter": "-+--+--+--+--+-+-", "measure": "amphibrach.penta.plus"}, "line.11": {"text": "Wie eine Vase aus dem Petersburger exotischen Museum die Zukunft.", "tokens": ["Wie", "ei\u00b7ne", "Va\u00b7se", "aus", "dem", "Pe\u00b7ters\u00b7bur\u00b7ger", "e\u00b7xot\u00b7isc\u00b7hen", "Mu\u00b7se\u00b7um", "die", "Zu\u00b7kunft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "ADJA", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-+--+--+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.2": {"line.1": {"text": "Freundchen, was soll das?", "tokens": ["Freund\u00b7chen", ",", "was", "soll", "das", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "VMFIN", "PDS", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Einmal m\u00fcssen wir doch alle sterben.", "tokens": ["Ein\u00b7mal", "m\u00fcs\u00b7sen", "wir", "doch", "al\u00b7le", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PIS", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Reg dich nicht auf.", "tokens": ["Reg", "dich", "nicht", "auf", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKNEG", "PTKVZ", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Eine Kugel im Kopf ist immer noch besser", "tokens": ["Ei\u00b7ne", "Ku\u00b7gel", "im", "Kopf", "ist", "im\u00b7mer", "noch", "bes\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN", "VAFIN", "ADV", "ADV", "ADJD"], "meter": "+-+--+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Als ein Loch in der Hose.", "tokens": ["Als", "ein", "Loch", "in", "der", "Ho\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Wenn du mir hundert Kerenskirubel gibst,", "tokens": ["Wenn", "du", "mir", "hun\u00b7dert", "Ke\u00b7rens\u00b7ki\u00b7ru\u00b7bel", "gibst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "La\u00df ich deine Leiche", "tokens": ["La\u00df", "ich", "dei\u00b7ne", "Lei\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "An der Mauer f\u00fcr deine Braut photographieren.", "tokens": ["An", "der", "Mau\u00b7er", "f\u00fcr", "dei\u00b7ne", "Braut", "pho\u00b7to\u00b7gra\u00b7phie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Was meinst du?", "tokens": ["Was", "meinst", "du", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.3": {"line.1": {"text": "Ru\u00dfland ist gro\u00df. Ru\u00dfland ist gro\u00df.", "tokens": ["Ru\u00df\u00b7land", "ist", "gro\u00df", ".", "Ru\u00df\u00b7land", "ist", "gro\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJD", "$.", "NE", "VAFIN", "ADJD", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Die Sonne h\u00e4ngt hoch \u2013 gottverdammt \u2013", "tokens": ["Die", "Son\u00b7ne", "h\u00e4ngt", "hoch", "\u2013", "gott\u00b7ver\u00b7dammt", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$(", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer hat sie so hoch geh\u00e4ngt?", "tokens": ["Wer", "hat", "sie", "so", "hoch", "ge\u00b7h\u00e4ngt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "General Wrangel hat sie an den Galgen gebracht.", "tokens": ["Ge\u00b7ne\u00b7ral", "Wran\u00b7gel", "hat", "sie", "an", "den", "Gal\u00b7gen", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}, "stanza.4": {"line.1": {"text": "Jeden Morgen begegne ich dem gro\u00dfen General.", "tokens": ["Je\u00b7den", "Mor\u00b7gen", "be\u00b7geg\u00b7ne", "ich", "dem", "gro\u00b7\u00dfen", "Ge\u00b7ne\u00b7ral", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Er steht am Newski-Prospekt", "tokens": ["Er", "steht", "am", "New\u00b7ski\u00b7Pro\u00b7spekt"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Und verkauft die Prawda.", "tokens": ["Und", "ver\u00b7kauft", "die", "Praw\u00b7da", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "--+-+-", "measure": "anapaest.init"}, "line.4": {"text": "So hat er einmal uns alle verkauft:", "tokens": ["So", "hat", "er", "ein\u00b7mal", "uns", "al\u00b7le", "ver\u00b7kauft", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PPER", "PIS", "VVPP", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "An seine Auftraggeber.", "tokens": ["An", "sei\u00b7ne", "Auf\u00b7trag\u00b7ge\u00b7ber", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "General, Wei\u00dfbart, Wei\u00dfgardist:", "tokens": ["Ge\u00b7ne\u00b7ral", ",", "Wei\u00df\u00b7bart", ",", "Wei\u00df\u00b7gar\u00b7dist", ":"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Deine Arbeit ist keine Schande.", "tokens": ["Dei\u00b7ne", "Ar\u00b7beit", "ist", "kei\u00b7ne", "Schan\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PIAT", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Und du verdienst ", "tokens": ["Und", "du", "ver\u00b7dienst"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPER", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Wenn du Lenin sprichst,", "tokens": ["Wenn", "du", "Le\u00b7nin", "sprichst", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "VVFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Bl\u00fchen die Zahlen wie Blumen,", "tokens": ["Bl\u00fc\u00b7hen", "die", "Zah\u00b7len", "wie", "Blu\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "KOKOM", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Er hat eine Stierstirn, er rennt W\u00e4nde ein,", "tokens": ["Er", "hat", "ei\u00b7ne", "Stiers\u00b7tirn", ",", "er", "rennt", "W\u00e4n\u00b7de", "ein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PPER", "VVFIN", "NN", "PTKVZ", "$,"], "meter": "-+--+---+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Solche aus Papiermach\u00e9,", "tokens": ["Sol\u00b7che", "aus", "Pa\u00b7pier\u00b7mach\u00e9", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "APPR", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Solche aus Zeitungsballen,", "tokens": ["Sol\u00b7che", "aus", "Zei\u00b7tungs\u00b7bal\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "APPR", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.6": {"text": "Die dicksten L\u00fcgen der Welt,", "tokens": ["Die", "dicks\u00b7ten", "L\u00fc\u00b7gen", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Solche aus Steinquadern.", "tokens": ["Sol\u00b7che", "aus", "Stein\u00b7qua\u00b7dern", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "APPR", "NN", "$."], "meter": "+--++-", "measure": "dactylic.init"}, "line.8": {"text": "Seine Stirn ist ein Hammer.", "tokens": ["Sei\u00b7ne", "Stirn", "ist", "ein", "Ham\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.9": {"text": "Die Splitter stieben.", "tokens": ["Die", "Split\u00b7ter", "stie\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Manchmal in einsamen N\u00e4chten,", "tokens": ["Manch\u00b7mal", "in", "ein\u00b7sa\u00b7men", "N\u00e4ch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Wenn ein Schu\u00df t\u00f6nt,", "tokens": ["Wenn", "ein", "Schu\u00df", "t\u00f6nt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Wenn der Geb\u00e4rschrei einer Frau", "tokens": ["Wenn", "der", "Ge\u00b7b\u00e4rsc\u00b7hrei", "ei\u00b7ner", "Frau"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die dunklen Stra\u00dfen zerrei\u00dft:", "tokens": ["Die", "dunk\u00b7len", "Stra\u00b7\u00dfen", "zer\u00b7rei\u00dft", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Weine ich \u00fcber mich, \u00fcber mein Vaterland, die Welt.", "tokens": ["Wei\u00b7ne", "ich", "\u00fc\u00b7ber", "mich", ",", "\u00fc\u00b7ber", "mein", "Va\u00b7ter\u00b7land", ",", "die", "Welt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,", "ART", "NN", "$."], "meter": "+--+--+--+-+-+", "measure": "dactylic.tri.plus"}}, "stanza.7": {"line.1": {"text": "Im Anfang war das Wort,", "tokens": ["Im", "An\u00b7fang", "war", "das", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Das Wort war der Anfang.", "tokens": ["Das", "Wort", "war", "der", "An\u00b7fang", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Nunmehr hei\u00dft es: fortschreiten.", "tokens": ["Nun\u00b7mehr", "hei\u00dft", "es", ":", "fort\u00b7schrei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "VVFIN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Weitergehen! Nicht stehen bleiben! Circulez!", "tokens": ["Wei\u00b7ter\u00b7ge\u00b7hen", "!", "Nicht", "ste\u00b7hen", "blei\u00b7ben", "!", "Cir\u00b7cu\u00b7lez", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$.", "PTKNEG", "VVINF", "VVINF", "$.", "NE", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.5": {"text": "Wie die Clowns im Zirkus, so rufe ich euch zu:", "tokens": ["Wie", "die", "Clowns", "im", "Zir\u00b7kus", ",", "so", "ru\u00b7fe", "ich", "euch", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPRART", "NN", "$,", "ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Commencez! Travaillez!", "tokens": ["Com\u00b7men\u00b7cez", "!", "Tra\u00b7vail\u00b7lez", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$.", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.7": {"text": "In dem Willen liegt die Tat.", "tokens": ["In", "dem", "Wil\u00b7len", "liegt", "die", "Tat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Sie sei gro\u00df!", "tokens": ["Sie", "sei", "gro\u00df", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "So wird am Ende wieder das Wort sein,", "tokens": ["So", "wird", "am", "En\u00b7de", "wie\u00b7der", "das", "Wort", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPRART", "NN", "ADV", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Das gro\u00dfe Wort, das sie beschreibt.", "tokens": ["Das", "gro\u00b7\u00dfe", "Wort", ",", "das", "sie", "be\u00b7schreibt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Darauf kommt es an:", "tokens": ["Da\u00b7rauf", "kommt", "es", "an", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Sich im kleinen Kreis seines Lebens so zu bewegen,", "tokens": ["Sich", "im", "klei\u00b7nen", "Kreis", "sei\u00b7nes", "Le\u00b7bens", "so", "zu", "be\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPRART", "ADJA", "NN", "PPOSAT", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "--+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Planetarisch zu bewegen,", "tokens": ["Pla\u00b7ne\u00b7ta\u00b7risch", "zu", "be\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df man in der sph\u00e4rischen Ellipse l\u00e4uft,", "tokens": ["Da\u00df", "man", "in", "der", "sph\u00e4\u00b7ri\u00b7schen", "El\u00b7lip\u00b7se", "l\u00e4uft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Wie die Erde um die Sonne, der Mond um die Erde.", "tokens": ["Wie", "die", "Er\u00b7de", "um", "die", "Son\u00b7ne", ",", "der", "Mond", "um", "die", "Er\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "--+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Darauf kommt es an:", "tokens": ["Da\u00b7rauf", "kommt", "es", "an", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Da\u00df Sinn und Sein,", "tokens": ["Da\u00df", "Sinn", "und", "Sein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "PPOSAT", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Wort und Werk,", "tokens": ["Wort", "und", "Werk", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Tat und Traum", "tokens": ["Tat", "und", "Traum"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "Unaufl\u00f6slich unentkettbar eins sind.", "tokens": ["Un\u00b7auf\u00b7l\u00f6s\u00b7lich", "un\u00b7ent\u00b7kett\u00b7bar", "eins", "sind", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "PIS", "VAFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}}}}