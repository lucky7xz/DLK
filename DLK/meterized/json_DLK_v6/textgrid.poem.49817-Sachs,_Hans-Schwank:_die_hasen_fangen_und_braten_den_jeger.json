{"textgrid.poem.49817": {"metadata": {"author": {"name": "Sachs, Hans", "birth": "N.A.", "death": "N.A."}, "title": "Schwank: die hasen fangen und braten den jeger", "genre": "verse", "period": "N.A.", "pub_year": 1550, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Eins morgens gieng ich durch ein walt,", "tokens": ["Eins", "mor\u00b7gens", "gieng", "ich", "durch", "ein", "walt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "es het geschneit und war grim kalt;", "tokens": ["es", "het", "ge\u00b7schneit", "und", "war", "grim", "kalt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "KON", "VAFIN", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "neben der stra\u00dfen h\u00f6rt ich vispern,", "tokens": ["ne\u00b7ben", "der", "stra\u00b7\u00dfen", "h\u00f6rt", "ich", "vis\u00b7pern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "VVFIN", "PPER", "VVINF", "$,"], "meter": "---+-+---", "measure": "unknown.measure.di"}, "line.4": {"text": "etwas hinder eim gstreu\u00df laut zispern;", "tokens": ["et\u00b7was", "hin\u00b7der", "eim", "gs\u00b7treu\u00df", "laut", "zis\u00b7pern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "+-+--+-+--", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "ich guckt hindurch, sach, das da sasen", "tokens": ["ich", "guckt", "hin\u00b7durch", ",", "sach", ",", "das", "da", "sa\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PAV", "$,", "VVFIN", "$,", "PRELS", "ADV", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "etwas in die zweihundert hasen,", "tokens": ["et\u00b7was", "in", "die", "zwei\u00b7hun\u00b7dert", "ha\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "CARD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "heten sam da iren reichstag.", "tokens": ["he\u00b7ten", "sam", "da", "i\u00b7ren", "reichs\u00b7tag", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "ein alter has erzelt die klag", "tokens": ["ein", "al\u00b7ter", "has", "er\u00b7zelt", "die", "klag"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "\u00fcber ein gar uralten jeger,", "tokens": ["\u00fc\u00b7ber", "ein", "gar", "ur\u00b7al\u00b7ten", "je\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-++-+-", "measure": "unknown.measure.penta"}, "line.10": {"text": "der sie teglich in irem leger", "tokens": ["der", "sie", "teg\u00b7lich", "in", "i\u00b7rem", "le\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADJD", "APPR", "ADJA", "NN"], "meter": "--+--+-++", "measure": "anapaest.di.plus"}, "line.11": {"text": "\u00fcberfiel mit lauschen und hetzen,", "tokens": ["\u00fc\u00b7berf\u00b7iel", "mit", "lau\u00b7schen", "und", "het\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "VVINF", "KON", "VVINF", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.12": {"text": "mit gscho\u00df, falken, hunden und netzen,", "tokens": ["mit", "gscho\u00df", ",", "fal\u00b7ken", ",", "hun\u00b7den", "und", "net\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "VVINF", "$,", "ADJA", "KON", "VVINF", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.13": {"text": "darmit sie vilfaltig verstricket", "tokens": ["dar\u00b7mit", "sie", "vil\u00b7fal\u00b7tig", "ver\u00b7stri\u00b7cket"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "VVFIN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.14": {"text": "und sie on alle barmung knicket,", "tokens": ["und", "sie", "on", "al\u00b7le", "bar\u00b7mung", "kni\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "darnach er sie denn schunt und brit,", "tokens": ["dar\u00b7nach", "er", "sie", "denn", "schunt", "und", "brit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PPER", "ADV", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "ir etlich gar zu st\u00fccken schnit,", "tokens": ["ir", "et\u00b7lich", "gar", "zu", "st\u00fc\u00b7cken", "schnit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADV", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "und bickt sie ein zu eim f\u00fcrhe\u00df,", "tokens": ["und", "bickt", "sie", "ein", "zu", "eim", "f\u00fcr\u00b7he\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "PTKA", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "nachdem mit zenen zri\u00df und fre\u00df;", "tokens": ["nach\u00b7dem", "mit", "ze\u00b7nen", "zri\u00df", "und", "fre\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ADJA", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.19": {"text": "das m\u00fcstens leiden und ir kinder", "tokens": ["das", "m\u00fcs\u00b7tens", "lei\u00b7den", "und", "ir", "kin\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "VVINF", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "und w\u00fcrden ir ie lenger minder,", "tokens": ["und", "w\u00fcr\u00b7den", "ir", "ie", "len\u00b7ger", "min\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "wiewol sie teglich junge tr\u00fcgen", "tokens": ["wie\u00b7wol", "sie", "teg\u00b7lich", "jun\u00b7ge", "tr\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "und die ausheckten und aufz\u00fcgen,", "tokens": ["und", "die", "aus\u00b7heck\u00b7ten", "und", "auf\u00b7z\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "und wo die leng sie noch da blieben,", "tokens": ["und", "wo", "die", "leng", "sie", "noch", "da", "blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "VVFIN", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "w\u00fcrdens all von im aufgeriben;", "tokens": ["w\u00fcr\u00b7dens", "all", "von", "im", "auf\u00b7ge\u00b7ri\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "APPR", "APPRART", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.25": {"text": "derhalb wer not, das sie allsant", "tokens": ["der\u00b7halb", "wer", "not", ",", "das", "sie", "all\u00b7sant"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "PWS", "VVFIN", "$,", "PRELS", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "dem jeger teten widerstant,", "tokens": ["dem", "je\u00b7ger", "te\u00b7ten", "wi\u00b7der\u00b7stant", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "wenn er zu nechst mit seim weidwerk", "tokens": ["wenn", "er", "zu", "nechst", "mit", "seim", "weid\u00b7werk"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKZU", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.28": {"text": "widerumb z\u00fcg auf disen berk,", "tokens": ["wi\u00b7de\u00b7rumb", "z\u00fcg", "auf", "di\u00b7sen", "berk", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.29": {"text": "das sie im soltn mit gmeinem haufen", "tokens": ["das", "sie", "im", "soltn", "mit", "gmei\u00b7nem", "hau\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "APPRART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "in einem sturm entgegen laufen,", "tokens": ["in", "ei\u00b7nem", "sturm", "ent\u00b7ge\u00b7gen", "lau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJD", "PTKVZ", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "grad zu auf in, on alle kr\u00fcmb,", "tokens": ["grad", "zu", "auf", "in", ",", "on", "al\u00b7le", "kr\u00fcmb", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "APPR", "APPR", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.32": {"text": "den alten jeger sto\u00dfen \u00fcmb,", "tokens": ["den", "al\u00b7ten", "je\u00b7ger", "sto\u00b7\u00dfen", "\u00fcmb", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "in denn mit sein hetzstricken binden,", "tokens": ["in", "denn", "mit", "sein", "hetz\u00b7stri\u00b7cken", "bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "dergleich seine leithund und winden.", "tokens": ["derg\u00b7leich", "sei\u00b7ne", "leit\u00b7hund", "und", "win\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "KON", "VVINF", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.35": {"text": "wenn sie denn also wern gefangen,", "tokens": ["wenn", "sie", "denn", "al\u00b7so", "wern", "ge\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.36": {"text": "als \u00fcbel, vor an in begangen,", "tokens": ["als", "\u00fc\u00b7bel", ",", "vor", "an", "in", "be\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "$,", "APPR", "APPR", "APPR", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.37": {"text": "m\u00f6cht man volk\u00f6mlich an in rechen.", "tokens": ["m\u00f6cht", "man", "vol\u00b7k\u00f6m\u00b7lich", "an", "in", "re\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADJD", "APPR", "APPR", "ADJA", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.38": {"text": "darzu waren all hasen sprechen,", "tokens": ["dar\u00b7zu", "wa\u00b7ren", "all", "ha\u00b7sen", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.39": {"text": "sie wolten ir belg all dran wagen", "tokens": ["sie", "wol\u00b7ten", "ir", "belg", "all", "dran", "wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "PIAT", "PAV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.40": {"text": "und stracks nachkommen seim ansagen,", "tokens": ["und", "stracks", "nach\u00b7kom\u00b7men", "seim", "an\u00b7sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVINF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.41": {"text": "ob sie m\u00f6chten den jeger fellen.", "tokens": ["ob", "sie", "m\u00f6ch\u00b7ten", "den", "je\u00b7ger", "fel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "ART", "ADJA", "NN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.42": {"text": "in dem h\u00f6rt ich ein horen schellen", "tokens": ["in", "dem", "h\u00f6rt", "ich", "ein", "ho\u00b7ren", "schel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "VVFIN", "PPER", "ART", "NN", "VVINF"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.43": {"text": "und auch jauchzen der hunde haufen;", "tokens": ["und", "auch", "jauch\u00b7zen", "der", "hun\u00b7de", "hau\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.44": {"text": "anfiengen die hasen zu laufen", "tokens": ["an\u00b7fi\u00b7en\u00b7gen", "die", "ha\u00b7sen", "zu", "lau\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PTKZU", "VVINF"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.45": {"text": "hinab gen tal dem jeger zu;", "tokens": ["hin\u00b7ab", "gen", "tal", "dem", "je\u00b7ger", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJD", "ART", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.46": {"text": "ich stunt ein weil, und in eim nu", "tokens": ["ich", "stunt", "ein", "weil", ",", "und", "in", "eim", "nu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "KOUS", "$,", "KON", "APPR", "ART", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.47": {"text": "kamen die hasen in ir leger", "tokens": ["ka\u00b7men", "die", "ha\u00b7sen", "in", "ir", "le\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "APPR", "NE", "NE"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.48": {"text": "und brachten mit den alten jeger,", "tokens": ["und", "brach\u00b7ten", "mit", "den", "al\u00b7ten", "je\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.49": {"text": "mit weidstricken gfangen und bunden,", "tokens": ["mit", "weid\u00b7stri\u00b7cken", "gfan\u00b7gen", "und", "bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.50": {"text": "mit all sein winden und leithunden,", "tokens": ["mit", "all", "sein", "win\u00b7den", "und", "leit\u00b7hun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "ADJA", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.51": {"text": "sein spie\u00df und weidme\u00dfer sie trugen,", "tokens": ["sein", "spie\u00df", "und", "weid\u00b7me\u00b7\u00dfer", "sie", "tru\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAINF", "VVFIN", "KON", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.52": {"text": "den jeger an eim strick aufzugen", "tokens": ["den", "je\u00b7ger", "an", "eim", "strick", "auf\u00b7zu\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.53": {"text": "an eim baum zu der strengen frag,", "tokens": ["an", "eim", "baum", "zu", "der", "stren\u00b7gen", "frag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.54": {"text": "wie vil er hasen all sein tag", "tokens": ["wie", "vil", "er", "ha\u00b7sen", "all", "sein", "tag"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "PPER", "VVFIN", "PIAT", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.55": {"text": "het umbbracht mit seinem weidwerk", "tokens": ["het", "umb\u00b7bracht", "mit", "sei\u00b7nem", "weid\u00b7werk"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "VVPP", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.56": {"text": "alhie an dem waldigen berk.", "tokens": ["al\u00b7hie", "an", "dem", "wal\u00b7di\u00b7gen", "berk", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.57": {"text": "da bekent er auf drithalb hundert,", "tokens": ["da", "be\u00b7kent", "er", "auf", "drit\u00b7halb", "hun\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "CARD", "CARD", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.58": {"text": "ieden mit namen ausgesundert.", "tokens": ["ie\u00b7den", "mit", "na\u00b7men", "aus\u00b7ge\u00b7sun\u00b7dert", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "APPR", "NN", "VVPP", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.59": {"text": "mit flei\u00df beschribens sein urgicht;", "tokens": ["mit", "flei\u00df", "be\u00b7schri\u00b7bens", "sein", "ur\u00b7gicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.60": {"text": "nach dem sa\u00dfen sie zu gericht,", "tokens": ["nach", "dem", "sa\u00b7\u00dfen", "sie", "zu", "ge\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.61": {"text": "teten sein jegerhoren schellen", "tokens": ["te\u00b7ten", "sein", "je\u00b7ger\u00b7ho\u00b7ren", "schel\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "ADJA", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.62": {"text": "und \u00fcber in ein urteil fellen,", "tokens": ["und", "\u00fc\u00b7ber", "in", "ein", "ur\u00b7teil", "fel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.63": {"text": "das man zu straf umb sein untaten", "tokens": ["das", "man", "zu", "straf", "umb", "sein", "un\u00b7ta\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "PTKZU", "VVFIN", "APPR", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.64": {"text": "in solt an einem spie\u00dfe braten,", "tokens": ["in", "solt", "an", "ei\u00b7nem", "spie\u00b7\u00dfe", "bra\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VMFIN", "APPR", "ART", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.65": {"text": "wie er den hasen auch het tan,", "tokens": ["wie", "er", "den", "ha\u00b7sen", "auch", "het", "tan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ADV", "VAFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.66": {"text": "wo ers gfenglich het kummen an.", "tokens": ["wo", "ers", "gfeng\u00b7lich", "het", "kum\u00b7men", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADJD", "VAFIN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.67": {"text": "auch feltens ein urteil den hunden,", "tokens": ["auch", "fel\u00b7tens", "ein", "ur\u00b7teil", "den", "hun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.68": {"text": "das sie all solten werden gschunden,", "tokens": ["das", "sie", "all", "sol\u00b7ten", "wer\u00b7den", "gschun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PIAT", "NN", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.69": {"text": "zerhauen und gesalzen ein", "tokens": ["zer\u00b7hau\u00b7en", "und", "ge\u00b7sal\u00b7zen", "ein"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "KON", "NN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.70": {"text": "und darnach aufgehangen sein.", "tokens": ["und", "dar\u00b7nach", "auf\u00b7ge\u00b7han\u00b7gen", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.71": {"text": "nach dem sch\u00fcrtens ein gro\u00dfes feuer,", "tokens": ["nach", "dem", "sch\u00fcr\u00b7tens", "ein", "gro\u00b7\u00dfes", "feu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.72": {"text": "namen den jeger ungeheuer", "tokens": ["na\u00b7men", "den", "je\u00b7ger", "un\u00b7ge\u00b7heu\u00b7er"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.73": {"text": "und bunden in an ein bratspie\u00df;", "tokens": ["und", "bun\u00b7den", "in", "an", "ein", "brat\u00b7spie\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "APPR", "APPR", "ART", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.74": {"text": "der einen tiefen seufzen lie\u00df", "tokens": ["der", "ei\u00b7nen", "tie\u00b7fen", "seuf\u00b7zen", "lie\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "VVINF", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.75": {"text": "und sprach: erst ich erkennen kan,", "tokens": ["und", "sprach", ":", "erst", "ich", "er\u00b7ken\u00b7nen", "kan", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "ADV", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.76": {"text": "das ich im hab zu vil getan,", "tokens": ["das", "ich", "im", "hab", "zu", "vil", "ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "APPRART", "VAFIN", "APPR", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.77": {"text": "drumb gschicht mir iezt auch nit unrecht;", "tokens": ["drumb", "gschicht", "mir", "iezt", "auch", "nit", "un\u00b7recht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "ADV", "PTKNEG", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.78": {"text": "ich hab euch gar zu hart durchecht", "tokens": ["ich", "hab", "euch", "gar", "zu", "hart", "dur\u00b7checht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.79": {"text": "on schult wider all billichkeit,", "tokens": ["on", "schult", "wi\u00b7der", "all", "bil\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.80": {"text": "wan ich gedacht zu jener zeit,", "tokens": ["wan", "ich", "ge\u00b7dacht", "zu", "je\u00b7ner", "zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVPP", "APPR", "PDAT", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.81": {"text": "ich wolt euch drucken, wie ich wolt,", "tokens": ["ich", "wolt", "euch", "dru\u00b7cken", ",", "wie", "ich", "wolt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "$,", "PWAV", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.82": {"text": "das ir mich allzeit fliehen solt", "tokens": ["das", "ir", "mich", "all\u00b7zeit", "flie\u00b7hen", "solt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "PRF", "ADV", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.83": {"text": "nach aller hasn natur und art;", "tokens": ["nach", "al\u00b7ler", "hasn", "na\u00b7tur", "und", "art", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.84": {"text": "iezt, so ir haltet widerpart", "tokens": ["iezt", ",", "so", "ir", "hal\u00b7tet", "wi\u00b7der\u00b7part"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "ADV", "PPER", "VVFIN", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.85": {"text": "und ir mein meister worden seit,", "tokens": ["und", "ir", "mein", "meis\u00b7ter", "wor\u00b7den", "seit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PPOSAT", "NN", "VAPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.86": {"text": "erkenn ich erst mein gro\u00df torheit.", "tokens": ["er\u00b7kenn", "ich", "erst", "mein", "gro\u00df", "tor\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.87": {"text": "nach dem die hasen ungeheuer", "tokens": ["nach", "dem", "die", "ha\u00b7sen", "un\u00b7ge\u00b7heu\u00b7er"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.88": {"text": "teten den jeger zu dem feuer", "tokens": ["te\u00b7ten", "den", "je\u00b7ger", "zu", "dem", "feu\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "APPR", "ART", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.89": {"text": "und dreten in umb an dem spie\u00df;", "tokens": ["und", "dre\u00b7ten", "in", "umb", "an", "dem", "spie\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "KOUI", "APPR", "ART", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.90": {"text": "mannichen lauten schrei er lie\u00df,", "tokens": ["man\u00b7ni\u00b7chen", "lau\u00b7ten", "schrei", "er", "lie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.91": {"text": "zu helfen ich im oft gedacht,", "tokens": ["zu", "hel\u00b7fen", "ich", "im", "oft", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPER", "APPRART", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.92": {"text": "doch sorg und forcht mich darvon bracht,", "tokens": ["doch", "sorg", "und", "forcht", "mich", "dar\u00b7von", "bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "VVFIN", "PRF", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.93": {"text": "das sie mir nicht gleich wie im taten,", "tokens": ["das", "sie", "mir", "nicht", "gleich", "wie", "im", "ta\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PPER", "PTKNEG", "ADV", "KOKOM", "APPRART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.94": {"text": "lie\u00df gleich den alten jeger braten,", "tokens": ["lie\u00df", "gleich", "den", "al\u00b7ten", "je\u00b7ger", "bra\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "ADJA", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.95": {"text": "all hund erschlagen, darnach schinden,", "tokens": ["all", "hund", "er\u00b7schla\u00b7gen", ",", "dar\u00b7nach", "schin\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "$,", "PAV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.96": {"text": "in st\u00fcck zerhauen; ich stunt hinden,", "tokens": ["in", "st\u00fcck", "zer\u00b7hau\u00b7en", ";", "ich", "stunt", "hin\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$.", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.97": {"text": "sach, wies ein teil einsalzten auch,", "tokens": ["sach", ",", "wies", "ein", "teil", "ein\u00b7salz\u00b7ten", "auch", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "VVFIN", "ART", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.98": {"text": "darnach aufhiengen in den rauch,", "tokens": ["dar\u00b7nach", "auf\u00b7hien\u00b7gen", "in", "den", "rauch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.99": {"text": "eins teils sie in eim ke\u00dfel suden,", "tokens": ["eins", "teils", "sie", "in", "eim", "ke\u00b7\u00dfel", "su\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.100": {"text": "all w\u00f6lf und f\u00fcchs sie darzu luden,", "tokens": ["all", "w\u00f6lf", "und", "f\u00fcchs", "sie", "dar\u00b7zu", "lu\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "VVFIN", "PPER", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.101": {"text": "mit in zu halten das fr\u00fcmal.", "tokens": ["mit", "in", "zu", "hal\u00b7ten", "das", "fr\u00fc\u00b7mal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "PTKZU", "VVINF", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.102": {"text": "nach dem gieng ich mein stra\u00df zu tal", "tokens": ["nach", "dem", "gieng", "ich", "mein", "stra\u00df", "zu", "tal"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "VVFIN", "PPER", "PPOSAT", "VVFIN", "APPR", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.103": {"text": "und gedacht mir bei der geschicht:", "tokens": ["und", "ge\u00b7dacht", "mir", "bei", "der", "ge\u00b7schicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "PPER", "APPR", "ART", "VVPP", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.104": {"text": "war ist es, wie Seneca spricht:", "tokens": ["war", "ist", "es", ",", "wie", "Se\u00b7ne\u00b7ca", "spricht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "VAFIN", "PPER", "$,", "PWAV", "NE", "VVFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.105": {"text": "welch herr treibet gro\u00df tyrannei,", "tokens": ["welch", "herr", "trei\u00b7bet", "gro\u00df", "ty\u00b7ran\u00b7nei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "VVFIN", "ADJD", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.106": {"text": "macht vil aufsetz und schinderei,", "tokens": ["macht", "vil", "auf\u00b7setz", "und", "schin\u00b7de\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.107": {"text": "meint zu drucken sein underton,", "tokens": ["meint", "zu", "dru\u00b7cken", "sein", "un\u00b7der\u00b7ton", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKZU", "VVINF", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.108": {"text": "auf das sie f\u00fcrchten sein person,", "tokens": ["auf", "das", "sie", "f\u00fcrch\u00b7ten", "sein", "per\u00b7son", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.109": {"text": "derselb mu\u00df ir auch f\u00f6rchten vil;", "tokens": ["der\u00b7selb", "mu\u00df", "ir", "auch", "f\u00f6rch\u00b7ten", "vil", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.110": {"text": "wenn ers gar \u00fcbermachen wil,", "tokens": ["wenn", "ers", "gar", "\u00fc\u00b7ber\u00b7ma\u00b7chen", "wil", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.111": {"text": "wirt es etwan mit ungst\u00fcm grochen,", "tokens": ["wirt", "es", "et\u00b7wan", "mit", "ungs\u00b7t\u00fcm", "gro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "ADJD", "ADJA", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.112": {"text": "und hart gespanter bogen brochen,", "tokens": ["und", "hart", "ge\u00b7span\u00b7ter", "bo\u00b7gen", "bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.113": {"text": "wie keiser Julio geschach,", "tokens": ["wie", "kei\u00b7ser", "Ju\u00b7lio", "ge\u00b7schach", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "ADJD", "$,"], "meter": "-+----+", "measure": "dactylic.init"}, "line.114": {"text": "auch andern mer vor und hernach;", "tokens": ["auch", "an\u00b7dern", "mer", "vor", "und", "her\u00b7nach", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "ADV", "PTKVZ", "KON", "ADV", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.115": {"text": "wer aber senftm\u00fctig regiert,", "tokens": ["wer", "a\u00b7ber", "senft\u00b7m\u00fc\u00b7tig", "re\u00b7giert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.116": {"text": "von den seinen geliebet wirt,", "tokens": ["von", "den", "sei\u00b7nen", "ge\u00b7lie\u00b7bet", "wirt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPOSAT", "VVPP", "VAFIN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.117": {"text": "tun im freiwillig alles gut", "tokens": ["tun", "im", "frei\u00b7wil\u00b7lig", "al\u00b7les", "gut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPRART", "ADJD", "PIS", "ADJD"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.118": {"text": "und setzen zu im leib und blut,", "tokens": ["und", "set\u00b7zen", "zu", "im", "leib", "und", "blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "PTKZU", "APPRART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.119": {"text": "darmit sein reich gr\u00fcn, bl\u00fc und wachs.", "tokens": ["dar\u00b7mit", "sein", "reich", "gr\u00fcn", ",", "bl\u00fc", "und", "wachs", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "ADJD", "ADJD", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "----+--+", "measure": "iambic.di.chol"}, "line.120": {"text": "senftmut bringt gut, so spricht Hans Sachs.", "tokens": ["senft\u00b7mut", "bringt", "gut", ",", "so", "spricht", "Hans", "Sachs", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "$,", "ADV", "VVFIN", "NE", "NE", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}}}}}