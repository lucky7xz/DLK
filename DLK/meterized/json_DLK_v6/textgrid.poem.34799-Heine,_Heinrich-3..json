{"textgrid.poem.34799": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "3.", "genre": "verse", "period": "N.A.", "pub_year": 1826, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Ritter Tannh\u00e4user, er wandelt so rasch,", "tokens": ["Der", "Rit\u00b7ter", "Tann\u00b7h\u00e4u\u00b7ser", ",", "er", "wan\u00b7delt", "so", "rasch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PPER", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+---+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Die F\u00fc\u00dfe, die wurden ihm wunde.", "tokens": ["Die", "F\u00fc\u00b7\u00dfe", ",", "die", "wur\u00b7den", "ihm", "wun\u00b7de", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VAFIN", "PPER", "ADJA", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Er kam zur\u00fcck in den Venusberg", "tokens": ["Er", "kam", "zu\u00b7r\u00fcck", "in", "den", "Ve\u00b7nus\u00b7berg"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wohl um die Mitternachtstunde.", "tokens": ["Wohl", "um", "die", "Mit\u00b7ter\u00b7nachts\u00b7tun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Frau Venus erwachte aus dem Schlaf,", "tokens": ["Frau", "Ve\u00b7nus", "er\u00b7wach\u00b7te", "aus", "dem", "Schlaf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Ist schnell aus dem Bette gesprungen;", "tokens": ["Ist", "schnell", "aus", "dem", "Bet\u00b7te", "ge\u00b7sprun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Sie hat mit ihrem wei\u00dfen Arm", "tokens": ["Sie", "hat", "mit", "ih\u00b7rem", "wei\u00b7\u00dfen", "Arm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den geliebten Mann umschlungen.", "tokens": ["Den", "ge\u00b7lieb\u00b7ten", "Mann", "um\u00b7schlun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Aus ihrer Nase rann das Blut,", "tokens": ["Aus", "ih\u00b7rer", "Na\u00b7se", "rann", "das", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Augen die Tr\u00e4nen entflossen;", "tokens": ["Den", "Au\u00b7gen", "die", "Tr\u00e4\u00b7nen", "ent\u00b7flos\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Sie hat mit Tr\u00e4nen und Blut das Gesicht", "tokens": ["Sie", "hat", "mit", "Tr\u00e4\u00b7nen", "und", "Blut", "das", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "NN", "KON", "NN", "ART", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Des geliebten Mannes begossen.", "tokens": ["Des", "ge\u00b7lieb\u00b7ten", "Man\u00b7nes", "be\u00b7gos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Der Ritter legte sich ins Bett,", "tokens": ["Der", "Rit\u00b7ter", "leg\u00b7te", "sich", "ins", "Bett", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er hat kein Wort gesprochen.", "tokens": ["Er", "hat", "kein", "Wort", "ge\u00b7spro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Frau Venus in die K\u00fcche ging,", "tokens": ["Frau", "Ve\u00b7nus", "in", "die", "K\u00fc\u00b7che", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Um ihm eine Suppe zu kochen.", "tokens": ["Um", "ihm", "ei\u00b7ne", "Sup\u00b7pe", "zu", "ko\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Sie gab ihm Suppe, sie gab ihm Brot,", "tokens": ["Sie", "gab", "ihm", "Sup\u00b7pe", ",", "sie", "gab", "ihm", "Brot", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "$,", "PPER", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sie wusch seine wunden F\u00fc\u00dfe,", "tokens": ["Sie", "wusch", "sei\u00b7ne", "wun\u00b7den", "F\u00fc\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.3": {"text": "Sie k\u00e4mmte ihm das struppige Haar,", "tokens": ["Sie", "k\u00e4mm\u00b7te", "ihm", "das", "strup\u00b7pi\u00b7ge", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und lachte dabei so s\u00fc\u00dfe.", "tokens": ["Und", "lach\u00b7te", "da\u00b7bei", "so", "s\u00fc\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "ADV", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "\u00bbtannh\u00e4user, edler Ritter mein,", "tokens": ["\u00bb", "tann\u00b7h\u00e4u\u00b7ser", ",", "ed\u00b7ler", "Rit\u00b7ter", "mein", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "ADJA", "NN", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bist lange ausgeblieben,", "tokens": ["Bist", "lan\u00b7ge", "aus\u00b7ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sag an, in welchen Landen du dich", "tokens": ["Sag", "an", ",", "in", "wel\u00b7chen", "Lan\u00b7den", "du", "dich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PTKVZ", "$,", "APPR", "PWAT", "NN", "PPER", "PRF"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "So lange herumgetrieben?\u00ab", "tokens": ["So", "lan\u00b7ge", "her\u00b7um\u00b7ge\u00b7trie\u00b7ben", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "VVPP", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "\u00bbfrau Venus, meine sch\u00f6ne Frau,", "tokens": ["\u00bb", "frau", "Ve\u00b7nus", ",", "mei\u00b7ne", "sch\u00f6\u00b7ne", "Frau", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "NN", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich hab in Welschland verweilet;", "tokens": ["Ich", "hab", "in", "Wel\u00b7schland", "ver\u00b7wei\u00b7let", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ich hatte Gesch\u00e4fte in Rom und bin", "tokens": ["Ich", "hat\u00b7te", "Ge\u00b7sch\u00e4f\u00b7te", "in", "Rom", "und", "bin"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "APPR", "NE", "KON", "VAFIN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Schnell wieder hierher geeilet.", "tokens": ["Schnell", "wie\u00b7der", "hier\u00b7her", "ge\u00b7ei\u00b7let", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "PAV", "VVPP", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Auf sieben H\u00fcgeln ist Rom gebaut,", "tokens": ["Auf", "sie\u00b7ben", "H\u00fc\u00b7geln", "ist", "Rom", "ge\u00b7baut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VAFIN", "NE", "VVPP", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Tiber tut dorten flie\u00dfen;", "tokens": ["Die", "Ti\u00b7ber", "tut", "dor\u00b7ten", "flie\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+----+-", "measure": "dactylic.init"}, "line.3": {"text": "Auch hab ich in Rom den Papst gesehn,", "tokens": ["Auch", "hab", "ich", "in", "Rom", "den", "Papst", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "NE", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der Papst, er l\u00e4\u00dft dich gr\u00fc\u00dfen.", "tokens": ["Der", "Papst", ",", "er", "l\u00e4\u00dft", "dich", "gr\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Auf meinem R\u00fcckweg sah ich Florenz,", "tokens": ["Auf", "mei\u00b7nem", "R\u00fcck\u00b7weg", "sah", "ich", "Flo\u00b7renz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "NE", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Bin auch durch Mailand gekommen,", "tokens": ["Bin", "auch", "durch", "Mai\u00b7land", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Und bin alsdann mit raschem Mut", "tokens": ["Und", "bin", "als\u00b7dann", "mit", "ra\u00b7schem", "Mut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Schweiz hinaufgeklommen.", "tokens": ["Die", "Schweiz", "hin\u00b7auf\u00b7ge\u00b7klom\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NE", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Und als ich \u00fcber die Alpen zog,", "tokens": ["Und", "als", "ich", "\u00fc\u00b7ber", "die", "Al\u00b7pen", "zog", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da fing es an zu schneien,", "tokens": ["Da", "fing", "es", "an", "zu", "schnei\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die blauen Seen, die lachten mich an,", "tokens": ["Die", "blau\u00b7en", "Seen", ",", "die", "lach\u00b7ten", "mich", "an", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Die Adler kr\u00e4chzen und schreien.", "tokens": ["Die", "Ad\u00b7ler", "kr\u00e4ch\u00b7zen", "und", "schrei\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "KON", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Und als ich auf dem Sankt Gotthard stand,", "tokens": ["Und", "als", "ich", "auf", "dem", "Sankt", "Got\u00b7thard", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "VVFIN", "NE", "VVFIN", "$,"], "meter": "---+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Da h\u00f6rt ich Deutschland schnarchen;", "tokens": ["Da", "h\u00f6rt", "ich", "Deutschland", "schnar\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "VVFIN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Es schlief da unten in sanfter Hut", "tokens": ["Es", "schlief", "da", "un\u00b7ten", "in", "sanf\u00b7ter", "Hut"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von sechsunddrei\u00dfig Monarchen.", "tokens": ["Von", "sech\u00b7sund\u00b7drei\u00b7\u00dfig", "Mon\u00b7ar\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "In Schwaben besah ich die Dichterschul',", "tokens": ["In", "Schwa\u00b7ben", "be\u00b7sah", "ich", "die", "Dicht\u00b7er\u00b7schul'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Gar liebe Gesch\u00f6pfchen und Tr\u00f6pfchen!", "tokens": ["Gar", "lie\u00b7be", "Ge\u00b7sch\u00f6pf\u00b7chen", "und", "Tr\u00f6pf\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Auf kleinen Kackst\u00fchlchen sa\u00dfen sie dort,", "tokens": ["Auf", "klei\u00b7nen", "Kack\u00b7st\u00fchl\u00b7chen", "sa\u00b7\u00dfen", "sie", "dort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Fallh\u00fctchen auf den K\u00f6pfchen.", "tokens": ["Fall\u00b7h\u00fct\u00b7chen", "auf", "den", "K\u00f6pf\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Zu Frankfurt kam ich am Schabbes an,", "tokens": ["Zu", "Frank\u00b7furt", "kam", "ich", "am", "Schab\u00b7bes", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und a\u00df dort Schalet und Kl\u00f6\u00dfe;", "tokens": ["Und", "a\u00df", "dort", "Scha\u00b7let", "und", "Kl\u00f6\u00b7\u00dfe", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "NN", "KON", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ihr habt die beste Religion,", "tokens": ["Ihr", "habt", "die", "bes\u00b7te", "Re\u00b7li\u00b7gi\u00b7on", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auch lieb ich das G\u00e4nsegekr\u00f6se.", "tokens": ["Auch", "lieb", "ich", "das", "G\u00e4n\u00b7se\u00b7ge\u00b7kr\u00f6\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.14": {"line.1": {"text": "In Dresden sah ich einen Hund,", "tokens": ["In", "Dres\u00b7den", "sah", "ich", "ei\u00b7nen", "Hund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der einst geh\u00f6rt zu den Bessern,", "tokens": ["Der", "einst", "ge\u00b7h\u00f6rt", "zu", "den", "Bes\u00b7sern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Doch fallen ihm jetzt die Z\u00e4hne aus,", "tokens": ["Doch", "fal\u00b7len", "ihm", "jetzt", "die", "Z\u00e4h\u00b7ne", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Er kann nur bellen und w\u00e4ssern.", "tokens": ["Er", "kann", "nur", "bel\u00b7len", "und", "w\u00e4s\u00b7sern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.15": {"line.1": {"text": "Zu Weimar, dem Musenwitwensitz,", "tokens": ["Zu", "Wei\u00b7mar", ",", "dem", "Mu\u00b7sen\u00b7wit\u00b7wen\u00b7sitz", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da h\u00f6rt ich viel Klagen erheben,", "tokens": ["Da", "h\u00f6rt", "ich", "viel", "Kla\u00b7gen", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Man weinte und jammerte: Goethe sei tot,", "tokens": ["Man", "wein\u00b7te", "und", "jam\u00b7mer\u00b7te", ":", "Goe\u00b7the", "sei", "tot", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "$.", "NE", "VAFIN", "ADJD", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Und Eckermann sei noch am Leben!", "tokens": ["Und", "E\u00b7cker\u00b7mann", "sei", "noch", "am", "Le\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.16": {"line.1": {"text": "Zu Potsdam vernahm ich ein lautes Geschrei \u2013", "tokens": ["Zu", "Pots\u00b7dam", "ver\u00b7nahm", "ich", "ein", "lau\u00b7tes", "Ge\u00b7schrei", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "\u203awas gibt es?\u2039 rief ich verwundert.", "tokens": ["\u203a", "was", "gibt", "es", "?", "\u2039", "rief", "ich", "ver\u00b7wun\u00b7dert", "."], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "$.", "$(", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u203adas ist der Gans in Berlin, der liest", "tokens": ["\u203a", "das", "ist", "der", "Gans", "in", "Ber\u00b7lin", ",", "der", "liest"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "PDS", "VAFIN", "ART", "NN", "APPR", "NE", "$,", "PRELS", "VVFIN"], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "Dort \u00fcber das letzte Jahrhundert.\u2039", "tokens": ["Dort", "\u00fc\u00b7ber", "das", "letz\u00b7te", "Jahr\u00b7hun\u00b7dert", ".", "\u2039"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.17": {"line.1": {"text": "Zu G\u00f6ttingen bl\u00fcht die Wissenschaft,", "tokens": ["Zu", "G\u00f6t\u00b7tin\u00b7gen", "bl\u00fcht", "die", "Wis\u00b7sen\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Doch bringt sie keine Fr\u00fcchte.", "tokens": ["Doch", "bringt", "sie", "kei\u00b7ne", "Fr\u00fcch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich kam dort durch in stockfinstrer Nacht,", "tokens": ["Ich", "kam", "dort", "durch", "in", "stock\u00b7finst\u00b7rer", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "APPR", "ADJA", "NN", "$,"], "meter": "-+----+-+", "measure": "dactylic.init"}, "line.4": {"text": "Sah nirgendswo ein Lichte.", "tokens": ["Sah", "nir\u00b7gends\u00b7wo", "ein", "Lich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Zu Celle im Zuchthaus sah ich nur", "tokens": ["Zu", "Cel\u00b7le", "im", "Zucht\u00b7haus", "sah", "ich", "nur"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPRART", "NN", "VVFIN", "PPER", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Hannoveraner \u2013 O Deutsche!", "tokens": ["Han\u00b7no\u00b7ve\u00b7ra\u00b7ner", "\u2013", "O", "Deut\u00b7sche", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$(", "NE", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Uns fehlt ein Nationalzuchthaus", "tokens": ["Uns", "fehlt", "ein", "Na\u00b7ti\u00b7o\u00b7nal\u00b7zucht\u00b7haus"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und eine gemeinsame Peitsche!", "tokens": ["Und", "ei\u00b7ne", "ge\u00b7mein\u00b7sa\u00b7me", "Peit\u00b7sche", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$."], "meter": "-+---+-+-", "measure": "dactylic.init"}}, "stanza.19": {"line.1": {"text": "Zu Hamburg frug ich: warum so sehr", "tokens": ["Zu", "Ham\u00b7burg", "frug", "ich", ":", "wa\u00b7rum", "so", "sehr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "PPER", "$.", "PWAV", "ADV", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Stra\u00dfen stinken t\u00e4ten?", "tokens": ["Die", "Stra\u00b7\u00dfen", "stin\u00b7ken", "t\u00e4\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch Juden und Christen versicherten mir,", "tokens": ["Doch", "Ju\u00b7den", "und", "Chris\u00b7ten", "ver\u00b7si\u00b7cher\u00b7ten", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "PPER", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Das k\u00e4me von den Fleeten.", "tokens": ["Das", "k\u00e4\u00b7me", "von", "den", "Flee\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Zu Hamburg, in der guten Stadt,", "tokens": ["Zu", "Ham\u00b7burg", ",", "in", "der", "gu\u00b7ten", "Stadt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wohnt mancher schlechte Geselle;", "tokens": ["Wohnt", "man\u00b7cher", "schlech\u00b7te", "Ge\u00b7sel\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Und als ich auf die B\u00f6rse kam,", "tokens": ["Und", "als", "ich", "auf", "die", "B\u00f6r\u00b7se", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich glaubte, ich w\u00e4r noch in Celle.", "tokens": ["Ich", "glaub\u00b7te", ",", "ich", "w\u00e4r", "noch", "in", "Cel\u00b7le", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ADV", "APPR", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.21": {"line.1": {"text": "Zu Hamburg sah ich Altona,", "tokens": ["Zu", "Ham\u00b7burg", "sah", "ich", "Al\u00b7to\u00b7na", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist auch eine sch\u00f6ne Gegend;", "tokens": ["Ist", "auch", "ei\u00b7ne", "sch\u00f6\u00b7ne", "Ge\u00b7gend", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ein andermal erz\u00e4hl ich dir,", "tokens": ["Ein", "an\u00b7der\u00b7mal", "er\u00b7z\u00e4hl", "ich", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was mir alldort begegent.\u00ab", "tokens": ["Was", "mir", "all\u00b7dort", "be\u00b7ge\u00b7gent", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "PPER", "ADV", "VVPP", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}}}}