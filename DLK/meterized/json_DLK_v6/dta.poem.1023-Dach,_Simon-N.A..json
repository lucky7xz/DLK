{"dta.poem.1023": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "N.A.", "genre": "Gelegenheitsschrift: Tod; Lyrik", "period": "N.A.", "pub_year": "1653", "urn": "urn:nbn:de:kobv:b4-203032-9", "language": ["de:0.99"], "booktitle": "Dach, Simon: Einf\u00e4ltige Leich-Reime. K\u00f6nigsberg, 1653."}, "poem": {"stanza.1": {"line.1": {"text": "Es mu\u00df doch nur gestorben seyn", "tokens": ["Es", "mu\u00df", "doch", "nur", "ge\u00b7stor\u00b7ben", "seyn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "VVPP", "VAINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Mittel ist dawieder/", "tokens": ["Kein", "Mit\u00b7tel", "ist", "da\u00b7wie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PAV", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sind schon nicht Fall vn\u0303 Kranckheit", "tokens": ["Sind", "schon", "nicht", "Fall", "v\u00f1", "Kran\u00b7ck\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PTKNEG", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Alter wirfft vns nieder/", "tokens": ["Das", "Al\u00b7ter", "wirfft", "vns", "nie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "(pein", "tokens": ["(", "pein"], "token_info": ["punct", "word"], "pos": ["$(", "NE"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Vnd heisst vns ausgehn wie ein Liecht", "tokens": ["Vnd", "heisst", "vns", "aus\u00b7gehn", "wie", "ein", "Liecht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "VVINF", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wenn Nahrung jhm gebricht", "tokens": ["Wenn", "Nah\u00b7rung", "jhm", "ge\u00b7bricht"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NN", "PPER", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Zuletzt wird anders nichts daraus/", "tokens": ["Zu\u00b7letzt", "wird", "an\u00b7ders", "nichts", "da\u00b7raus", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PIS", "PAV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Fackel dieser Erden", "tokens": ["Die", "Fa\u00b7ckel", "die\u00b7ser", "Er\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PDAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Sonne/ Kinder/ Freund' vnd Hau\u00df", "tokens": ["Die", "Son\u00b7ne", "/", "Kin\u00b7der", "/", "Freund'", "vnd", "Hau\u00df"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$(", "NN", "$(", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mu\u00df \u00fcbergeben werden/", "tokens": ["Mu\u00df", "\u00fc\u00b7ber\u00b7ge\u00b7ben", "wer\u00b7den", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "VVPP", "VAINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Denn die Natur erl\u00e4sst vns nicht", "tokens": ["Denn", "die", "Na\u00b7tur", "er\u00b7l\u00e4sst", "vns", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der strengen Schuld vnd Pflicht.", "tokens": ["Der", "stren\u00b7gen", "Schuld", "vnd", "Pflicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Was Wunder ist es dann da\u00df wir", "tokens": ["Was", "Wun\u00b7der", "ist", "es", "dann", "da\u00df", "wir"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "NN", "VAFIN", "PPER", "ADV", "KOUS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auch diese Fraw begraben?", "tokens": ["Auch", "die\u00b7se", "Fraw", "be\u00b7gra\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Jahre f\u00fchren sie von hier", "tokens": ["Die", "Jah\u00b7re", "f\u00fch\u00b7ren", "sie", "von", "hier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die sich verbunden haben", "tokens": ["Die", "sich", "ver\u00b7bun\u00b7den", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PRF", "VVPP", "VAINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Mit Schwachheit vnd mit sonst Verdru\u00df.", "tokens": ["Mit", "Schwach\u00b7heit", "vnd", "mit", "sonst", "Ver\u00b7dru\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dadurch man sterben mu\u00df.", "tokens": ["Da\u00b7durch", "man", "ster\u00b7ben", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Der zweene M\u00e4nner fr\u00fcher Tod", "tokens": ["Der", "zwee\u00b7ne", "M\u00e4n\u00b7ner", "fr\u00fc\u00b7her", "Tod"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fra\u00df viel von jhrem Hertzen/", "tokens": ["Fra\u00df", "viel", "von", "jhrem", "Hert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Der Kinder Hintritt bracht jhr Noht.", "tokens": ["Der", "Kin\u00b7der", "Hin\u00b7tritt", "bracht", "jhr", "Noht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wer zehlet sonst die Schmertzen", "tokens": ["Wer", "zeh\u00b7let", "sonst", "die", "Schmert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Die jhm durch ein sehr festes Band", "tokens": ["Die", "jhm", "durch", "ein", "sehr", "fes\u00b7tes", "Band"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Verkn\u00fcpfft der Witwenstand?", "tokens": ["Ver\u00b7kn\u00fcpfft", "der", "Wit\u00b7wen\u00b7stand", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Voraus der Sohn/ den Dantzig nam/", "tokens": ["Vo\u00b7raus", "der", "Sohn", "/", "den", "Dant\u00b7zig", "nam", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$(", "ART", "NE", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bek\u00fcmmert jhr die Sinnen/", "tokens": ["Be\u00b7k\u00fcm\u00b7mert", "jhr", "die", "Sin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bi\u00df gar zuletzt ein Fieber kam", "tokens": ["Bi\u00df", "gar", "zu\u00b7letzt", "ein", "Fie\u00b7ber", "kam"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd raffte sie von hinnen/", "tokens": ["Vnd", "raff\u00b7te", "sie", "von", "hin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ADV", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "So gehn wir eins dem andern nach", "tokens": ["So", "gehn", "wir", "eins", "dem", "an\u00b7dern", "nach"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "ART", "ADJA", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In vnser Schlaff-Gemach.", "tokens": ["In", "vn\u00b7ser", "Schlaff\u00b7Ge\u00b7mach", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Gleich wie auff einem Hochzeit-Mahl", "tokens": ["Gleich", "wie", "auff", "ei\u00b7nem", "Hoch\u00b7zeit\u00b7Mahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die gehen heim beyzeiten/", "tokens": ["Die", "ge\u00b7hen", "heim", "bey\u00b7zei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKVZ", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vnd diese sp\u00e4ter/ bi\u00df der Saal", "tokens": ["Vnd", "die\u00b7se", "sp\u00e4\u00b7ter", "/", "bi\u00df", "der", "Saal"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PDS", "ADJD", "$(", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gar einsam wird von Leuten/", "tokens": ["Gar", "ein\u00b7sam", "wird", "von", "Leu\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "APPR", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Vnd dann darauff in kurtzer Frist", "tokens": ["Vnd", "dann", "dar\u00b7auff", "in", "kurt\u00b7zer", "Frist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PAV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nur \u0153des Grawen ist.", "tokens": ["Nur", "\u0153des", "Gra\u00b7wen", "ist", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VAFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Wol vns vnd mehr als wol dabey", "tokens": ["Wol", "vns", "vnd", "mehr", "als", "wol", "da\u00b7bey"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "KON", "PIS", "KOKOM", "ADV", "PAV"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Da\u00df/ wenn wir sind gestorben/", "tokens": ["Da\u00df", "/", "wenn", "wir", "sind", "ge\u00b7stor\u00b7ben", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "KOUS", "PPER", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir werden durch den Tod erst frey/", "tokens": ["Wir", "wer\u00b7den", "durch", "den", "Tod", "erst", "frey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "ADV", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd gar nicht sind verdorben/", "tokens": ["Vnd", "gar", "nicht", "sind", "ver\u00b7dor\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Denn hier ist nur de\u00df Lebens Bann ", "tokens": ["Denn", "hier", "ist", "nur", "de\u00df", "Le\u00b7bens", "Bann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dort geht das Leben an.", "tokens": ["Dort", "geht", "das", "Le\u00b7ben", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Wo keine Tr\u00fcbsal keine List", "tokens": ["Wo", "kei\u00b7ne", "Tr\u00fcb\u00b7sal", "kei\u00b7ne", "List"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durchaus nicht hin kan kommen/", "tokens": ["Durc\u00b7haus", "nicht", "hin", "kan", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADV", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wo Gott das alles/ was er ist/", "tokens": ["Wo", "Gott", "das", "al\u00b7les", "/", "was", "er", "ist", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ART", "PIS", "$(", "PWS", "PPER", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu schawen giebt den Frommen/", "tokens": ["Zu", "scha\u00b7wen", "giebt", "den", "From\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wo man der Frewden \u00fcbrig hat", "tokens": ["Wo", "man", "der", "Frew\u00b7den", "\u00fcb\u00b7rig", "hat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ART", "NN", "ADJD", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vnd wird jhr nimmer sat.", "tokens": ["Vnd", "wird", "jhr", "nim\u00b7mer", "sat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Die\u00df ist zu dancken Christi Noht/", "tokens": ["Die\u00df", "ist", "zu", "dan\u00b7cken", "Chris\u00b7ti", "Noht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKZU", "VVINF", "NE", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der jetzt sich l\u00e4sst ermorden/", "tokens": ["Der", "jetzt", "sich", "l\u00e4sst", "er\u00b7mor\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PRF", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vnd als ist de\u00df Todes Tod", "tokens": ["Vnd", "als", "ist", "de\u00df", "To\u00b7des", "Tod"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOKOM", "VAFIN", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Der H\u00f6llen Pest geworden", "tokens": ["Der", "H\u00f6l\u00b7len", "Pest", "ge\u00b7wor\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VAPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Vnd hat de\u00df finstern Grabes Nacht", "tokens": ["Vnd", "hat", "de\u00df", "fins\u00b7tern", "Gra\u00b7bes", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zum s\u00fcssen Schlaff gemacht.", "tokens": ["Zum", "s\u00fcs\u00b7sen", "Schlaff", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Es kostet ihm kein zeitlich Gut", "tokens": ["Es", "kos\u00b7tet", "ihm", "kein", "zeit\u00b7lich", "Gut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vns wieder zu erwerben/", "tokens": ["Vns", "wie\u00b7der", "zu", "er\u00b7wer\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es that es nicht der Opffer Blut/", "tokens": ["Es", "that", "es", "nicht", "der", "Opf\u00b7fer", "Blut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er muste selber sterben", "tokens": ["Er", "mus\u00b7te", "sel\u00b7ber", "ster\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Vnd einen Tod zwar/ welcher gar", "tokens": ["Vnd", "ei\u00b7nen", "Tod", "zwar", "/", "wel\u00b7cher", "gar"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "NN", "ADV", "$(", "PRELS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Fluch vnd Grewel war.", "tokens": ["Ein", "Fluch", "vnd", "Gre\u00b7wel", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NE", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Die Last der S\u00fcnden ward jhm schwer", "tokens": ["Die", "Last", "der", "S\u00fcn\u00b7den", "ward", "jhm", "schwer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er trug sie allzusammen/", "tokens": ["Er", "trug", "sie", "all\u00b7zu\u00b7sam\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Gott st\u00fcrtzt auff jhn des Zornes Meer", "tokens": ["Gott", "st\u00fcrtzt", "auff", "jhn", "des", "Zor\u00b7nes", "Meer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "PPER", "ART", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Vnd seines Eiffers Flammen/", "tokens": ["Vnd", "sei\u00b7nes", "Eif\u00b7fers", "Flam\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Er sah' erb\u00e4rmlich vmb nach Raht", "tokens": ["Er", "sah'", "er\u00b7b\u00e4rm\u00b7lich", "vmb", "nach", "Raht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der weit weit vor jhm trat.", "tokens": ["Der", "weit", "weit", "vor", "jhm", "trat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Wo sind die mit so wenig Brod", "tokens": ["Wo", "sind", "die", "mit", "so", "we\u00b7nig", "Brod"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ART", "APPR", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von jhm ges\u00e4ttigt waren?", "tokens": ["Von", "jhm", "ge\u00b7s\u00e4t\u00b7tigt", "wa\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wo die in jhrer Kranckheit Noht", "tokens": ["Wo", "die", "in", "jhrer", "Kran\u00b7ck\u00b7heit", "Noht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Sein' heilsam' Hand erfahren?", "tokens": ["Sein'", "heil\u00b7sam'", "Hand", "er\u00b7fah\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Die J\u00fcnger s\u00e4mptlich fliehen auch", "tokens": ["Die", "J\u00fcn\u00b7ger", "s\u00e4mpt\u00b7lich", "flie\u00b7hen", "auch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie Bienen f\u00fcr dem Rauch.", "tokens": ["Wie", "Bie\u00b7nen", "f\u00fcr", "dem", "Rauch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Herr Jesu/ la\u00df die Todes-Pein", "tokens": ["Herr", "Je\u00b7su", "/", "la\u00df", "die", "To\u00b7des\u00b7Pein"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NE", "$(", "VVIMP", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vns zur Artzney gereichen/", "tokens": ["Vns", "zur", "Artz\u00b7ney", "ge\u00b7rei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "VVPP", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "O schleuss vns deinen Wunden ein/", "tokens": ["O", "schleuss", "vns", "dei\u00b7nen", "Wun\u00b7den", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PPOSAT", "NN", "ART", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Voraus wenn wir verbleichen", "tokens": ["Vo\u00b7raus", "wenn", "wir", "ver\u00b7blei\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "So f\u00fchr durch deine Todes-Qual", "tokens": ["So", "f\u00fchr", "durch", "dei\u00b7ne", "To\u00b7des\u00b7Qual"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vns in des Lebens-Saal.", "tokens": ["Vns", "in", "des", "Le\u00b7bens\u00b7Saal", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.14": {"line.1": {"text": "Die\u00df nahm die seelge Fraw in acht", "tokens": ["Die\u00df", "nahm", "die", "seel\u00b7ge", "Fraw", "in", "acht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "APPR", "CARD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als sie nun solte scheiden/", "tokens": ["Als", "sie", "nun", "sol\u00b7te", "schei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie gab den Ihren gutte Nacht/", "tokens": ["Sie", "gab", "den", "Ih\u00b7ren", "gut\u00b7te", "Nacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd in dem letzten Leiden", "tokens": ["Vnd", "in", "dem", "letz\u00b7ten", "Lei\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "War Jesus jhr Verstand vnd Mund", "tokens": ["War", "Je\u00b7sus", "jhr", "Ver\u00b7stand", "vnd", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NE", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie er am Creutze stund.", "tokens": ["Wie", "er", "am", "Creut\u00b7ze", "stund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Sie hat auch dessen Trost gemerckt", "tokens": ["Sie", "hat", "auch", "des\u00b7sen", "Trost", "ge\u00b7merckt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er ist jhr beygesprungen/", "tokens": ["Er", "ist", "jhr", "bey\u00b7ge\u00b7sprun\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hat in dem Tode sie gest\u00e4rckt", "tokens": ["Hat", "in", "dem", "To\u00b7de", "sie", "ge\u00b7st\u00e4rckt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der H\u00f6llen Macht bezwungen/", "tokens": ["Der", "H\u00f6l\u00b7len", "Macht", "be\u00b7zwun\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Vnd jhren Geist dahin gef\u00fchrt", "tokens": ["Vnd", "jhren", "Geist", "da\u00b7hin", "ge\u00b7f\u00fchrt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "PAV", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wo jhn kein Schmertz ber\u00fchrt.", "tokens": ["Wo", "jhn", "kein", "Schmertz", "be\u00b7r\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Jetzt schwebt sie bey jhm allezeit/", "tokens": ["Jetzt", "schwebt", "sie", "bey", "jhm", "al\u00b7le\u00b7zeit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist aller Noht entbunden/", "tokens": ["Ist", "al\u00b7ler", "Noht", "ent\u00b7bun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Lacht dieser Erden Eitelkeit", "tokens": ["Lacht", "die\u00b7ser", "Er\u00b7den", "Ei\u00b7tel\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PDAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd hat die Frewd' empfunden", "tokens": ["Vnd", "hat", "die", "Fre\u00b7wd'", "emp\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN", "VVPP"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Dergleichen sich kein Schatten h\u00e4lt", "tokens": ["Derg\u00b7lei\u00b7chen", "sich", "kein", "Schat\u00b7ten", "h\u00e4lt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "PRF", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In dieser gantzen Welt.", "tokens": ["In", "die\u00b7ser", "gant\u00b7zen", "Welt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Lasst diesen Trost nur bey Euch ein/", "tokens": ["Lasst", "die\u00b7sen", "Trost", "nur", "bey", "Euch", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "ADV", "APPR", "PPER", "ART", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fraw Sandinn/ Gottes Willen", "tokens": ["Fraw", "San\u00b7dinn", "/", "Got\u00b7tes", "Wil\u00b7len"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "NN", "$(", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "De\u00df ewren Zwang vnd Richtscheid seyn/", "tokens": ["De\u00df", "ew\u00b7ren", "Zwang", "vnd", "Richt\u00b7scheid", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er wird euch gnugsam stillen/", "tokens": ["Er", "wird", "euch", "gnug\u00b7sam", "stil\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Gott g\u00f6nnt jhr seiner Frewden Licht", "tokens": ["Gott", "g\u00f6nnt", "jhr", "sei\u00b7ner", "Frew\u00b7den", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das mi\u00dfg\u00f6nnt jhr Jhr nicht.", "tokens": ["Das", "mi\u00df\u00b7g\u00f6nnt", "jhr", "Ihr", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PPER", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}