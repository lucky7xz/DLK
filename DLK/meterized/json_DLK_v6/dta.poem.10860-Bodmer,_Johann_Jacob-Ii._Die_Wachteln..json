{"dta.poem.10860": {"metadata": {"author": {"name": "Bodmer, Johann Jacob", "birth": "N.A.", "death": "N.A."}, "title": "Ii.   Die Wachteln.", "genre": "Lyrik; Prosa", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-200905198310", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ein unzehlbares Wachtelnheer", "tokens": ["Ein", "un\u00b7zehl\u00b7ba\u00b7res", "Wach\u00b7teln\u00b7heer"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Befand sich allbereit am Strande,", "tokens": ["Be\u00b7fand", "sich", "all\u00b7be\u00b7reit", "am", "Stran\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und zielte st\u00fcndlich \u00fcber Meer", "tokens": ["Und", "ziel\u00b7te", "st\u00fcnd\u00b7lich", "\u00fc\u00b7ber", "Meer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nach jenem weitentlegnen Lande.", "tokens": ["Nach", "je\u00b7nem", "wei\u00b7tent\u00b7leg\u00b7nen", "Lan\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Eh sie die Reise unternahmen", "tokens": ["Eh", "sie", "die", "Rei\u00b7se", "un\u00b7ter\u00b7nah\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Verschl\u00fcckten sie den Bilsensamen,", "tokens": ["Ver\u00b7schl\u00fcck\u00b7ten", "sie", "den", "Bil\u00b7sen\u00b7sa\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wenn sie die Artzeney genommen,", "tokens": ["Wenn", "sie", "die", "Art\u00b7ze\u00b7ney", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Von ihrer Fettigkeit zu kommen;", "tokens": ["Von", "ih\u00b7rer", "Fet\u00b7tig\u00b7keit", "zu", "kom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Dieweil des Fettes schwere B\u00fcrde", "tokens": ["Die\u00b7weil", "des", "Fet\u00b7tes", "schwe\u00b7re", "B\u00fcr\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Sie sonst am Streichen hindern w\u00fcrde.", "tokens": ["Sie", "sonst", "am", "Strei\u00b7chen", "hin\u00b7dern", "w\u00fcr\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPRART", "NN", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Doch h\u00f6rte man die Jungen zancken,", "tokens": ["Doch", "h\u00f6r\u00b7te", "man", "die", "Jun\u00b7gen", "zan\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Die einen sagten: Wir erkrancken,", "tokens": ["Die", "ei\u00b7nen", "sag\u00b7ten", ":", "Wir", "er\u00b7kran\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$.", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Wenn wir so viele Tage fasten.", "tokens": ["Wenn", "wir", "so", "vie\u00b7le", "Ta\u00b7ge", "fas\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Die andern sprachen: Auszurasten,", "tokens": ["Die", "an\u00b7dern", "spra\u00b7chen", ":", "Aus\u00b7zu\u00b7ras\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "$.", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Ist auf dem unbegr\u00e4ntzten Meer", "tokens": ["Ist", "auf", "dem", "un\u00b7be\u00b7gr\u00e4ntz\u00b7ten", "Meer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Kein Aufenthalt f\u00fcr unser Heer.", "tokens": ["Kein", "Auf\u00b7ent\u00b7halt", "f\u00fcr", "un\u00b7ser", "Heer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Zudem ist unser schwacher Flug", "tokens": ["Zu\u00b7dem", "ist", "un\u00b7ser", "schwa\u00b7cher", "Flug"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Vom Untergange Vorboths gnug.", "tokens": ["Vom", "Un\u00b7ter\u00b7gan\u00b7ge", "Vor\u00b7boths", "gnug", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Die Alten sprachen: Sorget nicht,", "tokens": ["Die", "Al\u00b7ten", "spra\u00b7chen", ":", "Sor\u00b7get", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Es dienet euch zum Unterricht,", "tokens": ["Es", "die\u00b7net", "euch", "zum", "Un\u00b7ter\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Da\u00df wir nicht eh von Lande gehen,", "tokens": ["Da\u00df", "wir", "nicht", "eh", "von", "Lan\u00b7de", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "KOUS", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Bi\u00df da\u00df die guten Winde wehen.", "tokens": ["Bi\u00df", "da\u00df", "die", "gu\u00b7ten", "Win\u00b7de", "we\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Auch finden wir bey Sturm und Wetter", "tokens": ["Auch", "fin\u00b7den", "wir", "bey", "Sturm", "und", "Wet\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Jm Meer an allen Orten Bl\u00e4tter,", "tokens": ["Jm", "Meer", "an", "al\u00b7len", "Or\u00b7ten", "Bl\u00e4t\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Auf welche sich die M\u00fcden setzen,", "tokens": ["Auf", "wel\u00b7che", "sich", "die", "M\u00fc\u00b7den", "set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Und dieses sonder sich zu netzen.", "tokens": ["Und", "die\u00b7ses", "son\u00b7der", "sich", "zu", "net\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "KON", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Es ist uns noch ihr lieben Jungen,", "tokens": ["Es", "ist", "uns", "noch", "ihr", "lie\u00b7ben", "Jun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Auf allen Reisen wohl gelungen.", "tokens": ["Auf", "al\u00b7len", "Rei\u00b7sen", "wohl", "ge\u00b7lun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Die kluge Rede fand Geh\u00f6r,", "tokens": ["Die", "klu\u00b7ge", "Re\u00b7de", "fand", "Ge\u00b7h\u00f6r", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Sie machten sich gefa\u00dft zur Reise", "tokens": ["Sie", "mach\u00b7ten", "sich", "ge\u00b7fa\u00dft", "zur", "Rei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "VVPP", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Und thaten nach der Aeltern Weise.", "tokens": ["Und", "tha\u00b7ten", "nach", "der", "A\u00b7el\u00b7tern", "Wei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.32": {"text": "Jzt gieng der Zug hoch \u00fcber Meer,", "tokens": ["Jzt", "gieng", "der", "Zug", "hoch", "\u00fc\u00b7ber", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Und sie erfuhren gleich den Alten", "tokens": ["Und", "sie", "er\u00b7fuh\u00b7ren", "gleich", "den", "Al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "Da\u00df Jupiter die gantze Schaar", "tokens": ["Da\u00df", "Ju\u00b7pi\u00b7ter", "die", "gant\u00b7ze", "Schaar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Vor augenscheinlicher Gefahr", "tokens": ["Vor", "au\u00b7gen\u00b7schein\u00b7li\u00b7cher", "Ge\u00b7fahr"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Durch seinen weisen Schutz erhalten.", "tokens": ["Durch", "sei\u00b7nen", "wei\u00b7sen", "Schutz", "er\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}