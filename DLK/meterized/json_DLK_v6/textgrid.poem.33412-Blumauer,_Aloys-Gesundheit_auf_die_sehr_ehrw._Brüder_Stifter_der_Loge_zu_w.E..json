{"textgrid.poem.33412": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "Gesundheit auf die sehr ehrw. Br\u00fcder Stifter der Loge zu w.E.", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Auf, Br\u00fcder, la\u00dft uns jetzt den theuern", "tokens": ["Auf", ",", "Br\u00fc\u00b7der", ",", "la\u00dft", "uns", "jetzt", "den", "theu\u00b7ern"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "$,", "NN", "$,", "VVIMP", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Urhebern unsers Bund's ein Dankesopfer feiern,", "tokens": ["Ur\u00b7he\u00b7bern", "un\u00b7sers", "Bun\u00b7d's", "ein", "Dan\u00b7ke\u00b7sop\u00b7fer", "fei\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+--+-+--+-+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Damit wir nicht dem Strome gleich, \u2013", "tokens": ["Da\u00b7mit", "wir", "nicht", "dem", "Stro\u00b7me", "gleich", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ART", "NN", "ADV", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der klein am Quell, doch wasserreich", "tokens": ["Der", "klein", "am", "Quell", ",", "doch", "was\u00b7ser\u00b7reich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJD", "APPRART", "NN", "$,", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "In seinem Laufe ward, sich nur mit grossen Fl\u00fcssen,", "tokens": ["In", "sei\u00b7nem", "Lau\u00b7fe", "ward", ",", "sich", "nur", "mit", "gros\u00b7sen", "Fl\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "$,", "PRF", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Als wie mit seines Gleichen ma\u00df,", "tokens": ["Als", "wie", "mit", "sei\u00b7nes", "Glei\u00b7chen", "ma\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und seiner Quelle ganz verga\u00df, \u2013", "tokens": ["Und", "sei\u00b7ner", "Quel\u00b7le", "ganz", "ver\u00b7ga\u00df", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "VVFIN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Von ihr zur Lehre h\u00f6ren m\u00fcssen:", "tokens": ["Von", "ihr", "zur", "Leh\u00b7re", "h\u00f6\u00b7ren", "m\u00fcs\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "APPRART", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "\u00bbdu Stolzer br\u00fcstest jetzo dich;", "tokens": ["\u00bb", "du", "Stol\u00b7zer", "br\u00fcs\u00b7test", "jet\u00b7zo", "dich", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "NN", "VVFIN", "ADV", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Allein sag an, was w\u00e4rst du ohne mich?", "tokens": ["Al\u00b7lein", "sag", "an", ",", "was", "w\u00e4rst", "du", "oh\u00b7ne", "mich", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKVZ", "$,", "PWS", "VAFIN", "PPER", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "D'rum wisse: Wer vergi\u00dft, da\u00df er einst klein", "tokens": ["D'\u00b7rum", "wis\u00b7se", ":", "Wer", "ver\u00b7gi\u00dft", ",", "da\u00df", "er", "einst", "klein"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "$.", "PWS", "VVFIN", "$,", "KOUS", "PPER", "ADV", "ADJD"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.12": {"text": "In seinem Ursprung war, verdient nicht gro\u00df zu sein.\u00ab", "tokens": ["In", "sei\u00b7nem", "Ur\u00b7sprung", "war", ",", "ver\u00b7dient", "nicht", "gro\u00df", "zu", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "$,", "VVFIN", "PTKNEG", "ADJD", "PTKZU", "VAINF", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}