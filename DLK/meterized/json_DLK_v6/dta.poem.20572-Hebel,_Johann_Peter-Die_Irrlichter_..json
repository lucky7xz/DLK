{"dta.poem.20572": {"metadata": {"author": {"name": "Hebel, Johann Peter", "birth": "N.A.", "death": "N.A."}, "title": "Die Irrlichter .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1803", "urn": "urn:nbn:de:kobv:b4-200905192133", "language": ["de:0.99"], "booktitle": "[Hebel, Johann Peter]: Allemannische Gedichte. Karlsruhe, 1803."}, "poem": {"stanza.1": {"line.1": {"text": "Es wandlen in der stille dunkle Nacht               ", "tokens": ["Es", "wand\u00b7len", "in", "der", "stil\u00b7le", "dunk\u00b7le", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "wohl Engel um, mit Sterneblume gchr\u00f6nt,", "tokens": ["wohl", "En\u00b7gel", "um", ",", "mit", "Ster\u00b7ne\u00b7blu\u00b7me", "gchr\u00f6nt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PTKVZ", "$,", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "uf gr\u00fcne Matte, bis der Tag verwacht,", "tokens": ["uf", "gr\u00fc\u00b7ne", "Mat\u00b7te", ",", "bis", "der", "Tag", "ver\u00b7wacht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und do und d\u00f6rt e Betzit-Glocke t\u00f6nt.", "tokens": ["und", "do", "und", "d\u00f6rt", "e", "Bet\u00b7zit\u00b7Glo\u00b7cke", "t\u00f6nt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KON", "VVFIN", "NE", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Sie spr\u00f6che mitenander deis und das,", "tokens": ["Sie", "spr\u00f6\u00b7che", "mi\u00b7ten\u00b7an\u00b7der", "deis", "und", "das", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "KON", "PDS", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "sie machen \u00f6bbis mitenander us;", "tokens": ["sie", "ma\u00b7chen", "\u00f6b\u00b7bis", "mi\u00b7ten\u00b7an\u00b7der", "us", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u2019s sin gheimi Sache; niemes rothet, was?", "tokens": ["'s", "sin", "ghei\u00b7mi", "Sa\u00b7che", ";", "nie\u00b7mes", "ro\u00b7thet", ",", "was", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJA", "NN", "$.", "PIS", "VVFIN", "$,", "PWS", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Druf g\u00f6hn sie wieder furt, und richte\u2019s us.", "tokens": ["Druf", "g\u00f6hn", "sie", "wie\u00b7der", "furt", ",", "und", "rich\u00b7te's", "us", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,", "KON", "NE", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Und wenns so finster wird, wie in\u2019re Chue,", "tokens": ["Und", "wenns", "so", "fins\u00b7ter", "wird", ",", "wie", "in'\u00b7re", "Chue", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "ADJD", "VAFIN", "$,", "PWAV", "NE", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und wemme n\u00fcmme sieht, wo d\u2019Nu\u00dfb\u00e4um st\u00f6hn,", "tokens": ["und", "wem\u00b7me", "n\u00fcm\u00b7me", "sieht", ",", "wo", "d'\u00b7Nu\u00df\u00b7b\u00e4\u00b7um", "st\u00f6hn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$,", "PWAV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "was gschieht? se m\u00fc\u2019en die f\u00fc\u00fcrige Manne zu,", "tokens": ["was", "gschieht", "?", "se", "m\u00fc'\u00b7en", "die", "f\u00fc\u00fc\u00b7ri\u00b7ge", "Man\u00b7ne", "zu", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$.", "ADV", "VMFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "und m\u00fc\u2019en den Engle z\u00fcnde, wo sie g\u00f6hn.", "tokens": ["und", "m\u00fc'\u00b7en", "den", "Eng\u00b7le", "z\u00fcn\u00b7de", ",", "wo", "sie", "g\u00f6hn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "VVFIN", "$,", "PWAV", "PPER", "VVINF", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "Und iedem hangt e Bederthalben a,", "tokens": ["Und", "ie\u00b7dem", "hangt", "e", "Be\u00b7der\u00b7thal\u00b7ben", "a", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "NE", "NN", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und wenns em \u00f6d wird, lengt er ebe dri,", "tokens": ["und", "wenns", "em", "\u00f6d", "wird", ",", "lengt", "er", "e\u00b7be", "dri", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADJA", "ADJD", "VAFIN", "$,", "VVFIN", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und bii\u00dft e St\u00fcckli Schwefelschnitten a,", "tokens": ["und", "bii\u00dft", "e", "St\u00fcck\u00b7li", "Schwe\u00b7fel\u00b7schnit\u00b7ten", "a", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "NE", "NN", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und trinkt e Schl\u00fcckli Treber-Brentewi.", "tokens": ["und", "trinkt", "e", "Schl\u00fcck\u00b7li", "Tre\u00b7ber\u00b7B\u00b7ren\u00b7te\u00b7wi", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "NE", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Druf puzt er d\u2019Schn\u00f6ren amme Tsch\u00e4ubli ab;", "tokens": ["Druf", "puzt", "er", "d'\u00b7Schn\u00f6\u00b7ren", "am\u00b7me", "Tsch\u00e4ub\u00b7li", "ab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PDS", "VVFIN", "NE", "PTKVZ", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Hui, flackerets in liechte Flammen uf,", "tokens": ["Hui", ",", "fla\u00b7cke\u00b7rets", "in", "liech\u00b7te", "Flam\u00b7men", "uf", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "$,", "VVFIN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und, hui, gohts wieder d\u2019Matten uf und ab,", "tokens": ["und", ",", "hui", ",", "gohts", "wie\u00b7der", "d'\u00b7Mat\u00b7ten", "uf", "und", "ab", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "FM.la", "$,", "ADV", "ADV", "ADJA", "NN", "KON", "PTKVZ", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "mit neue Chr\u00e4fte, d\u2019 Matten ab und uf.", "tokens": ["mit", "neu\u00b7e", "Chr\u00e4f\u00b7te", ",", "d'", "Mat\u00b7ten", "ab", "und", "uf", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "NE", "NE", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "\u2019s isch chummliger so, wenn eim vorem Fu\u00df", "tokens": ["'s", "isch", "chumm\u00b7li\u00b7ger", "so", ",", "wenn", "eim", "vo\u00b7rem", "Fu\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADJD", "ADJA", "ADV", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "und vor den Auge d\u2019Togge selber rennt,", "tokens": ["und", "vor", "den", "Au\u00b7ge", "d'\u00b7Tog\u00b7ge", "sel\u00b7ber", "rennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PDS", "ADV", "VVFIN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "a\u00df wemme sie mit H\u00e4nde trage mu\u00df,", "tokens": ["a\u00df", "wem\u00b7me", "sie", "mit", "H\u00e4n\u00b7de", "tra\u00b7ge", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVFIN", "PPER", "APPR", "NN", "VVFIN", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und \u00f6bbe gar no d\u2019Finger dra verbrennt.", "tokens": ["und", "\u00f6b\u00b7be", "gar", "no", "d'\u00b7Fin\u00b7ger", "dra", "ver\u00b7brennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "NE", "NE", "NE", "VVFIN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.7": {"line.1": {"text": "Und schriket spot e Mensch dur d\u2019Nacht derher,", "tokens": ["Und", "schri\u00b7ket", "spot", "e", "Mensch", "dur", "d'\u00b7Nacht", "der\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "und sieht vo witem scho die Kerli goh,", "tokens": ["und", "sieht", "vo", "wi\u00b7tem", "scho", "die", "Ker\u00b7li", "goh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "FM", "FM", "FM", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und betet lisli: \u201eDas walt Gott der Her\u201c\u2014", "tokens": ["und", "be\u00b7tet", "lis\u00b7li", ":", "\u201e", "Das", "walt", "Gott", "der", "Her", "\u201c"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "NE", "$.", "$(", "PDS", "VVFIN", "NN", "ART", "NN", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "\u201each bleib bey uns\u201c \u2014 im Wetter sin sie do.", "tokens": ["\u201e", "ach", "bleib", "bey", "uns", "\u201c", "im", "Wet\u00b7ter", "sin", "sie", "do."], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "abbreviation"], "pos": ["$(", "ITJ", "VVFIN", "APPR", "PPER", "$(", "$(", "APPRART", "NN", "VAFIN", "PPER", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.8": {"line.1": {"text": "Worum? So bald der Engel bete h\u00f6rt,", "tokens": ["Wo\u00b7rum", "?", "So", "bald", "der", "En\u00b7gel", "be\u00b7te", "h\u00f6rt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "ADV", "ADV", "ART", "NN", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "se heimelets en a, er m\u00f6cht derzu.", "tokens": ["se", "hei\u00b7me\u00b7lets", "en", "a", ",", "er", "m\u00f6cht", "der\u00b7zu", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "$,", "PPER", "VMFIN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der f\u00fc\u00fcrig Marcher blieb io lieber d\u00f6rt,", "tokens": ["Der", "f\u00fc\u00fc\u00b7rig", "Mar\u00b7cher", "blieb", "i\u00b7o", "lie\u00b7ber", "d\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "und wenn er chunnt, se hebt er d\u2019 Ohre zu.", "tokens": ["und", "wenn", "er", "chunnt", ",", "se", "hebt", "er", "d'", "Oh\u00b7re", "zu", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "$,", "ADV", "VVFIN", "PPER", "NE", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.9": {"line.1": {"text": "Und schritet\u00f6bsch e trunk\u2019ne Ma dur d\u2019 Nacht,", "tokens": ["Und", "schri\u00b7te\u00b7t\u00f6bsch", "e", "trunk'\u00b7ne", "Ma", "dur", "d'", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "FM", "FM", "FM", "FM", "FM", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "er fluecht und sappermentet: \u201eChr\u00fctz und Stern,\u201c", "tokens": ["er", "fluecht", "und", "sap\u00b7per\u00b7men\u00b7tet", ":", "\u201e", "Chr\u00fctz", "und", "Stern", ",", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$.", "$(", "NE", "KON", "NN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und alli Zeichen, a\u00df der Bode chracht,", "tokens": ["und", "al\u00b7li", "Zei\u00b7chen", ",", "a\u00df", "der", "Bo\u00b7de", "chracht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "sell h\u00f6rti wohl der f\u00fc\u00fcrig Marcher gern.", "tokens": ["sell", "h\u00f6r\u00b7ti", "wohl", "der", "f\u00fc\u00fc\u00b7rig", "Mar\u00b7cher", "gern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ADV", "ART", "ADJD", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Doch wirds em nit so gut; der Engel seit:", "tokens": ["Doch", "wirds", "em", "nit", "so", "gut", ";", "der", "En\u00b7gel", "seit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIS", "PTKNEG", "ADV", "ADJD", "$.", "ART", "NN", "APPR", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u201efurt, weidli furt! Do magi n\u00fct dervo!\u201c", "tokens": ["\u201e", "furt", ",", "weid\u00b7li", "furt", "!", "Do", "ma\u00b7gi", "n\u00fct", "der\u00b7vo", "!", "\u201c"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "$,", "VVFIN", "PTKVZ", "$.", "FM.la", "FM.la", "FM.la", "FM.la", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Im Wetterleich, sen isch der wiit und breit", "tokens": ["Im", "Wet\u00b7ter\u00b7leich", ",", "sen", "isch", "der", "wiit", "und", "breit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "ADV", "ADJD", "ART", "NN", "KON", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "kei Marcher me, und au kei Engel do.", "tokens": ["kei", "Mar\u00b7cher", "me", ",", "und", "au", "kei", "En\u00b7gel", "do."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "abbreviation"], "pos": ["PIAT", "NN", "VVFIN", "$,", "KON", "NE", "PIAT", "NN", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "doch goht me still si Gang in Gottis G\u2019leit,", "tokens": ["doch", "goht", "me", "still", "si", "Gang", "in", "Got\u00b7tis", "G'\u00b7leit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "FM", "FM", "FM", "FM", "NN", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.2": {"text": "und denkt: \u201eDer ch\u00f6nnet bliben oder cho,", "tokens": ["und", "denkt", ":", "\u201e", "Der", "ch\u00f6n\u00b7net", "bli\u00b7ben", "o\u00b7der", "cho", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "ART", "NE", "VVFIN", "KON", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u201ene jede wei\u00df si Weg, und\u2019s Thal isch breit,\u201c", "tokens": ["\u201e", "ne", "je\u00b7de", "wei\u00df", "si", "Weg", ",", "un\u00b7d's", "Thal", "isch", "breit", ",", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "PIAT", "VVFIN", "ADJA", "NN", "$,", "KON", "NN", "ADJD", "ADJD", "$,", "$("], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "sel isch \u2019s vern\u00fcnftigst, und sie l\u00f6n ein go.", "tokens": ["sel", "isch", "'s", "ver\u00b7n\u00fcnf\u00b7tigst", ",", "und", "sie", "l\u00f6n", "ein", "go", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VVFIN", "$,", "KON", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.12": {"line.1": {"text": "Doch wenn der Wunderwitz ein \u00f6bbe brennt,", "tokens": ["Doch", "wenn", "der", "Wun\u00b7der\u00b7witz", "ein", "\u00f6b\u00b7be", "brennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "me lauft im Uhverstand den Engle no,", "tokens": ["me", "lauft", "im", "Uh\u00b7ver\u00b7stand", "den", "Eng\u00b7le", "no", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVFIN", "APPRART", "NN", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "jel isch ene wie Gift und Poperment;", "tokens": ["jel", "isch", "e\u00b7ne", "wie", "Gift", "und", "Po\u00b7per\u00b7ment", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJA", "KOKOM", "NN", "KON", "NN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "im Augeblick se l\u00f6n sie alles stoh.", "tokens": ["im", "Au\u00b7ge\u00b7blick", "se", "l\u00f6n", "sie", "al\u00b7les", "stoh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "FM", "FM", "PPER", "PIS", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Z\u2019erst sage sie: \u201eDenkwol es isch si Weg,", "tokens": ["Z'\u00b7erst", "sa\u00b7ge", "sie", ":", "\u201e", "Denk\u00b7wol", "es", "isch", "si", "Weg", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "$(", "KON", "PPER", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "\u201eer goht verbey, mer wen e wenig z\u2019ruk!\u201c", "tokens": ["\u201e", "er", "goht", "ver\u00b7bey", ",", "mer", "wen", "e", "we\u00b7nig", "z'\u00b7ruk", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "NN", "PTKVZ", "$,", "ADV", "PWS", "NE", "PIAT", "NN", "$.", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "So sage sie, und wandle still us weg,", "tokens": ["So", "sa\u00b7ge", "sie", ",", "und", "wand\u00b7le", "still", "us", "weg", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KON", "VVFIN", "ADJD", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und sieder nimmt der f\u00fc\u00fcrig Ma ne Schluck.", "tokens": ["und", "sie\u00b7der", "nimmt", "der", "f\u00fc\u00fc\u00b7rig", "Ma", "ne", "Schluck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "ADJD", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Doch folgt me witers \u00fcber Steg und Bort,", "tokens": ["Doch", "folgt", "me", "wi\u00b7ters", "\u00fc\u00b7ber", "Steg", "und", "Bort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "wo nummen au der Engel goht und stoht,", "tokens": ["wo", "num\u00b7men", "au", "der", "En\u00b7gel", "goht", "und", "stoht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "NE", "ART", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "se seit er z\u2019lezt: \u201eWas gilts i find en Ort,", "tokens": ["se", "seit", "er", "z'\u00b7lezt", ":", "\u201e", "Was", "gilts", "i", "find", "en", "Ort", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "VVFIN", "$.", "$(", "PWS", "VVFIN", "FM", "FM", "FM", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "\u201edu Lappi, wo di Weg nit dure goht!\u201c", "tokens": ["\u201e", "du", "Lap\u00b7pi", ",", "wo", "di", "Weg", "nit", "du\u00b7re", "goht", "!", "\u201c"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "NE", "$,", "PWAV", "NE", "NN", "PTKNEG", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Der Marcher mu\u00df vora; mit stillem Tritt", "tokens": ["Der", "Mar\u00b7cher", "mu\u00df", "vo\u00b7ra", ";", "mit", "stil\u00b7lem", "Tritt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "NE", "$.", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "der Engel hinterher, und lauft me no,", "tokens": ["der", "En\u00b7gel", "hin\u00b7ter\u00b7her", ",", "und", "lauft", "me", "no", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "KON", "VVFIN", "FM", "FM", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "se sinkt men in e G\u00fclle, \u2019s fehlt si nit.", "tokens": ["se", "sinkt", "men", "in", "e", "G\u00fcl\u00b7le", ",", "'s", "fehlt", "si", "nit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "APPR", "NE", "NE", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Jez weisch di B\u2019richt, und jez chasch wieder goh!", "tokens": ["Jez", "weisch", "di", "B'\u00b7richt", ",", "und", "jez", "cha\u00b7sch", "wie\u00b7der", "goh", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "NE", "NN", "$,", "KON", "ADV", "ADJD", "ADV", "ADJD", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}}}}}