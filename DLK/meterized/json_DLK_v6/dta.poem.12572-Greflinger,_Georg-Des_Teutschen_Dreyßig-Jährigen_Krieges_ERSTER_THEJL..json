{"dta.poem.12572": {"metadata": {"author": {"name": "Greflinger, Georg", "birth": "N.A.", "death": "N.A."}, "title": "Des  \n Teutschen  \n Drey\u00dfig-J\u00e4hrigen Krieges  \n  ERSTER THEJL.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1657", "urn": "urn:nbn:de:kobv:b4-200905199036", "language": ["de:0.99"], "booktitle": "Celadon von der Donau [i. e. Greflinger, Georg]: Der Deutschen Drey\u00dfig-J\u00e4hriger Krjeg. [s. l.], 1657."}, "poem": {"stanza.1": {"line.1": {"text": "Der ungeheure Krieg/ den B\u00f6h\u00e4imb hat emp\u00f6-\nret/", "tokens": ["Der", "un\u00b7ge\u00b7heu\u00b7re", "Krieg", "/", "den", "B\u00f6\u00b7h\u00e4i\u00b7mb", "hat", "em\u00b7p\u00f6", "ret", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NE", "VAFIN", "TRUNC", "VVFIN", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der unser Deutsches Reich nechst B\u00f6h\u00e4imb hat", "tokens": ["Der", "un\u00b7ser", "Deut\u00b7sches", "Reich", "nechst", "B\u00f6\u00b7h\u00e4i\u00b7mb", "hat"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "VVFIN", "NE", "VAFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "zerst\u00f6ret/", "tokens": ["zer\u00b7st\u00f6\u00b7ret", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Also/ da\u00df es zuletzt\u2019 ein Denckmal oder Schein", "tokens": ["Al\u00b7so", "/", "da\u00df", "es", "zu\u00b7letzt'", "ein", "Denck\u00b7mal", "o\u00b7der", "Schein"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$(", "KOUS", "PPER", "ADV", "ART", "NN", "KON", "NN"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Des alten Landes war/ sol meine Rede seyn.", "tokens": ["Des", "al\u00b7ten", "Lan\u00b7des", "war", "/", "sol", "mei\u00b7ne", "Re\u00b7de", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$(", "VMFIN", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hilff mier ", "tokens": ["Hilff", "mier"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Da\u00df meine Rede sich nach dem Verlauffe richte.", "tokens": ["Da\u00df", "mei\u00b7ne", "Re\u00b7de", "sich", "nach", "dem", "Ver\u00b7lauf\u00b7fe", "rich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PRF", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Vom Anfang wei\u00df ich nicht/ weil ich in solchem Jahr\u2019/", "tokens": ["Vom", "An\u00b7fang", "wei\u00df", "ich", "nicht", "/", "weil", "ich", "in", "sol\u00b7chem", "Jahr'", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PTKNEG", "$(", "KOUS", "PPER", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Als sich der Krieg erhob/ noch ungebohren war.", "tokens": ["Als", "sich", "der", "Krieg", "er\u00b7hob", "/", "noch", "un\u00b7ge\u00b7boh\u00b7ren", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "VVFIN", "$(", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "und darumb sag\u2019es mier/ wie ist der Krieg entstanden?", "tokens": ["und", "da\u00b7rumb", "sag'\u00b7es", "mier", "/", "wie", "ist", "der", "Krieg", "ent\u00b7stan\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "$(", "KOKOM", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "H\u00f6r: Als halb B\u00f6h\u00e4imb fast/ ein Reich in unsern Landen/", "tokens": ["H\u00f6r", ":", "Als", "halb", "B\u00f6\u00b7h\u00e4i\u00b7mb", "fast", "/", "ein", "Reich", "in", "un\u00b7sern", "Lan\u00b7den", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "KOUS", "ADJD", "NE", "ADV", "$(", "ART", "NN", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.12": {"text": "Dem Pabste widrig fiel/ und von der Tyranney/", "tokens": ["Dem", "Pabs\u00b7te", "wid\u00b7rig", "fiel", "/", "und", "von", "der", "Ty\u00b7ran\u00b7ney", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$(", "KON", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die das Gewissen zwung/ begehrte franck und frey", "tokens": ["Die", "das", "Ge\u00b7wis\u00b7sen", "zwung", "/", "be\u00b7gehr\u00b7te", "franck", "und", "frey"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "NN", "$(", "ADJA", "NN", "KON", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Zu leben/ (Dann es war den Evangelschen St\u00e4nden", "tokens": ["Zu", "le\u00b7ben", "/", "(", "Dann", "es", "war", "den", "E\u00b7van\u00b7gel\u00b7schen", "St\u00e4n\u00b7den"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$(", "$(", "ADV", "PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "In diesem K\u00f6nigreich\u2019 aus K\u00e4yser-Rudolffs H\u00e4nden", "tokens": ["In", "die\u00b7sem", "K\u00f6\u00b7nig\u00b7reich'", "aus", "K\u00e4y\u00b7ser\u00b7Ru\u00b7dolffs", "H\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "APPR", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ein Freyheits-Brief ", "tokens": ["Ein", "Frey\u00b7heits\u00b7Brief"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.17": {"text": "Und Freyheit frey zu seyn/ den auch Matthiens Krohn", "tokens": ["Und", "Frey\u00b7heit", "frey", "zu", "seyn", "/", "den", "auch", "Mat\u00b7thiens", "Krohn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NN", "ADJD", "PTKZU", "VAINF", "$(", "ART", "ADV", "NE", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.18": {"text": "In seinen W\u00fcrden lie\u00df/ noch gleichwol waren Leuthe/", "tokens": ["In", "sei\u00b7nen", "W\u00fcr\u00b7den", "lie\u00df", "/", "noch", "gleich\u00b7wol", "wa\u00b7ren", "Leu\u00b7the", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$(", "ADV", "ADV", "VAFIN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Die allerhand Verdru\u00df erregten/ und zum Streite", "tokens": ["Die", "al\u00b7ler\u00b7hand", "Ver\u00b7dru\u00df", "er\u00b7reg\u00b7ten", "/", "und", "zum", "Strei\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "VVINF", "$(", "KON", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Den L\u00e4rmen blaseten/ bald kam des K\u00e4ysers Hand", "tokens": ["Den", "L\u00e4r\u00b7men", "bla\u00b7se\u00b7ten", "/", "bald", "kam", "des", "K\u00e4y\u00b7sers", "Hand"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "$(", "ADV", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Mit ernstlichem Befehl die Kirche/ derer Stand", "tokens": ["Mit", "ernst\u00b7li\u00b7chem", "Be\u00b7fehl", "die", "Kir\u00b7che", "/", "de\u00b7rer", "Stand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "$(", "PDS", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Auf des Braunauschen Apts Gebiete war/ zu f\u00e4llen/", "tokens": ["Auf", "des", "Braun\u00b7au\u00b7schen", "Apts", "Ge\u00b7bie\u00b7te", "war", "/", "zu", "f\u00e4l\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "NN", "VAFIN", "$(", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "und ihren Gottesdienst daselbsten abzust\u00e4llen/", "tokens": ["und", "ih\u00b7ren", "Got\u00b7tes\u00b7dienst", "da\u00b7selbs\u00b7ten", "ab\u00b7zu\u00b7st\u00e4l\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Bald folgte das Gebot den jenen/ der hierin", "tokens": ["Bald", "folg\u00b7te", "das", "Ge\u00b7bot", "den", "je\u00b7nen", "/", "der", "hie\u00b7rin"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "PDAT", "$(", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Sich widrig sehen lie\u00df/ gefangen einzuziehn/", "tokens": ["Sich", "wid\u00b7rig", "se\u00b7hen", "lie\u00df", "/", "ge\u00b7fan\u00b7gen", "ein\u00b7zu\u00b7ziehn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVINF", "VVFIN", "$(", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Di\u00df alles kam ins Werck. Die Evangelsche St\u00e4nde", "tokens": ["Di\u00df", "al\u00b7les", "kam", "ins", "Werck", ".", "Die", "E\u00b7van\u00b7gel\u00b7sche", "St\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "PIS", "VVFIN", "APPRART", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.27": {"text": "Beschwerten sich hierob und baten umb ein Ende", "tokens": ["Be\u00b7schwer\u00b7ten", "sich", "hier\u00b7ob", "und", "ba\u00b7ten", "umb", "ein", "En\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ADV", "KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "von solcher ", "tokens": ["von", "sol\u00b7cher"], "token_info": ["word", "word"], "pos": ["APPR", "PIAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.29": {"text": "Je mehr ihr Gottes dienst bey der Romanschen Schaar", "tokens": ["Je", "mehr", "ihr", "Got\u00b7tes", "dienst", "bey", "der", "Ro\u00b7man\u00b7schen", "Schaar"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "+--+-+--+--+", "measure": "iambic.penta.invert"}, "line.30": {"text": "In Schimpf und Last verfiel/ daher sie sich zusammen", "tokens": ["In", "Schimpf", "und", "Last", "ver\u00b7fiel", "/", "da\u00b7her", "sie", "sich", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$(", "PAV", "PPER", "PRF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "In dem sehr grossen Prag verf\u00fcgten (Blut und Flammen", "tokens": ["In", "dem", "sehr", "gros\u00b7sen", "Prag", "ver\u00b7f\u00fcg\u00b7ten", "(", "Blut", "und", "Flam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "ADV", "ADJA", "NN", "VVFIN", "$(", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Erschienen diesen Tag) die K\u00e4yserliche Herrn", "tokens": ["Er\u00b7schie\u00b7nen", "die\u00b7sen", "Tag", ")", "die", "K\u00e4y\u00b7ser\u00b7li\u00b7che", "Herrn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PDAT", "NN", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "(der K\u00e4yser selbst war nun von B\u00f6h\u00e4imb etwas ferrn", "tokens": ["(", "der", "K\u00e4y\u00b7ser", "selbst", "war", "nun", "von", "B\u00f6\u00b7h\u00e4i\u00b7mb", "et\u00b7was", "ferrn"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "ADV", "VAFIN", "ADV", "APPR", "NE", "PIAT", "NN"], "meter": "-+--+--+-++-+", "measure": "amphibrach.tri.plus"}, "line.34": {"text": "und in dem sch\u00f6nen Wien) zu bitten/ die Beschwerden", "tokens": ["und", "in", "dem", "sch\u00f6\u00b7nen", "Wi\u00b7en", ")", "zu", "bit\u00b7ten", "/", "die", "Be\u00b7schwer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NE", "$(", "PTKZU", "VVINF", "$(", "ART", "NN"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.35": {"text": "Zu lindern/ eh es noch hiemit m\u00f6cht\u2019 \u00e4rger werden.", "tokens": ["Zu", "lin\u00b7dern", "/", "eh", "es", "noch", "hie\u00b7mit", "m\u00f6cht'", "\u00e4r\u00b7ger", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$(", "KOUS", "PPER", "ADV", "PAV", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Wie aber jeglich Theil bey seiner Meynung blieb", "tokens": ["Wie", "a\u00b7ber", "jeg\u00b7lich", "Theil", "bey", "sei\u00b7ner", "Mey\u00b7nung", "blieb"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "PIAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "und endlich auch der Zorn die Hand zur Rache trieb/)", "tokens": ["und", "end\u00b7lich", "auch", "der", "Zorn", "die", "Hand", "zur", "Ra\u00b7che", "trieb", "/", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "NN", "ART", "NN", "APPRART", "NN", "VVFIN", "$(", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Ach! sihe da/ da kam die Z\u00e4nckerey zum Streiten/", "tokens": ["Ach", "!", "si\u00b7he", "da", "/", "da", "kam", "die", "Z\u00e4n\u00b7cke\u00b7rey", "zum", "Strei\u00b7ten", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "ADV", "$(", "ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Worob man ihrer drey von K\u00e4yserlicher Seiten/", "tokens": ["Wo\u00b7rob", "man", "ih\u00b7rer", "drey", "von", "K\u00e4y\u00b7ser\u00b7li\u00b7cher", "Sei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPOSAT", "CARD", "APPR", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Als Grafen Slabata und Grafen Marteniz", "tokens": ["Als", "Gra\u00b7fen", "Sla\u00b7ba\u00b7ta", "und", "Gra\u00b7fen", "Mar\u00b7te\u00b7niz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "NE", "KON", "NN", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Nechst ihres innern Rahts Verfassern den Fabriz", "tokens": ["Nechst", "ih\u00b7res", "in\u00b7nern", "Rahts", "Ver\u00b7fas\u00b7sern", "den", "Fab\u00b7riz"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Aus hohen Fenstern ", "tokens": ["Aus", "ho\u00b7hen", "Fens\u00b7tern"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.43": {"text": "Vor Sie zu P\u00e4bstisch war/ da flog zugleich mit ihnen", "tokens": ["Vor", "Sie", "zu", "P\u00e4bs\u00b7tisch", "war", "/", "da", "flog", "zu\u00b7gleich", "mit", "ih\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "APPR", "NE", "VAFIN", "$(", "ADV", "VVFIN", "ADV", "APPR", "PPER"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Di\u00df Feuer in die Welt. Ach! da\u00df uns dessen Macht", "tokens": ["Di\u00df", "Feu\u00b7er", "in", "die", "Welt", ".", "Ach", "!", "da\u00df", "uns", "des\u00b7sen", "Macht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "NN", "APPR", "ART", "NN", "$.", "ITJ", "$.", "KOUS", "PPER", "PDS", "NN"], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.45": {"text": "Nicht gr\u00f6ssern Schaden hett\u2019 in unser Reich gebracht/", "tokens": ["Nicht", "gr\u00f6s\u00b7sern", "Scha\u00b7den", "hett'", "in", "un\u00b7ser", "Reich", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJA", "NN", "VAFIN", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Als ihnen dieser Sturz. Sie blieben bey dem Leben/", "tokens": ["Als", "ih\u00b7nen", "die\u00b7ser", "Sturz", ".", "Sie", "blie\u00b7ben", "bey", "dem", "Le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDAT", "NN", "$.", "PPER", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "uns Deutschen aber hat ihr Fall den Tod gegeben/", "tokens": ["uns", "Deut\u00b7schen", "a\u00b7ber", "hat", "ihr", "Fall", "den", "Tod", "ge\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ADV", "VAFIN", "PPOSAT", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Wier zappeln nur noch was. Matthias/ der die Krohn", "tokens": ["Wier", "zap\u00b7peln", "nur", "noch", "was", ".", "Mat\u00b7thi\u00b7as", "/", "der", "die", "Krohn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "PIS", "$.", "NE", "$(", "ART", "ART", "NN"], "meter": "----+-+-+--+", "measure": "iambic.tetra.chol"}, "line.49": {"text": "Von B\u00f6h\u00e4ims Landen trug und auch den K\u00e4yser-Thron", "tokens": ["Von", "B\u00f6\u00b7h\u00e4i\u00b7ms", "Lan\u00b7den", "trug", "und", "auch", "den", "K\u00e4y\u00b7ser\u00b7Thron"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "NN", "VVFIN", "KON", "ADV", "ART", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.50": {"text": "Besa\u00df/ nahm diese That/ an seinen Lieb- und Treuen", "tokens": ["Be\u00b7sa\u00df", "/", "nahm", "die\u00b7se", "That", "/", "an", "sei\u00b7nen", "Lie\u00b7b", "und", "Treu\u00b7en"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$(", "VVFIN", "PDAT", "NN", "$(", "APPR", "PPOSAT", "TRUNC", "KON", "NN"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.51": {"text": "Begangen/ \u00fcbel auf. Da war auch kein bereuen.", "tokens": ["Be\u00b7gan\u00b7gen", "/", "\u00fc\u00b7bel", "auf", ".", "Da", "war", "auch", "kein", "be\u00b7reu\u00b7en", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ADJD", "PTKVZ", "$.", "ADV", "VAFIN", "ADV", "PIAT", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Es schien in dieser That Jhm viel zu viel gethan/", "tokens": ["Es", "schien", "in", "die\u00b7ser", "That", "Jhm", "viel", "zu", "viel", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "NN", "PPER", "ADV", "PTKA", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Er sah auch \u00fcber di\u00df mit tr\u00fcben Augen an/", "tokens": ["Er", "sah", "auch", "\u00fc\u00b7ber", "di\u00df", "mit", "tr\u00fc\u00b7ben", "Au\u00b7gen", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PDS", "APPR", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Wie alles wider Jhn sich in die Waffen machte.", "tokens": ["Wie", "al\u00b7les", "wi\u00b7der", "Jhn", "sich", "in", "die", "Waf\u00b7fen", "mach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPR", "PPER", "PRF", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Dann h\u00f6r: Als dieses Volck den Sachen nach gedachte/", "tokens": ["Dann", "h\u00f6r", ":", "Als", "die\u00b7ses", "Volck", "den", "Sa\u00b7chen", "nach", "ge\u00b7dach\u00b7te", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "KOUS", "PDAT", "NN", "ART", "NN", "APPR", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Befund es alsobald/ es w\u00fcrde diese That", "tokens": ["Be\u00b7fund", "es", "al\u00b7so\u00b7bald", "/", "es", "w\u00fcr\u00b7de", "die\u00b7se", "That"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$(", "PPER", "VAFIN", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Des gro\u00dfen K\u00e4ysers Hertz/ als dessen Majestat", "tokens": ["Des", "gro\u00b7\u00dfen", "K\u00e4y\u00b7sers", "Hertz", "/", "als", "des\u00b7sen", "Ma\u00b7jes\u00b7tat"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "$(", "KOUS", "PRELAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Hiemit verletzet war/ zu Rach und Streit bewegen/", "tokens": ["Hie\u00b7mit", "ver\u00b7let\u00b7zet", "war", "/", "zu", "Rach", "und", "Streit", "be\u00b7we\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VAFIN", "$(", "APPR", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Drum nahm es sich in acht/ und lie\u00df die Drummel regen/", "tokens": ["Drum", "nahm", "es", "sich", "in", "acht", "/", "und", "lie\u00df", "die", "Drum\u00b7mel", "re\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "APPR", "CARD", "$(", "KON", "VVFIN", "ART", "NN", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Lie\u00df durch den Herrn von Thurn jhm allen Abbruch thun.", "tokens": ["Lie\u00df", "durch", "den", "Herrn", "von", "Thurn", "jhm", "al\u00b7len", "Ab\u00b7bruch", "thun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "APPR", "NE", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Gantz B\u00f6h\u00e4imb waffnete. Da solcher Aufstand nun", "tokens": ["Gantz", "B\u00f6\u00b7h\u00e4i\u00b7mb", "waff\u00b7ne\u00b7te", ".", "Da", "sol\u00b7cher", "Auf\u00b7stand", "nun"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "NE", "VVFIN", "$.", "ADV", "PIAT", "NN", "ADV"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.62": {"text": "Den K\u00e4yser gelten solt/ ergriff er seine Waffen", "tokens": ["Den", "K\u00e4y\u00b7ser", "gel\u00b7ten", "solt", "/", "er\u00b7griff", "er", "sei\u00b7ne", "Waf\u00b7fen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "VMFIN", "$(", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "und schickte den Tampier den L\u00e4rmen ab zu straffen/", "tokens": ["und", "schick\u00b7te", "den", "Tam\u00b7pier", "den", "L\u00e4r\u00b7men", "ab", "zu", "straf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Er kam mit einem Heer und fiel die B\u00f6hmen an/", "tokens": ["Er", "kam", "mit", "ei\u00b7nem", "Heer", "und", "fiel", "die", "B\u00f6h\u00b7men", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Es wurd jhm aber bald solch Widerstand gethan/", "tokens": ["Es", "wurd", "jhm", "a\u00b7ber", "bald", "solch", "Wi\u00b7der\u00b7stand", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Der ihm zum Schaden war. Di\u00df anders anzustellen/", "tokens": ["Der", "ihm", "zum", "Scha\u00b7den", "war", ".", "Di\u00df", "an\u00b7ders", "an\u00b7zu\u00b7stel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "VAFIN", "$.", "PDS", "ADV", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Beschrieb man dieses Volck von B\u00f6haimb f\u00fcr Rebellen/", "tokens": ["Be\u00b7schrieb", "man", "die\u00b7ses", "Volck", "von", "B\u00f6\u00b7haimb", "f\u00fcr", "Re\u00b7bel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PDAT", "NN", "APPR", "NE", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Und st\u00e4rckte den Tampier/ der dann sein b\u00e4stes that.", "tokens": ["Und", "st\u00e4rck\u00b7te", "den", "Tam\u00b7pier", "/", "der", "dann", "sein", "b\u00e4s\u00b7tes", "that", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$(", "ART", "ADV", "PPOSAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Sie aber fuhren fort/ verst\u00e4rckten ihren Stat", "tokens": ["Sie", "a\u00b7ber", "fuh\u00b7ren", "fort", "/", "ver\u00b7st\u00e4rck\u00b7ten", "ih\u00b7ren", "Stat"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "PTKVZ", "$(", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Und schrieben hin und her um\u0303 H\u00fclff/ an Pfaltz und Sachsen/", "tokens": ["Und", "schrie\u00b7ben", "hin", "und", "her", "um\u0303", "H\u00fclff", "/", "an", "Pfaltz", "und", "Sach\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "KON", "ADV", "APPR", "NN", "$(", "APPR", "NN", "KON", "NE", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Und an die Nachbarschafft. Das Feuer solte wachsen/", "tokens": ["Und", "an", "die", "Nach\u00b7bar\u00b7schafft", ".", "Das", "Feu\u00b7er", "sol\u00b7te", "wach\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$.", "ART", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Halb Schlesien fiel zu/ gantz M\u00e4hren folgte nach/", "tokens": ["Halb", "Schle\u00b7si\u00b7en", "fiel", "zu", "/", "gantz", "M\u00e4h\u00b7ren", "folg\u00b7te", "nach", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "PTKZU", "$(", "ADV", "NN", "VVFIN", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Die Lausnitz s\u00e4umte nicht/ hier wurd auch ", "tokens": ["Die", "Laus\u00b7nitz", "s\u00e4um\u00b7te", "nicht", "/", "hier", "wurd", "auch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "$(", "ADV", "VAFIN", "ADV"], "meter": "-+-+--++-", "measure": "iambic.tetra.relaxed"}, "line.74": {"text": "Das L\u00e4ndlein ob der En\u00df/ und mehr/ die ihr Gewissen", "tokens": ["Das", "L\u00e4nd\u00b7lein", "ob", "der", "En\u00df", "/", "und", "mehr", "/", "die", "ihr", "Ge\u00b7wis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "KOUS", "ART", "NN", "$(", "KON", "ADV", "$(", "ART", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "In Glaubens-Handlungen nicht wolten lassen schl\u00fcssen.", "tokens": ["In", "Glau\u00b7bens\u00b7Hand\u00b7lun\u00b7gen", "nicht", "wol\u00b7ten", "las\u00b7sen", "schl\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKNEG", "VMFIN", "VVINF", "VVINF", "$."], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.76": {"text": "Nach dem der Held Tampier bey solcher Kriegs Gefahr", "tokens": ["Nach", "dem", "der", "Held", "Tam\u00b7pier", "bey", "sol\u00b7cher", "Kriegs", "Ge\u00b7fahr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ART", "NN", "NE", "APPR", "PIAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Und M\u00e4nge grosser Feind allein zu wenig war/", "tokens": ["Und", "M\u00e4n\u00b7ge", "gros\u00b7ser", "Feind", "al\u00b7lein", "zu", "we\u00b7nig", "war", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJA", "NN", "ADV", "PTKA", "PIS", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Beschrieb man dort und da viel Hilff ihm bey zu stehen/", "tokens": ["Be\u00b7schrieb", "man", "dort", "und", "da", "viel", "Hilff", "ihm", "bey", "zu", "ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "KON", "ADV", "PIAT", "NN", "PPER", "APPR", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Dann sie bezwungen ihn/ da\u00df er vor ihnen gehen", "tokens": ["Dann", "sie", "be\u00b7zwun\u00b7gen", "ihn", "/", "da\u00df", "er", "vor", "ih\u00b7nen", "ge\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "PPER", "$(", "KOUS", "PPER", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Und B\u00f6h\u00e4imb lassen must. Es wurde Hilff geschickt", "tokens": ["Und", "B\u00f6\u00b7h\u00e4i\u00b7mb", "las\u00b7sen", "must", ".", "Es", "wur\u00b7de", "Hilff", "ge\u00b7schickt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NE", "VVINF", "VMFIN", "$.", "PPER", "VAFIN", "NN", "VVPP"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.81": {"text": "Die mit Bucquoyen kam/ der zimlich wol begl\u00fcckt", "tokens": ["Die", "mit", "Buc\u00b7quo\u00b7yen", "kam", "/", "der", "zim\u00b7lich", "wol", "be\u00b7gl\u00fcckt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "VVFIN", "$(", "ART", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "In diesem Handel wur. Dem satzten sie entgegen", "tokens": ["In", "die\u00b7sem", "Han\u00b7del", "wur", ".", "Dem", "satz\u00b7ten", "sie", "ent\u00b7ge\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "$.", "PDS", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Den Grafen/ Nahmens Ernst von Man\u00dffeld/ der zum Degen", "tokens": ["Den", "Gra\u00b7fen", "/", "Nah\u00b7mens", "Ernst", "von", "Man\u00df\u00b7feld", "/", "der", "zum", "De\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$(", "NN", "NE", "APPR", "NN", "$(", "ART", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Und Feld' erzogen schien/ der Pil\u00dfen st\u00fcrmend nahm/", "tokens": ["Und", "Feld'", "er\u00b7zo\u00b7gen", "schien", "/", "der", "Pil\u00b7\u00dfen", "st\u00fcr\u00b7mend", "nahm", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVPP", "VVFIN", "$(", "ART", "NN", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Wodurch in andre Pl\u00e4tz ein grosses Schrecken kam.", "tokens": ["Wo\u00b7durch", "in", "and\u00b7re", "Pl\u00e4tz", "ein", "gros\u00b7ses", "Schre\u00b7cken", "kam", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Umb dieser Zeiten Lcuff Jm Novembr. war ein Comet zu sehen/", "tokens": ["Umb", "die\u00b7ser", "Zei\u00b7ten", "Lcuff", "Jm", "No\u00b7vembr", ".", "war", "ein", "Co\u00b7met", "zu", "se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PDAT", "NN", "NN", "APPRART", "NN", "$.", "VAFIN", "ART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+--+-", "measure": "iambic.septa.relaxed"}, "line.87": {"text": "Der gantz Europen pflag erschrecklich durch zu gehen/", "tokens": ["Der", "gantz", "Eu\u00b7ro\u00b7pen", "pflag", "er\u00b7schreck\u00b7lich", "durch", "zu", "ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "VVFIN", "ADJD", "APPR", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Hatt\u2019 einen langen Schwantz/ halb-wei\u00df/ halb-schwartz/ halb-", "tokens": ["Hatt'", "ei\u00b7nen", "lan\u00b7gen", "Schwantz", "/", "halb\u00b7wei\u00df", "/", "halb\u00b7schwartz", "/", "halb"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$(", "ADJD", "$(", "NN", "$(", "TRUNC"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.89": {"text": "Das war nun der Prophet/ Krieg-Pest- und Hungers-Noth", "tokens": ["Das", "war", "nun", "der", "Pro\u00b7phet", "/", "Krieg\u00b7Pest", "und", "Hun\u00b7ger\u00b7sNoth"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV", "ART", "NN", "$(", "TRUNC", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Und tausend Straffen mehr Europen zu verk\u00fcnden/", "tokens": ["Und", "tau\u00b7send", "Straf\u00b7fen", "mehr", "Eu\u00b7ro\u00b7pen", "zu", "ver\u00b7k\u00fcn\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "PIAT", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Wie es hierauf ergieng/ das wird sich/ h\u00f6re/ finden.", "tokens": ["Wie", "es", "hier\u00b7auf", "er\u00b7gieng", "/", "das", "wird", "sich", "/", "h\u00f6\u00b7re", "/", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "PAV", "VVFIN", "$(", "PDS", "VAFIN", "PRF", "$(", "VVFIN", "$(", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Matthias lie\u00df ", "tokens": ["Mat\u00b7thi\u00b7as", "lie\u00df"], "token_info": ["word", "word"], "pos": ["NE", "VVFIN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.93": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.94": {"text": "Der wider B\u00f6h\u00e4imb sich mit allen Kr\u00e4fften legte/", "tokens": ["Der", "wi\u00b7der", "B\u00f6\u00b7h\u00e4i\u00b7mb", "sich", "mit", "al\u00b7len", "Kr\u00e4ff\u00b7ten", "leg\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NE", "PRF", "APPR", "PIAT", "NN", "VVFIN", "$("], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.95": {"text": "Und also von dem Grund' es wider ihn erregte.", "tokens": ["Und", "al\u00b7so", "von", "dem", "Grund'", "es", "wi\u00b7der", "ihn", "er\u00b7reg\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Es war als wie ein Meer/ je st\u00e4rcker da\u00df es w\u00e4ht/", "tokens": ["Es", "war", "als", "wie", "ein", "Meer", "/", "je", "st\u00e4r\u00b7cker", "da\u00df", "es", "w\u00e4ht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOUS", "KOKOM", "ART", "NN", "$(", "ADV", "ADJD", "KOUS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Je gr\u00f6\u00dfer solches sich mit seinen Wellen bl\u00e4ht.", "tokens": ["Je", "gr\u00f6\u00b7\u00dfer", "sol\u00b7ches", "sich", "mit", "sei\u00b7nen", "Wel\u00b7len", "bl\u00e4ht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PIAT", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "So/ da\u00df der Graf von Thurn mit seinen blancken Waffen/", "tokens": ["So", "/", "da\u00df", "der", "Graf", "von", "Thurn", "mit", "sei\u00b7nen", "blan\u00b7cken", "Waf\u00b7fen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KOUS", "ART", "NN", "APPR", "NE", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "Sich recht vor Wien begab/ und gab jhr gnug zu schaffen.", "tokens": ["Sich", "recht", "vor", "Wi\u00b7en", "be\u00b7gab", "/", "und", "gab", "jhr", "gnug", "zu", "schaf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "APPR", "NE", "VVFIN", "$(", "KON", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.100": {"text": "Weil aber Man\u00dffelds Heer durch des Bucquoyen Schlag", "tokens": ["Weil", "a\u00b7ber", "Man\u00df\u00b7felds", "Heer", "durch", "des", "Buc\u00b7quo\u00b7yen", "Schlag"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PIAT", "NN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.101": {"text": "Was kranckte/ zog er ab und sch\u00fctzete das Prag.", "tokens": ["Was", "kranck\u00b7te", "/", "zog", "er", "ab", "und", "sch\u00fct\u00b7ze\u00b7te", "das", "Prag", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$(", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Man mahnte B\u00f6haimb starck die Waffen abzulegen/", "tokens": ["Man", "mahn\u00b7te", "B\u00f6\u00b7haimb", "starck", "die", "Waf\u00b7fen", "ab\u00b7zu\u00b7le\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NE", "VVFIN", "ART", "NN", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Je mehr des mahnens war/ je mehr war es entgegen/", "tokens": ["Je", "mehr", "des", "mah\u00b7nens", "war", "/", "je", "mehr", "war", "es", "ent\u00b7ge\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADV", "VAFIN", "$(", "ADV", "ADV", "VAFIN", "PPER", "PTKVZ", "$("], "meter": "+--+--+-+--+-", "measure": "dactylic.di.plus"}, "line.104": {"text": "Dann es den Ferdinand vor B\u00f6h\u00e4imbs K\u00f6nig nicht", "tokens": ["Dann", "es", "den", "Fer\u00b7di\u00b7nand", "vor", "B\u00f6\u00b7h\u00e4imbs", "K\u00f6\u00b7nig", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "ART", "NN", "APPR", "NE", "NN", "PTKNEG"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Erkennte/ weniger Gehorsam oder Pflicht", "tokens": ["Er\u00b7kenn\u00b7te", "/", "we\u00b7ni\u00b7ger", "Ge\u00b7hor\u00b7sam", "o\u00b7der", "Pflicht"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$(", "PIAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "Zu leisten ihm versprach. Weil aber diese Krohne", "tokens": ["Zu", "leis\u00b7ten", "ihm", "ver\u00b7sprach", ".", "Weil", "a\u00b7ber", "die\u00b7se", "Kroh\u00b7ne"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "PPER", "VVFIN", "$.", "KOUS", "ADV", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "Nicht Wittbe wolte seyn/ und weil auch diesem Throne", "tokens": ["Nicht", "Witt\u00b7be", "wol\u00b7te", "seyn", "/", "und", "weil", "auch", "die\u00b7sem", "Thro\u00b7ne"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "NN", "VMFIN", "VAINF", "$(", "KON", "KOUS", "ADV", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "Viel Wetter droheten/ als wurde Friederich", "tokens": ["Viel", "Wet\u00b7ter", "dro\u00b7he\u00b7ten", "/", "als", "wur\u00b7de", "Frie\u00b7de\u00b7rich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "$(", "KOKOM", "VAFIN", "NE"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.109": {"text": "Der Churf\u00fcrst an dem Reyhn/ nach dem ein andrer sich", "tokens": ["Der", "Chur\u00b7f\u00fcrst", "an", "dem", "Reyhn", "/", "nach", "dem", "ein", "an\u00b7drer", "sich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$(", "APPR", "ART", "ART", "ADJA", "PRF"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.110": {"text": "Hiervon hatt' abgesagt/ ", "tokens": ["Hier\u00b7von", "hatt'", "ab\u00b7ge\u00b7sagt", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.111": {"text": "Durch welches ersehr bald sein alles hat verlohren.", "tokens": ["Durch", "wel\u00b7ches", "er\u00b7sehr", "bald", "sein", "al\u00b7les", "hat", "ver\u00b7loh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "ADV", "VAINF", "PIS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Er nahm es an und zog sehr pr\u00e4chtig von dem Reyhn", "tokens": ["Er", "nahm", "es", "an", "und", "zog", "sehr", "pr\u00e4ch\u00b7tig", "von", "dem", "Reyhn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "ADV", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Auf Prag zu seiner Kr\u00f6hn- ach ", "tokens": ["Auf", "Prag", "zu", "sei\u00b7ner", "Kr\u00f6hn", "ach"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "APPR", "PPOSAT", "TRUNC", "XY"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.114": {"text": "Europa wurd hiedurch fast mehr als halb emp\u00f6ret/", "tokens": ["Eu\u00b7ro\u00b7pa", "wurd", "hie\u00b7durch", "fast", "mehr", "als", "halb", "em\u00b7p\u00f6\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PAV", "ADV", "PIAT", "KOKOM", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Und Deutschland wurd hiedurch fast auf den Grund zerst\u00f6ret.", "tokens": ["Und", "Deutschland", "wurd", "hie\u00b7durch", "fast", "auf", "den", "Grund", "zer\u00b7st\u00f6\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "PAV", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+---+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.116": {"text": "Damit die grosse Brunst noch gr\u00f6\u00dfer m\u00f6chte seyn/", "tokens": ["Da\u00b7mit", "die", "gros\u00b7se", "Brunst", "noch", "gr\u00f6\u00b7\u00dfer", "m\u00f6ch\u00b7te", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "ADV", "ADJD", "VMFIN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "So m\u00e4ngte sich in die auch Bethlem Gabor ein/", "tokens": ["So", "m\u00e4ng\u00b7te", "sich", "in", "die", "auch", "Beth\u00b7lem", "Ga\u00b7bor", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "PRELS", "ADV", "NE", "NE", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "Stund auf den K\u00e4yser auf/ verjagte M\u00f6nch uud Pfaffen", "tokens": ["Stund", "auf", "den", "K\u00e4y\u00b7ser", "auf", "/", "ver\u00b7jag\u00b7te", "M\u00f6nch", "u\u00b7ud", "Pfaf\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "APPR", "$(", "ADJA", "NN", "KON", "NN"], "meter": "++-+-+-+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.119": {"text": "Aus Siebenb\u00fcrgen weg/ bekriegte durch die Waffen", "tokens": ["Aus", "Sie\u00b7ben\u00b7b\u00fcr\u00b7gen", "weg", "/", "be\u00b7krieg\u00b7te", "durch", "die", "Waf\u00b7fen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "PTKVZ", "$(", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.120": {"text": "Viel Pl\u00e4tz\u2019 und brachte sie auch unter seine Macht.", "tokens": ["Viel", "Pl\u00e4tz'", "und", "brach\u00b7te", "sie", "auch", "un\u00b7ter", "sei\u00b7ne", "Macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.121": {"text": "Bald wurde des von Thurn sein Volck ihm zugebracht/", "tokens": ["Bald", "wur\u00b7de", "des", "von", "Thurn", "sein", "Volck", "ihm", "zu\u00b7ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "APPR", "NE", "PPOSAT", "NN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Damit er st\u00e4rcker wurd\u2019 und Lust h\u00e4tt\u2019 an dir Feinde/", "tokens": ["Da\u00b7mit", "er", "st\u00e4r\u00b7cker", "wurd'", "und", "Lust", "h\u00e4tt'", "an", "dir", "Fein\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "KON", "NN", "VAFIN", "APPR", "PPER", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.123": {"text": "Die aller Orten sich durch ihre nahen Freinde", "tokens": ["Die", "al\u00b7ler", "Or\u00b7ten", "sich", "durch", "ih\u00b7re", "na\u00b7hen", "Frein\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "PRF", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.124": {"text": "Verst\u00e4rckten. Dann da war Ertzhertzog Leopold/", "tokens": ["Ver\u00b7st\u00e4rck\u00b7ten", ".", "Dann", "da", "war", "Ertz\u00b7hert\u00b7zog", "Leo\u00b7pold", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ADV", "ADV", "VAFIN", "NE", "NE", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.125": {"text": "Der Franck- und Beyer-F\u00fcrst/ und andre/ die um Sold", "tokens": ["Der", "Fran\u00b7ck", "und", "Beyer\u00b7F\u00fcrst", "/", "und", "and\u00b7re", "/", "die", "um", "Sold"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "TRUNC", "KON", "NN", "$(", "KON", "PIS", "$(", "ART", "APPR", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.126": {"text": "Und Freundschafft ihren Dienst dem K\u00e4yser angetragen.", "tokens": ["Und", "Freund\u00b7schafft", "ih\u00b7ren", "Dienst", "dem", "K\u00e4y\u00b7ser", "an\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PPOSAT", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.127": {"text": "Es kam auch bald darauf in M\u00e4hren was zum schlagen/", "tokens": ["Es", "kam", "auch", "bald", "da\u00b7rauf", "in", "M\u00e4h\u00b7ren", "was", "zum", "schla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PAV", "APPR", "NN", "PRELS", "APPRART", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.128": {"text": "Und blieb durch Gabors Hilff dem B\u00f6hm die Oberhand.", "tokens": ["Und", "blieb", "durch", "Ga\u00b7bors", "Hilff", "dem", "B\u00f6hm", "die", "O\u00b7ber\u00b7hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NE", "NN", "ART", "NE", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.129": {"text": "Es halff nu nichts daf\u00fcr/ wie gro\u00df der Widerstand", "tokens": ["Es", "halff", "nu", "nichts", "da\u00b7f\u00fcr", "/", "wie", "gro\u00df", "der", "Wi\u00b7der\u00b7stand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "PAV", "$(", "PWAV", "ADJD", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.130": {"text": "Vom Gegentheile war. Hier sa\u00df der B\u00f6hm im Lentzen", "tokens": ["Vom", "Ge\u00b7gen\u00b7thei\u00b7le", "war", ".", "Hier", "sa\u00df", "der", "B\u00f6hm", "im", "Lent\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VAFIN", "$.", "ADV", "VVFIN", "ART", "NE", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.131": {"text": "Und kriegte noch darzu aus vielen Fremden Grentzen", "tokens": ["Und", "krieg\u00b7te", "noch", "dar\u00b7zu", "aus", "vie\u00b7len", "Frem\u00b7den", "Grent\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "PAV", "APPR", "PIAT", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.132": {"text": "Viel tausend Mann zu Hilff. Ein jeder war daran/", "tokens": ["Viel", "tau\u00b7send", "Mann", "zu", "Hilff", ".", "Ein", "je\u00b7der", "war", "da\u00b7ran", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "APPR", "NN", "$.", "ART", "PIS", "VAFIN", "PAV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.133": {"text": "Damit das Feuer wuchs. Ach welch ein Feuer kan", "tokens": ["Da\u00b7mit", "das", "Feu\u00b7er", "wuchs", ".", "Ach", "welch", "ein", "Feu\u00b7er", "kan"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "VVFIN", "$.", "ITJ", "PWAT", "ART", "NN", "VMFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.134": {"text": "Das Land und Leuthe frisst/ aus einem F\u00fcncklein kommen;", "tokens": ["Das", "Land", "und", "Leu\u00b7the", "frisst", "/", "aus", "ei\u00b7nem", "F\u00fcnc\u00b7klein", "kom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "$(", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.135": {"text": "Hierauf war widerum ein Zug nach Wien genommen", "tokens": ["Hier\u00b7auf", "war", "wi\u00b7de\u00b7rum", "ein", "Zug", "nach", "Wi\u00b7en", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "ADV", "ART", "NN", "APPR", "NE", "VVPP"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.136": {"text": "Doch wiederum umsonst. Hier kam in Bethlems Macht", "tokens": ["Doch", "wie\u00b7de\u00b7rum", "um\u00b7sonst", ".", "Hier", "kam", "in", "Beth\u00b7lems", "Macht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "$.", "ADV", "VVFIN", "APPR", "NE", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.137": {"text": "Pre\u00dfburg mit samt dem Schlo\u00df. Ein jeder war bedacht", "tokens": ["Pre\u00df\u00b7burg", "mit", "samt", "dem", "Schlo\u00df", ".", "Ein", "je\u00b7der", "war", "be\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "APPR", "APPR", "ART", "NN", "$.", "ART", "PIS", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.138": {"text": "Aufs K\u00e4ysers Schaden sich des Sieges zu bedienen.", "tokens": ["Aufs", "K\u00e4y\u00b7sers", "Scha\u00b7den", "sich", "des", "Sie\u00b7ges", "zu", "be\u00b7die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NN", "PRF", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.139": {"text": "Es glichen ihrer viel sich jetzo mit den Bienen/", "tokens": ["Es", "gli\u00b7chen", "ih\u00b7rer", "viel", "sich", "jet\u00b7zo", "mit", "den", "Bie\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "PIAT", "PRF", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.140": {"text": "Die schw\u00e4rmen/ wann die Sonn auf ihre St\u00f6cke scheint/", "tokens": ["Die", "schw\u00e4r\u00b7men", "/", "wann", "die", "Sonn", "auf", "ih\u00b7re", "St\u00f6\u00b7cke", "scheint", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$(", "PWAV", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.141": {"text": "Der nicht mit Ruh wil seyn/ der such\u2019 ihm einen Feind.", "tokens": ["Der", "nicht", "mit", "Ruh", "wil", "seyn", "/", "der", "such'", "ihm", "ei\u00b7nen", "Feind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "APPR", "NN", "VMFIN", "VAINF", "$(", "ART", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.142": {"text": "Als man in ", "tokens": ["Als", "man", "in"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PIS", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.143": {"text": "Wiewol ihr Landsmann auch der Bethlem Gabor siegte/", "tokens": ["Wie\u00b7wol", "ihr", "Lands\u00b7mann", "auch", "der", "Beth\u00b7lem", "Ga\u00b7bor", "sieg\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ART", "NN", "NE", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.144": {"text": "That ", "tokens": ["That"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.145": {"text": "Den Beyder-Krohnen Herrn/ und nahm an dessen Stand", "tokens": ["Den", "Bey\u00b7der\u00b7Kroh\u00b7nen", "Herrn", "/", "und", "nahm", "an", "des\u00b7sen", "Stand"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "KON", "VVFIN", "APPR", "PRELAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.146": {"text": "Den Bethlem Gabor an. Bey so gestalten Sachen", "tokens": ["Den", "Beth\u00b7lem", "Ga\u00b7bor", "an", ".", "Bey", "so", "ge\u00b7stal\u00b7ten", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "PTKVZ", "$.", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.147": {"text": "Must\u2019 unser K\u00e4yser sich an diese F\u00fcrsten machen", "tokens": ["Must'", "un\u00b7ser", "K\u00e4y\u00b7ser", "sich", "an", "die\u00b7se", "F\u00fcrs\u00b7ten", "ma\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPOSAT", "NN", "PRF", "APPR", "PDAT", "NN", "VVINF"], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.148": {"text": "Bey denen Cur und Macht und ein Gehorsam war/", "tokens": ["Bey", "de\u00b7nen", "Cur", "und", "Macht", "und", "ein", "Ge\u00b7hor\u00b7sam", "war", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "NN", "KON", "NN", "KON", "ART", "NN", "VAFIN", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.149": {"text": "Zu suchen/ da\u00df man doch die m\u00e4chtige Gefahr", "tokens": ["Zu", "su\u00b7chen", "/", "da\u00df", "man", "doch", "die", "m\u00e4ch\u00b7ti\u00b7ge", "Ge\u00b7fahr"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$(", "KOUS", "PIS", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.150": {"text": "Zu wenden/ neben ihm fich in die Waffen machte/", "tokens": ["Zu", "wen\u00b7den", "/", "ne\u00b7ben", "ihm", "fich", "in", "die", "Waf\u00b7fen", "mach\u00b7te", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$(", "APPR", "PPER", "PRF", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.151": {"text": "Worauf Cur-Sachsen sich bald in den Harnisch brachte", "tokens": ["Wo\u00b7rauf", "Cur\u00b7Sach\u00b7sen", "sich", "bald", "in", "den", "Har\u00b7nisch", "brach\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "NN", "PRF", "ADV", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+++-+-+-", "measure": "unknown.measure.septa"}, "line.152": {"text": "und erster Beystand war/ Er fiel der Lau\u00dfnitz ein.", "tokens": ["und", "ers\u00b7ter", "Beys\u00b7tand", "war", "/", "Er", "fiel", "der", "Lau\u00df\u00b7nitz", "ein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VAFIN", "$(", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.153": {"text": "Es kam auch dieser Zeit ein Spannjer an den Reyhn", "tokens": ["Es", "kam", "auch", "die\u00b7ser", "Zeit", "ein", "Spann\u00b7jer", "an", "den", "Reyhn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PDAT", "NN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.154": {"text": "Mit Nahmen Spinola/ der hielt des K\u00e4ysers Seiten", "tokens": ["Mit", "Nah\u00b7men", "Spi\u00b7no\u00b7la", "/", "der", "hielt", "des", "K\u00e4y\u00b7sers", "Sei\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "NE", "$(", "ART", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.155": {"text": "Und marterte die Pfaltz mit brennen und bestreiten/", "tokens": ["Und", "mar\u00b7ter\u00b7te", "die", "Pfaltz", "mit", "bren\u00b7nen", "und", "be\u00b7strei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "VVINF", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.156": {"text": "So wurd auch Man\u00dffelds Heer von des Bucquoyen", "tokens": ["So", "wurd", "auch", "Man\u00df\u00b7felds", "Heer", "von", "des", "Buc\u00b7quo\u00b7yen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "PIAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.157": {"text": "Schaar", "tokens": ["Schaar"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.158": {"text": "Bey Langeloys geschw\u00e4cht/ weil er zu Prage war.", "tokens": ["Bey", "Lan\u00b7ge\u00b7loys", "ge\u00b7schw\u00e4cht", "/", "weil", "er", "zu", "Pra\u00b7ge", "war", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVPP", "$(", "KOUS", "PPER", "APPR", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.159": {"text": "Es wolte nun das Gl\u00fcck der B\u00f6hmen fast zerscheitern/", "tokens": ["Es", "wol\u00b7te", "nun", "das", "Gl\u00fcck", "der", "B\u00f6h\u00b7men", "fast", "zer\u00b7schei\u00b7tern", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "ART", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.160": {"text": "und wie ergieng es dort bey Sitzendorff den Reitern", "tokens": ["und", "wie", "er\u00b7gieng", "es", "dort", "bey", "Sit\u00b7zen\u00b7dorff", "den", "Rei\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "VVFIN", "PPER", "ADV", "APPR", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.161": {"text": "Bey denen der von Fel\u00df der F\u00fchrer war? Er blieb", "tokens": ["Bey", "de\u00b7nen", "der", "von", "Fel\u00df", "der", "F\u00fch\u00b7rer", "war", "?", "Er", "blieb"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PRELS", "ART", "APPR", "NN", "ART", "NN", "VAFIN", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.162": {"text": "Und all sein Volck mit ihm durch der Bucquoyer Hieb.", "tokens": ["Und", "all", "sein", "Volck", "mit", "ihm", "durch", "der", "Buc\u00b7quo\u00b7yer", "Hieb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "PPOSAT", "NN", "APPR", "PPER", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.163": {"text": "Wiewol es beyderseits viel todte hat gegeben/", "tokens": ["Wie\u00b7wol", "es", "bey\u00b7der\u00b7seits", "viel", "tod\u00b7te", "hat", "ge\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.164": {"text": "Und blieb Bucquoy selbst genau alhier bey Leben.", "tokens": ["Und", "blieb", "Buc\u00b7quo\u00b7y", "selbst", "ge\u00b7nau", "al\u00b7hier", "bey", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "ADV", "ADJD", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.165": {"text": "Weil B\u00f6haimbs Feinde sich so st\u00e4rckten/ fchickte sich", "tokens": ["Weil", "B\u00f6\u00b7haimbs", "Fein\u00b7de", "sich", "so", "st\u00e4rck\u00b7ten", "/", "fchick\u00b7te", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "NE", "NN", "PRF", "ADV", "VVFIN", "$(", "VVFIN", "PRF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.166": {"text": "Denselben Hilff zu thun Printz Henrich Friederich", "tokens": ["Den\u00b7sel\u00b7ben", "Hilff", "zu", "thun", "Printz", "Hen\u00b7rich", "Frie\u00b7de\u00b7rich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "PTKZU", "VVINF", "NN", "NE", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.167": {"text": "Vom Hau\u00df ", "tokens": ["Vom", "Hau\u00df"], "token_info": ["word", "word"], "pos": ["APPRART", "NN"], "meter": "-+", "measure": "iambic.single"}, "line.168": {"text": "Was aber ihn fo bald zur\u00fccke hat bewogen", "tokens": ["Was", "a\u00b7ber", "ihn", "fo", "bald", "zu\u00b7r\u00fc\u00b7cke", "hat", "be\u00b7wo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "PPER", "ADV", "ADV", "VVFIN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.169": {"text": "Ist vielen unbewust. Indessen machte sich", "tokens": ["Ist", "vie\u00b7len", "un\u00b7be\u00b7wust", ".", "In\u00b7des\u00b7sen", "mach\u00b7te", "sich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PIAT", "NN", "$.", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.170": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.171": {"text": "Und that dem Feinde gleich mit rauben und mit brennen.", "tokens": ["Und", "that", "dem", "Fein\u00b7de", "gleich", "mit", "rau\u00b7ben", "und", "mit", "bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "APPR", "VVINF", "KON", "APPR", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.172": {"text": "Auf solches lie\u00df Tampier die Stadt Pre\u00dfburg berennen/", "tokens": ["Auf", "sol\u00b7ches", "lie\u00df", "Tam\u00b7pier", "die", "Stadt", "Pre\u00df\u00b7burg", "be\u00b7ren\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "NE", "ART", "NN", "NE", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.173": {"text": "Er selbst fiel an das Schlo\u00df/ der Gabor that Entsatz", "tokens": ["Er", "selbst", "fiel", "an", "das", "Schlo\u00df", "/", "der", "Ga\u00b7bor", "that", "Ent\u00b7satz"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "ART", "NN", "$(", "ART", "NN", "VVFIN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.174": {"text": "Und rettete den Ort/ Tampier blieb auf dem Platz.", "tokens": ["Und", "ret\u00b7te\u00b7te", "den", "Ort", "/", "Tam\u00b7pier", "blieb", "auf", "dem", "Platz", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$(", "NE", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.175": {"text": "Es machte sich auch nun der Beyer an die Bauern", "tokens": ["Es", "mach\u00b7te", "sich", "auch", "nun", "der", "Be\u00b7yer", "an", "die", "Bau\u00b7ern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ADV", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.176": {"text": "In Ober\u00f6sterreich/ die sich wie W\u00e4ll und Mauern", "tokens": ["In", "O\u00b7be\u00b7r\u00f6s\u00b7ter\u00b7reich", "/", "die", "sich", "wie", "W\u00e4ll", "und", "Mau\u00b7ern"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "$(", "PRELS", "PRF", "KOKOM", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.177": {"text": "Jhm widersetzeten/ hier hafftete kein Bley/", "tokens": ["Jhm", "wi\u00b7der\u00b7set\u00b7ze\u00b7ten", "/", "hier", "haff\u00b7te\u00b7te", "kein", "Bley", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "ADV", "VVFIN", "PIAT", "NN", "$("], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.178": {"text": "Hier that die Klinge nichts/ sie wolten auch so frey", "tokens": ["Hier", "that", "die", "Klin\u00b7ge", "nichts", "/", "sie", "wol\u00b7ten", "auch", "so", "frey"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PIS", "$(", "PPER", "VMFIN", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.179": {"text": "Wie B\u00f6haimb vor dem Papst in jhrem Glauben leben/", "tokens": ["Wie", "B\u00f6\u00b7haimb", "vor", "dem", "Papst", "in", "jhrem", "Glau\u00b7ben", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+---+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.180": {"text": "Und darum sah man sie wie B\u00f6haimb sich erheben", "tokens": ["Und", "da\u00b7rum", "sah", "man", "sie", "wie", "B\u00f6\u00b7haimb", "sich", "er\u00b7he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "PIS", "PPER", "KOKOM", "NE", "PRF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.181": {"text": "Vnd in den Waffen seyn. Der Bayer fiel sie an/", "tokens": ["Vnd", "in", "den", "Waf\u00b7fen", "seyn", ".", "Der", "Ba\u00b7yer", "fiel", "sie", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VAINF", "$.", "ART", "NE", "VVFIN", "PPER", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.182": {"text": "Es wurd ihm aber so ein Widerstand gethan", "tokens": ["Es", "wurd", "ihm", "a\u00b7ber", "so", "ein", "Wi\u00b7der\u00b7stand", "ge\u00b7than"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.183": {"text": "da\u00df mancher tapfrer Held sein Leben muste lassen.", "tokens": ["da\u00df", "man\u00b7cher", "tapf\u00b7rer", "Held", "sein", "Le\u00b7ben", "mus\u00b7te", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ADJA", "NN", "PPOSAT", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.184": {"text": "Hier blieb Ernst Ludwich todt/ ein F\u00fcrst vom Hause Sassen.", "tokens": ["Hier", "blieb", "Ernst", "Lud\u00b7wich", "todt", "/", "ein", "F\u00fcrst", "vom", "Hau\u00b7se", "Sas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NE", "ADJD", "$(", "ART", "NN", "APPRART", "NN", "NE", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.185": {"text": "Der Beyer r\u00fcckete/ Vergelt zu thun/ vor Lintz/", "tokens": ["Der", "Be\u00b7yer", "r\u00fc\u00b7cke\u00b7te", "/", "Ver\u00b7gelt", "zu", "thun", "/", "vor", "Lintz", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$(", "NN", "PTKZU", "VVINF", "$(", "APPR", "NE", "$("], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.186": {"text": "Wo er das Bauer-Heer mit einer gleichen M\u00fcntz", "tokens": ["Wo", "er", "das", "Bau\u00b7e\u00b7rHeer", "mit", "ei\u00b7ner", "glei\u00b7chen", "M\u00fcntz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.187": {"text": "Als er vorher empfieng/ bezahlte. Di\u00df ", "tokens": ["Als", "er", "vor\u00b7her", "emp\u00b7fi\u00b7eng", "/", "be\u00b7zahl\u00b7te", ".", "Di\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "$(", "VVFIN", "$.", "PDS"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.188": {"text": "Bezwung er sie mit Macht den Waffen abzustehen", "tokens": ["Be\u00b7zwung", "er", "sie", "mit", "Macht", "den", "Waf\u00b7fen", "ab\u00b7zu\u00b7ste\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PPER", "APPR", "NN", "ART", "NN", "VVIZU"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.189": {"text": "und unter ihm zu seyn. Nur kurtz vor diesem Streit", "tokens": ["und", "un\u00b7ter", "ihm", "zu", "seyn", ".", "Nur", "kurtz", "vor", "die\u00b7sem", "Streit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPER", "PTKZU", "VAINF", "$.", "ADV", "ADJD", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.190": {"text": "Wurd\u2019 auch die ", "tokens": ["Wurd'", "auch", "die"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "ADV", "ART"], "meter": "+--", "measure": "dactylic.init"}, "line.191": {"text": "Aus vielen M\u00e4chtigen/ die vor des Keysers Waffen", "tokens": ["Aus", "vie\u00b7len", "M\u00e4ch\u00b7ti\u00b7gen", "/", "die", "vor", "des", "Key\u00b7sers", "Waf\u00b7fen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "$(", "ART", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.192": {"text": "Jhr und der ", "tokens": ["Ihr", "und", "der"], "token_info": ["word", "word", "word"], "pos": ["PPER", "KON", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.193": {"text": "Vom B\u00e4yer aufgel\u00f6st/ jedoch gantz ohne Schlag.", "tokens": ["Vom", "B\u00e4\u00b7yer", "auf\u00b7ge\u00b7l\u00f6st", "/", "je\u00b7doch", "gantz", "oh\u00b7ne", "Schlag", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$(", "ADV", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.194": {"text": "So bald nun diese Macht der ", "tokens": ["So", "bald", "nun", "die\u00b7se", "Macht", "der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "PDAT", "NN", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.195": {"text": "Zog er dem K\u00e4yser zu. Weil nun die Bauer-Schaaren/", "tokens": ["Zog", "er", "dem", "K\u00e4y\u00b7ser", "zu", ".", "Weil", "nun", "die", "Bau\u00b7e\u00b7rSchaa\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$.", "KOUS", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.196": {"text": "Von denen jetzt gedacht/ ihm in dem Wege waren/", "tokens": ["Von", "de\u00b7nen", "jetzt", "ge\u00b7dacht", "/", "ihm", "in", "dem", "We\u00b7ge", "wa\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "VVPP", "$(", "PPER", "APPR", "ART", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.197": {"text": "So gieng er erst auf sie. Als K\u00e4yser Ferdinand", "tokens": ["So", "gieng", "er", "erst", "auf", "sie", ".", "Als", "K\u00e4y\u00b7ser", "Fer\u00b7di\u00b7nand"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$.", "KOUS", "NE", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.198": {"text": "Des Bayers Gl\u00fcck vernahm/ der durch des Tylli Hand", "tokens": ["Des", "Ba\u00b7yers", "Gl\u00fcck", "ver\u00b7nahm", "/", "der", "durch", "des", "Tyl\u00b7li", "Hand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "$(", "ART", "APPR", "ART", "NE", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.199": {"text": "Viel tapfre Thaten that/ dan Tylli war im Kriegen", "tokens": ["Viel", "tapf\u00b7re", "Tha\u00b7ten", "that", "/", "dan", "Tyl\u00b7li", "war", "im", "Krie\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "$(", "ADV", "NE", "VAFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.200": {"text": "Ein wolerfahrner Held/ der auch zu vielen Siegen", "tokens": ["Ein", "wo\u00b7ler\u00b7fahr\u00b7ner", "Held", "/", "der", "auch", "zu", "vie\u00b7len", "Sie\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.201": {"text": "Ein grosses Gl\u00fccke hatt\u2019/ empfahl er ihm sein Heer/", "tokens": ["Ein", "gros\u00b7ses", "Gl\u00fc\u00b7cke", "hatt'", "/", "emp\u00b7fahl", "er", "ihm", "sein", "Heer", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$(", "VVFIN", "PPER", "PPER", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.202": {"text": "Mit solchem so zu thun/ dnmit er Sieg und Ehr\u2019", "tokens": ["Mit", "sol\u00b7chem", "so", "zu", "thun", "/", "dn\u00b7mit", "er", "Sieg", "und", "Ehr'"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADV", "PTKZU", "VVINF", "$(", "KOUS", "PPER", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.203": {"text": "Erw\u00fcrb/ und B\u00f6haimb trieb die Waffen zu verlassen/", "tokens": ["Er\u00b7w\u00fcrb", "/", "und", "B\u00f6\u00b7haimb", "trieb", "die", "Waf\u00b7fen", "zu", "ver\u00b7las\u00b7sen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KON", "NE", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.204": {"text": "Hergegen ihrer Pflicht sich wieder anzumassen.", "tokens": ["Her\u00b7ge\u00b7gen", "ih\u00b7rer", "Pflicht", "sich", "wie\u00b7der", "an\u00b7zu\u00b7mas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PRF", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.205": {"text": "Ber Bayer nahm es an und schriebs dem Friederich/", "tokens": ["Ber", "Ba\u00b7yer", "nahm", "es", "an", "und", "schriebs", "dem", "Frie\u00b7de\u00b7rich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "ART", "NE", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.206": {"text": "Der B\u00f6hmen neuen Herrn/ der dann aufs b\u00e4ste sich", "tokens": ["Der", "B\u00f6h\u00b7men", "neu\u00b7en", "Herrn", "/", "der", "dann", "aufs", "b\u00e4s\u00b7te", "sich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "$(", "ART", "ADV", "APPRART", "ADJA", "PRF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.207": {"text": "darwider r\u00fcstete/ der Meynung ob zu siegen,", "tokens": ["dar\u00b7wi\u00b7der", "r\u00fcs\u00b7te\u00b7te", "/", "der", "Mey\u00b7nung", "ob", "zu", "sie\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "$(", "ART", "NN", "KOUS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.208": {"text": "Wann GOtt nicht selber wil mit deinen Feinden kriegen", "tokens": ["Wann", "Gott", "nicht", "sel\u00b7ber", "wil", "mit", "dei\u00b7nen", "Fein\u00b7den", "krie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "PTKNEG", "ADV", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.209": {"text": "So ist dein Werck zu schwach. Dann Er ists/ der den Krieg", "tokens": ["So", "ist", "dein", "Werck", "zu", "schwach", ".", "Dann", "Er", "ists", "/", "der", "den", "Krieg"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "PTKZU", "VVFIN", "$.", "ADV", "PPER", "VAFIN", "$(", "ART", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.210": {"text": "In seinen H\u00e4nden hat/ von GOTT kommt Schlag und", "tokens": ["In", "sei\u00b7nen", "H\u00e4n\u00b7den", "hat", "/", "von", "GoTT", "kommt", "Schlag", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "$(", "APPR", "NE", "VVFIN", "NN", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.211": {"text": "Sieg.", "tokens": ["Sieg", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+", "measure": "single.up"}, "line.212": {"text": "Der K\u00f6nig Friederich that \u00fcberall das Seine", "tokens": ["Der", "K\u00f6\u00b7nig", "Frie\u00b7de\u00b7rich", "that", "\u00fc\u00b7be\u00b7rall", "das", "Sei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "VVFIN", "ADV", "ART", "PPOSAT"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.213": {"text": "und bracht ein grosses Volck zu streiten auf die Beine.", "tokens": ["und", "bracht", "ein", "gros\u00b7ses", "Volck", "zu", "strei\u00b7ten", "auf", "die", "Bei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "PTKZU", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.214": {"text": "Da war F\u00fcrst Christian von Anhalt und sein Printz/", "tokens": ["Da", "war", "F\u00fcrst", "Chris\u00b7ti\u00b7an", "von", "An\u00b7halt", "und", "sein", "Printz", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "NE", "APPR", "NN", "KON", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.215": {"text": "Hans Ernst/ ein tapfrer F\u00fcrst der Weymarschen Provintz/", "tokens": ["Hans", "Ernst", "/", "ein", "tapf\u00b7rer", "F\u00fcrst", "der", "Wey\u00b7mar\u00b7schen", "Pro\u00b7vintz", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$(", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.216": {"text": "Ein F\u00fcrst von J\u00e4gerndorff/ darzu die tapfren Streiter", "tokens": ["Ein", "F\u00fcrst", "von", "J\u00e4\u00b7gern\u00b7dorff", "/", "dar\u00b7zu", "die", "tapf\u00b7ren", "Strei\u00b7ter"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NE", "$(", "PAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.217": {"text": "Von Hollach/ Thurn und Schlick/ sechstausend leichte", "tokens": ["Von", "Hol\u00b7lach", "/", "Thurn", "und", "Schlick", "/", "sech\u00b7stau\u00b7send", "leich\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NE", "$(", "NE", "KON", "NN", "$(", "ADJD", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.218": {"text": "Reiter", "tokens": ["Rei\u00b7ter"], "token_info": ["word"], "pos": ["NE"], "meter": "+-", "measure": "trochaic.single"}, "line.219": {"text": "Aus ", "tokens": ["Aus"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.220": {"text": "Viel Schlesier und mehr. Graff Man\u00dffeld wo war der?", "tokens": ["Viel", "Schle\u00b7sier", "und", "mehr", ".", "Graff", "Man\u00df\u00b7feld", "wo", "war", "der", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "ADV", "$.", "NE", "NN", "PWAV", "VAFIN", "ART", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.221": {"text": "Der lag mit seiner Macht umb Pil\u00dfen starck verw\u00e4llet", "tokens": ["Der", "lag", "mit", "sei\u00b7ner", "Macht", "umb", "Pil\u00b7\u00dfen", "starck", "ver\u00b7w\u00e4l\u00b7let"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "PPOSAT", "NN", "APPR", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.222": {"text": "Vnd zu des Ortes Schutz aida zu stehn best\u00e4llet/", "tokens": ["Vnd", "zu", "des", "Or\u00b7tes", "Schutz", "ai\u00b7da", "zu", "stehn", "be\u00b7st\u00e4l\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "NE", "PTKZU", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.223": {"text": "Weil/ wie man meynete/ daran gelegen war.", "tokens": ["Weil", "/", "wie", "man", "mey\u00b7ne\u00b7te", "/", "da\u00b7ran", "ge\u00b7le\u00b7gen", "war", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "PWAV", "PIS", "VVFIN", "$(", "PAV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.224": {"text": "Mit diesen Obristen und ihrer grossen Schaar.", "tokens": ["Mit", "die\u00b7sen", "O\u00b7bris\u00b7ten", "und", "ih\u00b7rer", "gros\u00b7sen", "Schaar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.225": {"text": "Zog Feld-Herr Christian von Anhalt vor die Feinde", "tokens": ["Zog", "Feld\u00b7Herr", "Chris\u00b7ti\u00b7an", "von", "An\u00b7halt", "vor", "die", "Fein\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "NE", "APPR", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.226": {"text": "Die wider B\u00f6haim sich und dieses Reiches Freinde", "tokens": ["Die", "wi\u00b7der", "B\u00f6\u00b7haim", "sich", "und", "die\u00b7ses", "Rei\u00b7ches", "Frein\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NE", "PRF", "KON", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.227": {"text": "Starck hatten aufgemacht. Es ist ein Berg bey Prag", "tokens": ["Starck", "hat\u00b7ten", "auf\u00b7ge\u00b7macht", ".", "Es", "ist", "ein", "Berg", "bey", "Prag"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "VVPP", "$.", "PPER", "VAFIN", "ART", "NN", "APPR", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.228": {"text": "Der wegen weissen Sands den Nahmen haben mag", "tokens": ["Der", "we\u00b7gen", "weis\u00b7sen", "Sands", "den", "Nah\u00b7men", "ha\u00b7ben", "mag"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN", "ART", "NN", "VAINF", "VMFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.229": {"text": "Der weisse Berg/ auf dem kam ", "tokens": ["Der", "weis\u00b7se", "Berg", "/", "auf", "dem", "kam"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "APPR", "ART", "VVFIN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.230": {"text": "Hier gieng der Jammer an. Man stund auf beyden Seiten", "tokens": ["Hier", "gieng", "der", "Jam\u00b7mer", "an", ".", "Man", "stund", "auf", "bey\u00b7den", "Sei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$.", "PIS", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.231": {"text": "Wie Mauern/ jeder war mit dieser Meynung da", "tokens": ["Wie", "Mau\u00b7ern", "/", "je\u00b7der", "war", "mit", "die\u00b7ser", "Mey\u00b7nung", "da"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "$(", "PIS", "VAFIN", "APPR", "PDAT", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.232": {"text": "Vor seines K\u00f6nigs Land zu siegen oder ja", "tokens": ["Vor", "sei\u00b7nes", "K\u00f6\u00b7nigs", "Land", "zu", "sie\u00b7gen", "o\u00b7der", "ja"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN", "PTKZU", "VVINF", "KON", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.233": {"text": "Zu sterben/ wie ein Held. Die pra\u00dflenden Cartaunen/", "tokens": ["Zu", "ster\u00b7ben", "/", "wie", "ein", "Held", ".", "Die", "pra\u00df\u00b7len\u00b7den", "Car\u00b7tau\u00b7nen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$(", "KOKOM", "ART", "NN", "$.", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.234": {"text": "vor derer Donders Macht Lufft/ Erd und Meer erstaunen/", "tokens": ["vor", "de\u00b7rer", "Don\u00b7ders", "Macht", "Lufft", "/", "Erd", "und", "Meer", "er\u00b7stau\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "NN", "NN", "NN", "$(", "NN", "KON", "NN", "VVINF", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.235": {"text": "Zerschmetterten bald dem/ bald jenem Pferd und Mann", "tokens": ["Zer\u00b7schmet\u00b7ter\u00b7ten", "bald", "dem", "/", "bald", "je\u00b7nem", "Pferd", "und", "Mann"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "$(", "ADV", "PDAT", "NN", "KON", "NN"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.236": {"text": "Vnd kehrten sie zur Lufft. Man sah es schmertzlich an/", "tokens": ["Vnd", "kehr\u00b7ten", "sie", "zur", "Lufft", ".", "Man", "sah", "es", "schmertz\u00b7lich", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN", "$.", "PIS", "VVFIN", "PPER", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.237": {"text": "Wie dort und da ein Held halb-todt wurd abgezogen/", "tokens": ["Wie", "dort", "und", "da", "ein", "Held", "halb\u00b7todt", "wurd", "ab\u00b7ge\u00b7zo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "KON", "ADV", "ART", "NN", "ADJD", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.238": {"text": "Wie dort ein Fu\u00df und Arm/ hier K\u00f6pf\u2019 und R\u00fcmpfe flogen.", "tokens": ["Wie", "dort", "ein", "Fu\u00df", "und", "Arm", "/", "hier", "K\u00f6pf'", "und", "R\u00fcmp\u00b7fe", "flo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "KON", "NN", "$(", "ADV", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.239": {"text": "Es schaumten Pferd und Mann f\u00fcr Zorn und Siegsbegier/", "tokens": ["Es", "schaum\u00b7ten", "Pferd", "und", "Mann", "f\u00fcr", "Zorn", "und", "Siegs\u00b7be\u00b7gier", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.240": {"text": "Ein jeder zog den Ruhm und Sieg dem Leben f\u00fcr.", "tokens": ["Ein", "je\u00b7der", "zog", "den", "Ruhm", "und", "Sieg", "dem", "Le\u00b7ben", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "ART", "NN", "KON", "NN", "ART", "NN", "APPR", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.241": {"text": "Ein jeder war gesinnt auf langen Kampf zu siegen/", "tokens": ["Ein", "je\u00b7der", "war", "ge\u00b7sinnt", "auf", "lan\u00b7gen", "Kampf", "zu", "sie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VAFIN", "ADJD", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.242": {"text": "Aufs Ende musten doch die B\u00f6hmen unten liegen/", "tokens": ["Aufs", "En\u00b7de", "mus\u00b7ten", "doch", "die", "B\u00f6h\u00b7men", "un\u00b7ten", "lie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VMFIN", "ADV", "ART", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.243": {"text": "Dann K\u00e4yser Ferdinand hatt eine grosse Macht.", "tokens": ["Dann", "K\u00e4y\u00b7ser", "Fer\u00b7di\u00b7nand", "hatt", "ei\u00b7ne", "gros\u00b7se", "Macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "NE", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.244": {"text": "Hier wurden/ wie man meynt/ acht tausend umbgebracht/", "tokens": ["Hier", "wur\u00b7den", "/", "wie", "man", "meynt", "/", "acht", "tau\u00b7send", "umb\u00b7ge\u00b7bracht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$(", "PWAV", "PIS", "VVFIN", "$(", "CARD", "CARD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.245": {"text": "die alle dieses mahl f\u00fcr B\u00f6haimb tapfer stritten.", "tokens": ["die", "al\u00b7le", "die\u00b7ses", "mahl", "f\u00fcr", "B\u00f6\u00b7haimb", "tap\u00b7fer", "strit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "PDS", "ADV", "APPR", "NE", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.246": {"text": "Da\u00df bey den K\u00e4yserschen viel Schadens wurd erlitten", "tokens": ["Da\u00df", "bey", "den", "K\u00e4y\u00b7ser\u00b7schen", "viel", "Scha\u00b7dens", "wurd", "er\u00b7lit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN", "PIAT", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.247": {"text": "Mag auch wol glaublich sein. Es lag das gantze Feld", "tokens": ["Mag", "auch", "wol", "glaub\u00b7lich", "sein", ".", "Es", "lag", "das", "gant\u00b7ze", "Feld"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ADV", "ADJD", "VAINF", "$.", "PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.248": {"text": "Mit Todten voll gestreut/ worunter auch der Held", "tokens": ["Mit", "Tod\u00b7ten", "voll", "ge\u00b7streut", "/", "wo\u00b7run\u00b7ter", "auch", "der", "Held"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADJD", "VVPP", "$(", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.249": {"text": "Vom Hause Pappenheim mit vielen grossen Wunden/", "tokens": ["Vom", "Hau\u00b7se", "Pap\u00b7pen\u00b7heim", "mit", "vie\u00b7len", "gros\u00b7sen", "Wun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NN", "APPR", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.250": {"text": "Der jedem todt erschien/ erb\u00e4rmlich wurd\u2019 erfunden/", "tokens": ["Der", "je\u00b7dem", "todt", "er\u00b7schien", "/", "er\u00b7b\u00e4rm\u00b7lich", "wurd'", "er\u00b7fun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADJD", "VVFIN", "$(", "ADJD", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.251": {"text": "Wurd\u2019 aber bald hernach also zu recht gebracht", "tokens": ["Wurd'", "a\u00b7ber", "bald", "her\u00b7nach", "al\u00b7so", "zu", "recht", "ge\u00b7bracht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "ADV", "PTKA", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.252": {"text": "Da\u00df er viel tausend schlug. Was diese grosse Schlacht", "tokens": ["Da\u00df", "er", "viel", "tau\u00b7send", "schlug", ".", "Was", "die\u00b7se", "gros\u00b7se", "Schlacht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVFIN", "$.", "PWS", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.253": {"text": "Den guten B\u00f6hmen hab\u2019 an Schrecken eingetrieben/", "tokens": ["Den", "gu\u00b7ten", "B\u00f6h\u00b7men", "hab'", "an", "Schre\u00b7cken", "ein\u00b7ge\u00b7trie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.254": {"text": "Was mehr von solcher kam/ wird nie genug beschrieben.", "tokens": ["Was", "mehr", "von", "sol\u00b7cher", "kam", "/", "wird", "nie", "ge\u00b7nug", "be\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "PIAT", "VVFIN", "$(", "VAFIN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.255": {"text": "Aus diesem Siege gieng das Feuer vollends auf", "tokens": ["Aus", "die\u00b7sem", "Sie\u00b7ge", "gieng", "das", "Feu\u00b7er", "vol\u00b7lends", "auf"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "ART", "NN", "ADV", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.256": {"text": "Vnd nahm von B\u00f6haimb ab nach Deutschland seinen", "tokens": ["Vnd", "nahm", "von", "B\u00f6\u00b7haimb", "ab", "nach", "Deutschland", "sei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NE", "PTKVZ", "APPR", "NE", "PPOSAT"], "meter": "-+-+-+----", "measure": "unknown.measure.tri"}, "line.257": {"text": "Lauff.", "tokens": ["Lauff", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+", "measure": "single.up"}}}}}