{"textgrid.poem.44033": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Je sch\u00e4rfer Streit, je gr\u00f6\u00dfer Lob.", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Je sch\u00e4rfer Streit, je gr\u00f6\u00dfer Lob.", "tokens": ["Je", "sch\u00e4r\u00b7fer", "Streit", ",", "je", "gr\u00f6\u00b7\u00dfer", "Lob", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "NN", "$,", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Ungl\u00fcck scherzet ziemlich grob", "tokens": ["Das", "Un\u00b7gl\u00fcck", "scher\u00b7zet", "ziem\u00b7lich", "grob"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und dehnt uns stets die theuren Jahre.", "tokens": ["Und", "dehnt", "uns", "stets", "die", "theu\u00b7ren", "Jah\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Jedoch, mein Freund, ergieb dich drein;", "tokens": ["Je\u00b7doch", ",", "mein", "Freund", ",", "er\u00b7gieb", "dich", "drein", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ist Tugend nicht verlegne Wahre,", "tokens": ["Ist", "Tu\u00b7gend", "nicht", "ver\u00b7leg\u00b7ne", "Wah\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "PTKNEG", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wird endlich unser Flei\u00df auch unser Joseph seyn.", "tokens": ["Wird", "end\u00b7lich", "un\u00b7ser", "Flei\u00df", "auch", "un\u00b7ser", "Jo\u00b7se\u00b7ph", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "ADV", "PPOSAT", "NE", "VAINF", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}, "stanza.2": {"line.1": {"text": "Wo liebt ein Mensch sein eignes Weh?", "tokens": ["Wo", "liebt", "ein", "Mensch", "sein", "eig\u00b7nes", "Weh", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich lieb es, da\u00df ich's dir gesteh,", "tokens": ["Ich", "lieb", "es", ",", "da\u00df", "ich's", "dir", "ge\u00b7steh", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und bin der Noth recht hoch verbunden:", "tokens": ["Und", "bin", "der", "Noth", "recht", "hoch", "ver\u00b7bun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADJD", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sie war der Anfang unsrer Treu,", "tokens": ["Sie", "war", "der", "An\u00b7fang", "uns\u00b7rer", "Treu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und da\u00df ich dich, mein Freund, gefunden,", "tokens": ["Und", "da\u00df", "ich", "dich", ",", "mein", "Freund", ",", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "$,", "PPOSAT", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das macht dein s\u00fc\u00dfes Creuz, der Schickung Tyranney.", "tokens": ["Das", "macht", "dein", "s\u00fc\u00b7\u00dfes", "Creuz", ",", "der", "Schi\u00b7ckung", "Ty\u00b7ran\u00b7ney", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "ADJA", "NN", "$,", "ART", "NN", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Las die betr\u00fcbt und traurig seyn,", "tokens": ["Las", "die", "be\u00b7tr\u00fcbt", "und", "trau\u00b7rig", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJD", "KON", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die ohne Mitgeno\u00dfen schreyn", "tokens": ["Die", "oh\u00b7ne", "Mit\u00b7ge\u00b7no\u00b7\u00dfen", "schreyn"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und keinem als sich selber klagen.", "tokens": ["Und", "kei\u00b7nem", "als", "sich", "sel\u00b7ber", "kla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "KOKOM", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wir haben Wollust durch den Schmerz", "tokens": ["Wir", "ha\u00b7ben", "Wol\u00b7lust", "durch", "den", "Schmerz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und k\u00f6nnen noch vom Gl\u00fccke sagen,", "tokens": ["Und", "k\u00f6n\u00b7nen", "noch", "vom", "Gl\u00fc\u00b7cke", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Denn was der eine f\u00fchlt, das tr\u00e4gt des andern Herz.", "tokens": ["Denn", "was", "der", "ei\u00b7ne", "f\u00fchlt", ",", "das", "tr\u00e4gt", "des", "an\u00b7dern", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "PIS", "VVFIN", "$,", "PDS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wir klagen th\u00f6richt \u00fcber Noth;", "tokens": ["Wir", "kla\u00b7gen", "th\u00f6\u00b7richt", "\u00fc\u00b7ber", "Noth", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denn wird uns unser t\u00e4glich Brodt", "tokens": ["Denn", "wird", "uns", "un\u00b7ser", "t\u00e4g\u00b7lich", "Brodt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "PPOSAT", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gleich schwer und k\u00e4rglich zugeme\u00dfen,", "tokens": ["Gleich", "schwer", "und", "k\u00e4rg\u00b7lich", "zu\u00b7ge\u00b7me\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Man wird doch endlich immer satt,", "tokens": ["Man", "wird", "doch", "end\u00b7lich", "im\u00b7mer", "satt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und wenn uns auch die Sorgen pre\u00dfen,", "tokens": ["Und", "wenn", "uns", "auch", "die", "Sor\u00b7gen", "pre\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Kommt oft doch auch ein Tag, der Trost und Lindrung hat.", "tokens": ["Kommt", "oft", "doch", "auch", "ein", "Tag", ",", "der", "Trost", "und", "Lind\u00b7rung", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ADV", "ADV", "ART", "NN", "$,", "ART", "NN", "KON", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Las h\u00f6ren, was dich gar so kr\u00e4nckt.", "tokens": ["Las", "h\u00f6\u00b7ren", ",", "was", "dich", "gar", "so", "kr\u00e4nckt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVINF", "$,", "PWS", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df niemand Gutes von uns denckt?", "tokens": ["Da\u00df", "nie\u00b7mand", "Gu\u00b7tes", "von", "uns", "denckt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer ist der Niemand? Grobe Leute.", "tokens": ["Wer", "ist", "der", "Nie\u00b7mand", "?", "Gro\u00b7be", "Leu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "PIS", "$.", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das ist uns warlich schlechte Schmach;", "tokens": ["Das", "ist", "uns", "war\u00b7lich", "schlech\u00b7te", "Schmach", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie sehn uns auf der lincken Seite", "tokens": ["Sie", "sehn", "uns", "auf", "der", "lin\u00b7cken", "Sei\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und sinnen weiter nichts als auf auf die Kleider nach.", "tokens": ["Und", "sin\u00b7nen", "wei\u00b7ter", "nichts", "als", "auf", "auf", "die", "Klei\u00b7der", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PIS", "KOKOM", "APPR", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Wir sind so gut als vogelfrey", "tokens": ["Wir", "sind", "so", "gut", "als", "vo\u00b7gel\u00b7frey"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "KOKOM", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und m\u00fc\u00dfen vor der Heucheley", "tokens": ["Und", "m\u00fc\u00b7\u00dfen", "vor", "der", "Heu\u00b7che\u00b7ley"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In dem und jenem Winckel stecken;", "tokens": ["In", "dem", "und", "je\u00b7nem", "Win\u00b7ckel", "ste\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "KON", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Vorsicht nimmt uns doch in Acht", "tokens": ["Die", "Vor\u00b7sicht", "nimmt", "uns", "doch", "in", "Acht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "APPR", "CARD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und l\u00e4st uns keinen Fluch erschr\u00f6cken,", "tokens": ["Und", "l\u00e4st", "uns", "kei\u00b7nen", "Fluch", "er\u00b7schr\u00f6\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der jenes reiche Volck im Marmor furchtsam macht.", "tokens": ["Der", "je\u00b7nes", "rei\u00b7che", "Volck", "im", "Mar\u00b7mor", "furcht\u00b7sam", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDAT", "ADJA", "NN", "APPRART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Wir tragen unsre Sch\u00e4ze mit,", "tokens": ["Wir", "tra\u00b7gen", "uns\u00b7re", "Sch\u00e4\u00b7ze", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Wei\u00dfheit folgt uns Schritt vor Schritt;", "tokens": ["Die", "Wei\u00df\u00b7heit", "folgt", "uns", "Schritt", "vor", "Schritt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Komm, las uns in die W\u00fcsten reisen.", "tokens": ["Komm", ",", "las", "uns", "in", "die", "W\u00fcs\u00b7ten", "rei\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bist du, getreuer Freund, dabey,", "tokens": ["Bist", "du", ",", "ge\u00b7treu\u00b7er", "Freund", ",", "da\u00b7bey", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "ADJA", "NN", "$,", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So will ich in der That beweisen,", "tokens": ["So", "will", "ich", "in", "der", "That", "be\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df auch ein Hirtenhaus mein sch\u00f6nstes Leipzig sey.", "tokens": ["Da\u00df", "auch", "ein", "Hir\u00b7ten\u00b7haus", "mein", "sch\u00f6ns\u00b7tes", "Leip\u00b7zig", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PPOSAT", "ADJA", "NE", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Ist keine Stunde durch den Tag,", "tokens": ["Ist", "kei\u00b7ne", "Stun\u00b7de", "durch", "den", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da unser Kummer ruhen mag,", "tokens": ["Da", "un\u00b7ser", "Kum\u00b7mer", "ru\u00b7hen", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So sind die N\u00e4chte voll Vergn\u00fcgen;", "tokens": ["So", "sind", "die", "N\u00e4ch\u00b7te", "voll", "Ver\u00b7gn\u00fc\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn unser Feind im Traum erschrickt", "tokens": ["Wenn", "un\u00b7ser", "Feind", "im", "Traum", "er\u00b7schrickt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "APPRART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und Neid und Sp\u00f6tter schnarchen liegen,", "tokens": ["Und", "Neid", "und", "Sp\u00f6t\u00b7ter", "schnar\u00b7chen", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wird unsre Redligkeit durch Wi\u00dfenschaft entz\u00fcckt.", "tokens": ["Wird", "uns\u00b7re", "Red\u00b7lig\u00b7keit", "durch", "Wi\u00b7\u00dfen\u00b7schaft", "ent\u00b7z\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Wir brauchen Geld. Verlang es nicht;", "tokens": ["Wir", "brau\u00b7chen", "Geld", ".", "Ver\u00b7lang", "es", "nicht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$.", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Himmel weis, wie viel gebricht,", "tokens": ["Der", "Him\u00b7mel", "weis", ",", "wie", "viel", "ge\u00b7bricht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er mu\u00df uns doch die Nothdurft geben;", "tokens": ["Er", "mu\u00df", "uns", "doch", "die", "Noth\u00b7durft", "ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Er mu\u00df, er kan, er wird's auch thun.", "tokens": ["Er", "mu\u00df", ",", "er", "kan", ",", "er", "wird's", "auch", "thun", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "PPER", "VMFIN", "$,", "PPER", "VAFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du weist, da\u00df Gl\u00fcck und Lust zum Leben", "tokens": ["Du", "weist", ",", "da\u00df", "Gl\u00fcck", "und", "Lust", "zum", "Le\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "NN", "KON", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Mehr auf Zufriedenheit als \u00dcberflu\u00df beruhn.", "tokens": ["Mehr", "auf", "Zu\u00b7frie\u00b7den\u00b7heit", "als", "\u00dc\u00b7berf\u00b7lu\u00df", "be\u00b7ruhn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KOUS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Das Absehn unsrer treuen M\u00fch", "tokens": ["Das", "Ab\u00b7sehn", "uns\u00b7rer", "treu\u00b7en", "M\u00fch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist, da\u00df sie Gott zu Ehren bl\u00fch", "tokens": ["Ist", ",", "da\u00df", "sie", "Gott", "zu", "Eh\u00b7ren", "bl\u00fch"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "$,", "KOUS", "PPER", "NN", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und unserm Nechsten einmahl n\u00fcze.", "tokens": ["Und", "un\u00b7serm", "Nechs\u00b7ten", "ein\u00b7mahl", "n\u00fc\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gelingt es nicht, getreuer Freund,", "tokens": ["Ge\u00b7lingt", "es", "nicht", ",", "ge\u00b7treu\u00b7er", "Freund", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So sey dies unser Trost und St\u00fcze:", "tokens": ["So", "sey", "dies", "un\u00b7ser", "Trost", "und", "St\u00fc\u00b7ze", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PDS", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wir thun nach unsrer Kraft und haben's gut gemeint.", "tokens": ["Wir", "thun", "nach", "uns\u00b7rer", "Kraft", "und", "ha\u00b7ben's", "gut", "ge\u00b7meint", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "KON", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Es bleibt wohl auch nicht immer so;", "tokens": ["Es", "bleibt", "wohl", "auch", "nicht", "im\u00b7mer", "so", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PTKNEG", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Oft keimen K\u00f6rner in dem Stroh", "tokens": ["Oft", "kei\u00b7men", "K\u00f6r\u00b7ner", "in", "dem", "Stroh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und Gr\u00e4ser aus dem d\u00fcrren Sande.", "tokens": ["Und", "Gr\u00e4\u00b7ser", "aus", "dem", "d\u00fcr\u00b7ren", "San\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wo ist ein Bliz, der ewig glimmt?", "tokens": ["Wo", "ist", "ein", "Bliz", ",", "der", "e\u00b7wig", "glimmt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wer weis, in welchem guten Lande", "tokens": ["Wer", "weis", ",", "in", "wel\u00b7chem", "gu\u00b7ten", "Lan\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "PTKVZ", "$,", "APPR", "PWAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der Himmel einen Herd vor unser Heil bestimmt!", "tokens": ["Der", "Him\u00b7mel", "ei\u00b7nen", "Herd", "vor", "un\u00b7ser", "Heil", "be\u00b7stimmt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Sieh jeden Sturm, der kommen kan,", "tokens": ["Sieh", "je\u00b7den", "Sturm", ",", "der", "kom\u00b7men", "kan", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NN", "$,", "PRELS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vorher mit Gro\u00dfmuthsaugen an,", "tokens": ["Vor\u00b7her", "mit", "Gro\u00df\u00b7muth\u00b7sau\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Und ist er da, so steh wie Mauren.", "tokens": ["Und", "ist", "er", "da", ",", "so", "steh", "wie", "Mau\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "$,", "ADV", "VVFIN", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich zieh dich mit in viel Gefahr,", "tokens": ["Ich", "zieh", "dich", "mit", "in", "viel", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch hastu wenig zu bedauren,", "tokens": ["Doch", "has\u00b7tu", "we\u00b7nig", "zu", "be\u00b7dau\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die Treue baut dir schon ein ewig Danckaltar.", "tokens": ["Die", "Treu\u00b7e", "baut", "dir", "schon", "ein", "e\u00b7wig", "Dan\u00b7ckal\u00b7tar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Ich weis, wofern auch nur ein Blat", "tokens": ["Ich", "weis", ",", "wo\u00b7fern", "auch", "nur", "ein", "Blat"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "PTKVZ", "$,", "KOUS", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von meiner M\u00fch das Gl\u00fccke hat,", "tokens": ["Von", "mei\u00b7ner", "M\u00fch", "das", "Gl\u00fc\u00b7cke", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Nachwelt Urtheil zu empfinden,", "tokens": ["Der", "Nach\u00b7welt", "Ur\u00b7theil", "zu", "emp\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So wird noch mancher heimlich flehn:", "tokens": ["So", "wird", "noch", "man\u00b7cher", "heim\u00b7lich", "flehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PIAT", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ach h\u00e4tt ich doch nur das Verbinden", "tokens": ["Ach", "h\u00e4tt", "ich", "doch", "nur", "das", "Ver\u00b7bin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "VAFIN", "PPER", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der Br\u00fcder solcher Art mit Augen angesehn!", "tokens": ["Der", "Br\u00fc\u00b7der", "sol\u00b7cher", "Art", "mit", "Au\u00b7gen", "an\u00b7ge\u00b7sehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Ihr Seelen, deren Freundschaftsbund", "tokens": ["Ihr", "See\u00b7len", ",", "de\u00b7ren", "Freund\u00b7schafts\u00b7bund"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PRELAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus gleicher Lieb und Treu entstund", "tokens": ["Aus", "glei\u00b7cher", "Lieb", "und", "Treu", "ent\u00b7stund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "KON"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und deren Nachruhm noch nicht schweiget,", "tokens": ["Und", "de\u00b7ren", "Nach\u00b7ruhm", "noch", "nicht", "schwei\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich seh, wie euer kleines Chor", "tokens": ["Ich", "seh", ",", "wie", "eu\u00b7er", "klei\u00b7nes", "Chor"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Schon l\u00e4ngst am Ehrenhimmel steiget,", "tokens": ["Schon", "l\u00e4ngst", "am", "Eh\u00b7ren\u00b7him\u00b7mel", "stei\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und bitte: Zieht auch uns in euren Kreis empor!", "tokens": ["Und", "bit\u00b7te", ":", "Zieht", "auch", "uns", "in", "eu\u00b7ren", "Kreis", "em\u00b7por", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKANT", "$.", "VVFIN", "ADV", "PPER", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Der Ehrgeiz treibt mich von Natur,", "tokens": ["Der", "Ehr\u00b7geiz", "treibt", "mich", "von", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf gro\u00dfer Geister Weg und Spur", "tokens": ["Auf", "gro\u00b7\u00dfer", "Geis\u00b7ter", "Weg", "und", "Spur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein weit Ged\u00e4chtn\u00fc\u00df zu erlangen.", "tokens": ["Ein", "weit", "Ge\u00b7d\u00e4cht\u00b7n\u00fc\u00df", "zu", "er\u00b7lan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Erhebt euch durch Verstand und Schwerd;", "tokens": ["Er\u00b7hebt", "euch", "durch", "Ver\u00b7stand", "und", "Schwerd", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich will mit keinen Lorbeern prangen", "tokens": ["Ich", "will", "mit", "kei\u00b7nen", "Lor\u00b7beern", "pran\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Als die mir Lieb und Treu durch Schubarten gew\u00e4hrt.", "tokens": ["Als", "die", "mir", "Lieb", "und", "Treu", "durch", "Schu\u00b7bar\u00b7ten", "ge\u00b7w\u00e4hrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PPER", "NN", "KON", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-++--+", "measure": "iambic.hexa.chol"}}}}}