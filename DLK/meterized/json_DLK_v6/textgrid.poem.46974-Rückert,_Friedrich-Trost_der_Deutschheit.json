{"textgrid.poem.46974": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Trost der Deutschheit", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wo willst du hin, o edles Weib,", "tokens": ["Wo", "willst", "du", "hin", ",", "o", "ed\u00b7les", "Weib", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PTKVZ", "$,", "FM", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wie bist du genannt?", "tokens": ["Und", "wie", "bist", "du", "ge\u00b7nannt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Du tr\u00e4gst f\u00fcrwahr an deinem Leib", "tokens": ["Du", "tr\u00e4gst", "f\u00fcr\u00b7wahr", "an", "dei\u00b7nem", "Leib"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gar seltsames Gewand.", "tokens": ["Gar", "selt\u00b7sa\u00b7mes", "Ge\u00b7wand", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "\u00bbdie Deutschheit zubenannt ich bin,", "tokens": ["\u00bb", "die", "Deutschheit", "zu\u00b7be\u00b7nannt", "ich", "bin", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "PPER", "VAFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und altdeutsch ist dies Kleid;", "tokens": ["Und", "alt\u00b7deutsch", "ist", "dies", "Kleid", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PDS", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df dir es deucht in deinem Sinn", "tokens": ["Da\u00df", "dir", "es", "deucht", "in", "dei\u00b7nem", "Sinn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So seltsam, thut mir leid.\u00ab", "tokens": ["So", "selt\u00b7sam", ",", "thut", "mir", "leid", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "$,", "VVFIN", "PPER", "ADJD", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Und wo denn willst du hin so schnell?", "tokens": ["Und", "wo", "denn", "willst", "du", "hin", "so", "schnell", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "VMFIN", "PPER", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Berichte du mich des.", "tokens": ["Be\u00b7rich\u00b7te", "du", "mich", "des", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ART", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "\u00bbwie du mich siehst, geh' ich zur Stell'", "tokens": ["\u00bb", "wie", "du", "mich", "siehst", ",", "geh'", "ich", "zur", "Stell'"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "PPER", "PRF", "VVFIN", "$,", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nach Wien jetzt zum Kongre\u00df.\u00ab", "tokens": ["Nach", "Wi\u00b7en", "jetzt", "zum", "Kon\u00b7gre\u00df", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NE", "ADV", "APPRART", "NN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Wohl freilich ja, es handelt sich", "tokens": ["Wohl", "frei\u00b7lich", "ja", ",", "es", "han\u00b7delt", "sich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "$,", "PPER", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Daselbst um dich auch mit;", "tokens": ["Da\u00b7selbst", "um", "dich", "auch", "mit", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch welchen Sprecher hast du, sprich,", "tokens": ["Doch", "wel\u00b7chen", "Spre\u00b7cher", "hast", "du", ",", "sprich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWAT", "NN", "VAFIN", "PPER", "$,", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der dich dabei vertritt?", "tokens": ["Der", "dich", "da\u00b7bei", "ver\u00b7tritt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PAV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "\u00bbich brauche keinen Sprecher nicht,", "tokens": ["\u00bb", "ich", "brau\u00b7che", "kei\u00b7nen", "Spre\u00b7cher", "nicht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PIAT", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Sprech'rin selbst bin ich.\u00ab", "tokens": ["Die", "Sprech'\u00b7rin", "selbst", "bin", "ich", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wenn man nun dort franz\u00f6sisch spricht,", "tokens": ["Wenn", "man", "nun", "dort", "fran\u00b7z\u00f6\u00b7sisch", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kannst du Franz\u00f6sisch? sprich!", "tokens": ["Kannst", "du", "Fran\u00b7z\u00f6\u00b7sisch", "?", "sprich", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "$.", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "\u00bbo weh, ich arme deutsche Frau,", "tokens": ["\u00bb", "o", "weh", ",", "ich", "ar\u00b7me", "deut\u00b7sche", "Frau", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "PTKVZ", "$,", "PPER", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Franz\u00f6sisch kann ich nicht;", "tokens": ["Fran\u00b7z\u00f6\u00b7sisch", "kann", "ich", "nicht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wo find' ich nur auf deutscher Au", "tokens": ["Wo", "find'", "ich", "nur", "auf", "deut\u00b7scher", "Au"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gleich einen, der es spricht?\u00ab", "tokens": ["Gleich", "ei\u00b7nen", ",", "der", "es", "spricht", "?", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ART", "$,", "PRELS", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Oh, mehr als einer findet sich,", "tokens": ["Oh", ",", "mehr", "als", "ei\u00b7ner", "fin\u00b7det", "sich", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "KOUS", "PIS", "VVFIN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der gut franz\u00f6sisch spricht;", "tokens": ["Der", "gut", "fran\u00b7z\u00f6\u00b7sisch", "spricht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch, ob er gut es spricht f\u00fcr dich,", "tokens": ["Doch", ",", "ob", "er", "gut", "es", "spricht", "f\u00fcr", "dich", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADJD", "PPER", "VVFIN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das wei\u00df ich freilich nicht.", "tokens": ["Das", "wei\u00df", "ich", "frei\u00b7lich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}