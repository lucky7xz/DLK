{"dta.poem.68": {"metadata": {"author": {"name": "Klopstock, Friedrich Gottlieb", "birth": "N.A.", "death": "N.A."}, "title": "An Bodmer.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1771", "urn": "urn:nbn:de:kobv:b4-200905199486", "language": ["de:0.99"], "booktitle": "[Klopstock, Friedrich Gottlieb]: Oden. Hamburg, 1771."}, "poem": {"stanza.1": {"line.1": {"text": "Der die Schickungen lenkt, heisset den fr\u00f6mmsten", "tokens": ["Der", "die", "Schi\u00b7ckun\u00b7gen", "lenkt", ",", "heis\u00b7set", "den", "fr\u00f6mms\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ART", "NN", "VVFIN", "$,", "VVFIN", "ART", "ADJA"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Mancher Seligkeit goldnes Bild", "tokens": ["Man\u00b7cher", "Se\u00b7lig\u00b7keit", "gold\u00b7nes", "Bild"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "ADJA", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Oft verwehen, und ruft da Labyrinth hervor,", "tokens": ["Oft", "ver\u00b7we\u00b7hen", ",", "und", "ruft", "da", "La\u00b7by\u00b7rinth", "her\u00b7vor", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$,", "KON", "VVFIN", "ADV", "NN", "PTKVZ", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Wo ein Sterblicher gehen will.", "tokens": ["Wo", "ein", "Sterb\u00b7li\u00b7cher", "ge\u00b7hen", "will", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "In die Fernen hinaus sieht, der Unendlichkeit", "tokens": ["In", "die", "Fer\u00b7nen", "hin\u00b7aus", "sieht", ",", "der", "Un\u00b7end\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "ADJA", "APZR", "VVFIN", "$,", "ART", "NN"], "meter": "--+---+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Uns unsichtbaren Schauplatz, Gott!", "tokens": ["Uns", "un\u00b7sicht\u00b7ba\u00b7ren", "Schau\u00b7platz", ",", "Gott", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ach, sie finden sich nicht, die f\u00fcr einander doch,", "tokens": ["Ach", ",", "sie", "fin\u00b7den", "sich", "nicht", ",", "die", "f\u00fcr", "ein\u00b7an\u00b7der", "doch", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VVFIN", "PRF", "PTKNEG", "$,", "PRELS", "APPR", "PRF", "ADV", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.8": {"text": "Und zur Liebe gesch\u00e4ffen sind.", "tokens": ["Und", "zur", "Lie\u00b7be", "ge\u00b7sch\u00e4f\u00b7fen", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVPP", "VAFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.9": {"text": "Jetzo trennet die Nacht fernerer Himmel sie,", "tokens": ["Jet\u00b7zo", "tren\u00b7net", "die", "Nacht", "fer\u00b7ne\u00b7rer", "Him\u00b7mel", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJA", "NN", "PPER", "$,"], "meter": "+-+--+---+-+", "measure": "trochaic.penta.relaxed"}, "line.10": {"text": "Jetzo lange Jahrhunderte.", "tokens": ["Jet\u00b7zo", "lan\u00b7ge", "Jahr\u00b7hun\u00b7der\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Niemals sah dich mein Blick, Sokrates-Addison,", "tokens": ["Nie\u00b7mals", "sah", "dich", "mein", "Blick", ",", "So\u00b7kra\u00b7tes\u00b7Ad\u00b7di\u00b7son", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,", "NE", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.12": {"text": "Niemals lehrte dein Mund mich selbst.", "tokens": ["Nie\u00b7mals", "lehr\u00b7te", "dein", "Mund", "mich", "selbst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "PPER", "ADV", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.13": {"text": "Niemals l\u00e4chelte mir Singer, der Lebenden", "tokens": ["Nie\u00b7mals", "l\u00e4\u00b7chel\u00b7te", "mir", "Sin\u00b7ger", ",", "der", "Le\u00b7ben\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,", "ART", "NN"], "meter": "+-+-+-+--+--", "measure": "trochaic.penta.relaxed"}, "line.14": {"text": "Und der Todten Gesellerinn.", "tokens": ["Und", "der", "Tod\u00b7ten", "Ge\u00b7sel\u00b7le\u00b7rinn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.15": {"text": "Auch dich werd ich nicht sehn, der du in jener Zeit,", "tokens": ["Auch", "dich", "werd", "ich", "nicht", "sehn", ",", "der", "du", "in", "je\u00b7ner", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "PPER", "PTKNEG", "VVINF", "$,", "PRELS", "PPER", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Wenn ich lange gestorben bin,", "tokens": ["Wenn", "ich", "lan\u00b7ge", "ge\u00b7stor\u00b7ben", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "VAFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.17": {"text": "F\u00fcr mein Herze gemacht, und mir der \u00e4hnlichste,", "tokens": ["F\u00fcr", "mein", "Her\u00b7ze", "ge\u00b7macht", ",", "und", "mir", "der", "\u00e4hn\u00b7lichs\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$,", "KON", "PPER", "ART", "ADJA", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.18": {"text": "Nach mir einmal auch seufzen wirst,", "tokens": ["Nach", "mir", "ein\u00b7mal", "auch", "seuf\u00b7zen", "wirst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "ADV", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Auch dich werd ich nicht sehn, wie du dein Leben lebst,", "tokens": ["Auch", "dich", "werd", "ich", "nicht", "sehn", ",", "wie", "du", "dein", "Le\u00b7ben", "lebst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "PPER", "PTKNEG", "VVINF", "$,", "PWAV", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Werd ich einst nicht dein Genius.", "tokens": ["Werd", "ich", "einst", "nicht", "dein", "Ge\u00b7nius", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.21": {"text": "Also ordnet es Gott, der in die Fernen sieht,", "tokens": ["Al\u00b7so", "ord\u00b7net", "es", "Gott", ",", "der", "in", "die", "Fer\u00b7nen", "sieht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,", "PRELS", "APPR", "ART", "ADJA", "VVFIN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.22": {"text": "Tiefer hin ins Unendliche!", "tokens": ["Tie\u00b7fer", "hin", "ins", "Un\u00b7end\u00b7li\u00b7che", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "APPRART", "NN", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.23": {"text": "Oft erf\u00fcllet er auch, was das erzitternde", "tokens": ["Oft", "er\u00b7f\u00fcl\u00b7let", "er", "auch", ",", "was", "das", "er\u00b7zit\u00b7tern\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "PRELS", "ART", "ADJA"], "meter": "--+--+-+-+--", "measure": "anapaest.di.plus"}, "line.24": {"text": "Volle Herz kaum zu w\u00fcnschen wagt.", "tokens": ["Vol\u00b7le", "Herz", "kaum", "zu", "w\u00fcn\u00b7schen", "wagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.25": {"text": "Wie von Tr\u00e4umen erwacht, sehn wir dann unser Gl\u00fcck,", "tokens": ["Wie", "von", "Tr\u00e4u\u00b7men", "er\u00b7wacht", ",", "sehn", "wir", "dann", "un\u00b7ser", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "VVPP", "$,", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.26": {"text": "Sehns mit Augen, und glaubens kaum.", "tokens": ["Sehns", "mit", "Au\u00b7gen", ",", "und", "glau\u00b7bens", "kaum", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "KON", "ADV", "ADV", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.27": {"text": "Dieses Gl\u00fccke ward mir, als ich das erstemal", "tokens": ["Die\u00b7ses", "Gl\u00fc\u00b7cke", "ward", "mir", ",", "als", "ich", "das", "ers\u00b7te\u00b7mal"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "VAFIN", "PPER", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.28": {"text": "Bodmers Armen entgegen kam.", "tokens": ["Bod\u00b7mers", "Ar\u00b7men", "ent\u00b7ge\u00b7gen", "kam", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPO", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}}}}