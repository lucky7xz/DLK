{"textgrid.poem.57318": {"metadata": {"author": {"name": "Klopstock, Friedrich Gottlieb", "birth": "N.A.", "death": "N.A."}, "title": "1L: O Krieg des sch\u00f6neren Lorbers werth,", "genre": "verse", "period": "N.A.", "pub_year": 1781, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O Krieg des sch\u00f6neren Lorbers werth,", "tokens": ["O", "Krieg", "des", "sch\u00f6\u00b7ne\u00b7ren", "Lor\u00b7bers", "werth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der unter dem schwellenden Segel, des Wimpels Fluge,", "tokens": ["Der", "un\u00b7ter", "dem", "schwel\u00b7len\u00b7den", "Se\u00b7gel", ",", "des", "Wim\u00b7pels", "Flu\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+--+--+--+-+-", "measure": "amphibrach.tetra.plus"}, "line.3": {"text": "Jetzo gef\u00fchrt wird, du Krieg der edleren Helden!", "tokens": ["Jet\u00b7zo", "ge\u00b7f\u00fchrt", "wird", ",", "du", "Krieg", "der", "ed\u00b7le\u00b7ren", "Hel\u00b7den", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAFIN", "$,", "PPER", "NN", "ART", "ADJA", "NN", "$."], "meter": "+--+--+-+--+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Dich singe der Dithyrambe, der keine Kriege sang.", "tokens": ["Dich", "sin\u00b7ge", "der", "Dit\u00b7hy\u00b7ram\u00b7be", ",", "der", "kei\u00b7ne", "Krie\u00b7ge", "sang", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.2": {"line.1": {"text": "Ein hoher Genius der Menschlichkeit:", "tokens": ["Ein", "ho\u00b7her", "Ge\u00b7nius", "der", "Menschlich\u00b7keit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Begeistert dich!", "tokens": ["Be\u00b7geis\u00b7tert", "dich", "!"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Du bist die Morgenr\u00f6the", "tokens": ["Du", "bist", "die", "Mor\u00b7gen\u00b7r\u00f6\u00b7the"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Eines nahenden grossen Tags!", "tokens": ["Ei\u00b7nes", "na\u00b7hen\u00b7den", "gros\u00b7sen", "Tags", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.3": {"line.1": {"text": "Europa's Bildung erhebt sich", "tokens": ["Eu\u00b7ro\u00b7pa's", "Bil\u00b7dung", "er\u00b7hebt", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NN", "VVFIN", "PRF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mit Adlerschwunge, durch weise Z\u00f6gerung", "tokens": ["Mit", "Ad\u00b7ler\u00b7schwun\u00b7ge", ",", "durch", "wei\u00b7se", "Z\u00f6\u00b7ge\u00b7rung"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Des Blutvergusses, durch weisere Meidung,", "tokens": ["Des", "Blut\u00b7ver\u00b7gus\u00b7ses", ",", "durch", "wei\u00b7se\u00b7re", "Mei\u00b7dung", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Durch g\u00f6ttliche Schonung,", "tokens": ["Durch", "g\u00f6tt\u00b7li\u00b7che", "Scho\u00b7nung", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.4": {"line.1": {"text": "In Stunden, da den Bruder t\u00f6dtend,", "tokens": ["In", "Stun\u00b7den", ",", "da", "den", "Bru\u00b7der", "t\u00f6d\u00b7tend", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "KOUS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der erhabene Mensch zum Ungeheuer werden muss.", "tokens": ["Der", "er\u00b7ha\u00b7be\u00b7ne", "Mensch", "zum", "Un\u00b7ge\u00b7heu\u00b7er", "wer\u00b7den", "muss", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "VAINF", "VMFIN", "$."], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Denn die Flotten schweben umher auf dem Ozean,", "tokens": ["Denn", "die", "Flot\u00b7ten", "schwe\u00b7ben", "um\u00b7her", "auf", "dem", "O\u00b7ze\u00b7an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKVZ", "APPR", "ART", "NN", "$,"], "meter": "+-+-+--+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Und suchen sich, und finden sich nicht.", "tokens": ["Und", "su\u00b7chen", "sich", ",", "und", "fin\u00b7den", "sich", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "$,", "KON", "VVFIN", "PRF", "PTKNEG", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.5": {"line.1": {"text": "Und wenn sie verweht, oder verstr\u00f6mt, sich endlich erblicken:", "tokens": ["Und", "wenn", "sie", "ver\u00b7weht", ",", "o\u00b7der", "ver\u00b7str\u00f6mt", ",", "sich", "end\u00b7lich", "er\u00b7bli\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "KON", "VVPP", "$,", "PRF", "ADV", "VVINF", "$."], "meter": "-+--+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "So k\u00e4mpfen sie l\u00e4nger als je", "tokens": ["So", "k\u00e4mp\u00b7fen", "sie", "l\u00e4n\u00b7ger", "als", "je"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "KOKOM", "ADV"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Den leichtzertrennenden Kampf", "tokens": ["Den", "leicht\u00b7zer\u00b7tren\u00b7nen\u00b7den", "Kampf"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Um des Windes Beystand.", "tokens": ["Um", "des", "Win\u00b7des", "Beys\u00b7tand", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Und muss es zuletzt denn doch auch beginnen", "tokens": ["Und", "muss", "es", "zu\u00b7letzt", "denn", "doch", "auch", "be\u00b7gin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADV", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das Treffen; so schlagen sie fern. F\u00fcrchterlich br\u00fcllet", "tokens": ["Das", "Tref\u00b7fen", ";", "so", "schla\u00b7gen", "sie", "fern", ".", "F\u00fcrch\u00b7ter\u00b7lich", "br\u00fcl\u00b7let"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$.", "ADV", "VVFIN", "PPER", "ADJD", "$.", "ADJD", "VVFIN"], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ihr Donner; aber er rollt", "tokens": ["Ihr", "Don\u00b7ner", ";", "a\u00b7ber", "er", "rollt"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$.", "KON", "PPER", "VVFIN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Seine Tod' in das Meer.", "tokens": ["Sei\u00b7ne", "Tod'", "in", "das", "Meer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.7": {"line.1": {"text": "Kein Schiff wird erobert, und keins, zu belastet", "tokens": ["Kein", "Schiff", "wird", "er\u00b7o\u00b7bert", ",", "und", "keins", ",", "zu", "be\u00b7las\u00b7tet"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "VVPP", "$,", "KON", "PIAT", "$,", "PTKZU", "VVFIN"], "meter": "-++-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Von der hineinrauschenden Woge, versenkt,", "tokens": ["Von", "der", "hin\u00b7ein\u00b7rau\u00b7schen\u00b7den", "Wo\u00b7ge", ",", "ver\u00b7senkt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Keins flamt in die H\u00f6h, und treibet,", "tokens": ["Keins", "flamt", "in", "die", "H\u00f6h", ",", "und", "trei\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "ART", "NN", "$,", "KON", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Scheiter, umher \u00fcber sinkenden Leichen.", "tokens": ["Schei\u00b7ter", ",", "um\u00b7her", "\u00fc\u00b7ber", "sin\u00b7ken\u00b7den", "Lei\u00b7chen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PTKVZ", "APPR", "ADJA", "NN", "$."], "meter": "+---+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Der Flotten, und der Schiffe Gebieter", "tokens": ["Der", "Flot\u00b7ten", ",", "und", "der", "Schif\u00b7fe", "Ge\u00b7bie\u00b7ter"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KON", "ART", "NN", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Schlagen so, ohne gegebenes Wort.", "tokens": ["Schla\u00b7gen", "so", ",", "oh\u00b7ne", "ge\u00b7ge\u00b7be\u00b7nes", "Wort", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "KOUI", "ADJA", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Was brauchen sie der Worte die tiefer denkenden", "tokens": ["Was", "brau\u00b7chen", "sie", "der", "Wor\u00b7te", "die", "tie\u00b7fer", "den\u00b7ken\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "M\u00e4nner? Sie handeln! verstehen sich durch ihr Handeln!", "tokens": ["M\u00e4n\u00b7ner", "?", "Sie", "han\u00b7deln", "!", "ver\u00b7ste\u00b7hen", "sich", "durch", "ihr", "Han\u00b7deln", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VVINF", "$.", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}}, "stanza.9": {"line.1": {"text": "Erdek\u00f6nigin, Europa! dich hebt, bis hinauf", "tokens": ["Er\u00b7de\u00b7k\u00f6\u00b7ni\u00b7gin", ",", "Eu\u00b7ro\u00b7pa", "!", "dich", "hebt", ",", "bis", "hin\u00b7auf"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "NE", "$.", "PPER", "VVFIN", "$,", "KOUS", "ADV"], "meter": "+-+-+-+--+--+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Zu dem hohen Ziel, deiner Bildung Adlerschwung:", "tokens": ["Zu", "dem", "ho\u00b7hen", "Ziel", ",", "dei\u00b7ner", "Bil\u00b7dung", "Ad\u00b7ler\u00b7schwung", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "PPOSAT", "NN", "NN", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Wenn unter deinen edleren Kriegern", "tokens": ["Wenn", "un\u00b7ter", "dei\u00b7nen", "ed\u00b7le\u00b7ren", "Krie\u00b7gern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Diese heilige Schonung Sitte wird!", "tokens": ["Die\u00b7se", "hei\u00b7li\u00b7ge", "Scho\u00b7nung", "Sit\u00b7te", "wird", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "NN", "VAFIN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.10": {"line.1": {"text": "O dann ist, was jetzo beginnt, der Morgenr\u00f6then sch\u00f6nste;", "tokens": ["O", "dann", "ist", ",", "was", "jet\u00b7zo", "be\u00b7ginnt", ",", "der", "Mor\u00b7gen\u00b7r\u00f6\u00b7then", "sch\u00f6ns\u00b7te", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "VAFIN", "$,", "PRELS", "ADV", "VVFIN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "Denn sie verk\u00fcndiget", "tokens": ["Denn", "sie", "ver\u00b7k\u00fcn\u00b7di\u00b7get"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPER", "VVFIN"], "meter": "++-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Einen seligen, nie noch von Mensch erlebten Tag,", "tokens": ["Ei\u00b7nen", "se\u00b7li\u00b7gen", ",", "nie", "noch", "von", "Mensch", "er\u00b7leb\u00b7ten", "Tag", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADV", "ADV", "APPR", "NN", "ADJA", "NN", "$,"], "meter": "+-+--+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Der Jahrhunderte strahlt,", "tokens": ["Der", "Jahr\u00b7hun\u00b7der\u00b7te", "strahlt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Auf uns, die noch nicht wussten, der Krieg", "tokens": ["Auf", "uns", ",", "die", "noch", "nicht", "wuss\u00b7ten", ",", "der", "Krieg"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPER", "$,", "PRELS", "ADV", "PTKNEG", "VVFIN", "$,", "ART", "NN"], "meter": "-----+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Sey das zischendste, tiefste Brandmaal der Menschheit!", "tokens": ["Sey", "das", "zi\u00b7schends\u00b7te", ",", "tiefs\u00b7te", "Brand\u00b7maal", "der", "Menschheit", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "$,", "ADJA", "NN", "ART", "NN", "$."], "meter": "---+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Mit welcher Hoheit Blick wird auf uns herabsehn,", "tokens": ["Mit", "wel\u00b7cher", "Ho\u00b7heit", "Blick", "wird", "auf", "uns", "her\u00b7ab\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "NN", "VAFIN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Wen die Heitre labt des goldenen Tages!", "tokens": ["Wen", "die", "Heit\u00b7re", "labt", "des", "gol\u00b7de\u00b7nen", "Ta\u00b7ges", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}}, "stanza.12": {"line.1": {"text": "Warest du, Saite, wirklicher Zukunft Weissagerin?", "tokens": ["Wa\u00b7rest", "du", ",", "Sai\u00b7te", ",", "wirk\u00b7li\u00b7cher", "Zu\u00b7kunft", "Weis\u00b7sa\u00b7ge\u00b7rin", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "NN", "$,", "ADJA", "NN", "NN", "$."], "meter": "+--+-+--+-++-+", "measure": "iambic.septa.invert"}, "line.2": {"text": "Sahe der Geist, welcher dich umschwebt,", "tokens": ["Sa\u00b7he", "der", "Geist", ",", "wel\u00b7cher", "dich", "um\u00b7schwebt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+--++-+-+", "measure": "dactylic.init"}, "line.3": {"text": "G\u00f6ttermenschen? oder hat er vernichtungsscheue", "tokens": ["G\u00f6t\u00b7ter\u00b7men\u00b7schen", "?", "o\u00b7der", "hat", "er", "ver\u00b7nich\u00b7tungs\u00b7scheu\u00b7e"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "KON", "VAFIN", "PPER", "VVFIN"], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Gottesleugner gesehn?", "tokens": ["Got\u00b7tes\u00b7leug\u00b7ner", "ge\u00b7sehn", "?"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}}}}