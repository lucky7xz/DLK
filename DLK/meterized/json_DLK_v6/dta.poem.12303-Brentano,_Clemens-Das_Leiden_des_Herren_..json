{"dta.poem.12303": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Das Leiden des Herren .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1806", "urn": "urn:nbn:de:kobv:b4-20090519157", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Christus, der Herr im Garten ging,               ", "tokens": ["Chris\u00b7tus", ",", "der", "Herr", "im", "Gar\u00b7ten", "ging", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sein bittres Leiden bald anfing,", "tokens": ["Sein", "bitt\u00b7res", "Lei\u00b7den", "bald", "an\u00b7fing", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da trauert Laub und gr\u00fcnes Gras,", "tokens": ["Da", "trau\u00b7ert", "Laub", "und", "gr\u00fc\u00b7nes", "Gras", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Weil Judas seiner bald vergas.", "tokens": ["Weil", "Ju\u00b7das", "sei\u00b7ner", "bald", "ver\u00b7gas", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPOSAT", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Sehr f\u00e4lschlich er ihn hinterging,", "tokens": ["Sehr", "f\u00e4lschlich", "er", "ihn", "hin\u00b7ter\u00b7ging", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ein schn\u00f6des Geld daf\u00fcr empfing,", "tokens": ["Ein", "schn\u00f6\u00b7des", "Geld", "da\u00b7f\u00fcr", "emp\u00b7fing", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Verkaufte seinen Gott und Herrn,", "tokens": ["Ver\u00b7kauf\u00b7te", "sei\u00b7nen", "Gott", "und", "Herrn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das sahen die Juden herzlich gern.", "tokens": ["Das", "sa\u00b7hen", "die", "Ju\u00b7den", "herz\u00b7lich", "gern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ADJD", "ADV", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Sie gingen in den Garten hin,", "tokens": ["Sie", "gin\u00b7gen", "in", "den", "Gar\u00b7ten", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit zornigem und b\u00f6sem Sinn,", "tokens": ["Mit", "zor\u00b7ni\u00b7gem", "und", "b\u00f6\u00b7sem", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Spie\u00df und Stangen die lose Rott,", "tokens": ["Mit", "Spie\u00df", "und", "Stan\u00b7gen", "die", "lo\u00b7se", "Rott", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Gefangen nahmen unsern Gott.", "tokens": ["Ge\u00b7fan\u00b7gen", "nah\u00b7men", "un\u00b7sern", "Gott", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Sie f\u00fchrten ihn ins Richters Haus,", "tokens": ["Sie", "f\u00fchr\u00b7ten", "ihn", "ins", "Rich\u00b7ters", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit scharfen Striemen wieder raus,", "tokens": ["Mit", "schar\u00b7fen", "Strie\u00b7men", "wie\u00b7der", "raus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gegeiselt und mit Dorn gekr\u00f6nt,", "tokens": ["Ge\u00b7gei\u00b7selt", "und", "mit", "Dorn", "ge\u00b7kr\u00f6nt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ach Jesu! wurdest du verh\u00f6hnt.", "tokens": ["Ach", "Je\u00b7su", "!", "wur\u00b7dest", "du", "ver\u00b7h\u00f6hnt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "ITJ", "$.", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ein scharfes Urtheil sprachen sie,", "tokens": ["Ein", "schar\u00b7fes", "Ur\u00b7theil", "spra\u00b7chen", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Indem der ganze Haufe schrie:", "tokens": ["In\u00b7dem", "der", "gan\u00b7ze", "Hau\u00b7fe", "schrie", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201enur weg, nur weg, nach Golgatha,", "tokens": ["\u201e", "nur", "weg", ",", "nur", "weg", ",", "nach", "Gol\u00b7ga\u00b7tha", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "PTKVZ", "$,", "ADV", "PTKVZ", "$,", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eund schlagt ihn an das Kreuze da.\u201c", "tokens": ["\u201e", "und", "schlagt", "ihn", "an", "das", "Kreu\u00b7ze", "da", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Er tr\u00e4gt das Kreuz, er tr\u00e4gt die Welt,", "tokens": ["Er", "tr\u00e4gt", "das", "Kreuz", ",", "er", "tr\u00e4gt", "die", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er ist dazu von Gott bestellt,", "tokens": ["Er", "ist", "da\u00b7zu", "von", "Gott", "be\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er tr\u00e4gt es mit gela\u00dfnem Muth,", "tokens": ["Er", "tr\u00e4gt", "es", "mit", "ge\u00b7la\u00df\u00b7nem", "Muth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es str\u00f6met von ihm Schweis und Blut.", "tokens": ["Es", "str\u00f6\u00b7met", "von", "ihm", "Schweis", "und", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ersch\u00f6pfet will er ruhen aus,", "tokens": ["Er\u00b7sch\u00f6p\u00b7fet", "will", "er", "ru\u00b7hen", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VMFIN", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vor eines reichen Juden Haus,", "tokens": ["Vor", "ei\u00b7nes", "rei\u00b7chen", "Ju\u00b7den", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Jude stie\u00df ihn spottend weg,", "tokens": ["Der", "Ju\u00b7de", "stie\u00df", "ihn", "spot\u00b7tend", "weg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er blickt ihn an, geht seinen Weg.", "tokens": ["Er", "blickt", "ihn", "an", ",", "geht", "sei\u00b7nen", "Weg", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Herr Jesus schwieg, doch Gott der bannt", "tokens": ["Herr", "Je\u00b7sus", "schwieg", ",", "doch", "Gott", "der", "bannt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NE", "VVFIN", "$,", "KON", "NN", "ART", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Juden, da\u00df er zieht durchs Land,", "tokens": ["Den", "Ju\u00b7den", ",", "da\u00df", "er", "zieht", "durchs", "Land", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und kann nicht sterben nimmermehr,", "tokens": ["Und", "kann", "nicht", "ster\u00b7ben", "nim\u00b7mer\u00b7mehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PTKNEG", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und wandert immer hin und her.", "tokens": ["Und", "wan\u00b7dert", "im\u00b7mer", "hin", "und", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ans Kreuz sie hingen Jesum bald,", "tokens": ["Ans", "Kreuz", "sie", "hin\u00b7gen", "Je\u00b7sum", "bald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Maria ward das Herze kalt:", "tokens": ["Ma\u00b7ria", "ward", "das", "Her\u00b7ze", "kalt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PDS", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u201eo weh, o weh! mein liebstes Herz,", "tokens": ["\u201e", "o", "weh", ",", "o", "weh", "!", "mein", "liebs\u00b7tes", "Herz", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "FM", "PTKVZ", "$,", "FM", "PTKVZ", "$.", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eich sterb zugleich von gleichem Schmerz.\u201c", "tokens": ["\u201e", "ich", "sterb", "zu\u00b7gleich", "von", "glei\u00b7chem", "Schmerz", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Maria unterm Kreuze stund,", "tokens": ["Ma\u00b7ria", "un\u00b7term", "Kreu\u00b7ze", "stund", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sie war betr\u00fcbt von Herzens-Grund,", "tokens": ["Sie", "war", "be\u00b7tr\u00fcbt", "von", "Her\u00b7zens\u00b7Grund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Von Herzen war sie sehr betr\u00fcbt", "tokens": ["Von", "Her\u00b7zen", "war", "sie", "sehr", "be\u00b7tr\u00fcbt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Um Jesum, den sie herzlich liebt.", "tokens": ["Um", "Je\u00b7sum", ",", "den", "sie", "herz\u00b7lich", "liebt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "$,", "PRELS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "\u201ejohannes, liebster J\u00fcnger mein,", "tokens": ["\u201e", "jo\u00b7han\u00b7nes", ",", "liebs\u00b7ter", "J\u00fcn\u00b7ger", "mein", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "$,", "ADJA", "NN", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201ela\u00df dir mein' Mutter befohlen seyn,", "tokens": ["\u201e", "la\u00df", "dir", "mein'", "Mut\u00b7ter", "be\u00b7foh\u00b7len", "seyn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "PPOSAT", "NN", "VVPP", "VAINF", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "\u201enimm sie zur Hand, f\u00fchr sie von dann,", "tokens": ["\u201e", "nimm", "sie", "zur", "Hand", ",", "f\u00fchr", "sie", "von", "dann", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "APPRART", "NN", "$,", "VVFIN", "PPER", "APPR", "ADV", "$,"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eda\u00df sie nicht schau mein Marter an.\u201c", "tokens": ["\u201e", "da\u00df", "sie", "nicht", "schau", "mein", "Mar\u00b7ter", "an", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "PTKNEG", "ADJD", "PPOSAT", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "\u201eja, Herr, das will ich gerne thun,", "tokens": ["\u201e", "ja", ",", "Herr", ",", "das", "will", "ich", "ger\u00b7ne", "thun", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "NN", "$,", "PDS", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eich will sie f\u00fchren allzusch\u00f6n,", "tokens": ["\u201e", "ich", "will", "sie", "f\u00fch\u00b7ren", "all\u00b7zu\u00b7sch\u00f6n", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201eich will sie tr\u00f6sten wohl und gut,", "tokens": ["\u201e", "ich", "will", "sie", "tr\u00f6s\u00b7ten", "wohl", "und", "gut", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "PPER", "VVFIN", "ADV", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201ewie ein Kind seiner Mutter thut.\u201c", "tokens": ["\u201e", "wie", "ein", "Kind", "sei\u00b7ner", "Mut\u00b7ter", "thut", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "ART", "NN", "PPOSAT", "NN", "VVFIN", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}}}}