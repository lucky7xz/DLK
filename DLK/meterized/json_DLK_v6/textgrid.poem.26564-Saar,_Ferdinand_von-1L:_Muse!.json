{"textgrid.poem.26564": {"metadata": {"author": {"name": "Saar, Ferdinand von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Muse!", "genre": "verse", "period": "N.A.", "pub_year": 1869, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Muse!", "tokens": ["Mu\u00b7se", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Die du einst Goethe's,", "tokens": ["Die", "du", "einst", "Goe\u00b7the's", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "NE", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Die du einst Schiller's Stirn gek\u00fc\u00dft:", "tokens": ["Die", "du", "einst", "Schil\u00b7ler's", "Stirn", "ge\u00b7k\u00fc\u00dft", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "NE", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Warum nicht wieder,", "tokens": ["Wa\u00b7rum", "nicht", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "ADV", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Nachdem ein Jahrhundert verflossen,", "tokens": ["Nach\u00b7dem", "ein", "Jahr\u00b7hun\u00b7dert", "ver\u00b7flos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVPP", "$,"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Umf\u00e4ngst du \u2013", "tokens": ["Um\u00b7f\u00e4ngst", "du", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PPER", "$("], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Statt nur hier und dort mit leisem Fittig zu streifen \u2013", "tokens": ["Statt", "nur", "hier", "und", "dort", "mit", "lei\u00b7sem", "Fit\u00b7tig", "zu", "strei\u00b7fen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "KON", "ADV", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.8": {"text": "Ganz und voll einen Auserw\u00e4hlten", "tokens": ["Ganz", "und", "voll", "ei\u00b7nen", "Au\u00b7ser\u00b7w\u00e4hl\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KON", "ADJD", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Mit himmlischer Weihe,", "tokens": ["Mit", "himm\u00b7li\u00b7scher", "Wei\u00b7he", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.10": {"text": "Auf da\u00df dem deutschen Volk", "tokens": ["Auf", "da\u00df", "dem", "deut\u00b7schen", "Volk"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Auf's neue ein Dichter erstehe,", "tokens": ["Auf's", "neu\u00b7e", "ein", "Dich\u00b7ter", "er\u00b7ste\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.12": {"text": "Gro\u00df, edel und gewaltig wie Jene!?", "tokens": ["Gro\u00df", ",", "e\u00b7del", "und", "ge\u00b7wal\u00b7tig", "wie", "Je\u00b7ne", "!?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "KON", "ADJD", "KOKOM", "PDS", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Th\u00f6richte Frage,", "tokens": ["Th\u00f6\u00b7rich\u00b7te", "Fra\u00b7ge", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Th\u00f6richter Anruf!", "tokens": ["Th\u00f6\u00b7rich\u00b7ter", "An\u00b7ruf", "!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Versiegt l\u00e4ngst ist der castalische Quell,", "tokens": ["Ver\u00b7siegt", "l\u00e4ngst", "ist", "der", "cas\u00b7ta\u00b7li\u00b7sche", "Quell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Gelichtet die heilige Neunzahl \u2013", "tokens": ["Ge\u00b7lich\u00b7tet", "die", "hei\u00b7li\u00b7ge", "Neun\u00b7zahl", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "ART", "ADJA", "NN", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Und auf st\u00e4ubendem Bretterboden nur,", "tokens": ["Und", "auf", "st\u00e4u\u00b7ben\u00b7dem", "Bret\u00b7ter\u00b7bo\u00b7den", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "ADV", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "In grellem Lichtreflex", "tokens": ["In", "grel\u00b7lem", "Lich\u00b7tre\u00b7flex"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Und mi\u00dfduftendem B\u00fchnenflitter,", "tokens": ["Und", "mi\u00df\u00b7duf\u00b7ten\u00b7dem", "B\u00fch\u00b7nen\u00b7flit\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Erscheinen sie noch, die einst den Olymp bev\u00f6lkert.", "tokens": ["Er\u00b7schei\u00b7nen", "sie", "noch", ",", "die", "einst", "den", "O\u00b7lymp", "be\u00b7v\u00f6l\u00b7kert", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "PRELS", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+--+--+", "measure": "iambic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Todt ist die Kunst!", "tokens": ["Todt", "ist", "die", "Kunst", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Todt \u2013 ob auch ein Heer von Dichtern", "tokens": ["Todt", "\u2013", "ob", "auch", "ein", "Heer", "von", "Dich\u00b7tern"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$(", "KOUS", "ADV", "ART", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Scandirende H\u00e4nde regt,", "tokens": ["Scan\u00b7di\u00b7ren\u00b7de", "H\u00e4n\u00b7de", "regt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ob unendlicher T\u00f6ne Schwall", "tokens": ["Ob", "un\u00b7end\u00b7li\u00b7cher", "T\u00f6\u00b7ne", "Schwall"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "Die Welt durchfluthet \u2013", "tokens": ["Die", "Welt", "durch\u00b7flut\u00b7het", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Und in Erz und Marmor", "tokens": ["Und", "in", "Erz", "und", "Mar\u00b7mor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "KON", "NN"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.7": {"text": "Und auf erstaunter Leinwand", "tokens": ["Und", "auf", "er\u00b7staun\u00b7ter", "Lein\u00b7wand"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Der C\u00e4sarenwahnsinn des Virtuosenthums", "tokens": ["Der", "C\u00e4\u00b7sa\u00b7ren\u00b7wahn\u00b7sinn", "des", "Vir\u00b7tu\u00b7o\u00b7sen\u00b7thums"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Seine Orgien feiert.", "tokens": ["Sei\u00b7ne", "Or\u00b7gi\u00b7en", "fei\u00b7ert", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.10": {"text": "Todt ist sie \u2013", "tokens": ["Todt", "ist", "sie", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.11": {"text": "Und hin und wieder nur,", "tokens": ["Und", "hin", "und", "wie\u00b7der", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "KON", "ADV", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Weit abseits vom Markt,", "tokens": ["Weit", "ab\u00b7seits", "vom", "Markt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "APPRART", "NN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.13": {"text": "Zucken, verendend,", "tokens": ["Zu\u00b7cken", ",", "ver\u00b7en\u00b7dend", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVPP", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.14": {"text": "Noch ihre letzten ", "tokens": ["Noch", "ih\u00b7re", "letz\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PPOSAT", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}}}}}