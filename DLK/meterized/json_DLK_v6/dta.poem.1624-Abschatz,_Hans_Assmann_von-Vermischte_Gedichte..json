{"dta.poem.1624": {"metadata": {"author": {"name": "Abschatz, Hans Assmann von", "birth": "N.A.", "death": "N.A."}, "title": "Vermischte  \n Gedichte.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1704", "urn": "urn:nbn:de:kobv:b4-200905199889", "language": ["de:0.99"], "booktitle": "Abschatz, Hans Assmann von: Poetische Ubersetzungen und Gedichte. Leipzig, 1704."}, "poem": {"stanza.1": {"line.1": {"text": "Das stoltze Rom ist hin/ der Tyber Pracht verflossen/", "tokens": ["Das", "stolt\u00b7ze", "Rom", "ist", "hin", "/", "der", "Ty\u00b7ber", "Pracht", "ver\u00b7flos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NE", "VAFIN", "ADV", "$(", "ART", "NN", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Quirinens Ruff ist todt/ der alle Welt erf\u00fcllt:", "tokens": ["Qui\u00b7ri\u00b7nens", "Ruff", "ist", "todt", "/", "der", "al\u00b7le", "Welt", "er\u00b7f\u00fcllt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "ADJD", "$(", "ART", "PIAT", "NN", "VVPP", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Was ewig wird genannt hat kurtze Zeit genossen", "tokens": ["Was", "e\u00b7wig", "wird", "ge\u00b7nannt", "hat", "kurt\u00b7ze", "Zeit", "ge\u00b7nos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADJD", "VAFIN", "VVPP", "VAFIN", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den angema\u00dften Ruhm/ und weist ein wahres Bild", "tokens": ["Den", "an\u00b7ge\u00b7ma\u00df\u00b7ten", "Ruhm", "/", "und", "weist", "ein", "wah\u00b7res", "Bild"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der schn\u00f6den Eitelkeit. Was Rom vorhin gewesen/", "tokens": ["Der", "schn\u00f6\u00b7den", "Ei\u00b7tel\u00b7keit", ".", "Was", "Rom", "vor\u00b7hin", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "PWS", "NE", "ADV", "VAPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ist nun desselben Grab/ ist Asche/ Schutt und Grau\u00df:", "tokens": ["Ist", "nun", "des\u00b7sel\u00b7ben", "Grab", "/", "ist", "A\u00b7sche", "/", "Schutt", "und", "Grau\u00df", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PDAT", "NN", "$(", "VAFIN", "NN", "$(", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was wir vom ", "tokens": ["Was", "wir", "vom"], "token_info": ["word", "word", "word"], "pos": ["PWS", "PPER", "APPRART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.8": {"text": "Sucht unser thr\u00e4nend Aug anizt vergebens aus:", "tokens": ["Sucht", "un\u00b7ser", "thr\u00e4\u00b7nend", "Aug", "a\u00b7nizt", "ver\u00b7ge\u00b7bens", "aus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJD", "NN", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die eingefallne Last mit Gra\u00df und Mo\u00df bedeckt/", "tokens": ["Die", "ein\u00b7ge\u00b7fall\u00b7ne", "Last", "mit", "Gra\u00df", "und", "Mo\u00df", "be\u00b7deckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "H\u00e4lt seine Leiche selbst f\u00fcr ihm und uns versteckt.", "tokens": ["H\u00e4lt", "sei\u00b7ne", "Lei\u00b7che", "selbst", "f\u00fcr", "ihm", "und", "uns", "ver\u00b7steckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "APPR", "PPER", "KON", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Jedoch was seh ich hier? ein neues Rom entstehen:", "tokens": ["Je\u00b7doch", "was", "seh", "ich", "hier", "?", "ein", "neu\u00b7es", "Rom", "ent\u00b7ste\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VVFIN", "PPER", "ADV", "$.", "ART", "ADJA", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Man f\u00fchret/ wie vorhin/ viel Schl\u00f6sser in die Lufft/", "tokens": ["Man", "f\u00fch\u00b7ret", "/", "wie", "vor\u00b7hin", "/", "viel", "Schl\u00f6s\u00b7ser", "in", "die", "Lufft", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$(", "KOKOM", "ADV", "$(", "PIAT", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Man lernt den Tyber-Strom in Marmol-Gr\u00e4ntzen gehen/", "tokens": ["Man", "lernt", "den", "Ty\u00b7ber\u00b7Strom", "in", "Mar\u00b7mol\u00b7Gr\u00e4nt\u00b7zen", "ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Jerneuert und best\u00e4rckt manch halb-begrabne Grufft/", "tokens": ["Jer\u00b7neu\u00b7ert", "und", "be\u00b7st\u00e4rckt", "manch", "halb\u00b7be\u00b7grab\u00b7ne", "Grufft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "VVFIN", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der Tempel Poliphem hat neuen Schmuck und Auge/", "tokens": ["Der", "Tem\u00b7pel", "Po\u00b7li\u00b7phem", "hat", "neu\u00b7en", "Schmuck", "und", "Au\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "ADJA", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Man baut die alten G\u00e4ng und L\u00e4uben wieder nach.", "tokens": ["Man", "baut", "die", "al\u00b7ten", "G\u00e4ng", "und", "L\u00e4u\u00b7ben", "wie\u00b7der", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "NN", "KON", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Welch angehobnes Werck ist/ das dem Nachfahr tauge?", "tokens": ["Welch", "an\u00b7ge\u00b7hob\u00b7nes", "Werck", "ist", "/", "das", "dem", "Nach\u00b7fahr", "tau\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "$(", "PDS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Man bessert/ bricht und baut/ damit man auch ein Fach", "tokens": ["Man", "bes\u00b7sert", "/", "bricht", "und", "baut", "/", "da\u00b7mit", "man", "auch", "ein", "Fach"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVPP", "$(", "VVFIN", "KON", "VVFIN", "$(", "KOUS", "PIS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "F\u00fcr Nahm und Wappen findt/ und geht die Welt nicht ein/", "tokens": ["F\u00fcr", "Nahm", "und", "Wap\u00b7pen", "findt", "/", "und", "geht", "die", "Welt", "nicht", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$(", "KON", "VVFIN", "ART", "NN", "PTKNEG", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "So wird das neue Rom ein ander Ph\u00f6nix seyn.", "tokens": ["So", "wird", "das", "neu\u00b7e", "Rom", "ein", "an\u00b7der", "Ph\u00f6\u00b7nix", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NE", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}