{"dta.poem.5506": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Vern\u00fcnftiger Gebrauch des Gegen-  \n w\u00e4rtigen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1736", "urn": "urn:nbn:de:kobv:b4-200905198582", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Geliebte Menschen, lernet, lernt,", "tokens": ["Ge\u00b7lieb\u00b7te", "Men\u00b7schen", ",", "ler\u00b7net", ",", "lernt", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "NN", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Gegenw\u00e4rtigen geniessen!", "tokens": ["Des", "Ge\u00b7gen\u00b7w\u00e4r\u00b7ti\u00b7gen", "ge\u00b7nies\u00b7sen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Weil alle Dinge von uns fliessen,", "tokens": ["Weil", "al\u00b7le", "Din\u00b7ge", "von", "uns", "flies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie sich ein Strom von uns entfernt.", "tokens": ["Wie", "sich", "ein", "Strom", "von", "uns", "ent\u00b7fernt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "APPR", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Durch Ueberlegen kann allein", "tokens": ["Durch", "Ue\u00b7ber\u00b7le\u00b7gen", "kann", "al\u00b7lein"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "VVINF", "VMFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von uns genossen und empfunden,", "tokens": ["Von", "uns", "ge\u00b7nos\u00b7sen", "und", "emp\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Gehemmt und angehalten seyn", "tokens": ["Ge\u00b7hemmt", "und", "an\u00b7ge\u00b7hal\u00b7ten", "seyn"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "KON", "VVPP", "VAINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der reg- und fl\u00fc\u00dfigen Secunden", "tokens": ["Der", "reg", "und", "fl\u00fc\u00b7\u00dfi\u00b7gen", "Se\u00b7cun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "TRUNC", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Entstehend\u2019 und vergehnde Schaar.", "tokens": ["Ent\u00b7ste\u00b7hend'", "und", "ver\u00b7gehn\u00b7de", "Schaar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Lebt achtzig, ja, lebt hundert Jahr,", "tokens": ["Lebt", "acht\u00b7zig", ",", "ja", ",", "lebt", "hun\u00b7dert", "Jahr", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "CARD", "$,", "PTKANT", "$,", "VVFIN", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Von Gl\u00fcck und Kranckheit ungekr\u00e4ncket,", "tokens": ["Von", "Gl\u00fcck", "und", "Kran\u00b7ck\u00b7heit", "un\u00b7ge\u00b7kr\u00e4n\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ADJD", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Ohn Elend, Kummer und Gefahr:", "tokens": ["Ohn", "E\u00b7lend", ",", "Kum\u00b7mer", "und", "Ge\u00b7fahr", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Sie sind verflossen und verschwunden,", "tokens": ["Sie", "sind", "ver\u00b7flos\u00b7sen", "und", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Als wie der Tag, der gestern war,", "tokens": ["Als", "wie", "der", "Tag", ",", "der", "ge\u00b7stern", "war", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "NN", "$,", "PRELS", "ADV", "VAFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.15": {"text": "Wo ihr nicht oft daran gedencket;", "tokens": ["Wo", "ihr", "nicht", "oft", "da\u00b7ran", "ge\u00b7den\u00b7cket", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PTKNEG", "ADV", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Das Leben ist wie ein Geschrey,", "tokens": ["Das", "Le\u00b7ben", "ist", "wie", "ein", "Ge\u00b7schrey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Denckt man nicht, da\u00df man lebt, vorbey.", "tokens": ["Denckt", "man", "nicht", ",", "da\u00df", "man", "lebt", ",", "vor\u00b7bey", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PIS", "PTKNEG", "$,", "KOUS", "PIS", "VVFIN", "$,", "PTKVZ", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}}, "stanza.2": {"line.1": {"text": "Wofern wir aber \u00fcberlegen", "tokens": ["Wo\u00b7fern", "wir", "a\u00b7ber", "\u00fc\u00b7berl\u00b7e\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und, was man guts besitzt, erwegen;", "tokens": ["Und", ",", "was", "man", "guts", "be\u00b7sitzt", ",", "er\u00b7we\u00b7gen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "PRELS", "PIS", "NN", "VVPP", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wird der Genu\u00df so vieler Sachen,", "tokens": ["Wird", "der", "Ge\u00b7nu\u00df", "so", "vie\u00b7ler", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die unser Sch\u00f6pfer uns beschehrt,", "tokens": ["Die", "un\u00b7ser", "Sch\u00f6p\u00b7fer", "uns", "be\u00b7schehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und deren wir so wenig wehrt,", "tokens": ["Und", "de\u00b7ren", "wir", "so", "we\u00b7nig", "wehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "PPER", "ADV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Uns froh, erkenntlich, danckbar machen.", "tokens": ["Uns", "froh", ",", "er\u00b7kennt\u00b7lich", ",", "dan\u00b7ck\u00b7bar", "ma\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJD", "$,", "ADJD", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Wir werden auch zugleich die Plagen,", "tokens": ["Wir", "wer\u00b7den", "auch", "zu\u00b7gleich", "die", "Pla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Womit uns mancher Fall beschwehrt,", "tokens": ["Wo\u00b7mit", "uns", "man\u00b7cher", "Fall", "be\u00b7schwehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Geschickter werden zu ertragen.", "tokens": ["Ge\u00b7schick\u00b7ter", "wer\u00b7den", "zu", "er\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAINF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Denn, wer beym Unfall in der Welt", "tokens": ["Denn", ",", "wer", "beym", "Un\u00b7fall", "in", "der", "Welt"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "PWS", "APPRART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Gute nicht dagegen h\u00e4lt,", "tokens": ["Das", "Gu\u00b7te", "nicht", "da\u00b7ge\u00b7gen", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das ihm der Sch\u00f6pfer g\u00f6nnt und schencket,", "tokens": ["Das", "ihm", "der", "Sch\u00f6p\u00b7fer", "g\u00f6nnt", "und", "schen\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dem wird auch eine kleine Pein", "tokens": ["Dem", "wird", "auch", "ei\u00b7ne", "klei\u00b7ne", "Pein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Schon gro\u00df und unertr\u00e4glich seyn.", "tokens": ["Schon", "gro\u00df", "und", "un\u00b7er\u00b7tr\u00e4g\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "So la\u00dft uns darauf Achtung geben", "tokens": ["So", "la\u00dft", "uns", "da\u00b7rauf", "Ach\u00b7tung", "ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "PPER", "PAV", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was Salomo so weislich lehrt:", "tokens": ["Was", "Sa\u00b7lo\u00b7mo", "so", "weis\u00b7lich", "lehrt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist blos das Theil, das uns beschehrt.", "tokens": ["Ist", "blos", "das", "Theil", ",", "das", "uns", "be\u00b7schehrt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Man setzt mit Recht noch dies daneben:", "tokens": ["Man", "setzt", "mit", "Recht", "noch", "dies", "da\u00b7ne\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "NN", "ADV", "PDS", "PAV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es wird dadurch auch GOtt geehrt;", "tokens": ["Es", "wird", "da\u00b7durch", "auch", "Gott", "ge\u00b7ehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "ADV", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Weil sein Gesch\u00f6pfe noch wohl wehrt,", "tokens": ["Weil", "sein", "Ge\u00b7sch\u00f6p\u00b7fe", "noch", "wohl", "wehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df wir uns, froh zu seyn, bestreben.", "tokens": ["Da\u00df", "wir", "uns", ",", "froh", "zu", "seyn", ",", "be\u00b7stre\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "$,", "ADJD", "PTKZU", "VAINF", "$,", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}