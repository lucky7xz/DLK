{"textgrid.poem.61600": {"metadata": {"author": {"name": "Geibel, Emanuel", "birth": "N.A.", "death": "N.A."}, "title": "Bothwell", "genre": "verse", "period": "N.A.", "pub_year": 1833, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie bebte K\u00f6nigin Marie,", "tokens": ["Wie", "beb\u00b7te", "K\u00f6\u00b7ni\u00b7gin", "Ma\u00b7rie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als durchs geheime Pf\u00f6rtlein spat", "tokens": ["Als", "durchs", "ge\u00b7hei\u00b7me", "Pf\u00f6rt\u00b7lein", "spat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPRART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit ungebognem Haupt und Knie", "tokens": ["Mit", "un\u00b7ge\u00b7bog\u00b7nem", "Haupt", "und", "Knie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In ihr Gemach Graf Bothwell trat!", "tokens": ["In", "ihr", "Ge\u00b7mach", "Graf", "Both\u00b7well", "trat", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NE", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ihr sch\u00f6n Gesicht ward leichenwei\u00df;", "tokens": ["Ihr", "sch\u00f6n", "Ge\u00b7sicht", "ward", "lei\u00b7chen\u00b7wei\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie zuckt' und sah ihn fragend an:", "tokens": ["Sie", "zuckt'", "und", "sah", "ihn", "fra\u00b7gend", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er wischte von der Stirn den Schwei\u00df", "tokens": ["Er", "wischte", "von", "der", "Stirn", "den", "Schwei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und sagte dumpf: \u00bbEs ist getan.", "tokens": ["Und", "sag\u00b7te", "dumpf", ":", "\u00bb", "Es", "ist", "ge\u00b7tan", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$.", "$(", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "\u00bbes ist getan, dein s\u00fc\u00dfer Mund", "tokens": ["\u00bb", "es", "ist", "ge\u00b7tan", ",", "dein", "s\u00fc\u00b7\u00dfer", "Mund"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PPER", "VAFIN", "VVPP", "$,", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War nicht f\u00fcr Buben solcher Art,", "tokens": ["War", "nicht", "f\u00fcr", "Bu\u00b7ben", "sol\u00b7cher", "Art", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "APPR", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Heut abend um die achte Stund'", "tokens": ["Heut", "a\u00b7bend", "um", "die", "ach\u00b7te", "Stund'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hielt Heinrich Darnley Himmelfahrt.\u00ab \u2013", "tokens": ["Hielt", "Hein\u00b7rich", "Darn\u00b7ley", "Him\u00b7mel\u00b7fahrt", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NE", "NE", "NE", "NN", "$.", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Sie schrie empor: \u00bbVerzeih' dir Gott!", "tokens": ["Sie", "schrie", "em\u00b7por", ":", "\u00bb", "Ver\u00b7zeih'", "dir", "Gott", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "$(", "VVIMP", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nimm all mein Gold, nimm hin und flieh!\u00ab", "tokens": ["Nimm", "all", "mein", "Gold", ",", "nimm", "hin", "und", "flieh", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "PIAT", "PPOSAT", "NN", "$,", "VVIMP", "PTKVZ", "KON", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da lacht' er laut in grimmem Spott:", "tokens": ["Da", "lacht'", "er", "laut", "in", "grim\u00b7mem", "Spott", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbwas soll mir Gold f\u00fcr Blut, Marie?", "tokens": ["\u00bb", "was", "soll", "mir", "Gold", "f\u00fcr", "Blut", ",", "Ma\u00b7rie", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PWS", "VMFIN", "PPER", "NN", "APPR", "NN", "$,", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "\u00bbich liebe dich, und wenn ich mich", "tokens": ["\u00bb", "ich", "lie\u00b7be", "dich", ",", "und", "wenn", "ich", "mich"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "PPER", "$,", "KON", "KOUS", "PPER", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der H\u00f6ll' ergab zu dieser Frist,", "tokens": ["Der", "H\u00f6ll'", "er\u00b7gab", "zu", "die\u00b7ser", "Frist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So war's um dich, allein um dich,", "tokens": ["So", "wa\u00b7r's", "um", "dich", ",", "al\u00b7lein", "um", "dich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PPER", "$,", "ADV", "APPR", "PPER", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Weil du der sch\u00f6nste Teufel bist.", "tokens": ["Weil", "du", "der", "sch\u00f6ns\u00b7te", "Teu\u00b7fel", "bist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "\u00bbdie Hand, die einen K\u00f6nig schlug,", "tokens": ["\u00bb", "die", "Hand", ",", "die", "ei\u00b7nen", "K\u00f6\u00b7nig", "schlug", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Greift auch nach einer K\u00f6nigin.\u00ab", "tokens": ["Greift", "auch", "nach", "ei\u00b7ner", "K\u00f6\u00b7ni\u00b7gin", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADV", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er rief's, und Graun in jedem Zug,", "tokens": ["Er", "rie\u00b7f's", ",", "und", "Graun", "in", "je\u00b7dem", "Zug", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Starr wie ein Wachsbild sank sie hin.", "tokens": ["Starr", "wie", "ein", "Wachs\u00b7bild", "sank", "sie", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Er hub sie auf; sie f\u00fchlt' es nicht,", "tokens": ["Er", "hub", "sie", "auf", ";", "sie", "f\u00fchlt'", "es", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$.", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df ihr ins Fleisch sein Stahlhemd schnitt;", "tokens": ["Da\u00df", "ihr", "ins", "Fleisch", "sein", "Stahl\u00b7hemd", "schnitt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr lockig Haupthaar wallte dicht", "tokens": ["Ihr", "lo\u00b7ckig", "Haupt\u00b7haar", "wall\u00b7te", "dicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADJD", "NN", "VVFIN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Um seine Schulter, wie er schritt.", "tokens": ["Um", "sei\u00b7ne", "Schul\u00b7ter", ",", "wie", "er", "schritt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Er stie\u00df den Ring an ihre Hand,", "tokens": ["Er", "stie\u00df", "den", "Ring", "an", "ih\u00b7re", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er schwang sie vor sich fest aufs Ro\u00df", "tokens": ["Er", "schwang", "sie", "vor", "sich", "fest", "aufs", "Ro\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PRF", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und jagt' ins wetterschw\u00fcle Land", "tokens": ["Und", "jagt'", "ins", "wet\u00b7ter\u00b7schw\u00fc\u00b7le", "Land"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hinaus mit ihr gen Dunbar-Schlo\u00df.", "tokens": ["Hin\u00b7aus", "mit", "ihr", "gen", "Dun\u00b7ba\u00b7rSchlo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Schwarz war die Nacht, als w\u00e4re rings", "tokens": ["Schwarz", "war", "die", "Nacht", ",", "als", "w\u00e4\u00b7re", "rings"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "VAFIN", "ART", "NN", "$,", "KOKOM", "VAFIN", "ADV"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erloschen jeder Stern des Heils;", "tokens": ["Er\u00b7lo\u00b7schen", "je\u00b7der", "Stern", "des", "Heils", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nur manchmal in den Wolken ging's", "tokens": ["Nur", "manch\u00b7mal", "in", "den", "Wol\u00b7ken", "ging's"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gleichwie das Blitzen eines Beils.", "tokens": ["Gleich\u00b7wie", "das", "Blit\u00b7zen", "ei\u00b7nes", "Beils", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}