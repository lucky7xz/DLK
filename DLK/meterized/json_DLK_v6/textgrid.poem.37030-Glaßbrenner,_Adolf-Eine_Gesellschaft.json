{"textgrid.poem.37030": {"metadata": {"author": {"name": "Gla\u00dfbrenner, Adolf", "birth": "N.A.", "death": "N.A."}, "title": "Eine Gesellschaft", "genre": "verse", "period": "N.A.", "pub_year": 1843, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbvier der Scudi mu\u00df ich zahlen,\u00ab sagte Gr\u00e4fin Lotte mir.", "tokens": ["\u00bb", "vier", "der", "Scu\u00b7di", "mu\u00df", "ich", "zah\u00b7len", ",", "\u00ab", "sag\u00b7te", "Gr\u00e4\u00b7fin", "Lot\u00b7te", "mir", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "CARD", "ART", "NE", "VMFIN", "PPER", "VVINF", "$,", "$(", "VVFIN", "NN", "NE", "PPER", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "\u00bbwas, vier Scudi?\u00ab", "tokens": ["\u00bb", "was", ",", "vier", "Scu\u00b7di", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "$,", "CARD", "NE", "$.", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "\u00bbf\u00fcr den Boten, f\u00fcr die kleine Karte hier!", "tokens": ["\u00bb", "f\u00fcr", "den", "Bo\u00b7ten", ",", "f\u00fcr", "die", "klei\u00b7ne", "Kar\u00b7te", "hier", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "NN", "$,", "APPR", "ART", "ADJA", "NN", "ADV", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Du bist zum Diner gebeten bei dem Lord Brummbrumm von B\u00e4r;", "tokens": ["Du", "bist", "zum", "Di\u00b7ner", "ge\u00b7be\u00b7ten", "bei", "dem", "Lord", "Brumm\u00b7brumm", "von", "B\u00e4r", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "VVPP", "APPR", "ART", "NN", "NE", "APPR", "NN", "$."], "meter": "-+-+--+-+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.5": {"text": "Daf\u00fcr giebt, so will's die Sitte, man dem Diener solch Douceur.\u00ab", "tokens": ["Da\u00b7f\u00fcr", "giebt", ",", "so", "will's", "die", "Sit\u00b7te", ",", "man", "dem", "Die\u00b7ner", "solch", "Dou\u00b7ce\u00b7ur", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VVFIN", "$,", "ADV", "VMFIN", "ART", "NN", "$,", "PIS", "ART", "NN", "PIAT", "NN", "$.", "$("], "meter": "--+-+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}}, "stanza.2": {"line.1": {"text": "\u00bbvier der Scudi, Gr\u00e4fin Lotte, das ist stark! Ich bin kein Filz,", "tokens": ["\u00bb", "vier", "der", "Scu\u00b7di", ",", "Gr\u00e4\u00b7fin", "Lot\u00b7te", ",", "das", "ist", "stark", "!", "Ich", "bin", "kein", "Filz", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "CARD", "ART", "NE", "$,", "NN", "NE", "$,", "PDS", "VAFIN", "ADJD", "$.", "PPER", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Doch f\u00fcr zween der Scudi speis' ich dr\u00fcben in dem", "tokens": ["Doch", "f\u00fcr", "zween", "der", "Scu\u00b7di", "speis'", "ich", "dr\u00fc\u00b7ben", "in", "dem"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "VVFIN", "ART", "NE", "VVFIN", "PPER", "ADV", "APPR", "ART"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "(solche geistvoll-nationale Namen f\u00fchren hies'gen Orts", "tokens": ["(", "sol\u00b7che", "geist\u00b7voll\u00b7na\u00b7ti\u00b7o\u00b7na\u00b7le", "Na\u00b7men", "f\u00fch\u00b7ren", "hies'\u00b7gen", "Orts"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PIAT", "ADJA", "NN", "VVINF", "VVFIN", "NN"], "meter": "+-+-+--+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.4": {"text": "Die Hotels!) ich sollte meinen, so vorz\u00fcglich wie bei Lords.\u00ab", "tokens": ["Die", "Ho\u00b7tels", "!", ")", "ich", "soll\u00b7te", "mei\u00b7nen", ",", "so", "vor\u00b7z\u00fcg\u00b7lich", "wie", "bei", "Lords", ".", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$.", "$(", "PPER", "VMFIN", "PPOSAT", "$,", "ADV", "ADJD", "KOKOM", "APPR", "NE", "$.", "$("], "meter": "-+--+-+-+-+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.3": {"line.1": {"text": "Lotte l\u00e4chelte. \u00bbNein, wahrlich\u00ab, rief sie, \u00bbnein, so ideal", "tokens": ["Lot\u00b7te", "l\u00e4\u00b7chel\u00b7te", ".", "\u00bb", "Nein", ",", "wahr\u00b7lich", "\u00ab", ",", "rief", "sie", ",", "\u00bb", "nein", ",", "so", "i\u00b7deal"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "punct", "word", "word"], "pos": ["NE", "VVFIN", "$.", "$(", "PTKANT", "$,", "ADV", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "PTKANT", "$,", "ADV", "ADJD"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.2": {"text": "Wie beim edlen Lord, dem Brummb\u00e4r, ist im Pilze nie das Mahl!", "tokens": ["Wie", "beim", "ed\u00b7len", "Lord", ",", "dem", "Brumm\u00b7b\u00e4r", ",", "ist", "im", "Pil\u00b7ze", "nie", "das", "Mahl", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "ADJA", "NN", "$,", "ART", "NN", "$,", "VAFIN", "APPRART", "NN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Auch ist's wohl nicht mehr als billig, da\u00df ein Lord f\u00fcr solch ein Fest", "tokens": ["Auch", "ist's", "wohl", "nicht", "mehr", "als", "bil\u00b7lig", ",", "da\u00df", "ein", "Lord", "f\u00fcr", "solch", "ein", "Fest"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "PTKNEG", "ADV", "KOKOM", "ADJD", "$,", "KOUS", "ART", "NN", "APPR", "PIAT", "ART", "NN"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Einen h\u00f6hern Preis sich zahlen als die Fremdenkneipe l\u00e4\u00dft.\u00ab", "tokens": ["Ei\u00b7nen", "h\u00f6\u00b7hern", "Preis", "sich", "zah\u00b7len", "als", "die", "Frem\u00b7den\u00b7knei\u00b7pe", "l\u00e4\u00dft", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "PRF", "VVINF", "KOKOM", "ART", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.4": {"line.1": {"text": "\u00bbaber\u00ab, fuhr sie fort, \u00bbich wei\u00df nicht, was Du jetzt schon ein Dich zw\u00e4ngst", "tokens": ["\u00bb", "a\u00b7ber", "\u00ab", ",", "fuhr", "sie", "fort", ",", "\u00bb", "ich", "wei\u00df", "nicht", ",", "was", "Du", "jetzt", "schon", "ein", "Dich", "zw\u00e4ngst"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "$(", "$,", "VVFIN", "PPER", "PTKVZ", "$,", "$(", "PPER", "VVFIN", "PTKNEG", "$,", "PWS", "PPER", "ADV", "ADV", "ART", "PPER", "VVFIN"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "In den wei\u00dfen Schwalbenschwanzrock?\u00ab \u00bbJetzt schon?\u00ab wiederholt' ich. \u00bbL\u00e4ngst", "tokens": ["In", "den", "wei\u00b7\u00dfen", "Schwal\u00b7ben\u00b7schwanz\u00b7rock", "?", "\u00ab", "\u00bb", "Jetzt", "schon", "?", "\u00ab", "wie\u00b7der\u00b7holt'", "ich", ".", "\u00bb", "L\u00e4ngst"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "$(", "$(", "ADV", "ADV", "$.", "$(", "VVFIN", "PPER", "$.", "$(", "NN"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Hat es Zw\u00f6lf vom Kerkerthurme hertrompetet, und hier diese", "tokens": ["Hat", "es", "Zw\u00f6lf", "vom", "Ker\u00b7ker\u00b7thur\u00b7me", "her\u00b7trom\u00b7pe\u00b7tet", ",", "und", "hier", "die\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPER", "CARD", "APPRART", "NN", "VVPP", "$,", "KON", "ADV", "PDAT"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Karte giebt die Ordre deutlich: Zum Diner, Eilf Uhr pr\u00e4cise.\u00ab", "tokens": ["Kar\u00b7te", "giebt", "die", "Ord\u00b7re", "deut\u00b7lich", ":", "Zum", "Di\u00b7ner", ",", "Eilf", "Uhr", "pr\u00e4\u00b7ci\u00b7se", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "ADJD", "$.", "APPRART", "NN", "$,", "FM.la", "FM.la", "FM.la", "$.", "$("], "meter": "+-+-+-+--+--+-+-", "measure": "trochaic.septa.relaxed"}}, "stanza.5": {"line.1": {"text": "\u00bbpfui, da\u00df man doch,\u00ab rief die Gr\u00e4fin, \u00bbDich erzog so ordin\u00e4r!", "tokens": ["\u00bb", "pfui", ",", "da\u00df", "man", "doch", ",", "\u00ab", "rief", "die", "Gr\u00e4\u00b7fin", ",", "\u00bb", "Dich", "er\u00b7zog", "so", "or\u00b7di\u00b7n\u00e4r", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "KOUS", "PIS", "ADV", "$,", "$(", "VVFIN", "ART", "NN", "$,", "$(", "PPER", "VVFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Kein Begriff von ", "tokens": ["Kein", "Be\u00b7griff", "von"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "APPR"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Wie im Gro\u00dfen m\u00fcssen alle Vornehm-Edlen auch im Kleinen", "tokens": ["Wie", "im", "Gro\u00b7\u00dfen", "m\u00fcs\u00b7sen", "al\u00b7le", "Vor\u00b7nehm\u00b7Ed\u00b7len", "auch", "im", "Klei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPRART", "NN", "VMFIN", "PIAT", "NN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Anders sprechen und auch immer anders schreiben als sie meinen.", "tokens": ["An\u00b7ders", "spre\u00b7chen", "und", "auch", "im\u00b7mer", "an\u00b7ders", "schrei\u00b7ben", "als", "sie", "mei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "KON", "ADV", "ADV", "ADV", "VVINF", "KOKOM", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.6": {"line.1": {"text": "Noch drei Stunden mu\u00dft Du warten! K\u00e4mst Du in's Palais vor Acht,", "tokens": ["Noch", "drei", "Stun\u00b7den", "mu\u00dft", "Du", "war\u00b7ten", "!", "K\u00e4mst", "Du", "in's", "Pa\u00b7lais", "vor", "Acht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "VMFIN", "PPER", "VVINF", "$.", "VVFIN", "PPER", "APPRART", "NN", "APPR", "CARD", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "W\u00fcrdest von den Domestiken, und mit Recht, Du ausgelacht.\u00ab", "tokens": ["W\u00fcr\u00b7dest", "von", "den", "Do\u00b7mes\u00b7ti\u00b7ken", ",", "und", "mit", "Recht", ",", "Du", "aus\u00b7ge\u00b7lacht", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "$,", "KON", "APPR", "NN", "$,", "PPER", "VVPP", "$.", "$("], "meter": "+-+--+--+-+-+-+", "measure": "trochaic.septa.relaxed"}}, "stanza.7": {"line.1": {"text": "\u00bbaber ich bin zum Diner doch ...\u00ab Ja, so schrieb man, zum Diner;", "tokens": ["\u00bb", "a\u00b7ber", "ich", "bin", "zum", "Di\u00b7ner", "doch", "...", "\u00ab", "Ja", ",", "so", "schrieb", "man", ",", "zum", "Di\u00b7ner", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "KON", "PPER", "VAFIN", "APPRART", "NN", "ADV", "$(", "$(", "PTKANT", "$,", "ADV", "VVFIN", "PIS", "$,", "APPRART", "NN", "$."], "meter": "+--+-+--+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Aber eben, weil man so schrieb, lud man ein Dich zum Souper.", "tokens": ["A\u00b7ber", "e\u00b7ben", ",", "weil", "man", "so", "schrieb", ",", "lud", "man", "ein", "Dich", "zum", "Sou\u00b7per", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PIS", "ADV", "VVFIN", "$,", "VVFIN", "PIS", "ART", "PPER", "APPRART", "NN", "$."], "meter": "+-+--+-+-+-+-+-", "measure": "trochaic.septa.relaxed"}}, "stanza.8": {"line.1": {"text": "Sagt man denn nicht \u00bbGuten Tag!\u00ab auch und w\u00fcnscht eine b\u00f6se Nacht?", "tokens": ["Sagt", "man", "denn", "nicht", "\u00bb", "Gu\u00b7ten", "Tag", "!", "\u00ab", "auch", "und", "w\u00fcnscht", "ei\u00b7ne", "b\u00f6\u00b7se", "Nacht", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "PTKNEG", "$(", "ADJA", "NN", "$.", "$(", "ADV", "KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "--+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Wird beim \u00bbProsit!\u00ab und \u00bbHelf Gott!\u00ab denn nicht das Gegentheil gedacht?", "tokens": ["Wird", "beim", "\u00bb", "Pro\u00b7sit", "!", "\u00ab", "und", "\u00bb", "Helf", "Gott", "!", "\u00ab", "denn", "nicht", "das", "Ge\u00b7gen\u00b7theil", "ge\u00b7dacht", "?"], "token_info": ["word", "word", "punct", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "$(", "NN", "$.", "$(", "KON", "$(", "NE", "NN", "$.", "$(", "ADV", "PTKNEG", "ART", "NN", "VVPP", "$."], "meter": "-+-+-++-+-+-+-+", "measure": "unknown.measure.octa.plus"}}, "stanza.9": {"line.1": {"text": "Schreibt man nicht \u00bbErgeb'ner Diener,\u00ab lieber Dich mit F\u00fc\u00dfen tretend?", "tokens": ["Schreibt", "man", "nicht", "\u00bb", "Er\u00b7ge\u00b7b'\u00b7ner", "Die\u00b7ner", ",", "\u00ab", "lie\u00b7ber", "Dich", "mit", "F\u00fc\u00b7\u00dfen", "tre\u00b7tend", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PTKNEG", "$(", "ADJA", "NN", "$,", "$(", "ADV", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "+--+-+-+-+-+-+-+-", "measure": "iambic.octa.plus.invert"}, "line.2": {"text": "Segnet man uns nicht die Mahlzeit, Obstruction f\u00fcr uns erbetend?", "tokens": ["Seg\u00b7net", "man", "uns", "nicht", "die", "Mahl\u00b7zeit", ",", "O\u00b7bstruc\u00b7ti\u00b7on", "f\u00fcr", "uns", "er\u00b7be\u00b7tend", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "PTKNEG", "ART", "NN", "$,", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.3": {"text": "Preist man nicht ein Werk und meint doch, da\u00df es werth nicht einen Dreier?", "tokens": ["Preist", "man", "nicht", "ein", "Werk", "und", "meint", "doch", ",", "da\u00df", "es", "werth", "nicht", "ei\u00b7nen", "Drei\u00b7er", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "PTKNEG", "ART", "NN", "KON", "VVFIN", "ADV", "$,", "KOUS", "PPER", "ADJD", "PTKNEG", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Freut man sich nicht, Dich zu sehen, denkend: hole Dich der Geier!?", "tokens": ["Freut", "man", "sich", "nicht", ",", "Dich", "zu", "se\u00b7hen", ",", "den\u00b7kend", ":", "ho\u00b7le", "Dich", "der", "Gei\u00b7er", "!?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PRF", "PTKNEG", "$,", "PPER", "PTKZU", "VVINF", "$,", "VVPP", "$.", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.5": {"text": "Ja, ich darf Dir's nicht verhehlen, da\u00df man, wo Du heute Gast,", "tokens": ["Ja", ",", "ich", "darf", "Dir's", "nicht", "ver\u00b7heh\u00b7len", ",", "da\u00df", "man", ",", "wo", "Du", "heu\u00b7te", "Gast", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VMFIN", "PIS", "PTKNEG", "VVINF", "$,", "KOUS", "PIS", "$,", "PWAV", "PPER", "ADV", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.6": {"text": "Deiner fremden Abkunft wegen, just Dich wie die S\u00fcnde ha\u00dft,", "tokens": ["Dei\u00b7ner", "frem\u00b7den", "Ab\u00b7kunft", "we\u00b7gen", ",", "just", "Dich", "wie", "die", "S\u00fcn\u00b7de", "ha\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "$,", "VVFIN", "PPER", "KOKOM", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.7": {"text": "Oder, besser: wie die ", "tokens": ["O\u00b7der", ",", "bes\u00b7ser", ":", "wie", "die"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["NE", "$,", "ADJD", "$.", "PWAV", "ART"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}}, "stanza.10": {"line.1": {"text": "\u00bbl\u00e4ngst schon,\u00ab wandte das Gespr\u00e4ch ich, \u00bbwollt' ich, Gr\u00e4fin, mich erdreisten", "tokens": ["\u00bb", "l\u00e4ngst", "schon", ",", "\u00ab", "wand\u00b7te", "das", "Ge\u00b7spr\u00e4ch", "ich", ",", "\u00bb", "wollt'", "ich", ",", "Gr\u00e4\u00b7fin", ",", "mich", "er\u00b7dreis\u00b7ten"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["$(", "ADV", "ADV", "$,", "$(", "VVFIN", "ART", "NN", "PPER", "$,", "$(", "VMFIN", "PPER", "$,", "NN", "$,", "PPER", "VVINF"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Mein Erstaunen auszudr\u00fccken, da\u00df, bei Allem, was Sie leisten", "tokens": ["Mein", "Er\u00b7stau\u00b7nen", "aus\u00b7zu\u00b7dr\u00fc\u00b7cken", ",", "da\u00df", ",", "bei", "Al\u00b7lem", ",", "was", "Sie", "leis\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVIZU", "$,", "KOUS", "$,", "APPR", "PIS", "$,", "PWS", "PPER", "VVFIN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "An Geburt, Geist, Sch\u00f6nheit, Bildung, Euer Hochhochhochgeboren", "tokens": ["An", "Ge\u00b7burt", ",", "Geist", ",", "Sch\u00f6n\u00b7heit", ",", "Bil\u00b7dung", ",", "Eu\u00b7er", "Hoch\u00b7hoch\u00b7hoch\u00b7ge\u00b7bo\u00b7ren"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Sich den niedern Stand als Jungfer oder Hausmamsell erkoren.\u00ab", "tokens": ["Sich", "den", "nie\u00b7dern", "Stand", "als", "Jung\u00b7fer", "o\u00b7der", "Haus\u00b7mam\u00b7sell", "er\u00b7ko\u00b7ren", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PRF", "ART", "ADJA", "NN", "KOUS", "NN", "KON", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.11": {"line.1": {"text": "Bitter lachend sprach die Gr\u00e4fin: \u00bbKann Ich das Gesetz umsto\u00dfen,", "tokens": ["Bit\u00b7ter", "la\u00b7chend", "sprach", "die", "Gr\u00e4\u00b7fin", ":", "\u00bb", "Kann", "Ich", "das", "Ge\u00b7setz", "um\u00b7sto\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "NN", "$.", "$(", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+---+-+-+-", "measure": "unknown.measure.septa"}, "line.2": {"text": "Das der Primogenitur, ach, lastend auf des Reiches Gro\u00dfen?", "tokens": ["Das", "der", "Pri\u00b7mo\u00b7ge\u00b7ni\u00b7tur", ",", "ach", ",", "las\u00b7tend", "auf", "des", "Rei\u00b7ches", "Gro\u00b7\u00dfen", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "$,", "ITJ", "$,", "ADJD", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Wie die erstgebor'nen S\u00f6hne Erben nur des ganzen Gutes,", "tokens": ["Wie", "die", "erst\u00b7ge\u00b7bor'\u00b7nen", "S\u00f6h\u00b7ne", "Er\u00b7ben", "nur", "des", "gan\u00b7zen", "Gu\u00b7tes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "NN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Sind die erstgebor'nen T\u00f6chter Kinder nur des vollen Blutes.", "tokens": ["Sind", "die", "erst\u00b7ge\u00b7bor'\u00b7nen", "T\u00f6ch\u00b7ter", "Kin\u00b7der", "nur", "des", "vol\u00b7len", "Blu\u00b7tes", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "NN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.12": {"line.1": {"text": "Sie nur d\u00fcrfen sich verm\u00e4hlen einem Ritter oder Lord;", "tokens": ["Sie", "nur", "d\u00fcr\u00b7fen", "sich", "ver\u00b7m\u00e4h\u00b7len", "ei\u00b7nem", "Rit\u00b7ter", "o\u00b7der", "Lord", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "PRF", "VVFIN", "ART", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Ohne Mittel, ohne Mitleid werden wir hinausgejagt,", "tokens": ["Oh\u00b7ne", "Mit\u00b7tel", ",", "oh\u00b7ne", "Mit\u00b7leid", "wer\u00b7den", "wir", "hin\u00b7aus\u00b7ge\u00b7jagt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "KOUI", "NN", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Um bei Plebs, beim niedern B\u00fcrger, zu verdingen uns als Magd!\u00ab", "tokens": ["Um", "bei", "Plebs", ",", "beim", "nie\u00b7dern", "B\u00fcr\u00b7ger", ",", "zu", "ver\u00b7din\u00b7gen", "uns", "als", "Magd", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUI", "APPR", "NE", "$,", "APPRART", "ADJA", "NN", "$,", "PTKZU", "VVINF", "PPER", "KOUS", "NN", "$.", "$("], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.13": {"line.1": {"text": "\u00bbaber warum wird\u00ab, so fragt' ich zornger\u00f6thet, \u00bbdenn von oben", "tokens": ["\u00bb", "a\u00b7ber", "wa\u00b7rum", "wird", "\u00ab", ",", "so", "fragt'", "ich", "zorn\u00b7ge\u00b7r\u00f6\u00b7thet", ",", "\u00bb", "denn", "von", "o\u00b7ben"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "KON", "PWAV", "VAFIN", "$(", "$,", "ADV", "VVFIN", "PPER", "VVFIN", "$,", "$(", "KON", "APPR", "ADV"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Dieser Tollheit nicht gesteuert, dies Gesetz nicht aufgehoben?\u00ab", "tokens": ["Die\u00b7ser", "Toll\u00b7heit", "nicht", "ge\u00b7steu\u00b7ert", ",", "dies", "Ge\u00b7setz", "nicht", "auf\u00b7ge\u00b7ho\u00b7ben", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDAT", "NN", "PTKNEG", "VVPP", "$,", "PDS", "NN", "PTKNEG", "VVPP", "$.", "$("], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Da ... ich wu\u00dfte nicht, was pl\u00f6tzlich sie so aus der Stimmung brachte:", "tokens": ["Da", "...", "ich", "wu\u00df\u00b7te", "nicht", ",", "was", "pl\u00f6tz\u00b7lich", "sie", "so", "aus", "der", "Stim\u00b7mung", "brach\u00b7te", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "PPER", "VVFIN", "PTKNEG", "$,", "PRELS", "ADJD", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Sah die Gr\u00e4fin mich erstaunt an, schnitt Gesichter und \u2013 und ", "tokens": ["Sah", "die", "Gr\u00e4\u00b7fin", "mich", "er\u00b7staunt", "an", ",", "schnitt", "Ge\u00b7sich\u00b7ter", "und", "\u2013", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "ART", "NN", "PPER", "ADJD", "PTKVZ", "$,", "VVFIN", "NN", "KON", "$(", "KON"], "meter": "+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}}, "stanza.14": {"line.1": {"text": "Lachte so charmant und herzlich, da\u00df ich, der mit Recht Ergrimmte,", "tokens": ["Lach\u00b7te", "so", "char\u00b7mant", "und", "herz\u00b7lich", ",", "da\u00df", "ich", ",", "der", "mit", "Recht", "Er\u00b7grimm\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "KON", "ADJD", "$,", "KOUS", "PPER", "$,", "PRELS", "APPR", "NN", "VVFIN", "$,"], "meter": "+--+--+-+-+-+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Ueber's Primogenitur-Recht, ", "tokens": ["Ue\u00b7ber's", "Pri\u00b7mo\u00b7ge\u00b7ni\u00b7tur\u00b7Recht", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.15": {"line.1": {"text": "Und wir lachten, scherzten, lachen, ", "tokens": ["Und", "wir", "lach\u00b7ten", ",", "scherz\u00b7ten", ",", "la\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "VVFIN", "$,", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Welches f\u00fcr moralisch-strenge M\u00e4nner, welche diesem Werke", "tokens": ["Wel\u00b7ches", "f\u00fcr", "mo\u00b7ra\u00b7lischstren\u00b7ge", "M\u00e4n\u00b7ner", ",", "wel\u00b7che", "die\u00b7sem", "Wer\u00b7ke"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "APPR", "ADJA", "NN", "$,", "PRELS", "PDAT", "NN"], "meter": "+--+-+-+-+-+-+-", "measure": "iambic.septa.invert"}, "line.3": {"text": "Ihren Beifall zollen m\u00f6chten, ich expre\u00df hierbei bemerke.", "tokens": ["Ih\u00b7ren", "Bei\u00b7fall", "zol\u00b7len", "m\u00f6ch\u00b7ten", ",", "ich", "ex\u00b7pre\u00df", "hier\u00b7bei", "be\u00b7mer\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "VMFIN", "$,", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+--+", "measure": "iambic.octa.plus.octa.plus.chol"}}, "stanza.16": {"line.1": {"text": "\u00bbwisse\u00ab, sagte Lotte endlich, ihres Dienstherrn Gunst abwehrend,", "tokens": ["\u00bb", "wis\u00b7se", "\u00ab", ",", "sag\u00b7te", "Lot\u00b7te", "end\u00b7lich", ",", "ih\u00b7res", "Dienst\u00b7herrn", "Gunst", "ab\u00b7weh\u00b7rend", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$(", "$,", "VVFIN", "NE", "ADV", "$,", "PPOSAT", "NN", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Und ihn \u00fcber ihr Gel\u00e4chter, das so pl\u00f6tzlich kam, belehrend:", "tokens": ["Und", "ihn", "\u00fc\u00b7ber", "ihr", "Ge\u00b7l\u00e4ch\u00b7ter", ",", "das", "so", "pl\u00f6tz\u00b7lich", "kam", ",", "be\u00b7leh\u00b7rend", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PPOSAT", "NN", "$,", "PRELS", "ADV", "ADJD", "VVFIN", "$,", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "\u00bbwisse, da\u00df auf diesem Sterne Jeder, der wie Du Warum? fr\u00e4gt,", "tokens": ["\u00bb", "wis\u00b7se", ",", "da\u00df", "auf", "die\u00b7sem", "Ster\u00b7ne", "Je\u00b7der", ",", "der", "wie", "Du", "Wa\u00b7rum", "?", "fr\u00e4gt", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "KOUS", "APPR", "PDAT", "NN", "PIS", "$,", "PRELS", "KOKOM", "PPER", "PWAV", "$.", "VVFIN", "$,"], "meter": "+-+-+-+-+--+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.4": {"text": "Uns zum Lachen reizt und immer, ohne Ausnahme sehr ", "tokens": ["Uns", "zum", "La\u00b7chen", "reizt", "und", "im\u00b7mer", ",", "oh\u00b7ne", "Aus\u00b7nah\u00b7me", "sehr"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "APPRART", "NN", "VVFIN", "KON", "ADV", "$,", "KOUI", "NN", "ADV"], "meter": "+-+-+-+-+--+-+", "measure": "trochaic.septa.relaxed"}}, "stanza.17": {"line.1": {"text": "Das, was ist, das ", "tokens": ["Das", ",", "was", "ist", ",", "das"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["PDS", "$,", "PWS", "VAFIN", "$,", "PRELS"], "meter": "-+--", "measure": "dactylic.init"}, "line.2": {"text": "Unvern\u00fcnftig, was gewesen aber und was sein wird k\u00fcnftig.\u00ab", "tokens": ["Un\u00b7ver\u00b7n\u00fcnf\u00b7tig", ",", "was", "ge\u00b7we\u00b7sen", "a\u00b7ber", "und", "was", "sein", "wird", "k\u00fcnf\u00b7tig", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "$,", "PRELS", "VAPP", "ADV", "KON", "PWS", "VAINF", "VAFIN", "ADJD", "$.", "$("], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.18": {"line.1": {"text": "Fast zwei Stunden lang lief diese tiefeste Philosophie", "tokens": ["Fast", "zwei", "Stun\u00b7den", "lang", "lief", "die\u00b7se", "tie\u00b7fes\u00b7te", "Phi\u00b7lo\u00b7so\u00b7phie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "CARD", "NN", "ADJD", "VVFIN", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+-+--+--+", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Meiner Gr\u00e4fin durch den Kopf mir, ehe ich begriffen sie.", "tokens": ["Mei\u00b7ner", "Gr\u00e4\u00b7fin", "durch", "den", "Kopf", "mir", ",", "e\u00b7he", "ich", "be\u00b7grif\u00b7fen", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "PPER", "$,", "KOUS", "PPER", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Doch, da\u00df ich f\u00fcr mich behalte, was mir so viel Zeit und Gr\u00fcbeln", "tokens": ["Doch", ",", "da\u00df", "ich", "f\u00fcr", "mich", "be\u00b7hal\u00b7te", ",", "was", "mir", "so", "viel", "Zeit", "und", "Gr\u00fc\u00b7beln"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "PPER", "APPR", "PPER", "VVFIN", "$,", "PWS", "PPER", "ADV", "PIAT", "NN", "KON", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Kostete, wird mir der Leser, wenn er billig, nicht ver\u00fcbeln.", "tokens": ["Kos\u00b7te\u00b7te", ",", "wird", "mir", "der", "Le\u00b7ser", ",", "wenn", "er", "bil\u00b7lig", ",", "nicht", "ver\u00b7\u00fc\u00b7beln", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "VAFIN", "PPER", "ART", "NN", "$,", "KOUS", "PPER", "ADJD", "$,", "PTKNEG", "VVINF", "$."], "meter": "+--+--+-+-+-+-+-", "measure": "dactylic.di.plus"}}, "stanza.19": {"line.1": {"text": "Die Toilette war beendet: wei\u00dfer Frack und wei\u00dfer Claque,", "tokens": ["Die", "To\u00b7i\u00b7let\u00b7te", "war", "be\u00b7en\u00b7det", ":", "wei\u00b7\u00dfer", "Frack", "und", "wei\u00b7\u00dfer", "Cla\u00b7que", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "ADJA", "NN", "KON", "ADJA", "NE", "$,"], "meter": "-+-+-+-+-+-+-+--+", "measure": "iambic.octa.plus.octa.plus.chol"}, "line.2": {"text": "Wei\u00dfe Schuh und schwarze W\u00e4sche, und, nach neuestem Geschmack,", "tokens": ["Wei\u00b7\u00dfe", "Schuh", "und", "schwar\u00b7ze", "W\u00e4\u00b7sche", ",", "und", ",", "nach", "neu\u00b7es\u00b7tem", "Ge\u00b7schmack", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJA", "NN", "$,", "KON", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Pantalons mit circa F\u00fcnfzig Gold-Quadraten, die als Rahmen", "tokens": ["Pan\u00b7ta\u00b7lons", "mit", "cir\u00b7ca", "F\u00fcnf\u00b7zig", "Gold\u00b7Qua\u00b7dra\u00b7ten", ",", "die", "als", "Rah\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "APPR", "NE", "CARD", "NN", "$,", "PRELS", "KOUS", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Farbiger Bildnisse dienten von Theater-Herrn und Damen.", "tokens": ["Far\u00b7bi\u00b7ger", "Bild\u00b7nis\u00b7se", "dien\u00b7ten", "von", "The\u00b7a\u00b7ter\u00b7Herrn", "und", "Da\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "+--+--+-+-+-+-+-", "measure": "dactylic.di.plus"}}, "stanza.20": {"line.1": {"text": "Kaum fiel's auf mir von dem Kutscher, dessen rosenrother Wagen", "tokens": ["Kaum", "fiel's", "auf", "mir", "von", "dem", "Kut\u00b7scher", ",", "des\u00b7sen", "ro\u00b7sen\u00b7ro\u00b7ther", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PPER", "APPR", "ART", "NN", "$,", "PRELAT", "ADJA", "NN"], "meter": "-+-+--+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Nunmehr rasch mich zur Gesellschaft des Lord Brummb\u00e4r sollte tragen,", "tokens": ["Nun\u00b7mehr", "rasch", "mich", "zur", "Ge\u00b7sell\u00b7schaft", "des", "Lord", "Brumm\u00b7b\u00e4r", "soll\u00b7te", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "APPRART", "NN", "ART", "NN", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+--+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Da\u00df er einen ", "tokens": ["Da\u00df", "er", "ei\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "ART"], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Da ich wu\u00dfte, da\u00df die Peitsche hier in Scepterehren stand.", "tokens": ["Da", "ich", "wu\u00df\u00b7te", ",", "da\u00df", "die", "Peit\u00b7sche", "hier", "in", "Scep\u00b7te\u00b7reh\u00b7ren", "stand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "KOUS", "ART", "NN", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.21": {"line.1": {"text": "Als sich, unter vielen andern, meine rosige Karosse", "tokens": ["Als", "sich", ",", "un\u00b7ter", "vie\u00b7len", "an\u00b7dern", ",", "mei\u00b7ne", "ro\u00b7si\u00b7ge", "Ka\u00b7ros\u00b7se"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PRF", "$,", "APPR", "PIAT", "ADJA", "$,", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "N\u00e4herte dem alt-verfall'nen also h\u00f6chst ehrw\u00fcrd'gen Schlosse,", "tokens": ["N\u00e4\u00b7her\u00b7te", "dem", "al\u00b7tver\u00b7fall'\u00b7nen", "al\u00b7so", "h\u00f6chst", "ehr\u00b7w\u00fcrd'\u00b7gen", "Schlos\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "H\u00f6rte ich von zween Lakaien staunend das Geschrei, das stete:", "tokens": ["H\u00f6r\u00b7te", "ich", "von", "zween", "La\u00b7kai\u00b7en", "stau\u00b7nend", "das", "Ge\u00b7schrei", ",", "das", "ste\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "VVFIN", "NN", "ADJD", "ART", "NN", "$,", "PDS", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "\u00bbheut ist hier bei unsrer Herrschaft eine ungeheure Fete!\u00ab", "tokens": ["\u00bb", "heut", "ist", "hier", "bei", "uns\u00b7rer", "Herr\u00b7schaft", "ei\u00b7ne", "un\u00b7ge\u00b7heu\u00b7re", "Fe\u00b7te", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VAFIN", "ADV", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.22": {"line.1": {"text": "Auf der Flur zun\u00e4chst der Treppe, war placirt, wenn auch von bester", "tokens": ["Auf", "der", "Flur", "zu\u00b7n\u00e4chst", "der", "Trep\u00b7pe", ",", "war", "pla\u00b7cirt", ",", "wenn", "auch", "von", "bes\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV", "ART", "NN", "$,", "VAFIN", "VVPP", "$,", "KOUS", "ADV", "APPR", "ADJA"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Qualit\u00e4t nicht just, ein gro\u00dfes Blech- und Streich- und Pauk-Orchester,", "tokens": ["Qua\u00b7li\u00b7t\u00e4t", "nicht", "just", ",", "ein", "gro\u00b7\u00dfes", "Blech", "und", "Streich", "und", "Pauk\u00b7Or\u00b7ches\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADV", "$,", "ART", "ADJA", "TRUNC", "KON", "TRUNC", "KON", "NN", "$,"], "meter": "+-+-+-+-+-+-+---", "measure": "unknown.measure.septa"}, "line.3": {"text": "Und das lie\u00df (mein Wort als Dichter, da\u00df ich ", "tokens": ["Und", "das", "lie\u00df", "(", "mein", "Wort", "als", "Dich\u00b7ter", ",", "da\u00df", "ich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PDS", "VVFIN", "$(", "PPOSAT", "NN", "KOUS", "NN", "$,", "KOUS", "PPER"], "meter": "+-+-+-+-++", "measure": "unknown.measure.hexa"}}, "stanza.23": {"line.1": {"text": "Ob nun diese Melodieen himmlisches Original,", "tokens": ["Ob", "nun", "die\u00b7se", "Me\u00b7lo\u00b7di\u00b7e\u00b7en", "himm\u00b7li\u00b7sches", "O\u00b7rig\u00b7i\u00b7nal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PDAT", "NN", "ADJA", "NN", "$,"], "meter": "-+---+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ob vom Himmel einst sie Mozart, ob sie Ihm der Himmel stahl", "tokens": ["Ob", "vom", "Him\u00b7mel", "einst", "sie", "Mo\u00b7zart", ",", "ob", "sie", "Ihm", "der", "Him\u00b7mel", "stahl"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPRART", "NN", "ADV", "PPER", "NE", "$,", "KOUS", "PPER", "PPER", "ART", "NN", "VVFIN"], "meter": "--+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und durch seine Sph\u00e4ren rauschen, in den Sternen lie\u00df verbreiten?", "tokens": ["Und", "durch", "sei\u00b7ne", "Sph\u00e4\u00b7ren", "rau\u00b7schen", ",", "in", "den", "Ster\u00b7nen", "lie\u00df", "ver\u00b7brei\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VVINF", "$,", "APPR", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Darum werde ich, der Sel'ge, mit Unsel'gen mich nicht streiten.", "tokens": ["Da\u00b7rum", "wer\u00b7de", "ich", ",", "der", "Sel'\u00b7ge", ",", "mit", "Un\u00b7sel'\u00b7gen", "mich", "nicht", "strei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "$,", "ART", "NN", "$,", "APPR", "NN", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.24": {"line.1": {"text": "Als ich in den gro\u00dfen Saal trat, fand ich alle G\u00e4ste stumm!", "tokens": ["Als", "ich", "in", "den", "gro\u00b7\u00dfen", "Saal", "trat", ",", "fand", "ich", "al\u00b7le", "G\u00e4s\u00b7te", "stumm", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "NN", "VVFIN", "$,", "VVFIN", "PPER", "PIAT", "NN", "ADJD", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Alle gingen gr\u00fc\u00dfend, knixend, um das Theeservice herum,", "tokens": ["Al\u00b7le", "gin\u00b7gen", "gr\u00fc\u00b7\u00dfend", ",", "kni\u00b7xend", ",", "um", "das", "Thee\u00b7ser\u00b7vi\u00b7ce", "he\u00b7rum", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADJD", "$,", "VVPP", "$,", "KOUI", "ART", "NN", "PTKVZ", "$,"], "meter": "--+-+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Das auf einem langen Tische gl\u00e4nzte und, ich sah es klar", "tokens": ["Das", "auf", "ei\u00b7nem", "lan\u00b7gen", "Ti\u00b7sche", "gl\u00e4nz\u00b7te", "und", ",", "ich", "sah", "es", "klar"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "APPR", "ART", "ADJA", "NN", "VVFIN", "KON", "$,", "PPER", "VVFIN", "PPER", "ADJD"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "An den zierlich kleinen L\u00f6ffeln, von massivem Silber war.", "tokens": ["An", "den", "zier\u00b7lich", "klei\u00b7nen", "L\u00f6f\u00b7feln", ",", "von", "mas\u00b7si\u00b7vem", "Sil\u00b7ber", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJD", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "VAFIN", "$."], "meter": "--+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.25": {"line.1": {"text": "Festen Schritts trat ich zur Lady, die sich tief vor mir verbeugte", "tokens": ["Fes\u00b7ten", "Schritts", "trat", "ich", "zur", "La\u00b7dy", ",", "die", "sich", "tief", "vor", "mir", "ver\u00b7beug\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "NE", "VVFIN", "PPER", "APPRART", "NN", "$,", "PRELS", "PRF", "ADJD", "APPR", "PPER", "VVFIN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Und durch einen Nasenst\u00fcber ihre Achtung mir bezeugte;", "tokens": ["Und", "durch", "ei\u00b7nen", "Na\u00b7sen\u00b7st\u00fc\u00b7ber", "ih\u00b7re", "Ach\u00b7tung", "mir", "be\u00b7zeug\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Darauf stellt' ich mich dem Lord vor, welcher dreimal vor mir knixte,", "tokens": ["Da\u00b7rauf", "stellt'", "ich", "mich", "dem", "Lord", "vor", ",", "wel\u00b7cher", "drei\u00b7mal", "vor", "mir", "knix\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "ART", "NN", "PTKVZ", "$,", "PRELS", "ADV", "APPR", "PPER", "VVFIN", "$,"], "meter": "--+-+-+-+-+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Dann jedoch, stumm ab sich wendend, wieder seinen Schnauzbart wichste.", "tokens": ["Dann", "je\u00b7doch", ",", "stumm", "ab", "sich", "wen\u00b7dend", ",", "wie\u00b7der", "sei\u00b7nen", "Schnauz\u00b7bart", "wichs\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "ADJD", "APPR", "PRF", "VVPP", "$,", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.26": {"line.1": {"text": "Nach Verlauf von zehn Minuten trat in's Zimmer ein Lakai,", "tokens": ["Nach", "Ver\u00b7lauf", "von", "zehn", "Mi\u00b7nu\u00b7ten", "trat", "in's", "Zim\u00b7mer", "ein", "La\u00b7kai", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "CARD", "NN", "VVFIN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-+++", "measure": "unknown.measure.octa.plus"}, "line.2": {"text": "Unterbrechend diese Stille durch nachfolgendes Geschrei:", "tokens": ["Un\u00b7ter\u00b7bre\u00b7chend", "die\u00b7se", "Stil\u00b7le", "durch", "nach\u00b7fol\u00b7gen\u00b7des", "Ge\u00b7schrei", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "\u00bbherrn und Damen, ich verk\u00fcnde: ", "tokens": ["\u00bb", "herrn", "und", "Da\u00b7men", ",", "ich", "ver\u00b7k\u00fcn\u00b7de", ":"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVINF", "KON", "NN", "$,", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Ich fand's roh, die Unterhaltung ihres Schmucks so zu entkleiden,", "tokens": ["Ich", "fan\u00b7d's", "roh", ",", "die", "Un\u00b7ter\u00b7hal\u00b7tung", "ih\u00b7res", "Schmucks", "so", "zu", "ent\u00b7klei\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,", "ART", "NN", "PPOSAT", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.2": {"text": "Ihr die beiden besten Stoffe so gewaltsam abzuschneiden!", "tokens": ["Ihr", "die", "bei\u00b7den", "bes\u00b7ten", "Stof\u00b7fe", "so", "ge\u00b7walt\u00b7sam", "ab\u00b7zu\u00b7schnei\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "PIAT", "ADJA", "NN", "ADV", "ADJD", "VVIZU", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Doch ich irrte mich, denn pl\u00f6tzlich brach in den Gesellschaftsketten", "tokens": ["Doch", "ich", "irr\u00b7te", "mich", ",", "denn", "pl\u00f6tz\u00b7lich", "brach", "in", "den", "Ge\u00b7sell\u00b7schafts\u00b7ket\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$,", "KON", "ADJD", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Ein Geschnatter los, so m\u00e4chtig, um ein Capitol zu retten.", "tokens": ["Ein", "Ge\u00b7schnat\u00b7ter", "los", ",", "so", "m\u00e4ch\u00b7tig", ",", "um", "ein", "Ca\u00b7pi\u00b7tol", "zu", "ret\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "ADV", "ADJD", "$,", "KOUI", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.28": {"line.1": {"text": "\u00bbaber\u00ab, fragte einen Gast ich, der an meiner Seite stand,", "tokens": ["\u00bb", "a\u00b7ber", "\u00ab", ",", "frag\u00b7te", "ei\u00b7nen", "Gast", "ich", ",", "der", "an", "mei\u00b7ner", "Sei\u00b7te", "stand", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$(", "$,", "VVFIN", "ART", "NN", "PPER", "$,", "PRELS", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Einen kleinen, netten Knaben, einen Gardelieutenant,", "tokens": ["Ei\u00b7nen", "klei\u00b7nen", ",", "net\u00b7ten", "Kna\u00b7ben", ",", "ei\u00b7nen", "Gar\u00b7de\u00b7li\u00b7eu\u00b7ten\u00b7ant", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+--+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.3": {"text": "\u00bbwas bedeutet das Gekicher, das ich h\u00f6re, und warum", "tokens": ["\u00bb", "was", "be\u00b7deu\u00b7tet", "das", "Ge\u00b7ki\u00b7cher", ",", "das", "ich", "h\u00f6\u00b7re", ",", "und", "wa\u00b7rum"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "PWS", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "KON", "PWAV"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Drehn beim Sprechen sich die Leute stets gesichterschneidend um?\u00ab", "tokens": ["Drehn", "beim", "Spre\u00b7chen", "sich", "die", "Leu\u00b7te", "stets", "ge\u00b7sich\u00b7ter\u00b7schnei\u00b7dend", "um", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["CARD", "APPRART", "NN", "PRF", "ART", "NN", "ADV", "VVPP", "PTKVZ", "$.", "$("], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.29": {"line.1": {"text": "\u00bbnun, man macht sich Complimente\u00ab, sprach er, \u00bbsagt sich Schmeichelein.", "tokens": ["\u00bb", "nun", ",", "man", "macht", "sich", "Com\u00b7pli\u00b7men\u00b7te", "\u00ab", ",", "sprach", "er", ",", "\u00bb", "sagt", "sich", "Schmei\u00b7che\u00b7lein", "."], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "PIS", "VVFIN", "PRF", "NN", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "VVFIN", "PRF", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Jeder aber wei\u00df: der Andre glaubt's nicht, und drum gilt's als fein,", "tokens": ["Je\u00b7der", "a\u00b7ber", "wei\u00df", ":", "der", "And\u00b7re", "glaubt's", "nicht", ",", "und", "drum", "gilt's", "als", "fein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "VVFIN", "$.", "ART", "PIS", "VVFIN", "PTKNEG", "$,", "KON", "PAV", "VVFIN", "KOKOM", "ADJD", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Da\u00df man stracks \u2013 nachdem man eben Einen, da\u00df er klug, versichert,", "tokens": ["Da\u00df", "man", "stracks", "\u2013", "nach\u00b7dem", "man", "e\u00b7ben", "Ei\u00b7nen", ",", "da\u00df", "er", "klug", ",", "ver\u00b7si\u00b7chert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "$(", "KOUS", "PIS", "ADV", "ART", "$,", "KOUS", "PPER", "ADJD", "$,", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+--+", "measure": "iambic.octa.plus.octa.plus.chol"}, "line.4": {"text": "Sch\u00f6n, gelehrt, fromm und so weiter \u2013 umdreht sich und h\u00f6hnisch kichert.\u00ab", "tokens": ["Sch\u00f6n", ",", "ge\u00b7lehrt", ",", "fromm", "und", "so", "wei\u00b7ter", "\u2013", "um\u00b7dreht", "sich", "und", "h\u00f6h\u00b7nisch", "ki\u00b7chert", ".", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "VVPP", "$,", "ADJD", "KON", "ADV", "ADV", "$(", "VVFIN", "PRF", "KON", "ADJD", "VVFIN", "$.", "$("], "meter": "+-+-+-+--+--+--+", "measure": "trochaic.septa.relaxed"}}, "stanza.30": {"line.1": {"text": "\u00bballerdings sehr eigenth\u00fcmlich, aber l\u00e4stig und beschwerlich\u00ab,", "tokens": ["\u00bb", "al\u00b7ler\u00b7dings", "sehr", "ei\u00b7gent\u00b7h\u00fcm\u00b7lich", ",", "a\u00b7ber", "l\u00e4s\u00b7tig", "und", "be\u00b7schwer\u00b7lich", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADV", "ADJD", "$,", "ADV", "ADJD", "KON", "ADJD", "$(", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Meint' ich, \u00bbk\u00fcrzer w\u00e4r's, man spr\u00e4che miteinander wahr und ehrlich!\u00ab", "tokens": ["Meint'", "ich", ",", "\u00bb", "k\u00fcr\u00b7zer", "w\u00e4r's", ",", "man", "spr\u00e4\u00b7che", "mi\u00b7tein\u00b7an\u00b7der", "wahr", "und", "ehr\u00b7lich", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$,", "$(", "ADJD", "VAFIN", "$,", "PIS", "VVFIN", "ADV", "ADJD", "KON", "ADJD", "$.", "$("], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Und es schmeichelte mir h\u00f6chlich, da\u00df der Gardelieutenant", "tokens": ["Und", "es", "schmei\u00b7chel\u00b7te", "mir", "h\u00f6ch\u00b7lich", ",", "da\u00df", "der", "Gar\u00b7de\u00b7li\u00b7eu\u00b7ten\u00b7ant"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADJD", "$,", "KOUS", "ART", "NN"], "meter": "--+-+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Diesen Ausspruch \u00bbkolossal gut!\u00ab und \u00bbauf Ehre, reizend!\u00ab fand.", "tokens": ["Die\u00b7sen", "Aus\u00b7spruch", "\u00bb", "ko\u00b7los\u00b7sal", "gut", "!", "\u00ab", "und", "\u00bb", "auf", "Eh\u00b7re", ",", "rei\u00b7zend", "!", "\u00ab", "fand", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "punct", "word", "punct"], "pos": ["PDAT", "NN", "$(", "ADJD", "ADJD", "$.", "$(", "KON", "$(", "APPR", "NN", "$,", "VVPP", "$.", "$(", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.31": {"line.1": {"text": "\u00bbja, 'sist wahr, was man behauptet\u00ab, rief er, \u00bbIhr seid ein Genie!\u00ab", "tokens": ["\u00bb", "ja", ",", "'sist", "wahr", ",", "was", "man", "be\u00b7haup\u00b7tet", "\u00ab", ",", "rief", "er", ",", "\u00bb", "Ihr", "seid", "ein", "Ge\u00b7nie", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKANT", "$,", "ADJD", "PTKVZ", "$,", "PRELS", "PIS", "VVFIN", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "PPER", "VAFIN", "ART", "NN", "$.", "$("], "meter": "+-+-+-+-+--+--+", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Drehte aber schnell den Kopf um, kicherte ein Hi, hi, hi!,", "tokens": ["Dreh\u00b7te", "a\u00b7ber", "schnell", "den", "Kopf", "um", ",", "ki\u00b7cher\u00b7te", "ein", "Hi", ",", "hi", ",", "hi", "!", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "ART", "NN", "PTKVZ", "$,", "VVFIN", "ART", "NN", "$,", "VVFIN", "$,", "ITJ", "$.", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Ging zu einem Thee-Lakain und \u2013 so ist's Ton hier \u2013 lie\u00df durch diesen", "tokens": ["Ging", "zu", "ei\u00b7nem", "Thee\u00b7La\u00b7kain", "und", "\u2013", "so", "ist's", "Ton", "hier", "\u2013", "lie\u00df", "durch", "die\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "KON", "$(", "ADV", "ADJA", "NN", "ADV", "$(", "VVFIN", "APPR", "PDAT"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Eine Schaale Thee sich langsam in die edle Kehle gie\u00dfen.", "tokens": ["Ei\u00b7ne", "Schaa\u00b7le", "Thee", "sich", "lang\u00b7sam", "in", "die", "ed\u00b7le", "Keh\u00b7le", "gie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PRF", "ADJD", "APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.32": {"line.1": {"text": "Doch die Leserinnen werden, wie ich merke, ungeduldig", "tokens": ["Doch", "die", "Le\u00b7se\u00b7rin\u00b7nen", "wer\u00b7den", ",", "wie", "ich", "mer\u00b7ke", ",", "un\u00b7ge\u00b7dul\u00b7dig"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KON", "ART", "NN", "VAINF", "$,", "PWAV", "PPER", "VVFIN", "$,", "ADJD"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Da\u00df das Wichtigste von Allem ich so lange ihnen schuldig:", "tokens": ["Da\u00df", "das", "Wich\u00b7tigs\u00b7te", "von", "Al\u00b7lem", "ich", "so", "lan\u00b7ge", "ih\u00b7nen", "schul\u00b7dig", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "PIS", "PPER", "ADV", "ADV", "PPER", "ADJD", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Die Beschreibung der ", "tokens": ["Die", "Be\u00b7schrei\u00b7bung", "der"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "ART"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Ganz gewi\u00df nicht so geschmackvoll wie die unsre!\u00ab \u2013 Hi, hi, hi!", "tokens": ["Ganz", "ge\u00b7wi\u00df", "nicht", "so", "ge\u00b7schmack\u00b7voll", "wie", "die", "uns\u00b7re", "!", "\u00ab", "\u2013", "Hi", ",", "hi", ",", "hi", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "ADV", "ADJD", "KOKOM", "ART", "NN", "$.", "$(", "$(", "NE", "$,", "VVFIN", "$,", "ITJ", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.33": {"line.1": {"text": "Meine Damen: hier die Weibchen, deren Wuchs so sch\u00f6n wie zart,", "tokens": ["Mei\u00b7ne", "Da\u00b7men", ":", "hier", "die", "Weib\u00b7chen", ",", "de\u00b7ren", "Wuchs", "so", "sch\u00f6n", "wie", "zart", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "ADV", "ART", "NN", "$,", "PRELAT", "NN", "ADV", "ADJD", "KOKOM", "ADJD", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Schlagen, sich zu Damen drechselnd, alle aus Natur und Art;", "tokens": ["Schla\u00b7gen", ",", "sich", "zu", "Da\u00b7men", "drech\u00b7selnd", ",", "al\u00b7le", "aus", "Na\u00b7tur", "und", "Art", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRF", "APPR", "NN", "VVPP", "$,", "PIS", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Plustern sich das Haar um's K\u00f6pfchen, als ob g\u00e4nzlich ohne Ohren,", "tokens": ["Plus\u00b7tern", "sich", "das", "Haar", "um's", "K\u00f6pf\u00b7chen", ",", "als", "ob", "g\u00e4nz\u00b7lich", "oh\u00b7ne", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ART", "NN", "ADJA", "NN", "$,", "KOKOM", "KOUS", "ADJD", "APPR", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Tragen's Kleid so lang als w\u00e4ren ohne F\u00fc\u00dfe sie geboren!", "tokens": ["Tra\u00b7gen's", "Kleid", "so", "lang", "als", "w\u00e4\u00b7ren", "oh\u00b7ne", "F\u00fc\u00b7\u00dfe", "sie", "ge\u00b7bo\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADV", "ADJD", "KOKOM", "VAFIN", "APPR", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.34": {"line.1": {"text": "Bilden aus den Marmor-Armen: Windbeutel und Schwimmeblasen!", "tokens": ["Bil\u00b7den", "aus", "den", "Mar\u00b7mor\u00b7Ar\u00b7men", ":", "Wind\u00b7beu\u00b7tel", "und", "Schwim\u00b7me\u00b7bla\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$.", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Pressen sich die Brust ein, schn\u00fcren sich so \u00fcber alle Maa\u00dfen,", "tokens": ["Pres\u00b7sen", "sich", "die", "Brust", "ein", ",", "schn\u00fc\u00b7ren", "sich", "so", "\u00fc\u00b7ber", "al\u00b7le", "Maa\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ART", "NN", "PTKVZ", "$,", "VVFIN", "PRF", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Da\u00df sich ihre Grazie wandelt in ein Schreckgespenst von Knochen;", "tokens": ["Da\u00df", "sich", "ih\u00b7re", "Gra\u00b7zie", "wan\u00b7delt", "in", "ein", "Schreck\u00b7ge\u00b7spenst", "von", "Kno\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Da\u00df bei starkem Winde drau\u00dfen viel schon mittendurch gebrochen!", "tokens": ["Da\u00df", "bei", "star\u00b7kem", "Win\u00b7de", "drau\u00b7\u00dfen", "viel", "schon", "mit\u00b7ten\u00b7durch", "ge\u00b7bro\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ADJA", "NN", "ADV", "ADV", "ADV", "APPR", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.35": {"line.1": {"text": "Doch dies ", "tokens": ["Doch", "dies"], "token_info": ["word", "word"], "pos": ["KON", "PDS"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Das ersetzen anderswo sie durch ein ungeheures ", "tokens": ["Das", "er\u00b7set\u00b7zen", "an\u00b7ders\u00b7wo", "sie", "durch", "ein", "un\u00b7ge\u00b7heu\u00b7res"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "PPER", "APPR", "ART", "ADJA"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.3": {"text": "Wo? das hab' ich nicht verrathen! Denn selbst ein Incognito,", "tokens": ["Wo", "?", "das", "hab'", "ich", "nicht", "ver\u00b7ra\u00b7then", "!", "Denn", "selbst", "ein", "In\u00b7co\u00b7gni\u00b7to", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "PDS", "VAFIN", "PPER", "PTKNEG", "VVPP", "$.", "KON", "ADV", "ART", "ADV", "$,"], "meter": "+-+-+-+--+--+-+", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "Das f\u00fcr ", "tokens": ["Das", "f\u00fcr"], "token_info": ["word", "word"], "pos": ["PDS", "APPR"], "meter": "-+", "measure": "iambic.single"}}, "stanza.36": {"line.1": {"text": "Ebenso will ich nicht z\u00e4hlen, durch wie viele Unterkleider", "tokens": ["E\u00b7ben\u00b7so", "will", "ich", "nicht", "z\u00e4h\u00b7len", ",", "durch", "wie", "vie\u00b7le", "Un\u00b7ter\u00b7klei\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,", "APPR", "KOKOM", "PIAT", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Von dem Weib die Dame trennt sich, und das Weib verunziert leider,", "tokens": ["Von", "dem", "Weib", "die", "Da\u00b7me", "trennt", "sich", ",", "und", "das", "Weib", "ver\u00b7un\u00b7ziert", "lei\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVFIN", "PRF", "$,", "KON", "ART", "NN", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Denn das k\u00f6nnte ", "tokens": ["Denn", "das", "k\u00f6nn\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["KON", "PDS", "VMFIN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Wenn auch nicht in \u00fcble Lage \u2013 doch in Mi\u00dfcredit mich bringen.", "tokens": ["Wenn", "auch", "nicht", "in", "\u00fcb\u00b7le", "La\u00b7ge", "\u2013", "doch", "in", "Mi\u00df\u00b7cre\u00b7dit", "mich", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PTKNEG", "APPR", "ADJA", "NN", "$(", "ADV", "APPR", "NN", "PRF", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.37": {"line.1": {"text": "Schm\u00e4h'n wir lieber etwas \u00fcber jene Damen da vom Hofe,", "tokens": ["Schm\u00e4h'n", "wir", "lie\u00b7ber", "et\u00b7was", "\u00fc\u00b7ber", "je\u00b7ne", "Da\u00b7men", "da", "vom", "Ho\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "APPR", "PDAT", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Eine Sultanin und deren erste Leib- und Ehren-Zofe,", "tokens": ["Ei\u00b7ne", "Sul\u00b7ta\u00b7nin", "und", "de\u00b7ren", "ers\u00b7te", "Leib", "und", "Eh\u00b7ren\u00b7Zo\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PRELAT", "ADJA", "TRUNC", "KON", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Die zwar auch mit ihren \u00e4chten, mit den feinern Reizen geizen,", "tokens": ["Die", "zwar", "auch", "mit", "ih\u00b7ren", "\u00e4ch\u00b7ten", ",", "mit", "den", "fei\u00b7nern", "Rei\u00b7zen", "gei\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "APPR", "PPOSAT", "ADJA", "$,", "APPR", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Daf\u00fcr aber sich mit plumpen, etwas feisten Reizen spreizen.", "tokens": ["Da\u00b7f\u00fcr", "a\u00b7ber", "sich", "mit", "plum\u00b7pen", ",", "et\u00b7was", "feis\u00b7ten", "Rei\u00b7zen", "sprei\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "PRF", "APPR", "VVINF", "$,", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.38": {"line.1": {"text": "Spreizen? Nein, das ist das rechte Wort noch nicht; denn da von ", "tokens": ["Sprei\u00b7zen", "?", "Nein", ",", "das", "ist", "das", "rech\u00b7te", "Wort", "noch", "nicht", ";", "denn", "da", "von"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "PTKANT", "$,", "PDS", "VAFIN", "ART", "ADJA", "NN", "ADV", "PTKNEG", "$.", "KON", "ADV", "APPR"], "meter": "+-+-+-+-+--+-+", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Weit'sten Sinnes hier die Rede, brauchen besser wir wohl: br\u00fcsten?", "tokens": ["Weit'\u00b7sten", "Sin\u00b7nes", "hier", "die", "Re\u00b7de", ",", "brau\u00b7chen", "bes\u00b7ser", "wir", "wohl", ":", "br\u00fcs\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "ART", "NN", "$,", "VVFIN", "ADJD", "PPER", "ADV", "$.", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "O, wo nehm' ich nur f\u00fcr ", "tokens": ["O", ",", "wo", "nehm'", "ich", "nur", "f\u00fcr"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "PWAV", "VVFIN", "PPER", "ADV", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.39": {"line.1": {"text": "Und wird selbst bei dieser Frage rosenroth bis unter's Kinn.", "tokens": ["Und", "wird", "selbst", "bei", "die\u00b7ser", "Fra\u00b7ge", "ro\u00b7sen\u00b7roth", "bis", "un\u00b7ter's", "Kinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "APPR", "PDAT", "NN", "ADJD", "APPR", "APPRART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Nein, das Sch\u00e4men ist hier Ton nicht. Erstens hat man's nicht vonn\u00f6then,", "tokens": ["Nein", ",", "das", "Sch\u00e4\u00b7men", "ist", "hier", "Ton", "nicht", ".", "Ers\u00b7tens", "hat", "man's", "nicht", "von\u00b7n\u00f6\u00b7then", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "NN", "VAFIN", "ADV", "NN", "PTKNEG", "$.", "NN", "VAFIN", "PIS", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Und zum Andern, weil die Wangen hier beim Sch\u00e4men nicht err\u00f6then.", "tokens": ["Und", "zum", "An\u00b7dern", ",", "weil", "die", "Wan\u00b7gen", "hier", "beim", "Sch\u00e4\u00b7men", "nicht", "er\u00b7r\u00f6\u00b7then", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "ADJA", "$,", "KOUS", "ART", "NN", "ADV", "APPRART", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.40": {"line.1": {"text": "Nicht err\u00f6then? Nein, die Schaam haucht hier im Reiche Jedermann", "tokens": ["Nicht", "er\u00b7r\u00f6\u00b7then", "?", "Nein", ",", "die", "Schaam", "haucht", "hier", "im", "Rei\u00b7che", "Je\u00b7der\u00b7mann"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "VVINF", "$.", "PTKANT", "$,", "ART", "NN", "VVFIN", "ADV", "APPRART", "NE", "NE"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Statt der lieblich rothen Farbe eine h\u00e4\u00dflich tr\u00fcbe an.", "tokens": ["Statt", "der", "lieb\u00b7lich", "ro\u00b7then", "Far\u00b7be", "ei\u00b7ne", "h\u00e4\u00df\u00b7lich", "tr\u00fc\u00b7be", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJD", "ADJA", "NN", "ART", "ADJD", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Hier wird \u2013 und das ist f\u00fcr Frauen doch gewi\u00df nicht einerlei! \u2013", "tokens": ["Hier", "wird", "\u2013", "und", "das", "ist", "f\u00fcr", "Frau\u00b7en", "doch", "ge\u00b7wi\u00df", "nicht", "ei\u00b7ner\u00b7lei", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "$(", "KON", "PDS", "VAFIN", "APPR", "NN", "ADV", "ADV", "PTKNEG", "ADV", "$.", "$("], "meter": "-+--+-+-+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Hier wird man nicht roth beim Sch\u00e4men, nein, hier wird man ", "tokens": ["Hier", "wird", "man", "nicht", "roth", "beim", "Sch\u00e4\u00b7men", ",", "nein", ",", "hier", "wird", "man"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIS", "PTKNEG", "ADJD", "APPRART", "NN", "$,", "PTKANT", "$,", "ADV", "VAFIN", "PIS"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.41": {"line.1": {"text": "Doch, ich mu\u00df jetzt Abschied (weh mir!) von der sch\u00f6nen Les'rin nehmen", "tokens": ["Doch", ",", "ich", "mu\u00df", "jetzt", "Ab\u00b7schied", "(", "weh", "mir", "!", ")", "von", "der", "sch\u00f6\u00b7nen", "Les'\u00b7rin", "neh\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "PPER", "VMFIN", "ADV", "NN", "$(", "VVIMP", "PPER", "$.", "$(", "APPR", "ART", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Und (noch weher mir!) zu einem Pf\u00e4nderspiele mich bequemen,", "tokens": ["Und", "(", "noch", "we\u00b7her", "mir", "!", ")", "zu", "ei\u00b7nem", "Pf\u00e4n\u00b7der\u00b7spie\u00b7le", "mich", "be\u00b7que\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "ADV", "ADJD", "PPER", "$.", "$(", "APPR", "ART", "NN", "PPER", "ADJA", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Das, ich merkt' es an der lauten, allgemeinen Stuhlrevolte", "tokens": ["Das", ",", "ich", "merkt'", "es", "an", "der", "lau\u00b7ten", ",", "all\u00b7ge\u00b7mei\u00b7nen", "Stuhl\u00b7re\u00b7vol\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "$,", "PPER", "VVFIN", "PPER", "APPR", "ART", "ADJA", "$,", "ADJA", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Und der jungen M\u00e4dchen Kichern, jetzt geleistet werden sollte.", "tokens": ["Und", "der", "jun\u00b7gen", "M\u00e4d\u00b7chen", "Ki\u00b7chern", ",", "jetzt", "ge\u00b7leis\u00b7tet", "wer\u00b7den", "soll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "NN", "$,", "ADV", "VVPP", "VAINF", "VMFIN", "$."], "meter": "--+-+-+-+-+-+-+-", "measure": "anapaest.init"}}, "stanza.42": {"line.1": {"text": "Etwas Trost fand meine Seele, opfermuthig, schmerzdurchschauert,", "tokens": ["Et\u00b7was", "Trost", "fand", "mei\u00b7ne", "See\u00b7le", ",", "op\u00b7fer\u00b7mut\u00b7hig", ",", "schmerz\u00b7durch\u00b7schau\u00b7ert", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "PPOSAT", "NN", "$,", "ADJD", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Im empirischen Bewu\u00dftsein, da\u00df solch' Spiel nie lange dauert;", "tokens": ["Im", "em\u00b7pi\u00b7ri\u00b7schen", "Be\u00b7wu\u00df\u00b7tsein", ",", "da\u00df", "solch'", "Spiel", "nie", "lan\u00b7ge", "dau\u00b7ert", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "KOUS", "PIAT", "NN", "ADV", "ADV", "VVFIN", "$."], "meter": "+--+---+-+-++-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Da\u00df, und wenn's auch immer wieder, wieder, immer wieder statthat,", "tokens": ["Da\u00df", ",", "und", "wenn's", "auch", "im\u00b7mer", "wie\u00b7der", ",", "wie\u00b7der", ",", "im\u00b7mer", "wie\u00b7der", "statt\u00b7hat", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KON", "PIS", "ADV", "ADV", "ADV", "$,", "ADV", "$,", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Weil's so schonend f\u00fcr den Geist ist, man's doch jedes Mal bald satt hat.", "tokens": ["Weil's", "so", "scho\u00b7nend", "f\u00fcr", "den", "Geist", "ist", ",", "man's", "doch", "je\u00b7des", "Mal", "bald", "satt", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADJD", "APPR", "ART", "NN", "VAFIN", "$,", "PIS", "ADV", "PIAT", "NN", "ADV", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+-+-+-+--+", "measure": "iambic.octa.plus.octa.plus.chol"}}, "stanza.43": {"line.1": {"text": "Und fast war ich ganz getr\u00f6stet, als ich sah, da\u00df man dies Spiel", "tokens": ["Und", "fast", "war", "ich", "ganz", "ge\u00b7tr\u00f6s\u00b7tet", ",", "als", "ich", "sah", ",", "da\u00df", "man", "dies", "Spiel"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$,", "KOUS", "PPER", "VVFIN", "$,", "KOUS", "PIS", "PDS", "NN"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Ohne Pf\u00e4nderaustausch spielte; gleich begann beim s\u00fc\u00dfen Ziel!", "tokens": ["Oh\u00b7ne", "Pf\u00e4n\u00b7de\u00b7raus\u00b7tausch", "spiel\u00b7te", ";", "gleich", "be\u00b7gann", "beim", "s\u00fc\u00b7\u00dfen", "Ziel", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$.", "ADV", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+--+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Allem Speck- und Schinkenschneiden und den geistigen Gen\u00fcssen", "tokens": ["Al\u00b7lem", "Speck", "und", "Schin\u00b7ken\u00b7schnei\u00b7den", "und", "den", "geis\u00b7ti\u00b7gen", "Ge\u00b7n\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "TRUNC", "KON", "NN", "KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Dieser Art dabei entsagte, und sich einzig hielt an's K\u00fcssen.", "tokens": ["Die\u00b7ser", "Art", "da\u00b7bei", "ent\u00b7sag\u00b7te", ",", "und", "sich", "ein\u00b7zig", "hielt", "an's", "K\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "PAV", "VVFIN", "$,", "KON", "PRF", "ADJD", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.44": {"line.1": {"text": "Alle Damen zogen n\u00e4mlich zum Beginn der Minnelust", "tokens": ["Al\u00b7le", "Da\u00b7men", "zo\u00b7gen", "n\u00e4m\u00b7lich", "zum", "Be\u00b7ginn", "der", "Min\u00b7ne\u00b7lust"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "ADV", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Blumen aus dem Blumenkorbe, den sie trugen vor der Brust,", "tokens": ["Blu\u00b7men", "aus", "dem", "Blu\u00b7men\u00b7kor\u00b7be", ",", "den", "sie", "tru\u00b7gen", "vor", "der", "Brust", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Sch\u00fcchtern sie den M\u00e4nnern reichend, die sich durften dann erlauben,", "tokens": ["Sch\u00fcch\u00b7tern", "sie", "den", "M\u00e4n\u00b7nern", "rei\u00b7chend", ",", "die", "sich", "durf\u00b7ten", "dann", "er\u00b7lau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "VVPP", "$,", "PRELS", "PRF", "VMFIN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "So viel Blumen als sie hatten, so viel K\u00fcsse sich zu rauben.", "tokens": ["So", "viel", "Blu\u00b7men", "als", "sie", "hat\u00b7ten", ",", "so", "viel", "K\u00fcs\u00b7se", "sich", "zu", "rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "KOUS", "PPER", "VAFIN", "$,", "ADV", "PIAT", "NN", "PRF", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.45": {"line.1": {"text": "Eine Dame, deren Tochter meine Mutter konnte sein,", "tokens": ["Ei\u00b7ne", "Da\u00b7me", ",", "de\u00b7ren", "Toch\u00b7ter", "mei\u00b7ne", "Mut\u00b7ter", "konn\u00b7te", "sein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELAT", "NN", "PPOSAT", "NN", "VMFIN", "VAINF", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "R\u00fcckte aus mich los und bot mir huldvoll Sieben Bl\u00fcmelein!", "tokens": ["R\u00fcck\u00b7te", "aus", "mich", "los", "und", "bot", "mir", "huld\u00b7voll", "Sie\u00b7ben", "Bl\u00fc\u00b7me\u00b7lein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "PTKVZ", "KON", "VVFIN", "PPER", "ADJD", "CARD", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Sieben! Das war unversch\u00e4mt doch! Dankend dr\u00fcckt' ich ihr die H\u00e4nde,", "tokens": ["Sie\u00b7ben", "!", "Das", "war", "un\u00b7ver\u00b7sch\u00e4mt", "doch", "!", "Dan\u00b7kend", "dr\u00fcckt'", "ich", "ihr", "die", "H\u00e4n\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "$.", "PDS", "VAFIN", "ADJD", "ADV", "$.", "ADJD", "VVFIN", "PPER", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Mich entschuld'gend, da\u00df ich fremd sei und das Spiel noch nicht verst\u00e4nde.", "tokens": ["Mich", "ent\u00b7schuld'\u00b7gend", ",", "da\u00df", "ich", "fremd", "sei", "und", "das", "Spiel", "noch", "nicht", "ver\u00b7st\u00e4n\u00b7de", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "KON", "ART", "NN", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.46": {"line.1": {"text": "Und dann schob den Gardelieutenant ich als Opfer ihr an's Herz,", "tokens": ["Und", "dann", "schob", "den", "Gar\u00b7de\u00b7li\u00b7eu\u00b7ten\u00b7ant", "ich", "als", "Op\u00b7fer", "ihr", "an's", "Herz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "PPER", "KOUS", "NN", "PPER", "APPRART", "NN", "$,"], "meter": "-+--+--+-+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Und entsagte gerne diesem zu loyalen Minnescherz;", "tokens": ["Und", "ent\u00b7sag\u00b7te", "ger\u00b7ne", "die\u00b7sem", "zu", "lo\u00b7ya\u00b7len", "Min\u00b7ne\u00b7scherz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PDAT", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Ging zum Theetisch in der Hoffnung, da\u00df des Festes Unterhaltung", "tokens": ["Ging", "zum", "Thee\u00b7tisch", "in", "der", "Hoff\u00b7nung", ",", "da\u00df", "des", "Fes\u00b7tes", "Un\u00b7ter\u00b7hal\u00b7tung"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "APPRART", "NN", "APPR", "ART", "NN", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Bald gewinnen w\u00fcrde eine ... unterhaltende Gestaltung.", "tokens": ["Bald", "ge\u00b7win\u00b7nen", "w\u00fcr\u00b7de", "ei\u00b7ne", "...", "un\u00b7ter\u00b7hal\u00b7ten\u00b7de", "Ge\u00b7stal\u00b7tung", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VAFIN", "ART", "$(", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.47": {"line.1": {"text": "Aber, ach, statt dessen tauchte, und mit eitlem Ungest\u00fcm,", "tokens": ["A\u00b7ber", ",", "ach", ",", "statt", "des\u00b7sen", "tauch\u00b7te", ",", "und", "mit", "eit\u00b7lem", "Un\u00b7ge\u00b7st\u00fcm", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ITJ", "$,", "KOUI", "PDS", "VVFIN", "$,", "KON", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Auf ein frech-geschmackanspeiend-nervenmarternd Ungeth\u00fcm,", "tokens": ["Auf", "ein", "frech\u00b7ge\u00b7schmackan\u00b7spei\u00b7en\u00b7dner\u00b7ven\u00b7mar\u00b7ternd", "Un\u00b7ge\u00b7th\u00fcm", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+-+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Das sich durch Miauung \u00e4u\u00dfert, Klapprung, Kratz-, Quiek-, Kreisch- und Grunzung,", "tokens": ["Das", "sich", "durch", "Mi\u00b7au\u00b7ung", "\u00e4u\u00b7\u00dfert", ",", "Klapp\u00b7rung", ",", "Kratz", ",", "Quiek", ",", "Kreisch", "und", "Grun\u00b7zung", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "APPR", "NN", "VVFIN", "$,", "NN", "$,", "TRUNC", "$,", "TRUNC", "$,", "TRUNC", "KON", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Und Dilettantismus hei\u00dfet oder besser: Kunstverhunzung.", "tokens": ["Und", "Di\u00b7let\u00b7tan\u00b7tis\u00b7mus", "hei\u00b7\u00dfet", "o\u00b7der", "bes\u00b7ser", ":", "Kunst\u00b7ver\u00b7hun\u00b7zung", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "KON", "ADJD", "$.", "NN", "$."], "meter": "-+-+--+-+-+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.48": {"line.1": {"text": "Auf der Erde kann von diesem gr\u00e4ulichen socialen Drachen,", "tokens": ["Auf", "der", "Er\u00b7de", "kann", "von", "die\u00b7sem", "gr\u00e4u\u00b7li\u00b7chen", "so\u00b7ci\u00b7a\u00b7len", "Dra\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "APPR", "PDAT", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+---+--+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Kunst- Molch und \u00e4sthet'schen Lindwurm, schwerlich man ein Bild sich machen!", "tokens": ["Kunst", "Molch", "und", "\u00e4s\u00b7thet'\u00b7schen", "Lind\u00b7wurm", ",", "schwer\u00b7lich", "man", "ein", "Bild", "sich", "ma\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["TRUNC", "NN", "KON", "ADJA", "NN", "$,", "ADJD", "PIS", "ART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+--+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Nein, die klugen Leser werden, wenn ich schild're, wie er ras't,", "tokens": ["Nein", ",", "die", "klu\u00b7gen", "Le\u00b7ser", "wer\u00b7den", ",", "wenn", "ich", "schild'\u00b7re", ",", "wie", "er", "ras't", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "ADJA", "NN", "VAINF", "$,", "KOUS", "PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "L\u00e4chelnd und die K\u00f6pfe sch\u00fcttelnd meinen: unser Autor spa\u00dft!", "tokens": ["L\u00e4\u00b7chelnd", "und", "die", "K\u00f6p\u00b7fe", "sch\u00fct\u00b7telnd", "mei\u00b7nen", ":", "un\u00b7ser", "Au\u00b7tor", "spa\u00dft", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ART", "NN", "ADJD", "VVFIN", "$.", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.49": {"line.1": {"text": "Und doch ist es reine Wahrheit, wenn ich sage: jene Frau,", "tokens": ["Und", "doch", "ist", "es", "rei\u00b7ne", "Wahr\u00b7heit", ",", "wenn", "ich", "sa\u00b7ge", ":", "je\u00b7ne", "Frau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADJA", "NN", "$,", "KOUS", "PPER", "VVFIN", "$.", "PDAT", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Noch vor Kurzem geistvoll-lieblich, l\u00e4\u00dft er kreischen wie 'nen Pfau!", "tokens": ["Noch", "vor", "Kur\u00b7zem", "geist\u00b7voll\u00b7lieb\u00b7lich", ",", "l\u00e4\u00dft", "er", "krei\u00b7schen", "wie", "'nen", "Pfau", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "ADJD", "$,", "VVFIN", "PPER", "VVINF", "KOKOM", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "L\u00e4\u00dft er sich den Mund aussp\u00fclen mit Rouladen, und owaihn,", "tokens": ["L\u00e4\u00dft", "er", "sich", "den", "Mund", "aus\u00b7sp\u00fc\u00b7len", "mit", "Rou\u00b7la\u00b7den", ",", "und", "o\u00b7waihn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ART", "NN", "VVFIN", "APPR", "NN", "$,", "KON", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Jammern, st\u00f6hnen und sich qu\u00e4len bis Mitleid'ge Bravo schrein.", "tokens": ["Jam\u00b7mern", ",", "st\u00f6h\u00b7nen", "und", "sich", "qu\u00e4\u00b7len", "bis", "Mit\u00b7lei\u00b7d'\u00b7ge", "Bra\u00b7vo", "schrein", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "KON", "PRF", "VVINF", "KON", "NN", "NE", "PTKVZ", "$."], "meter": "+-+-+-+-+-+--+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.50": {"line.1": {"text": "Jene Eltern l\u00e4\u00dft er wandeln ihr liebreizend Kind zum Affen,", "tokens": ["Je\u00b7ne", "El\u00b7tern", "l\u00e4\u00dft", "er", "wan\u00b7deln", "ihr", "lieb\u00b7rei\u00b7zend", "Kind", "zum", "Af\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "PPER", "VVFIN", "PPER", "ADJD", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Und dort den Familienvater selber wandeln sich zum Laffen!", "tokens": ["Und", "dort", "den", "Fa\u00b7mi\u00b7li\u00b7en\u00b7va\u00b7ter", "sel\u00b7ber", "wan\u00b7deln", "sich", "zum", "Laf\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "ADV", "VVFIN", "PRF", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.3": {"text": "Jener holden Jungfrau wickelt aus der Kehle er ein Kn\u00e4ul", "tokens": ["Je\u00b7ner", "hol\u00b7den", "Jung\u00b7frau", "wi\u00b7ckelt", "aus", "der", "Keh\u00b7le", "er", "ein", "Kn\u00e4ul"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDAT", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "PPER", "ART", "NN"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Falscher T\u00f6ne ab und Schn\u00f6rkeln, bis sie Allen wird ein Gr\u00e4ul!", "tokens": ["Fal\u00b7scher", "T\u00f6\u00b7ne", "ab", "und", "Schn\u00f6r\u00b7keln", ",", "bis", "sie", "Al\u00b7len", "wird", "ein", "Gr\u00e4ul", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKVZ", "KON", "NN", "$,", "KOUS", "PPER", "NE", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.51": {"line.1": {"text": "Diesen braven J\u00fcngling zwingt er eine Geige abzukratzen,", "tokens": ["Die\u00b7sen", "bra\u00b7ven", "J\u00fcng\u00b7ling", "zwingt", "er", "ei\u00b7ne", "Gei\u00b7ge", "ab\u00b7zu\u00b7krat\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "VVFIN", "PPER", "ART", "NN", "VVIZU", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Da\u00df selbst von den nahen D\u00e4chern h\u00fclfeschreiend fliehn die Katzen;", "tokens": ["Da\u00df", "selbst", "von", "den", "na\u00b7hen", "D\u00e4\u00b7chern", "h\u00fcl\u00b7fe\u00b7schrei\u00b7end", "fliehn", "die", "Kat\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "ART", "ADJA", "NN", "ADJD", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Einen Andern l\u00e4\u00dft er klimpern, da\u00df man diesem Drahtarbeiter", "tokens": ["Ei\u00b7nen", "An\u00b7dern", "l\u00e4\u00dft", "er", "klim\u00b7pern", ",", "da\u00df", "man", "die\u00b7sem", "Draht\u00b7ar\u00b7bei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "VVINF", "$,", "KOUS", "PIS", "PDAT", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Gern 'nen Groschen schenkte, bittend: Bester, ein paar H\u00e4user weiter!", "tokens": ["Gern", "'nen", "Gro\u00b7schen", "schenk\u00b7te", ",", "bit\u00b7tend", ":", "Bes\u00b7ter", ",", "ein", "paar", "H\u00e4u\u00b7ser", "wei\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "$,", "VVPP", "$.", "NN", "$,", "ART", "PIAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.52": {"line.1": {"text": "Einen dritten braven J\u00fcngling l\u00e4\u00dft er, ohne zu err\u00f6then,", "tokens": ["Ei\u00b7nen", "drit\u00b7ten", "bra\u00b7ven", "J\u00fcng\u00b7ling", "l\u00e4\u00dft", "er", ",", "oh\u00b7ne", "zu", "er\u00b7r\u00f6\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "VVFIN", "PPER", "$,", "KOUI", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Einen Mozart oder Weber langsam mit der Fl\u00f6te t\u00f6dten!", "tokens": ["Ei\u00b7nen", "Mo\u00b7zart", "o\u00b7der", "We\u00b7ber", "lang\u00b7sam", "mit", "der", "Fl\u00f6\u00b7te", "t\u00f6d\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NE", "ADJD", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+--+--+-+-+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Einen Greis ein Lied abknarren von verliebten Turteltauben,", "tokens": ["Ei\u00b7nen", "Greis", "ein", "Lied", "ab\u00b7knar\u00b7ren", "von", "ver\u00b7lieb\u00b7ten", "Tur\u00b7tel\u00b7tau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Und zwei M\u00e4dchen ohne Stimme Wuthhusten und Racheschnauben!", "tokens": ["Und", "zwei", "M\u00e4d\u00b7chen", "oh\u00b7ne", "Stim\u00b7me", "Wuth\u00b7hus\u00b7ten", "und", "Ra\u00b7ch\u00b7e\u00b7schnau\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "APPR", "NN", "NN", "KON", "NN", "$."], "meter": "--+-+-+--+--+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.53": {"line.1": {"text": "Selbst die Mutter nicht, die Hausfrau, schont dies schn\u00f6de Ungeheuer!", "tokens": ["Selbst", "die", "Mut\u00b7ter", "nicht", ",", "die", "Haus\u00b7frau", ",", "schont", "dies", "schn\u00f6\u00b7de", "Un\u00b7ge\u00b7heu\u00b7er", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PTKNEG", "$,", "ART", "NN", "$,", "VVFIN", "PDS", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Eine dicke F\u00fcnfzigj\u00e4hr'ge schmort in hei\u00dfem Liebesfeuer,", "tokens": ["Ei\u00b7ne", "di\u00b7cke", "F\u00fcnf\u00b7zig\u00b7j\u00e4hr'\u00b7ge", "schmort", "in", "hei\u00b7\u00dfem", "Lie\u00b7bes\u00b7feu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Aechzt Gef\u00fchl heraus, keucht Wehmuth, schwitzt sich Triller ab und girrt", "tokens": ["A\u00b7echzt", "Ge\u00b7f\u00fchl", "he\u00b7raus", ",", "keucht", "Weh\u00b7muth", ",", "schwitzt", "sich", "Tril\u00b7ler", "ab", "und", "girrt"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "PTKVZ", "$,", "VVFIN", "NN", "$,", "VVFIN", "PRF", "NN", "PTKVZ", "KON", "VVFIN"], "meter": "+--+-+-+-+-+-+-+", "measure": "iambic.octa.plus.invert"}, "line.4": {"text": "Zehn Mal den gerechten Zweifel: ob der Liebste kommen wird?", "tokens": ["Zehn", "Mal", "den", "ge\u00b7rech\u00b7ten", "Zwei\u00b7fel", ":", "ob", "der", "Liebs\u00b7te", "kom\u00b7men", "wird", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ART", "ADJA", "NN", "$.", "KOUS", "ART", "NN", "VVINF", "VAFIN", "$."], "meter": "-+--+-+-+-+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.54": {"line.1": {"text": "Und sonst w\u00fcrd'ge Frau'n und M\u00e4nner, die, zu zeigen, wie sie leiden,", "tokens": ["Und", "sonst", "w\u00fcrd'\u00b7ge", "Frau'n", "und", "M\u00e4n\u00b7ner", ",", "die", ",", "zu", "zei\u00b7gen", ",", "wie", "sie", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "KON", "NN", "$,", "PRELS", "$,", "PTKZU", "VVINF", "$,", "PWAV", "PPER", "VVINF", "$,"], "meter": "-+--+-+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Bei dem Treiben dieses Drachens, heimlich sich Gesichter schneiden,", "tokens": ["Bei", "dem", "Trei\u00b7ben", "die\u00b7ses", "Dra\u00b7chens", ",", "heim\u00b7lich", "sich", "Ge\u00b7sich\u00b7ter", "schnei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PDAT", "NN", "$,", "ADJD", "PRF", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Rufen: \u00bbBravo! Ganz vortrefflich!\u00ab wenn ein Leidensact zu Ende,", "tokens": ["Ru\u00b7fen", ":", "\u00bb", "Bra\u00b7vo", "!", "Ganz", "vor\u00b7treff\u00b7lich", "!", "\u00ab", "wenn", "ein", "Lei\u00b7den\u00b7sact", "zu", "En\u00b7de", ","], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "ITJ", "$.", "ADV", "ADJD", "$.", "$(", "KOUS", "ART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Hauend, And're hauen m\u00f6gend, sich in ihre eig'nen H\u00e4nde!", "tokens": ["Hau\u00b7end", ",", "An\u00b7d'\u00b7re", "hau\u00b7en", "m\u00f6\u00b7gend", ",", "sich", "in", "ih\u00b7re", "eig'\u00b7nen", "H\u00e4n\u00b7de", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "VVPP", "$,", "PRF", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}}, "stanza.55": {"line.1": {"text": "Und Personen, deren Bildung zweifellos wie ihr Geschmack,", "tokens": ["Und", "Per\u00b7so\u00b7nen", ",", "de\u00b7ren", "Bil\u00b7dung", "zwei\u00b7fel\u00b7los", "wie", "ihr", "Ge\u00b7schmack", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELAT", "NN", "ADJD", "KOKOM", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Macht, tritt Einer von den Ihren auf mit seinem Dudelsack,", "tokens": ["Macht", ",", "tritt", "Ei\u00b7ner", "von", "den", "Ih\u00b7ren", "auf", "mit", "sei\u00b7nem", "Du\u00b7del\u00b7sack", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PIS", "APPR", "ART", "NN", "APPR", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Augenblicks der Lindwurm d\u00e4misch, so vernagelt, so verr\u00fcckt,", "tokens": ["Au\u00b7gen\u00b7blicks", "der", "Lind\u00b7wurm", "d\u00e4\u00b7misch", ",", "so", "ver\u00b7na\u00b7gelt", ",", "so", "ver\u00b7r\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ADJD", "$,", "ADV", "VVPP", "$,", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Da\u00df das Plumpste sie bezaubert und das Schrecklichste entz\u00fcckt!", "tokens": ["Da\u00df", "das", "Plumps\u00b7te", "sie", "be\u00b7zau\u00b7bert", "und", "das", "Schreck\u00b7lichs\u00b7te", "ent\u00b7z\u00fcckt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "VVPP", "KON", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.56": {"line.1": {"text": "Mehr noch d\u00fcrften meine Leser staunen, wenn ich ihnen sage,", "tokens": ["Mehr", "noch", "d\u00fcrf\u00b7ten", "mei\u00b7ne", "Le\u00b7ser", "stau\u00b7nen", ",", "wenn", "ich", "ih\u00b7nen", "sa\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPOSAT", "NN", "VVFIN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Da\u00df dies Monstrum, dies sociale, rasend, w\u00fcthend alle Tage,", "tokens": ["Da\u00df", "dies", "Monst\u00b7rum", ",", "dies", "so\u00b7ci\u00b7a\u00b7le", ",", "ra\u00b7send", ",", "w\u00fct\u00b7hend", "al\u00b7le", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "NN", "$,", "PDS", "ADV", "$,", "VVPP", "$,", "ADJD", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.3": {"text": "Von Gewaltigen geh\u00e4tschelt und gepflegt wird. Und warum?", "tokens": ["Von", "Ge\u00b7wal\u00b7ti\u00b7gen", "ge\u00b7h\u00e4t\u00b7schelt", "und", "ge\u00b7pflegt", "wird", ".", "Und", "wa\u00b7rum", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "KON", "VVPP", "VAFIN", "$.", "KON", "PWAV", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Weil es ", "tokens": ["Weil", "es"], "token_info": ["word", "word"], "pos": ["KOUS", "PPER"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.57": {"line.1": {"text": "Weil er kitzelt statt zu spornen, und verbuhlt der Jugend Kraft;", "tokens": ["Weil", "er", "kit\u00b7zelt", "statt", "zu", "spor\u00b7nen", ",", "und", "ver\u00b7buhlt", "der", "Ju\u00b7gend", "Kraft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "ADJD", "PTKZU", "VVINF", "$,", "KON", "VVFIN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Weil, was Feuer, Drang und Muth ist, unter ihm erstickt, erschlafft;", "tokens": ["Weil", ",", "was", "Feu\u00b7er", ",", "Drang", "und", "Muth", "ist", ",", "un\u00b7ter", "ihm", "er\u00b7stickt", ",", "er\u00b7schlafft", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "$,", "PWS", "NN", "$,", "NN", "KON", "NN", "VAFIN", "$,", "APPR", "PPER", "VVPP", "$,", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Weil den Geist er nur auf kleine, eitle Eitelkeiten lenkt,", "tokens": ["Weil", "den", "Geist", "er", "nur", "auf", "klei\u00b7ne", ",", "eit\u00b7le", "Ei\u00b7tel\u00b7kei\u00b7ten", "lenkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "ADV", "APPR", "ADJA", "$,", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Und ihn einwiegt und ihn einlullt, da\u00df er ja nicht forscht und denkt.", "tokens": ["Und", "ihn", "ein\u00b7wiegt", "und", "ihn", "ein\u00b7lullt", ",", "da\u00df", "er", "ja", "nicht", "forscht", "und", "denkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVPP", "KON", "PPER", "VVPP", "$,", "KOUS", "PPER", "ADV", "PTKNEG", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.58": {"line.1": {"text": "Da\u00df der Mensch nicht aus der Traumwelt in die Welt des Lebens schweift!", "tokens": ["Da\u00df", "der", "Mensch", "nicht", "aus", "der", "Traum\u00b7welt", "in", "die", "Welt", "des", "Le\u00b7bens", "schweift", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PTKNEG", "APPR", "ART", "NN", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Da\u00df er ja nicht nach den Werken seiner edlen Dichter greift!", "tokens": ["Da\u00df", "er", "ja", "nicht", "nach", "den", "Wer\u00b7ken", "sei\u00b7ner", "ed\u00b7len", "Dich\u00b7ter", "greift", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "APPR", "ART", "NN", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Ja nicht in gesell'gem Kreise diesen und sich selbst erhebt,", "tokens": ["Ja", "nicht", "in", "ge\u00b7sell'\u00b7gem", "Krei\u00b7se", "die\u00b7sen", "und", "sich", "selbst", "er\u00b7hebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PTKNEG", "APPR", "ADJA", "NN", "PDAT", "KON", "PRF", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Ja nicht nach erhab'nen Zielen, so die Denker preisen, strebt!", "tokens": ["Ja", "nicht", "nach", "er\u00b7hab'\u00b7nen", "Zie\u00b7len", ",", "so", "die", "Den\u00b7ker", "prei\u00b7sen", ",", "strebt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKANT", "PTKNEG", "APPR", "ADJA", "NN", "$,", "ADV", "ART", "NN", "VVFIN", "$,", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.59": {"line.1": {"text": "Darum kennt man von den Dichtern hier kaum mehr als ihren Ruhm;", "tokens": ["Da\u00b7rum", "kennt", "man", "von", "den", "Dich\u00b7tern", "hier", "kaum", "mehr", "als", "ih\u00b7ren", "Ruhm", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIS", "APPR", "ART", "NN", "ADV", "ADV", "PIAT", "KOKOM", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Darum sind sie nur der Schr\u00e4nke nicht des Volkes Eigenthum!", "tokens": ["Da\u00b7rum", "sind", "sie", "nur", "der", "Schr\u00e4n\u00b7ke", "nicht", "des", "Vol\u00b7kes", "Ei\u00b7gen\u00b7thum", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "ART", "NN", "PTKNEG", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Darum, weil dies Volk sie adlen, spornen, kr\u00e4ft'gen w\u00fcrden, darum", "tokens": ["Da\u00b7rum", ",", "weil", "dies", "Volk", "sie", "ad\u00b7len", ",", "spor\u00b7nen", ",", "kr\u00e4ft'\u00b7gen", "w\u00fcr\u00b7den", ",", "da\u00b7rum"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word"], "pos": ["PAV", "$,", "KOUS", "PDS", "NN", "PPER", "VVINF", "$,", "VVFIN", "$,", "VVINF", "VAFIN", "$,", "PAV"], "meter": "----+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.4": {"text": "Scheucht man fort sie durch Gedudel, durch ein ew'ges Lirumlarum!", "tokens": ["Scheucht", "man", "fort", "sie", "durch", "Ge\u00b7du\u00b7del", ",", "durch", "ein", "ew'\u00b7ges", "Li\u00b7rum\u00b7la\u00b7rum", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PTKVZ", "PPER", "APPR", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+---+--+-+", "measure": "trochaic.septa.relaxed"}}, "stanza.60": {"line.1": {"text": "Darum .... doch der Geist allein nicht, auch der K\u00f6rper fordert Nahrung,", "tokens": ["Da\u00b7rum", "....", "doch", "der", "Geist", "al\u00b7lein", "nicht", ",", "auch", "der", "K\u00f6r\u00b7per", "for\u00b7dert", "Nah\u00b7rung", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$.", "ADV", "ART", "NN", "ADV", "PTKNEG", "$,", "ADV", "ART", "NN", "VVFIN", "NN", "$,"], "meter": "--+-+-+-+-+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Wie dem Volke der Instinkt lehrt und Gelehrten die Erfahrung!", "tokens": ["Wie", "dem", "Vol\u00b7ke", "der", "Ins\u00b7tinkt", "lehrt", "und", "Ge\u00b7lehr\u00b7ten", "die", "Er\u00b7fah\u00b7rung", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "VVFIN", "KON", "NN", "ART", "NN", "$."], "meter": "--+--+-+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und so ward denn das Gedudel, wurden denn die Singeschnurren", "tokens": ["Und", "so", "ward", "denn", "das", "Ge\u00b7du\u00b7del", ",", "wur\u00b7den", "denn", "die", "Sin\u00b7ge\u00b7schnur\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "ADV", "ART", "NN", "$,", "VAFIN", "ADV", "ART", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Endlich, endlich \u00fcbert\u00f6nt durch obligates Magenknurren.", "tokens": ["End\u00b7lich", ",", "end\u00b7lich", "\u00fc\u00b7ber\u00b7t\u00f6nt", "durch", "ob\u00b7li\u00b7ga\u00b7tes", "Ma\u00b7gen\u00b7knur\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.61": {"line.1": {"text": "Doch so weit das Auge schweifte rings durch alle die Salons:", "tokens": ["Doch", "so", "weit", "das", "Au\u00b7ge", "schweif\u00b7te", "rings", "durch", "al\u00b7le", "die", "Sa\u00b7lons", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "ART", "NN", "VVFIN", "ADV", "APPR", "PIS", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Keine Spur von einem Seefisch, von Ragout mit Champignons!", "tokens": ["Kei\u00b7ne", "Spur", "von", "ei\u00b7nem", "See\u00b7fisch", ",", "von", "Ra\u00b7gout", "mit", "Cham\u00b7pig\u00b7nons", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ART", "NN", "$,", "APPR", "NN", "APPR", "NE", "$."], "meter": "+-+-+-+--+--+-+", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Gar Nichts von gef\u00fcllter Lammsbrust, Fricassee's und Fricardellen,", "tokens": ["Gar", "Nichts", "von", "ge\u00b7f\u00fcll\u00b7ter", "Lamms\u00b7brust", ",", "Fri\u00b7cas\u00b7see's", "und", "Fri\u00b7car\u00b7del\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "APPR", "ADJA", "NN", "$,", "NE", "KON", "NN", "$,"], "meter": "--+-+-+-+-+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Von Filets mit Tr\u00fcffeln, Hasen, Tauben oder Lachsforellen!", "tokens": ["Von", "Fi\u00b7lets", "mit", "Tr\u00fcf\u00b7feln", ",", "Ha\u00b7sen", ",", "Tau\u00b7ben", "o\u00b7der", "Lachs\u00b7fo\u00b7rel\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+--+-+-+-+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.62": {"line.1": {"text": "Kein Gedanke hier von Austern! Keine Schnepfen, keine K\u00fccken!", "tokens": ["Kein", "Ge\u00b7dan\u00b7ke", "hier", "von", "Aus\u00b7tern", "!", "Kei\u00b7ne", "Schnep\u00b7fen", ",", "kei\u00b7ne", "K\u00fc\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "APPR", "NN", "$.", "PIAT", "NN", "$,", "PIAT", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Kein Atom von einem Rumsteak oder eines Rehes R\u00fccken!", "tokens": ["Kein", "A\u00b7tom", "von", "ei\u00b7nem", "Rums\u00b7teak", "o\u00b7der", "ei\u00b7nes", "Re\u00b7hes", "R\u00fc\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ART", "NN", "KON", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Keine Ahnung von 'nem Kalbskopf, noch von irgend einem Braten,", "tokens": ["Kei\u00b7ne", "Ah\u00b7nung", "von", "'nem", "Kalbs\u00b7kopf", ",", "noch", "von", "ir\u00b7gend", "ei\u00b7nem", "Bra\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ART", "NN", "$,", "ADV", "APPR", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Von Pasteten oder andern gastronomisch-edlen Thaten!", "tokens": ["Von", "Pas\u00b7te\u00b7ten", "o\u00b7der", "an\u00b7dern", "ga\u00b7stro\u00b7no\u00b7misched\u00b7len", "Tha\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ADJA", "ADJA", "NN", "$."], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.63": {"line.1": {"text": "Und so weit das Auge schweifte: keine einz'ge Flasche Sekt!", "tokens": ["Und", "so", "weit", "das", "Au\u00b7ge", "schweif\u00b7te", ":", "kei\u00b7ne", "einz'\u00b7ge", "Fla\u00b7sche", "Sekt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "ART", "NN", "VVFIN", "$.", "PIAT", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Der uns so poetisch fr\u00f6hlicht, und der au\u00dferdem auch", "tokens": ["Der", "uns", "so", "po\u00b7e\u00b7tisch", "fr\u00f6h\u00b7licht", ",", "und", "der", "au\u00b7\u00dfer\u00b7dem", "auch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVFIN", "$,", "KON", "ART", "PAV", "ADV"], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Nichts von ", "tokens": ["Nichts", "von"], "token_info": ["word", "word"], "pos": ["PIS", "APPR"], "meter": "++", "measure": "spondeus"}, "line.4": {"text": "Von der gern ich einen Korb mir ... auch wohl zweie geben lie\u00df!", "tokens": ["Von", "der", "gern", "ich", "ei\u00b7nen", "Korb", "mir", "...", "auch", "wohl", "zwei\u00b7e", "ge\u00b7ben", "lie\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "PPER", "ART", "NN", "PPER", "$(", "ADV", "ADV", "ADV", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.64": {"line.1": {"text": "Keine ", "tokens": ["Kei\u00b7ne"], "token_info": ["word"], "pos": ["PIAT"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "(g\u00e4b' es selbst so hohe Geister in den Sph\u00e4ren Dummdummdumms)!", "tokens": ["(", "g\u00e4b'", "es", "selbst", "so", "ho\u00b7he", "Geis\u00b7ter", "in", "den", "Sph\u00e4\u00b7ren", "Dumm\u00b7dumm\u00b7dumms", ")", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PPER", "ADV", "ADV", "ADJA", "NN", "APPR", "ART", "NN", "NE", "$(", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Keine ", "tokens": ["Kei\u00b7ne"], "token_info": ["word"], "pos": ["PIAT"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Nichts von diesen Himmelsrittern Seiner Majest\u00e4t Apoll's!", "tokens": ["Nichts", "von", "die\u00b7sen", "Him\u00b7mels\u00b7rit\u00b7tern", "Sei\u00b7ner", "Ma\u00b7jes\u00b7t\u00e4t", "A\u00b7poll's", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "PDAT", "NN", "PPOSAT", "NN", "NE", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.65": {"line.1": {"text": "Seh' ich recht? Da naht ein Diener! Armes Herz, verzweifle nicht!", "tokens": ["Seh'", "ich", "recht", "?", "Da", "naht", "ein", "Die\u00b7ner", "!", "Ar\u00b7mes", "Herz", ",", "ver\u00b7zweif\u00b7le", "nicht", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$.", "ADV", "VVFIN", "ART", "NN", "$.", "ADJA", "NN", "$,", "VVFIN", "PTKNEG", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Selbst im Jenseits ist dem Deutschen Ruhe und Geduld ja Pflicht!", "tokens": ["Selbst", "im", "Jen\u00b7seits", "ist", "dem", "Deut\u00b7schen", "Ru\u00b7he", "und", "Ge\u00b7duld", "ja", "Pflicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VAFIN", "ART", "ADJA", "NN", "KON", "NN", "ADV", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Ja, es ", "tokens": ["Ja", ",", "es"], "token_info": ["word", "punct", "word"], "pos": ["PTKANT", "$,", "PPER"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Kein College folgt ihm! Keiner! Das ist ", "tokens": ["Kein", "Col\u00b7le\u00b7ge", "folgt", "ihm", "!", "Kei\u00b7ner", "!", "Das", "ist"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "$.", "PIS", "$.", "PDS", "VAFIN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.66": {"line.1": {"text": "Nein, kein Teller, kein Besteck folgt', keine Speise und kein Trank,", "tokens": ["Nein", ",", "kein", "Tel\u00b7ler", ",", "kein", "Be\u00b7steck", "folgt'", ",", "kei\u00b7ne", "Spei\u00b7se", "und", "kein", "Trank", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PIAT", "NN", "$,", "PIAT", "NN", "VVFIN", "$,", "PIAT", "NN", "KON", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Und \u2013 wie ", "tokens": ["Und", "\u2013", "wie"], "token_info": ["word", "punct", "word"], "pos": ["KON", "$(", "KOKOM"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Alle andern G\u00e4ste nahmen ruhig sich Servietten und ....", "tokens": ["Al\u00b7le", "an\u00b7dern", "G\u00e4s\u00b7te", "nah\u00b7men", "ru\u00b7hig", "sich", "Ser\u00b7viet\u00b7ten", "und", "...."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "ADJD", "PRF", "NN", "KON", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Wischten sich, als ob sie \u00e4\u00dfen! wischten sich damit den Mund!", "tokens": ["Wischten", "sich", ",", "als", "ob", "sie", "\u00e4\u00b7\u00dfen", "!", "wischten", "sich", "da\u00b7mit", "den", "Mund", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$,", "KOKOM", "KOUS", "PPER", "VVINF", "$.", "VVFIN", "PRF", "PAV", "ART", "NN", "$."], "meter": "+-+--+-+--+-+", "measure": "trochaic.hexa.relaxed"}}, "stanza.67": {"line.1": {"text": "Und der Gardelieutnant sagte auf Befragen: das sei", "tokens": ["Und", "der", "Gar\u00b7de\u00b7li\u00b7eut\u00b7nant", "sag\u00b7te", "auf", "Be\u00b7fra\u00b7gen", ":", "das", "sei"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "APPR", "NN", "$.", "PDS", "VAFIN"], "meter": "--+--+-+-+-+--+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Wirklich essen oder trinken in Gesellschaft sei", "tokens": ["Wirk\u00b7lich", "es\u00b7sen", "o\u00b7der", "trin\u00b7ken", "in", "Ge\u00b7sell\u00b7schaft", "sei"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVINF", "KON", "VVFIN", "APPR", "NN", "VAFIN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.3": {"text": "\u00bbund das\u00ab, f\u00fcgte er hinzu noch, \u00bbdas, verehrter Herr, wird ", "tokens": ["\u00bb", "und", "das", "\u00ab", ",", "f\u00fcg\u00b7te", "er", "hin\u00b7zu", "noch", ",", "\u00bb", "das", ",", "ver\u00b7ehr\u00b7ter", "Herr", ",", "wird"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "word"], "pos": ["$(", "KON", "ART", "$(", "$,", "VVFIN", "PPER", "PTKVZ", "ADV", "$,", "$(", "PDS", "$,", "ADJA", "NN", "$,", "VAFIN"], "meter": "--+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Der Sie sicher von Geburt sind, nicht befremden. \u2013 Hi, hi, hi!\u00ab", "tokens": ["Der", "Sie", "si\u00b7cher", "von", "Ge\u00b7burt", "sind", ",", "nicht", "be\u00b7frem\u00b7den", ".", "\u2013", "Hi", ",", "hi", ",", "hi", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "PPER", "PRF", "APPR", "NN", "VAFIN", "$,", "PTKNEG", "VVINF", "$.", "$(", "NE", "$,", "VVFIN", "$,", "ITJ", "$.", "$("], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.68": {"line.1": {"text": "\u00bbdarf ich um die Ehre bitten\u00ab, unterbrach uns eine Sch\u00f6ne,", "tokens": ["\u00bb", "darf", "ich", "um", "die", "Eh\u00b7re", "bit\u00b7ten", "\u00ab", ",", "un\u00b7ter\u00b7brach", "uns", "ei\u00b7ne", "Sch\u00f6\u00b7ne", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$(", "$,", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "\u00bbzu dem ersten Hopphopphoppsa, dessen wunders\u00fc\u00dfen T\u00f6ne", "tokens": ["\u00bb", "zu", "dem", "ers\u00b7ten", "Hop\u00b7phop\u00b7phopp\u00b7sa", ",", "des\u00b7sen", "wun\u00b7der\u00b7s\u00fc\u00b7\u00dfen", "T\u00f6\u00b7ne"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "APPR", "ART", "ADJA", "NN", "$,", "PRELAT", "ADJA", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Vom Orchester aus dem Tanzsaal durch der R\u00e4ume L\u00fcfte kr\u00e4useln", "tokens": ["Vom", "Or\u00b7ches\u00b7ter", "aus", "dem", "Tanz\u00b7saal", "durch", "der", "R\u00e4u\u00b7me", "L\u00fcf\u00b7te", "kr\u00e4u\u00b7seln"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "APPR", "ART", "NN", "NN", "VVINF"], "meter": "-+--+-+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Und durch das entz\u00fcckte Ohr uns in des Busens Tiefe s\u00e4useln?\u00ab", "tokens": ["Und", "durch", "das", "ent\u00b7z\u00fcck\u00b7te", "Ohr", "uns", "in", "des", "Bu\u00b7sens", "Tie\u00b7fe", "s\u00e4u\u00b7seln", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "PPER", "APPR", "ART", "NN", "NN", "VVINF", "$.", "$("], "meter": "----+-+-+-+-+-+-", "measure": "unknown.measure.hexa"}}, "stanza.69": {"line.1": {"text": "Dankend lehnt' ich ab den Antrag, da ich mir an der Serviette,", "tokens": ["Dan\u00b7kend", "lehnt'", "ich", "ab", "den", "An\u00b7trag", ",", "da", "ich", "mir", "an", "der", "Ser\u00b7viet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "KOUS", "PPER", "PRF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+--+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Wie ich vorgab, meinen Magen leider ganz verdorben h\u00e4tte,", "tokens": ["Wie", "ich", "vor\u00b7gab", ",", "mei\u00b7nen", "Ma\u00b7gen", "lei\u00b7der", "ganz", "ver\u00b7dor\u00b7ben", "h\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "PPOSAT", "NN", "ADV", "ADV", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Und daher nicht disponirt sei, mich in diesem wilden Ranzen,", "tokens": ["Und", "da\u00b7her", "nicht", "dis\u00b7po\u00b7nirt", "sei", ",", "mich", "in", "die\u00b7sem", "wil\u00b7den", "Ran\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "PTKNEG", "VVPP", "VAFIN", "$,", "PRF", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Pusten und Keuchen auszuzeichnen, das man hier benamset: Tanzen.", "tokens": ["Pus\u00b7ten", "und", "Keu\u00b7chen", "aus\u00b7zu\u00b7zeich\u00b7nen", ",", "das", "man", "hier", "be\u00b7nam\u00b7set", ":", "Tan\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "KON", "NN", "VVIZU", "$,", "PRELS", "PIS", "ADV", "VVFIN", "$.", "NN", "$."], "meter": "+--+-+-+-+-+-+-+-", "measure": "iambic.octa.plus.invert"}}, "stanza.70": {"line.1": {"text": "Dann ging ich zum edlen Lord hin, gab ihm einen Nasenst\u00fcber", "tokens": ["Dann", "ging", "ich", "zum", "ed\u00b7len", "Lord", "hin", ",", "gab", "ihm", "ei\u00b7nen", "Na\u00b7sen\u00b7st\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "PTKVZ", "$,", "VVFIN", "PPER", "ART", "NN"], "meter": "-+--+-+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Und empfahl mich, ihm versichernd, da\u00df ich ganz Bewund'rung \u00fcber", "tokens": ["Und", "emp\u00b7fahl", "mich", ",", "ihm", "ver\u00b7si\u00b7chernd", ",", "da\u00df", "ich", "ganz", "Be\u00b7wun\u00b7d'\u00b7rung", "\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$,", "PPER", "VVPP", "$,", "KOUS", "PPER", "ADV", "NN", "APPR"], "meter": "--+-+-+-+-+-+--+-", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Seine gro\u00dfe Fete w\u00e4re, und in meinem Leben nie", "tokens": ["Sei\u00b7ne", "gro\u00b7\u00dfe", "Fe\u00b7te", "w\u00e4\u00b7re", ",", "und", "in", "mei\u00b7nem", "Le\u00b7ben", "nie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "$,", "KON", "APPR", "PPOSAT", "NN", "ADV"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Mir solch k\u00f6stliches Diner sei vorgekommen. \u2013 \u00bbHi, hi, hi!\u00ab", "tokens": ["Mir", "solch", "k\u00f6st\u00b7li\u00b7ches", "Di\u00b7ner", "sei", "vor\u00b7ge\u00b7kom\u00b7men", ".", "\u2013", "\u00bb", "Hi", ",", "hi", ",", "hi", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["PPER", "PIAT", "ADJA", "NN", "VAFIN", "VVPP", "$.", "$(", "$(", "NE", "$,", "VVFIN", "$,", "ITJ", "$.", "$("], "meter": "+-+--+--+-+-+-+", "measure": "trochaic.septa.relaxed"}}, "stanza.71": {"line.1": {"text": "Unten aber streckt' ich w\u00fcthend die geballte Faust empor", "tokens": ["Un\u00b7ten", "a\u00b7ber", "streckt'", "ich", "w\u00fct\u00b7hend", "die", "ge\u00b7ball\u00b7te", "Faust", "em\u00b7por"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADJD", "ART", "ADJA", "NN", "PTKVZ"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Nach der Belle-Etage droben, wo's so ", "tokens": ["Nach", "der", "Bel\u00b7le\u00b7E\u00b7ta\u00b7ge", "dro\u00b7ben", ",", "wo's", "so"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV", "$,", "PWAV", "ADV"], "meter": "+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Niemals wieder anzunehmen eine Einladung von Lords,", "tokens": ["Nie\u00b7mals", "wie\u00b7der", "an\u00b7zu\u00b7neh\u00b7men", "ei\u00b7ne", "Ein\u00b7la\u00b7dung", "von", "Lords", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVIZU", "ART", "NN", "APPR", "NE", "$,"], "meter": "+-+-+-+-+--+--+", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "Die der Himmel w\u00fcrde richten ob versuchten Hungermords!", "tokens": ["Die", "der", "Him\u00b7mel", "w\u00fcr\u00b7de", "rich\u00b7ten", "ob", "ver\u00b7such\u00b7ten", "Hun\u00b7ger\u00b7mords", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VAFIN", "VVINF", "KOUS", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.72": {"line.1": {"text": "\u00bbhier!\u00ab Der erste Kammerdiener rief's, hing mir den Mantel um", "tokens": ["\u00bb", "hier", "!", "\u00ab", "Der", "ers\u00b7te", "Kam\u00b7mer\u00b7die\u00b7ner", "rie\u00b7f's", ",", "hing", "mir", "den", "Man\u00b7tel", "um"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "$.", "$(", "ART", "ADJA", "NN", "NE", "$,", "VVFIN", "PPER", "ART", "NN", "APPR"], "meter": "+-+-+-+-+-+--+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Und \u2013 nein, das ist Unbeflecktheit! Mehr als Unsinn! Mehr als dumm! \u2013", "tokens": ["Und", "\u2013", "nein", ",", "das", "ist", "Un\u00b7be\u00b7fleckt\u00b7heit", "!", "Mehr", "als", "Un\u00b7sinn", "!", "Mehr", "als", "dumm", "!", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "$(", "PTKANT", "$,", "PDS", "VAFIN", "NN", "$.", "PIAT", "KOKOM", "NN", "$.", "PIAT", "KOKOM", "ADJD", "$.", "$("], "meter": "-+--+-+-+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Gab mir einen blanken Scudi: Trinkgeld! Er! und sprach dazu:", "tokens": ["Gab", "mir", "ei\u00b7nen", "blan\u00b7ken", "Scu\u00b7di", ":", "Trink\u00b7geld", "!", "Er", "!", "und", "sprach", "da\u00b7zu", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NE", "$.", "NN", "$.", "PPER", "$.", "KON", "VVFIN", "PAV", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "\u00bbrestauriren Sie sich, Lieber! W\u00fcnsche angenehme Ruh'!\u00ab", "tokens": ["\u00bb", "res\u00b7tau\u00b7ri\u00b7ren", "Sie", "sich", ",", "Lie\u00b7ber", "!", "W\u00fcn\u00b7sche", "an\u00b7ge\u00b7neh\u00b7me", "Ruh'", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PPER", "PRF", "$,", "ADJD", "$.", "NN", "ADJA", "NN", "$.", "$("], "meter": "-+--+-+-+-+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.73": {"line.1": {"text": "W\u00fcthend, meiner Sinne kaum noch Lehrling denn geschweige Meister,", "tokens": ["W\u00fct\u00b7hend", ",", "mei\u00b7ner", "Sin\u00b7ne", "kaum", "noch", "Lehr\u00b7ling", "denn", "ge\u00b7schwei\u00b7ge", "Meis\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PPOSAT", "NN", "ADV", "ADV", "NN", "KON", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Flucht' ich auf dies Schlo\u00df hernieder ", "tokens": ["Flucht'", "ich", "auf", "dies", "Schlo\u00df", "her\u00b7nie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PDS", "NN", "PTKVZ"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Warf den Scudi einer Statue ", "tokens": ["Warf", "den", "Scu\u00b7di", "ei\u00b7ner", "Sta\u00b7tue"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ART", "NE", "ART", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Nach der Br\u00fccke hin und st\u00fcrzte ... in's Hotel \u00bbZur guten Tante.\u00ab", "tokens": ["Nach", "der", "Br\u00fc\u00b7cke", "hin", "und", "st\u00fcrz\u00b7te", "...", "in's", "Ho\u00b7tel", "\u00bb", "Zur", "gu\u00b7ten", "Tan\u00b7te", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "KON", "VVFIN", "$(", "APPRART", "NN", "$(", "APPRART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+--+--+-+-", "measure": "trochaic.septa.relaxed"}}}}}