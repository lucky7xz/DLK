{"dta.poem.21115": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "N.A.", "genre": "Gelegenheitsschrift: Tod; Lyrik", "period": "N.A.", "pub_year": "1658", "urn": "urn:nbn:de:kobv:b4-203030-9", "language": ["de:0.99"], "booktitle": "Dach, Simon: Auff seligen wiewol hochbetrawerlichen Hintritt aus dieser Welt. K\u00f6nigsberg, 1658."}, "poem": {"stanza.1": {"line.1": {"text": "Der tapffern Leute k\u00fchnen Streit/", "tokens": ["Der", "tapf\u00b7fern", "Leu\u00b7te", "k\u00fch\u00b7nen", "Streit", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd ihre Tugend einverleiben", "tokens": ["Vnd", "ih\u00b7re", "Tu\u00b7gend", "ein\u00b7ver\u00b7lei\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dem Buch der g\u00fcldnen Ewigheit", "tokens": ["Dem", "Buch", "der", "g\u00fcld\u00b7nen", "E\u00b7wig\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df/ trifft sie nun die letzte Noht/", "tokens": ["Da\u00df", "/", "trifft", "sie", "nun", "die", "letz\u00b7te", "Noht", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Jhr Lob nicht f\u00fchle mit den Tod.", "tokens": ["Ihr", "Lob", "nicht", "f\u00fch\u00b7le", "mit", "den", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Was n\u00fctzten Herren Rappen Thaten/", "tokens": ["Was", "n\u00fctz\u00b7ten", "Her\u00b7ren", "Rap\u00b7pen", "Tha\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "NN", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nun wir Jhn sencken in den Sand", "tokens": ["Nun", "wir", "Jhn", "sen\u00b7cken", "in", "den", "Sand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "W\u00fcrd' Jhnen eilends nicht gerathen", "tokens": ["W\u00fcrd'", "Jh\u00b7nen", "ei\u00b7lends", "nicht", "ge\u00b7ra\u00b7then"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Durch dies und jene weise Hand?", "tokens": ["Durch", "dies", "und", "je\u00b7ne", "wei\u00b7se", "Hand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "KON", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd bliebe nicht sein Nahm bestehn", "tokens": ["Vnd", "blie\u00b7be", "nicht", "sein", "Nahm", "be\u00b7stehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn gleich die Welt solt untergehn?", "tokens": ["Wenn", "gleich", "die", "Welt", "solt", "un\u00b7ter\u00b7gehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Was w\u00fcrdet Jhr/ Jhr Erben/ sagen", "tokens": ["Was", "w\u00fcr\u00b7det", "Ihr", "/", "Ihr", "Er\u00b7ben", "/", "sa\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PWS", "VAFIN", "PPER", "$(", "PPOSAT", "NN", "$(", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn Jhr nun trettet Seinen Pfad?", "tokens": ["Wenn", "Ihr", "nun", "tret\u00b7tet", "Sei\u00b7nen", "Pfad", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie w\u00fcrdet Jhr es doch vertragen", "tokens": ["Wie", "w\u00fcr\u00b7det", "Ihr", "es", "doch", "ver\u00b7tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPER", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df niemand Jhn beschrieben hat?", "tokens": ["Da\u00df", "nie\u00b7mand", "Jhn", "be\u00b7schrie\u00b7ben", "hat", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd da\u00df ohn allen Vnterscheid", "tokens": ["Vnd", "da\u00df", "ohn", "al\u00b7len", "Vn\u00b7ter\u00b7scheid"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Er und sein Ruhm l\u00e4g' abgemeyt.", "tokens": ["Er", "und", "sein", "Ruhm", "l\u00e4g'", "ab\u00b7ge\u00b7meyt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PPOSAT", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Was wir den Kindern hinterlassen", "tokens": ["Was", "wir", "den", "Kin\u00b7dern", "hin\u00b7ter\u00b7las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das sind viel tausend Huben nicht/", "tokens": ["Das", "sind", "viel", "tau\u00b7send", "Hu\u00b7ben", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "CARD", "NN", "PTKNEG", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auch nicht ein Schatz der schier ohn massen", "tokens": ["Auch", "nicht", "ein", "Schatz", "der", "schier", "ohn", "mas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PTKNEG", "ART", "NN", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr Menge durch die Kasten bricht/", "tokens": ["F\u00fcr", "Men\u00b7ge", "durch", "die", "Kas\u00b7ten", "bricht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ach nein/Ihr wahres Erbschafft Gut", "tokens": ["Ach", "nein", "/", "Ihr", "wah\u00b7res", "Erb\u00b7schafft", "Gut"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PTKANT", "$(", "PPOSAT", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das ist der Eltern Tugend-Muth.", "tokens": ["Das", "ist", "der", "El\u00b7tern", "Tu\u00b7gen\u00b7dMuth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Was schn\u00f6der Reichthum kan verfangen", "tokens": ["Was", "schn\u00f6\u00b7der", "Reicht\u00b7hum", "kan", "ver\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADJA", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das hat der Krieg uns gnug gezeigt", "tokens": ["Das", "hat", "der", "Krieg", "uns", "gnug", "ge\u00b7zeigt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Viel die wie F\u00fcrsten erst gegangen", "tokens": ["Viel", "die", "wie", "F\u00fcrs\u00b7ten", "erst", "ge\u00b7gan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "KOKOM", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd aller Leute Mund geschweigt/", "tokens": ["Vnd", "al\u00b7ler", "Leu\u00b7te", "Mund", "ge\u00b7schweigt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Die geben ietzt weit besser Kauff/", "tokens": ["Die", "ge\u00b7ben", "ietzt", "weit", "bes\u00b7ser", "Kauff", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADJD", "ADJA", "NN", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Vnd ziehn wie arme Bettler auff.", "tokens": ["Vnd", "ziehn", "wie", "ar\u00b7me", "Bett\u00b7ler", "auff", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "KOKOM", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Der Ehren Erbgut mu\u00df bestehen", "tokens": ["Der", "Eh\u00b7ren", "Erb\u00b7gut", "mu\u00df", "be\u00b7ste\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd wird in bl\u00fcte stets gesp\u00fcrt", "tokens": ["Vnd", "wird", "in", "bl\u00fc\u00b7te", "stets", "ge\u00b7sp\u00fcrt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "VVFIN", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Lands-Knecht mu\u00df vor\u00fcbergehen", "tokens": ["Der", "Lands\u00b7Knecht", "mu\u00df", "vor\u00b7\u00fc\u00b7ber\u00b7ge\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Trotz einem der hie was ber\u00fchrt/", "tokens": ["Trotz", "ei\u00b7nem", "der", "hie", "was", "be\u00b7r\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "ADV", "PIS", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Kind das liebet Ehr uud Ruhm.", "tokens": ["Ein", "Kind", "das", "lie\u00b7bet", "Ehr", "u\u00b7ud", "Ruhm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDS", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "H\u00e4lt dieses f\u00fcr ein F\u00fcrstenthum", "tokens": ["H\u00e4lt", "die\u00b7ses", "f\u00fcr", "ein", "F\u00fcrs\u00b7ten\u00b7thum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PDAT", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "De\u00df kan ich mich versichert halten", "tokens": ["De\u00df", "kan", "ich", "mich", "ver\u00b7si\u00b7chert", "hal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "PPER", "PRF", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df manchem der nach Tugend ringt/", "tokens": ["Da\u00df", "man\u00b7chem", "der", "nach", "Tu\u00b7gend", "ringt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ART", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Liest er die Seinen in den Alten", "tokens": ["Liest", "er", "die", "Sei\u00b7nen", "in", "den", "Al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "PPOSS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das Hertz in ihm f\u00fcr Frewden springt/", "tokens": ["Das", "Hertz", "in", "ihm", "f\u00fcr", "Frew\u00b7den", "springt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd n\u00e4hme weder Edelstein", "tokens": ["Vnd", "n\u00e4h\u00b7me", "we\u00b7der", "E\u00b7del\u00b7stein"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Noch Gold f\u00fcr diesen Schatz allein.", "tokens": ["Noch", "Gold", "f\u00fcr", "die\u00b7sen", "Schatz", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "PDAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Vnd dieses sol auch Euch ergetzen", "tokens": ["Vnd", "die\u00b7ses", "sol", "auch", "Euch", "er\u00b7get\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VMFIN", "ADV", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Jhr Edlen Rappen alle vier/", "tokens": ["Ihr", "Ed\u00b7len", "Rap\u00b7pen", "al\u00b7le", "vier", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PIAT", "CARD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "H\u00f6rt ihr von ewrer Vorfahrt schw\u00e4tzen/", "tokens": ["H\u00f6rt", "ihr", "von", "ew\u00b7rer", "Vor\u00b7fahrt", "schw\u00e4t\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So sollt ihr wallen von Begier/", "tokens": ["So", "sollt", "ihr", "wal\u00b7len", "von", "Be\u00b7gier", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVINF", "APPR", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd seyd ihr warlich Stein und Ertz", "tokens": ["Vnd", "seyd", "ihr", "war\u00b7lich", "Stein", "und", "Ertz"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nimmt Euch der Cantzler nicht das Hertz", "tokens": ["Nimmt", "Euch", "der", "Cantz\u00b7ler", "nicht", "das", "Hertz"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKNEG", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Der ewer Gro\u00dfvatter gewesen", "tokens": ["Der", "e\u00b7wer", "Gro\u00df\u00b7vat\u00b7ter", "ge\u00b7we\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "VAPP"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Vnd dieses Landes Ober-Raht.", "tokens": ["Vnd", "die\u00b7ses", "Lan\u00b7des", "O\u00b7ber\u00b7Raht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie hochgelehrt wie au\u00dferlesen", "tokens": ["Wie", "hoch\u00b7ge\u00b7lehrt", "wie", "au\u00b7\u00dfer\u00b7le\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "KOKOM", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Lateinisch Er geredet hat", "tokens": ["La\u00b7tei\u00b7nisch", "Er", "ge\u00b7re\u00b7det", "hat"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "PPER", "VVPP", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wei\u00df Preussen gnug/ wir ziehen an", "tokens": ["Wei\u00df", "Preus\u00b7sen", "gnug", "/", "wir", "zie\u00b7hen", "an"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NE", "ADV", "$(", "PPER", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "F\u00fcr einen Au\u00dfbund diesen Mann.", "tokens": ["F\u00fcr", "ei\u00b7nen", "Au\u00df\u00b7bund", "die\u00b7sen", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Er war ein Cicero in Pohlen/", "tokens": ["Er", "war", "ein", "Ci\u00b7ce\u00b7ro", "in", "Poh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "NE", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So offt Er sich dahin gemacht", "tokens": ["So", "offt", "Er", "sich", "da\u00b7hin", "ge\u00b7macht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PPER", "PRF", "PAV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Jhm ein Gewerbe war befohlen/", "tokens": ["Jhm", "ein", "Ge\u00b7wer\u00b7be", "war", "be\u00b7foh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was Ruhm hat Er zur\u00fcck gebracht/", "tokens": ["Was", "Ruhm", "hat", "Er", "zu\u00b7r\u00fcck", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "PPER", "PTKVZ", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Jhm nicht schlechtes Gut erwarb", "tokens": ["Das", "Jhm", "nicht", "schlech\u00b7tes", "Gut", "er\u00b7warb"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "PTKNEG", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bi\u00df Er in h\u00f6chsten Ehren starb.", "tokens": ["Bi\u00df", "Er", "in", "h\u00f6chs\u00b7ten", "Eh\u00b7ren", "starb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Lasst Jhr Euch folgends nicht bewegen", "tokens": ["Lasst", "Ihr", "Euch", "fol\u00b7gends", "nicht", "be\u00b7we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "PIS", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Auch Ewres Vaters ernsten Flei\u00df/", "tokens": ["Auch", "Ew\u00b7res", "Va\u00b7ters", "erns\u00b7ten", "Flei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So mu\u00df kein Blut in Euch sich regen", "tokens": ["So", "mu\u00df", "kein", "Blut", "in", "Euch", "sich", "re\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PIAT", "NN", "APPR", "PPER", "PRF", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das streben wil nach Ruhm und Prei\u00df/", "tokens": ["Das", "stre\u00b7ben", "wil", "nach", "Ruhm", "und", "Prei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VMFIN", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dafern Jhr von Jhm melden h\u00f6rt", "tokens": ["Da\u00b7fern", "Ihr", "von", "Jhm", "mel\u00b7den", "h\u00f6rt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPER", "VVINF", "VVFIN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Wie seine Tugend Jhn emp\u00f6rt.", "tokens": ["Wie", "sei\u00b7ne", "Tu\u00b7gend", "Jhn", "em\u00b7p\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Wie Er sich Anfangs leiten lassen", "tokens": ["Wie", "Er", "sich", "An\u00b7fangs", "lei\u00b7ten", "las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PRF", "ADV", "VVINF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Stracks auff der Furcht des HErren Bahn", "tokens": ["Stracks", "auff", "der", "Furcht", "des", "Her\u00b7ren", "Bahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd guter K\u00fcnste Grund zu fassen", "tokens": ["Vnd", "gu\u00b7ter", "K\u00fcns\u00b7te", "Grund", "zu", "fas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Erst fern nach Thoren sich verthan/", "tokens": ["Erst", "fern", "nach", "Tho\u00b7ren", "sich", "ver\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NN", "PRF", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Darnach in Pohlen sich gewand", "tokens": ["Dar\u00b7nach", "in", "Poh\u00b7len", "sich", "ge\u00b7wand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "APPR", "NE", "PRF", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bi\u00df Jhm die Sprache ward bekant.", "tokens": ["Bi\u00df", "Jhm", "die", "Spra\u00b7che", "ward", "be\u00b7kant", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Wie/ als sein Vater Jhm verblichen/", "tokens": ["Wie", "/", "als", "sein", "Va\u00b7ter", "Jhm", "ver\u00b7bli\u00b7chen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$(", "KOUS", "PPOSAT", "NN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sein Lob das Hertz in Jhm geregt", "tokens": ["Sein", "Lob", "das", "Hertz", "in", "Jhm", "ge\u00b7regt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ART", "NN", "APPR", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df Er von hinnen nicht gewichen", "tokens": ["Da\u00df", "Er", "von", "hin\u00b7nen", "nicht", "ge\u00b7wi\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADV", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bi\u00df da\u00df Er festen Grund gelegt", "tokens": ["Bi\u00df", "da\u00df", "Er", "fes\u00b7ten", "Grund", "ge\u00b7legt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "PPER", "ADJA", "NN", "VVPP"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Der Wei\u00dfheit/ welche nachmals Jhn", "tokens": ["Der", "Wei\u00df\u00b7heit", "/", "wel\u00b7che", "nach\u00b7mals", "Jhn"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$(", "PRELS", "ADV", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gezwungen Holland ein-zu-ziehn.", "tokens": ["Ge\u00b7zwun\u00b7gen", "Hol\u00b7land", "ein\u00b7zu\u00b7ziehn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NE", "VVIZU", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Hie kunt Jhn g\u00e4ntzlich nicht begn\u00fcgen", "tokens": ["Hie", "kunt", "Jhn", "g\u00e4ntz\u00b7lich", "nicht", "be\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Wissenschafft und Kunst allein/", "tokens": ["Die", "Wis\u00b7sen\u00b7schafft", "und", "Kunst", "al\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Waffen wolt' Er darzu f\u00fcgen", "tokens": ["Die", "Waf\u00b7fen", "wolt'", "Er", "dar\u00b7zu", "f\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "PPER", "PAV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Drumb must' Er auch ein Kriegsmann seyn/", "tokens": ["Drumb", "must'", "Er", "auch", "ein", "Kriegs\u00b7mann", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ADV", "ART", "NN", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "erfrewt es Euch nicht/ wenn Jhr Jhn", "tokens": ["er\u00b7frewt", "es", "Euch", "nicht", "/", "wenn", "Ihr", "Jhn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "PTKNEG", "$(", "KOUS", "PPER", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit vor Breda nun sehet ziehn?", "tokens": ["Mit", "vor", "Bre\u00b7da", "nun", "se\u00b7het", "ziehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "NE", "ADV", "VVFIN", "VVINF", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.17": {"line.1": {"text": "Vnd alles da in Auffsicht fassen", "tokens": ["Vnd", "al\u00b7les", "da", "in", "Auff\u00b7sicht", "fas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "ADV", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist nur wozu Gelegenheit/", "tokens": ["Ist", "nur", "wo\u00b7zu", "Ge\u00b7le\u00b7gen\u00b7heit", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PWAV", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Schlaff sich nirgends irren lassen/", "tokens": ["Den", "Schlaff", "sich", "nir\u00b7gends", "ir\u00b7ren", "las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADV", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Selbst schweben mitten in dem Streit", "tokens": ["Selbst", "schwe\u00b7ben", "mit\u00b7ten", "in", "dem", "Streit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den Helden kunt und offenbahr", "tokens": ["Den", "Hel\u00b7den", "kunt", "und", "of\u00b7fen\u00b7bahr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nie bleich in N\u00f6hten und Gefahr.", "tokens": ["Nie", "bleich", "in", "N\u00f6h\u00b7ten", "und", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Ey wenn er durch die Wellen gehet", "tokens": ["Ey", "wenn", "er", "durch", "die", "Wel\u00b7len", "ge\u00b7het"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "KOUS", "PPER", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd Engelland sich anvertrawt?", "tokens": ["Vnd", "En\u00b7gel\u00b7land", "sich", "an\u00b7ver\u00b7trawt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu Londen und zu Oxfurt stehet", "tokens": ["Zu", "Lon\u00b7den", "und", "zu", "Ox\u00b7furt", "ste\u00b7het"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "KON", "APPR", "NE", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd alle Sachen da beschawt/", "tokens": ["Vnd", "al\u00b7le", "Sa\u00b7chen", "da", "be\u00b7schawt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd nach", "tokens": ["Vnd", "nach"], "token_info": ["word", "word"], "pos": ["KON", "APPR"], "meter": "++", "measure": "spondeus"}, "line.6": {"text": "In Schweden findet Auffenthalt?", "tokens": ["In", "Schwe\u00b7den", "fin\u00b7det", "Auf\u00b7fent\u00b7halt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Vnd habt Jhr nicht daran Gefallen", "tokens": ["Vnd", "habt", "Ihr", "nicht", "da\u00b7ran", "Ge\u00b7fal\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "PAV", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df Jhn Gustaff in Hulde nimmt", "tokens": ["Da\u00df", "Jhn", "Gus\u00b7taff", "in", "Hul\u00b7de", "nimmt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "NE", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Indem Er Preussen Jhm f\u00fcr allen", "tokens": ["In\u00b7dem", "Er", "Preus\u00b7sen", "Jhm", "f\u00fcr", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "NN", "PPER", "APPR", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu \u00fcberraschen hat bestimmt/", "tokens": ["Zu", "\u00fc\u00b7berr\u00b7a\u00b7schen", "hat", "be\u00b7stimmt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Auch unter seiner Hoffstat Jhn", "tokens": ["Auch", "un\u00b7ter", "sei\u00b7ner", "Hoff\u00b7stat", "Jhn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zwingt durch die Wellen herzuziehn?", "tokens": ["Zwingt", "durch", "die", "Wel\u00b7len", "her\u00b7zu\u00b7ziehn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Hie wo er seiner wol genossen", "tokens": ["Hie", "wo", "er", "sei\u00b7ner", "wol", "ge\u00b7nos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PWAV", "PPER", "PPOSAT", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Ihm gezogen in das Feld", "tokens": ["Mit", "Ihm", "ge\u00b7zo\u00b7gen", "in", "das", "Feld"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VVPP", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd manchen festen Ort umbschlossen/", "tokens": ["Vnd", "man\u00b7chen", "fes\u00b7ten", "Ort", "umbsc\u00b7hlos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bi\u00df Jhn G\u00f6rg Wilhelm unterstellt/", "tokens": ["Bi\u00df", "Jhn", "G\u00f6rg", "Wil\u00b7helm", "un\u00b7ter\u00b7stellt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "NE", "NE", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df Er sol zu den Pohlen gehn", "tokens": ["Da\u00df", "Er", "sol", "zu", "den", "Poh\u00b7len", "gehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VMFIN", "APPR", "ART", "NN", "VVINF"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Die Satzung wolt' es nicht gestehn/", "tokens": ["Die", "Sat\u00b7zung", "wolt'", "es", "nicht", "ge\u00b7stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Vnd heisst ihn Deutschland wieder sehen/", "tokens": ["Vnd", "heisst", "ihn", "Deutschland", "wie\u00b7der", "se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NE", "ADV", "VVINF", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Der Held von Weimar nimmt Ihn an.", "tokens": ["Der", "Held", "von", "Wei\u00b7mar", "nimmt", "Ihn", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nichts ist da schier ohn Ihn geschehen", "tokens": ["Nichts", "ist", "da", "schier", "ohn", "Ihn", "ge\u00b7sche\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ADV", "ADJD", "APPR", "PPER", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wo Er nicht zeigte seinen Mann", "tokens": ["Wo", "Er", "nicht", "zeig\u00b7te", "sei\u00b7nen", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PTKNEG", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Bi\u00df Ihn G\u00f6rg Wilhelm an sich zieht", "tokens": ["Bi\u00df", "Ihn", "G\u00f6rg", "Wil\u00b7helm", "an", "sich", "zieht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "NE", "NE", "APPR", "PRF", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd Jhn die Marcke wieder sieht.", "tokens": ["Vnd", "Jhn", "die", "Mar\u00b7cke", "wie\u00b7der", "sieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Da Er den Ehrengrad erworben", "tokens": ["Da", "Er", "den", "Eh\u00b7ren\u00b7grad", "er\u00b7wor\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der endlich blieb Sein Eigenthum", "tokens": ["Der", "end\u00b7lich", "blieb", "Sein", "Ei\u00b7gen\u00b7thum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bi\u00df da\u00df Er selig ist gestorben.", "tokens": ["Bi\u00df", "da\u00df", "Er", "se\u00b7lig", "ist", "ge\u00b7stor\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "ADJD", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wo lass' ich Seinen andern Ruhm/", "tokens": ["Wo", "lass'", "ich", "Sei\u00b7nen", "an\u00b7dern", "Ruhm", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df Er voraus mit Hertz und Wahn", "tokens": ["Da\u00df", "Er", "vo\u00b7raus", "mit", "Hertz", "und", "Wahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKVZ", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Niedrigheit war zugethan?", "tokens": ["Der", "Nied\u00b7rig\u00b7heit", "war", "zu\u00b7ge\u00b7than", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Nicht auff den Adel sich verlassen", "tokens": ["Nicht", "auff", "den", "A\u00b7del", "sich", "ver\u00b7las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "APPR", "ART", "NN", "PRF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ob Er von Mutter Seiten gleich", "tokens": ["Ob", "Er", "von", "Mut\u00b7ter", "Sei\u00b7ten", "gleich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Creutzen sich hatt' anzumassen?", "tokens": ["Der", "Creut\u00b7zen", "sich", "hatt'", "an\u00b7zu\u00b7mas\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "VAFIN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Er war auch von Erbarmen reich/", "tokens": ["Er", "war", "auch", "von", "Er\u00b7bar\u00b7men", "reich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So offt ein Armer Jhn besprach", "tokens": ["So", "offt", "ein", "Ar\u00b7mer", "Jhn", "be\u00b7sprach"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vmb H\u00fclff und Raht in ungemach.", "tokens": ["Vmb", "H\u00fclff", "und", "Raht", "in", "un\u00b7ge\u00b7mach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "APPR", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Wie weinet doch umb Ihr Szabinen/", "tokens": ["Wie", "wei\u00b7net", "doch", "umb", "Ihr", "Sza\u00b7bi\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie kl\u00e4glich h\u00e4lt sich Angerapp/", "tokens": ["Wie", "kl\u00e4g\u00b7lich", "h\u00e4lt", "sich", "An\u00b7ge\u00b7rapp", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PRF", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vmb Gehrcken wil das Feld nicht gr\u00fcnen", "tokens": ["Vmb", "Gehr\u00b7cken", "wil", "das", "Feld", "nicht", "gr\u00fc\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VMFIN", "ART", "NN", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Jm Caymischen nimmt alles ab", "tokens": ["Jm", "Cay\u00b7mi\u00b7schen", "nimmt", "al\u00b7les", "ab"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "PIS", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Heerden m\u00fcssen mager stehn", "tokens": ["Die", "Heer\u00b7den", "m\u00fcs\u00b7sen", "ma\u00b7ger", "stehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "ADJD", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Hirten s\u00e4mptlich trawrig gehn.", "tokens": ["Die", "Hir\u00b7ten", "s\u00e4mpt\u00b7lich", "traw\u00b7rig", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Was hielt Er von gelehrten Leuten/", "tokens": ["Was", "hielt", "Er", "von", "ge\u00b7lehr\u00b7ten", "Leu\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was vom geehrten Predig-Ampt?", "tokens": ["Was", "vom", "ge\u00b7ehr\u00b7ten", "Pre\u00b7dig\u00b7Ampt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "er lie\u00df sich GOttes Wort bedeuten", "tokens": ["er", "lie\u00df", "sich", "Got\u00b7tes", "Wort", "be\u00b7deu\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "NN", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd hielte sich durchaus verdamt", "tokens": ["Vnd", "hiel\u00b7te", "sich", "durc\u00b7haus", "ver\u00b7damt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "K\u00e4m Jhm nicht Christus rohte Fluth/", "tokens": ["K\u00e4m", "Jhm", "nicht", "Chris\u00b7tus", "roh\u00b7te", "Fluth", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PTKNEG", "NE", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die unsre S\u00fcnde tilgt zu gut.", "tokens": ["Die", "uns\u00b7re", "S\u00fcn\u00b7de", "tilgt", "zu", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "H\u00f6rt Jhr nun die\u00df an Jhm erheben/", "tokens": ["H\u00f6rt", "Ihr", "nun", "die\u00df", "an", "Jhm", "er\u00b7he\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PDS", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So fasst es mit genawer Acht", "tokens": ["So", "fasst", "es", "mit", "ge\u00b7na\u00b7wer", "Acht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJD", "CARD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Vnd kehrt es gantz in ewer Leben.", "tokens": ["Vnd", "kehrt", "es", "gantz", "in", "e\u00b7wer", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die\u00df heisst sich recht betr\u00fcbt gemacht", "tokens": ["Die\u00df", "heisst", "sich", "recht", "be\u00b7tr\u00fcbt", "ge\u00b7macht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PRF", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn Jhr an seinen Sinn gedenckt", "tokens": ["Wenn", "Ihr", "an", "sei\u00b7nen", "Sinn", "ge\u00b7denckt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd \u00fcber dem Verlust Euch kr\u00e4nckt.", "tokens": ["Vnd", "\u00fc\u00b7ber", "dem", "Ver\u00b7lust", "Euch", "kr\u00e4nckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Sucht ewren Adel in der Tugend", "tokens": ["Sucht", "ew\u00b7ren", "A\u00b7del", "in", "der", "Tu\u00b7gend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd blo\u00df in dem Gebl\u00fcte nicht/", "tokens": ["Vnd", "blo\u00df", "in", "dem", "Ge\u00b7bl\u00fc\u00b7te", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "PTKNEG", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn der besteht in strenger Jugend", "tokens": ["Denn", "der", "be\u00b7steht", "in", "stren\u00b7ger", "Ju\u00b7gend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In Kunst und aller Demut-Pflicht/", "tokens": ["In", "Kunst", "und", "al\u00b7ler", "De\u00b7mut\u00b7Pflicht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd haltet unwehrt einen Muth", "tokens": ["Vnd", "hal\u00b7tet", "un\u00b7wehrt", "ei\u00b7nen", "Muth"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der nichts zeigt als der Eltern Blut.", "tokens": ["Der", "nichts", "zeigt", "als", "der", "El\u00b7tern", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "KOKOM", "ART", "NN", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.30": {"line.1": {"text": "Vnd stellet so an Ewer Leben", "tokens": ["Vnd", "stel\u00b7let", "so", "an", "E\u00b7wer", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da\u00df Jhr ohn Wiederred und Streit", "tokens": ["Da\u00df", "Ihr", "ohn", "Wie\u00b7der\u00b7red", "und", "Streit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NE", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vns euren Cantzler herzugeben", "tokens": ["Vns", "eu\u00b7ren", "Cantz\u00b7ler", "her\u00b7zu\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Aus ewrem mittel schuldig seyd/", "tokens": ["Aus", "ew\u00b7rem", "mit\u00b7tel", "schul\u00b7dig", "seyd", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Auch einen der an Kunst und Trew", "tokens": ["Auch", "ei\u00b7nen", "der", "an", "Kunst", "und", "Trew"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ART", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dem wehrten Vater \u00e4hnlich sey", "tokens": ["Dem", "wehr\u00b7ten", "Va\u00b7ter", "\u00e4hn\u00b7lich", "sey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJD", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Die andern ihren grossen Ahnen", "tokens": ["Die", "an\u00b7dern", "ih\u00b7ren", "gros\u00b7sen", "Ah\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die auch bey den Oenhausen seyn/", "tokens": ["Die", "auch", "bey", "den", "O\u00b7en\u00b7hau\u00b7sen", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "VAINF", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Die auch nicht sind ohn Schild und Fahnen", "tokens": ["Die", "auch", "nicht", "sind", "ohn", "Schild", "und", "Fah\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "PTKNEG", "VAFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd fern durch Deutschland nicht gemein/", "tokens": ["Vnd", "fern", "durch", "Deutschland", "nicht", "ge\u00b7mein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "NE", "PTKNEG", "ADJD", "$("], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.5": {"text": "Seht was man ihm von Ewrer Schlacht/", "tokens": ["Seht", "was", "man", "ihm", "von", "Ew\u00b7rer", "Schlacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PWS", "PIS", "PPER", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "O lebet nur/ f\u00fcr Hoffnung macht.", "tokens": ["O", "le\u00b7bet", "nur", "/", "f\u00fcr", "Hoff\u00b7nung", "macht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "$(", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Hoch Edle Fraw/ nehmt Ewer Leiden", "tokens": ["Hoch", "Ed\u00b7le", "Fraw", "/", "nehmt", "E\u00b7wer", "Lei\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "ADJA", "NN", "$(", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das Creutz mit Christen-Armen an/", "tokens": ["Das", "Creutz", "mit", "Chris\u00b7ten\u00b7Ar\u00b7men", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd wisst Euch GOttes zu bescheiden/", "tokens": ["Vnd", "wisst", "Euch", "Got\u00b7tes", "zu", "be\u00b7schei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Ewren Sachen rahten kan", "tokens": ["Der", "Ew\u00b7ren", "Sa\u00b7chen", "rah\u00b7ten", "kan"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd h\u00f6hnt nicht ewer Christenthum", "tokens": ["Vnd", "h\u00f6hnt", "nicht", "e\u00b7wer", "Chris\u00b7ten\u00b7thum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das Euch gebiert nicht schlechten Ruhm.", "tokens": ["Das", "Euch", "ge\u00b7biert", "nicht", "schlech\u00b7ten", "Ruhm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "VVFIN", "PTKNEG", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Wer seinem GOtt sich h\u00e4lt ergeben", "tokens": ["Wer", "sei\u00b7nem", "Gott", "sich", "h\u00e4lt", "er\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPOSAT", "NN", "PRF", "VVFIN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd dienet Ihm mit aller Macht/", "tokens": ["Vnd", "die\u00b7net", "Ihm", "mit", "al\u00b7ler", "Macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der mu\u00df ohn Z\u00fcchtigung nicht leben/", "tokens": ["Der", "mu\u00df", "ohn", "Z\u00fcch\u00b7ti\u00b7gung", "nicht", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "APPR", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Darauff hat Christus selber Acht", "tokens": ["Dar\u00b7auff", "hat", "Chris\u00b7tus", "sel\u00b7ber", "Acht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "NE", "ADV", "CARD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Auff da\u00df sie stets in Creutz und Pein", "tokens": ["Auff", "da\u00df", "sie", "stets", "in", "Creutz", "und", "Pein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "PPER", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vnd niemals ohn Anfechtung seyn.", "tokens": ["Vnd", "nie\u00b7mals", "ohn", "An\u00b7fech\u00b7tung", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Die\u00df ist bey allen/ die Jhn lieben.", "tokens": ["Die\u00df", "ist", "bey", "al\u00b7len", "/", "die", "Jhn", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PIAT", "$(", "PRELS", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Erwegt die Gutthat auch dabey/", "tokens": ["Er\u00b7wegt", "die", "Gut\u00b7that", "auch", "da\u00b7bey", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "PAV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Jhr trugt der lieben Kinder sieben", "tokens": ["Ihr", "trugt", "der", "lie\u00b7ben", "Kin\u00b7der", "sie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "CARD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nur eines misst die sch\u00f6ne Reih.", "tokens": ["Nur", "ei\u00b7nes", "misst", "die", "sch\u00f6\u00b7ne", "Reih", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit manchem ist es gantz geschehn", "tokens": ["Mit", "man\u00b7chem", "ist", "es", "gantz", "ge\u00b7schehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Euch hat der Krieg noch \u00fcbersehn.", "tokens": ["Euch", "hat", "der", "Krieg", "noch", "\u00fc\u00b7ber\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Jhr seyd so gro\u00df nicht mitgenommen.", "tokens": ["Ihr", "seyd", "so", "gro\u00df", "nicht", "mit\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wo bleibt der Eydam zu dem Jhr", "tokens": ["Wo", "bleibt", "der", "Ey\u00b7dam", "zu", "dem", "Ihr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "ART", "NN", "APPR", "PRELS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Recht in dem Creutze seyd gekommen/", "tokens": ["Recht", "in", "dem", "Creut\u00b7ze", "seyd", "ge\u00b7kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Wo lass' ich seiner K\u00fcnste Zier/", "tokens": ["Wo", "lass'", "ich", "sei\u00b7ner", "K\u00fcns\u00b7te", "Zier", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Herr R\u00e4der kan euch/ Fraw/ allein", "tokens": ["Herr", "R\u00e4\u00b7der", "kan", "euch", "/", "Fraw", "/", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["NN", "NN", "VMFIN", "PPER", "$(", "NN", "$(", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "An Mannes stat und Vaters seyn.", "tokens": ["An", "Man\u00b7nes", "stat", "und", "Va\u00b7ters", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "KON", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Herr Rapp ist Euch nun minder tod", "tokens": ["Herr", "Rapp", "ist", "Euch", "nun", "min\u00b7der", "tod"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "NE", "VAFIN", "PPER", "ADV", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nun er kan seine L\u00fccke b\u00fcssen.", "tokens": ["Nun", "er", "kan", "sei\u00b7ne", "L\u00fc\u00b7cke", "b\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "O lieb' und angenehme Noht", "tokens": ["O", "lieb'", "und", "an\u00b7ge\u00b7neh\u00b7me", "Noht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die GOtt sucht also zu vers\u00fcssen!", "tokens": ["Die", "Gott", "sucht", "al\u00b7so", "zu", "ver\u00b7s\u00fcs\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ging' ich den Meinen also ab/", "tokens": ["Ging'", "ich", "den", "Mei\u00b7nen", "al\u00b7so", "ab", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "ADV", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie fr\u00f6lich f\u00fchr ich in mein Grab!", "tokens": ["Wie", "fr\u00f6\u00b7lich", "f\u00fchr", "ich", "in", "mein", "Grab", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}