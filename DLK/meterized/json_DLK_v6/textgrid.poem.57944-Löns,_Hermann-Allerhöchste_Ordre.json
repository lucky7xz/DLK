{"textgrid.poem.57944": {"metadata": {"author": {"name": "L\u00f6ns, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "Allerh\u00f6chste Ordre", "genre": "verse", "period": "N.A.", "pub_year": 1890, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich hab' die Sache dicke,", "tokens": ["Ich", "hab'", "die", "Sa\u00b7che", "di\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ich hab' die Sache satt;", "tokens": ["Ich", "hab'", "die", "Sa\u00b7che", "satt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es sind mir zu viel N\u00f6rgler", "tokens": ["Es", "sind", "mir", "zu", "viel", "N\u00f6rg\u00b7ler"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "In meiner lieben Stadt.", "tokens": ["In", "mei\u00b7ner", "lie\u00b7ben", "Stadt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Schwarzseher kann 'ch nicht brauchen,", "tokens": ["Schwarz\u00b7se\u00b7her", "kann", "'ch", "nicht", "brau\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hab' Besseres zu tun,", "tokens": ["Hab'", "Bes\u00b7se\u00b7res", "zu", "tun", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wem's nicht pa\u00dft, der sch\u00fcttle", "tokens": ["Und", "wem's", "nicht", "pa\u00dft", ",", "der", "sch\u00fctt\u00b7le"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PWS", "PTKNEG", "VVFIN", "$,", "PRELS", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Den Staub von seinen Schuh'n.", "tokens": ["Den", "Staub", "von", "sei\u00b7nen", "Schuh'", "n."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Wir brauchen Optimisten,", "tokens": ["Wir", "brau\u00b7chen", "Op\u00b7ti\u00b7mis\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und der, der das nicht ist,", "tokens": ["Und", "der", ",", "der", "das", "nicht", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "PRELS", "PDS", "PTKNEG", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der zieh' gef\u00e4lligst w\u00e4rtser", "tokens": ["Der", "zieh'", "ge\u00b7f\u00e4l\u00b7ligst", "w\u00e4rt\u00b7ser"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "VAFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mit seinem Pessi-Mist.", "tokens": ["Mit", "sei\u00b7nem", "Pes\u00b7si\u00b7Mist", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Ausrotten will ich g\u00e4nzlich", "tokens": ["Aus\u00b7rot\u00b7ten", "will", "ich", "g\u00e4nz\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VMFIN", "PPER", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Das N\u00f6rgeleigew\u00e4chs;", "tokens": ["Das", "N\u00f6r\u00b7ge\u00b7lei\u00b7ge\u00b7w\u00e4chs", ";"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Soll sein ", "tokens": ["Soll", "sein"], "token_info": ["word", "word"], "pos": ["VMFIN", "PPOSAT"], "meter": "-+", "measure": "iambic.single"}}}}}