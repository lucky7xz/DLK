{"dta.poem.4320": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Die Wirbel-Winde.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-20083-6", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wann von verschiednen Wolken-Klumpen verschiedne", "tokens": ["Wann", "von", "ver\u00b7schied\u00b7nen", "Wol\u00b7ken\u00b7Klum\u00b7pen", "ver\u00b7schied\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ADJA", "NN", "ADJA"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wind' hervorgebracht,", "tokens": ["Wind'", "her\u00b7vor\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Und diese sich zu denen f\u00fcgen, die erst geweht, vermehret", "tokens": ["Und", "die\u00b7se", "sich", "zu", "de\u00b7nen", "f\u00fc\u00b7gen", ",", "die", "erst", "ge\u00b7weht", ",", "ver\u00b7meh\u00b7ret"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KON", "PDS", "PRF", "APPR", "PRELS", "VVINF", "$,", "PRELS", "ADV", "VVFIN", "$,", "VVFIN"], "meter": "-+-----+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "sich", "tokens": ["sich"], "token_info": ["word"], "pos": ["PRF"], "meter": "-", "measure": "single.down"}}, "stanza.2": {"line.1": {"text": "Die Wut des aufgebrachten Sturms und der ergrimmten", "tokens": ["Die", "Wut", "des", "auf\u00b7ge\u00b7brach\u00b7ten", "Sturms", "und", "der", "er\u00b7grimm\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "KON", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Winde Macht,", "tokens": ["Win\u00b7de", "Macht", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Sie stossen pfeifend auf einander, und pressen sich gewal-", "tokens": ["Sie", "stos\u00b7sen", "pfei\u00b7fend", "auf", "ein\u00b7an\u00b7der", ",", "und", "pres\u00b7sen", "sich", "ge\u00b7wa\u00b7l"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ADV", "$,", "KON", "VVFIN", "PRF", "TRUNC"], "meter": "-+-+-+-+--+-+--+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "tiglich,", "tokens": ["tig\u00b7lich", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "--", "measure": "unknown.measure.zero"}, "line.5": {"text": "Es drehet sich die Luft im Wirbel. Der unter sich gest\u00fcrz-", "tokens": ["Es", "dre\u00b7het", "sich", "die", "Luft", "im", "Wir\u00b7bel", ".", "Der", "un\u00b7ter", "sich", "ge\u00b7st\u00fcrz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ART", "NN", "APPRART", "NN", "$.", "ART", "APPR", "PRF", "TRUNC"], "meter": "-+-+-+--+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.6": {"text": "te Duft,", "tokens": ["te", "Duft", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Der augenblicks erhobne Staub, die schwarze Dunkelheit", "tokens": ["Der", "au\u00b7gen\u00b7blicks", "er\u00b7hob\u00b7ne", "Staub", ",", "die", "schwar\u00b7ze", "Dun\u00b7kel\u00b7heit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.8": {"text": "der Luft,", "tokens": ["der", "Luft", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "Der Regen, Strohm-weis\u2019 abgest\u00fcrzt, Blitz, Hagel und", "tokens": ["Der", "Re\u00b7gen", ",", "Strohm\u00b7weis'", "ab\u00b7ge\u00b7st\u00fcrzt", ",", "Blitz", ",", "Ha\u00b7gel", "und"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "NN", "VVPP", "$,", "NN", "$,", "NN", "KON"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "des Donners Knall,", "tokens": ["des", "Don\u00b7ners", "Knall", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.11": {"text": "Erregen Schrecken, Furcht, Verheerung, und grossen", "tokens": ["Er\u00b7re\u00b7gen", "Schre\u00b7cken", ",", "Furcht", ",", "Ver\u00b7hee\u00b7rung", ",", "und", "gros\u00b7sen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "NN", "$,", "NN", "$,", "KON", "ADJA"], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}, "line.12": {"text": "Schaden \u00fcberall.", "tokens": ["Scha\u00b7den", "\u00fc\u00b7be\u00b7rall", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.13": {"text": "Die Segen-reiche Saat der Felder, die Pracht der G\u00e4rten", "tokens": ["Die", "Se\u00b7gen\u00b7rei\u00b7che", "Saat", "der", "Fel\u00b7der", ",", "die", "Pracht", "der", "G\u00e4r\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "sind zerst\u00f6rt,", "tokens": ["sind", "zer\u00b7st\u00f6rt", ","], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.15": {"text": "So B\u00e4um\u2019 als H\u00e4user umgest\u00fcrzt, und ganze L\u00e4nder", "tokens": ["So", "B\u00e4um'", "als", "H\u00e4u\u00b7ser", "um\u00b7ge\u00b7st\u00fcrzt", ",", "und", "gan\u00b7ze", "L\u00e4n\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "NN", "KOUS", "NN", "VVPP", "$,", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "umgekehrt.", "tokens": ["um\u00b7ge\u00b7kehrt", "."], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.3": {"line.1": {"text": "Allein, wird man solch wildes Wesen, das gleichsam", "tokens": ["Al\u00b7lein", ",", "wird", "man", "solch", "wil\u00b7des", "We\u00b7sen", ",", "das", "gleich\u00b7sam"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "VAFIN", "PIS", "PIAT", "ADJA", "NN", "$,", "PRELS", "ADJD"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "die Natur verheert,", "tokens": ["die", "Na\u00b7tur", "ver\u00b7heert", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Wohl eines weisen Sch\u00f6pfers F\u00fchrung, und GOttes", "tokens": ["Wohl", "ei\u00b7nes", "wei\u00b7sen", "Sch\u00f6p\u00b7fers", "F\u00fch\u00b7rung", ",", "und", "Got\u00b7tes"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "NN", "$,", "KON", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Werke nennen k\u00f6nnen?", "tokens": ["Wer\u00b7ke", "nen\u00b7nen", "k\u00f6n\u00b7nen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVINF", "VMINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Wir m\u00fcssen die\u00df kein wildes Wesen, und das unordentlich", "tokens": ["Wir", "m\u00fcs\u00b7sen", "die\u00df", "kein", "wil\u00b7des", "We\u00b7sen", ",", "und", "das", "un\u00b7or\u00b7dent\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PDS", "PIAT", "ADJA", "NN", "$,", "KON", "ART", "ADJD"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.6": {"text": "nicht nennen,", "tokens": ["nicht", "nen\u00b7nen", ","], "token_info": ["word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "$,"], "meter": "+--", "measure": "dactylic.init"}, "line.7": {"text": "Was in der That vorher gewollt, und minder nicht vorher", "tokens": ["Was", "in", "der", "That", "vor\u00b7her", "ge\u00b7wollt", ",", "und", "min\u00b7der", "nicht", "vor\u00b7her"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "ART", "NN", "ADV", "VMPP", "$,", "KON", "ADV", "PTKNEG", "ADV"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.8": {"text": "geseh'n,", "tokens": ["ge\u00b7seh'n", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "Als die Gesetze der Bewegung, wodurch die Wirkungen", "tokens": ["Als", "die", "Ge\u00b7set\u00b7ze", "der", "Be\u00b7we\u00b7gung", ",", "wo\u00b7durch", "die", "Wir\u00b7kun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "$,", "PWAV", "ART", "NN"], "meter": "++-+-+-+-+-+-+-", "measure": "unknown.measure.octa.plus"}, "line.10": {"text": "gescheh'n.", "tokens": ["ge\u00b7scheh'", "n."], "token_info": ["word", "abbreviation"], "pos": ["XY", "XY"], "meter": "-+", "measure": "iambic.single"}}, "stanza.4": {"line.1": {"text": "Sowohl der Donner und die Winde sind Gottes Werk\u2019,", "tokens": ["So\u00b7wohl", "der", "Don\u00b7ner", "und", "die", "Win\u00b7de", "sind", "Got\u00b7tes", "Werk'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "KON", "ART", "NN", "VAFIN", "NN", "NE", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "als Bl\u00fcht' und Fr\u00fcchte,", "tokens": ["als", "Bl\u00fcht'", "und", "Fr\u00fcch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Er schuf sowohl die bittern Mittel, als wie die s\u00fcssesten", "tokens": ["Er", "schuf", "so\u00b7wohl", "die", "bit\u00b7tern", "Mit\u00b7tel", ",", "als", "wie", "die", "s\u00fcs\u00b7ses\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "ART", "ADJA", "NN", "$,", "KOUS", "KOKOM", "ART", "ADJA"], "meter": "-+-+-+-+--+-+--", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Gerichte.", "tokens": ["Ge\u00b7rich\u00b7te", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.5": {"line.1": {"text": "Durch Sturm und Wind wird GOtt nicht minder ge-", "tokens": ["Durch", "Sturm", "und", "Wind", "wird", "Gott", "nicht", "min\u00b7der", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VAFIN", "NN", "PTKNEG", "ADV", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "horcht, erh\u00f6het und geehrt,", "tokens": ["horcht", ",", "er\u00b7h\u00f6\u00b7het", "und", "ge\u00b7ehrt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "KON", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Als wie durch Zephyrs sanftes Hauchen. Es ist kein", "tokens": ["Als", "wie", "durch", "Ze\u00b7phyrs", "sanf\u00b7tes", "Hau\u00b7chen", ".", "Es", "ist", "kein"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "KOKOM", "APPR", "NN", "ADJA", "NN", "$.", "PPER", "VAFIN", "PIAT"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "einzigs Seiner Werke,", "tokens": ["ein\u00b7zigs", "Sei\u00b7ner", "Wer\u00b7ke", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$,"], "meter": "++--+-", "measure": "trochaic.tri.relaxed"}, "line.5": {"text": "Das Seine Ehre nicht verbreitet, worinn man Seinen", "tokens": ["Das", "Sei\u00b7ne", "Eh\u00b7re", "nicht", "ver\u00b7brei\u00b7tet", ",", "wo\u00b7rinn", "man", "Sei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "PPOSAT", "NN", "PTKNEG", "VVPP", "$,", "PWAV", "PIS", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Ruhm nicht merke.", "tokens": ["Ruhm", "nicht", "mer\u00b7ke", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Sie richten alle treulich aus, was jeglichem zu thun", "tokens": ["Sie", "rich\u00b7ten", "al\u00b7le", "treu\u00b7lich", "aus", ",", "was", "jeg\u00b7li\u00b7chem", "zu", "thun"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "ADJD", "PTKVZ", "$,", "PRELS", "PIS", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.8": {"text": "geh\u00f6rt.", "tokens": ["ge\u00b7h\u00f6rt", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "Wir werden all\u2019 in einer Sprache, die deutlich ist, durch", "tokens": ["Wir", "wer\u00b7den", "all'", "in", "ei\u00b7ner", "Spra\u00b7che", ",", "die", "deut\u00b7lich", "ist", ",", "durch"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "PIS", "APPR", "ART", "NN", "$,", "PRELS", "ADJD", "VAFIN", "$,", "APPR"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "sie belehrt,", "tokens": ["sie", "be\u00b7lehrt", ","], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVPP", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.11": {"text": "Ob selbe gleich verschiedlich klinget.", "tokens": ["Ob", "sel\u00b7be", "gleich", "ver\u00b7schied\u00b7lich", "klin\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Welt belebet,", "tokens": ["Welt", "be\u00b7le\u00b7bet", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.13": {"text": "Zeigt uns den Umstand aller Wesen und alles Lebens in", "tokens": ["Zeigt", "uns", "den", "Um\u00b7stand", "al\u00b7ler", "We\u00b7sen", "und", "al\u00b7les", "Le\u00b7bens", "in"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "PIAT", "NN", "KON", "PIAT", "NN", "APPR"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.14": {"text": "der Welt.", "tokens": ["der", "Welt", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.15": {"text": "Durchs Licht, das alle Dinge schm\u00fccket, versch\u00f6nert,", "tokens": ["Durchs", "Licht", ",", "das", "al\u00b7le", "Din\u00b7ge", "schm\u00fc\u00b7cket", ",", "ver\u00b7sch\u00f6\u00b7nert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "sichtbar macht und zieret,", "tokens": ["sicht\u00b7bar", "macht", "und", "zie\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.17": {"text": "Wird man zur Urquell\u2019 aller Sch\u00f6nheit, und aller Ding\u2019", "tokens": ["Wird", "man", "zur", "Ur\u00b7quell'", "al\u00b7ler", "Sch\u00f6n\u00b7heit", ",", "und", "al\u00b7ler", "Ding'"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PIS", "APPRART", "NN", "PIAT", "NN", "$,", "KON", "PIAT", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "empor gef\u00fchret.", "tokens": ["em\u00b7por", "ge\u00b7f\u00fch\u00b7ret", "."], "token_info": ["word", "word", "punct"], "pos": ["PTKVZ", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.19": {"text": "Die Str\u00f6hme, Bluhmen, Fr\u00fcchte, Bl\u00e4tter, das Gras,", "tokens": ["Die", "Str\u00f6h\u00b7me", ",", "Bluh\u00b7men", ",", "Fr\u00fcch\u00b7te", ",", "Bl\u00e4t\u00b7ter", ",", "das", "Gras", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.20": {"text": "die Kr\u00e4uter, Wald und Feld,", "tokens": ["die", "Kr\u00e4u\u00b7ter", ",", "Wald", "und", "Feld", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.21": {"text": "Die reden mit uns unaufh\u00f6rlich von GOtt, dem Ursprung", "tokens": ["Die", "re\u00b7den", "mit", "uns", "un\u00b7auf\u00b7h\u00f6r\u00b7lich", "von", "Gott", ",", "dem", "Ur\u00b7sprung"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "PPER", "ADJD", "APPR", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "aller Gaben.", "tokens": ["al\u00b7ler", "Ga\u00b7ben", "."], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.23": {"text": "Allein, des Donners Stimme schreckt, die ihrer mi\u00dfge-", "tokens": ["Al\u00b7lein", ",", "des", "Don\u00b7ners", "Stim\u00b7me", "schreckt", ",", "die", "ih\u00b7rer", "mi\u00df\u00b7ge"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "ART", "NN", "NN", "VVFIN", "$,", "PRELS", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "brauchet haben,", "tokens": ["brau\u00b7chet", "ha\u00b7ben", ","], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "VAINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.25": {"text": "Und wenn der Blitz sie gleich nicht r\u00fchrt; so sind sie doch", "tokens": ["Und", "wenn", "der", "Blitz", "sie", "gleich", "nicht", "r\u00fchrt", ";", "so", "sind", "sie", "doch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "PPER", "ADV", "PTKNEG", "VVFIN", "$.", "ADV", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "in Furcht gebracht,", "tokens": ["in", "Furcht", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.27": {"text": "Ermnert und vermahnet worden. Von allen dem, was", "tokens": ["Erm\u00b7nert", "und", "ver\u00b7mah\u00b7net", "wor\u00b7den", ".", "Von", "al\u00b7len", "dem", ",", "was"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["VVPP", "KON", "VVPP", "VAPP", "$.", "APPR", "PIAT", "PDS", "$,", "PWS"], "meter": "+-+-+-+--+--+", "measure": "trochaic.hexa.relaxed"}, "line.28": {"text": "Gott gemacht,", "tokens": ["Gott", "ge\u00b7macht", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.6": {"line.1": {"text": "Und was uns rings umher umgiebt, ist nichts, das uns", "tokens": ["Und", "was", "uns", "rings", "um\u00b7her", "um\u00b7giebt", ",", "ist", "nichts", ",", "das", "uns"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "PWS", "PPER", "ADV", "PTKVZ", "VVFIN", "$,", "VAFIN", "PIS", "$,", "PRELS", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "von Jhm nicht spricht,", "tokens": ["von", "Jhm", "nicht", "spricht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Das uns, durch Zeichen einer G\u00fcte, nicht reizt, und uns", "tokens": ["Das", "uns", ",", "durch", "Zei\u00b7chen", "ei\u00b7ner", "G\u00fc\u00b7te", ",", "nicht", "reizt", ",", "und", "uns"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PDS", "PPER", "$,", "APPR", "NN", "ART", "NN", "$,", "PTKNEG", "VVFIN", "$,", "KON", "PPER"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "zur Liebe bringet,", "tokens": ["zur", "Lie\u00b7be", "brin\u00b7get", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Wie oder auch durch strenge Proben, und ein zu f\u00fcrchtend", "tokens": ["Wie", "o\u00b7der", "auch", "durch", "stren\u00b7ge", "Pro\u00b7ben", ",", "und", "ein", "zu", "f\u00fcrch\u00b7tend"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "KON", "ADV", "APPR", "ADJA", "NN", "$,", "KON", "ART", "PTKZU", "VVPP"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Straf-Gericht,", "tokens": ["Straf\u00b7Ge\u00b7richt", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Uns nicht Sein majest\u00e4tisch Wesen zu ehren und zu f\u00fcrch-", "tokens": ["Uns", "nicht", "Sein", "ma\u00b7jes\u00b7t\u00e4\u00b7tisch", "We\u00b7sen", "zu", "eh\u00b7ren", "und", "zu", "f\u00fcrch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "PTKNEG", "PPOSAT", "ADJD", "NN", "PTKZU", "VVINF", "KON", "APPR", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "ten zwinget.", "tokens": ["ten", "zwin\u00b7get", "."], "token_info": ["word", "word", "punct"], "pos": ["FM", "VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Zudem sind Ungewitter nicht nur blo\u00df bestimmt, uns zu", "tokens": ["Zu\u00b7dem", "sind", "Un\u00b7ge\u00b7wit\u00b7ter", "nicht", "nur", "blo\u00df", "be\u00b7stimmt", ",", "uns", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PAV", "VAFIN", "NN", "PTKNEG", "ADV", "ADV", "VVPP", "$,", "PPER", "PTKZU"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.10": {"text": "belehren,", "tokens": ["be\u00b7leh\u00b7ren", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.11": {"text": "Sie dienen, den durch lange Ruh verdickten Luft-Kreis", "tokens": ["Sie", "die\u00b7nen", ",", "den", "durch", "lan\u00b7ge", "Ruh", "ver\u00b7dick\u00b7ten", "Luft\u00b7Kreis"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVINF", "$,", "PRELS", "APPR", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-++", "measure": "unknown.measure.septa"}, "line.12": {"text": "aufzukl\u00e4ren,", "tokens": ["auf\u00b7zu\u00b7kl\u00e4\u00b7ren", ","], "token_info": ["word", "punct"], "pos": ["VVIZU", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.13": {"text": "Und aus dem Grunde zu verbessern, sie t\u00f6dten der Insecten", "tokens": ["Und", "aus", "dem", "Grun\u00b7de", "zu", "ver\u00b7bes\u00b7sern", ",", "sie", "t\u00f6d\u00b7ten", "der", "In\u00b7sec\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,", "PPER", "VVFIN", "ART", "NN"], "meter": "+--+-+-+--+-+-+-", "measure": "iambic.septa.invert"}, "line.14": {"text": "Brut,", "tokens": ["Brut", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.15": {"text": "Die sonst zwar n\u00fctzet, aber doch, durch ihre Menge, Scha-", "tokens": ["Die", "sonst", "zwar", "n\u00fct\u00b7zet", ",", "a\u00b7ber", "doch", ",", "durch", "ih\u00b7re", "Men\u00b7ge", ",", "Scha"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADV", "ADV", "VVFIN", "$,", "ADV", "ADV", "$,", "APPR", "PPOSAT", "NN", "$,", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.16": {"text": "den thut.", "tokens": ["den", "thut", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "VVFIN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.17": {"text": "Sie f\u00fcllen trockene Cysternen da, wo sonst keine Brunnen", "tokens": ["Sie", "f\u00fcl\u00b7len", "tro\u00b7cke\u00b7ne", "Cys\u00b7ter\u00b7nen", "da", ",", "wo", "sonst", "kei\u00b7ne", "Brun\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "PTKVZ", "$,", "PWAV", "ADV", "PIAT", "NN"], "meter": "-+-+--+--+-++-+-", "measure": "iambic.septa.relaxed"}, "line.18": {"text": "quellen,", "tokens": ["quel\u00b7len", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.19": {"text": "Und taugen, oft in einer Stunde, verseigte Str\u00f6hme her-", "tokens": ["Und", "tau\u00b7gen", ",", "oft", "in", "ei\u00b7ner", "Stun\u00b7de", ",", "ver\u00b7seig\u00b7te", "Str\u00f6h\u00b7me", "her"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "ADV", "APPR", "ART", "NN", "$,", "ADJA", "NN", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.20": {"text": "zustellen,", "tokens": ["zu\u00b7stel\u00b7len", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.21": {"text": "Die sonsten kaum, (wenn nicht zuweilen ein Regen-reicher", "tokens": ["Die", "sons\u00b7ten", "kaum", ",", "(", "wenn", "nicht", "zu\u00b7wei\u00b7len", "ein", "Re\u00b7gen\u00b7rei\u00b7cher"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "$,", "$(", "KOUS", "PTKNEG", "ADV", "ART", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Donner br\u00fcllt)", "tokens": ["Don\u00b7ner", "br\u00fcllt", ")"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.23": {"text": "Mit einem schwach- und langen Flu\u00df der Winter in viel", "tokens": ["Mit", "ei\u00b7nem", "schwach", "und", "lan\u00b7gen", "Flu\u00df", "der", "Win\u00b7ter", "in", "viel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "TRUNC", "KON", "ADJA", "NN", "ART", "NN", "APPR", "PIAT"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.24": {"text": "Wochen f\u00fcllt.", "tokens": ["Wo\u00b7chen", "f\u00fcllt", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.7": {"line.1": {"text": "Ach, la\u00dft uns denn, nebst Seiner Macht, des Sch\u00f6pfers", "tokens": ["Ach", ",", "la\u00dft", "uns", "denn", ",", "nebst", "Sei\u00b7ner", "Macht", ",", "des", "Sch\u00f6p\u00b7fers"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ITJ", "$,", "VVIMP", "PPER", "ADV", "$,", "APPR", "PPOSAT", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Huld und Liebe fassen,", "tokens": ["Huld", "und", "Lie\u00b7be", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und uns von Seinen weisen Wegen in der Natur beleh-", "tokens": ["Und", "uns", "von", "Sei\u00b7nen", "wei\u00b7sen", "We\u00b7gen", "in", "der", "Na\u00b7tur", "be\u00b7leh"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "PPOSAT", "ADJA", "NN", "APPR", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-++-+-+", "measure": "unknown.measure.octa.plus"}, "line.4": {"text": "ren lassen!", "tokens": ["ren", "las\u00b7sen", "!"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Ach, la\u00dft uns Ordnung, Kunst und Absicht auch in den", "tokens": ["Ach", ",", "la\u00dft", "uns", "Ord\u00b7nung", ",", "Kunst", "und", "Ab\u00b7sicht", "auch", "in", "den"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "VVIMP", "PPER", "NN", "$,", "NN", "KON", "NN", "ADV", "APPR", "ART"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "C\u00f6rpern, die so klein,", "tokens": ["C\u00f6r\u00b7pern", ",", "die", "so", "klein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ADV", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Und doch so grosse Dinge wirken, bewundern, froh und", "tokens": ["Und", "doch", "so", "gros\u00b7se", "Din\u00b7ge", "wir\u00b7ken", ",", "be\u00b7wun\u00b7dern", ",", "froh", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "ADV", "ADJA", "NN", "VVINF", "$,", "VVINF", "$,", "ADJD", "KON"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "dankbar seyn!", "tokens": ["dank\u00b7bar", "seyn", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VAINF", "$."], "meter": "+-+", "measure": "trochaic.di"}}}}}